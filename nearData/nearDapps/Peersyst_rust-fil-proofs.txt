*GitHub Repository "Peersyst/rust-fil-proofs"*

'''--- .circleci/config.yml ---
version: 2.1

jobs:
  ensure_groth_parameters_and_keys_linux:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - restore_parameter_cache
      - ensure_filecoin_parameters
      - save_parameter_cache
  cargo_fetch:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - run:
          name: Calculate dependencies
          command: cargo generate-lockfile
          no_output_timeout: 30m
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - run: rustup install $(cat rust-toolchain)
      - run: rustup default $(cat rust-toolchain)
      - run: rustup component add rustfmt-preview
      - run: rustup component add clippy
      - run: cargo update
      - run: cargo fetch
      - run: rustc +stable --version
      - run: rustc +$(cat rust-toolchain) --version
      - persist_to_workspace:
          root: "."
          paths:
            - Cargo.lock
      - save_cache:
          key: cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
          paths:
            - /root/.cargo
            - /root/.rustup
  test:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - restore_parameter_cache
      - run:
          name: Test (stable)
          command: cargo +stable test --verbose --all
          no_output_timeout: 15m
      - run:
          name: Prune the output files
          command: |
            for file in target/debug/* target/debug/.??*; do
              [ -d $file -o ! -x $file ] && rm -r $file
            done
      - persist_to_workspace:
          root: "."
          paths:
            - target/debug/*

  test_release:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - restore_parameter_cache
      - run:
          name: Test (stable) in release profile
          command: |
            cargo +stable test --verbose --release --all
            RUSTFLAGS="-D warnings" cargo +stable build --examples --release --all

  test_ignored_release:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    parameters:
      crate:
        type: string
      features:
        type: string
        default: ""
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - restore_parameter_cache
      - run:
          name: Test ignored in release profile
          command: |
              cd << parameters.crate >>
              cargo test --release << parameters.features >> -- --ignored
          environment:
            RUST_TEST_THREADS: 1
          no_output_timeout: 30m

  test_nightly:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - restore_parameter_cache
      - run:
          name: Test (nightly)
          command: cargo +$(cat rust-toolchain) test --verbose --all
          no_output_timeout: 15m

  bench_nightly:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - restore_parameter_cache
      - run:
          name: Benchmarks (nightly)
          command: cargo +$(cat rust-toolchain) build --benches --verbose --all
          no_output_timeout: 15m

  metrics_capture:
    docker:
      - image: filecoin/rust:latest
    environment:
      RUSTFLAGS: -Awarnings -C target-cpu=native
    working_directory: /mnt/crate
    resource_class: 2xlarge+
    steps:
      - add_ssh_keys:
          fingerprints:
            - "f8:db:3c:6d:f9:74:2c:9e:07:42:3f:3f:23:07:f7:6d"
      - run:
          name: Add benchmark server's public key to known hosts
          command: |
            mkdir -p ~/.ssh/
            if [[ ! -f ~/.ssh/known_hosts ]] || ! grep "${BENCHMARK_SERVER_IP_ADDR}" ~/.ssh/known_hosts; then
              echo "
            ${BENCHMARK_SERVER_RSA_FINGERPRINT}
              " >> ~/.ssh/known_hosts
            fi
      - checkout
      - attach_workspace:
          at: "."
      - run:
          name: Install jq
          command: apt-get install time jq -yqq
      - run:
          name: Ensure existence of Groth parameters and keys on remote host
          command: |
            ./fil-proofs-tooling/scripts/run-remote.sh "${CIRCLE_BRANCH}" "${BENCHMARK_SERVER_SSH_USERNAME}@${BENCHMARK_SERVER_IP_ADDR}" cargo run --release --package filecoin-proofs --bin=paramcache -- --params-for-sector-sizes=$((512*1024*1024))
          no_output_timeout: 60m
      - run:
          name: Run hash-constraints benchmarks on remote host
          command: |
            ./fil-proofs-tooling/scripts/run-remote.sh "${CIRCLE_BRANCH}" "${BENCHMARK_SERVER_SSH_USERNAME}@${BENCHMARK_SERVER_IP_ADDR}" ./fil-proofs-tooling/scripts/benchy.sh hash-constraints > hash-constraints.json
            cat hash-constraints.json
          no_output_timeout: 60m
      - run:
          name: Run micro benchmarks
          command: |
            ./fil-proofs-tooling/scripts/run-remote.sh "${CIRCLE_BRANCH}" "${BENCHMARK_SERVER_SSH_USERNAME}@${BENCHMARK_SERVER_IP_ADDR}" ./fil-proofs-tooling/scripts/micro.sh > micro-benchmarks.json
            cat micro-benchmarks.json
          no_output_timeout: 60m
      - run:
          name: Run stacked benchmarks using 512MiB sectors
          command: |
            ./fil-proofs-tooling/scripts/run-remote.sh "${CIRCLE_BRANCH}" "${BENCHMARK_SERVER_SSH_USERNAME}@${BENCHMARK_SERVER_IP_ADDR}" ./fil-proofs-tooling/scripts/benchy.sh stacked --size=$((512*1024)) > stacked-benchmarks.json
            cat stacked-benchmarks.json
          no_output_timeout: 60m
      - run:
          name: Run Window PoST benchmarks using a 512MiB sector
          command: |
            ./fil-proofs-tooling/scripts/run-remote.sh "${CIRCLE_BRANCH}" "${BENCHMARK_SERVER_SSH_USERNAME}@${BENCHMARK_SERVER_IP_ADDR}" ./fil-proofs-tooling/scripts/benchy.sh window-post --size=$((512*1024)) > window-post-benchmarks.json
            cat window-post-benchmarks.json
          no_output_timeout: 60m
      - run:
          name: Aggregate benchmarks into single JSON document
          command: |
            ./fil-proofs-tooling/scripts/aggregate-benchmarks.sh stacked-benchmarks.json micro-benchmarks.json hash-constraints.json window-post-benchmarks.json > aggregated-benchmarks.json
            cat aggregated-benchmarks.json
      - store_artifacts:
          path: stacked-benchmarks.json
      - store_artifacts:
          path: hash-constraints.json
      - store_artifacts:
          path: micro-benchmarks.json
      - store_artifacts:
          path: aggregated-benchmarks.json

  rustfmt:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - run:
          name: Run cargo fmt
          command: cargo fmt --all -- --check

  clippy:
    docker:
      - image: filecoin/rust:latest
    working_directory: /mnt/crate
    resource_class: 2xlarge
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - restore_cache:
          keys:
            - cargo-v27f-{{ checksum "rust-toolchain" }}-{{ checksum "Cargo.toml" }}-{{ checksum "Cargo.lock" }}-{{ arch }}
      - run:
          name: Run cargo clippy
          command: cargo +$(cat rust-toolchain) clippy --all
  test_nightly_darwin:
    macos:
      xcode: "10.0.0"
    working_directory: ~/crate
    resource_class: large
    steps:
      - configure_environment_variables
      - checkout
      - run:
          name: Install Rust
          command: |
            curl https://sh.rustup.rs -sSf | sh -s -- -y
      - run: rustup install $(cat rust-toolchain)
      - run: rustup default $(cat rust-toolchain)
      - run: cargo update
      - run: cargo fetch
      - run:
          name: Test (nightly, Darwin)
          command: |
            sudo ulimit -n 20000
            sudo ulimit -u 20000
            ulimit -n 20000
            cargo +$(cat rust-toolchain) test --release --verbose --all
          no_output_timeout: 2h

  validate_commit_msg:
    docker:
      - image: circleci/node:latest
    resource_class: xlarge
    steps:
      - configure_environment_variables
      - checkout
      - attach_workspace:
          at: "."
      - run:
          name: Install dependencies
          command: npm i @commitlint/config-angular @commitlint/cli
      - run:
          name: Validate Commit Messages
          command: |
              npx commitlint --extends @commitlint/config-angular --from origin/master --to $CIRCLE_SHA1
commands:
  ensure_filecoin_parameters:
    steps:
      - configure_environment_variables
      - run:
          name: Build paramcache if it doesn't already exist
          command: |
            set -x; test -f ~/paramcache.awesome \
            || (cargo build --release --all && find . -type f -name paramcache | xargs -I {} mv {} ~/paramcache.awesome)
      - run:
          name: Obtain filecoin groth parameters
          command: ~/paramcache.awesome --params-for-sector-sizes='2048,4096,16384,32768'
          no_output_timeout: 60m
  save_parameter_cache:
    steps:
      - save_cache:
          key: proof-params-v27f-{{ checksum "filecoin-proofs/parameters.json" }}-{{ arch }}
          paths:
            - "~/paramcache.awesome"
            - "~/filecoin-proof-parameters/"
  restore_parameter_cache:
    steps:
      - configure_environment_variables
      - restore_cache:
         keys:
            - proof-params-v27f-{{ checksum "filecoin-proofs/parameters.json" }}-{{ arch }}
  configure_environment_variables:
    steps:
      - run:
          name: Configure environment variables
          command: |
            echo 'export FIL_PROOFS_PARAMETER_CACHE="${HOME}/filecoin-proof-parameters/"' >> $BASH_ENV
            echo 'export PATH="${HOME}/.cargo/bin:${PATH}"' >> $BASH_ENV
            echo 'export RUST_LOG=info' >> $BASH_ENV

workflows:
  version: 2.1
  test_all:
    jobs:
      - ensure_groth_parameters_and_keys_linux
      - cargo_fetch
      - rustfmt:
          requires:
            - cargo_fetch
      - clippy:
          requires:
            - cargo_fetch
      - test_release:
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test_ignored_release:
          name: test_ignored_release_storage_proofs_post
          crate: "storage-proofs/post"
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test_ignored_release:
          name: test_ignored_release_storage_proofs_core
          crate: "storage-proofs/core"
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test_ignored_release:
          name: test_ignored_release_storage_proofs_porep
          crate: "storage-proofs/porep"
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test_ignored_release:
          name: test_ignored_release_filecoin_proofs
          crate: "filecoin-proofs"
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test:
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - test_nightly:
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - bench_nightly:
          requires:
            - cargo_fetch
            - ensure_groth_parameters_and_keys_linux
      - validate_commit_msg
      - test_nightly_darwin
      - metrics_capture:
          requires:
            - cargo_fetch
          filters:
            branches:
              only:
                - master

'''
'''--- .clippy.toml ---
type-complexity-threshold = 400
'''
'''--- CHANGELOG.md ---
# Changelog

All notable changes to rust-fil-proofs will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://book.async.rs/overview/stability-guarantees.html).

## Unreleased

## 2.0.0 - 2020-05-27

- Add a method 'unseal_range' to unseal a sector to a file descriptor
- Calculate required config count based on tree shape
- Update merkle tree cached tree usage (fixing an incorrect size usage)
- Replace merkle_light 'height' property usage with 'row_count'
- Update stacked bench usage of recent replica changes

## 1.0.0 - 2020-05-19

- Initial stable release

'''
'''--- CONTRIBUTING.md ---
# Contributing

Welcome, it is great that you found your way here. In order to make the best of all our time, we have gathered some notes
below which we think can be helpful when contributing to this project.

## Getting Started

Please start by reviewing this file.

## Coding Standards

- No compiler warnings.
- No [clippy](https://github.com/rust-lang/rust-clippy) warnings.
- Minimize use of `unsafe` and justify usage in comments.
- Prefer `expect` with a good description to `unwrap`.
- Write unit tests in the same file.
- Format your code with `rustfmt`
- Code should compile on `stable` and `nightly`. If adding `nightly` only features they should be behind a flag.
- Write benchmarks for performance sensitive areas. We use [criterion.rs](https://github.com/japaric/criterion.rs).

## General Guidelines
- PRs require code owner approval to merge.
- Please scope PRs to areas in which you have expertise. This code is still close to research.
- Please follow our commit guideline described below.
- Welcome contribution areas might include:
  - SNARKs
  - Proof-of-replication
  - Rust improvements
  - Optimizations
  - Documentation (expertise would require careful reading of the code)

## PR Merge Policy (Git topology)

### Allowed (white list)
 - Single fast-forward merge commit, with all internal commits squashed.
 - Non-fast-forward merge commit, with all internal commits squashed -- rebased to branch from the previous commit to master.
 - Non-fast-forward merge commit, with curated (as appropriate), linear, internal commits preserved -- rebased to branch from the previous commit to master.

### Disallowed (black list)
 - Non-rebased merge commits which branch from anywhere but the previous commit to master.
 - Merge commits whose internal history contains merge commits (except in rare circumstances).
 - Multiple fast-forward merge commits for a single PR.
 - Internal junk commits — (e.g. strings of WIP).

### In Practice
 - In general, please rebase PRs before merging.
 - To avoid having approvals dismissed by rebasing, authors may instead choose to:
   - First use GitHub's 'resolve conflicts' button;
   - Then merge with GitHub's 'squash and merge' button.

If automated conflict resolution is not possible, you will need to rebase and seek re-approval. In any event, please note the guidelines and prefer either a single commit or a usefully curated set of commits.

## Resources for learning Rust

- Beginners
  - [The Rust Book](https://doc.rust-lang.org/book/)
  - [Rust Playground](https://play.rust-lang.org/)
  - [Rust Docs](https://doc.rust-lang.org/)
  - [Clippy](https://github.com/rust-lang/rust-clippy)
  - [Rustfmt](https://github.com/rust-lang/rustfmt)
- Advanced
  - What does the Rust compiler do with my code? [Godbolt compiler explorer](https://rust.godbolt.org/)
  - How to safely write unsafe Rust: [The Rustonomicon](https://doc.rust-lang.org/nomicon/)
  - Did someone say macros? [The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/index.html)

## Commit Message Guidelines

We have very precise rules over how our git commit messages can be formatted. This leads to **more
readable messages** that are easy to follow when looking through the **project history**. But also,
we use the git commit messages to **generate the change log programmatically**.

### Commit Message Format

Each commit message consists of a **header**, a **body** and a **footer**.  The header has a special
format that includes a **type**, a **scope** and a **subject**:

```
<type>(<scope>): <subject>
<BLANK LINE>
<body>
<BLANK LINE>
<footer>
```

The **header** is mandatory and the **scope** of the header is optional.

Any line of the commit message cannot be longer 100 characters! This allows the message to be easier
to read on GitHub as well as in various git tools.

The footer should contain a [closing reference to an issue](https://help.github.com/articles/closing-issues-via-commit-messages/) if any.

Samples: (even more [samples](https://github.com/filecoin-project/rust-fil-proofs/commits/master))

```
docs(changelog): update changelog to beta.5
```
```
fix(release): need to depend on latest rxjs and zone.js
The version in our package.json gets copied to the one we publish, and users need the latest of these.
```

### Revert
If the commit reverts a previous commit, it should begin with `revert: `, followed by the header of the reverted commit. In the body it should say: `This reverts commit <hash>.`, where the hash is the SHA of the commit being reverted.

### Type
Must be one of the following:

* **build**: Changes that affect the build system or external dependencies (example scopes: cargo, benchmarks)
* **ci**: Changes to our CI configuration files and scripts (example scopes: Circle)
* **docs**: Documentation only changes
* **feat**: A new feature
* **fix**: A bug fix
* **perf**: A code change that improves performance
* **refactor**: A code change that neither fixes a bug nor adds a feature
* **style**: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)
* **test**: Adding missing tests or correcting existing tests
* **revert**: Used only for `git revert` commits.

### Scope
The scope should be the name of the crate affected (as perceived by the person reading the changelog generated from commit messages.

The following is the list of supported scopes:

* **fil-proofs-tooling**
* **filecoin-proofs**
* **storage-proofs**

There are currently a few exceptions to the "use package name" rule:

* **cargo**: used for changes that change the cargo workspace layout, e.g.
  public path changes, Cargo.toml changes done to all packages, etc.
* **changelog**: used for updating the release notes in CHANGELOG.md
* none/empty string: useful for `style`, `test` and `refactor` changes that are done across all
  packages (e.g. `style: add missing semicolons`) and for docs changes that are not related to a
  specific package (e.g. `docs: fix typo in tutorial`).

> If you find yourself wanting to use other scopes regularly, please open an issue so we can discuss and extend this list.

### Subject
The subject contains a succinct description of the change:

* use the imperative, present tense: "change" not "changed" nor "changes"
* don't capitalize the first letter
* no dot (.) at the end

### Body
Just as in the **subject**, use the imperative, present tense: "change" not "changed" nor "changes".
The body should include the motivation for the change and contrast this with previous behavior.

### Footer
The footer should contain any information about **Breaking Changes** and is also the place to
reference GitHub issues that this commit **Closes**.

**Breaking Changes** should start with the word `BREAKING CHANGE:` with a space or two newlines. The rest of the commit message is then used for this.

This guideline was adopted from the [Angular project](https://github.com/angular/angular/blob/master/CONTRIBUTING.md#commit).

## Licensing

As mentioned in the [readme](README.md) all contributions are dual licensed under Apache 2 and MIT.

'''
'''--- Cargo.toml ---
[workspace]

members = [
  "filecoin-proofs",
  "storage-proofs",
  "storage-proofs/core",
  "storage-proofs/porep",
  "storage-proofs/post",
  "fil-proofs-tooling",
  "sha2raw"
]

'''
'''--- README.md ---
# Filecoin Proving Subsystem (FPS)

The **Filecoin Proving Subsystem** provides the storage proofs required by the Filecoin protocol. It is implemented entirely in Rust, as a series of partially inter-dependent crates – some of which export C bindings to the supported API. This decomposition into distinct crates/modules is relatively recent, and in some cases current code has not been fully refactored to reflect the intended eventual organization.

There are currently four different crates:

- [**Storage Proofs (`storage-proofs`)**](./storage-proofs)
    A library for constructing storage proofs – including non-circuit proofs, corresponding SNARK circuits, and a method of combining them.

    `storage-proofs` is intended to serve as a reference implementation for _**Proof-of-Replication**_ (**PoRep**), while also performing the heavy lifting for `filecoin-proofs`.

     Primary Components:
     -   **PoR** (**_Proof-of-Retrievability_**: Merkle inclusion proof)
     -   **DrgPoRep** (_Depth Robust Graph_ **_Proof-of-Replication_**)
     -   **StackedDrgPoRep**
     -   **PoSt** (Proof-of-Spacetime)

- [**Filecoin Proofs (`filecoin-proofs`)**](./filecoin-proofs)
  A wrapper around `storage-proofs`, providing an FFI-exported API callable from C (and in practice called by [go-filecoin](https://github.com/filecoin-project/go-filecoin') via cgo). Filecoin-specific values of setup parameters are included here, and circuit parameters generated by Filecoin’s (future) trusted setup will also live here.

    ![FPS crate dependencies](/img/fps-dependencies.png?raw=true)

## Design Notes

Earlier in the design process, we considered implementing what has become the **FPS** in Go – as a wrapper around potentially multiple SNARK circuit libraries. We eventually decided to use [bellman](https://github.com/zkcrypto/bellman) – a library developed by Zcash, which supports efficient pedersen hashing inside of SNARKs. Having made that decision, it was natural and efficient to implement the entire subsystem in Rust. We considered the benefits (self-contained codebase, ability to rely on static typing across layers) and costs (developer ramp-up, sometimes unwieldiness of borrow-checker) as part of that larger decision and determined that the overall project benefits (in particular ability to build on Zcash’s work) outweighed the costs.

We also considered whether the **FPS** should be implemented as a standalone binary accessed from [**`go-filecoin`**](https://github.com/filecoin-project/go-filecoin) either as a single-invocation CLI or as a long-running daemon process. Bundling the **FPS** as an FFI dependency was chosen for both the simplicity of having a Filecoin node deliverable as a single monolithic binary, and for the (perceived) relative development simplicity of the API implementation.

If at any point it were to become clear that the FFI approach is irredeemably problematic, the option of moving to a standalone **FPS** remains. However, the majority of technical problems associated with calling from Go into Rust are now solved, even while allowing for a high degree of runtime configurability. Therefore, continuing down the same path we have already invested in, and have begun to reap rewards from, seems likely.

## Install and configure Rust

**NOTE:** If you have installed `rust-fil-proofs` incidentally, as a submodule of `go-filecoin`, then you may already have installed Rust.

The instructions below assume you have independently installed `rust-fil-proofs` in order to test, develop, or experiment with it.

[Install Rust.](https://www.rust-lang.org/en-US/install.html)

Configure to use nightly:

```
> rustup default nightly
```

## Build

**NOTE:** `rust-fil-proofs` can only be built for and run on 64-bit platforms; building will panic if the target architecture is not 64-bits.

```
> cargo build --release --all
```

## Test

```
> cargo test --all
```

## Examples

```
> cargo build --all --examples --release
```

Running them

```
> ./target/release/examples/merklepor
> ./target/release/examples/drgporep
> ./target/release/examples/drgporep-vanilla
> ./target/release/examples/drgporep-vanilla-disk
```

## Benchmarks

```
> cargo bench --all
```

To benchmark the examples you can [bencher](src/bin/bencher.rs).

```
# build the script
> cargo build
# run the benchmarks
> ./target/debug/bencher
```

The results are written into the `.bencher` directory, as JSON files. The benchmarks are controlled through the [bench.config.toml](bench.config.toml) file.

Note: On macOS you need `gtime` (`brew install gnu-time`), as the built in `time` command is not enough.

## Profiling

For development purposes we have an (experimental) support for CPU and memory profiling in Rust through a [`gperftools`](https://github.com/dignifiedquire/rust-gperftools) binding library. These can be enabled though the `cpu-profile` and `heap-profile` features in `filecoin-proofs`. An example setup can be found in this [`Dockerfile`](./Dockerfile-profile) to profile CPU usage for the [`stacked`](https://github.com/filecoin-project/rust-fil-proofs/blob/master/filecoin-proofs/examples/stacked.rs#L40-L61) example.

## Logging

For better logging with backtraces on errors, developers should use `expects` rather than `expect` on `Result<T, E>` and `Option<T>`.

The crate use [`log`](https://crates.io/crates/log) for logging, which by default does not log at all. In order to log output crates like [`fil_logger`](https://crates.io/crates/fil_logger) can be used.

For example

```rust
fn main() {
    fil_logger::init();
}
```

and then when running the code setting

```sh
> RUST_LOG=filecoin_proofs=info
```

will enable all logging.

## Memory Leak Detection

To run the leak detector against the FFI-exposed portion of
libsector_builder_ffi.a, simply run the FFI example with leak detection enabled.
On a Linux machine, you can run the following command:

```shell
RUSTFLAGS="-Z sanitizer=leak" cargo run --release --package filecoin-proofs --example ffi --target x86_64-unknown-linux-gnu
```

If using mac OS, you'll have to run the leak detection from within a Docker
container. After installing Docker, run the following commands to build and run
the proper Docker image and then the leak detector itself:

```shell
docker build -t foo -f ./Dockerfile-ci . && \
  docker run \
    -it \
    -e RUSTFLAGS="-Z sanitizer=leak" \
    --privileged \
    -w /mnt/crate \
    -v `pwd`:/mnt/crate -v $(TMP=$(mktemp -d) && mv ${TMP} /tmp/ && echo /tmp${TMP}):/mnt/crate/target \
    foo:latest \
    cargo run --release --package filecoin-proofs --example ffi --target x86_64-unknown-linux-gnu
```

## Optimizing for either speed or memory during replication

While replicating and generating the Merkle Trees (MT) for the proof at the same time there will always be a time-memory trade-off to consider, we present here strategies to optimize one at the cost of the other.

### Speed

One of the most computational expensive operations during replication (besides the encoding itself) is the generation of the indexes of the (expansion) parents in the Stacked graph, implemented through a Feistel cipher (used as a pseudorandom permutation). To reduce that time we provide a caching mechanism to generate them only once and reuse them throughout replication (across the different layers). Already built into the system it can be activated with the environmental variable

```
FIL_PROOFS_MAXIMIZE_CACHING=1
```

To check that it's working you can inspect the replication log to find `using parents cache of unlimited size`. As the log indicates, we don't have a fine grain control at the moment so it either stores all parents or none. This cache can add almost an entire sector size to the memory used during replication, if you can spare it though this setting is _very recommended_ as it has a considerable impact on replication time.

(You can also verify if the cache is working by inspecting the time each layer takes to encode, `encoding, layer:` in the log, where the first two layers, forward and reverse, will take more time than the rest to populate the cache while the remaining 8 should see a considerable time drop.)

**Speed Optimized Pedersen Hashing** - we use Pedersen hashing to generate Merkle Trees and verify Merkle proofs. Batched Pedersen hashing has the property that we can pre-compute known intermediary values intrinsic to the Pedersen hashing process that will be reused across hashes in the batch. By pre-computing and cacheing these intermediary values, we decrease the runtime per Pedersen hash at the cost of increasing memory usage. We optimize for this speed-memory trade-off by varying the cache size via a Pedersen Hash parameter known as the "window-size". This window-size parameter is configured via the [`pedersen_hash_exp_window_size` setting in `storage-proofs`](https://github.com/filecoin-project/rust-fil-proofs/blob/master/storage-proofs/src/settings.rs). By default, Bellman has a cache size of 256 values (a window-size of 8 bits), we increase the cache size to 65,536 values (a window-size of 16 bits) which results in a roughly 40% decrease in Pedersen Hash runtime at the cost of a 9% increase in memory usage. See the [Pedersen cache issue](https://github.com/filecoin-project/rust-fil-proofs/issues/697) for more benchmarks and expected performance effects.

### Memory

At the moment the default configuration is set to reduce memory consumption as much as possible so there's not much to do from the user side. (We are now storing MTs on disk, which were the main source of memory consumption.) You should expect a maximum RSS between 1-2 sector sizes, if you experience peaks beyond that range please report an issue (you can check the max RSS with the `/usr/bin/time -v` command).

**Memory Optimized Pedersen Hashing** - for consumers of `storage-proofs` concerned with memory usage, the memory usage of Pedersen hashing can be reduced by lowering the Pederen Hash `window-size` parameter (i.e. its cache size). Reducing the cache size will reduce memory usage while increasing the runtime per Pedersen hash. The Pedersen Hash window-size can be changed via the setting `pedersen_hash_exp_window_size` in [`settings.rs`](https://github.com/filecoin-project/rust-fil-proofs/blob/master/storage-proofs/src/settings.rs). See the [Pedersen cache issue](https://github.com/filecoin-project/rust-fil-proofs/issues/697) for more benchmarks and expected performance effects.

The following benchmarks were observed when running replication on 1MiB (1024 kibibytes) of data on a new m5a.2xlarge EC2 instance with 32GB of RAM for Pedersen Hash window-sizes of 16 (the current default) and 8 bits:

```
$ cargo build --bin benchy --release
$ env time -v cargo run --bin benchy --release -- stacked --size=1024

window-size: 16
User time (seconds): 87.82
Maximum resident set size (kbytes): 1712320

window-size: 8
User time (seconds): 128.85
Maximum resident set size (kbytes): 1061564
```

Note that for a window-size of 16 bits the runtime for replication is 30% faster while the maximum RSS is about 40% higher compared to a window-size of 8 bits.

## Generate Documentation

First, navigate to the `rust-fil-proofs` directory.
- If you installed `rust-fil-proofs` automatically as a submodule of `go-filecoin`:
```
> cd <go-filecoin-install-path>/go-filecoin/proofs/rust-fil-proofs
```

- If you cloned `rust-fil-proofs` manually, it will be wherever you cloned it:
```
> cd <install-path>/rust-fil-proofs
```

[Note that the version of `rust-fil-proofs` included in `go-filecoin` as a submodule is not always the current head of `rust-fil-proofs/master`. For documentation corresponding to the latest source, you should clone `rust-fil-proofs` yourself.]

Now, generate the documentation:
```
> cargo doc --all --no-deps
```

View the docs by pointing your browser at: `…/rust-fil-proofs/target/doc/proofs/index.html`.

---

## API Reference

The **FPS** is accessed from [**go-filecoin**](https://github.com/filecoin-project/go-filecoin) via FFI calls to its API, which is the union of the APIs of its constituents:

 The Rust source code serves as the source of truth defining the **FPS** APIs. View the source directly:

- [**filecoin-proofs**](https://github.com/filecoin-project/rust-fil-proofs/blob/master/filecoin-proofs/src/api/mod.rs)
- [**sector-base**](https://github.com/filecoin-project/rust-fil-proofs/blob/master/sector-base/README.md#api-reference).

Or better, generate the documentation locally (until repository is public). Follow the instructions to generate documentation above. Then navigate to:
- **Sector Base API:** `…/rust-fil-proofs/target/doc/sector_base/api/index.html`
- **Filecoin Proofs API:** `…/rust-fil-proofs/target/doc/filecoin_proofs/api/index.html`

- [Go implementation of filecoin-proofs sectorbuilder API](https://github.com/filecoin-project/go-filecoin/blob/master/proofs/sectorbuilder/rustsectorbuilder.go) and [associated interface structures](https://github.com/filecoin-project/go-filecoin/blob/master/proofs/sectorbuilder/interface.go).
- [Go implementation of filecoin-proofs verifier API](https://github.com/filecoin-project/go-filecoin/blob/master/proofs/rustverifier.go) and [associated interface structures](https://github.com/filecoin-project/go-filecoin/blob/master/proofs/interface.go).

## Contributing

See [Contributing](CONTRIBUTING.md)

## License

The Filecoin Project is dual-licensed under Apache 2.0 and MIT terms:

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

'''
'''--- fil-proofs-tooling/Cargo.toml ---
[package]
name = "fil-proofs-tooling"
description = "Tooling for rust-fil-proofs"
version = "2.0.0"
authors = ["dignifiedquire <dignifiedquire@gmail.com>"]
license = "MIT OR Apache-2.0"
publish = false
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[dependencies]
clap = "2"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.5"
permutate = "0.3"
lazy_static = "1.2"
glob = "0.3"
human-size = "0.4"
prettytable-rs = "0.8"
regex = "=1.3.7"
commandspec = "0.12.2"
chrono = { version = "0.4.7", features = ["serde"] }
memmap = "0.7.0"
bellperson = "0.8.0"
paired = "0.19.0"
fil-sapling-crypto = "0.6.0"
rand = "0.7"
storage-proofs = { path = "../storage-proofs"}
filecoin-proofs = { path = "../filecoin-proofs"}
tempfile = "3.0.8"
cpu-time = "1.0.0"
git2 = "0.10.1"
heim = "0.0.9"
futures-preview = "0.3.0-alpha.17"
raw-cpuid = "7.0.3"
blake2s_simd = "0.5.6"
fil_logger = "0.1"
log = "0.4.8"
uom = "0.26"
merkletree = "0.20.0"
bincode = "1.1.2"
anyhow = "1.0.23"
ff = { version = "0.2.0", package = "fff" }
rand_xorshift = "0.2.0"
bytefmt = "0.1.7"
rayon = "1.3.0"
flexi_logger = "0.14.7"
typenum = "1.11.2"

[features]
default = ["gpu", "measurements"]
gpu = ["storage-proofs/gpu", "filecoin-proofs/gpu", "bellperson/gpu", "fil-sapling-crypto/gpu"]
measurements = ["storage-proofs/measurements"]
profile = ["storage-proofs/profile", "measurements"]

'''
'''--- fil-proofs-tooling/README.md ---
# fil-proofs-tooling

This crate contains the following binaries

- `benchy` - Can be used to capture Stacked performance metrics
- `micro` - Runs the micro benchmarks written with criterion, parses the output.

## `benchy`

The `benchy` program can (currently) be used to capture Stacked performance
metrics. Metrics are printed to stdout.

```
$ ./target/release/benchy stacked --size=1024 | jq '.'
{
  "inputs": {
    "dataSize": 1048576,
    "m": 5,
    "expansionDegree": 8,
    "slothIter": 0,
    "partitions": 1,
    "hasher": "pedersen",
    "samples": 5,
    "layers": 10
  },
  "outputs": {
    "avgGrothVerifyingCpuTimeMs": null,
    "avgGrothVerifyingWallTimeMs": null,
    "circuitNumConstraints": null,
    "circuitNumInputs": null,
    "extractingCpuTimeMs": null,
    "extractingWallTimeMs": null,
    "replicationWallTimeMs": 4318,
    "replicationCpuTimeMs": 32232,
    "replicationWallTimeNsPerByte": 4117,
    "replicationCpuTimeNsPerByte": 30739,
    "totalProvingCpuTimeMs": 0,
    "totalProvingWallTimeMs": 0,
    "vanillaProvingCpuTimeUs": 378,
    "vanillaProvingWallTimeUs": 377,
    "vanillaVerificationWallTimeUs": 98435,
    "vanillaVerificationCpuTimeUs": 98393,
    "verifyingWallTimeAvg": 97,
    "verifyingCpuTimeAvg": 97
  }
}
```

To include information about RAM utilization during Stacked benchmarking, run
`benchy` via its wrapper script:

```
$ ./scripts/benchy.sh stacked --size=1024 | jq '.'
{
  "inputs": {
    "dataSize": 1048576,
    "m": 5,
    "expansionDegree": 8,
    "slothIter": 0,
    "partitions": 1,
    "hasher": "pedersen",
    "samples": 5,
    "layers": 10
  },
  "outputs": {
    "avgGrothVerifyingCpuTimeMs": null,
    "avgGrothVerifyingWallTimeMs": null,
    "circuitNumConstraints": null,
    "circuitNumInputs": null,
    "extractingCpuTimeMs": null,
    "extractingWallTimeMs": null,
    "replicationWallTimeMs": 4318,
    "replicationCpuTimeMs": 32232,
    "replicationWallTimeNsPerByte": 4117,
    "replicationCpuTimeNsPerByte": 30739,
    "totalProvingCpuTimeMs": 0,
    "totalProvingWallTimeMs": 0,
    "vanillaProvingCpuTimeUs": 378,
    "vanillaProvingWallTimeUs": 377,
    "vanillaVerificationWallTimeUs": 98435,
    "vanillaVerificationCpuTimeUs": 98393,
    "verifyingWallTimeAvg": 97,
    "verifyingCpuTimeAvg": 97,
    "maxResidentSetSizeKb": 45644
  }
}
```

To run benchy on a remote server, provide SSH connection information to the
benchy-remote.sh script:

```shell
10:13 $ ./fil-proofs-tooling/scripts/benchy-remote.sh master foo@16.16.16.16 stacked --size=1 | jq '.'
{
  "inputs": {
    // ...
  },
  "outputs": {
    // ...
  }
}
```

Run benchy in "prodbench" mode with custom input and detailed metrics.

```shell
> echo '{
    "drg_parents": 6,
    "expander_parents": 8,
    "graph_parents": 8,
    "porep_challenges": 50,
    "porep_partitions": 10,
    "post_challenged_nodes": 1,
    "post_challenges": 20,
    "sector_size_bytes": 1024,
    "stacked_layers": 4,
    "window_size_bytes": 512,
    "wrapper_parents_all": 8
}' > config.json
> cat config.json|RUST_LOG=info ./target/release/benchy prodbench|jq '.'
…
{
  "git": {
    "hash": "d751257b4f7339f6ec3de7b3fda1b1b8979ccf21",
    "date": "2019-12-18T21:08:21Z"
  },
  "system": {
    "system": "Linux",
    "release": "5.2.0-3-amd64",
    "version": "#1 SMP Debian 5.2.17-1 (2019-09-26)",
    "architecture": "x86_64",
    "processor": "Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz",
    "processor-base-frequency-hz": 2000,
    "processor-max-frequency-hz": 4000,
    "processor-features": "FeatureInfo { eax: 526058, ebx: 101713920, edx_ecx: SSE3 | PCLMULQDQ | DTES64 | MONITOR | DSCPL | VMX | EIST | TM2 | SSSE3 | FMA | CMPXCHG16B | PDCM | PCID | SSE41 | SSE42 | X2APIC | MOVBE | POPCNT | TSC_DEADLINE | AESNI | XSAVE | OSXSAVE | AVX | F16C | RDRAND | FPU | VME | DE | PSE | TSC | MSR | PAE | MCE | CX8 | APIC | SEP | MTRR | PGE | MCA | CMOV | PAT | PSE36 | CLFSH | DS | ACPI | MMX | FXSR | SSE | SSE2 | SS | HTT | TM | PBE | 0x4800 }",
    "processor-cores-logical": 8,
    "processor-cores-physical": 4,
    "memory-total-bytes": 32932844000
  },
  "benchmarks": {
    "inputs": {
      "window_size_bytes": 512,
      "sector_size_bytes": 1024,
      "drg_parents": 6,
      "expander_parents": 8,
      "porep_challenges": 50,
      "porep_partitions": 10,
      "post_challenges": 20,
      "post_challenged_nodes": 1,
      "stacked_layers": 4,
      "wrapper_parents_all": 8
    },
    "outputs": {
      "comm_d_cpu_time_ms": 0,
      "comm_d_wall_time_ms": 0,
      "encode_window_time_all_cpu_time_ms": 11,
      "encode_window_time_all_wall_time_ms": 4,
      "encoding_cpu_time_ms": 23,
      "encoding_wall_time_ms": 18,
      "epost_cpu_time_ms": 1,
      "epost_wall_time_ms": 1,
      "generate_tree_c_cpu_time_ms": 12,
      "generate_tree_c_wall_time_ms": 6,
      "porep_commit_time_cpu_time_ms": 83,
      "porep_commit_time_wall_time_ms": 27,
      "porep_proof_gen_cpu_time_ms": 6501654,
      "porep_proof_gen_wall_time_ms": 972945,
      "post_finalize_ticket_cpu_time_ms": 0,
      "post_finalize_ticket_time_ms": 0,
      "epost_inclusions_cpu_time_ms": 1,
      "epost_inclusions_wall_time_ms": 0,
      "post_partial_ticket_hash_cpu_time_ms": 1,
      "post_partial_ticket_hash_time_ms": 1,
      "post_proof_gen_cpu_time_ms": 61069,
      "post_proof_gen_wall_time_ms": 9702,
      "post_read_challenged_range_cpu_time_ms": 0,
      "post_read_challenged_range_time_ms": 0,
      "post_verify_cpu_time_ms": 37,
      "post_verify_wall_time_ms": 31,
      "tree_r_last_cpu_time_ms": 14,
      "tree_r_last_wall_time_ms": 6,
      "window_comm_leaves_time_cpu_time_ms": 20,
      "window_comm_leaves_time_wall_time_ms": 3,
      "porep_constraints": 67841707,
      "post_constraints": 335127,
      "kdf_constraints": 212428
    }
  }
}
```

## `micro`

All arguments passed to `micro` will be passed to `cargo bench --all <your arguments> -- --verbose --color never`.
Except for the following

### Example

```sh
> cargo run --bin micro -- --bench blake2s hash-blake2s
```

'''
'''--- fil-proofs-tooling/release.toml ---
disable-push = true
disable-publish = true
disable-tag = true
no-dev-version = true

'''
'''--- fil-proofs-tooling/scripts/aggregate-benchmarks.sh ---
#!/usr/bin/env bash

set -e

stacked_path=$1
micro_path=$2
hash_constraints_path=$3
election_post_path=$4

jq --sort-keys -s '{ benchmarks: { "stacked-benchmarks": { outputs: { "max-resident-set-size-kb": .[0] } } } } * .[1]' \
  <(jq '.["max-resident-set-size-kb"]' $stacked_path) \
  <(jq -s '.[0] * { benchmarks: { "hash-constraints": .[1], "stacked-benchmarks": .[2], "micro-benchmarks": .[3], "election-post-benchmarks": .[4] } }' \
    <(jq 'del (.benchmarks)' $micro_path) \
    <(jq '.benchmarks' $hash_constraints_path) \
    <(jq '.benchmarks' $stacked_path) \
    <(jq '.benchmarks' $micro_path) \
    <(jq '.benchmarks' $election_post_path))

'''
'''--- fil-proofs-tooling/scripts/benchy.sh ---
#!/usr/bin/env bash

which jq >/dev/null || { printf '%s\n' "error: jq" >&2; exit 1; }

BENCHY_STDOUT=$(mktemp)
GTIME_STDERR=$(mktemp)
JQ_STDERR=$(mktemp)

GTIME_BIN="env time"
GTIME_ARG="-f '{ \"max-resident-set-size-kb\": %M }' cargo run --quiet --bin benchy --release -- ${@}"

if [[ $(env time --version 2>&1) != *"GNU"* ]]; then
    if [[ $(/usr/bin/time --version 2>&1) != *"GNU"* ]]; then
        if [[ $(env gtime --version 2>&1) != *"GNU"* ]]; then
            printf '%s\n' "error: GNU time not installed" >&2
            exit 1
        else
            GTIME_BIN="gtime"
        fi
    else
        GTIME_BIN="/usr/bin/time"
    fi
fi

CMD="${GTIME_BIN} ${GTIME_ARG}"

eval "RUST_BACKTRACE=1 RUSTFLAGS=\"-Awarnings -C target-cpu=native\" ${CMD}" > $BENCHY_STDOUT 2> $GTIME_STDERR

GTIME_EXIT_CODE=$?

jq -s '.[0] * .[1]' $BENCHY_STDOUT $GTIME_STDERR 2> $JQ_STDERR

JQ_EXIT_CODE=$?

if [[ ! $GTIME_EXIT_CODE -eq 0 || ! $JQ_EXIT_CODE -eq 0 ]]; then
    >&2 echo "*********************************************"
    >&2 echo "* benchy failed - dumping debug information *"
    >&2 echo "*********************************************"
    >&2 echo ""
    >&2 echo "<COMMAND>"
    >&2 echo "${CMD}"
    >&2 echo "</COMMAND>"
    >&2 echo ""
    >&2 echo "<GTIME_STDERR>"
    >&2 echo "$(cat $GTIME_STDERR)"
    >&2 echo "</GTIME_STDERR>"
    >&2 echo ""
    >&2 echo "<BENCHY_STDOUT>"
    >&2 echo "$(cat $BENCHY_STDOUT)"
    >&2 echo "</BENCHY_STDOUT>"
    >&2 echo ""
    >&2 echo "<JQ_STDERR>"
    >&2 echo "$(cat $JQ_STDERR)"
    >&2 echo "</JQ_STDERR>"
    exit 1
fi

'''
'''--- fil-proofs-tooling/scripts/micro.sh ---
#!/usr/bin/env bash

MICRO_SDERR=$(mktemp)
MICRO_SDOUT=$(mktemp)
JQ_STDERR=$(mktemp)

CMD="cargo run --bin micro --release ${@}"

eval "RUST_BACKTRACE=1 RUSTFLAGS=\"-Awarnings -C target-cpu=native\" ${CMD}" 1> $MICRO_SDOUT 2> $MICRO_SDERR

MICRO_EXIT_CODE=$?

cat $MICRO_SDOUT | jq '.' 2> $JQ_STDERR

JQ_EXIT_CODE=$?

if [[ ! $MICRO_EXIT_CODE -eq 0 || ! $JQ_EXIT_CODE -eq 0 ]]; then
    >&2 echo "********************************************"
    >&2 echo "* micro failed - dumping debug information *"
    >&2 echo "********************************************"
    >&2 echo ""
    >&2 echo "<COMMAND>"
    >&2 echo "${CMD}"
    >&2 echo "</COMMAND>"
    >&2 echo ""
    >&2 echo "<MICRO_SDERR>"
    >&2 echo "$(cat $MICRO_SDERR)"
    >&2 echo "</MICRO_SDERR>"
    >&2 echo ""
    >&2 echo "<MICRO_SDOUT>"
    >&2 echo "$(cat $MICRO_SDOUT)"
    >&2 echo "</MICRO_SDOUT>"
    >&2 echo ""
    >&2 echo "<JQ_STDERR>"
    >&2 echo "$(cat $JQ_STDERR)"
    >&2 echo "</JQ_STDERR>"
    exit 1
fi

'''
'''--- fil-proofs-tooling/scripts/retry.sh ---
#!/usr/bin/env bash

# Inspired by https://gist.github.com/reacocard/28611bfaa2395072119464521d48729a

set -o errexit
set -o nounset
set -o pipefail

# Retry a command on a particular exit code, up to a max number of attempts,
# with exponential backoff.
# Invocation:
#   err_retry exit_code attempts sleep_multiplier <command>
# exit_code: The exit code to retry on.
# attempts: The number of attempts to make.
# sleep_millis: Multiplier for sleep between attempts. Examples:
#     If multiplier is 1000, sleep intervals are 1, 4, 9, 16, etc. seconds.
#     If multiplier is 5000, sleep intervals are 5, 20, 45, 80, 125, etc. seconds.

exit_code=$1
attempts=$2
sleep_millis=$3
shift 3

for attempt in `seq 1 $attempts`; do
    # This weird construction lets us capture return codes under -o errexit
    "$@" && rc=$? || rc=$?

    if [[ ! $rc -eq $exit_code ]]; then
        exit $rc
    fi

    if [[ $attempt -eq $attempts ]]; then
        exit $rc
    fi

    sleep_ms="$(($attempt * $attempt * $sleep_millis))"

    sleep_seconds=$(echo "scale=2; ${sleep_ms}/1000" | bc)

    (>&2 echo "sleeping ${sleep_seconds}s and then retrying ($((attempt + 1))/${attempts})")

    sleep "${sleep_seconds}"
done

'''
'''--- fil-proofs-tooling/scripts/run-remote.sh ---
#!/usr/bin/env bash

CMDS=$(cat <<EOF

set -e

# Creates a temporary directory in which we build rust-fil-proofs and capture
# performance metrics. The name of the directory (today's UTC seconds plus 24
# hours) serves as a cleanup mechanism; before metrics are captured, any expired
# directories are removed.

_one_day_from_now=\$((\$(date +%s) + 86400))
_metrics_dir=/tmp/metrics/\$_one_day_from_now

# Find and prune any stale metrics directories.
find /tmp/metrics/ -maxdepth 1 -mindepth 1 -type d -printf "%f\n" \
    | xargs -I {} bash -c 'if (({} < \$(date +%s))) ; then rm -rf /tmp/metrics/{} ; fi' 2> /dev/null

git clone -b $1 --single-branch https://github.com/filecoin-project/rust-fil-proofs.git \$_metrics_dir || true

cd \$_metrics_dir

./fil-proofs-tooling/scripts/retry.sh 42 10 60000 \
    ./fil-proofs-tooling/scripts/with-lock.sh 42 /tmp/metrics.lock \
    ./fil-proofs-tooling/scripts/with-dots.sh \
    ${@:3}
EOF
)

ssh -q $2 "$CMDS"

'''
'''--- fil-proofs-tooling/scripts/with-dots.sh ---
#!/usr/bin/env bash

trap cleanup EXIT

cleanup() {
  kill $DOT_PID
}

(
  sleep 1
  while true; do
    (printf "." >&2)
    sleep 1
  done
) &
DOT_PID=$!

$@

'''
'''--- fil-proofs-tooling/scripts/with-lock.sh ---
#!/usr/bin/env bash

# Inspired by http://mywiki.wooledge.org/BashFAQ/045

failure_code=$1
lockdir=$2
shift 2

# Check to make sure that the process which owns the lock, if one exists, is
# still alive. If the process is not alive, release the lock.
for lockdir_pid in $(find "$lockdir" -type f -exec basename {} \; 2> /dev/null)
do
    if ! ps -p "${lockdir_pid}" > /dev/null
    then
        (>&2 echo "cleaning up leaked lock (pid=${lockdir_pid}, path=${lockdir})")
        rm -rf "${lockdir}"
    fi
done

if mkdir "$lockdir" > /dev/null 2>&1
then
    (>&2 echo "successfully acquired lock (pid=$$, path=${lockdir})")

    # Create a file to track the process id that acquired the lock. This
    # is used to prevent leaks if the lock isn't relinquished correctly.
    touch "$lockdir/$$"

    # Unlock (by removing dir and pid file) when the script finishes.
    trap '(>&2 echo "relinquishing lock (${lockdir})"); rm -rf "$lockdir"' EXIT

    # Execute command
    "$@"
else
    (>&2 echo "failed to acquire lock (path=${lockdir})")
    exit "$failure_code"
fi

'''
'''--- fil-proofs-tooling/src/bin/benchy/hash_fns.rs ---
use bellperson::gadgets::boolean::Boolean;
use bellperson::ConstraintSystem;
use fil_proofs_tooling::metadata::Metadata;
use paired::bls12_381::Bls12;
use rand::RngCore;
use serde::Serialize;
use storage_proofs::crypto;
use storage_proofs::gadgets::pedersen::{pedersen_compression_num, pedersen_md_no_padding};
use storage_proofs::gadgets::TestConstraintSystem;
use storage_proofs::util::{bits_to_bytes, bytes_into_boolean_vec, bytes_into_boolean_vec_be};

fn blake2s_count(bytes: usize) -> anyhow::Result<Report> {
    let rng = &mut rand::thread_rng();

    let mut cs = TestConstraintSystem::<Bls12>::new();
    let mut data = vec![0u8; bytes];
    rng.fill_bytes(&mut data);

    let data_bits: Vec<Boolean> = {
        let mut cs = cs.namespace(|| "data");
        bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), data.len()).unwrap()
    };

    let personalization = vec![0u8; 8];
    let out: Vec<bool> =
        bellperson::gadgets::blake2s::blake2s(&mut cs, &data_bits, &personalization)?
            .into_iter()
            .map(|b| b.get_value().unwrap())
            .collect();

    assert!(cs.is_satisfied(), "constraints not satisfied");

    let expected = blake2s_simd::blake2s(&data);
    assert_eq!(
        expected.as_ref(),
        &bits_to_bytes(&out[..])[..],
        "circuit and non circuit do not match"
    );

    Ok(Report {
        hash_fn: "blake2s".into(),
        bytes,
        constraints: cs.num_constraints(),
    })
}

fn sha256_count(bytes: usize) -> anyhow::Result<Report> {
    let mut rng = rand::thread_rng();

    let mut cs = TestConstraintSystem::<Bls12>::new();
    let mut data = vec![0u8; bytes];
    rng.fill_bytes(&mut data);

    let data_bits: Vec<Boolean> = {
        let mut cs = cs.namespace(|| "data");
        bytes_into_boolean_vec_be(&mut cs, Some(data.as_slice()), data.len()).unwrap()
    };

    let _out: Vec<bool> = bellperson::gadgets::sha256::sha256(&mut cs, &data_bits)?
        .into_iter()
        .map(|b| b.get_value().unwrap())
        .collect();

    assert!(cs.is_satisfied(), "constraints not satisfied");

    Ok(Report {
        hash_fn: "sha256".into(),
        bytes,
        constraints: cs.num_constraints(),
    })
}

fn pedersen_count(bytes: usize) -> anyhow::Result<Report> {
    let mut rng = rand::thread_rng();

    let mut cs = TestConstraintSystem::<Bls12>::new();
    let mut data = vec![0u8; bytes];
    rng.fill_bytes(&mut data);

    let data_bits: Vec<Boolean> = {
        let mut cs = cs.namespace(|| "data");
        bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), data.len()).unwrap()
    };

    if bytes < 128 {
        let out = pedersen_compression_num(&mut cs, &data_bits)?;
        assert!(cs.is_satisfied(), "constraints not satisfied");

        let expected = crypto::pedersen::pedersen(data.as_slice());
        assert_eq!(
            expected,
            out.get_value().unwrap(),
            "circuit and non circuit do not match"
        );
    } else {
        let out = pedersen_md_no_padding(cs.namespace(|| "pedersen"), &data_bits)
            .expect("pedersen hashing failed");
        assert!(cs.is_satisfied(), "constraints not satisfied");
        let expected = crypto::pedersen::pedersen_md_no_padding(data.as_slice());
        assert_eq!(
            expected,
            out.get_value().unwrap(),
            "circuit and non circuit do not match"
        );
    }

    Ok(Report {
        hash_fn: "pedersen".into(),
        bytes,
        constraints: cs.num_constraints(),
    })
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Report {
    hash_fn: String,
    constraints: usize,
    bytes: usize,
}

pub fn run() -> anyhow::Result<()> {
    let reports = vec![
        blake2s_count(32)?,
        blake2s_count(64)?,
        blake2s_count(128)?,
        blake2s_count(256)?,
        pedersen_count(32)?,
        pedersen_count(64)?,
        pedersen_count(128)?,
        pedersen_count(256)?,
        sha256_count(32)?,
        sha256_count(64)?,
        sha256_count(128)?,
        sha256_count(256)?,
    ];

    // print reports
    let wrapped = Metadata::wrap(reports)?;
    serde_json::to_writer(std::io::stdout(), &wrapped)?;

    Ok(())
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/main.rs ---
use std::io::{stdin, stdout};

use anyhow::Result;
use clap::{value_t, App, Arg, SubCommand};

use crate::prodbench::ProdbenchInputs;

mod hash_fns;
mod merkleproofs;
mod prodbench;
mod stacked;
mod window_post;
mod winning_post;

fn main() -> Result<()> {
    fil_logger::init();

    let stacked_cmd = SubCommand::with_name("stacked")
                .about("Run stacked sealing")
                .arg(
                    Arg::with_name("size")
                        .required(true)
                        .long("size")
                        .help("The data size in KB")
                        .takes_value(true),
                )
                .arg(
                    Arg::with_name("challenges")
                        .long("challenges")
                        .help("How many challenges to execute")
                        .default_value("1")
                        .takes_value(true),
                )

                .arg(
                    Arg::with_name("hasher")
                        .long("hasher")
                        .help("Which hasher should be used. Available: \"pedersen\", \"sha256\", \"blake2s\" (default \"pedersen\")")
                        .default_value("pedersen")
                        .takes_value(true),
                )
                .arg(
                    Arg::with_name("layers")
                        .long("layers")
                        .help("How many layers to use")
                        .default_value("11")
                        .takes_value(true),
                )
                .arg(
                    Arg::with_name("no-tmp")
                        .long("no-tmp")
                        .help("Don't use a temp file for random data (write to current directory instead).")
                )
                .arg(
                    Arg::with_name("dump")
                        .long("dump")
                        .help("Dump vanilla proofs to current directory.")
                )
                .arg(
                    Arg::with_name("partitions")
                        .long("partitions")
                        .help("How many circuit partitions to use")
                        .default_value("1")
                        .takes_value(true),
                )
                .arg(
                    Arg::with_name("groth")
                        .long("groth")
                        .help("Generate and verify a groth circuit proof.")
                )
                .arg(
                    Arg::with_name("bench")
                        .long("bench")
                        .help("Synthesize and report inputs/constraints for a circuit.")
                )
                .arg(
                    Arg::with_name("no-bench")
                        .long("no-bench")
                        .help("Don't synthesize and report inputs/constraints for a circuit.")
                )
                .arg(
                    Arg::with_name("bench-only")
                        .long("bench-only")
                        .help("Don't replicate or perform Groth proving.")
                        .conflicts_with_all(&["no-bench", "groth", "extract"])
                )
                .arg(
                    Arg::with_name("circuit")
                        .long("circuit")
                        .help("Print the constraint system.")
                )
                .arg(
                    Arg::with_name("extract")
                        .long("extract")
                        .help("Extract data after proving and verifying.")
                );

    let window_post_cmd = SubCommand::with_name("window-post")
        .about("Benchmark Window PoST")
        .arg(
            Arg::with_name("size")
                .long("size")
                .required(true)
                .help("The data size in KiB")
                .takes_value(true),
        );

    let winning_post_cmd = SubCommand::with_name("winning-post")
        .about("Benchmark Winning PoST")
        .arg(
            Arg::with_name("size")
                .long("size")
                .required(true)
                .help("The data size in KiB")
                .takes_value(true),
        );

    let hash_cmd = SubCommand::with_name("hash-constraints")
        .about("Benchmark hash function inside of a circuit");

    let prodbench_cmd = SubCommand::with_name("prodbench")
        .about("Benchmark prodbench")
        .arg(
            Arg::with_name("config")
                .long("config")
                .takes_value(true)
                .required(false)
                .help("path to config.json"),
        )
        .arg(
            Arg::with_name("skip-seal-proof")
                .long("skip-seal-proof")
                .takes_value(false)
                .help("skip generation (and verification) of seal proof"),
        )
        .arg(
            Arg::with_name("skip-post-proof")
                .long("skip-post-proof")
                .takes_value(false)
                .help("skip generation (and verification) of PoSt proof"),
        )
        .arg(
            Arg::with_name("only-replicate")
                .long("only-replicate")
                .takes_value(false)
                .help("only run replication"),
        )
        .arg(
            Arg::with_name("only-add-piece")
                .long("only-add-piece")
                .takes_value(false)
                .help("only run piece addition"),
        );

    let merkleproof_cmd = SubCommand::with_name("merkleproofs")
        .about("Benchmark merkle proof generation")
        .arg(
            Arg::with_name("size")
                .long("size")
                .required(true)
                .help("The size of the data underlying the tree KiB")
                .takes_value(true),
        )
        .arg(
            Arg::with_name("proofs")
                .long("proofs")
                .default_value("0")
                .required(false)
                .help("How many proofs to generate (default is all)")
                .takes_value(true),
        )
        .arg(
            Arg::with_name("validate")
                .long("validate")
                .required(false)
                .default_value("false")
                .help("Validate proofs if specified")
                .takes_value(false),
        );

    let matches = App::new("benchy")
        .version("0.1")
        .subcommand(stacked_cmd)
        .subcommand(window_post_cmd)
        .subcommand(winning_post_cmd)
        .subcommand(hash_cmd)
        .subcommand(prodbench_cmd)
        .subcommand(merkleproof_cmd)
        .get_matches();

    match matches.subcommand() {
        ("stacked", Some(m)) => {
            let layers = value_t!(m, "layers", usize)?;

            stacked::run(stacked::RunOpts {
                bench: m.is_present("bench"),
                bench_only: m.is_present("bench-only"),
                challenges: value_t!(m, "challenges", usize)?,
                circuit: m.is_present("circuit"),
                dump: m.is_present("dump"),
                extract: m.is_present("extract"),
                groth: m.is_present("groth"),
                hasher: value_t!(m, "hasher", String)?,
                layers,
                no_bench: m.is_present("no-bench"),
                no_tmp: m.is_present("no-tmp"),
                partitions: value_t!(m, "partitions", usize)?,
                size: value_t!(m, "size", usize)?,
            })?;
        }
        ("window-post", Some(m)) => {
            let sector_size_kibs = value_t!(m, "size", usize)
                .expect("could not convert `size` CLI argument to `usize`");
            let sector_size = sector_size_kibs * 1024;
            window_post::run(sector_size)?;
        }
        ("winning-post", Some(m)) => {
            let sector_size_kibs = value_t!(m, "size", usize)
                .expect("could not convert `size` CLI argument to `usize`");
            let sector_size = sector_size_kibs * 1024;
            winning_post::run(sector_size)?;
        }
        ("hash-constraints", Some(_m)) => {
            hash_fns::run()?;
        }
        ("merkleproofs", Some(m)) => {
            let size_kibs = value_t!(m, "size", usize)?;
            let size = size_kibs * 1024;

            let proofs = value_t!(m, "proofs", usize)?;
            merkleproofs::run(size, proofs, m.is_present("validate"))?;
        }
        ("prodbench", Some(m)) => {
            let inputs: ProdbenchInputs = if m.is_present("config") {
                let file = value_t!(m, "config", String).unwrap();
                serde_json::from_reader(
                    std::fs::File::open(&file)
                        .unwrap_or_else(|_| panic!("invalid file {:?}", file)),
                )
            } else {
                serde_json::from_reader(stdin())
            }
            .expect("failed to deserialize stdin to ProdbenchInputs");

            let outputs = prodbench::run(
                inputs,
                m.is_present("skip-seal-proof"),
                m.is_present("skip-post-proof"),
                m.is_present("only-replicate"),
                m.is_present("only-add-piece"),
            );

            serde_json::to_writer(stdout(), &outputs)
                .expect("failed to write ProdbenchOutput to stdout")
        }
        _ => panic!("carnation"),
    }

    Ok(())
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/merkleproofs.rs ---
use anyhow::Result;
use log::info;
use merkletree::merkle::{is_merkle_tree_size_valid, FromIndexedParallelIterator, MerkleTree};
use merkletree::store::DiskStore;
use rand::{thread_rng, Rng};
use rayon::prelude::*;
use storage_proofs::hasher::{Domain, Hasher, PoseidonHasher};
use storage_proofs::util::NODE_SIZE;
use typenum::{Unsigned, U0, U1, U2, U8};

#[allow(clippy::type_complexity)]
fn generate_tree<R: Rng, BaseTreeArity: Unsigned>(
    rng: &mut R,
    size: usize,
) -> Result<
    MerkleTree<
        <PoseidonHasher as Hasher>::Domain,
        <PoseidonHasher as Hasher>::Function,
        DiskStore<<PoseidonHasher as Hasher>::Domain>,
        BaseTreeArity,
    >,
> {
    let el = <PoseidonHasher as Hasher>::Domain::random(rng);
    info!("--- create tree {} KiB", (size * NODE_SIZE) / 1024);
    MerkleTree::from_par_iter((0..size).into_par_iter().map(|_| el))
}

#[allow(clippy::type_complexity)]
fn generate_sub_tree<R: Rng, BaseTreeArity: Unsigned, SubTreeArity: Unsigned>(
    rng: &mut R,
    size: usize,
) -> Result<
    MerkleTree<
        <PoseidonHasher as Hasher>::Domain,
        <PoseidonHasher as Hasher>::Function,
        DiskStore<<PoseidonHasher as Hasher>::Domain>,
        BaseTreeArity,
        SubTreeArity,
    >,
> {
    let base_tree_count = BaseTreeArity::to_usize();
    let mut trees = Vec::with_capacity(base_tree_count);
    info!("-- create sub-tree {} KiB", (size * NODE_SIZE) / 1024);
    for _ in 0..base_tree_count {
        trees.push(generate_tree::<R, BaseTreeArity>(
            rng,
            size / base_tree_count,
        )?);
    }

    MerkleTree::from_trees(trees)
}

#[allow(clippy::type_complexity)]
fn generate_proofs<
    R: Rng,
    BaseTreeArity: Unsigned,
    SubTreeArity: Unsigned,
    TopTreeArity: Unsigned,
>(
    rng: &mut R,
    tree: MerkleTree<
        <PoseidonHasher as Hasher>::Domain,
        <PoseidonHasher as Hasher>::Function,
        DiskStore<<PoseidonHasher as Hasher>::Domain>,
        BaseTreeArity,
        SubTreeArity,
        TopTreeArity,
    >,
    nodes: usize,
    proofs_count: usize,
    validate: bool,
) -> Result<()> {
    info!("creating {} inclusion proofs", proofs_count);

    for _ in 0..proofs_count {
        let challenge = rng.gen_range(0, nodes);
        let proof = tree.gen_proof(challenge).expect("failed to generate proof");
        if validate {
            assert!(proof
                .validate::<<PoseidonHasher as Hasher>::Function>()
                .expect("failed to validate"));
        }
    }

    Ok(())
}

fn run_tree_bench<R: Rng, BaseTreeArity: Unsigned, SubTreeArity: Unsigned>(
    rng: &mut R,
    nodes: usize,
    proofs_count: usize,
    validate: bool,
) -> Result<()> {
    let arity = BaseTreeArity::to_usize();
    let tree_count = SubTreeArity::to_usize();

    info!(
        "is_merkle_tree_size_valid({}, {})? {}",
        nodes,
        arity,
        is_merkle_tree_size_valid(nodes / tree_count, arity)
    );
    assert!(is_merkle_tree_size_valid(nodes / tree_count, arity));

    let mut trees = Vec::with_capacity(tree_count);
    for _ in 0..tree_count {
        trees.push(generate_tree::<R, BaseTreeArity>(rng, nodes / tree_count)?);
    }

    let tree: MerkleTree<
        <PoseidonHasher as Hasher>::Domain,
        <PoseidonHasher as Hasher>::Function,
        DiskStore<<PoseidonHasher as Hasher>::Domain>,
        BaseTreeArity,
        SubTreeArity,
    > = MerkleTree::from_trees(trees)?;

    generate_proofs::<R, BaseTreeArity, SubTreeArity, U0>(rng, tree, nodes, proofs_count, validate)
}

fn run_top_tree_bench<
    R: Rng,
    BaseTreeArity: Unsigned,
    SubTreeArity: Unsigned,
    TopTreeArity: Unsigned,
>(
    rng: &mut R,
    nodes: usize,
    proofs_count: usize,
    validate: bool,
) -> Result<()> {
    let base_tree_count = BaseTreeArity::to_usize();
    let sub_tree_count = SubTreeArity::to_usize();
    let top_tree_count = TopTreeArity::to_usize();

    info!(
        "base layer check: is_merkle_tree_size_valid({}, {})? {}",
        nodes / top_tree_count / sub_tree_count / base_tree_count,
        base_tree_count,
        is_merkle_tree_size_valid(
            nodes / top_tree_count / sub_tree_count / base_tree_count,
            base_tree_count
        )
    );
    assert!(is_merkle_tree_size_valid(
        nodes / top_tree_count / sub_tree_count / base_tree_count,
        base_tree_count
    ));

    info!(
        "sub-tree layer check: is_merkle_tree_size_valid({}, {})? {}",
        nodes / top_tree_count / sub_tree_count,
        sub_tree_count,
        is_merkle_tree_size_valid(nodes / top_tree_count / sub_tree_count, sub_tree_count)
    );
    assert!(is_merkle_tree_size_valid(
        nodes / top_tree_count / sub_tree_count,
        sub_tree_count
    ));

    info!(
        "top-tree layer check: is_merkle_tree_size_valid({}, {})? {}",
        nodes / top_tree_count,
        top_tree_count,
        is_merkle_tree_size_valid(nodes / top_tree_count, top_tree_count)
    );
    assert!(is_merkle_tree_size_valid(
        nodes / top_tree_count,
        sub_tree_count
    ));

    let mut sub_trees = Vec::with_capacity(sub_tree_count);
    for i in 0..top_tree_count {
        info!(
            "- create top-tree layer {}/{} -- {} KiB",
            i + 1,
            top_tree_count,
            (nodes * NODE_SIZE) / top_tree_count / 1024
        );
        sub_trees.push(generate_sub_tree::<R, BaseTreeArity, SubTreeArity>(
            rng,
            nodes / top_tree_count,
        )?);
    }

    let tree = MerkleTree::from_sub_trees(sub_trees)?;

    generate_proofs::<R, BaseTreeArity, SubTreeArity, TopTreeArity>(
        rng,
        tree,
        nodes,
        proofs_count,
        validate,
    )
}

pub fn run(size: usize, proofs_count: usize, validate: bool) -> Result<()> {
    // These sizes are supported without requiring compound merkle trees.
    // Valid --size args are: 2, 8192, 524288, 33554432
    pub const SECTOR_SIZE_2_KIB: u64 = 2_048;
    pub const SECTOR_SIZE_8_MIB: u64 = 1 << 23;
    pub const SECTOR_SIZE_512_MIB: u64 = 1 << 29;
    pub const SECTOR_SIZE_32_GIB: u64 = 1 << 35;

    // These sizes require compound merkle trees.
    // Valid --size args are: 4, 16384, 1048576, 67108864
    pub const SECTOR_SIZE_4_KIB: u64 = 2 * SECTOR_SIZE_2_KIB;
    pub const SECTOR_SIZE_16_MIB: u64 = 2 * SECTOR_SIZE_8_MIB;
    pub const SECTOR_SIZE_1_GIB: u64 = 2 * SECTOR_SIZE_512_MIB;
    pub const SECTOR_SIZE_64_GIB: u64 = 2 * SECTOR_SIZE_32_GIB;

    let mut rng = thread_rng();

    let nodes = size / NODE_SIZE;
    info!("sector size of {} consists of {} nodes", size, nodes);

    match size as u64 {
        // 2 KIB sectors are composed of a single 2KIB tree of arity 8.
        SECTOR_SIZE_2_KIB => run_tree_bench::<_, U8, U1>(&mut rng, nodes, proofs_count, validate),
        // 4 KIB sectors are composed of 2 2KIB trees each of arity 8.
        SECTOR_SIZE_4_KIB => run_tree_bench::<_, U8, U2>(&mut rng, nodes, proofs_count, validate),
        // 8 MIB sectors are composed of a single 8MIB tree of arity 8.
        SECTOR_SIZE_8_MIB => run_tree_bench::<_, U8, U1>(&mut rng, nodes, proofs_count, validate),
        // 16 MIB sectors are composed of 2 8MIB trees each of arity 8.
        SECTOR_SIZE_16_MIB => run_tree_bench::<_, U8, U2>(&mut rng, nodes, proofs_count, validate),
        // 512 MIB sectors are composed of a single 512MIB tree of arity 8.
        SECTOR_SIZE_512_MIB => run_tree_bench::<_, U8, U1>(&mut rng, nodes, proofs_count, validate),
        // 1 GIB sectors are composed of 2 512MB trees each of arity 8.
        SECTOR_SIZE_1_GIB => run_tree_bench::<_, U8, U2>(&mut rng, nodes, proofs_count, validate),
        // 32 GIB sectors are composed of 8 4GIB trees each of arity 8.
        SECTOR_SIZE_32_GIB => run_tree_bench::<_, U8, U8>(&mut rng, nodes, proofs_count, validate),
        // 64 GIB sectors are composed of 2 32 GIB trees.
        SECTOR_SIZE_64_GIB => run_top_tree_bench::<_, U8, U8, U2>(&mut rng, nodes, proofs_count, validate),
        _ => panic!("Invalid sector size specified (valid values are: 2, 4, 8192, 16384, 524288, 1048576, 33554432, 67108864)")
    }
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/prodbench.rs ---
use bellperson::Circuit;
use fil_proofs_tooling::shared::{create_replicas, PROVER_ID, RANDOMNESS, TICKET_BYTES};
use fil_proofs_tooling::{measure, Metadata};
use filecoin_proofs::constants::{DefaultOctTree, POREP_PARTITIONS};
use filecoin_proofs::types::PaddedBytesAmount;
use filecoin_proofs::types::SectorSize;
use filecoin_proofs::types::*;
use filecoin_proofs::{
    clear_cache, constants::DefaultOctLCTree, seal_commit_phase1, seal_commit_phase2,
    validate_cache_for_commit, PoRepConfig,
};
use log::info;
use paired::bls12_381::Bls12;
use rand::SeedableRng;
use rand_xorshift::XorShiftRng;
use serde::{Deserialize, Serialize};
use storage_proofs::compound_proof::CompoundProof;
use storage_proofs::gadgets::BenchCS;
use storage_proofs::hasher::Sha256Hasher;
#[cfg(feature = "measurements")]
use storage_proofs::measurements::Operation;
#[cfg(feature = "measurements")]
use storage_proofs::measurements::OP_MEASUREMENTS;
use storage_proofs::parameter_cache::CacheableParameters;
use storage_proofs::proof::ProofScheme;

const SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

type ProdbenchTree = DefaultOctTree;

#[derive(Default, Debug, Serialize)]
pub struct ProdbenchReport {
    inputs: ProdbenchInputs,
    outputs: ProdbenchOutputs,
}

#[derive(Default, Debug, Deserialize, Serialize)]
pub struct ProdbenchInputs {
    /// The size of sector.
    sector_size: String,
    porep_challenges: u64,
    porep_partitions: u8,
    post_challenges: u64,
    post_challenged_nodes: u64,
    stacked_layers: u64,
    /// How many sectors should be created in parallel.
    num_sectors: u64,
}

impl ProdbenchInputs {
    pub fn sector_size_bytes(&self) -> u64 {
        bytefmt::parse(&self.sector_size).unwrap()
    }
}

#[derive(Default, Debug, Serialize)]
pub struct ProdbenchOutputs {
    comm_d_cpu_time_ms: u64,
    comm_d_wall_time_ms: u64,
    encode_window_time_all_cpu_time_ms: u64,
    encode_window_time_all_wall_time_ms: u64,
    encoding_cpu_time_ms: u64,
    encoding_wall_time_ms: u64,
    generate_tree_c_cpu_time_ms: u64,
    generate_tree_c_wall_time_ms: u64,
    porep_commit_time_cpu_time_ms: u64,
    porep_commit_time_wall_time_ms: u64,
    porep_proof_gen_cpu_time_ms: u64,
    porep_proof_gen_wall_time_ms: u64,
    post_finalize_ticket_cpu_time_ms: u64,
    post_finalize_ticket_time_ms: u64,
    post_partial_ticket_hash_cpu_time_ms: u64,
    post_partial_ticket_hash_time_ms: u64,
    post_proof_gen_cpu_time_ms: u64,
    post_proof_gen_wall_time_ms: u64,
    post_read_challenged_range_cpu_time_ms: u64,
    post_read_challenged_range_time_ms: u64,
    post_verify_cpu_time_ms: u64,
    post_verify_wall_time_ms: u64,
    tree_r_last_cpu_time_ms: u64,
    tree_r_last_wall_time_ms: u64,
    window_comm_leaves_time_cpu_time_ms: u64,
    window_comm_leaves_time_wall_time_ms: u64,
    add_piece_cpu_time_ms: u64,
    add_piece_wall_time_ms: u64,
    generate_piece_commitment_cpu_time_ms: u64,
    generate_piece_commitment_wall_time_ms: u64,
    #[serde(flatten)]
    circuits: CircuitOutputs,
}

#[cfg(not(feature = "measurements"))]
fn augment_with_op_measurements(mut _output: &mut ProdbenchOutputs) {}

#[cfg(feature = "measurements")]
fn augment_with_op_measurements(mut output: &mut ProdbenchOutputs) {
    // drop the tx side of the channel, causing the iterator to yield None
    // see also: https://doc.rust-lang.org/src/std/sync/mpsc/mod.rs.html#368
    OP_MEASUREMENTS
        .0
        .lock()
        .expect("failed to acquire mutex")
        .take();

    let measurements = OP_MEASUREMENTS
        .1
        .lock()
        .expect("failed to acquire lock on rx side of perf channel");

    for m in measurements.iter() {
        use Operation::*;
        let cpu_time = m.cpu_time.as_millis() as u64;
        let wall_time = m.wall_time.as_millis() as u64;

        match m.op {
            GenerateTreeC => {
                output.generate_tree_c_cpu_time_ms = cpu_time;
                output.generate_tree_c_wall_time_ms = wall_time;
            }
            GenerateTreeRLast => {
                output.tree_r_last_cpu_time_ms = cpu_time;
                output.tree_r_last_wall_time_ms = wall_time;
            }
            CommD => {
                output.comm_d_cpu_time_ms = cpu_time;
                output.comm_d_wall_time_ms = wall_time;
            }
            EncodeWindowTimeAll => {
                output.encode_window_time_all_cpu_time_ms = cpu_time;
                output.encode_window_time_all_wall_time_ms = wall_time;
            }
            WindowCommLeavesTime => {
                output.window_comm_leaves_time_cpu_time_ms = cpu_time;
                output.window_comm_leaves_time_wall_time_ms = wall_time;
            }
            PorepCommitTime => {
                output.porep_commit_time_cpu_time_ms = cpu_time;
                output.porep_commit_time_wall_time_ms = wall_time;
            }
            AddPiece => {
                output.add_piece_cpu_time_ms = cpu_time;
                output.add_piece_wall_time_ms = wall_time;
            }
            GeneratePieceCommitment => {
                output.generate_piece_commitment_cpu_time_ms = cpu_time;
                output.generate_piece_commitment_wall_time_ms = wall_time;
            }
            _ => {}
        }
    }
}

fn configure_global_config(inputs: &ProdbenchInputs) {
    filecoin_proofs::constants::LAYERS
        .write()
        .unwrap()
        .insert(inputs.sector_size_bytes(), inputs.stacked_layers as usize);
    filecoin_proofs::constants::POREP_PARTITIONS
        .write()
        .unwrap()
        .insert(inputs.sector_size_bytes(), inputs.porep_partitions);
    filecoin_proofs::constants::POREP_MINIMUM_CHALLENGES
        .write()
        .unwrap()
        .insert(inputs.sector_size_bytes(), inputs.porep_challenges);
}

pub fn run(
    inputs: ProdbenchInputs,
    skip_seal_proof: bool,
    skip_post_proof: bool,
    only_replicate: bool,
    only_add_piece: bool,
) -> Metadata<ProdbenchReport> {
    configure_global_config(&inputs);

    let mut outputs = ProdbenchOutputs::default();

    let sector_size = SectorSize(inputs.sector_size_bytes());

    assert!(inputs.num_sectors > 0, "Missing num_sectors");

    let (cfg, repls) = create_replicas::<DefaultOctLCTree>(
        sector_size,
        inputs.num_sectors as usize,
        only_add_piece,
    );

    if only_add_piece || only_replicate {
        augment_with_op_measurements(&mut outputs);
        return Metadata::wrap(ProdbenchReport { inputs, outputs })
            .expect("failed to retrieve metadata");
    }

    let (created, replica_measurement) = repls.unwrap();
    generate_params(&inputs);

    if !skip_seal_proof {
        for (value, (sector_id, replica_info)) in
            replica_measurement.return_value.iter().zip(created.iter())
        {
            let measured = measure(|| {
                validate_cache_for_commit::<_, _, DefaultOctLCTree>(
                    &replica_info.private_replica_info.cache_dir_path(),
                    &replica_info.private_replica_info.replica_path(),
                )?;

                let phase1_output = seal_commit_phase1::<_, DefaultOctLCTree>(
                    cfg,
                    &replica_info.private_replica_info.cache_dir_path(),
                    &replica_info.private_replica_info.replica_path(),
                    PROVER_ID,
                    *sector_id,
                    TICKET_BYTES,
                    RANDOMNESS,
                    value.clone(),
                    &replica_info.piece_info,
                )?;

                clear_cache::<DefaultOctLCTree>(
                    &replica_info.private_replica_info.cache_dir_path(),
                )?;

                seal_commit_phase2(cfg, phase1_output, PROVER_ID, *sector_id)
            })
            .expect("failed to prove sector");

            outputs.porep_proof_gen_cpu_time_ms += measured.cpu_time.as_millis() as u64;
            outputs.porep_proof_gen_wall_time_ms += measured.wall_time.as_millis() as u64;
        }
    }

    if !skip_post_proof {
        // TODO: add winning and window PoSt
    }

    // Clean-up persisted replica files.
    for (_, info) in &created {
        std::fs::remove_file(info.private_replica_info.replica_path())
            .expect("failed to remove sealed replica file");
    }

    augment_with_op_measurements(&mut outputs);
    outputs.circuits = run_measure_circuits(&inputs);

    Metadata::wrap(ProdbenchReport { inputs, outputs }).expect("failed to retrieve metadata")
}

#[derive(Default, Debug, Serialize)]
struct CircuitOutputs {
    // porep_snark_partition_constraints
    pub porep_constraints: usize,
    // replica_inclusion (constraints: single merkle path pedersen)
    // data_inclusion (constraints: sha merklepath)
    // window_inclusion (constraints: merkle inclusion path in comm_c)
    // ticket_constraints - (skip)
    // replica_inclusion (constraints: single merkle path pedersen)
    // column_leaf_hash_constraints - (64 byte * stacked layers) pedersen_md
    // kdf_constraints
    // merkle_tree_datahash_constraints - sha2 constraints 64
    // merkle_tree_hash_constraints - 64 byte pedersen
}

fn run_measure_circuits(i: &ProdbenchInputs) -> CircuitOutputs {
    let porep_constraints = measure_porep_circuit(i);

    CircuitOutputs { porep_constraints }
}

fn measure_porep_circuit(i: &ProdbenchInputs) -> usize {
    use storage_proofs::drgraph::new_seed;
    use storage_proofs::porep::stacked::{
        LayerChallenges, SetupParams, StackedCompound, StackedDrg,
    };

    let layers = i.stacked_layers as usize;
    let challenge_count = i.porep_challenges as usize;
    let drg_degree = filecoin_proofs::constants::DRG_DEGREE;
    let expansion_degree = filecoin_proofs::constants::EXP_DEGREE;
    let nodes = (i.sector_size_bytes() / 32) as usize;
    let layer_challenges = LayerChallenges::new(layers, challenge_count);

    let sp = SetupParams {
        nodes,
        degree: drg_degree,
        expansion_degree,
        seed: new_seed(),
        layer_challenges,
    };

    let pp = StackedDrg::<ProdbenchTree, Sha256Hasher>::setup(&sp).unwrap();

    let mut cs = BenchCS::<Bls12>::new();
    <StackedCompound<_, _> as CompoundProof<StackedDrg<ProdbenchTree, Sha256Hasher>, _>>::blank_circuit(
        &pp,
    )
    .synthesize(&mut cs)
    .unwrap();

    cs.num_constraints()
}

fn generate_params(i: &ProdbenchInputs) {
    let sector_size = SectorSize(i.sector_size_bytes());
    let partitions = PoRepProofPartitions(
        *POREP_PARTITIONS
            .read()
            .unwrap()
            .get(&i.sector_size_bytes())
            .expect("unknown sector size"),
    );
    info!(
        "generating params: porep: (size: {:?}, partitions: {:?})",
        &sector_size, &partitions
    );

    cache_porep_params(PoRepConfig {
        sector_size,
        partitions,
    });
}

fn cache_porep_params(porep_config: PoRepConfig) {
    use filecoin_proofs::parameters::public_params;
    use storage_proofs::porep::stacked::{StackedCompound, StackedDrg};

    let public_params = public_params(
        PaddedBytesAmount::from(porep_config),
        usize::from(PoRepProofPartitions::from(porep_config)),
    )
    .unwrap();

    {
        let circuit = <StackedCompound<ProdbenchTree, _> as CompoundProof<
            StackedDrg<ProdbenchTree, Sha256Hasher>,
            _,
        >>::blank_circuit(&public_params);
        StackedCompound::<ProdbenchTree, Sha256Hasher>::get_param_metadata(circuit, &public_params)
            .expect("cannot get param metadata");
    }
    {
        let circuit = <StackedCompound<ProdbenchTree, _> as CompoundProof<
            StackedDrg<ProdbenchTree, Sha256Hasher>,
            _,
        >>::blank_circuit(&public_params);
        StackedCompound::<ProdbenchTree, Sha256Hasher>::get_groth_params(
            Some(&mut XorShiftRng::from_seed(SEED)),
            circuit,
            &public_params,
        )
        .expect("failed to get groth params");
    }
    {
        let circuit = <StackedCompound<ProdbenchTree, _> as CompoundProof<
            StackedDrg<ProdbenchTree, Sha256Hasher>,
            _,
        >>::blank_circuit(&public_params);

        StackedCompound::<ProdbenchTree, Sha256Hasher>::get_verifying_key(
            Some(&mut XorShiftRng::from_seed(SEED)),
            circuit,
            &public_params,
        )
        .expect("failed to get verifying key");
    }
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/stacked.rs ---
use std::fs::OpenOptions;
use std::time::Duration;
use std::{io, u32};

use anyhow::bail;
use bellperson::Circuit;
use chrono::Utc;
use log::info;
use merkletree::store::StoreConfig;
use paired::bls12_381::Bls12;
use rand::Rng;
use serde::Serialize;

use fil_proofs_tooling::{measure, FuncMeasurement, Metadata};
use storage_proofs::cache_key::CacheKey;
use storage_proofs::compound_proof::{self, CompoundProof};
use storage_proofs::drgraph::*;
use storage_proofs::gadgets::BenchCS;
use storage_proofs::hasher::{Blake2sHasher, Domain, Hasher, PedersenHasher, Sha256Hasher};
use storage_proofs::merkle::{BinaryMerkleTree, MerkleTreeTrait};
use storage_proofs::porep::stacked::StackedCompound;
use storage_proofs::porep::stacked::{
    self, ChallengeRequirements, LayerChallenges, StackedDrg, TemporaryAuxCache, BINARY_ARITY,
    EXP_DEGREE,
};
use storage_proofs::porep::PoRep;
use storage_proofs::proof::ProofScheme;
use storage_proofs::test_helper::setup_replica;
use tempfile::TempDir;

fn dump_proof_bytes<Tree: MerkleTreeTrait>(
    all_partition_proofs: &[Vec<stacked::Proof<Tree, Sha256Hasher>>],
) -> anyhow::Result<()> {
    let file = OpenOptions::new()
        .write(true)
        .create(true)
        .open(format!("./proofs-{:?}", Utc::now()))
        .unwrap();

    serde_json::to_writer(file, all_partition_proofs)?;

    Ok(())
}

#[derive(Clone, Debug)]
struct Params {
    samples: usize,
    data_size: usize,
    partitions: usize,
    layer_challenges: LayerChallenges,
    circuit: bool,
    groth: bool,
    bench: bool,
    extract: bool,
    dump_proofs: bool,
    bench_only: bool,
    hasher: String,
}

impl From<Params> for Inputs {
    fn from(p: Params) -> Self {
        Inputs {
            sector_size: p.data_size,
            partitions: p.partitions,
            hasher: p.hasher.clone(),
            samples: p.samples,
            layers: p.layer_challenges.layers(),
            partition_challenges: p.layer_challenges.challenges_count_all() / p.partitions,
            total_challenges: p.layer_challenges.challenges_count_all(),
        }
    }
}

fn generate_report<H: 'static>(params: Params, cache_dir: &TempDir) -> anyhow::Result<Report>
where
    H: Hasher,
{
    let FuncMeasurement {
        cpu_time: total_cpu_time,
        wall_time: total_wall_time,
        return_value: mut report,
    } = measure(|| {
        let mut report = Report {
            inputs: Inputs::from(params.clone()),
            outputs: Default::default(),
        };

        let Params {
            samples,
            data_size,
            partitions,
            circuit,
            groth,
            bench,
            extract,
            dump_proofs,
            bench_only,
            layer_challenges,
            ..
        } = &params;

        let mut total_proving_wall_time = Duration::new(0, 0);
        let mut total_proving_cpu_time = Duration::new(0, 0);

        let rng = &mut rand::thread_rng();
        let nodes = data_size / 32;
        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| {
                let v: H::Domain = H::Domain::random(rng);
                v.into_bytes()
            })
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        let replica_id = H::Domain::random(rng);
        let sp = stacked::SetupParams {
            nodes,
            degree: BASE_DEGREE,
            expansion_degree: EXP_DEGREE,
            seed: new_seed(),
            layer_challenges: layer_challenges.clone(),
        };

        let pp = StackedDrg::<BinaryMerkleTree<H>, Sha256Hasher>::setup(&sp)?;

        let (pub_in, priv_in, d) = if *bench_only {
            (None, None, None)
        } else {
            // Generate a replica path.
            let replica_path = cache_dir.path().join("replica-path");
            let mut mmapped_data = setup_replica(&data, &replica_path);

            let seed = rng.gen();

            let FuncMeasurement {
                cpu_time: replication_cpu_time,
                wall_time: replication_wall_time,
                return_value: (pub_inputs, priv_inputs),
            } = measure(|| {
                let (tau, (p_aux, t_aux)) =
                    StackedDrg::<BinaryMerkleTree<H>, Sha256Hasher>::replicate(
                        &pp,
                        &replica_id,
                        (&mut mmapped_data[..]).into(),
                        None,
                        config.clone(),
                        replica_path.clone(),
                    )?;

                let pb = stacked::PublicInputs::<H::Domain, <Sha256Hasher as Hasher>::Domain> {
                    replica_id,
                    seed,
                    tau: Some(tau),
                    k: Some(0),
                };

                // Convert TemporaryAux to TemporaryAuxCache, which instantiates all
                // elements based on the configs stored in TemporaryAux.
                let t_aux = TemporaryAuxCache::new(&t_aux, replica_path)
                    .expect("failed to restore contents of t_aux");

                let pv = stacked::PrivateInputs { p_aux, t_aux };

                Ok((pb, pv))
            })?;

            let avg_duration = |duration: Duration, data_size: &usize| {
                if *data_size > (u32::MAX as usize) {
                    // Duration only supports division by u32, so if data_size (of type usize) is larger,
                    // we have to jump through some hoops to get the value we want, which is duration / size.
                    // Consider: x = size / max
                    //           y = duration / x = duration * max / size
                    //           y / max = duration * max / size * max = duration / size
                    let x = *data_size as f64 / f64::from(u32::MAX);
                    let y = duration / x as u32;
                    y / u32::MAX
                } else {
                    duration / (*data_size as u32)
                }
            };

            report.outputs.replication_wall_time_ms =
                Some(replication_wall_time.as_millis() as u64);
            report.outputs.replication_cpu_time_ms = Some(replication_cpu_time.as_millis() as u64);

            report.outputs.replication_wall_time_ns_per_byte =
                Some(avg_duration(replication_wall_time, data_size).as_nanos() as u64);
            report.outputs.replication_cpu_time_ns_per_byte =
                Some(avg_duration(replication_cpu_time, data_size).as_nanos() as u64);

            let FuncMeasurement {
                cpu_time: vanilla_proving_cpu_time,
                wall_time: vanilla_proving_wall_time,
                return_value: all_partition_proofs,
            } = measure(|| {
                StackedDrg::<BinaryMerkleTree<H>, Sha256Hasher>::prove_all_partitions(
                    &pp,
                    &pub_inputs,
                    &priv_inputs,
                    *partitions,
                )
            })?;

            report.outputs.vanilla_proving_wall_time_us =
                Some(vanilla_proving_wall_time.as_micros() as u64);
            report.outputs.vanilla_proving_cpu_time_us =
                Some(vanilla_proving_cpu_time.as_micros() as u64);

            total_proving_wall_time += vanilla_proving_wall_time;
            total_proving_cpu_time += vanilla_proving_cpu_time;

            if *dump_proofs {
                dump_proof_bytes(&all_partition_proofs)?;
            }

            let mut total_verification_time = FuncMeasurement {
                cpu_time: Duration::new(0, 0),
                wall_time: Duration::new(0, 0),
                return_value: (),
            };

            for _ in 0..*samples {
                let m = measure(|| {
                    let verified =
                        StackedDrg::<BinaryMerkleTree<H>, Sha256Hasher>::verify_all_partitions(
                            &pp,
                            &pub_inputs,
                            &all_partition_proofs,
                        )?;

                    if !verified {
                        panic!("verification failed");
                    }

                    Ok(())
                })?;

                total_verification_time.cpu_time += m.cpu_time;
                total_verification_time.wall_time += m.wall_time;

                report.outputs.vanilla_verification_wall_time_us =
                    Some(m.wall_time.as_micros() as u64);
                report.outputs.vanilla_verification_cpu_time_us =
                    Some(m.cpu_time.as_micros() as u64);
            }

            let avg_seconds = |duration: Duration, samples: &usize| {
                let n = duration / *samples as u32;
                f64::from(n.subsec_nanos()) / 1_000_000_000f64 + (n.as_secs() as f64)
            };

            report.outputs.verifying_wall_time_avg_ms =
                Some((avg_seconds(total_verification_time.wall_time, samples) * 1000.0) as u64);
            report.outputs.verifying_cpu_time_avg_ms =
                Some((avg_seconds(total_verification_time.cpu_time, samples) * 1000.0) as u64);

            (Some(pub_inputs), Some(priv_inputs), Some(data))
        };

        if *circuit || *groth || *bench || *bench_only {
            let CircuitWorkMeasurement {
                cpu_time,
                wall_time,
            } = do_circuit_work(&pp, pub_in, priv_in, &params, &mut report)?;
            total_proving_wall_time += wall_time;
            total_proving_cpu_time += cpu_time;
        }

        if let Some(data) = d {
            if *extract {
                let m = measure(|| {
                    StackedDrg::<BinaryMerkleTree<H>, Sha256Hasher>::extract_all(
                        &pp,
                        &replica_id,
                        &data,
                        Some(config.clone()),
                    )
                })?;

                assert_ne!(&(*data), m.return_value.as_slice());
                report.outputs.extracting_wall_time_ms = Some(m.wall_time.as_millis() as u64);
                report.outputs.extracting_cpu_time_ms = Some(m.cpu_time.as_millis() as u64);
            }
        }

        // total proving time is the sum of "the circuit work" and vanilla
        // proving time
        report.outputs.total_proving_wall_time_ms =
            Some(total_proving_wall_time.as_millis() as u64);
        report.outputs.total_proving_cpu_time_ms = Some(total_proving_cpu_time.as_millis() as u64);

        Ok(report)
    })?;

    report.outputs.total_report_wall_time_ms = total_wall_time.as_millis() as u64;
    report.outputs.total_report_cpu_time_ms = total_cpu_time.as_millis() as u64;

    Ok(report)
}

struct CircuitWorkMeasurement {
    cpu_time: Duration,
    wall_time: Duration,
}

fn do_circuit_work<Tree: 'static + MerkleTreeTrait>(
    pp: &<StackedDrg<Tree, Sha256Hasher> as ProofScheme>::PublicParams,
    pub_in: Option<<StackedDrg<Tree, Sha256Hasher> as ProofScheme>::PublicInputs>,
    priv_in: Option<<StackedDrg<Tree, Sha256Hasher> as ProofScheme>::PrivateInputs>,
    params: &Params,
    report: &mut Report,
) -> anyhow::Result<CircuitWorkMeasurement> {
    let mut proving_wall_time = Duration::new(0, 0);
    let mut proving_cpu_time = Duration::new(0, 0);

    let Params {
        samples,
        partitions,
        circuit,
        groth,
        bench,
        bench_only,
        ..
    } = params;

    let compound_public_params = compound_proof::PublicParams {
        vanilla_params: pp.clone(),
        partitions: Some(*partitions),
        priority: false,
    };

    if *bench || *circuit || *bench_only {
        info!("Generating blank circuit: start");
        let mut cs = BenchCS::<Bls12>::new();
        <StackedCompound<_, _> as CompoundProof<StackedDrg<Tree, Sha256Hasher>, _>>::blank_circuit(
            &pp,
        )
        .synthesize(&mut cs)?;

        report.outputs.circuit_num_inputs = Some(cs.num_inputs() as u64);
        report.outputs.circuit_num_constraints = Some(cs.num_constraints() as u64);
        info!("Generating blank circuit: done");
    }

    if *groth {
        info!("Generating Groth Proof");
        let pub_inputs = pub_in.expect("missing public inputs");
        let priv_inputs = priv_in.expect("missing private inputs");

        // We should implement a method of CompoundProof, which will skip vanilla proving.
        // We should also allow the serialized vanilla proofs to be passed (as a file) to the example
        // and skip replication/vanilla-proving entirely.
        let gparams = <StackedCompound<_, _> as CompoundProof<
            StackedDrg<Tree, Sha256Hasher>,
            _,
        >>::groth_params::<rand::rngs::OsRng>(
            None, &compound_public_params.vanilla_params
        )?;

        let multi_proof = {
            let FuncMeasurement {
                wall_time,
                cpu_time,
                return_value,
            } = measure(|| {
                StackedCompound::prove(&compound_public_params, &pub_inputs, &priv_inputs, &gparams)
            })?;
            proving_wall_time += wall_time;
            proving_cpu_time += cpu_time;
            return_value
        };

        let verified = {
            let mut total_groth_verifying_wall_time = Duration::new(0, 0);
            let mut total_groth_verifying_cpu_time = Duration::new(0, 0);

            let mut result = true;
            for _ in 0..*samples {
                let cur_result = result;
                let m = measure(|| {
                    StackedCompound::verify(
                        &compound_public_params,
                        &pub_inputs,
                        &multi_proof,
                        &ChallengeRequirements {
                            minimum_challenges: 1,
                        },
                    )
                })?;

                // If one verification fails, result becomes permanently false.
                result = result && cur_result;
                total_groth_verifying_wall_time += m.wall_time;
                total_groth_verifying_cpu_time += m.cpu_time;
            }
            let avg_groth_verifying_wall_time = total_groth_verifying_wall_time / *samples as u32;
            let avg_groth_verifying_cpu_time = total_groth_verifying_cpu_time / *samples as u32;

            report.outputs.avg_groth_verifying_wall_time_ms =
                Some(avg_groth_verifying_wall_time.as_millis() as u64);
            report.outputs.avg_groth_verifying_cpu_time_ms =
                Some(avg_groth_verifying_cpu_time.as_millis() as u64);

            result
        };
        assert!(verified);
    }

    Ok(CircuitWorkMeasurement {
        cpu_time: proving_cpu_time,
        wall_time: proving_wall_time,
    })
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Inputs {
    sector_size: usize,
    partitions: usize,
    hasher: String,
    samples: usize,
    layers: usize,
    partition_challenges: usize,
    total_challenges: usize,
}

#[derive(Serialize, Default)]
#[serde(rename_all = "kebab-case")]
struct Outputs {
    avg_groth_verifying_cpu_time_ms: Option<u64>,
    avg_groth_verifying_wall_time_ms: Option<u64>,
    circuit_num_constraints: Option<u64>,
    circuit_num_inputs: Option<u64>,
    extracting_cpu_time_ms: Option<u64>,
    extracting_wall_time_ms: Option<u64>,
    replication_wall_time_ms: Option<u64>,
    replication_cpu_time_ms: Option<u64>,
    replication_wall_time_ns_per_byte: Option<u64>,
    replication_cpu_time_ns_per_byte: Option<u64>,
    total_report_cpu_time_ms: u64,
    total_report_wall_time_ms: u64,
    total_proving_cpu_time_ms: Option<u64>,
    total_proving_wall_time_ms: Option<u64>,
    vanilla_proving_cpu_time_us: Option<u64>,
    vanilla_proving_wall_time_us: Option<u64>,
    vanilla_verification_wall_time_us: Option<u64>,
    vanilla_verification_cpu_time_us: Option<u64>,
    verifying_wall_time_avg_ms: Option<u64>,
    verifying_cpu_time_avg_ms: Option<u64>,
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Report {
    inputs: Inputs,
    outputs: Outputs,
}

impl Report {
    /// Print all results to stdout
    pub fn print(&self) {
        let wrapped = Metadata::wrap(&self).expect("failed to retrieve metadata");
        serde_json::to_writer(io::stdout(), &wrapped).expect("cannot write report-JSON to stdout");
    }
}

pub struct RunOpts {
    pub bench: bool,
    pub bench_only: bool,
    pub challenges: usize,
    pub circuit: bool,
    pub dump: bool,
    pub extract: bool,
    pub groth: bool,
    pub hasher: String,
    pub layers: usize,
    pub no_bench: bool,
    pub no_tmp: bool,
    pub partitions: usize,
    pub size: usize,
}

pub fn run(opts: RunOpts) -> anyhow::Result<()> {
    let layer_challenges = LayerChallenges::new(opts.layers, opts.challenges);

    let params = Params {
        data_size: opts.size * 1024,
        partitions: opts.partitions,
        layer_challenges,
        dump_proofs: opts.dump,
        groth: opts.groth,
        bench: !opts.no_bench && opts.bench,
        bench_only: opts.bench_only,
        circuit: opts.circuit,
        extract: opts.extract,
        hasher: opts.hasher,
        samples: 5,
    };

    info!("Benchy Stacked: {:?}", &params);

    let cache_dir = tempfile::tempdir().unwrap();

    let report = match params.hasher.as_ref() {
        "pedersen" => generate_report::<PedersenHasher>(params, &cache_dir)?,
        "sha256" => generate_report::<Sha256Hasher>(params, &cache_dir)?,
        "blake2s" => generate_report::<Blake2sHasher>(params, &cache_dir)?,
        _ => bail!("invalid hasher: {}", params.hasher),
    };

    report.print();

    Ok(())
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/window_post.rs ---
use std::collections::BTreeMap;
use std::io::{stdout, Seek, SeekFrom, Write};

use fil_proofs_tooling::shared::{PROVER_ID, RANDOMNESS, TICKET_BYTES};
use fil_proofs_tooling::{measure, Metadata};
use filecoin_proofs::constants::{
    POREP_PARTITIONS, WINDOW_POST_CHALLENGE_COUNT, WINDOW_POST_SECTOR_COUNT,
};
use filecoin_proofs::types::{
    PaddedBytesAmount, PoRepConfig, PoRepProofPartitions, PoStConfig, SectorSize,
    UnpaddedBytesAmount,
};
use filecoin_proofs::{
    add_piece, generate_piece_commitment, generate_window_post, seal_commit_phase1,
    seal_commit_phase2, seal_pre_commit_phase1, seal_pre_commit_phase2, validate_cache_for_commit,
    validate_cache_for_precommit_phase2, verify_window_post, with_shape, PoStType,
    PrivateReplicaInfo, PublicReplicaInfo,
};
use log::info;
use serde::Serialize;
use storage_proofs::merkle::MerkleTreeTrait;
use storage_proofs::sector::SectorId;
use tempfile::NamedTempFile;

const SECTOR_ID: u64 = 0;

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Inputs {
    sector_size: u64,
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Outputs {
    seal_pre_commit_phase1_cpu_time_ms: u64,
    seal_pre_commit_phase1_wall_time_ms: u64,
    validate_cache_for_precommit_phase2_cpu_time_ms: u64,
    validate_cache_for_precommit_phase2_wall_time_ms: u64,
    seal_pre_commit_phase2_cpu_time_ms: u64,
    seal_pre_commit_phase2_wall_time_ms: u64,
    validate_cache_for_commit_cpu_time_ms: u64,
    validate_cache_for_commit_wall_time_ms: u64,
    seal_commit_phase1_cpu_time_ms: u64,
    seal_commit_phase1_wall_time_ms: u64,
    seal_commit_phase2_cpu_time_ms: u64,
    seal_commit_phase2_wall_time_ms: u64,
    gen_window_post_cpu_time_ms: u64,
    gen_window_post_wall_time_ms: u64,
    verify_window_post_cpu_time_ms: u64,
    verify_window_post_wall_time_ms: u64,
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Report {
    inputs: Inputs,
    outputs: Outputs,
}

impl Report {
    /// Print all results to stdout
    pub fn print(&self) {
        let wrapped = Metadata::wrap(&self).expect("failed to retrieve metadata");
        serde_json::to_writer(stdout(), &wrapped).expect("cannot write report JSON to stdout");
    }
}

pub fn run_window_post_bench<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
) -> anyhow::Result<()> {
    let sector_size_unpadded_bytes_ammount =
        UnpaddedBytesAmount::from(PaddedBytesAmount(sector_size));

    // Create files for the staged and sealed sectors.
    let mut staged_file =
        NamedTempFile::new().expect("could not create temp file for staged sector");

    let sealed_file = NamedTempFile::new().expect("could not create temp file for sealed sector");

    // Generate the data from which we will create a replica, we will then prove the continued
    // storage of that replica using the PoSt.
    let piece_bytes: Vec<u8> = (0..usize::from(sector_size_unpadded_bytes_ammount))
        .map(|_| rand::random::<u8>())
        .collect();

    let mut piece_file = NamedTempFile::new()?;
    piece_file.write_all(&piece_bytes)?;
    piece_file.as_file_mut().sync_all()?;
    piece_file.as_file_mut().seek(SeekFrom::Start(0))?;

    let piece_info =
        generate_piece_commitment(piece_file.as_file_mut(), sector_size_unpadded_bytes_ammount)?;
    piece_file.as_file_mut().seek(SeekFrom::Start(0))?;

    add_piece(
        &mut piece_file,
        &mut staged_file,
        sector_size_unpadded_bytes_ammount,
        &[],
    )?;

    let piece_infos = vec![piece_info];

    // Replicate the staged sector, write the replica file to `sealed_path`.
    let porep_config = PoRepConfig {
        sector_size: SectorSize(sector_size),
        partitions: PoRepProofPartitions(
            *POREP_PARTITIONS
                .read()
                .unwrap()
                .get(&(sector_size))
                .unwrap(),
        ),
    };
    let cache_dir = tempfile::tempdir().unwrap();
    let sector_id = SectorId::from(SECTOR_ID);

    let seal_pre_commit_phase1_measurement = measure(|| {
        seal_pre_commit_phase1::<_, _, _, Tree>(
            porep_config,
            cache_dir.path(),
            staged_file.path(),
            sealed_file.path(),
            PROVER_ID,
            sector_id,
            TICKET_BYTES,
            &piece_infos,
        )
    })
    .expect("failed in seal_pre_commit_phase1");
    let phase1_output = seal_pre_commit_phase1_measurement.return_value;

    let validate_cache_for_precommit_phase2_measurement = measure(|| {
        validate_cache_for_precommit_phase2::<_, _, Tree>(
            cache_dir.path(),
            sealed_file.path(),
            &phase1_output,
        )
    })
    .expect("failed to validate cache for precommit phase2");

    let seal_pre_commit_phase2_measurement = measure(|| {
        seal_pre_commit_phase2::<_, _, Tree>(
            porep_config,
            phase1_output,
            cache_dir.path(),
            sealed_file.path(),
        )
    })
    .expect("failed in seal_pre_commit_phase2");
    let seal_pre_commit_output = seal_pre_commit_phase2_measurement.return_value;

    let seed = [0u8; 32];
    let comm_r = seal_pre_commit_output.comm_r;

    let validate_cache_for_commit_measurement =
        measure(|| validate_cache_for_commit::<_, _, Tree>(cache_dir.path(), sealed_file.path()))
            .expect("failed to validate cache for commit");

    let seal_commit_phase1_measurement = measure(|| {
        seal_commit_phase1::<_, Tree>(
            porep_config,
            cache_dir.path(),
            sealed_file.path(),
            PROVER_ID,
            sector_id,
            TICKET_BYTES,
            seed,
            seal_pre_commit_output,
            &piece_infos,
        )
    })
    .expect("failed in seal_commit_phase1");
    let phase1_output = seal_commit_phase1_measurement.return_value;

    let seal_commit_phase2_measurement =
        measure(|| seal_commit_phase2::<Tree>(porep_config, phase1_output, PROVER_ID, sector_id))
            .expect("failed in seal_commit_phase2");

    let pub_replica = PublicReplicaInfo::new(comm_r).expect("failed to create public replica info");

    let priv_replica = PrivateReplicaInfo::<Tree>::new(
        sealed_file.path().to_path_buf(),
        comm_r,
        cache_dir.into_path(),
    )
    .expect("failed to create private replica info");

    // Store the replica's private and publicly facing info for proving and verifying respectively.
    let mut pub_replica_info: BTreeMap<SectorId, PublicReplicaInfo> = BTreeMap::new();
    let mut priv_replica_info: BTreeMap<SectorId, PrivateReplicaInfo<Tree>> = BTreeMap::new();

    pub_replica_info.insert(sector_id, pub_replica);
    priv_replica_info.insert(sector_id, priv_replica);

    // Measure PoSt generation and verification.
    let post_config = PoStConfig {
        sector_size: SectorSize(sector_size),
        challenge_count: WINDOW_POST_CHALLENGE_COUNT,
        sector_count: *WINDOW_POST_SECTOR_COUNT
            .read()
            .unwrap()
            .get(&sector_size)
            .unwrap(),
        typ: PoStType::Window,
        priority: true,
    };

    let gen_window_post_measurement = measure(|| {
        generate_window_post::<Tree>(&post_config, &RANDOMNESS, &priv_replica_info, PROVER_ID)
    })
    .expect("failed to generate window post");

    let proof = &gen_window_post_measurement.return_value;

    let verify_window_post_measurement = measure(|| {
        verify_window_post::<Tree>(
            &post_config,
            &RANDOMNESS,
            &pub_replica_info,
            PROVER_ID,
            &proof,
        )
    })
    .expect("failed to verify window post proof");

    let report = Report {
        inputs: Inputs { sector_size },
        outputs: Outputs {
            seal_pre_commit_phase1_cpu_time_ms: seal_pre_commit_phase1_measurement
                .cpu_time
                .as_millis() as u64,
            seal_pre_commit_phase1_wall_time_ms: seal_pre_commit_phase1_measurement
                .wall_time
                .as_millis() as u64,
            validate_cache_for_precommit_phase2_cpu_time_ms:
                validate_cache_for_precommit_phase2_measurement
                    .cpu_time
                    .as_millis() as u64,
            validate_cache_for_precommit_phase2_wall_time_ms:
                validate_cache_for_precommit_phase2_measurement
                    .wall_time
                    .as_millis() as u64,
            seal_pre_commit_phase2_cpu_time_ms: seal_pre_commit_phase2_measurement
                .cpu_time
                .as_millis() as u64,
            seal_pre_commit_phase2_wall_time_ms: seal_pre_commit_phase2_measurement
                .wall_time
                .as_millis() as u64,
            validate_cache_for_commit_cpu_time_ms: validate_cache_for_commit_measurement
                .cpu_time
                .as_millis() as u64,
            validate_cache_for_commit_wall_time_ms: validate_cache_for_commit_measurement
                .wall_time
                .as_millis() as u64,
            seal_commit_phase1_cpu_time_ms: seal_commit_phase1_measurement.cpu_time.as_millis()
                as u64,
            seal_commit_phase1_wall_time_ms: seal_commit_phase1_measurement.wall_time.as_millis()
                as u64,
            seal_commit_phase2_cpu_time_ms: seal_commit_phase2_measurement.cpu_time.as_millis()
                as u64,
            seal_commit_phase2_wall_time_ms: seal_commit_phase2_measurement.wall_time.as_millis()
                as u64,
            gen_window_post_cpu_time_ms: gen_window_post_measurement.cpu_time.as_millis() as u64,
            gen_window_post_wall_time_ms: gen_window_post_measurement.wall_time.as_millis() as u64,
            verify_window_post_cpu_time_ms: verify_window_post_measurement.cpu_time.as_millis()
                as u64,
            verify_window_post_wall_time_ms: verify_window_post_measurement.wall_time.as_millis()
                as u64,
        },
    };

    // Create a JSON serializable report that we print to stdout (that will later be parsed using
    // the CLI JSON parser `jq`).
    report.print();
    Ok(())
}

pub fn run(sector_size: usize) -> anyhow::Result<()> {
    info!("Benchy Window PoSt: sector-size={}", sector_size,);

    with_shape!(
        sector_size as u64,
        run_window_post_bench,
        sector_size as u64
    )
}

'''
'''--- fil-proofs-tooling/src/bin/benchy/winning_post.rs ---
use std::io::stdout;

use anyhow::anyhow;
use fil_proofs_tooling::shared::{create_replica, PROVER_ID, RANDOMNESS};
use fil_proofs_tooling::{measure, Metadata};
use filecoin_proofs::constants::{WINNING_POST_CHALLENGE_COUNT, WINNING_POST_SECTOR_COUNT};
use filecoin_proofs::types::PoStConfig;
use filecoin_proofs::{
    generate_winning_post, generate_winning_post_sector_challenge, verify_winning_post, with_shape,
    PoStType,
};
use log::info;
use serde::Serialize;
use storage_proofs::merkle::MerkleTreeTrait;

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Inputs {
    sector_size: u64,
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Outputs {
    gen_winning_post_cpu_time_ms: u64,
    gen_winning_post_wall_time_ms: u64,
    verify_winning_post_cpu_time_ms: u64,
    verify_winning_post_wall_time_ms: u64,
    gen_winning_post_sector_challenge_cpu_time_ms: u64,
    gen_winning_post_sector_challenge_wall_time_ms: u64,
}

#[derive(Serialize)]
#[serde(rename_all = "kebab-case")]
struct Report {
    inputs: Inputs,
    outputs: Outputs,
}

impl Report {
    /// Print all results to stdout
    pub fn print(&self) {
        let wrapped = Metadata::wrap(&self).expect("failed to retrieve metadata");
        serde_json::to_writer(stdout(), &wrapped).expect("cannot write report JSON to stdout");
    }
}

pub fn run_fallback_post_bench<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
) -> anyhow::Result<()> {
    if WINNING_POST_SECTOR_COUNT != 1 {
        return Err(anyhow!(
            "This benchmark only works with WINNING_POST_SECTOR_COUNT == 1"
        ));
    }
    let (sector_id, replica_output) = create_replica::<Tree>(sector_size);

    // Store the replica's private and publicly facing info for proving and verifying respectively.
    let pub_replica_info = vec![(sector_id, replica_output.public_replica_info)];
    let priv_replica_info = vec![(sector_id, replica_output.private_replica_info)];

    let post_config = PoStConfig {
        sector_size: sector_size.into(),
        sector_count: WINNING_POST_SECTOR_COUNT,
        challenge_count: WINNING_POST_CHALLENGE_COUNT,
        typ: PoStType::Winning,
        priority: true,
    };

    let gen_winning_post_sector_challenge_measurement = measure(|| {
        generate_winning_post_sector_challenge::<Tree>(
            &post_config,
            &RANDOMNESS,
            WINNING_POST_SECTOR_COUNT as u64,
            PROVER_ID,
        )
    })
    .expect("failed to generate winning post sector challenge");

    let gen_winning_post_measurement = measure(|| {
        generate_winning_post::<Tree>(&post_config, &RANDOMNESS, &priv_replica_info[..], PROVER_ID)
    })
    .expect("failed to generate winning post");

    let proof = &gen_winning_post_measurement.return_value;

    let verify_winning_post_measurement = measure(|| {
        verify_winning_post::<Tree>(
            &post_config,
            &RANDOMNESS,
            &pub_replica_info[..],
            PROVER_ID,
            &proof,
        )
    })
    .expect("failed to verify winning post proof");

    // Create a JSON serializable report that we print to stdout (that will later be parsed using
    // the CLI JSON parser `jq`).
    let report = Report {
        inputs: Inputs { sector_size },
        outputs: Outputs {
            gen_winning_post_cpu_time_ms: gen_winning_post_measurement.cpu_time.as_millis() as u64,
            gen_winning_post_wall_time_ms: gen_winning_post_measurement.wall_time.as_millis()
                as u64,
            verify_winning_post_cpu_time_ms: verify_winning_post_measurement.cpu_time.as_millis()
                as u64,
            verify_winning_post_wall_time_ms: verify_winning_post_measurement.wall_time.as_millis()
                as u64,
            gen_winning_post_sector_challenge_cpu_time_ms:
                gen_winning_post_sector_challenge_measurement
                    .cpu_time
                    .as_millis() as u64,
            gen_winning_post_sector_challenge_wall_time_ms:
                gen_winning_post_sector_challenge_measurement
                    .wall_time
                    .as_millis() as u64,
        },
    };
    report.print();
    Ok(())
}

pub fn run(sector_size: usize) -> anyhow::Result<()> {
    info!("Benchy Winning PoSt: sector-size={}", sector_size,);

    with_shape!(
        sector_size as u64,
        run_fallback_post_bench,
        sector_size as u64
    )
}

'''
'''--- fil-proofs-tooling/src/bin/gpu-cpu-test/README.md ---
GPU CPU Test
============

This is a test utility to test whether it works to prioritize certain proofs. When a proof is prioritized, it will run on the GPU and all other proofs will be pushed to the CPU.

This utility is meant to be run manually. It spawns multiple threads/processes that run proofs. Those get killed after 5 minutes of running. The overall test runs longer as some input data needs to be generated. By default, one thread/process will always be prioritized to run on the GPU. The other one might be moved to the CPU.

To check whether the prioritization is working, run it first with default parameters:

    $ RUST_LOG=debug cargo run --release --bin gpu-cpu-test

Occasionally you should see log messaged like

    2020-05-15T12:35:48.680 366073 low-02 WARN bellperson::gpu::locks > GPU acquired by a high priority process! Freeing up Multiexp kernels...

which indicate that the high priority proof indeed pushes lower priority ones down from the GPU onto the CPU.

Once the test is completed there should be log messages that contain the results, the number of proofs run per thread:

    Thread high info: RunInfo { elapsed: 301.714277787s, iterations: 51 }
    Thread low-01 info: RunInfo { elapsed: 306.615414259s, iterations: 15 }
    Thread low-02 info: RunInfo { elapsed: 303.641817512s, iterations: 17 }

The high priority proof clearly was able to run more proofs than the lower priority ones.

To double check the result, you can also run the test without special priorities. Then the number of proofs run should be similar across all the threads as you can see below (the first thread is always called `high` even if it doesn't run with high priority):

    $ RUST_LOG=debug cargo run --release --bin gpu-cpu-test -- --gpu-stealing=false
    Thread high info: RunInfo { elapsed: 307.515676843s, iterations: 34 }
    Thread low-01 info: RunInfo { elapsed: 305.585567866s, iterations: 34 }
    Thread low-02 info: RunInfo { elapsed: 302.7105106s, iterations: 34 }

'''
'''--- fil-proofs-tooling/src/bin/gpu-cpu-test/main.rs ---
use std::collections::HashMap;
use std::process::{self, Child, Command, Stdio};
use std::str;
use std::sync::mpsc::{self, Receiver, Sender, TryRecvError};
use std::thread;
use std::time::{Duration, Instant};

use clap::{arg_enum, value_t, App, Arg};
use fil_proofs_tooling::shared::{create_replica, PROVER_ID, RANDOMNESS};
use filecoin_proofs::constants::{SectorShape8MiB, SECTOR_SIZE_8_MIB};
use filecoin_proofs::types::{PoStConfig, SectorSize};
use filecoin_proofs::{
    generate_winning_post, PoStType, PrivateReplicaInfo, WINNING_POST_CHALLENGE_COUNT,
    WINNING_POST_SECTOR_COUNT,
};
use log::{debug, info};
use storage_proofs::sector::SectorId;

type MerkleTree = SectorShape8MiB;
const SECTOR_SIZE: u64 = SECTOR_SIZE_8_MIB;
const TIMEOUT: u64 = 5 * 60;
const POST_CONFIG: PoStConfig = PoStConfig {
    sector_size: SectorSize(SECTOR_SIZE),
    challenge_count: WINNING_POST_CHALLENGE_COUNT,
    sector_count: WINNING_POST_SECTOR_COUNT,
    typ: PoStType::Winning,
    priority: false,
};

arg_enum! {
    #[derive(Debug)]
    pub enum Mode {
        Threads,
        Processes,
    }
}

#[derive(Debug)]
pub struct RunInfo {
    elapsed: Duration,
    iterations: u8,
}

pub fn colored_with_thread(
    writer: &mut dyn std::io::Write,
    now: &mut flexi_logger::DeferredNow,
    record: &flexi_logger::Record,
) -> Result<(), std::io::Error> {
    let level = record.level();
    write!(
        writer,
        "{} {} {} {} {} > {}",
        now.now().format("%Y-%m-%dT%H:%M:%S%.3f"),
        process::id(),
        thread::current()
            .name()
            .unwrap_or(&format!("{:?}", thread::current().id())),
        flexi_logger::style(level, level),
        record.module_path().unwrap_or("<unnamed>"),
        record.args(),
    )
}

fn generate_post(priv_replica_info: &[(SectorId, PrivateReplicaInfo<MerkleTree>)]) {
    generate_winning_post::<MerkleTree>(&POST_CONFIG, &RANDOMNESS, priv_replica_info, PROVER_ID)
        .expect("failed to generate PoSt");
}

fn generate_post_in_priority(priv_replica_info: &[(SectorId, PrivateReplicaInfo<MerkleTree>)]) {
    let mut post_config = POST_CONFIG;
    post_config.priority = true;
    generate_winning_post::<MerkleTree>(&post_config, &RANDOMNESS, priv_replica_info, PROVER_ID)
        .expect("failed to generate PoSt with high priority");
}

fn thread_fun(
    rx: Receiver<()>,
    gpu_stealing: bool,
    priv_replica_infos: &[(SectorId, PrivateReplicaInfo<MerkleTree>)],
) -> RunInfo {
    let timing = Instant::now();
    let mut iteration = 0;
    while iteration < std::u8::MAX {
        info!("iter {}", iteration);

        // This is the higher priority proof, get it on the GPU even if there is one running
        // already there
        if gpu_stealing {
            // Run the actual proof
            generate_post_in_priority(&priv_replica_infos);
        } else {
            // Run the actual proof
            generate_post(&priv_replica_infos);
        }

        // Waiting for this thread to be killed
        match rx.try_recv() {
            Ok(_) | Err(TryRecvError::Disconnected) => {
                debug!("High priority proofs received kill message");
                break;
            }
            Err(TryRecvError::Empty) => (),
        }
        iteration += 1;
    }
    RunInfo {
        elapsed: timing.elapsed(),
        iterations: iteration,
    }
}

fn spawn_thread(
    name: &str,
    gpu_stealing: bool,
    priv_replica_info: (SectorId, PrivateReplicaInfo<MerkleTree>),
) -> (Sender<()>, thread::JoinHandle<RunInfo>) {
    let (tx, rx) = mpsc::channel();

    let thread_config = thread::Builder::new().name(name.to_string());
    let handler = thread_config
        .spawn(move || -> RunInfo { thread_fun(rx, gpu_stealing, &[priv_replica_info]) })
        .expect("Could not spawn thread");

    (tx, handler)
}

fn threads_mode(parallel: u8, gpu_stealing: bool) {
    // All channels we send a termination message to
    let mut senders = Vec::new();
    // All thread handles that get terminated
    let mut threads: Vec<Option<thread::JoinHandle<_>>> = Vec::new();

    // Create fixtures only once for both threads
    let (sector_id, replica_output) = create_replica::<MerkleTree>(SECTOR_SIZE);
    let priv_replica_info = (sector_id, replica_output.private_replica_info);

    // Put each proof into it's own scope (the other one is due to the if statement)
    {
        let (tx, handler) = spawn_thread("high", gpu_stealing, priv_replica_info.clone());
        senders.push(tx);
        threads.push(Some(handler));
    }

    (1..parallel).for_each(|ii| {
        let name = format!("low-{:02}", ii);
        let (tx, handler) = spawn_thread(&name, false, priv_replica_info.clone());
        senders.push(tx);
        threads.push(Some(handler));
    });

    // Terminate all threads after that amount of time
    let timeout = Duration::from_secs(TIMEOUT);
    thread::sleep(timeout);
    info!("Waited long enough to kill all threads");
    for tx in senders {
        tx.send(()).unwrap();
    }

    for thread in &mut threads {
        if let Some(handler) = thread.take() {
            let thread_name = handler
                .thread()
                .name()
                .unwrap_or(&format!("{:?}", handler.thread().id()))
                .to_string();
            let run_info = handler.join().unwrap();
            info!("Thread {} info: {:?}", thread_name, run_info);
            // Also print it, so that we can get that information in processes mode
            println!("Thread {} info: {:?}", thread_name, run_info);
        }
    }
}

fn processes_mode(parallel: u8, gpu_stealing: bool) {
    let mut children = HashMap::new();

    // Put each process into it's own scope (the other one is due to the if statement)
    {
        let name = "high";
        let child = spawn_process(&name, gpu_stealing);
        children.insert(name.to_string(), child);
    }

    (1..parallel).for_each(|ii| {
        let name = format!("low-{:02}", ii);
        let child = spawn_process(&name, false);
        children.insert(name, child);
    });

    // Wait for all processes to finish and log their output
    for (name, child) in children {
        let output = child.wait_with_output().unwrap();
        info!(
            "Process {} info: {}",
            name,
            str::from_utf8(&output.stdout).unwrap()
        );
    }
}

fn spawn_process(name: &str, gpu_stealing: bool) -> Child {
    // Runs this this programm again in it's own process, but this time it is spawning a single
    // thread to run the actual proof.
    Command::new("cargo")
        .arg("run")
        .arg("--release")
        .args(&["--bin", "gpu-cpu-test"])
        .arg("--")
        .args(&["--gpu-stealing", &gpu_stealing.to_string()])
        .args(&["--parallel", "1"])
        .args(&["--mode", "threads"])
        // Print logging to the main process stderr
        .stderr(Stdio::inherit())
        // Use the stdout to return a result
        .stdout(Stdio::piped())
        .spawn()
        .unwrap_or_else(|_| panic!("failed to execute process {}", name))
}

fn main() {
    flexi_logger::Logger::with_env()
        .format(colored_with_thread)
        .start()
        .expect("Initializing logger failed. Was another logger already initialized?");

    let matches = App::new("gpu-cpu-test")
        .version("0.1")
        .about("Tests if moving proofs from GPU to CPU works")
        .arg(
            Arg::with_name("parallel")
                .long("parallel")
                .help("Run multiple proofs in parallel.")
                .default_value("3"),
        )
        .arg(
            Arg::with_name("gpu-stealing")
                .long("gpu-stealing")
                .help("Force high priority proof on the GPU and let low priority one continue on CPU.")
                .default_value("true"),
        )
        .arg(
            Arg::with_name("mode")
              .long("mode")
              .help("Whether to run with threads or processes.")
               .possible_values(&["threads", "processes"])
               .case_insensitive(true)
               .default_value("threads"),
        )
        .get_matches();

    let parallel = value_t!(matches, "parallel", u8).unwrap();
    if parallel == 1 {
        info!("Running high priority proof only")
    } else {
        info!("Running high and low priority proofs in parallel")
    }
    let gpu_stealing = value_t!(matches, "gpu-stealing", bool).unwrap();
    if gpu_stealing {
        info!("Force low piority proofs to CPU")
    } else {
        info!("Let everyone queue up to run on GPU")
    }
    let mode = value_t!(matches, "mode", Mode).unwrap_or_else(|e| e.exit());
    match mode {
        Mode::Threads => info!("Using threads"),
        Mode::Processes => info!("Using processes"),
    }

    match mode {
        Mode::Threads => {
            threads_mode(parallel, gpu_stealing);
        }
        Mode::Processes => {
            processes_mode(parallel, gpu_stealing);
        }
    }
}

'''
'''--- fil-proofs-tooling/src/bin/micro.rs ---
use std::io::{self, BufRead};

use anyhow::{anyhow, Context, Result};
use commandspec::command;
use fil_proofs_tooling::metadata::Metadata;
use regex::Regex;
use serde::Serialize;

#[derive(Debug, Default, Clone, PartialEq, Serialize)]
#[serde(rename_all = "kebab-case")]
struct Interval {
    start: f64,
    end: f64,
    unit: Option<String>,
}

#[derive(Debug, Default, Clone, PartialEq, Serialize)]
#[serde(rename_all = "kebab-case")]
struct Point {
    value: f64,
    unit: Option<String>,
}

#[derive(Debug, Default, Clone, PartialEq, Serialize)]
#[serde(rename_all = "kebab-case")]
struct CriterionResult {
    name: String,
    samples: u32,
    time_med: Point,
    time: Interval,
    throughput: Option<Interval>,
    throughput_med: Option<Point>,
    slope: Option<Interval>,
    mean: Option<Interval>,
    median: Option<Interval>,
    r_2: Option<Interval>,
    std_dev: Option<Interval>,
    med_abs_dev: Option<Interval>,
}

fn make_detail_re(name: &str) -> Regex {
    Regex::new(&format!(r"{}\s+\[(\d+\.\d+ \w+) (\d+\.\d+ \w+)\]", name)).expect("invalid regex")
}

/// Parses the output of `cargo bench -p storage-proofs --bench <benchmark> -- --verbose --colors never`.
fn parse_criterion_out(s: impl AsRef<str>) -> Result<Vec<CriterionResult>> {
    let mut res = Vec::new();

    let start_re = Regex::new(r"^Benchmarking ([^:]+)$").expect("invalid regex");
    let sample_re = Regex::new(r"Collecting (\d+) samples").expect("invalid regex");
    let time_re = Regex::new(r"time:\s+\[(\d+\.\d+ \w+) (\d+\.\d+ \w+) (\d+\.\d+ \w+)]")
        .expect("invalid regex");

    let throughput_re =
        Regex::new(r"thrpt:\s+\[(\d+\.\d+ \w+/s) (\d+\.\d+ \w+/s) (\d+\.\d+ \w+/s)]")
            .expect("invalid regex");

    let slope_re = make_detail_re("slope");
    let r_2_re = Regex::new(r"R\^2\s+\[(\d+\.\d+) (\d+\.\d+)\]").expect("invalid regex");
    let mean_re = make_detail_re("mean");
    let std_dev_re = make_detail_re(r"std\. dev\.");
    let median_re = make_detail_re("median");
    let med_abs_dev_re = make_detail_re(r"med\. abs\. dev\.");

    #[allow(clippy::type_complexity)]
    let mut current: Option<(
        String,
        Option<u32>,
        Option<Point>,
        Option<Interval>,
        Option<Interval>,
        Option<Point>,
        Option<Interval>,
        Option<Interval>,
        Option<Interval>,
        Option<Interval>,
        Option<Interval>,
        Option<Interval>,
    )> = None;

    for line in s.as_ref().lines() {
        if let Some(caps) = start_re.captures(line) {
            if current.is_some() {
                let r = current.take().unwrap();
                res.push(CriterionResult {
                    name: r.0,
                    samples: r.1.unwrap_or_default(),
                    time_med: r.2.unwrap_or_default(),
                    time: r.3.unwrap_or_default(),
                    throughput: r.4,
                    throughput_med: r.5,
                    slope: r.6,
                    mean: r.7,
                    median: r.8,
                    r_2: r.9,
                    std_dev: r.10,
                    med_abs_dev: r.11,
                });
            }
            current = Some((
                caps[1].to_string(),
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
            ));
        }

        if let Some(ref mut current) = current {
            // Samples
            if let Some(caps) = sample_re.captures(line) {
                current.1 = Some(caps[1].parse().unwrap_or_default());
            }

            // Time
            if let Some(caps) = time_re.captures(line) {
                current.2 = Some(Point {
                    value: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
                current.3 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[3]),
                    unit: Some("us".to_string()),
                });
            }

            // Throughput
            if let Some(caps) = throughput_re.captures(line) {
                current.4 = Some(Interval {
                    start: throughput_val(&caps[1]),
                    end: throughput_val(&caps[3]),
                    unit: Some(throughput_to_uom(&caps[1])),
                });
                current.5 = Some(Point {
                    value: throughput_val(&caps[2]),
                    unit: Some(throughput_to_uom(&caps[2])),
                });
            }

            // Slope
            if let Some(caps) = slope_re.captures(line) {
                current.6 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
            }

            // Mean
            if let Some(caps) = mean_re.captures(line) {
                current.7 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
            }

            // median
            if let Some(caps) = median_re.captures(line) {
                current.8 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
            }

            // R^2
            if let Some(caps) = r_2_re.captures(line) {
                current.9 = Some(Interval {
                    start: caps[1].parse().unwrap(),
                    end: caps[2].parse().unwrap(),
                    unit: None,
                });
            }

            // std.dev
            if let Some(caps) = std_dev_re.captures(line) {
                current.10 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
            }

            // med.abs.dev
            if let Some(caps) = med_abs_dev_re.captures(line) {
                current.11 = Some(Interval {
                    start: time_to_us(&caps[1]),
                    end: time_to_us(&caps[2]),
                    unit: Some("us".to_string()),
                });
            }
        }
    }

    if current.is_some() {
        let r = current.take().unwrap();
        res.push(CriterionResult {
            name: r.0,
            samples: r.1.unwrap_or_default(),
            time_med: r.2.unwrap_or_default(),
            time: r.3.unwrap_or_default(),
            throughput: r.4,
            throughput_med: r.5,
            slope: r.6,
            mean: r.7,
            median: r.8,
            r_2: r.9,
            std_dev: r.10,
            med_abs_dev: r.11,
        });
    }
    Ok(res)
}

/// parses a string of the form "521.80 KiB/s".
fn throughput_to_uom(s: &str) -> String {
    let parts = s.trim().split_whitespace().collect::<Vec<_>>();
    assert_eq!(parts.len(), 2, "invalid val: {:?}", parts);
    let _: f64 = parts[0].parse().expect("invalid number");
    parts[1].to_string()
}

/// parses a string of the form "521.80 KiB/s".
fn throughput_val(s: &str) -> f64 {
    let parts = s.trim().split_whitespace().collect::<Vec<_>>();
    assert_eq!(parts.len(), 2, "invalid val: {:?}", parts);
    let ts: f64 = parts[0].parse().expect("invalid number");
    ts
}

/// parses a string of the form "123.12 us".
fn time_to_us(s: &str) -> f64 {
    let parts = s.trim().split_whitespace().collect::<Vec<_>>();
    assert_eq!(parts.len(), 2, "invalid val: {:?}", parts);
    let ts: f64 = parts[0].parse().expect("invalid number");
    let normalized = match parts[1] {
        "ps" => ts / 1_000_000.,
        "ns" => ts / 1000.,
        "us" => ts,
        "ms" => ts * 1000.,
        "s" => ts * 1000. * 1000.,
        _ => panic!("unknown unit: {}", parts[1]),
    };

    (normalized * 10000.0).round() / 10000.0
}

fn run_benches(mut args: Vec<String>) -> Result<()> {
    let is_verbose = if let Some(index) = args.iter().position(|a| a.as_str() == "--verbose") {
        args.remove(index);
        true
    } else {
        false
    };

    let mut cmd = command!(
        r"
        cargo bench -p storage-proofs {args} -- --verbose --color never
    ",
        args = args
    )
    .map_err(|err| anyhow!("{:?}", err))?;

    let process = cmd.stdout(std::process::Stdio::piped()).spawn()?;

    let stdout = process.stdout.context("Failed to capture stdout")?;

    let reader = std::io::BufReader::new(stdout);
    let mut stdout = String::new();
    reader.lines().for_each(|line| {
        let line = line.unwrap();
        if is_verbose {
            println!("{}", &line);
        }
        stdout += &line;
        stdout += "\n";
    });

    let parsed_results = parse_criterion_out(stdout)?;

    let wrapped = Metadata::wrap(parsed_results)?;

    serde_json::to_writer(io::stdout(), &wrapped).context("cannot write report-JSON to stdout")?;

    Ok(())
}

fn main() {
    let pass_through = std::env::args().skip(1).collect();

    match run_benches(pass_through) {
        Ok(()) => {}
        Err(err) => {
            eprintln!("{}", err);
            std::process::exit(1);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_time_to_us() {
        assert_eq!(time_to_us("123.12 us"), 123.12);
        assert_eq!(time_to_us("1.0 s"), 1_000_000.);
    }

    #[test]
    fn test_throughput_uom() {
        assert_eq!(throughput_to_uom("521.80 KiB/s"), "KiB/s");
        assert_eq!(throughput_to_uom("521.80 MiB/hr"), "MiB/hr");
    }

    #[test]
    fn test_parse_criterion_no_throughput() {
        let stdout = "Benchmarking merkletree/blake2s/128
Benchmarking merkletree/blake2s/128: Warming up for 3.0000 s
Benchmarking merkletree/blake2s/128: Collecting 20 samples in estimated 5.0192 s (39060 iterations)
Benchmarking merkletree/blake2s/128: Analyzing
merkletree/blake2s/128  time:   [141.11 us 151.42 us 159.66 us]
                    change: [-25.163% -21.490% -17.475%] (p = 0.00 < 0.05)
                    Performance has improved.
Found 4 outliers among 20 measurements (20.00%)
1 (5.00%) high mild
3 (15.00%) high severe
slope  [141.11 us 159.66 us] R^2            [0.8124914 0.8320154]
mean   [140.55 us 150.62 us] std. dev.      [5.6028 us 15.213 us]
median [138.33 us 143.23 us] med. abs. dev. [1.7507 ms 8.4109 ms]";

        let parsed = parse_criterion_out(stdout).unwrap();
        assert_eq!(
            parsed,
            vec![CriterionResult {
                name: "merkletree/blake2s/128".into(),
                samples: 20,
                time_med: Point {
                    unit: Some("us".to_string()),
                    value: 151.42,
                },
                time: Interval {
                    start: 141.11,
                    end: 159.66,
                    unit: Some("us".to_string())
                },
                throughput: None,
                throughput_med: None,
                slope: Some(Interval {
                    start: 141.11,
                    end: 159.66,
                    unit: Some("us".to_string())
                }),
                mean: Some(Interval {
                    start: 140.55,
                    end: 150.62,
                    unit: Some("us".to_string())
                }),
                median: Some(Interval {
                    start: 138.33,
                    end: 143.23,
                    unit: Some("us".to_string())
                }),
                r_2: Some(Interval {
                    start: 0.8124914,
                    end: 0.8320154,
                    unit: None
                }),
                std_dev: Some(Interval {
                    start: 5.6028,
                    end: 15.213,
                    unit: Some("us".to_string())
                }),
                med_abs_dev: Some(Interval {
                    start: 1750.7,
                    end: 8410.9,
                    unit: Some("us".to_string())
                }),
            }]
        );
    }

    #[test]
    fn test_parse_criterion_with_throughput() {
        let with_throughput = "Benchmarking merkletree/blake2s/128
Benchmarking merkletree/blake2s/128: Warming up for 3.0000 s
Benchmarking merkletree/blake2s/128: Collecting 20 samples in estimated 5.0192 s (39060 iterations)
Benchmarking merkletree/blake2s/128: Analyzing
merkletree/blake2s/128
                    time:   [141.11 us 151.42 us 159.66 us]
                    thrpt:  [68.055 MiB/s 68.172 MiB/s 68.644 MiB/s]
             change:
                    time:   [-25.163% -21.490% -17.475%] (p = 0.00 < 0.05)
                    thrpt:  [-25.163% -21.490% -17.475%] (p = 0.00 < 0.05)
                    Performance has improved.
Found 4 outliers among 20 measurements (20.00%)
1 (5.00%) high mild
3 (15.00%) high severe
slope  [141.11 us 159.66 us] R^2            [0.8124914 0.8320154]
mean   [140.55 us 150.62 us] std. dev.      [5.6028 us 15.213 us]
median [138.33 us 143.23 us] med. abs. dev. [1.7507 ms 8.4109 ms]";

        let parsed = parse_criterion_out(with_throughput).unwrap();
        assert_eq!(
            parsed,
            vec![CriterionResult {
                name: "merkletree/blake2s/128".into(),
                samples: 20,
                time_med: Point {
                    unit: Some("us".to_string()),
                    value: 151.42,
                },
                time: Interval {
                    start: 141.11,
                    end: 159.66,
                    unit: Some("us".to_string())
                },
                throughput: Some(Interval {
                    start: 68.055,
                    end: 68.644,
                    unit: Some("MiB/s".to_string())
                }),
                throughput_med: Some(Point {
                    value: 68.172,
                    unit: Some("MiB/s".to_string())
                }),
                slope: Some(Interval {
                    start: 141.11,
                    end: 159.66,
                    unit: Some("us".to_string())
                }),
                mean: Some(Interval {
                    start: 140.55,
                    end: 150.62,
                    unit: Some("us".to_string())
                }),
                median: Some(Interval {
                    start: 138.33,
                    end: 143.23,
                    unit: Some("us".to_string())
                }),
                r_2: Some(Interval {
                    start: 0.8124914,
                    end: 0.8320154,
                    unit: None
                }),
                std_dev: Some(Interval {
                    start: 5.6028,
                    end: 15.213,
                    unit: Some("us".to_string())
                }),
                med_abs_dev: Some(Interval {
                    start: 1750.7,
                    end: 8410.9,
                    unit: Some("us".to_string())
                }),
            }]
        );
    }
}

'''
'''--- fil-proofs-tooling/src/lib.rs ---
pub mod measure;
pub mod metadata;
pub mod shared;
pub use measure::{measure, FuncMeasurement};
pub use metadata::Metadata;
pub use shared::{create_replica, create_replicas};

'''
'''--- fil-proofs-tooling/src/measure.rs ---
use std::time::{Duration, Instant};

use anyhow::Result;
use cpu_time::ProcessTime;

pub struct FuncMeasurement<T> {
    pub cpu_time: Duration,
    pub wall_time: Duration,
    pub return_value: T,
}

pub fn measure<T, F>(f: F) -> Result<FuncMeasurement<T>>
where
    F: FnOnce() -> Result<T>,
{
    let cpu_time_start = ProcessTime::now();
    let wall_start_time = Instant::now();

    let x = f()?;

    Ok(FuncMeasurement {
        cpu_time: cpu_time_start.elapsed(),
        wall_time: wall_start_time.elapsed(),
        return_value: x,
    })
}

'''
'''--- fil-proofs-tooling/src/metadata.rs ---
use anyhow::{anyhow, Result};
use chrono::{DateTime, TimeZone, Utc};
use git2::Repository;
use serde::Serialize;

/// Captures metadata about the current setup.
#[derive(Debug, Serialize)]
#[serde(rename_all = "kebab-case")]
pub struct Metadata<T> {
    git: GitMetadata,
    system: SystemMetadata,
    benchmarks: T,
}

impl<T> Metadata<T> {
    pub fn wrap(benchmarks: T) -> Result<Self> {
        Ok(Metadata {
            git: GitMetadata::new()?,
            system: SystemMetadata::new()?,
            benchmarks,
        })
    }
}

/// Captures git specific metadata about the current repo.
#[derive(Debug, Serialize)]
#[serde(rename_all = "kebab-case")]
pub struct GitMetadata {
    hash: String,
    date: DateTime<Utc>,
}

impl GitMetadata {
    pub fn new() -> Result<Self> {
        let repo_path = if let Ok(mdir) = std::env::var("CARGO_MANIFEST_DIR") {
            std::path::Path::new(&mdir).into()
        } else {
            std::env::current_dir()?
        };
        let repo = Repository::discover(&repo_path)?;
        let head = repo.head()?;
        let commit = head.peel_to_commit()?;
        let date = Utc.timestamp(commit.time().seconds(), 0);

        Ok(GitMetadata {
            hash: commit.id().to_string(),
            date,
        })
    }
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "kebab-case")]
pub struct SystemMetadata {
    system: String,
    release: String,
    version: String,
    architecture: String,
    processor: String,
    processor_base_frequency_hz: u16,
    processor_max_frequency_hz: u16,
    processor_features: String,
    processor_cores_logical: u64,
    processor_cores_physical: u64,
    memory_total_bytes: u64,
}

impl SystemMetadata {
    pub fn new() -> Result<Self> {
        let host = futures::executor::block_on(heim::host::platform())
            .map_err(|_| anyhow!("Failed to retrieve host information"))?;

        let memory = futures::executor::block_on(heim::memory::memory())
            .map_err(|_| anyhow!("Failed to retrieve memory information"))?;
        let cpu_logical = futures::executor::block_on(heim::cpu::logical_count())
            .map_err(|_| anyhow!("Failed to retrieve cpu logical count information"))?;

        let cpu_physical = futures::executor::block_on(heim::cpu::physical_count())
            .map_err(|_| anyhow!("Failed to retrieve cpu physical count information"))?;

        let cpuid = raw_cpuid::CpuId::new();
        let processor = cpuid
            .get_extended_function_info()
            .and_then(|info| info.processor_brand_string().map(|s| s.to_string()))
            .unwrap_or_default();
        let (base, max) = cpuid
            .get_processor_frequency_info()
            .map(|info| {
                (
                    info.processor_base_frequency(),
                    info.processor_max_frequency(),
                )
            })
            .unwrap_or_default();

        Ok(SystemMetadata {
            system: host.system().into(),
            release: host.release().into(),
            version: host.version().into(),
            architecture: host.architecture().as_str().into(),
            processor,
            processor_base_frequency_hz: base,
            processor_max_frequency_hz: max,
            processor_features: cpuid
                .get_feature_info()
                .map(|info| format!("{:?}", info))
                .unwrap_or_default(),
            processor_cores_logical: cpu_logical,
            processor_cores_physical: cpu_physical.unwrap_or_default(),
            memory_total_bytes: memory.total().get::<uom::si::information::byte>(),
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_metadata() {
        let m = Metadata::wrap(()).unwrap();
        println!("{:#?}", m);

        assert!(m.system.memory_total_bytes > 0);
    }
}

'''
'''--- fil-proofs-tooling/src/shared.rs ---
use std::io::{BufWriter, Seek, SeekFrom, Write};

use log::info;
use rand::RngCore;
use rayon::prelude::*;
use tempfile::NamedTempFile;

use filecoin_proofs::constants::POREP_PARTITIONS;
use filecoin_proofs::types::{
    MerkleTreeTrait, PaddedBytesAmount, PoRepConfig, SectorSize, UnpaddedBytesAmount,
};
use filecoin_proofs::{
    add_piece, seal_pre_commit_phase1, seal_pre_commit_phase2, validate_cache_for_precommit_phase2,
    PieceInfo, PoRepProofPartitions, PrivateReplicaInfo, PublicReplicaInfo, SealPreCommitOutput,
};
use storage_proofs::sector::SectorId;

use crate::{measure, FuncMeasurement};

pub const PROVER_ID: [u8; 32] = [9; 32];
pub const RANDOMNESS: [u8; 32] = [44; 32];
pub const TICKET_BYTES: [u8; 32] = [1; 32];

pub struct PreCommitReplicaOutput<Tree: 'static + MerkleTreeTrait> {
    pub piece_info: Vec<PieceInfo>,
    pub private_replica_info: PrivateReplicaInfo<Tree>,
    pub public_replica_info: PublicReplicaInfo,
}

pub fn create_piece(piece_bytes: UnpaddedBytesAmount) -> NamedTempFile {
    info!("create_piece");
    let mut file = NamedTempFile::new().expect("failed to create piece file");
    {
        let mut writer = BufWriter::new(&mut file);
        let mut len = u64::from(piece_bytes) as usize;
        let chunk_size = 8 * 1024 * 1024;
        let mut buffer = vec![0u8; chunk_size];
        rand::thread_rng().fill_bytes(&mut buffer);

        while len > 0 {
            let to_write = std::cmp::min(len, chunk_size);
            writer
                .write_all(&buffer[..to_write])
                .expect("failed to write buffer");
            len -= to_write;
        }
    }
    assert_eq!(
        u64::from(piece_bytes),
        file.as_file().metadata().unwrap().len()
    );

    file.as_file_mut()
        .sync_all()
        .expect("failed to sync piece file");

    file.as_file_mut()
        .seek(SeekFrom::Start(0))
        .expect("failed to seek to beginning of piece file");

    file
}

/// Create a replica for a single sector
pub fn create_replica<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
) -> (SectorId, PreCommitReplicaOutput<Tree>) {
    let (_porep_config, result) = create_replicas::<Tree>(SectorSize(sector_size), 1, false);
    // Extract the sector ID and replica output out of the result
    result
        .unwrap()
        .0
        .pop()
        .expect("failed to create replica outputs")
}

#[allow(clippy::type_complexity)]
pub fn create_replicas<Tree: 'static + MerkleTreeTrait>(
    sector_size: SectorSize,
    qty_sectors: usize,
    only_add: bool,
) -> (
    PoRepConfig,
    Option<(
        Vec<(SectorId, PreCommitReplicaOutput<Tree>)>,
        FuncMeasurement<Vec<SealPreCommitOutput>>,
    )>,
) {
    info!("creating replicas: {:?} - {}", sector_size, qty_sectors);
    let sector_size_unpadded_bytes_ammount =
        UnpaddedBytesAmount::from(PaddedBytesAmount::from(sector_size));

    let porep_config = PoRepConfig {
        sector_size,
        partitions: PoRepProofPartitions(
            *POREP_PARTITIONS
                .read()
                .unwrap()
                .get(&u64::from(sector_size))
                .expect("unknown sector size"),
        ),
    };

    let mut out: Vec<(SectorId, PreCommitReplicaOutput<Tree>)> = Default::default();
    let mut sector_ids = Vec::new();
    let mut cache_dirs = Vec::new();
    let mut staged_files = Vec::new();
    let mut sealed_files = Vec::new();

    for i in 0..qty_sectors {
        info!("creating sector {}/{}", i, qty_sectors);

        sector_ids.push(SectorId::from(rand::random::<u64>()));
        cache_dirs.push(tempfile::tempdir().expect("failed to create cache dir"));

        let staged_file =
            NamedTempFile::new().expect("could not create temp file for staged sector");

        let sealed_file =
            NamedTempFile::new().expect("could not create temp file for sealed sector");
        // Prevent that the sealed sector file gets deleted when `sealed_file` runs out of scope
        let (_, sealed_path) = sealed_file
            .keep()
            .expect("failed to leep sealed sector file around");

        sealed_files.push(sealed_path);
        staged_files.push(staged_file);
    }

    let piece_files: Vec<_> = (0..qty_sectors)
        .into_par_iter()
        .map(|_i| {
            create_piece(UnpaddedBytesAmount::from(PaddedBytesAmount::from(
                sector_size,
            )))
        })
        .collect();

    info!("adding pieces");
    let mut piece_infos = Vec::new();
    for (i, (mut piece_file, mut staged_file)) in piece_files
        .into_iter()
        .zip(staged_files.iter_mut())
        .enumerate()
    {
        info!("add piece {}", i);
        let (info, _) = add_piece(
            &mut piece_file,
            &mut staged_file,
            sector_size_unpadded_bytes_ammount,
            &[],
        )
        .unwrap();
        piece_infos.push(vec![info]);
    }

    if only_add {
        return (porep_config, None);
    }

    let seal_pre_commit_outputs = measure(|| {
        let phase1s = cache_dirs
            .par_iter()
            .zip(staged_files.par_iter())
            .zip(sealed_files.par_iter())
            .zip(sector_ids.par_iter())
            .zip(piece_infos.par_iter())
            .map(
                |((((cache_dir, staged_file), sealed_file), sector_id), piece_infos)| {
                    seal_pre_commit_phase1(
                        porep_config,
                        cache_dir,
                        staged_file,
                        sealed_file,
                        PROVER_ID,
                        *sector_id,
                        TICKET_BYTES,
                        piece_infos,
                    )
                },
            )
            .collect::<Result<Vec<_>, _>>()?;

        phase1s
            .into_iter()
            .enumerate()
            .map(|(i, phase1)| {
                validate_cache_for_precommit_phase2::<_, _, Tree>(
                    &cache_dirs[i],
                    &sealed_files[i],
                    &phase1,
                )?;
                seal_pre_commit_phase2(porep_config, phase1, &cache_dirs[i], &sealed_files[i])
            })
            .collect::<Result<Vec<_>, _>>()
    })
    .expect("seal_pre_commit produced an error");

    info!("collecting infos");

    let priv_infos = sealed_files
        .iter()
        .zip(seal_pre_commit_outputs.return_value.iter())
        .zip(cache_dirs.into_iter())
        .map(|((sealed_file, seal_pre_commit_output), cache_dir)| {
            PrivateReplicaInfo::new(
                sealed_file.to_path_buf(),
                seal_pre_commit_output.comm_r,
                cache_dir.into_path(),
            )
            .expect("failed to create PrivateReplicaInfo")
        })
        .collect::<Vec<_>>();

    let pub_infos = seal_pre_commit_outputs
        .return_value
        .iter()
        .map(|sp| PublicReplicaInfo::new(sp.comm_r).expect("failed to create PublicReplicaInfo"))
        .collect::<Vec<_>>();

    for (((sector_id, piece_info), priv_info), pub_info) in sector_ids
        .into_iter()
        .zip(piece_infos.into_iter())
        .zip(priv_infos.into_iter())
        .zip(pub_infos.into_iter())
    {
        out.push((
            sector_id,
            PreCommitReplicaOutput {
                piece_info,
                private_replica_info: priv_info,
                public_replica_info: pub_info,
            },
        ));
    }

    (porep_config, Some((out, seal_pre_commit_outputs)))
}

'''
'''--- filecoin-proofs/Cargo.toml ---
[package]
name = "filecoin-proofs"
description = "The Filecoin specific aspects of storage-proofs, including a C based FFI, to generate and verify proofs."
version = "2.0.0"
authors = ["dignifiedquire <dignifiedquire@gmail.com>", "laser <l@s3r.com>", "porcuquine <porcuquine@users.noreply.github.com>"]
license = "MIT OR Apache-2.0"
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[dependencies]
storage-proofs = { version = "2.0.0", path = "../storage-proofs" }
bitvec = "0.17"
chrono = "0.4"
rand = "0.7"
lazy_static = "1.2"
memmap = "0.7"
colored = "1.6"
pbr = "1.0"
byteorder = "1"
itertools = "0.9"
serde_cbor = "0.10.2"
serde = { version = "1.0", features = ["rc", "derive"] }
serde_json = "1.0"
regex = "=1.3.7"
ff = { version = "0.2.1", package = "fff" }
blake2b_simd = "0.5"
bellperson = "0.8.0"
paired = "0.19.0"
fil-sapling-crypto = "0.6.0"
clap = "2"
log = "0.4.7"
fil_logger = "0.1"
env_proxy = "0.3"
os_type = "2.2.0"
flate2 = { version = "1.0.9", features = ["rust_backend"]}
tar = "0.4.26"
rayon = "1.1.0"
blake2s_simd = "0.5.8"
hex = "0.4.0"
tee = "0.1.0"
os_pipe = "0.9.1"
merkletree = "0.20.0"
bincode = "1.1.2"
anyhow = "1.0.23"
rand_xorshift = "0.2.0"
typenum = "1.11.2"
bitintr = "0.3.0"
gperftools = { version = "0.2", optional = true }
phase2 = { package = "phase21", version = "0.6.0" }
simplelog = "0.7.4"
rand_chacha = "0.2.1"
dialoguer = "0.6.2"
generic-array = "0.13.2"
structopt = "0.3.12"
humansize = "1.1.0"
indicatif = "0.14.0"

[dependencies.reqwest]
version = "0.9"
default-features = false
features = ["default-tls-vendored"]

[dev-dependencies]
criterion = "0.3"
rexpect = "0.3.0"
pretty_assertions = "0.6.1"
failure = "0.1.7"
tempfile = "3"

[features]
default = ["gpu"]
cpu-profile = ["gperftools"]
heap-profile = ["gperftools/heap"]
simd = ["storage-proofs/simd"]
asm = ["storage-proofs/asm"]
gpu = ["storage-proofs/gpu", "bellperson/gpu", "fil-sapling-crypto/gpu"]

[[bench]]
name = "preprocessing"
harness = false

'''
'''--- filecoin-proofs/README.md ---
# Filecoin Proofs

> The Filecoin specific aspects of `storage-proofs`, including a C based FFI, to generate and verify proofs.

## License

MIT or Apache 2.0

'''
'''--- filecoin-proofs/benches/preprocessing.rs ---
use std::io::{self, Read};
use std::time::Duration;

use criterion::{criterion_group, criterion_main, Criterion, ParameterizedBenchmark, Throughput};
use filecoin_proofs::fr32_reader::Fr32Reader;
use rand::{thread_rng, Rng};

#[cfg(feature = "cpu-profile")]
#[inline(always)]
fn start_profile(stage: &str) {
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .start(format!("./{}.profile", stage))
        .unwrap();
}

#[cfg(not(feature = "cpu-profile"))]
#[inline(always)]
fn start_profile(_stage: &str) {}

#[cfg(feature = "cpu-profile")]
#[inline(always)]
fn stop_profile() {
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .stop()
        .unwrap();
}

#[cfg(not(feature = "cpu-profile"))]
#[inline(always)]
fn stop_profile() {}

fn random_data(size: usize) -> Vec<u8> {
    let mut rng = thread_rng();
    (0..size).map(|_| rng.gen()).collect()
}

fn preprocessing_benchmark(c: &mut Criterion) {
    c.bench(
        "preprocessing",
        ParameterizedBenchmark::new(
            "write_padded",
            |b, size| {
                let data = random_data(*size);
                let mut buf = Vec::with_capacity(*size);

                start_profile(&format!("write_padded_{}", *size));
                b.iter(|| {
                    let mut reader = Fr32Reader::new(io::Cursor::new(&data));
                    reader.read_to_end(&mut buf).unwrap();
                    assert!(buf.len() >= data.len());
                });
                stop_profile();
            },
            vec![128, 256, 512, 256_000, 512_000, 1024_000, 2048_000],
        )
        .sample_size(10)
        .throughput(|s| Throughput::Bytes(*s as u64))
        .warm_up_time(Duration::from_secs(1)),
    );
}

criterion_group!(benches, preprocessing_benchmark);
criterion_main!(benches);

'''
'''--- filecoin-proofs/parameters.json ---
{
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-0170db1f394b35d995252228ee359194b13199d259380541dc529fb0099096b0.params": {
    "cid": "QmYkygifkXnrnsN4MJsjBFHTQJHx294CyikDgDK8nYxdGh",
    "digest": "df3f30442a6d6b4192f5071fb17e820c",
    "sector_size": 2048
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-0170db1f394b35d995252228ee359194b13199d259380541dc529fb0099096b0.vk": {
    "cid": "QmdXyqbmy2bkJA9Kyhh6z25GrTCq48LwX6c1mxPsm54wi7",
    "digest": "0bea3951abf9557a3569f68e52a30c6c",
    "sector_size": 2048
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-0cfb4f178bbb71cf2ecfcd42accce558b27199ab4fb59cb78f2483fe21ef36d9.params": {
    "cid": "Qmf5XZZtP5VcYTf65MbKjLVabcS6cYMbr2rFShmfJzh5e5",
    "digest": "655e6277638edc8c658094f6f0b33d54",
    "sector_size": 536870912
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-0cfb4f178bbb71cf2ecfcd42accce558b27199ab4fb59cb78f2483fe21ef36d9.vk": {
    "cid": "QmPuhdWnAXBks43emnkqi9FQzyU1gASKyz23zrD27BPGs8",
    "digest": "57690e3a6a94c3f704802a674b34f36b",
    "sector_size": 536870912
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-3ea05428c9d11689f23529cde32fd30aabd50f7d2c93657c1d3650bca3e8ea9e.params": {
    "cid": "QmPNVgTN7N5vDtD5u7ERMTLcvUtrKRBfYVUDr6uW3pKhX7",
    "digest": "3d390654f58e603b896ac70c653f5676",
    "sector_size": 2048
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-3ea05428c9d11689f23529cde32fd30aabd50f7d2c93657c1d3650bca3e8ea9e.vk": {
    "cid": "Qmbj61Zez7v5xA7nSCnmWbyLYznWJDWeusz7Yg8EcgVdoN",
    "digest": "8c170a164743c39576a7f47a1b51e6f3",
    "sector_size": 2048
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-50c7368dea9593ed0989e70974d28024efa9d156d585b7eea1be22b2e753f331.params": {
    "cid": "QmRApb8RZoBK3cqicT7V3ydXg8yVvqPFMPrQNXP33aBihp",
    "digest": "b1b58ff9a297b82885e8a7dfb035f83c",
    "sector_size": 8388608
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-50c7368dea9593ed0989e70974d28024efa9d156d585b7eea1be22b2e753f331.vk": {
    "cid": "QmcytF1dTdqMFoyXi931j1RgmGtLfR9LLLaBznRt1tPQyD",
    "digest": "1a09e00c641f192f55af3433a028f050",
    "sector_size": 8388608
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-5294475db5237a2e83c3e52fd6c2b03859a1831d45ed08c4f35dbf9a803165a9.params": {
    "cid": "QmPvr54tWaVeP4WnekivzUAJitTqsQfvikBvAHNEaDNQSw",
    "digest": "9380e41368ed4083dbc922b290d3b786",
    "sector_size": 8388608
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-5294475db5237a2e83c3e52fd6c2b03859a1831d45ed08c4f35dbf9a803165a9.vk": {
    "cid": "QmXyVLVDRCcxA9SjT7PeK8HFtyxZ2ZH3SHa8KoGLw8VGJt",
    "digest": "f0731a7e20f90704bd38fc5d27882f6d",
    "sector_size": 8388608
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-7d739b8cf60f1b0709eeebee7730e297683552e4b69cab6984ec0285663c5781.params": {
    "cid": "Qmf5f6ko3dqj7qauzXpZqxM9B2x2sL977K6gE2ppNwuJPv",
    "digest": "273ebb8c896326b7c292bee8b775fd38",
    "sector_size": 536870912
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-0-0-7d739b8cf60f1b0709eeebee7730e297683552e4b69cab6984ec0285663c5781.vk": {
    "cid": "QmfP3MQe8koW63n5MkDENENVHxib78MJYYyZvbneCsuze8",
    "digest": "3dd94da9da64e51b3445bc528d84e76d",
    "sector_size": 536870912
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-0-0377ded656c6f524f1618760bffe4e0a1c51d5a70c4509eedae8a27555733edc.params": {
    "cid": "QmYEeeCE8uT2bsVkxcqqUYeMmMEbe6rfmo8wQCv7jFHqqm",
    "digest": "c947f2021304ed43b7216f7a8436e294",
    "sector_size": 34359738368
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-0-0377ded656c6f524f1618760bffe4e0a1c51d5a70c4509eedae8a27555733edc.vk": {
    "cid": "QmXB63ExriFjB4ywWnXTnFwCcLFfCeEP3h15qtL5i7F4aX",
    "digest": "ab20d7b253e7e9a0d2ccdf7599ec8ec3",
    "sector_size": 34359738368
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-0-559e581f022bb4e4ec6e719e563bf0e026ad6de42e56c18714a2c692b1b88d7e.params": {
    "cid": "QmW5Yxg3L1NSzuQVcRMHMbG3uvVoi4dTLzVaDpnEUPQpnA",
    "digest": "079ba19645828ae42b22b0e3f4866e8d",
    "sector_size": 34359738368
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-0-559e581f022bb4e4ec6e719e563bf0e026ad6de42e56c18714a2c692b1b88d7e.vk": {
    "cid": "QmQzZ5dJ11tcSBees38WX41tZLXS9BqpEti253m5QcnTNs",
    "digest": "c76125a50a7de315165de359b5174ae4",
    "sector_size": 34359738368
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-2-2627e4006b67f99cef990c0a47d5426cb7ab0a0ad58fc1061547bf2d28b09def.params": {
    "cid": "QmNk3wga1tS53FUu1QnkK8ehWA2cqpCnSEAPv3KLxdJxNa",
    "digest": "421e4790c0b80e0107a7ff67acf14084",
    "sector_size": 68719476736
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-2-2627e4006b67f99cef990c0a47d5426cb7ab0a0ad58fc1061547bf2d28b09def.vk": {
    "cid": "QmVQCHGsrUtbn9RjHs1e6GXfeXDW5m9w4ge48PSX3Z2as2",
    "digest": "8b60e9cc1470a6729c687d6cf0a1f79c",
    "sector_size": 68719476736
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-2-b62098629d07946e9028127e70295ed996fe3ed25b0f9f88eb610a0ab4385a3c.params": {
    "cid": "QmTL3VvydaMFWKvE5VzxjgKsJYgL9JMM4JVYNtQxdj9JK1",
    "digest": "2685f31124b22ea6b2857e5a5e87ffa3",
    "sector_size": 68719476736
  },
  "v26-proof-of-spacetime-fallback-merkletree-poseidon_hasher-8-8-2-b62098629d07946e9028127e70295ed996fe3ed25b0f9f88eb610a0ab4385a3c.vk": {
    "cid": "QmSVWbLqQYbUbbJyfsRMzEib2rfSqMtnPks1Nw22omcBQm",
    "digest": "efe703cd2839597c7ca5c2a906b74296",
    "sector_size": 68719476736
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-032d3138d22506ec0082ed72b2dcba18df18477904e35bafee82b3793b06832f.params": {
    "cid": "QmU9dH31nZZUJnsogR4Ld4ySUcH6wm2RgmGiujwnqtbU6k",
    "digest": "fcef8e87ae2afd7a28aae44347b804cf",
    "sector_size": 2048
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-032d3138d22506ec0082ed72b2dcba18df18477904e35bafee82b3793b06832f.vk": {
    "cid": "QmdJ15DMGPooye5NaPcRfXUdHUDibcN7hKjbmTGuu1K4AQ",
    "digest": "2ee2b3518229680db15161d4f582af37",
    "sector_size": 2048
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-6babf46ce344ae495d558e7770a585b2382d54f225af8ed0397b8be7c3fcd472.params": {
    "cid": "QmZgtxcY3tMXXQxZTA7ZTUDXLVUnfxNcerXgeW4gG2NnfP",
    "digest": "3273c7135cb75684248b475781b738ee",
    "sector_size": 536870912
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-6babf46ce344ae495d558e7770a585b2382d54f225af8ed0397b8be7c3fcd472.vk": {
    "cid": "QmSS6ZkAV2aGZcgKgdPpEEgihXF1ryZX8PSAZDWSoeL1d4",
    "digest": "1519b5f61d9044a59f2bdc57537c094b",
    "sector_size": 536870912
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-ecd683648512ab1765faa2a5f14bab48f676e633467f0aa8aad4b55dcb0652bb.params": {
    "cid": "QmQBGXeiNn6hVwbR6qFarQqiNGDdKk4h9ucfyvcXyfYz2N",
    "digest": "7d5f896f435c38e93bcda6dd168d860b",
    "sector_size": 8388608
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-0-0-sha256_hasher-ecd683648512ab1765faa2a5f14bab48f676e633467f0aa8aad4b55dcb0652bb.vk": {
    "cid": "QmPrZgBVGMckEAeu5eSJnLmiAwcPQjKjZe5ir6VaQ5AxKs",
    "digest": "fe6d2de44580a0db5a4934688899b92f",
    "sector_size": 8388608
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-8-0-sha256_hasher-82a357d2f2ca81dc61bb45f4a762807aedee1b0a53fd6c4e77b46a01bfef7820.params": {
    "cid": "QmZL2cq45XJn5BFzagAZwgFmLrcM1W6CXoiEF9C5j5tjEF",
    "digest": "acdfed9f0512bc85a01a9fb871d475d5",
    "sector_size": 34359738368
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-8-0-sha256_hasher-82a357d2f2ca81dc61bb45f4a762807aedee1b0a53fd6c4e77b46a01bfef7820.vk": {
    "cid": "QmQ4zB7nNa1tDYNifBkExRnZtwtxZw775iaqvVsZyRi6Q2",
    "digest": "524a2f3e9d6826593caebc41bb545c40",
    "sector_size": 34359738368
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-8-2-sha256_hasher-96f1b4a04c5c51e4759bbf224bbc2ef5a42c7100f16ec0637123f16a845ddfb2.params": {
    "cid": "QmY7DitNKXFeLQt9QoVQkfjM1EvRnprqUVxjmkTXkHDNka",
    "digest": "f27271c0537ba65ade2ec045f8fbd069",
    "sector_size": 68719476736
  },
  "v26-stacked-proof-of-replication-merkletree-poseidon_hasher-8-8-2-sha256_hasher-96f1b4a04c5c51e4759bbf224bbc2ef5a42c7100f16ec0637123f16a845ddfb2.vk": {
    "cid": "QmUJsvoCuQ4LszPmeRVAkMYb5qY95ctz3UXKhu8xLzyFKo",
    "digest": "576b292938c6c9d0a0e721bd867a543b",
    "sector_size": 68719476736
  }
}
'''
'''--- filecoin-proofs/src/api/mod.rs ---
use std::fs::File;
use std::io::{BufWriter, Read, Write};
use std::path::{Path, PathBuf};

use anyhow::{ensure, Context, Result};
use bincode::deserialize;
use merkletree::store::{DiskStore, LevelCacheStore, StoreConfig};
use storage_proofs::cache_key::CacheKey;
use storage_proofs::hasher::Hasher;
use storage_proofs::measurements::{measure_op, Operation};
use storage_proofs::merkle::get_base_tree_count;
use storage_proofs::porep::stacked::{
    generate_replica_id, PersistentAux, StackedDrg, TemporaryAux,
};
use storage_proofs::porep::PoRep;
use storage_proofs::sector::SectorId;
use typenum::Unsigned;

use crate::api::util::{as_safe_commitment, get_base_tree_leafs, get_base_tree_size};
use crate::commitment_reader::CommitmentReader;
use crate::constants::{
    DefaultBinaryTree, DefaultOctTree, DefaultPieceDomain, DefaultPieceHasher,
    MINIMUM_RESERVED_BYTES_FOR_PIECE_IN_FULLY_ALIGNED_SECTOR as MINIMUM_PIECE_SIZE,
};
use crate::fr32::write_unpadded;
use crate::parameters::public_params;
use crate::types::{
    Commitment, MerkleTreeTrait, PaddedBytesAmount, PieceInfo, PoRepConfig, PoRepProofPartitions,
    ProverId, SealPreCommitPhase1Output, Ticket, UnpaddedByteIndex, UnpaddedBytesAmount,
};

mod post;
mod seal;
pub(crate) mod util;

pub use self::post::*;
pub use self::seal::*;

use storage_proofs::pieces::generate_piece_commitment_bytes_from_source;

/// Unseals the sector at `sealed_path` and returns the bytes for a piece
/// whose first (unpadded) byte begins at `offset` and ends at `offset` plus
/// `num_bytes`, inclusive. Note that the entire sector is unsealed each time
/// this function is called.
///
/// # Arguments
///
/// * `porep_config` - porep configuration containing the sector size.
/// * `cache_path` - path to the directory in which the sector data's Merkle Tree is written.
/// * `sealed_path` - path to the sealed sector file that we will unseal and read a byte range.
/// * `output_path` - path to a file that we will write the requested byte range to.
/// * `prover_id` - the prover-id that sealed the sector.
/// * `sector_id` - the sector-id of the sealed sector.
/// * `comm_d` - the commitment to the sector's data.
/// * `ticket` - the ticket that was used to generate the sector's replica-id.
/// * `offset` - the byte index in the unsealed sector of the first byte that we want to read.
/// * `num_bytes` - the number of bytes that we want to read.
#[allow(clippy::too_many_arguments)]
pub fn get_unsealed_range<T: Into<PathBuf> + AsRef<Path>, Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    cache_path: T,
    sealed_path: T,
    output_path: T,
    prover_id: ProverId,
    sector_id: SectorId,
    comm_d: Commitment,
    ticket: Ticket,
    offset: UnpaddedByteIndex,
    num_bytes: UnpaddedBytesAmount,
) -> Result<UnpaddedBytesAmount> {
    let f_in = File::open(&sealed_path)
        .with_context(|| format!("could not open sealed_path={:?}", sealed_path.as_ref()))?;

    let f_out = File::create(&output_path)
        .with_context(|| format!("could not create output_path={:?}", output_path.as_ref()))?;

    let buf_f_out = BufWriter::new(f_out);

    unseal_range::<_, _, _, Tree>(
        porep_config,
        cache_path,
        f_in,
        buf_f_out,
        prover_id,
        sector_id,
        comm_d,
        ticket,
        offset,
        num_bytes,
    )
}

/// Unseals the sector read from `sealed_sector` and returns the bytes for a
/// piece whose first (unpadded) byte begins at `offset` and ends at `offset`
/// plus `num_bytes`, inclusive. Note that the entire sector is unsealed each
/// time this function is called.
///
/// # Arguments
///
/// * `porep_config` - porep configuration containing the sector size.
/// * `cache_path` - path to the directory in which the sector data's Merkle Tree is written.
/// * `sealed_sector` - a byte source from which we read sealed sector data.
/// * `unsealed_output` - a byte sink to which we write unsealed, un-bit-padded sector bytes.
/// * `prover_id` - the prover-id that sealed the sector.
/// * `sector_id` - the sector-id of the sealed sector.
/// * `comm_d` - the commitment to the sector's data.
/// * `ticket` - the ticket that was used to generate the sector's replica-id.
/// * `offset` - the byte index in the unsealed sector of the first byte that we want to read.
/// * `num_bytes` - the number of bytes that we want to read.
#[allow(clippy::too_many_arguments)]
pub fn unseal_range<P, R, W, Tree>(
    porep_config: PoRepConfig,
    cache_path: P,
    mut sealed_sector: R,
    mut unsealed_output: W,
    prover_id: ProverId,
    sector_id: SectorId,
    comm_d: Commitment,
    ticket: Ticket,
    offset: UnpaddedByteIndex,
    num_bytes: UnpaddedBytesAmount,
) -> Result<UnpaddedBytesAmount>
where
    P: Into<PathBuf> + AsRef<Path>,
    R: Read,
    W: Write,
    Tree: 'static + MerkleTreeTrait,
{
    ensure!(comm_d != [0; 32], "Invalid all zero commitment (comm_d)");

    let comm_d =
        as_safe_commitment::<<DefaultPieceHasher as Hasher>::Domain, _>(&comm_d, "comm_d")?;

    let replica_id =
        generate_replica_id::<Tree::Hasher, _>(&prover_id, sector_id.into(), &ticket, comm_d);

    let mut data = Vec::new();
    sealed_sector.read_to_end(&mut data)?;

    let base_tree_size = get_base_tree_size::<DefaultBinaryTree>(porep_config.sector_size)?;
    let base_tree_leafs = get_base_tree_leafs::<DefaultBinaryTree>(base_tree_size)?;
    // MT for original data is always named tree-d, and it will be
    // referenced later in the process as such.
    let config = StoreConfig::new(
        cache_path.as_ref(),
        CacheKey::CommDTree.to_string(),
        StoreConfig::default_rows_to_discard(
            base_tree_leafs,
            <DefaultBinaryTree as MerkleTreeTrait>::Arity::to_usize(),
        ),
    );
    let pp = public_params(
        PaddedBytesAmount::from(porep_config),
        usize::from(PoRepProofPartitions::from(porep_config)),
    )?;

    let offset_padded: PaddedBytesAmount = UnpaddedBytesAmount::from(offset).into();
    let num_bytes_padded: PaddedBytesAmount = num_bytes.into();

    let unsealed_all =
        StackedDrg::<Tree, DefaultPieceHasher>::extract_all(&pp, &replica_id, &data, Some(config))?;
    let start: usize = offset_padded.into();
    let end = start + usize::from(num_bytes_padded);
    let unsealed = &unsealed_all[start..end];

    // If the call to `extract_range` was successful, the `unsealed` vector must
    // have a length which equals `num_bytes_padded`. The byte at its 0-index
    // byte will be the the byte at index `offset_padded` in the sealed sector.
    let written = write_unpadded(unsealed, &mut unsealed_output, 0, num_bytes.into())
        .context("write_unpadded failed")?;

    Ok(UnpaddedBytesAmount(written as u64))
}

/// Generates a piece commitment for the provided byte source. Returns an error
/// if the byte source produced more than `piece_size` bytes.
///
/// # Arguments
///
/// * `source` - a readable source of unprocessed piece bytes. The piece's commitment will be
/// generated for the bytes read from the source plus any added padding.
/// * `piece_size` - the number of unpadded user-bytes which can be read from source before EOF.
pub fn generate_piece_commitment<T: std::io::Read>(
    source: T,
    piece_size: UnpaddedBytesAmount,
) -> Result<PieceInfo> {
    measure_op(Operation::GeneratePieceCommitment, || {
        ensure_piece_size(piece_size)?;

        // send the source through the preprocessor
        let source = std::io::BufReader::new(source);
        let mut fr32_reader = crate::fr32_reader::Fr32Reader::new(source);

        let commitment = generate_piece_commitment_bytes_from_source::<DefaultPieceHasher>(
            &mut fr32_reader,
            PaddedBytesAmount::from(piece_size).into(),
        )?;

        PieceInfo::new(commitment, piece_size)
    })
}

/// Computes a NUL-byte prefix and/or suffix for `source` using the provided
/// `piece_lengths` and `piece_size` (such that the `source`, after
/// preprocessing, will occupy a subtree of a merkle tree built using the bytes
/// from `target`), runs the resultant byte stream through the preprocessor,
/// and writes the result to `target`. Returns a tuple containing the number of
/// bytes written to `target` (`source` plus alignment) and the commitment.
///
/// WARNING: Depending on the ordering and size of the pieces in
/// `piece_lengths`, this function could write a prefix of NUL bytes which
/// wastes ($SIZESECTORSIZE/2)-$MINIMUM_PIECE_SIZE space. This function will be
/// deprecated in favor of `write_and_preprocess`, and miners will be prevented
/// from sealing sectors containing more than $TOOMUCH alignment bytes.
///
/// # Arguments
///
/// * `source` - a readable source of unprocessed piece bytes.
/// * `target` - a writer where we will write the processed piece bytes.
/// * `piece_size` - the number of unpadded user-bytes which can be read from source before EOF.
/// * `piece_lengths` - the number of bytes for each previous piece in the sector.
pub fn add_piece<R, W>(
    source: R,
    target: W,
    piece_size: UnpaddedBytesAmount,
    piece_lengths: &[UnpaddedBytesAmount],
) -> Result<(PieceInfo, UnpaddedBytesAmount)>
where
    R: Read,
    W: Write,
{
    measure_op(Operation::AddPiece, || {
        ensure_piece_size(piece_size)?;

        let source = std::io::BufReader::new(source);
        let mut target = std::io::BufWriter::new(target);

        let written_bytes = crate::pieces::sum_piece_bytes_with_alignment(&piece_lengths);
        let piece_alignment = crate::pieces::get_piece_alignment(written_bytes, piece_size);
        let fr32_reader = crate::fr32_reader::Fr32Reader::new(source);

        // write left alignment
        for _ in 0..usize::from(PaddedBytesAmount::from(piece_alignment.left_bytes)) {
            target.write_all(&[0u8][..])?;
        }

        let mut commitment_reader = CommitmentReader::new(fr32_reader);
        let n = std::io::copy(&mut commitment_reader, &mut target)
            .context("failed to write and preprocess bytes")?;

        ensure!(n != 0, "add_piece: read 0 bytes before EOF from source");
        let n = PaddedBytesAmount(n as u64);
        let n: UnpaddedBytesAmount = n.into();

        ensure!(n == piece_size, "add_piece: invalid bytes amount written");

        // write right alignment
        for _ in 0..usize::from(PaddedBytesAmount::from(piece_alignment.right_bytes)) {
            target.write_all(&[0u8][..])?;
        }

        let commitment = commitment_reader.finish()?;
        let mut comm = [0u8; 32];
        comm.copy_from_slice(commitment.as_ref());

        let written = piece_alignment.left_bytes + piece_alignment.right_bytes + piece_size;

        Ok((PieceInfo::new(comm, n)?, written))
    })
}

fn ensure_piece_size(piece_size: UnpaddedBytesAmount) -> Result<()> {
    ensure!(
        piece_size >= UnpaddedBytesAmount(MINIMUM_PIECE_SIZE),
        "Piece must be at least {} bytes",
        MINIMUM_PIECE_SIZE
    );

    let padded_piece_size: PaddedBytesAmount = piece_size.into();
    ensure!(
        u64::from(padded_piece_size).is_power_of_two(),
        "Bit-padded piece size must be a power of 2 ({:?})",
        padded_piece_size,
    );

    Ok(())
}

/// Writes bytes from `source` to `target`, adding bit-padding ("preprocessing")
/// as needed. Returns a tuple containing the number of bytes written to
/// `target` and the commitment.
///
/// WARNING: This function neither prepends nor appends alignment bytes to the
/// `target`; it is the caller's responsibility to ensure properly sized
/// and ordered writes to `target` such that `source`-bytes occupy whole
/// subtrees of the final merkle tree built over `target`.
///
/// # Arguments
///
/// * `source` - a readable source of unprocessed piece bytes.
/// * `target` - a writer where we will write the processed piece bytes.
/// * `piece_size` - the number of unpadded user-bytes which can be read from source before EOF.
pub fn write_and_preprocess<R, W>(
    source: R,
    target: W,
    piece_size: UnpaddedBytesAmount,
) -> Result<(PieceInfo, UnpaddedBytesAmount)>
where
    R: Read,
    W: Write,
{
    add_piece(source, target, piece_size, Default::default())
}

// Verifies if a DiskStore specified by a config (or set of 'required_configs' is consistent).
fn verify_store(config: &StoreConfig, arity: usize, required_configs: usize) -> Result<()> {
    let store_path = StoreConfig::data_path(&config.path, &config.id);
    if !Path::new(&store_path).exists() {
        // Configs may have split due to sector size, so we need to
        // check deterministic paths from here.
        let orig_path = store_path.clone().into_os_string().into_string().unwrap();
        let mut configs: Vec<StoreConfig> = Vec::with_capacity(required_configs);
        for i in 0..required_configs {
            let cur_path = orig_path
                .clone()
                .replace(".dat", format!("-{}.dat", i).as_str());

            if Path::new(&cur_path).exists() {
                let path_str = cur_path.as_str();
                let tree_names = vec!["tree-d", "tree-c", "tree-r-last"];
                for name in tree_names {
                    if path_str.find(name).is_some() {
                        configs.push(StoreConfig::from_config(
                            config,
                            format!("{}-{}", name, i),
                            None,
                        ));
                        break;
                    }
                }
            }
        }

        ensure!(
            configs.len() == required_configs,
            "Missing store file (or associated split paths): {}",
            store_path.display()
        );

        let store_len = config.size.unwrap();
        for config in &configs {
            ensure!(
                DiskStore::<DefaultPieceDomain>::is_consistent(store_len, arity, &config,)?,
                "Store is inconsistent: {:?}",
                StoreConfig::data_path(&config.path, &config.id)
            );
        }
    } else {
        ensure!(
            DiskStore::<DefaultPieceDomain>::is_consistent(config.size.unwrap(), arity, &config,)?,
            "Store is inconsistent: {:?}",
            store_path
        );
    }

    Ok(())
}

// Verifies if a LevelCacheStore specified by a config is consistent.
fn verify_level_cache_store<Tree: MerkleTreeTrait>(config: &StoreConfig) -> Result<()> {
    let store_path = StoreConfig::data_path(&config.path, &config.id);
    if !Path::new(&store_path).exists() {
        let required_configs = get_base_tree_count::<Tree>();

        // Configs may have split due to sector size, so we need to
        // check deterministic paths from here.
        let orig_path = store_path.clone().into_os_string().into_string().unwrap();
        let mut configs: Vec<StoreConfig> = Vec::with_capacity(required_configs);
        for i in 0..required_configs {
            let cur_path = orig_path
                .clone()
                .replace(".dat", format!("-{}.dat", i).as_str());

            if Path::new(&cur_path).exists() {
                let path_str = cur_path.as_str();
                let tree_names = vec!["tree-d", "tree-c", "tree-r-last"];
                for name in tree_names {
                    if path_str.find(name).is_some() {
                        configs.push(StoreConfig::from_config(
                            config,
                            format!("{}-{}", name, i),
                            None,
                        ));
                        break;
                    }
                }
            }
        }

        ensure!(
            configs.len() == required_configs,
            "Missing store file (or associated split paths): {}",
            store_path.display()
        );

        let store_len = config.size.unwrap();
        for config in &configs {
            ensure!(
                LevelCacheStore::<DefaultPieceDomain, std::fs::File>::is_consistent(
                    store_len,
                    Tree::Arity::to_usize(),
                    &config,
                )?,
                "Store is inconsistent: {:?}",
                StoreConfig::data_path(&config.path, &config.id)
            );
        }
    } else {
        ensure!(
            LevelCacheStore::<DefaultPieceDomain, std::fs::File>::is_consistent(
                config.size.unwrap(),
                Tree::Arity::to_usize(),
                &config,
            )?,
            "Store is inconsistent: {:?}",
            store_path
        );
    }

    Ok(())
}

// Checks for the existence of the tree d store, the replica, and all generated labels.
pub fn validate_cache_for_precommit_phase2<R, T, Tree: MerkleTreeTrait>(
    cache_path: R,
    replica_path: T,
    seal_precommit_phase1_output: &SealPreCommitPhase1Output<Tree>,
) -> Result<()>
where
    R: AsRef<Path>,
    T: AsRef<Path>,
{
    ensure!(
        replica_path.as_ref().exists(),
        "Missing replica: {}",
        replica_path.as_ref().to_path_buf().display()
    );

    // Verify all stores/labels within the Labels object, but
    // respecting the current cache_path.
    let cache = cache_path.as_ref().to_path_buf();
    seal_precommit_phase1_output
        .labels
        .verify_stores(verify_store, &cache)?;

    // Update the previous phase store path to the current cache_path.
    let mut config = StoreConfig::from_config(
        &seal_precommit_phase1_output.config,
        &seal_precommit_phase1_output.config.id,
        seal_precommit_phase1_output.config.size,
    );
    config.path = cache_path.as_ref().into();

    verify_store(
        &config,
        <DefaultBinaryTree as MerkleTreeTrait>::Arity::to_usize(),
        get_base_tree_count::<Tree>(),
    )
}

// Checks for the existence of the replica data and t_aux, which in
// turn allows us to verify the tree d, tree r, tree c, and the
// labels.
pub fn validate_cache_for_commit<R, T, Tree: MerkleTreeTrait>(
    cache_path: R,
    replica_path: T,
) -> Result<()>
where
    R: AsRef<Path>,
    T: AsRef<Path>,
{
    // Verify that the replica exists and is not empty.
    ensure!(
        replica_path.as_ref().exists(),
        "Missing replica: {}",
        replica_path.as_ref().to_path_buf().display()
    );

    let metadata = File::open(&replica_path)?.metadata()?;
    ensure!(
        metadata.len() > 0,
        "Replica {} exists, but is empty!",
        replica_path.as_ref().to_path_buf().display()
    );

    let cache = &cache_path.as_ref();

    // Make sure p_aux exists and is valid.
    let p_aux_path = cache.join(CacheKey::PAux.to_string());
    let p_aux_bytes = std::fs::read(&p_aux_path)
        .with_context(|| format!("could not read file p_aux={:?}", p_aux_path))?;

    let _: PersistentAux<<Tree::Hasher as Hasher>::Domain> = deserialize(&p_aux_bytes)?;
    drop(p_aux_bytes);

    // Make sure t_aux exists and is valid.
    let t_aux = {
        let t_aux_path = cache.join(CacheKey::TAux.to_string());
        let t_aux_bytes = std::fs::read(&t_aux_path)
            .with_context(|| format!("could not read file t_aux={:?}", t_aux_path))?;

        let mut res: TemporaryAux<Tree, DefaultPieceHasher> = deserialize(&t_aux_bytes)?;

        // Switch t_aux to the passed in cache_path
        res.set_cache_path(&cache_path);
        res
    };

    // Verify all stores/labels within the Labels object.
    let cache = cache_path.as_ref().to_path_buf();
    t_aux.labels.verify_stores(verify_store, &cache)?;

    // Verify each tree disk store.
    verify_store(
        &t_aux.tree_d_config,
        <DefaultBinaryTree as MerkleTreeTrait>::Arity::to_usize(),
        get_base_tree_count::<Tree>(),
    )?;
    verify_store(
        &t_aux.tree_c_config,
        <DefaultOctTree as MerkleTreeTrait>::Arity::to_usize(),
        get_base_tree_count::<Tree>(),
    )?;
    verify_level_cache_store::<DefaultOctTree>(&t_aux.tree_r_last_config)?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use paired::bls12_381::Fr;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs::fr32::bytes_into_fr;

    use crate::constants::*;
    use crate::types::SectorSize;

    #[test]
    fn test_verify_seal_fr32_validation() {
        let convertible_to_fr_bytes = [0; 32];
        let out = bytes_into_fr(&convertible_to_fr_bytes);
        assert!(out.is_ok(), "tripwire");

        let not_convertible_to_fr_bytes = [255; 32];
        let out = bytes_into_fr(&not_convertible_to_fr_bytes);
        assert!(out.is_err(), "tripwire");

        {
            let result = verify_seal::<DefaultOctLCTree>(
                PoRepConfig {
                    sector_size: SectorSize(SECTOR_SIZE_2_KIB),
                    partitions: PoRepProofPartitions(
                        *POREP_PARTITIONS
                            .read()
                            .unwrap()
                            .get(&SECTOR_SIZE_2_KIB)
                            .unwrap(),
                    ),
                },
                not_convertible_to_fr_bytes,
                convertible_to_fr_bytes,
                [0; 32],
                SectorId::from(0),
                [0; 32],
                [0; 32],
                &[],
            );

            if let Err(err) = result {
                let needle = "Invalid all zero commitment";
                let haystack = format!("{}", err);

                assert!(
                    haystack.contains(needle),
                    format!("\"{}\" did not contain \"{}\"", haystack, needle)
                );
            } else {
                panic!("should have failed comm_r to Fr32 conversion");
            }
        }

        {
            let result = verify_seal::<DefaultOctLCTree>(
                PoRepConfig {
                    sector_size: SectorSize(SECTOR_SIZE_2_KIB),
                    partitions: PoRepProofPartitions(
                        *POREP_PARTITIONS
                            .read()
                            .unwrap()
                            .get(&SECTOR_SIZE_2_KIB)
                            .unwrap(),
                    ),
                },
                convertible_to_fr_bytes,
                not_convertible_to_fr_bytes,
                [0; 32],
                SectorId::from(0),
                [0; 32],
                [0; 32],
                &[],
            );

            if let Err(err) = result {
                let needle = "Invalid all zero commitment";
                let haystack = format!("{}", err);

                assert!(
                    haystack.contains(needle),
                    format!("\"{}\" did not contain \"{}\"", haystack, needle)
                );
            } else {
                panic!("should have failed comm_d to Fr32 conversion");
            }
        }
    }

    #[test]
    fn test_random_domain_element() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..100 {
            let random_el: DefaultTreeDomain = Fr::random(rng).into();
            let mut randomness = [0u8; 32];
            randomness.copy_from_slice(AsRef::<[u8]>::as_ref(&random_el));
            let back: DefaultTreeDomain = as_safe_commitment(&randomness, "test").unwrap();
            assert_eq!(back, random_el);
        }
    }
}

'''
'''--- filecoin-proofs/src/api/post.rs ---
use std::collections::BTreeMap;
use std::hash::{Hash, Hasher as StdHasher};
use std::marker::PhantomData;
use std::path::{Path, PathBuf};

use anyhow::{ensure, Context, Result};
use bincode::deserialize;
use generic_array::typenum::Unsigned;
use log::{info, trace};
use merkletree::store::StoreConfig;
use storage_proofs::cache_key::CacheKey;
use storage_proofs::compound_proof::{self, CompoundProof};
use storage_proofs::hasher::{Domain, Hasher};
use storage_proofs::merkle::{
    create_tree, get_base_tree_count, split_config_and_replica, MerkleTreeTrait, MerkleTreeWrapper,
};
use storage_proofs::multi_proof::MultiProof;
use storage_proofs::post::fallback;
use storage_proofs::sector::*;

use crate::api::util::{as_safe_commitment, get_base_tree_leafs, get_base_tree_size};
use crate::caches::{get_post_params, get_post_verifying_key};
use crate::constants::*;
use crate::parameters::{window_post_setup_params, winning_post_setup_params};
use crate::types::{
    ChallengeSeed, Commitment, PersistentAux, PoStConfig, ProverId, SectorSize, TemporaryAux,
};
use crate::PoStType;

/// The minimal information required about a replica, in order to be able to generate
/// a PoSt over it.
#[derive(Debug)]
pub struct PrivateReplicaInfo<Tree: MerkleTreeTrait> {
    /// Path to the replica.
    replica: PathBuf,
    /// The replica commitment.
    comm_r: Commitment,
    /// Persistent Aux.
    aux: PersistentAux<<Tree::Hasher as Hasher>::Domain>,
    /// Contains sector-specific (e.g. merkle trees) assets
    cache_dir: PathBuf,

    _t: PhantomData<Tree>,
}

impl<Tree: MerkleTreeTrait> Clone for PrivateReplicaInfo<Tree> {
    fn clone(&self) -> Self {
        Self {
            replica: self.replica.clone(),
            comm_r: self.comm_r,
            aux: self.aux.clone(),
            cache_dir: self.cache_dir.clone(),
            _t: Default::default(),
        }
    }
}

impl<Tree: MerkleTreeTrait> std::cmp::PartialEq for PrivateReplicaInfo<Tree> {
    fn eq(&self, other: &Self) -> bool {
        self.replica == other.replica
            && self.comm_r == other.comm_r
            && self.aux == other.aux
            && self.cache_dir == other.cache_dir
    }
}

impl<Tree: MerkleTreeTrait> Hash for PrivateReplicaInfo<Tree> {
    fn hash<H: StdHasher>(&self, state: &mut H) {
        self.replica.hash(state);
        self.comm_r.hash(state);
        self.aux.hash(state);
        self.cache_dir.hash(state);
    }
}

impl<Tree: MerkleTreeTrait> std::cmp::Eq for PrivateReplicaInfo<Tree> {}

impl<Tree: MerkleTreeTrait> std::cmp::Ord for PrivateReplicaInfo<Tree> {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.comm_r.as_ref().cmp(other.comm_r.as_ref())
    }
}

impl<Tree: MerkleTreeTrait> std::cmp::PartialOrd for PrivateReplicaInfo<Tree> {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        self.comm_r.as_ref().partial_cmp(other.comm_r.as_ref())
    }
}

impl<Tree: 'static + MerkleTreeTrait> PrivateReplicaInfo<Tree> {
    pub fn new(replica: PathBuf, comm_r: Commitment, cache_dir: PathBuf) -> Result<Self> {
        ensure!(comm_r != [0; 32], "Invalid all zero commitment (comm_r)");

        let aux = {
            let f_aux_path = cache_dir.join(CacheKey::PAux.to_string());
            let aux_bytes = std::fs::read(&f_aux_path)
                .with_context(|| format!("could not read from path={:?}", f_aux_path))?;

            deserialize(&aux_bytes)
        }?;

        ensure!(replica.exists(), "Sealed replica does not exist");

        Ok(PrivateReplicaInfo {
            replica,
            comm_r,
            aux,
            cache_dir,
            _t: Default::default(),
        })
    }

    pub fn cache_dir_path(&self) -> &Path {
        self.cache_dir.as_path()
    }

    pub fn replica_path(&self) -> &Path {
        self.replica.as_path()
    }

    pub fn safe_comm_r(&self) -> Result<<Tree::Hasher as Hasher>::Domain> {
        as_safe_commitment(&self.comm_r, "comm_r")
    }

    pub fn safe_comm_c(&self) -> Result<<Tree::Hasher as Hasher>::Domain> {
        Ok(self.aux.comm_c)
    }

    pub fn safe_comm_r_last(&self) -> Result<<Tree::Hasher as Hasher>::Domain> {
        Ok(self.aux.comm_r_last)
    }

    /// Generate the merkle tree of this particular replica.
    pub fn merkle_tree(
        &self,
        sector_size: SectorSize,
    ) -> Result<
        MerkleTreeWrapper<
            Tree::Hasher,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >,
    > {
        let base_tree_size = get_base_tree_size::<Tree>(sector_size)?;
        let base_tree_leafs = get_base_tree_leafs::<Tree>(base_tree_size)?;
        trace!(
            "post: base tree size {}, base tree leafs {}, rows_to_discard {}, arities [{}, {}, {}]",
            base_tree_size,
            base_tree_leafs,
            StoreConfig::default_rows_to_discard(base_tree_leafs, Tree::Arity::to_usize()),
            Tree::Arity::to_usize(),
            Tree::SubTreeArity::to_usize(),
            Tree::TopTreeArity::to_usize(),
        );

        let mut config = StoreConfig::new(
            self.cache_dir_path(),
            CacheKey::CommRLastTree.to_string(),
            StoreConfig::default_rows_to_discard(base_tree_leafs, Tree::Arity::to_usize()),
        );
        config.size = Some(base_tree_size);

        let tree_count = get_base_tree_count::<Tree>();
        let (configs, replica_config) = split_config_and_replica(
            config,
            self.replica_path().to_path_buf(),
            base_tree_leafs,
            tree_count,
        )?;

        create_tree::<Tree>(base_tree_size, &configs, Some(&replica_config))
    }
}

/// The minimal information required about a replica, in order to be able to verify
/// a PoSt over it.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct PublicReplicaInfo {
    /// The replica commitment.
    comm_r: Commitment,
}

impl std::cmp::Ord for PublicReplicaInfo {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.comm_r.as_ref().cmp(other.comm_r.as_ref())
    }
}

impl std::cmp::PartialOrd for PublicReplicaInfo {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl PublicReplicaInfo {
    pub fn new(comm_r: Commitment) -> Result<Self> {
        ensure!(comm_r != [0; 32], "Invalid all zero commitment (comm_r)");
        Ok(PublicReplicaInfo { comm_r })
    }

    pub fn safe_comm_r<T: Domain>(&self) -> Result<T> {
        as_safe_commitment(&self.comm_r, "comm_r")
    }
}

// Ensure that any associated cached data persisted is discarded.
pub fn clear_cache<Tree: MerkleTreeTrait>(cache_dir: &Path) -> Result<()> {
    let t_aux = {
        let f_aux_path = cache_dir.to_path_buf().join(CacheKey::TAux.to_string());
        let aux_bytes = std::fs::read(&f_aux_path)
            .with_context(|| format!("could not read from path={:?}", f_aux_path))?;

        deserialize(&aux_bytes)
    }?;

    TemporaryAux::<Tree, DefaultPieceHasher>::clear_temp(t_aux)
}

// Ensure that any associated cached data persisted is discarded.
pub fn clear_caches<Tree: MerkleTreeTrait>(
    replicas: &BTreeMap<SectorId, PrivateReplicaInfo<Tree>>,
) -> Result<()> {
    for replica in replicas.values() {
        clear_cache::<Tree>(&replica.cache_dir.as_path())?;
    }

    Ok(())
}

pub type SnarkProof = Vec<u8>;

/// Generates a Winning proof-of-spacetime.
pub fn generate_winning_post<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
    randomness: &ChallengeSeed,
    replicas: &[(SectorId, PrivateReplicaInfo<Tree>)],
    prover_id: ProverId,
) -> Result<SnarkProof> {
    info!("generate_winning_post:start");
    ensure!(
        post_config.typ == PoStType::Winning,
        "invalid post config type"
    );

    ensure!(
        replicas.len() == post_config.sector_count,
        "invalid amount of replicas"
    );

    let randomness_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(randomness, "randomness")?;
    let prover_id_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(&prover_id, "prover_id")?;

    let vanilla_params = winning_post_setup_params(&post_config)?;
    let param_sector_count = vanilla_params.sector_count;

    let setup_params = compound_proof::SetupParams {
        vanilla_params,
        partitions: None,
        priority: post_config.priority,
    };
    let pub_params: compound_proof::PublicParams<fallback::FallbackPoSt<Tree>> =
        fallback::FallbackPoStCompound::setup(&setup_params)?;
    let groth_params = get_post_params::<Tree>(&post_config)?;

    let trees = replicas
        .iter()
        .map(|(_, replica)| replica.merkle_tree(post_config.sector_size))
        .collect::<Result<Vec<_>>>()?;

    let mut pub_sectors = Vec::with_capacity(param_sector_count);
    let mut priv_sectors = Vec::with_capacity(param_sector_count);

    for _ in 0..param_sector_count {
        for ((id, replica), tree) in replicas.iter().zip(trees.iter()) {
            let comm_r = replica.safe_comm_r()?;
            let comm_c = replica.safe_comm_c()?;
            let comm_r_last = replica.safe_comm_r_last()?;

            pub_sectors.push(fallback::PublicSector::<<Tree::Hasher as Hasher>::Domain> {
                id: *id,
                comm_r,
            });
            priv_sectors.push(fallback::PrivateSector {
                tree,
                comm_c,
                comm_r_last,
            });
        }
    }

    let pub_inputs = fallback::PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
        randomness: randomness_safe,
        prover_id: prover_id_safe,
        sectors: &pub_sectors,
        k: None,
    };

    let priv_inputs = fallback::PrivateInputs::<Tree> {
        sectors: &priv_sectors,
    };

    let proof = fallback::FallbackPoStCompound::<Tree>::prove(
        &pub_params,
        &pub_inputs,
        &priv_inputs,
        &groth_params,
    )?;
    let proof = proof.to_vec()?;

    info!("generate_winning_post:finish");

    Ok(proof)
}

/// Given some randomness and a the length of available sectors, generates the challenged sector.
///
/// The returned values are indicies in the range of `0..sector_set_size`, requiring the caller
/// to match the index to the correct sector.
pub fn generate_winning_post_sector_challenge<Tree: MerkleTreeTrait>(
    post_config: &PoStConfig,
    randomness: &ChallengeSeed,
    sector_set_size: u64,
    prover_id: Commitment,
) -> Result<Vec<u64>> {
    ensure!(sector_set_size != 0, "empty sector set is invalid");
    ensure!(
        post_config.typ == PoStType::Winning,
        "invalid post config type"
    );

    let prover_id_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(&prover_id, "prover_id")?;

    let randomness_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(randomness, "randomness")?;
    fallback::generate_sector_challenges(
        randomness_safe,
        post_config.sector_count,
        sector_set_size,
        prover_id_safe,
    )
}

/// Verifies a winning proof-of-spacetime.
///
/// The provided `replicas` must be the same ones as passed to `generate_winning_post`, and be based on
/// the indices generated by `generate_winning_post_sector_challenge`. It is the responsibility of the
/// caller to ensure this.
pub fn verify_winning_post<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
    randomness: &ChallengeSeed,
    replicas: &[(SectorId, PublicReplicaInfo)],
    prover_id: ProverId,
    proof: &[u8],
) -> Result<bool> {
    info!("verify_winning_post:start");

    ensure!(
        post_config.typ == PoStType::Winning,
        "invalid post config type"
    );
    ensure!(
        post_config.sector_count == replicas.len(),
        "invalid amount of replicas provided"
    );

    let randomness_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(randomness, "randomness")?;
    let prover_id_safe: <Tree::Hasher as Hasher>::Domain =
        as_safe_commitment(&prover_id, "prover_id")?;

    let vanilla_params = winning_post_setup_params(&post_config)?;
    let param_sector_count = vanilla_params.sector_count;

    let setup_params = compound_proof::SetupParams {
        vanilla_params,
        partitions: None,
        priority: false,
    };
    let pub_params: compound_proof::PublicParams<fallback::FallbackPoSt<Tree>> =
        fallback::FallbackPoStCompound::setup(&setup_params)?;

    let verifying_key = get_post_verifying_key::<Tree>(&post_config)?;

    let proof = MultiProof::new_from_reader(None, &proof[..], &verifying_key)?;
    if proof.len() != 1 {
        return Ok(false);
    }

    let mut pub_sectors = Vec::with_capacity(param_sector_count);
    for _ in 0..param_sector_count {
        for (id, replica) in replicas.iter() {
            let comm_r = replica.safe_comm_r()?;
            pub_sectors.push(fallback::PublicSector { id: *id, comm_r });
        }
    }

    let pub_inputs = fallback::PublicInputs {
        randomness: randomness_safe,
        prover_id: prover_id_safe,
        sectors: &pub_sectors,
        k: None,
    };

    let is_valid = fallback::FallbackPoStCompound::verify(
        &pub_params,
        &pub_inputs,
        &proof,
        &fallback::ChallengeRequirements {
            minimum_challenge_count: post_config.challenge_count * post_config.sector_count,
        },
    )?;

    if !is_valid {
        return Ok(false);
    }

    info!("verify_winning_post:finish");

    Ok(true)
}

/// Generates a Window proof-of-spacetime.
pub fn generate_window_post<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
    randomness: &ChallengeSeed,
    replicas: &BTreeMap<SectorId, PrivateReplicaInfo<Tree>>,
    prover_id: ProverId,
) -> Result<SnarkProof> {
    info!("generate_window_post:start");
    ensure!(
        post_config.typ == PoStType::Window,
        "invalid post config type"
    );

    let randomness_safe = as_safe_commitment(randomness, "randomness")?;
    let prover_id_safe = as_safe_commitment(&prover_id, "prover_id")?;

    let vanilla_params = window_post_setup_params(&post_config);
    let partitions = get_partitions_for_window_post(replicas.len(), &post_config);

    let sector_count = vanilla_params.sector_count;
    let setup_params = compound_proof::SetupParams {
        vanilla_params,
        partitions,
        priority: post_config.priority,
    };

    let pub_params: compound_proof::PublicParams<fallback::FallbackPoSt<Tree>> =
        fallback::FallbackPoStCompound::setup(&setup_params)?;
    let groth_params = get_post_params::<Tree>(&post_config)?;

    let trees: Vec<_> = replicas
        .iter()
        .map(|(_id, replica)| replica.merkle_tree(post_config.sector_size))
        .collect::<Result<_>>()?;

    let mut pub_sectors = Vec::with_capacity(sector_count);
    let mut priv_sectors = Vec::with_capacity(sector_count);

    for ((sector_id, replica), tree) in replicas.iter().zip(trees.iter()) {
        let comm_r = replica.safe_comm_r()?;
        let comm_c = replica.safe_comm_c()?;
        let comm_r_last = replica.safe_comm_r_last()?;

        pub_sectors.push(fallback::PublicSector {
            id: *sector_id,
            comm_r,
        });
        priv_sectors.push(fallback::PrivateSector {
            tree,
            comm_c,
            comm_r_last,
        });
    }

    let pub_inputs = fallback::PublicInputs {
        randomness: randomness_safe,
        prover_id: prover_id_safe,
        sectors: &pub_sectors,
        k: None,
    };

    let priv_inputs = fallback::PrivateInputs::<Tree> {
        sectors: &priv_sectors,
    };

    let proof = fallback::FallbackPoStCompound::prove(
        &pub_params,
        &pub_inputs,
        &priv_inputs,
        &groth_params,
    )?;

    info!("generate_window_post:finish");

    Ok(proof.to_vec()?)
}

/// Verifies a window proof-of-spacetime.
pub fn verify_window_post<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
    randomness: &ChallengeSeed,
    replicas: &BTreeMap<SectorId, PublicReplicaInfo>,
    prover_id: ProverId,
    proof: &[u8],
) -> Result<bool> {
    info!("verify_window_post:start");

    ensure!(
        post_config.typ == PoStType::Window,
        "invalid post config type"
    );

    let randomness_safe = as_safe_commitment(randomness, "randomness")?;
    let prover_id_safe = as_safe_commitment(&prover_id, "prover_id")?;

    let vanilla_params = window_post_setup_params(&post_config);
    let partitions = get_partitions_for_window_post(replicas.len(), &post_config);

    let setup_params = compound_proof::SetupParams {
        vanilla_params,
        partitions,
        priority: false,
    };
    let pub_params: compound_proof::PublicParams<fallback::FallbackPoSt<Tree>> =
        fallback::FallbackPoStCompound::setup(&setup_params)?;

    let verifying_key = get_post_verifying_key::<Tree>(&post_config)?;

    let proof = MultiProof::new_from_reader(partitions, &proof[..], &verifying_key)?;

    let pub_sectors: Vec<_> = replicas
        .iter()
        .map(|(sector_id, replica)| {
            let comm_r = replica.safe_comm_r()?;
            Ok(fallback::PublicSector {
                id: *sector_id,
                comm_r,
            })
        })
        .collect::<Result<_>>()?;

    let pub_inputs = fallback::PublicInputs {
        randomness: randomness_safe,
        prover_id: prover_id_safe,
        sectors: &pub_sectors,
        k: None,
    };

    let is_valid = fallback::FallbackPoStCompound::verify(
        &pub_params,
        &pub_inputs,
        &proof,
        &fallback::ChallengeRequirements {
            minimum_challenge_count: post_config.challenge_count * post_config.sector_count,
        },
    )?;

    if !is_valid {
        return Ok(false);
    }

    info!("verify_window_post:finish");

    Ok(true)
}

fn get_partitions_for_window_post(
    total_sector_count: usize,
    post_config: &PoStConfig,
) -> Option<usize> {
    let partitions = (total_sector_count as f32 / post_config.sector_count as f32).ceil() as usize;

    if partitions > 1 {
        Some(partitions)
    } else {
        None
    }
}

'''
'''--- filecoin-proofs/src/api/seal.rs ---
use std::fs::{self, File, OpenOptions};
use std::io::prelude::*;
use std::path::{Path, PathBuf};

use anyhow::{ensure, Context, Result};
use bincode::{deserialize, serialize};
use log::{info, trace};
use memmap::MmapOptions;
use merkletree::store::{DiskStore, Store, StoreConfig};
use paired::bls12_381::Fr;
use storage_proofs::cache_key::CacheKey;
use storage_proofs::compound_proof::{self, CompoundProof};
use storage_proofs::drgraph::Graph;
use storage_proofs::hasher::{Domain, Hasher};
use storage_proofs::measurements::{measure_op, Operation::CommD};
use storage_proofs::merkle::{create_base_merkle_tree, BinaryMerkleTree, MerkleTreeTrait};
use storage_proofs::multi_proof::MultiProof;
use storage_proofs::porep::stacked::{
    self, generate_replica_id, ChallengeRequirements, StackedCompound, StackedDrg, Tau,
    TemporaryAux, TemporaryAuxCache,
};
use storage_proofs::proof::ProofScheme;
use storage_proofs::sector::SectorId;

use crate::api::util::{
    as_safe_commitment, commitment_from_fr, get_base_tree_leafs, get_base_tree_size,
};
use crate::caches::{get_stacked_params, get_stacked_verifying_key};
use crate::constants::{
    DefaultBinaryTree, DefaultPieceDomain, DefaultPieceHasher, POREP_MINIMUM_CHALLENGES,
    SINGLE_PARTITION_PROOF_LEN,
};
use crate::parameters::setup_params;
pub use crate::pieces;
pub use crate::pieces::verify_pieces;
use crate::types::{
    Commitment, PaddedBytesAmount, PieceInfo, PoRepConfig, PoRepProofPartitions, ProverId,
    SealCommitOutput, SealCommitPhase1Output, SealPreCommitOutput, SealPreCommitPhase1Output,
    SectorSize, Ticket, BINARY_ARITY,
};

#[allow(clippy::too_many_arguments)]
pub fn seal_pre_commit_phase1<R, S, T, Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    cache_path: R,
    in_path: S,
    out_path: T,
    prover_id: ProverId,
    sector_id: SectorId,
    ticket: Ticket,
    piece_infos: &[PieceInfo],
) -> Result<SealPreCommitPhase1Output<Tree>>
where
    R: AsRef<Path>,
    S: AsRef<Path>,
    T: AsRef<Path>,
{
    info!("seal_pre_commit_phase1: start");

    let sector_bytes = usize::from(PaddedBytesAmount::from(porep_config));
    fs::metadata(&in_path)
        .with_context(|| format!("could not read in_path={:?})", in_path.as_ref().display()))?;

    fs::metadata(&out_path)
        .with_context(|| format!("could not read out_path={:?}", out_path.as_ref().display()))?;

    // Copy unsealed data to output location, where it will be sealed in place.
    fs::copy(&in_path, &out_path).with_context(|| {
        format!(
            "could not copy in_path={:?} to out_path={:?}",
            in_path.as_ref().display(),
            out_path.as_ref().display()
        )
    })?;

    let f_data = OpenOptions::new()
        .read(true)
        .write(true)
        .open(&out_path)
        .with_context(|| format!("could not open out_path={:?}", out_path.as_ref().display()))?;

    // Zero-pad the data to the requested size by extending the underlying file if needed.
    f_data.set_len(sector_bytes as u64)?;

    let data = unsafe {
        MmapOptions::new()
            .map_mut(&f_data)
            .with_context(|| format!("could not mmap out_path={:?}", out_path.as_ref().display()))?
    };

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
        StackedDrg<Tree, DefaultPieceHasher>,
        _,
    >>::setup(&compound_setup_params)?;

    info!("building merkle tree for the original data");
    let (config, comm_d) = measure_op(CommD, || -> Result<_> {
        let base_tree_size = get_base_tree_size::<DefaultBinaryTree>(porep_config.sector_size)?;
        let base_tree_leafs = get_base_tree_leafs::<DefaultBinaryTree>(base_tree_size)?;
        ensure!(
            compound_public_params.vanilla_params.graph.size() == base_tree_leafs,
            "graph size and leaf size don't match"
        );

        trace!(
            "seal phase 1: sector_size {}, base tree size {}, base tree leafs {}, cached above base {}",
            u64::from(porep_config.sector_size),
            base_tree_size,
            base_tree_leafs,
            StoreConfig::default_rows_to_discard(base_tree_leafs, BINARY_ARITY)
        );

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let mut config = StoreConfig::new(
            cache_path.as_ref(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(base_tree_leafs, BINARY_ARITY),
        );
        let data_tree = create_base_merkle_tree::<BinaryMerkleTree<DefaultPieceHasher>>(
            Some(config.clone()),
            base_tree_leafs,
            &data,
        )?;
        drop(data);

        config.size = Some(data_tree.len());
        let comm_d_root: Fr = data_tree.root().into();
        let comm_d = commitment_from_fr(comm_d_root);

        drop(data_tree);

        Ok((config, comm_d))
    })?;

    info!("verifying pieces");

    ensure!(
        verify_pieces(&comm_d, piece_infos, porep_config.into())?,
        "pieces and comm_d do not match"
    );

    let replica_id =
        generate_replica_id::<Tree::Hasher, _>(&prover_id, sector_id.into(), &ticket, comm_d);

    let labels = StackedDrg::<Tree, DefaultPieceHasher>::replicate_phase1(
        &compound_public_params.vanilla_params,
        &replica_id,
        config.clone(),
    )?;

    Ok(SealPreCommitPhase1Output {
        labels,
        config,
        comm_d,
    })
}

#[allow(clippy::too_many_arguments)]
pub fn seal_pre_commit_phase2<R, S, Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    phase1_output: SealPreCommitPhase1Output<Tree>,
    cache_path: S,
    replica_path: R,
) -> Result<SealPreCommitOutput>
where
    R: AsRef<Path>,
    S: AsRef<Path>,
{
    info!("seal_pre_commit_phase2: start");

    let SealPreCommitPhase1Output {
        mut labels,
        mut config,
        comm_d,
        ..
    } = phase1_output;

    labels.update_root(cache_path.as_ref());
    config.path = cache_path.as_ref().into();

    let f_data = OpenOptions::new()
        .read(true)
        .write(true)
        .open(&replica_path)
        .with_context(|| {
            format!(
                "could not open replica_path={:?}",
                replica_path.as_ref().display()
            )
        })?;
    let data = unsafe {
        MmapOptions::new().map_mut(&f_data).with_context(|| {
            format!(
                "could not mmap replica_path={:?}",
                replica_path.as_ref().display()
            )
        })?
    };
    let data: storage_proofs::Data<'_> = (data, PathBuf::from(replica_path.as_ref())).into();

    // Load data tree from disk
    let data_tree = {
        let base_tree_size = get_base_tree_size::<DefaultBinaryTree>(porep_config.sector_size)?;
        let base_tree_leafs = get_base_tree_leafs::<DefaultBinaryTree>(base_tree_size)?;

        trace!(
            "seal phase 2: base tree size {}, base tree leafs {}, cached above base {}",
            base_tree_size,
            base_tree_leafs,
            StoreConfig::default_rows_to_discard(base_tree_leafs, BINARY_ARITY)
        );
        ensure!(
            config.rows_to_discard
                == StoreConfig::default_rows_to_discard(base_tree_leafs, BINARY_ARITY),
            "Invalid cache size specified"
        );

        let store: DiskStore<DefaultPieceDomain> =
            DiskStore::new_from_disk(base_tree_size, BINARY_ARITY, &config)?;
        BinaryMerkleTree::<DefaultPieceHasher>::from_data_store(store, base_tree_leafs)?
    };

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
        StackedDrg<Tree, DefaultPieceHasher>,
        _,
    >>::setup(&compound_setup_params)?;

    let (tau, (p_aux, t_aux)) = StackedDrg::<Tree, DefaultPieceHasher>::replicate_phase2(
        &compound_public_params.vanilla_params,
        labels,
        data,
        data_tree,
        config,
        replica_path.as_ref().to_path_buf(),
    )?;

    let comm_r = commitment_from_fr(tau.comm_r.into());

    // Persist p_aux and t_aux here
    let p_aux_path = cache_path.as_ref().join(CacheKey::PAux.to_string());
    let mut f_p_aux = File::create(&p_aux_path)
        .with_context(|| format!("could not create file p_aux={:?}", p_aux_path))?;
    let p_aux_bytes = serialize(&p_aux)?;
    f_p_aux
        .write_all(&p_aux_bytes)
        .with_context(|| format!("could not write to file p_aux={:?}", p_aux_path))?;

    let t_aux_path = cache_path.as_ref().join(CacheKey::TAux.to_string());
    let mut f_t_aux = File::create(&t_aux_path)
        .with_context(|| format!("could not create file t_aux={:?}", t_aux_path))?;
    let t_aux_bytes = serialize(&t_aux)?;
    f_t_aux
        .write_all(&t_aux_bytes)
        .with_context(|| format!("could not write to file t_aux={:?}", t_aux_path))?;

    Ok(SealPreCommitOutput { comm_r, comm_d })
}

#[allow(clippy::too_many_arguments)]
pub fn seal_commit_phase1<T: AsRef<Path>, Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    cache_path: T,
    replica_path: T,
    prover_id: ProverId,
    sector_id: SectorId,
    ticket: Ticket,
    seed: Ticket,
    pre_commit: SealPreCommitOutput,
    piece_infos: &[PieceInfo],
) -> Result<SealCommitPhase1Output<Tree>> {
    info!("seal_commit_phase1:start");

    let SealPreCommitOutput { comm_d, comm_r } = pre_commit;

    ensure!(comm_d != [0; 32], "Invalid all zero commitment (comm_d)");
    ensure!(comm_r != [0; 32], "Invalid all zero commitment (comm_r)");
    ensure!(
        verify_pieces(&comm_d, piece_infos, porep_config.into())?,
        "pieces and comm_d do not match"
    );

    let p_aux = {
        let p_aux_path = cache_path.as_ref().join(CacheKey::PAux.to_string());
        let p_aux_bytes = std::fs::read(&p_aux_path)
            .with_context(|| format!("could not read file p_aux={:?}", p_aux_path))?;

        deserialize(&p_aux_bytes)
    }?;

    let t_aux = {
        let t_aux_path = cache_path.as_ref().join(CacheKey::TAux.to_string());
        let t_aux_bytes = std::fs::read(&t_aux_path)
            .with_context(|| format!("could not read file t_aux={:?}", t_aux_path))?;

        let mut res: TemporaryAux<_, _> = deserialize(&t_aux_bytes)?;

        // Switch t_aux to the passed in cache_path
        res.set_cache_path(cache_path);
        res
    };

    // Convert TemporaryAux to TemporaryAuxCache, which instantiates all
    // elements based on the configs stored in TemporaryAux.
    let t_aux_cache: TemporaryAuxCache<Tree, DefaultPieceHasher> =
        TemporaryAuxCache::new(&t_aux, replica_path.as_ref().to_path_buf())
            .context("failed to restore contents of t_aux")?;

    let comm_r_safe = as_safe_commitment(&comm_r, "comm_r")?;
    let comm_d_safe = DefaultPieceDomain::try_from_bytes(&comm_d)?;

    let replica_id =
        generate_replica_id::<Tree::Hasher, _>(&prover_id, sector_id.into(), &ticket, comm_d_safe);

    let public_inputs = stacked::PublicInputs {
        replica_id,
        tau: Some(stacked::Tau {
            comm_d: comm_d_safe,
            comm_r: comm_r_safe,
        }),
        k: None,
        seed,
    };

    let private_inputs = stacked::PrivateInputs::<Tree, DefaultPieceHasher> {
        p_aux,
        t_aux: t_aux_cache,
    };

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
        StackedDrg<Tree, DefaultPieceHasher>,
        _,
    >>::setup(&compound_setup_params)?;

    let vanilla_proofs = StackedDrg::prove_all_partitions(
        &compound_public_params.vanilla_params,
        &public_inputs,
        &private_inputs,
        StackedCompound::partition_count(&compound_public_params),
    )?;

    let sanity_check = StackedDrg::<Tree, DefaultPieceHasher>::verify_all_partitions(
        &compound_public_params.vanilla_params,
        &public_inputs,
        &vanilla_proofs,
    )?;
    ensure!(sanity_check, "Invalid vanilla proof generated");

    info!("seal_commit_phase1:end");

    Ok(SealCommitPhase1Output {
        vanilla_proofs,
        comm_r,
        comm_d,
        replica_id,
        seed,
        ticket,
    })
}

#[allow(clippy::too_many_arguments)]
pub fn seal_commit_phase2<Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    phase1_output: SealCommitPhase1Output<Tree>,
    prover_id: ProverId,
    sector_id: SectorId,
) -> Result<SealCommitOutput> {
    info!("seal_commit_phase2:start");

    let SealCommitPhase1Output {
        vanilla_proofs,
        comm_d,
        comm_r,
        replica_id,
        seed,
        ticket,
    } = phase1_output;

    ensure!(comm_d != [0; 32], "Invalid all zero commitment (comm_d)");
    ensure!(comm_r != [0; 32], "Invalid all zero commitment (comm_r)");

    let comm_r_safe = as_safe_commitment(&comm_r, "comm_r")?;
    let comm_d_safe = DefaultPieceDomain::try_from_bytes(&comm_d)?;

    let public_inputs = stacked::PublicInputs {
        replica_id,
        tau: Some(stacked::Tau {
            comm_d: comm_d_safe,
            comm_r: comm_r_safe,
        }),
        k: None,
        seed,
    };

    let groth_params = get_stacked_params::<Tree>(porep_config)?;

    info!(
        "got groth params ({}) while sealing",
        u64::from(PaddedBytesAmount::from(porep_config))
    );

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
        StackedDrg<Tree, DefaultPieceHasher>,
        _,
    >>::setup(&compound_setup_params)?;

    info!("snark_proof:start");
    let groth_proofs = StackedCompound::<Tree, DefaultPieceHasher>::circuit_proofs(
        &public_inputs,
        vanilla_proofs,
        &compound_public_params.vanilla_params,
        &groth_params,
        compound_public_params.priority,
    )?;
    info!("snark_proof:finish");

    let proof = MultiProof::new(groth_proofs, &groth_params.vk);

    let mut buf = Vec::with_capacity(
        SINGLE_PARTITION_PROOF_LEN * usize::from(PoRepProofPartitions::from(porep_config)),
    );

    proof.write(&mut buf)?;

    // Verification is cheap when parameters are cached,
    // and it is never correct to return a proof which does not verify.
    verify_seal::<Tree>(
        porep_config,
        comm_r,
        comm_d,
        prover_id,
        sector_id,
        ticket,
        seed,
        &buf,
    )
    .context("post-seal verification sanity check failed")?;

    info!("seal_commit_phase2:end");

    Ok(SealCommitOutput { proof: buf })
}

/// Computes a sectors's `comm_d` given its pieces.
///
/// # Arguments
///
/// * `porep_config` - this sector's porep config that contains the number of bytes in the sector.
/// * `piece_infos` - the piece info (commitment and byte length) for each piece in this sector.
pub fn compute_comm_d(sector_size: SectorSize, piece_infos: &[PieceInfo]) -> Result<Commitment> {
    pieces::compute_comm_d(sector_size, piece_infos)
}

/// Verifies the output of some previously-run seal operation.
///
/// # Arguments
///
/// * `porep_config` - this sector's porep config that contains the number of bytes in this sector.
/// * `comm_r_in` - commitment to the sector's replica (`comm_r`).
/// * `comm_d_in` - commitment to the sector's data (`comm_d`).
/// * `prover_id` - the prover-id that sealed this sector.
/// * `sector_id` - this sector's sector-id.
/// * `ticket` - the ticket that was used to generate this sector's replica-id.
/// * `seed` - the seed used to derive the porep challenges.
/// * `proof_vec` - the porep circuit proof serialized into a vector of bytes.
#[allow(clippy::too_many_arguments)]
pub fn verify_seal<Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    comm_r_in: Commitment,
    comm_d_in: Commitment,
    prover_id: ProverId,
    sector_id: SectorId,
    ticket: Ticket,
    seed: Ticket,
    proof_vec: &[u8],
) -> Result<bool> {
    ensure!(comm_d_in != [0; 32], "Invalid all zero commitment (comm_d)");
    ensure!(comm_r_in != [0; 32], "Invalid all zero commitment (comm_r)");

    let sector_bytes = PaddedBytesAmount::from(porep_config);
    let comm_r: <Tree::Hasher as Hasher>::Domain = as_safe_commitment(&comm_r_in, "comm_r")?;
    let comm_d: DefaultPieceDomain = as_safe_commitment(&comm_d_in, "comm_d")?;

    let replica_id =
        generate_replica_id::<Tree::Hasher, _>(&prover_id, sector_id.into(), &ticket, comm_d);

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params: compound_proof::PublicParams<
        '_,
        StackedDrg<'_, Tree, DefaultPieceHasher>,
    > = StackedCompound::setup(&compound_setup_params)?;

    let public_inputs =
        stacked::PublicInputs::<<Tree::Hasher as Hasher>::Domain, DefaultPieceDomain> {
            replica_id,
            tau: Some(Tau { comm_r, comm_d }),
            seed,
            k: None,
        };

    let verifying_key = get_stacked_verifying_key::<Tree>(porep_config)?;

    info!(
        "got verifying key ({}) while verifying seal",
        u64::from(sector_bytes)
    );

    let proof = MultiProof::new_from_reader(
        Some(usize::from(PoRepProofPartitions::from(porep_config))),
        proof_vec,
        &verifying_key,
    )?;

    StackedCompound::verify(
        &compound_public_params,
        &public_inputs,
        &proof,
        &ChallengeRequirements {
            minimum_challenges: *POREP_MINIMUM_CHALLENGES
                .read()
                .unwrap()
                .get(&u64::from(SectorSize::from(porep_config)))
                .expect("unknown sector size") as usize,
        },
    )
    .map_err(Into::into)
}

/// Verifies a batch of outputs of some previously-run seal operations.
///
/// # Arguments
///
/// * `porep_config` - this sector's porep config that contains the number of bytes in this sector.
/// * `[comm_r_ins]` - list of commitments to the sector's replica (`comm_r`).
/// * `[comm_d_ins]` - list of commitments to the sector's data (`comm_d`).
/// * `[prover_ids]` - list of prover-ids that sealed this sector.
/// * `[sector_ids]` - list of the sector's sector-id.
/// * `[tickets]` - list of tickets that was used to generate this sector's replica-id.
/// * `[seeds]` - list of seeds used to derive the porep challenges.
/// * `[proof_vecs]` - list of porep circuit proofs serialized into a vector of bytes.
#[allow(clippy::too_many_arguments)]
pub fn verify_batch_seal<Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
    comm_r_ins: &[Commitment],
    comm_d_ins: &[Commitment],
    prover_ids: &[ProverId],
    sector_ids: &[SectorId],
    tickets: &[Ticket],
    seeds: &[Ticket],
    proof_vecs: &[&[u8]],
) -> Result<bool> {
    ensure!(!comm_r_ins.is_empty(), "Cannot prove empty batch");
    let l = comm_r_ins.len();
    ensure!(l == comm_d_ins.len(), "Inconsistent inputs");
    ensure!(l == prover_ids.len(), "Inconsistent inputs");
    ensure!(l == prover_ids.len(), "Inconsistent inputs");
    ensure!(l == sector_ids.len(), "Inconsistent inputs");
    ensure!(l == tickets.len(), "Inconsistent inputs");
    ensure!(l == seeds.len(), "Inconsistent inputs");
    ensure!(l == proof_vecs.len(), "Inconsistent inputs");

    for comm_d_in in comm_d_ins {
        ensure!(
            comm_d_in != &[0; 32],
            "Invalid all zero commitment (comm_d)"
        );
    }
    for comm_r_in in comm_r_ins {
        ensure!(
            comm_r_in != &[0; 32],
            "Invalid all zero commitment (comm_r)"
        );
    }

    let sector_bytes = PaddedBytesAmount::from(porep_config);

    let verifying_key = get_stacked_verifying_key::<Tree>(porep_config)?;
    info!(
        "got verifying key ({}) while verifying seal",
        u64::from(sector_bytes)
    );

    let compound_setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )?,
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let compound_public_params: compound_proof::PublicParams<
        '_,
        StackedDrg<'_, Tree, DefaultPieceHasher>,
    > = StackedCompound::setup(&compound_setup_params)?;

    let mut public_inputs = Vec::with_capacity(l);
    let mut proofs = Vec::with_capacity(l);

    for i in 0..l {
        let comm_r = as_safe_commitment(&comm_r_ins[i], "comm_r")?;
        let comm_d = as_safe_commitment(&comm_d_ins[i], "comm_d")?;

        let replica_id = generate_replica_id::<Tree::Hasher, _>(
            &prover_ids[i],
            sector_ids[i].into(),
            &tickets[i],
            comm_d,
        );

        public_inputs.push(stacked::PublicInputs::<
            <Tree::Hasher as Hasher>::Domain,
            DefaultPieceDomain,
        > {
            replica_id,
            tau: Some(Tau { comm_r, comm_d }),
            seed: seeds[i],
            k: None,
        });
        proofs.push(MultiProof::new_from_reader(
            Some(usize::from(PoRepProofPartitions::from(porep_config))),
            proof_vecs[i],
            &verifying_key,
        )?);
    }

    StackedCompound::<Tree, DefaultPieceHasher>::batch_verify(
        &compound_public_params,
        &public_inputs,
        &proofs,
        &ChallengeRequirements {
            minimum_challenges: *POREP_MINIMUM_CHALLENGES
                .read()
                .unwrap()
                .get(&u64::from(SectorSize::from(porep_config)))
                .expect("unknown sector size") as usize,
        },
    )
    .map_err(Into::into)
}

'''
'''--- filecoin-proofs/src/api/util.rs ---
use anyhow::{Context, Result};
use merkletree::merkle::{get_merkle_tree_leafs, get_merkle_tree_len};
use paired::bls12_381::Fr;
use storage_proofs::fr32::{bytes_into_fr, fr_into_bytes};
use storage_proofs::hasher::{Domain, Hasher};
use storage_proofs::merkle::{get_base_tree_count, MerkleTreeTrait};
use typenum::Unsigned;

use crate::types::{Commitment, SectorSize};

pub(crate) fn as_safe_commitment<H: Domain, T: AsRef<str>>(
    comm: &[u8; 32],
    commitment_name: T,
) -> Result<H> {
    bytes_into_fr(comm)
        .map(Into::into)
        .with_context(|| format!("Invalid commitment ({})", commitment_name.as_ref(),))
}

pub(crate) fn commitment_from_fr(fr: Fr) -> Commitment {
    let mut commitment = [0; 32];
    for (i, b) in fr_into_bytes(&fr).iter().enumerate() {
        commitment[i] = *b;
    }
    commitment
}

pub(crate) fn get_base_tree_size<Tree: MerkleTreeTrait>(sector_size: SectorSize) -> Result<usize> {
    let base_tree_leaves = u64::from(sector_size) as usize
        / std::mem::size_of::<<Tree::Hasher as Hasher>::Domain>()
        / get_base_tree_count::<Tree>();

    get_merkle_tree_len(base_tree_leaves, Tree::Arity::to_usize())
}

pub(crate) fn get_base_tree_leafs<Tree: MerkleTreeTrait>(base_tree_size: usize) -> Result<usize> {
    get_merkle_tree_leafs(base_tree_size, Tree::Arity::to_usize())
}

'''
'''--- filecoin-proofs/src/bin/fakeipfsadd.rs ---
use blake2b_simd::State as Blake2b;
use clap::{App, Arg};
use std::fs::File;

pub fn main() {
    let matches = App::new("fakeipfsadd")
        .version("0.1")
        .about(
            "
This program is used to simulate the `ipfs add` command while testing. It
accepts a path to a file and writes 32 characters of its hex-encoded BLAKE2b 
checksum to stdout. Note: The real `ipfs add` command computes and emits a CID.
",
        )
        .arg(Arg::with_name("add").index(1).required(true))
        .arg(Arg::with_name("file-path").index(2).required(true))
        .arg(
            Arg::with_name("quieter")
                .short("Q")
                .required(true)
                .help("Simulates the -Q argument to `ipfs add`"),
        )
        .get_matches();

    let src_file_path = matches
        .value_of("file-path")
        .expect("failed to get file path");

    let mut src_file = File::open(&src_file_path)
        .unwrap_or_else(|_| panic!("failed to open file at {}", &src_file_path));

    let mut hasher = Blake2b::new();

    std::io::copy(&mut src_file, &mut hasher).expect("failed to write BLAKE2b bytes to hasher");

    let hex_string: String = hasher.finalize().to_hex()[..32].into();

    println!("{}", hex_string)
}

'''
'''--- filecoin-proofs/src/bin/paramcache.rs ---
use dialoguer::{theme::ColorfulTheme, MultiSelect};
use humansize::{file_size_opts, FileSize};
use indicatif::ProgressBar;
use log::{info, warn};
use rand::rngs::OsRng;
use structopt::StructOpt;

use filecoin_proofs::constants::*;
use filecoin_proofs::parameters::{
    public_params, window_post_public_params, winning_post_public_params,
};
use filecoin_proofs::types::*;
use filecoin_proofs::with_shape;
use filecoin_proofs::PoStType;
use storage_proofs::compound_proof::CompoundProof;
use storage_proofs::parameter_cache::CacheableParameters;
use storage_proofs::porep::stacked::{StackedCompound, StackedDrg};
use storage_proofs::post::fallback::{FallbackPoSt, FallbackPoStCircuit, FallbackPoStCompound};

const PUBLISHED_SECTOR_SIZES: [u64; 10] = [
    SECTOR_SIZE_2_KIB,
    SECTOR_SIZE_4_KIB,
    SECTOR_SIZE_16_KIB,
    SECTOR_SIZE_32_KIB,
    SECTOR_SIZE_8_MIB,
    SECTOR_SIZE_16_MIB,
    SECTOR_SIZE_512_MIB,
    SECTOR_SIZE_1_GIB,
    SECTOR_SIZE_32_GIB,
    SECTOR_SIZE_64_GIB,
];

fn cache_porep_params<Tree: 'static + MerkleTreeTrait>(porep_config: PoRepConfig) {
    info!("PoRep params");

    let public_params = public_params(
        PaddedBytesAmount::from(porep_config),
        usize::from(PoRepProofPartitions::from(porep_config)),
    )
    .unwrap();

    {
        let circuit = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
            StackedDrg<Tree, DefaultPieceHasher>,
            _,
        >>::blank_circuit(&public_params);
        let _ = StackedCompound::<Tree, DefaultPieceHasher>::get_param_metadata(
            circuit,
            &public_params,
        );
    }
    {
        let circuit = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
            StackedDrg<Tree, DefaultPieceHasher>,
            _,
        >>::blank_circuit(&public_params);
        StackedCompound::<Tree, DefaultPieceHasher>::get_groth_params(
            Some(&mut OsRng),
            circuit,
            &public_params,
        )
        .expect("failed to get groth params");
    }
    {
        let circuit = <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
            StackedDrg<Tree, DefaultPieceHasher>,
            _,
        >>::blank_circuit(&public_params);

        StackedCompound::<Tree, DefaultPieceHasher>::get_verifying_key(
            Some(&mut OsRng),
            circuit,
            &public_params,
        )
        .expect("failed to get verifying key");
    }
}

fn cache_winning_post_params<Tree: 'static + MerkleTreeTrait>(post_config: &PoStConfig) {
    info!("Winning PoSt params");

    let post_public_params = winning_post_public_params::<Tree>(post_config).unwrap();

    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);
        let _ = <FallbackPoStCompound<Tree>>::get_param_metadata(post_circuit, &post_public_params)
            .expect("failed to get metadata");
    }
    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);
        <FallbackPoStCompound<Tree>>::get_groth_params(
            Some(&mut OsRng),
            post_circuit,
            &post_public_params,
        )
        .expect("failed to get groth params");
    }
    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);

        <FallbackPoStCompound<Tree>>::get_verifying_key(
            Some(&mut OsRng),
            post_circuit,
            &post_public_params,
        )
        .expect("failed to get verifying key");
    }
}

fn cache_window_post_params<Tree: 'static + MerkleTreeTrait>(post_config: &PoStConfig) {
    info!("Window PoSt params");

    let post_public_params = window_post_public_params::<Tree>(post_config).unwrap();

    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);
        let _ = <FallbackPoStCompound<Tree>>::get_param_metadata(post_circuit, &post_public_params)
            .expect("failed to get metadata");
    }
    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);
        <FallbackPoStCompound<Tree>>::get_groth_params(
            Some(&mut OsRng),
            post_circuit,
            &post_public_params,
        )
        .expect("failed to get groth params");
    }
    {
        let post_circuit: FallbackPoStCircuit<Tree> =
            <FallbackPoStCompound<Tree> as CompoundProof<
                FallbackPoSt<Tree>,
                FallbackPoStCircuit<Tree>,
            >>::blank_circuit(&post_public_params);

        <FallbackPoStCompound<Tree>>::get_verifying_key(
            Some(&mut OsRng),
            post_circuit,
            &post_public_params,
        )
        .expect("failed to get verifying key");
    }
}

/// Generate and persist Groth parameters and verifying keys for filecoin-proofs.
#[derive(Debug, StructOpt)]
#[structopt(name = "paramcache")]
struct Opt {
    /// Only generate parameters for post.
    #[structopt(long)]
    only_post: bool,
    #[structopt(short = "z", long, use_delimiter = true)]
    params_for_sector_sizes: Vec<u64>,
}

fn generate_params_post(sector_size: u64) {
    with_shape!(
        sector_size,
        cache_winning_post_params,
        &PoStConfig {
            sector_size: SectorSize(sector_size),
            challenge_count: WINNING_POST_CHALLENGE_COUNT,
            sector_count: WINNING_POST_SECTOR_COUNT,
            typ: PoStType::Winning,
            priority: true,
        }
    );

    with_shape!(
        sector_size,
        cache_window_post_params,
        &PoStConfig {
            sector_size: SectorSize(sector_size),
            challenge_count: WINDOW_POST_CHALLENGE_COUNT,
            sector_count: *WINDOW_POST_SECTOR_COUNT
                .read()
                .unwrap()
                .get(&sector_size)
                .unwrap(),
            typ: PoStType::Window,
            priority: true,
        }
    );
}

fn generate_params_porep(sector_size: u64) {
    with_shape!(
        sector_size,
        cache_porep_params,
        PoRepConfig {
            sector_size: SectorSize(sector_size),
            partitions: PoRepProofPartitions(
                *POREP_PARTITIONS
                    .read()
                    .unwrap()
                    .get(&sector_size)
                    .expect("missing sector size"),
            ),
        }
    );
}

// Run this from the command-line to pre-generate the groth parameters used by the API.
pub fn main() {
    // The logger is used and every message from this tool is also logged into those logs.
    // Though the information is also printed to stdout, so that users who haven't set the
    // `RUST_LOG` environment variable also see warngings/progress.
    fil_logger::init();

    let opts = Opt::from_args();

    // Display interactive menu if no sizes are given
    let sizes: Vec<u64> = if opts.params_for_sector_sizes.is_empty() {
        let sector_sizes = PUBLISHED_SECTOR_SIZES
            .iter()
            .map(|sector_size| {
                // Right aligning the numbers makes them easier to read
                format!(
                    "{: >7}",
                    sector_size.file_size(file_size_opts::BINARY).unwrap(),
                )
            })
            .collect::<Vec<_>>();

        let selected_sector_sizes = MultiSelect::with_theme(&ColorfulTheme::default())
            .with_prompt("Select the sizes that should be generated if not already cached")
            .items(&sector_sizes[..])
            .interact()
            .unwrap();

        // Extract the selected sizes
        PUBLISHED_SECTOR_SIZES
            .iter()
            .enumerate()
            .filter_map(|(index, size)| {
                if selected_sector_sizes.contains(&index) {
                    Some(*size)
                } else {
                    None
                }
            })
            .collect()
    } else {
        opts.params_for_sector_sizes
            .into_iter()
            .filter(|size| {
                if PUBLISHED_SECTOR_SIZES.contains(size) {
                    return true;
                }

                warn!("ignoring invalid sector size: {}", size);
                println!("ignoring invalid sector size: {}", size);
                false
            })
            .collect()
    };

    if sizes.is_empty() {
        info!("No valid sector sizes given. Abort.");
        println!("No valid sector sizes given. Abort.");
    }

    let only_post = opts.only_post;

    for sector_size in sizes {
        let human_size = sector_size.file_size(file_size_opts::BINARY).unwrap();
        let message = format!("Generating sector size: {}", human_size);
        info!("{}", &message);

        let spinner = ProgressBar::new_spinner();
        spinner.set_message(&message);
        spinner.enable_steady_tick(100);

        generate_params_post(sector_size);

        if !only_post {
            generate_params_porep(sector_size);
        }
        spinner.finish_with_message(&format!("✔ {}", &message));
    }
}

'''
'''--- filecoin-proofs/src/bin/paramfetch.rs ---
use std::collections::HashSet;
use std::fs::{create_dir_all, rename, File};
use std::io::copy;
use std::io::prelude::*;
use std::io::{BufReader, Stdout};
use std::path::{Path, PathBuf};
use std::process::exit;
use std::process::Command;
use std::{fs, io};

use anyhow::{bail, ensure, Context, Result};
use clap::{values_t, App, Arg, ArgMatches};
use flate2::read::GzDecoder;
use itertools::Itertools;
use pbr::{ProgressBar, Units};
use reqwest::{header, Client, Proxy, Url};
use tar::Archive;

use filecoin_proofs::param::*;
use storage_proofs::parameter_cache::{
    parameter_cache_dir, GROTH_PARAMETER_EXT, PARAMETER_CACHE_DIR, PARAMETER_CACHE_ENV_VAR,
};

const ERROR_PARAMETER_FILE: &str = "failed to find file in cache";
const ERROR_PARAMETER_ID: &str = "failed to find key in manifest";

const IPGET_PATH: &str = "/var/tmp/ipget";
const DEFAULT_PARAMETERS: &str = include_str!("../../parameters.json");
const IPGET_VERSION: &str = "v0.4.0";

struct FetchProgress<R> {
    inner: R,
    progress_bar: ProgressBar<Stdout>,
}

impl<R: Read> Read for FetchProgress<R> {
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        self.inner.read(buf).map(|n| {
            self.progress_bar.add(n as u64);
            n
        })
    }
}

pub fn main() {
    fil_logger::init();

    let matches = App::new("paramfetch")
        .version("1.1")
        .about(
            &format!(
                "
Set {} to specify Groth parameter and verifying key-cache directory.
Defaults to '{}'
",
                PARAMETER_CACHE_ENV_VAR,
                PARAMETER_CACHE_DIR
            )[..],
        )
        .arg(
            Arg::with_name("json")
                .value_name("JSON")
                .takes_value(true)
                .short("j")
                .long("json")
                .help("Use specific JSON file"),
        )
        .arg(
            Arg::with_name("retry")
                .short("r")
                .long("retry")
                .help("Prompt to retry on failure"),
        )
        .arg(
            Arg::with_name("all")
                .short("a")
                .long("all")
                .conflicts_with("params-for-sector-sizes")
                .help("Download all available parameters and verifying keys"),
        )
        .arg(
            Arg::with_name("params-for-sector-sizes")
                .short("z")
                .long("params-for-sector-sizes")
                .conflicts_with("all")
                .require_delimiter(true)
                .value_delimiter(",")
                .multiple(true)
                .help("A comma-separated list of sector sizes, in bytes, for which Groth parameters will be downloaded"),
        )
        .arg(
            Arg::with_name("verbose")
                .short("v")
                .long("verbose")
                .help("Print diagnostic information to stdout"),
        )
        .arg(
            Arg::with_name("ipget-bin")
                .conflicts_with("ipget-version")
                .takes_value(true)
                .short("i")
                .long("ipget-bin")
                .help("Use specific ipget binary instead of looking for (or installing) one in /var/tmp/ipget/ipget"),
        )
        .arg(
            Arg::with_name("ipget-args")
                .takes_value(true)
                .long("ipget-args")
                .help("Specify additional arguments for ipget")
        )
        .arg(
            Arg::with_name("ipget-version")
                .conflicts_with("ipget-bin")
                .long("ipget-version")
                .takes_value(true)
                .help("Set the version of ipget to use")
        )
        .get_matches();

    match fetch(&matches) {
        Ok(_) => println!("done"),
        Err(err) => {
            println!("fatal error: {}", err);
            exit(1);
        }
    }
}

fn fetch(matches: &ArgMatches) -> Result<()> {
    let manifest = if matches.is_present("json") {
        let json_path = PathBuf::from(matches.value_of("json").unwrap());
        println!("using JSON file: {:?}", json_path);

        if !json_path.exists() {
            bail!(
                "JSON file '{}' does not exist",
                &json_path.to_str().unwrap_or("")
            );
        }

        let file = File::open(&json_path)?;
        let reader = BufReader::new(file);

        serde_json::from_reader(reader).with_context(|| {
            format!(
                "JSON file '{}' did not parse correctly",
                &json_path.to_str().unwrap_or(""),
            )
        })?
    } else {
        println!("using built-in manifest");
        serde_json::from_str(&DEFAULT_PARAMETERS)?
    };

    let retry = matches.is_present("retry");

    let mut filenames = get_filenames_from_parameter_map(&manifest)?;

    println!("{} files in manifest...", filenames.len());
    println!();

    // if user has specified sector sizes for which they wish to download Groth
    // parameters, trim non-matching Groth parameter filenames from the list
    if matches.is_present("params-for-sector-sizes") {
        let whitelisted_sector_sizes: HashSet<u64> =
            values_t!(matches.values_of("params-for-sector-sizes"), u64)?
                .into_iter()
                .collect();

        // always download all verifying keys - but conditionally skip Groth
        // parameters for sector sizes the user doesn't care about
        filenames = filenames
            .into_iter()
            .filter(|id| {
                !has_extension(id, GROTH_PARAMETER_EXT) || {
                    manifest
                        .get(id)
                        .map(|p| p.sector_size)
                        .map(|n| whitelisted_sector_sizes.contains(&n))
                        .unwrap_or(false)
                }
            })
            .collect_vec();
    }

    println!("{} files to check for (re)download...", filenames.len());
    println!();

    // ensure filename corresponds to asset on disk and that its checksum
    // matches that which is specified in the manifest
    filenames = get_filenames_requiring_download(&manifest, filenames)?;

    // don't prompt the user to download files if they've used certain flags
    if !matches.is_present("params-for-sector-sizes")
        && !matches.is_present("all")
        && !filenames.is_empty()
    {
        filenames = choose_from(&filenames, |filename| {
            manifest.get(filename).map(|x| x.sector_size)
        })?;
        println!();
    }

    let is_verbose = matches.is_present("verbose");
    let ipget_bin_path = matches.value_of("ipget-bin");
    let ipget_version = matches.value_of("ipget-version").unwrap_or(IPGET_VERSION);
    let ipget_args = matches.value_of("ipget-args");

    // Make sure we have ipget available
    if ipget_bin_path.is_none() {
        ensure_ipget(is_verbose, ipget_version)?;
    }

    let ipget_path = if let Some(p) = ipget_bin_path {
        PathBuf::from(p)
    } else {
        PathBuf::from(&get_ipget_bin(ipget_version))
    };

    loop {
        println!("{} files to fetch...", filenames.len());
        println!();

        for filename in &filenames {
            println!("fetching: {}", filename);
            print!("downloading file... ");
            io::stdout().flush().unwrap();

            match fetch_parameter_file(is_verbose, &manifest, &filename, &ipget_path, ipget_args) {
                Ok(_) => println!("ok\n"),
                Err(err) => println!("error: {}\n", err),
            }
        }

        // if we haven't downloaded a valid copy of each asset specified in the
        // manifest, ask the user if they wish to try again
        filenames = get_filenames_requiring_download(&manifest, filenames)?;

        if filenames.is_empty() {
            break;
        } else {
            println!("{} files failed to be fetched:", filenames.len());

            for parameter_id in &filenames {
                println!("{}", parameter_id);
            }

            println!();

            if !retry || !choose("try again?") {
                bail!("some files failed to be fetched. try again, or run paramcache to generate locally");
            }
        }
    }

    Ok(())
}

fn get_ipget_bin(version: &str) -> String {
    format!("{}-{}/ipget/ipget", IPGET_PATH, version)
}

/// Check if ipget is available, dowwnload it otherwise.
fn ensure_ipget(is_verbose: bool, version: &str) -> Result<()> {
    let ipget_bin = get_ipget_bin(version);
    if Path::new(&ipget_bin).exists() {
        Ok(())
    } else {
        download_ipget(is_verbose, version)
    }
    .map(|_| {
        if is_verbose {
            println!("ipget installed: {}", ipget_bin);
        }
    })
}

/// Download a version of ipget.
fn download_ipget(is_verbose: bool, version: &str) -> Result<()> {
    let (os, extension) = if cfg!(target_os = "macos") {
        ("darwin", "tar.gz")
    } else if cfg!(target_os = "windows") {
        ("windows", "zip")
    } else {
        ("linux", "tar.gz")
    };

    let url = Url::parse(&format!(
        "https://dist.ipfs.io/ipget/{}/ipget_{}_{}-amd64.{}",
        version, version, os, extension
    ))?;

    if is_verbose {
        println!("downloading ipget@{}-{}...", version, os);
    }

    // download file
    let p = format!("{}-{}.{}", IPGET_PATH, version, extension);
    download_file(url, &p, is_verbose)?;

    // extract file
    if extension == "tar.gz" {
        let tar_gz = fs::File::open(p)?;
        let tar = GzDecoder::new(tar_gz);
        let mut archive = Archive::new(tar);
        archive.unpack(format!("/var/tmp/ipget-{}", version))?;
    } else {
        // TODO: handle zip archives on windows
        unimplemented!("failed to install ipget: unzip is not yet supported");
    }

    Ok(())
}

/// Download the given file.
fn download_file(url: Url, target: impl AsRef<Path>, is_verbose: bool) -> Result<()> {
    let mut file = File::create(target)?;

    let client = Client::builder()
        .proxy(Proxy::custom(move |url| env_proxy::for_url(&url).to_url()))
        .build()?;
    let total_size = {
        let res = client.head(url.as_str()).send()?;
        if res.status().is_success() {
            res.headers()
                .get(header::CONTENT_LENGTH)
                .and_then(|ct_len| ct_len.to_str().ok())
                .and_then(|ct_len| ct_len.parse().ok())
                .unwrap_or(0)
        } else {
            bail!("failed to download file: {}", url);
        }
    };

    let req = client.get(url.as_str());
    if is_verbose {
        let mut pb = ProgressBar::new(total_size);
        pb.set_units(Units::Bytes);

        let mut source = FetchProgress {
            inner: req.send()?,
            progress_bar: pb,
        };

        let _ = copy(&mut source, &mut file)?;
    } else {
        let mut source = req.send()?;
        let _ = copy(&mut source, &mut file)?;
    }

    Ok(())
}

fn fetch_parameter_file(
    is_verbose: bool,
    parameter_map: &ParameterMap,
    filename: &str,
    ipget_bin_path: impl AsRef<Path>,
    ipget_args: Option<impl AsRef<str>>,
) -> Result<()> {
    let parameter_data = parameter_map_lookup(parameter_map, filename)?;
    let path = get_full_path_for_file_within_cache(filename);

    create_dir_all(parameter_cache_dir())?;
    download_file_with_ipget(
        &parameter_data.cid,
        path,
        is_verbose,
        ipget_bin_path,
        ipget_args,
    )
}

fn download_file_with_ipget(
    cid: impl AsRef<str>,
    target: impl AsRef<Path>,
    is_verbose: bool,
    ipget_bin_path: impl AsRef<Path>,
    ipget_args: Option<impl AsRef<str>>,
) -> Result<()> {
    let mut cmd = Command::new(ipget_bin_path.as_ref().as_os_str());
    cmd.arg("-o")
        .arg(target.as_ref().to_str().unwrap())
        .arg(cid.as_ref());

    if let Some(args) = ipget_args {
        cmd.args(args.as_ref().split(' '));
    }

    let output = cmd.output()?;

    if is_verbose {
        io::stdout().write_all(&output.stdout)?;
        io::stderr().write_all(&output.stderr)?;
    }

    ensure!(
        output.status.success(),
        "failed to download {}",
        target.as_ref().display()
    );

    Ok(())
}

fn get_filenames_requiring_download(
    parameter_map: &ParameterMap,
    parameter_ids: Vec<String>,
) -> Result<Vec<String>> {
    Ok(parameter_ids
        .into_iter()
        .filter(|parameter_id| {
            println!("checking: {}", parameter_id);
            print!("does file exist... ");

            if get_full_path_for_file_within_cache(parameter_id).exists() {
                println!("yes");
                print!("is file valid... ");
                io::stdout().flush().unwrap();

                match validate_parameter_file(&parameter_map, &parameter_id) {
                    Ok(true) => {
                        println!("yes\n");
                        false
                    }
                    Ok(false) => {
                        println!("no\n");
                        invalidate_parameter_file(&parameter_id).unwrap();
                        true
                    }
                    Err(err) => {
                        println!("error: {}\n", err);
                        true
                    }
                }
            } else {
                println!("no\n");
                true
            }
        })
        .collect())
}

fn get_filenames_from_parameter_map(parameter_map: &ParameterMap) -> Result<Vec<String>> {
    Ok(parameter_map.iter().map(|(k, _)| k.clone()).collect())
}

fn validate_parameter_file(parameter_map: &ParameterMap, filename: &str) -> Result<bool> {
    let parameter_data = parameter_map_lookup(parameter_map, filename)?;
    let digest = get_digest_for_file_within_cache(filename)?;

    if parameter_data.digest != digest {
        Ok(false)
    } else {
        Ok(true)
    }
}

fn invalidate_parameter_file(filename: &str) -> Result<()> {
    let parameter_file_path = get_full_path_for_file_within_cache(filename);
    let target_parameter_file_path =
        parameter_file_path.with_file_name(format!("{}-invalid-digest", filename));

    ensure!(parameter_file_path.exists(), ERROR_PARAMETER_FILE);
    rename(parameter_file_path, target_parameter_file_path)?;

    Ok(())
}

fn parameter_map_lookup<'a>(
    parameter_map: &'a ParameterMap,
    filename: &str,
) -> Result<&'a ParameterData> {
    ensure!(parameter_map.contains_key(filename), ERROR_PARAMETER_ID);

    Ok(parameter_map.get(filename).unwrap())
}

'''
'''--- filecoin-proofs/src/bin/parampublish.rs ---
use std::collections::BTreeMap;
use std::fs::{read_dir, File};
use std::io;
use std::io::prelude::*;
use std::io::BufWriter;
use std::path::{Path, PathBuf};
use std::process::{exit, Command};

use anyhow::{ensure, Context, Result};
use clap::{App, Arg, ArgMatches};
use dialoguer::{theme::ColorfulTheme, MultiSelect, Select};
use humansize::{file_size_opts, FileSize};
use itertools::Itertools;

use filecoin_proofs::param::{
    add_extension, choose_from, filename_to_parameter_id, get_digest_for_file_within_cache,
    get_full_path_for_file_within_cache, has_extension, parameter_id_to_metadata_map,
    ParameterData, ParameterMap,
};
use filecoin_proofs::{
    SECTOR_SIZE_2_KIB, SECTOR_SIZE_32_GIB, SECTOR_SIZE_512_MIB, SECTOR_SIZE_64_GIB,
    SECTOR_SIZE_8_MIB,
};
use storage_proofs::parameter_cache::{
    parameter_cache_dir, CacheEntryMetadata, GROTH_PARAMETER_EXT, PARAMETER_CACHE_DIR,
    PARAMETER_METADATA_EXT, VERIFYING_KEY_EXT,
};

const ERROR_IPFS_COMMAND: &str = "failed to run ipfs";
const ERROR_IPFS_PUBLISH: &str = "failed to publish via ipfs";
const PUBLISH_SECTOR_SIZES: [u64; 5] = [
    SECTOR_SIZE_2_KIB,
    SECTOR_SIZE_8_MIB,
    SECTOR_SIZE_512_MIB,
    SECTOR_SIZE_32_GIB,
    SECTOR_SIZE_64_GIB,
];

pub fn main() {
    fil_logger::init();

    let matches = App::new("parampublish")
        .version("1.0")
        .about(
            &format!(
                "
Set $FIL_PROOFS_PARAMETER_CACHE to specify parameter directory.
Defaults to '{}'
",
                PARAMETER_CACHE_DIR
            )[..],
        )
        .arg(
            Arg::with_name("json")
                .value_name("JSON")
                .takes_value(true)
                .short("j")
                .long("json")
                .help("Use specific json file"),
        )
        .arg(
            Arg::with_name("all")
                .short("a")
                .long("all")
                .help("Publish all local Groth parameters and verifying keys"),
        )
        .arg(
            Arg::with_name("ipfs-bin")
                .takes_value(true)
                .short("i")
                .long("ipfs-bin")
                .help("Use specific ipfs binary instead of searching for one in $PATH"),
        )
        .get_matches();

    match publish(&matches) {
        Ok(_) => println!("done"),
        Err(err) => {
            println!("fatal error: {}", err);
            exit(1);
        }
    }
}

fn publish(matches: &ArgMatches) -> Result<()> {
    let ipfs_bin_path = matches.value_of("ipfs-bin").unwrap_or("ipfs");

    // Get all valid parameter IDs which have all three files, `.meta`, `.params and `.vk`
    // associated with them. If one of the files is missing, it won't show up in the selection.
    let (mut parameter_ids, counter) = get_filenames_in_cache_dir()?
        .iter()
        .filter(|f| {
            has_extension(f, GROTH_PARAMETER_EXT)
                || has_extension(f, VERIFYING_KEY_EXT)
                || has_extension(f, PARAMETER_METADATA_EXT)
        })
        .sorted()
        // Make sure there are always three files per parameter ID
        .fold(
            (Vec::new(), 0),
            |(mut result, mut counter): (std::vec::Vec<String>, u8), filename| {
                let parameter_id = filename_to_parameter_id(&filename).unwrap();
                // Check if previous file had the same parameter ID
                if !result.is_empty() && &parameter_id == result.last().unwrap() {
                    counter += 1;
                } else {
                    // There weren't three files for the same parameter ID, hence remove it from
                    // the list
                    if counter < 3 {
                        result.pop();
                    }

                    // It's a new parameter ID, hence reset the counter and add it to the list
                    counter = 1;
                    result.push(parameter_id);
                }

                (result, counter)
            },
        );

    // There might be lef-overs from the last fold iterations
    if counter < 3 {
        parameter_ids.pop();
    }

    if parameter_ids.is_empty() {
        println!(
            "No valid parameters in directory {:?} found.",
            parameter_cache_dir()
        );
        std::process::exit(1)
    }

    // build a mapping from parameter id to metadata
    let meta_map = parameter_id_to_metadata_map(&parameter_ids)?;

    let filenames = if !matches.is_present("all") {
        let tmp_filenames = meta_map
            .keys()
            .flat_map(|parameter_id| {
                vec![
                    add_extension(parameter_id, GROTH_PARAMETER_EXT),
                    add_extension(parameter_id, VERIFYING_KEY_EXT),
                ]
            })
            .collect_vec();
        choose_from(&tmp_filenames, |filename| {
            filename_to_parameter_id(PathBuf::from(filename))
                .as_ref()
                .and_then(|p_id| meta_map.get(p_id).map(|x| x.sector_size))
        })?
    } else {
        // `--all` let's you select a specific version
        let versions: Vec<String> = meta_map
            .keys()
            // Split off the version of the parameters
            .map(|parameter_id| parameter_id.split('-').next().unwrap().to_string())
            // Sort by descending order, newest parameter first
            .sorted_by(|a, b| Ord::cmp(&b, &a))
            .dedup()
            .collect();
        let selected_version = Select::with_theme(&ColorfulTheme::default())
            .with_prompt("Select a version (press 'q' to quit)")
            .default(0)
            .items(&versions[..])
            .interact_opt()
            .unwrap();
        let version = match selected_version {
            Some(index) => &versions[index],
            None => {
                println!("Aborted.");
                std::process::exit(1)
            }
        };

        // The parameter IDs that should bet published
        let mut parameter_ids = meta_map
            .keys()
            // Filter out all that don't match the selected version
            .filter(|parameter_id| parameter_id.starts_with(version))
            .collect_vec();

        // Display the sector sizes
        let sector_sizes_iter = parameter_ids
            .iter()
            // Get sector size and parameter ID
            .map(|&parameter_id| {
                meta_map
                    .get(parameter_id)
                    .map(|x| (x.sector_size, parameter_id))
                    .unwrap()
            })
            // Sort it ascending by sector size
            .sorted_by(|a, b| Ord::cmp(&a.0, &b.0));

        // The parameters IDs need to be sorted the same way as the menu we display, else
        // the selected items won't match the list we select from
        parameter_ids = sector_sizes_iter
            .clone()
            .map(|(_, parameter_id)| parameter_id)
            .collect_vec();

        let sector_sizes = sector_sizes_iter
            .clone()
            // Format them
            .map(|(sector_size, parameter_id)| {
                format!(
                    "({:?}) {:?}",
                    sector_size.file_size(file_size_opts::BINARY).unwrap(),
                    parameter_id
                )
            })
            .collect_vec();
        // Set the default, pre-selected sizes
        let default_sector_sizes = sector_sizes_iter
            .map(|(sector_size, _)| PUBLISH_SECTOR_SIZES.contains(&sector_size))
            .collect_vec();
        let selected_sector_sizes = MultiSelect::with_theme(&ColorfulTheme::default())
            .with_prompt("Select the sizes to publish")
            .items(&sector_sizes[..])
            .defaults(&default_sector_sizes)
            .interact()
            .unwrap();

        if selected_sector_sizes.is_empty() {
            println!("Nothing selected. Abort.");
        } else {
            // Filter out the selected ones
            parameter_ids = parameter_ids
                .into_iter()
                .enumerate()
                .filter_map(|(index, parameter_id)| {
                    if selected_sector_sizes.contains(&index) {
                        Some(parameter_id)
                    } else {
                        None
                    }
                })
                .collect_vec();
        }

        // Generate filenames based on their parameter IDs
        parameter_ids
            .iter()
            .flat_map(|parameter_id| {
                vec![
                    add_extension(parameter_id, GROTH_PARAMETER_EXT),
                    add_extension(parameter_id, VERIFYING_KEY_EXT),
                ]
            })
            .collect_vec()
    };
    println!();

    let json = PathBuf::from(matches.value_of("json").unwrap_or("./parameters.json"));
    let mut parameter_map: ParameterMap = BTreeMap::new();

    if !filenames.is_empty() {
        println!("publishing {} files...", filenames.len());
        println!();

        for filename in filenames {
            let id = filename_to_parameter_id(&filename)
                .with_context(|| format!("failed to parse id from file name {}", filename))?;

            let meta: &CacheEntryMetadata = meta_map
                .get(&id)
                .with_context(|| format!("no metadata found for parameter id {}", id))?;

            println!("publishing: {}", filename);
            print!("publishing to ipfs... ");
            io::stdout().flush().unwrap();

            match publish_parameter_file(&ipfs_bin_path, &filename) {
                Ok(cid) => {
                    println!("ok");
                    print!("generating digest... ");
                    io::stdout().flush().unwrap();

                    let digest = get_digest_for_file_within_cache(&filename)?;
                    let data = ParameterData {
                        cid,
                        digest,
                        sector_size: meta.sector_size,
                    };

                    parameter_map.insert(filename, data);

                    println!("ok");
                }
                Err(err) => println!("error: {}", err),
            }

            println!();
        }

        write_parameter_map_to_disk(&parameter_map, &json)?;
    } else {
        println!("no files to publish");
    }

    Ok(())
}

fn get_filenames_in_cache_dir() -> Result<Vec<String>> {
    let path = parameter_cache_dir();

    if path.exists() {
        Ok(read_dir(path)?
            .map(|f| f.unwrap().path())
            .filter(|p| p.is_file())
            .map(|p| {
                p.as_path()
                    .file_name()
                    .unwrap()
                    .to_str()
                    .unwrap()
                    .to_string()
            })
            .collect())
    } else {
        println!(
            "parameter directory '{}' does not exist",
            path.as_path().to_str().unwrap()
        );

        Ok(Vec::new())
    }
}

fn publish_parameter_file(ipfs_bin_path: &str, filename: &str) -> Result<String> {
    let path = get_full_path_for_file_within_cache(filename);

    let output = Command::new(ipfs_bin_path)
        .arg("add")
        .arg("-Q")
        .arg(&path)
        .output()
        .expect(ERROR_IPFS_COMMAND);

    ensure!(output.status.success(), ERROR_IPFS_PUBLISH);

    Ok(String::from_utf8(output.stdout)?.trim().to_string())
}

fn write_parameter_map_to_disk<P: AsRef<Path>>(
    parameter_map: &ParameterMap,
    dest_path: P,
) -> Result<()> {
    let p: &Path = dest_path.as_ref();
    let file = File::create(p)?;
    let writer = BufWriter::new(file);
    serde_json::to_writer_pretty(writer, &parameter_map)?;

    Ok(())
}

'''
'''--- filecoin-proofs/src/bin/phase2.rs ---
/// A CLI program for running Phase2 of Filecoin's trusted-setup.
///
/// # Build
///
/// From the directory `rust-fil-proofs` run:
///
/// ```
/// $ RUSTFLAGS="-C target-cpu=native" cargo build --release -p filecoin-proofs --bin=phase2
/// ```
///
/// # Usage
///
/// ```
/// # Create initial params for a circuit using:
/// $ RUST_BACKTRACE=1 ./target/release/phase2 new \
///     <--porep, --epost, --fpost> \
///     [--poseidon (default), --sha-pedersen] \
///     <--2kib, --8mib, --512mib, --32gib, --64gib>
///
/// # Contribute randomness to the phase2 params for a circuit:
/// $ RUST_BACKTRACE=1 ./target/release/phase2 contribute <path to params file>
///
/// # Verify the transition from one phase2 params file to another:
/// $ RUST_BACKTRACE=1 ./target/release/phase2 verify \
///     --paths=<comma separated list of file paths to params> \
///     --contributions=<comma separated list of contribution digests>
///
/// # Run verification as a daemon - verify the parameters and contributions as they are written to
/// # the `rust-fil-proofs` directory:
/// $ RUST_BACKTRACE=1 ./target/release/phase2 verifyd
/// ```
use std::fmt::{self, Display, Formatter};
use std::fs::{self, File};
use std::io::{BufReader, BufWriter};
use std::path::Path;
use std::process::Command;
use std::str::{self, FromStr};
use std::thread::sleep;
use std::time::{Duration, Instant};

use clap::{App, AppSettings, Arg, ArgGroup, SubCommand};
use filecoin_proofs::constants::*;
use filecoin_proofs::parameters::{
    setup_params, window_post_public_params, winning_post_public_params,
};
use filecoin_proofs::types::*;
use filecoin_proofs::with_shape;
use log::info;
use phase2::{verify_contribution, MPCParameters};
use rand::SeedableRng;
use simplelog::{self, CombinedLogger, LevelFilter, TermLogger, TerminalMode, WriteLogger};
use storage_proofs::compound_proof::{self, CompoundProof};
use storage_proofs::hasher::Sha256Hasher;
use storage_proofs::merkle::MerkleTreeTrait;
use storage_proofs::porep::stacked::{StackedCircuit, StackedCompound, StackedDrg};
use storage_proofs::post::fallback::{FallbackPoSt, FallbackPoStCircuit, FallbackPoStCompound};

#[derive(Clone, Copy)]
enum Proof {
    Porep,
    WinningPost,
    WindowPost,
}

impl Display for Proof {
    fn fmt(&self, f: &mut Formatter) -> fmt::Result {
        let s = match self {
            Proof::Porep => "PoRep",
            Proof::WinningPost => "WinningPoSt",
            Proof::WindowPost => "WindowPoSt",
        };
        write!(f, "{}", s)
    }
}

#[derive(Clone, Copy)]
enum Hasher {
    Poseidon,
    // ShaPedersen,
}

impl Display for Hasher {
    fn fmt(&self, f: &mut Formatter) -> fmt::Result {
        let s = match self {
            Hasher::Poseidon => "Poseidon",
            // Hasher::ShaPedersen => "SHA-Pedersen",
        };
        write!(f, "{}", s)
    }
}

fn display_sector_size(sector_size: u64) -> String {
    match sector_size {
        SECTOR_SIZE_2_KIB => "2KiB".to_string(),
        SECTOR_SIZE_8_MIB => "8MiB".to_string(),
        SECTOR_SIZE_512_MIB => "512MiB".to_string(),
        SECTOR_SIZE_32_GIB => "32GiB".to_string(),
        SECTOR_SIZE_64_GIB => "64GiB".to_string(),
        _ => unreachable!(),
    }
}

fn get_head_commit() -> String {
    let output = Command::new("git")
        .args(&["rev-parse", "--short=7", "HEAD"])
        .output()
        .expect("failed to execute child process: `git rev-parse --short=7 HEAD`");

    str::from_utf8(&output.stdout).unwrap().trim().to_string()
}

fn params_filename(
    proof: Proof,
    hasher: Hasher,
    sector_size: u64,
    head: &str,
    param_number: usize,
) -> String {
    let mut filename = format!(
        "{}_{}_{}_{}_{}",
        proof,
        hasher,
        display_sector_size(sector_size),
        head,
        param_number
    );
    filename.make_ascii_lowercase();
    filename.replace("-", "_")
}

fn initial_params_filename(proof: Proof, hasher: Hasher, sector_size: u64) -> String {
    params_filename(proof, hasher, sector_size, &get_head_commit(), 0)
}

/// Parses a phase2 parameters filename `path` (e.g. "porep_poseidon_32gib_abcdef_0") to a tuple
/// containing the proof, hasher, sector-size, shortened head commit, and contribution number (e.g.
/// `(Proof::Porep, Hasher::Poseidon, SECTOR_SIZE_32_GIB, "abcdef1", 0)`).
fn parse_params_filename(path: &str) -> (Proof, Hasher, u64, String, usize) {
    let filename = path.rsplitn(2, '/').next().unwrap();
    let split: Vec<&str> = filename.split('_').collect();

    let proof = match split[0] {
        "porep" => Proof::Porep,
        "winning-post" => Proof::WinningPost,
        "window-post" => Proof::WindowPost,
        other => panic!("invalid proof id in filename: {}", other),
    };

    // TODO: this is broken if we enable SHA-Pedersen.
    let hasher = match split[1] {
        "poseidon" => Hasher::Poseidon,
        // "sha_pedersen" => Hasher::ShaPedersen,
        other => panic!("invalid hasher id in filename: {}", other),
    };

    let sector_size = match split[2] {
        "2kib" => SECTOR_SIZE_2_KIB,
        "8mib" => SECTOR_SIZE_8_MIB,
        "512mib" => SECTOR_SIZE_512_MIB,
        "32gib" => SECTOR_SIZE_32_GIB,
        "64gib" => SECTOR_SIZE_64_GIB,
        other => panic!("invalid sector-size id in filename: {}", other),
    };

    let head = split[3].to_string();

    let param_number = usize::from_str(split[4])
        .unwrap_or_else(|_| panic!("invalid param number in filename: {}", split[3]));

    (proof, hasher, sector_size, head, param_number)
}

fn blank_porep_poseidon_circuit<Tree: MerkleTreeTrait>(
    sector_size: u64,
) -> StackedCircuit<'static, Tree, Sha256Hasher> {
    let n_partitions = *POREP_PARTITIONS.read().unwrap().get(&sector_size).unwrap();

    let porep_config = PoRepConfig {
        sector_size: SectorSize(sector_size),
        partitions: PoRepProofPartitions(n_partitions),
    };

    let setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )
        .unwrap(),
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let public_params = <StackedCompound<Tree, Sha256Hasher> as CompoundProof<
        StackedDrg<Tree, Sha256Hasher>,
        _,
    >>::setup(&setup_params)
    .unwrap();

    <StackedCompound<Tree, Sha256Hasher> as CompoundProof<
        StackedDrg<Tree, Sha256Hasher>,
        _,
    >>::blank_circuit(&public_params.vanilla_params)
}

/*
fn blank_porep_sha_pedersen_circuit(
    sector_size: u64,
) -> StackedCircuit<'static, PedersenHasher, Sha256Hasher> {
    let	n_partitions = *POREP_PARTITIONS.read().unwrap().get(&sector_size).unwrap();

    let porep_config = PoRepConfig {
        sector_size: SectorSize(sector_size),
        partitions: PoRepProofPartitions(n_partitions),
    };

    let setup_params = compound_proof::SetupParams {
        vanilla_params: setup_params(
            PaddedBytesAmount::from(porep_config),
            usize::from(PoRepProofPartitions::from(porep_config)),
        )
        .unwrap(),
        partitions: Some(usize::from(PoRepProofPartitions::from(porep_config))),
        priority: false,
    };

    let public_params =
        <StackedCompound<PedersenHasher, Sha256Hasher> as CompoundProof<_, StackedDrg<PedersenHasher, Sha256Hasher>, _>>::setup(
            &setup_params,
        )
        .unwrap();

    <StackedCompound<PedersenHasher, Sha256Hasher> as CompoundProof<
        _,
        StackedDrg<PedersenHasher, Sha256Hasher>,
        _,
    >>::blank_circuit(&public_params.vanilla_params)
}
*/

fn blank_winning_post_poseidon_circuit<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
) -> FallbackPoStCircuit<Tree> {
    let post_config = PoStConfig {
        sector_size: SectorSize(sector_size),
        challenge_count: WINNING_POST_CHALLENGE_COUNT,
        sector_count: WINNING_POST_SECTOR_COUNT,
        typ: PoStType::Winning,
        priority: false,
    };

    let public_params = winning_post_public_params::<Tree>(&post_config).unwrap();

    <FallbackPoStCompound<Tree> as CompoundProof<
        FallbackPoSt<Tree>,
        FallbackPoStCircuit<Tree>,
    >>::blank_circuit(&public_params)
}

fn blank_window_post_poseidon_circuit<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
) -> FallbackPoStCircuit<Tree> {
    let post_config = PoStConfig {
        sector_size: SectorSize(sector_size),
        challenge_count: WINDOW_POST_CHALLENGE_COUNT,
        sector_count: *WINDOW_POST_SECTOR_COUNT
            .read()
            .unwrap()
            .get(&sector_size)
            .unwrap(),
        typ: PoStType::Window,
        priority: false,
    };

    let public_params = window_post_public_params::<Tree>(&post_config).unwrap();

    <FallbackPoStCompound<Tree> as CompoundProof<
        FallbackPoSt<Tree>,
        FallbackPoStCircuit<Tree>,
    >>::blank_circuit(&public_params)
}
/*
fn blank_fallback_post_sha_pedersen_circuit(sector_size: u64) -> ... {}
*/

/// Creates the first phase2 parameters for a circuit and writes them to a file.
fn create_initial_params<Tree: 'static + MerkleTreeTrait>(
    proof: Proof,
    hasher: Hasher,
    sector_size: u64,
) {
    let start_total = Instant::now();

    info!(
        "creating initial params for circuit: {} {} {} {}",
        proof,
        hasher,
        display_sector_size(sector_size),
        get_head_commit()
    );

    let params_path = initial_params_filename(proof, hasher, sector_size);
    let params_file = File::create(&params_path).unwrap();
    let mut params_writer = BufWriter::with_capacity(1024 * 1024, params_file);

    let dt_create_circuit: u64;
    let dt_create_params: u64;

    let params = match (proof, hasher) {
        (Proof::Porep, Hasher::Poseidon) => {
            let start = Instant::now();
            let circuit = blank_porep_poseidon_circuit::<Tree>(sector_size);
            dt_create_circuit = start.elapsed().as_secs();
            let start = Instant::now();
            let params = phase2::MPCParameters::new(circuit).unwrap();
            dt_create_params = start.elapsed().as_secs();
            params
        }
        /*
        (Proof::Porep, Hasher::ShaPedersen) => {
            let start = Instant::now();
            let circuit = blank_porep_sha_pedersen_circuit(sector_size);
            dt_create_circuit = start.elapsed().as_secs();
            let start = Instant::now();
            let params = phase2::MPCParameters::new(circuit).unwrap();
            dt_create_params = start.elapsed().as_secs();
            params
        }
        */
        (Proof::WinningPost, Hasher::Poseidon) => {
            let start = Instant::now();
            let circuit = blank_winning_post_poseidon_circuit::<Tree>(sector_size);
            dt_create_circuit = start.elapsed().as_secs();
            let start = Instant::now();
            let params = phase2::MPCParameters::new(circuit).unwrap();
            dt_create_params = start.elapsed().as_secs();
            params
        }
        (Proof::WindowPost, Hasher::Poseidon) => {
            let start = Instant::now();
            let circuit = blank_window_post_poseidon_circuit::<Tree>(sector_size);
            dt_create_circuit = start.elapsed().as_secs();
            let start = Instant::now();
            let params = phase2::MPCParameters::new(circuit).unwrap();
            dt_create_params = start.elapsed().as_secs();
            params
        } /*(Proof::FallbackPost, Hasher::ShaPedersen) => { ... }
           */
    };

    info!(
        "successfully created initial params for circuit, dt_create_circuit={}s, dt_create_params={}s",
        dt_create_circuit,
        dt_create_params
    );

    info!("writing initial params to file: {}", params_path);
    params.write(&mut params_writer).unwrap();

    info!(
        "successfully created initial params for circuit: {} {} {} {}, dt_total={}s",
        proof,
        hasher,
        display_sector_size(sector_size),
        get_head_commit(),
        start_total.elapsed().as_secs()
    );
}

/// Prompt the user to mash on their keyboard to gather entropy.
fn prompt_for_randomness() -> [u8; 32] {
    use dialoguer::{theme::ColorfulTheme, Password};

    let raw = Password::with_theme(&ColorfulTheme::default())
        .with_prompt(
            "Please randomly press your keyboard for entropy (press Return/Enter when finished)",
        )
        .interact()
        .unwrap();

    let hashed = blake2b_simd::blake2b(raw.as_bytes());

    let mut seed = [0u8; 32];
    seed.copy_from_slice(&hashed.as_ref()[..32]);
    seed
}

/// Contributes entropy to the current phase2 parameters for a circuit, then writes the updated
/// parameters to a new file.
fn contribute_to_params(path_before: &str) {
    let start_total = Instant::now();

    let (proof, hasher, sector_size, head, param_number_before) =
        parse_params_filename(path_before);

    info!(
        "contributing randomness to params for circuit: {} {} {} {}",
        proof,
        hasher,
        display_sector_size(sector_size),
        head
    );

    assert_eq!(
        head,
        get_head_commit(),
        "cannot contribute to parameters using a different circuit version",
    );

    let seed = prompt_for_randomness();
    let mut rng = rand_chacha::ChaChaRng::from_seed(seed);

    info!("reading 'before' params from disk: {}", path_before);
    let file_before = File::open(path_before).unwrap();
    let mut params_reader = BufReader::with_capacity(1024 * 1024, file_before);
    let start = Instant::now();
    let mut params = phase2::MPCParameters::read(&mut params_reader, true).unwrap();
    info!(
        "successfully read 'before' params from disk, dt_read={}s",
        start.elapsed().as_secs()
    );

    info!("making contribution");
    let start = Instant::now();
    let contribution = params.contribute(&mut rng);
    info!(
        "successfully made contribution, contribution hash: {}, dt_contribute={}s",
        hex::encode(&contribution[..]),
        start.elapsed().as_secs()
    );

    let path_after = params_filename(proof, hasher, sector_size, &head, param_number_before + 1);
    info!("writing 'after' params to file: {}", path_after);
    let file_after = File::create(path_after).unwrap();
    let mut params_writer = BufWriter::with_capacity(1024 * 1024, file_after);
    params.write(&mut params_writer).unwrap();
    info!(
        "successfully made contribution, dt_total={}s",
        start_total.elapsed().as_secs()
    );
}

/// Verifies a sequence of parameter transitions against a sequence of corresponding contribution
/// hashes. For example, verifies that the first digest in `contribution_hashes` transitions the
/// first parameters file in `param_paths` to the second file, then verifies that the second
/// contribution hash transitions the second parameters file to the third file.
fn verify_param_transitions(param_paths: &[&str], contribution_hashes: &[[u8; 64]]) {
    let start_total = Instant::now();

    assert_eq!(
        param_paths.len() - 1,
        contribution_hashes.len(),
        "the number of contributions must be one less than the number of parameter files"
    );

    let mut next_params_before: Option<phase2::MPCParameters> = None;

    for (param_pair, provided_contribution_hash) in
        param_paths.windows(2).zip(contribution_hashes.iter())
    {
        let path_before = param_pair[0];
        let path_after = param_pair[1];

        info!(
            "verifying transition:\n\tparams: {} -> {}\n\tcontribution: {}",
            path_before,
            path_after,
            hex::encode(&provided_contribution_hash[..])
        );

        // If we are verifying the first contribution read both `path_before` and `path_after`
        // files. For every subsequent verification, move the previous loop's "after" params to this
        // loop's "before" params then read this loop's "after" params file. This will minimize the
        // number of expensive parameter file reads.
        let params_before = match next_params_before.take() {
            Some(params_before) => params_before,
            None => {
                info!("reading 'before' params from disk: {}", path_before);
                let file = File::open(path_before).unwrap();
                let mut reader = BufReader::with_capacity(1024 * 1024, file);
                let start = Instant::now();
                let params_before = phase2::MPCParameters::read(&mut reader, true).unwrap();
                info!(
                    "successfully read 'before' params from disk, dt_read={}s",
                    start.elapsed().as_secs()
                );
                params_before
            }
        };

        let params_after = {
            info!("reading 'after' params from disk: {}", path_after);
            let file = File::open(path_after).unwrap();
            let mut reader = BufReader::with_capacity(1024 * 1024, file);
            let start = Instant::now();
            let params_after = phase2::MPCParameters::read(&mut reader, true).unwrap();
            info!(
                "successfully read 'after' params from disk, dt_read={}s",
                start.elapsed().as_secs()
            );
            params_after
        };

        info!("verifying param transition");
        let start_verification = Instant::now();

        let calculated_contribution_hash =
            phase2::verify_contribution(&params_before, &params_after).expect("invalid transition");

        assert_eq!(
            &provided_contribution_hash[..],
            &calculated_contribution_hash[..],
            "provided contribution hash ({}) does not match calculated contribution hash ({})",
            hex::encode(&provided_contribution_hash[..]),
            hex::encode(&calculated_contribution_hash[..]),
        );

        info!(
            "successfully verified param transition, dt_verify={}s",
            start_verification.elapsed().as_secs()
        );

        next_params_before = Some(params_after);
    }

    info!(
        "successfully verified all param transitions, dt_total={}s",
        start_total.elapsed().as_secs()
    );
}

fn verify_param_transistions_daemon(proof: Proof, hasher: Hasher, sector_size: u64) {
    const SLEEP_SECS: u64 = 10;

    let head = get_head_commit();

    info!(
        "starting the verification daemon for the circuit: {} {} {} {}",
        proof,
        hasher,
        display_sector_size(sector_size),
        head
    );

    let mut next_before_params: Option<MPCParameters> = None;
    let mut next_before_filename: Option<String> = None;
    let mut param_number: usize = 0;

    loop {
        let (before_params, before_filename) = if next_before_params.is_some() {
            let before_params = next_before_params.take().unwrap();
            let before_filename = next_before_filename.take().unwrap();
            (before_params, before_filename)
        } else {
            let before_filename = params_filename(proof, hasher, sector_size, &head, param_number);
            let before_path = Path::new(&before_filename);
            if !before_path.exists() {
                info!("waiting for params file: {}", before_filename);
                while !before_path.exists() {
                    sleep(Duration::from_secs(SLEEP_SECS));
                }
            }
            info!("found file: {}", before_filename);
            info!("reading params file: {}", before_filename);
            let file = File::open(&before_path).unwrap();
            let mut reader = BufReader::with_capacity(1024 * 1024, file);
            let read_start = Instant::now();
            let before_params = MPCParameters::read(&mut reader, true).unwrap();
            info!(
                "successfully read params, dt_read={}s",
                read_start.elapsed().as_secs()
            );
            param_number += 1;
            (before_params, before_filename)
        };

        let after_filename = params_filename(proof, hasher, sector_size, &head, param_number);
        let after_path = Path::new(&after_filename);

        if !after_path.exists() {
            info!("waiting for params file: {}", after_filename);
            while !after_path.exists() {
                sleep(Duration::from_secs(SLEEP_SECS));
            }
        }
        info!("found file: {}", after_filename);

        let after_params = {
            info!("reading params file: {}", after_filename);
            let file = File::open(&after_path).unwrap();
            let mut reader = BufReader::with_capacity(1024 * 1024, file);
            let read_start = Instant::now();
            let params = MPCParameters::read(&mut reader, true).unwrap();
            info!(
                "successfully read params, dt_read={}s",
                read_start.elapsed().as_secs()
            );
            param_number += 1;
            params
        };

        let contribution_hash_filename = format!("{}_contribution", after_filename);
        let contribution_hash_path = Path::new(&contribution_hash_filename);

        if !contribution_hash_path.exists() {
            info!(
                "waiting for contribution hash file: {}",
                contribution_hash_filename
            );
            while !contribution_hash_path.exists() {
                sleep(Duration::from_secs(SLEEP_SECS));
            }
        }
        info!("found file: {}", contribution_hash_filename);

        let hex_str = fs::read_to_string(&contribution_hash_path)
            .expect("failed to read contribution hash file")
            .trim()
            .to_string();

        let provided_contribution_hash = {
            let mut arr = [0u8; 64];
            let vec = hex::decode(&hex_str).unwrap_or_else(|_| {
                panic!("contribution hash is not a valid hex string: {}", hex_str)
            });
            info!("parsed contribution hash");
            arr.copy_from_slice(&vec[..]);
            arr
        };

        info!(
            "verifying param transition:\n\t{} -> {}\n\t{}",
            before_filename, after_filename, hex_str
        );

        let start_verification = Instant::now();

        let calculated_contribution_hash =
            verify_contribution(&before_params, &after_params).expect("invalid transition");

        assert_eq!(
            &provided_contribution_hash[..],
            &calculated_contribution_hash[..],
            "provided contribution hash ({}) does not match calculated contribution hash ({})",
            hex_str,
            hex::encode(&calculated_contribution_hash[..]),
        );

        info!(
            "successfully verified param transition, dt_verify={}s\n",
            start_verification.elapsed().as_secs()
        );

        next_before_params = Some(after_params);
        next_before_filename = Some(after_filename);
    }
}

/// Creates the logger for the "new" CLI subcommand. Writes info logs to stdout, error logs to
/// stderr, and all logs to the file: `<proof>_<hasher>_<sector-size>_<head>_0.log`.
fn setup_new_logger(proof: Proof, hasher: Hasher, sector_size: u64) {
    let log_filename = format!(
        "{}.log",
        initial_params_filename(proof, hasher, sector_size)
    );

    let log_file = File::create(&log_filename)
        .unwrap_or_else(|_| panic!("failed to create log file: {}", log_filename));

    CombinedLogger::init(vec![
        TermLogger::new(
            LevelFilter::Info,
            simplelog::Config::default(),
            TerminalMode::Mixed,
        )
        .unwrap(),
        WriteLogger::new(LevelFilter::Info, simplelog::Config::default(), log_file),
    ])
    .expect("failed to setup logger");
}

/// Creates the logger for the "contribute" CLI subcommand. Writes info logs to stdout, error logs
/// to stderr, and all logs to the file:
/// `<proof>_<hasher>_<sector-size>_<head>_<param number containing contribution>.log`.
fn setup_contribute_logger(path_before: &str) {
    let (proof, hasher, sector_size, head, param_number_before) =
        parse_params_filename(path_before);

    let mut log_filename =
        params_filename(proof, hasher, sector_size, &head, param_number_before + 1);

    log_filename.push_str(".log");

    let log_file = File::create(&log_filename)
        .unwrap_or_else(|_| panic!("failed to create log file: {}", log_filename));

    CombinedLogger::init(vec![
        TermLogger::new(
            LevelFilter::Info,
            simplelog::Config::default(),
            TerminalMode::Mixed,
        )
        .unwrap(),
        WriteLogger::new(LevelFilter::Info, simplelog::Config::default(), log_file),
    ])
    .expect("failed to setup logger");
}

/// Creates the logger for the "contribute" CLI subcommand. Writes info logs to stdout, error logs
/// to stderr, and all logs to the file:
/// <proof>_<hasher>_<sector-size>_<head>_verify_<first param number>_<last param number>.log
fn setup_verify_logger(param_paths: &[&str]) {
    let (proof, hasher, sector_size, head, first_param_number) =
        parse_params_filename(param_paths.first().unwrap());

    let last_param_number = parse_params_filename(param_paths.last().unwrap()).4;

    let mut log_filename = format!(
        "{}_{}_{}_{}_verify_{}_{}.log",
        proof,
        hasher,
        display_sector_size(sector_size),
        head,
        first_param_number,
        last_param_number
    );
    log_filename.make_ascii_lowercase();
    let log_filename = log_filename.replace("-", "_");

    let log_file = File::create(&log_filename)
        .unwrap_or_else(|_| panic!("failed to create log file: {}", log_filename));

    CombinedLogger::init(vec![
        TermLogger::new(
            LevelFilter::Info,
            simplelog::Config::default(),
            TerminalMode::Mixed,
        )
        .unwrap(),
        WriteLogger::new(LevelFilter::Info, simplelog::Config::default(), log_file),
    ])
    .expect("failed to setup logger");
}

/// Setup the logger for the `verifyd` CLI subcommand. Writes info logs to stdout, error logs to
/// stderr, and all logs to the file: <proof>_<hasher>_<sector-size>_<head>_verifyd.log
fn setup_verifyd_logger(proof: Proof, hasher: Hasher, sector_size: u64) {
    let mut log_filename = format!(
        "{}_{}_{}_{}_verifyd.log",
        proof,
        hasher,
        display_sector_size(sector_size),
        &get_head_commit(),
    );
    log_filename.make_ascii_lowercase();
    let log_filename = log_filename.replace("-", "_");

    let log_file = File::create(&log_filename)
        .unwrap_or_else(|_| panic!("failed to create log file: {}", log_filename));

    CombinedLogger::init(vec![
        TermLogger::new(
            LevelFilter::Info,
            simplelog::Config::default(),
            TerminalMode::Mixed,
        )
        .unwrap(),
        WriteLogger::new(LevelFilter::Info, simplelog::Config::default(), log_file),
    ])
    .expect("failed to setup logger");
}

#[allow(clippy::cognitive_complexity)]
fn main() {
    let new_command = SubCommand::with_name("new")
        .about("Create parameters")
        .arg(
            Arg::with_name("porep")
                .long("porep")
                .help("Generate PoRep parameters"),
        )
        .arg(
            Arg::with_name("winning-post")
                .long("winning-post")
                .help("Generate WinningPoSt parameters"),
        )
        .arg(
            Arg::with_name("window-post")
                .long("window-post")
                .help("Generate WindowPoSt parameters"),
        )
        .group(
            ArgGroup::with_name("proof")
                .args(&["porep", "winning-post", "window-post"])
                .required(true)
                .multiple(false),
        )
        .arg(
            Arg::with_name("poseidon")
                .long("poseidon")
                .help("Use the Poseidon hash function for column commitments and Merkle trees"),
        )
        /*
        .arg(
            Arg::with_name("sha-pedersen")
                .long("sha-pedersen")
                .help("Use SHA256 for column commitments and Pedersen hash for Merkle trees"),
        )
        */
        .group(
            ArgGroup::with_name("hasher")
                .args(&["poseidon"])
                .required(false), /*
                                  .args(&["poseidon", "sha-pedersen"])
                                  .required(true)
                                  .multiple(false),
                                  */
        )
        .arg(
            Arg::with_name("2kib")
                .long("2kib")
                .help("Use circuits with 2KiB sector sizes"),
        )
        .arg(
            Arg::with_name("8mib")
                .long("8mib")
                .help("Use circuits with 16MiB sector sizes"),
        )
        .arg(
            Arg::with_name("512mib")
                .long("512mib")
                .help("Use circuits with 256MiB sector sizes"),
        )
        .arg(
            Arg::with_name("32gib")
                .long("32gib")
                .help("Use circuits with 32GiB sector sizes"),
        )
        .arg(
            Arg::with_name("64gib")
                .long("64gib")
                .help("Use circuits with 64GiB sector sizes"),
        )
        .group(
            ArgGroup::with_name("sector-size")
                .args(&["2kib", "8mib", "512mib", "32gib", "64gib"])
                .required(true)
                .multiple(false),
        );

    let contribute_command = SubCommand::with_name("contribute")
        .about("Contribute to parameters")
        .arg(
            Arg::with_name("path-before")
                .index(1)
                .required(true)
                .help("The path to the parameters file to read and contribute to"),
        );

    let verify_command = SubCommand::with_name("verify")
        .about("Verify that a set of contribution hashes correctly transition a set of params")
        .arg(
            Arg::with_name("paths")
                .long("paths")
                .required(true)
                .takes_value(true)
                .value_delimiter(",")
                .min_values(2)
                .help("Comma separated list (no whitespace between items) of paths to parameter files"),
        )
        .arg(
            Arg::with_name("contributions")
                .long("contributions")
                .required(true)
                .takes_value(true)
                .case_insensitive(true)
                .value_delimiter(",")
                .min_values(1)
                .help(
                    "An ordered (first to most recent) comma separated list of hex-encoded \
                    contribution hashes. There must be no whitespace in any of the digest strings \
                    or between any items in the list. Each digest must be 128 characters long \
                    (i.e. each digest hex string encodes 64 bytes), digest strings can use upper \
                    or lower case hex characters."
                ),
        );

    let verifyd_command = SubCommand::with_name("verifyd")
        .about("Run the param verification daemon")
        .arg(
            Arg::with_name("porep")
                .long("porep")
                .help("Generate PoRep parameters"),
        )
        .arg(
            Arg::with_name("winning-post")
                .long("winning-post")
                .help("Generate WinningPoSt parameters"),
        )
        .arg(
            Arg::with_name("window-post")
                .long("window-post")
                .help("Generate WindowPoSt parameters"),
        )
        .group(
            ArgGroup::with_name("proof")
                .args(&["porep", "winning-post", "window-post"])
                .required(true)
                .multiple(false),
        )
        .arg(
            Arg::with_name("poseidon")
                .long("poseidon")
                .help("Use the Poseidon hash function for column commitments and Merkle trees"),
        )
        /*
        .arg(
            Arg::with_name("sha-pedersen")
                .long("sha-pedersen")
                .help("Use SHA256 for column commitments and Pedersen hash for Merkle trees"),
        )
        */
        .group(
            ArgGroup::with_name("hasher")
                .args(&["poseidon"])
                .required(false), /*
                                  .args(&["poseidon", "sha-pedersen"])
                                  .required(true)
                                  .multiple(false),
                                  */
        )
        .arg(
            Arg::with_name("2kib")
                .long("2kib")
                .help("Use circuits with 2KiB sector sizes"),
        )
        .arg(
            Arg::with_name("8mib")
                .long("8mib")
                .help("Use circuits with 16MiB sector sizes"),
        )
        .arg(
            Arg::with_name("512mib")
                .long("512mib")
                .help("Use circuits with 256MiB sector sizes"),
        )
        .arg(
            Arg::with_name("32gib")
                .long("32gib")
                .help("Use circuits with 32GiB sector sizes"),
        )
        .arg(
            Arg::with_name("64gib")
                .long("64gib")
                .help("Use circuits with 64GiB sector sizes"),
        )
        .group(
            ArgGroup::with_name("sector-size")
                .args(&["2kib", "8mib", "512mib", "32gib", "64gib"])
                .required(true)
                .multiple(false),
        );

    let matches = App::new("phase2")
        .version("1.0")
        .setting(AppSettings::ArgRequiredElseHelp)
        .setting(AppSettings::SubcommandRequired)
        .subcommand(new_command)
        .subcommand(contribute_command)
        .subcommand(verify_command)
        .subcommand(verifyd_command)
        .get_matches();

    if let (subcommand, Some(matches)) = matches.subcommand() {
        match subcommand {
            "new" => {
                let proof = if matches.is_present("porep") {
                    Proof::Porep
                } else if matches.is_present("winning-post") {
                    Proof::WinningPost
                } else {
                    Proof::WindowPost
                };

                // Default to using Poseidon for the hasher.
                let hasher = Hasher::Poseidon;
                /*
                let hasher = if matches.is_present("sha-pedersen") {
                    Hasher::ShaPedersen
                } else {
                    Hasher::Poseidon
                };
                */

                let sector_size = if matches.is_present("2kib") {
                    SECTOR_SIZE_2_KIB
                } else if matches.is_present("8mib") {
                    SECTOR_SIZE_8_MIB
                } else if matches.is_present("512mib") {
                    SECTOR_SIZE_512_MIB
                } else if matches.is_present("32gib") {
                    SECTOR_SIZE_32_GIB
                } else {
                    SECTOR_SIZE_64_GIB
                };

                setup_new_logger(proof, hasher, sector_size);
                with_shape!(
                    sector_size,
                    create_initial_params,
                    proof,
                    hasher,
                    sector_size
                );
            }
            "contribute" => {
                let path_before = matches.value_of("path-before").unwrap();
                setup_contribute_logger(path_before);
                contribute_to_params(path_before);
            }
            "verify" => {
                let param_paths: Vec<&str> = matches.values_of("paths").unwrap().collect();

                let contribution_hashes: Vec<[u8; 64]> = matches
                    .values_of("contributions")
                    .unwrap()
                    .map(|hex_str| {
                        let mut digest_bytes_arr = [0u8; 64];
                        let digest_bytes_vec = hex::decode(hex_str).unwrap_or_else(|_| {
                            panic!("contribution hash is not a valid hex string: {}", hex_str)
                        });
                        digest_bytes_arr.copy_from_slice(&digest_bytes_vec[..]);
                        digest_bytes_arr
                    })
                    .collect();

                setup_verify_logger(&param_paths);
                verify_param_transitions(&param_paths, &contribution_hashes);
            }
            "verifyd" => {
                let proof = if matches.is_present("porep") {
                    Proof::Porep
                } else if matches.is_present("winning-post") {
                    Proof::WinningPost
                } else {
                    Proof::WindowPost
                };

                // Default to using Poseidon for the hasher.
                let hasher = Hasher::Poseidon;
                /*
                let hasher = if matches.is_present("sha-pedersen") {
                    Hasher::ShaPedersen
                } else {
                    Hasher::Poseidon
                };
                */

                let sector_size = if matches.is_present("2kib") {
                    SECTOR_SIZE_2_KIB
                } else if matches.is_present("8mib") {
                    SECTOR_SIZE_8_MIB
                } else if matches.is_present("512mib") {
                    SECTOR_SIZE_512_MIB
                } else if matches.is_present("32gib") {
                    SECTOR_SIZE_32_GIB
                } else {
                    SECTOR_SIZE_64_GIB
                };

                setup_verifyd_logger(proof, hasher, sector_size);
                verify_param_transistions_daemon(proof, hasher, sector_size);
            }
            _ => unreachable!(),
        }
    }
}

'''
'''--- filecoin-proofs/src/caches.rs ---
use std::collections::HashMap;
use std::sync::Arc;
use std::sync::Mutex;

use anyhow::Result;
use bellperson::groth16;
use lazy_static::lazy_static;
use log::info;
use paired::bls12_381::Bls12;
use storage_proofs::compound_proof::CompoundProof;
use storage_proofs::porep::stacked::{StackedCompound, StackedDrg};
use storage_proofs::post::fallback;

use crate::constants::DefaultPieceHasher;
use crate::parameters::{public_params, window_post_public_params, winning_post_public_params};
use crate::types::*;

type Bls12GrothParams = groth16::MappedParameters<Bls12>;
pub type Bls12VerifyingKey = groth16::VerifyingKey<Bls12>;

type Cache<G> = HashMap<String, Arc<G>>;
type GrothMemCache = Cache<Bls12GrothParams>;
type VerifyingKeyMemCache = Cache<Bls12VerifyingKey>;

lazy_static! {
    static ref GROTH_PARAM_MEMORY_CACHE: Mutex<GrothMemCache> = Default::default();
    static ref VERIFYING_KEY_MEMORY_CACHE: Mutex<VerifyingKeyMemCache> = Default::default();
}

pub fn cache_lookup<F, G>(
    cache_ref: &Mutex<Cache<G>>,
    identifier: String,
    generator: F,
) -> Result<Arc<G>>
where
    F: FnOnce() -> Result<G>,
    G: Send + Sync,
{
    info!("trying parameters memory cache for: {}", &identifier);
    {
        let cache = (*cache_ref).lock().unwrap();

        if let Some(entry) = cache.get(&identifier) {
            info!("found params in memory cache for {}", &identifier);
            return Ok(entry.clone());
        }
    }

    info!("no params in memory cache for {}", &identifier);

    let new_entry = Arc::new(generator()?);
    let res = new_entry.clone();
    {
        let cache = &mut (*cache_ref).lock().unwrap();
        cache.insert(identifier, new_entry);
    }

    Ok(res)
}

#[inline]
pub fn lookup_groth_params<F>(identifier: String, generator: F) -> Result<Arc<Bls12GrothParams>>
where
    F: FnOnce() -> Result<Bls12GrothParams>,
{
    cache_lookup(&*GROTH_PARAM_MEMORY_CACHE, identifier, generator)
}

#[inline]
pub fn lookup_verifying_key<F>(identifier: String, generator: F) -> Result<Arc<Bls12VerifyingKey>>
where
    F: FnOnce() -> Result<Bls12VerifyingKey>,
{
    let vk_identifier = format!("{}-verifying-key", &identifier);
    cache_lookup(&*VERIFYING_KEY_MEMORY_CACHE, vk_identifier, generator)
}

pub fn get_stacked_params<Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
) -> Result<Arc<Bls12GrothParams>> {
    let public_params = public_params::<Tree>(
        PaddedBytesAmount::from(porep_config),
        usize::from(PoRepProofPartitions::from(porep_config)),
    )?;

    let parameters_generator = || {
        <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
            StackedDrg<Tree, DefaultPieceHasher>,
            _,
        >>::groth_params::<rand::rngs::OsRng>(None, &public_params)
        .map_err(Into::into)
    };

    Ok(lookup_groth_params(
        format!(
            "STACKED[{}]",
            usize::from(PaddedBytesAmount::from(porep_config))
        ),
        parameters_generator,
    )?)
}

pub fn get_post_params<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
) -> Result<Arc<Bls12GrothParams>> {
    match post_config.typ {
        PoStType::Winning => {
            let post_public_params = winning_post_public_params::<Tree>(post_config)?;

            let parameters_generator = || {
                <fallback::FallbackPoStCompound<Tree> as CompoundProof<
                    fallback::FallbackPoSt<Tree>,
                    fallback::FallbackPoStCircuit<Tree>,
                >>::groth_params::<rand::rngs::OsRng>(None, &post_public_params)
                .map_err(Into::into)
            };

            Ok(lookup_groth_params(
                format!(
                    "WINNING_POST[{}]",
                    usize::from(post_config.padded_sector_size())
                ),
                parameters_generator,
            )?)
        }
        PoStType::Window => {
            let post_public_params = window_post_public_params::<Tree>(post_config)?;

            let parameters_generator = || {
                <fallback::FallbackPoStCompound<Tree> as CompoundProof<
                    fallback::FallbackPoSt<Tree>,
                    fallback::FallbackPoStCircuit<Tree>,
                >>::groth_params::<rand::rngs::OsRng>(None, &post_public_params)
                .map_err(Into::into)
            };

            Ok(lookup_groth_params(
                format!(
                    "Window_POST[{}]",
                    usize::from(post_config.padded_sector_size())
                ),
                parameters_generator,
            )?)
        }
    }
}

pub fn get_stacked_verifying_key<Tree: 'static + MerkleTreeTrait>(
    porep_config: PoRepConfig,
) -> Result<Arc<Bls12VerifyingKey>> {
    let public_params = public_params(
        PaddedBytesAmount::from(porep_config),
        usize::from(PoRepProofPartitions::from(porep_config)),
    )?;

    let vk_generator = || {
        <StackedCompound<Tree, DefaultPieceHasher> as CompoundProof<
            StackedDrg<Tree, DefaultPieceHasher>,
            _,
        >>::verifying_key::<rand::rngs::OsRng>(None, &public_params)
        .map_err(Into::into)
    };

    Ok(lookup_verifying_key(
        format!(
            "STACKED[{}]",
            usize::from(PaddedBytesAmount::from(porep_config))
        ),
        vk_generator,
    )?)
}

pub fn get_post_verifying_key<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
) -> Result<Arc<Bls12VerifyingKey>> {
    match post_config.typ {
        PoStType::Winning => {
            let post_public_params = winning_post_public_params::<Tree>(post_config)?;

            let vk_generator = || {
                <fallback::FallbackPoStCompound<Tree> as CompoundProof<
                    fallback::FallbackPoSt<Tree>,
                    fallback::FallbackPoStCircuit<Tree>,
                >>::verifying_key::<rand::rngs::OsRng>(None, &post_public_params)
                .map_err(Into::into)
            };

            Ok(lookup_verifying_key(
                format!(
                    "WINNING_POST[{}]",
                    usize::from(post_config.padded_sector_size())
                ),
                vk_generator,
            )?)
        }
        PoStType::Window => {
            let post_public_params = window_post_public_params::<Tree>(post_config)?;

            let vk_generator = || {
                <fallback::FallbackPoStCompound<Tree> as CompoundProof<
                    fallback::FallbackPoSt<Tree>,
                    fallback::FallbackPoStCircuit<Tree>,
                >>::verifying_key::<rand::rngs::OsRng>(None, &post_public_params)
                .map_err(Into::into)
            };

            Ok(lookup_verifying_key(
                format!(
                    "WINDOW_POST[{}]",
                    usize::from(post_config.padded_sector_size())
                ),
                vk_generator,
            )?)
        }
    }
}

'''
'''--- filecoin-proofs/src/commitment_reader.rs ---
use std::io::{self, Read};

use anyhow::{ensure, Result};
use rayon::prelude::*;
use storage_proofs::hasher::{HashFunction, Hasher};

use crate::constants::DefaultPieceHasher;

/// Calculates comm-d of the data piped through to it.
/// Data must be bit padded and power of 2 bytes.
pub struct CommitmentReader<R> {
    source: R,
    buffer: [u8; 64],
    buffer_pos: usize,
    current_tree: Vec<<DefaultPieceHasher as Hasher>::Domain>,
}

impl<R: Read> CommitmentReader<R> {
    pub fn new(source: R) -> Self {
        CommitmentReader {
            source,
            buffer: [0u8; 64],
            buffer_pos: 0,
            current_tree: Vec::new(),
        }
    }

    /// Attempt to generate the next hash, but only if the buffers are full.
    fn try_hash(&mut self) {
        if self.buffer_pos < 63 {
            return;
        }

        // WARNING: keep in sync with DefaultPieceHasher and its .node impl
        let hash = <DefaultPieceHasher as Hasher>::Function::hash(&self.buffer);
        self.current_tree.push(hash);
        self.buffer_pos = 0;

        // TODO: reduce hashes when possible, instead of keeping them around.
    }

    pub fn finish(self) -> Result<<DefaultPieceHasher as Hasher>::Domain> {
        ensure!(self.buffer_pos == 0, "not enough inputs provided");

        let CommitmentReader { current_tree, .. } = self;

        let mut current_row = current_tree;

        while current_row.len() > 1 {
            let next_row = current_row
                .par_chunks(2)
                .map(|chunk| crate::pieces::piece_hash(chunk[0].as_ref(), chunk[1].as_ref()))
                .collect::<Vec<_>>();

            current_row = next_row;
        }
        debug_assert_eq!(current_row.len(), 1);

        Ok(current_row.into_iter().next().unwrap())
    }
}

impl<R: Read> Read for CommitmentReader<R> {
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        let start = self.buffer_pos;
        let left = 64 - self.buffer_pos;
        let end = start + std::cmp::min(left, buf.len());

        // fill the buffer as much as possible
        let r = self.source.read(&mut self.buffer[start..end])?;

        // write the data, we read
        buf[..r].copy_from_slice(&self.buffer[start..start + r]);

        self.buffer_pos += r;

        // try to hash
        self.try_hash();

        Ok(r)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::types::*;

    use storage_proofs::pieces::generate_piece_commitment_bytes_from_source;

    #[test]
    fn test_commitment_reader() {
        let piece_size = 127 * 8;
        let source = vec![255u8; piece_size];
        let mut fr32_reader = crate::fr32_reader::Fr32Reader::new(io::Cursor::new(&source));

        let commitment1 = generate_piece_commitment_bytes_from_source::<DefaultPieceHasher>(
            &mut fr32_reader,
            PaddedBytesAmount::from(UnpaddedBytesAmount(piece_size as u64)).into(),
        )
        .unwrap();

        let fr32_reader = crate::fr32_reader::Fr32Reader::new(io::Cursor::new(&source));
        let mut commitment_reader = CommitmentReader::new(fr32_reader);
        io::copy(&mut commitment_reader, &mut io::sink()).unwrap();

        let commitment2 = commitment_reader.finish().unwrap();

        assert_eq!(&commitment1[..], AsRef::<[u8]>::as_ref(&commitment2));
    }
}

'''
'''--- filecoin-proofs/src/constants.rs ---
use std::collections::HashMap;
use std::sync::RwLock;

use lazy_static::lazy_static;
use storage_proofs::hasher::Hasher;
use storage_proofs::util::NODE_SIZE;
use typenum::{U0, U2, U8};

use crate::param::{ParameterData, ParameterMap};
use crate::types::UnpaddedBytesAmount;

pub const SECTOR_SIZE_2_KIB: u64 = 1 << 11;
pub const SECTOR_SIZE_4_KIB: u64 = 1 << 12;
pub const SECTOR_SIZE_16_KIB: u64 = 1 << 14;
pub const SECTOR_SIZE_32_KIB: u64 = 1 << 15;
pub const SECTOR_SIZE_8_MIB: u64 = 1 << 23;
pub const SECTOR_SIZE_16_MIB: u64 = 1 << 24;
pub const SECTOR_SIZE_512_MIB: u64 = 1 << 29;
pub const SECTOR_SIZE_1_GIB: u64 = 1 << 30;
pub const SECTOR_SIZE_32_GIB: u64 = 1 << 35;
pub const SECTOR_SIZE_64_GIB: u64 = 1 << 36;

pub const WINNING_POST_CHALLENGE_COUNT: usize = 66;
pub const WINNING_POST_SECTOR_COUNT: usize = 1;

pub const WINDOW_POST_CHALLENGE_COUNT: usize = 10;

pub const DRG_DEGREE: usize = storage_proofs::drgraph::BASE_DEGREE;
pub const EXP_DEGREE: usize = storage_proofs::porep::stacked::EXP_DEGREE;

lazy_static! {
    pub static ref PARAMETERS: ParameterMap =
        serde_json::from_str(include_str!("../parameters.json")).expect("Invalid parameters.json");
    pub static ref POREP_MINIMUM_CHALLENGES: RwLock<HashMap<u64, u64>> = RwLock::new(
        [
            (SECTOR_SIZE_2_KIB, 2),
            (SECTOR_SIZE_4_KIB, 2),
            (SECTOR_SIZE_16_KIB, 2),
            (SECTOR_SIZE_32_KIB, 2),
            (SECTOR_SIZE_8_MIB, 2),
            (SECTOR_SIZE_16_MIB, 2),
            (SECTOR_SIZE_512_MIB, 2),
            (SECTOR_SIZE_1_GIB, 2),
            (SECTOR_SIZE_32_GIB, 138),
            (SECTOR_SIZE_64_GIB, 138),
        ]
        .iter()
        .copied()
        .collect()
    );
    pub static ref POREP_PARTITIONS: RwLock<HashMap<u64, u8>> = RwLock::new(
        [
            (SECTOR_SIZE_2_KIB, 1),
            (SECTOR_SIZE_4_KIB, 1),
            (SECTOR_SIZE_16_KIB, 1),
            (SECTOR_SIZE_32_KIB, 1),
            (SECTOR_SIZE_8_MIB, 1),
            (SECTOR_SIZE_16_MIB, 1),
            (SECTOR_SIZE_512_MIB, 1),
            (SECTOR_SIZE_1_GIB, 1),
            (SECTOR_SIZE_32_GIB, 8),
            (SECTOR_SIZE_64_GIB, 8),
        ]
        .iter()
        .copied()
        .collect()
    );
    pub static ref LAYERS: RwLock<HashMap<u64, usize>> = RwLock::new(
        [
            (SECTOR_SIZE_2_KIB, 2),
            (SECTOR_SIZE_4_KIB, 2),
            (SECTOR_SIZE_16_KIB, 2),
            (SECTOR_SIZE_32_KIB, 2),
            (SECTOR_SIZE_8_MIB, 2),
            (SECTOR_SIZE_16_MIB, 2),
            (SECTOR_SIZE_512_MIB, 2),
            (SECTOR_SIZE_1_GIB, 2),
            (SECTOR_SIZE_32_GIB, 11),
            (SECTOR_SIZE_64_GIB, 11),
        ]
        .iter()
        .copied()
        .collect()
    );
    // These numbers must match those used for Window PoSt scheduling in the miner actor.
    // Please coordinate changes with actor code.
    // https://github.com/filecoin-project/specs-actors/blob/master/actors/abi/sector.go
    pub static ref WINDOW_POST_SECTOR_COUNT: RwLock<HashMap<u64, usize>> = RwLock::new(
        [
            (SECTOR_SIZE_2_KIB, 2),
            (SECTOR_SIZE_4_KIB, 2),
            (SECTOR_SIZE_16_KIB, 2),
            (SECTOR_SIZE_32_KIB, 2),
            (SECTOR_SIZE_8_MIB, 2),
            (SECTOR_SIZE_16_MIB, 2),
            (SECTOR_SIZE_512_MIB, 2),
            (SECTOR_SIZE_1_GIB, 2),
            (SECTOR_SIZE_32_GIB, 2349), // this gives 133,977,564 constraints, fitting just in a single partition
            (SECTOR_SIZE_64_GIB, 2300), // this gives 131,182,800 constraints, fitting just in a single partition
        ]
        .iter()
        .copied()
        .collect()
    );
}

/// The size of a single snark proof.
pub const SINGLE_PARTITION_PROOF_LEN: usize = 192;

pub const MINIMUM_RESERVED_LEAVES_FOR_PIECE_IN_SECTOR: u64 = 4;

// Bit padding causes bytes to only be aligned at every 127 bytes (for 31.75 bytes).
pub const MINIMUM_RESERVED_BYTES_FOR_PIECE_IN_FULLY_ALIGNED_SECTOR: u64 =
    (MINIMUM_RESERVED_LEAVES_FOR_PIECE_IN_SECTOR * NODE_SIZE as u64) - 1;

/// The minimum size a single piece must have before padding.
pub const MIN_PIECE_SIZE: UnpaddedBytesAmount = UnpaddedBytesAmount(127);

/// The hasher used for creating comm_d.
pub type DefaultPieceHasher = storage_proofs::hasher::Sha256Hasher;
pub type DefaultPieceDomain = <DefaultPieceHasher as Hasher>::Domain;

/// The default hasher for merkle trees currently in use.
pub type DefaultTreeHasher = storage_proofs::hasher::PoseidonHasher;
pub type DefaultTreeDomain = <DefaultTreeHasher as Hasher>::Domain;

pub type DefaultBinaryTree = storage_proofs::merkle::BinaryMerkleTree<DefaultTreeHasher>;
pub type DefaultOctTree = storage_proofs::merkle::OctMerkleTree<DefaultTreeHasher>;
pub type DefaultOctLCTree = storage_proofs::merkle::OctLCMerkleTree<DefaultTreeHasher>;

pub type SectorShape2KiB = LCTree<DefaultTreeHasher, U8, U0, U0>;
pub type SectorShape4KiB = LCTree<DefaultTreeHasher, U8, U2, U0>;
pub type SectorShape16KiB = LCTree<DefaultTreeHasher, U8, U8, U0>;
pub type SectorShape32KiB = LCTree<DefaultTreeHasher, U8, U8, U2>;
pub type SectorShape8MiB = LCTree<DefaultTreeHasher, U8, U0, U0>;
pub type SectorShape16MiB = LCTree<DefaultTreeHasher, U8, U2, U0>;
pub type SectorShape512MiB = LCTree<DefaultTreeHasher, U8, U0, U0>;
pub type SectorShape1GiB = LCTree<DefaultTreeHasher, U8, U2, U0>;
pub type SectorShape32GiB = LCTree<DefaultTreeHasher, U8, U8, U0>;
pub type SectorShape64GiB = LCTree<DefaultTreeHasher, U8, U8, U2>;

pub use storage_proofs::merkle::{DiskTree, LCTree};

/// Get the correct parameter data for a given cache id.
pub fn get_parameter_data(cache_id: &str) -> Option<&ParameterData> {
    PARAMETERS.get(&parameter_id(cache_id))
}

fn parameter_id(cache_id: &str) -> String {
    format!(
        "v{}-{}.params",
        storage_proofs::parameter_cache::VERSION,
        cache_id
    )
}

/// Calls a function with the type hint of the sector shape matching the provided sector.
/// Panics if provided with an unknown sector size.
#[macro_export]
macro_rules! with_shape {
    ($size:expr, $f:ident) => {
        with_shape!($size, $f,)
    };
    ($size:expr, $f:ident, $($args:expr,)*) => {
        match $size {
            _x if $size == $crate::constants::SECTOR_SIZE_2_KIB => {
              $f::<$crate::constants::SectorShape2KiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_4_KIB => {
              $f::<$crate::constants::SectorShape4KiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_16_KIB => {
              $f::<$crate::constants::SectorShape16KiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_32_KIB => {
              $f::<$crate::constants::SectorShape32KiB>($($args),*)
            },
            _xx if $size == $crate::constants::SECTOR_SIZE_8_MIB => {
              $f::<$crate::constants::SectorShape8MiB>($($args),*)
            },
            _xx if $size == $crate::constants::SECTOR_SIZE_16_MIB => {
              $f::<$crate::constants::SectorShape16MiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_512_MIB => {
              $f::<$crate::constants::SectorShape512MiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_1_GIB => {
              $f::<$crate::constants::SectorShape1GiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_32_GIB => {
              $f::<$crate::constants::SectorShape32GiB>($($args),*)
            },
            _x if $size == $crate::constants::SECTOR_SIZE_64_GIB => {
              $f::<$crate::constants::SectorShape64GiB>($($args),*)
            },
            _ => panic!("unsupported sector size: {}", $size),
        }
    };
    ($size:expr, $f:ident, $($args:expr),*) => {
        with_shape!($size, $f, $($args,)*)
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    use generic_array::typenum::Unsigned;
    use storage_proofs::merkle::MerkleTreeTrait;

    fn canonical_shape(sector_size: u64) -> (usize, usize, usize) {
        // This could perhaps be cleaned up, but I think it expresses the intended constraints
        // and is consistent with our current hard-coded size->shape mappings.
        assert_eq!(sector_size.count_ones(), 1);
        let log_byte_size = sector_size.trailing_zeros();
        let log_nodes = log_byte_size - 5; // 2^5 = 32-byte nodes

        let max_tree_log = 3; // Largest allowable arity. The optimal shape.

        let log_max_base = 27; // 4 GiB worth of nodes
        let log_base = max_tree_log; // Base must be oct trees.x
        let log_in_base = u32::min(log_max_base, (log_nodes / log_base) * log_base); // How many nodes in base?

        let log_upper = log_nodes - log_in_base; // Nodes in sub and upper combined.
        let log_rem = log_upper % max_tree_log; // Remainder after filling optimal trees.

        let (log_sub, log_top) = {
            // Are the upper trees empty?
            if log_upper > 0 {
                // Do we need a remainder tree?
                if log_rem == 0 {
                    (Some(max_tree_log), None) // No remainder tree, fill the sub tree optimall.y
                } else {
                    // Need a remainder tree.

                    // Do we have room for another max tree?
                    if log_upper > max_tree_log {
                        // There is room. Use the sub tree for as much overflow as we can fit optimally.
                        // And put the rest in the top tree.
                        (Some(max_tree_log), Some(log_rem))
                    } else {
                        // Can't fit another max tree.
                        // Just put the remainder in the sub tree.
                        (Some(log_rem), None)
                    }
                }
            } else {
                // Upper trees are empty.
                (None, None)
            }
        };

        let base = 1 << log_base;
        let sub = if let Some(l) = log_sub { 1 << l } else { 0 };
        let top = if let Some(l) = log_top { 1 << l } else { 0 };

        (base, sub, top)
    }

    fn arities_to_usize<Tree: MerkleTreeTrait>() -> (usize, usize, usize) {
        (
            Tree::Arity::to_usize(),
            Tree::SubTreeArity::to_usize(),
            Tree::TopTreeArity::to_usize(),
        )
    }

    #[test]
    fn test_with_shape_macro() {
        test_with_shape_macro_aux(SECTOR_SIZE_2_KIB);
        test_with_shape_macro_aux(SECTOR_SIZE_4_KIB);
        test_with_shape_macro_aux(SECTOR_SIZE_8_MIB);
        test_with_shape_macro_aux(SECTOR_SIZE_16_MIB);
        test_with_shape_macro_aux(SECTOR_SIZE_512_MIB);
        test_with_shape_macro_aux(SECTOR_SIZE_1_GIB);
        test_with_shape_macro_aux(SECTOR_SIZE_32_GIB);
        test_with_shape_macro_aux(SECTOR_SIZE_64_GIB);
    }

    fn test_with_shape_macro_aux(sector_size: u64) {
        let expected = canonical_shape(sector_size);
        let arities = with_shape!(sector_size, arities_to_usize);
        assert_eq!(
            arities, expected,
            "Wrong shape for sector size {}: have {:?} but need {:?}.",
            sector_size, arities, expected
        );
    }
}

'''
'''--- filecoin-proofs/src/fr32.rs ---
use std::cmp::min;
use std::io::{self, Error, ErrorKind, Read, Seek, SeekFrom, Write};

use anyhow::{ensure, Result};
use bitvec::{order::Lsb0 as LittleEndian, vec::BitVec};

/** PaddingMap represents a mapping between data and its padded equivalent.

The padding process takes a *byte-aligned stream* of unpadded *raw* data
as input and returns another byte stream where padding is applied every
`data_bits` to align them to the byte boundary (`element_bits`). The
(inverse) *unpadding* process maps that output back to the raw input
that generated it.

# Padded layout

At the *byte-level*, the padded layout is:

```text
      (full element)              (full)                 (incomplete)
||  data_bits  pad_bits  ||  data_bits  pad_bits  ||  some_data  (no_padding)
                         ^^                               ^^
                  element boundary                (some_data < data_bits)
                   (byte-aligned)
```

Each *element* is a byte-aligned stream comprised of a *full unit* of `data_bits`
with `pad_bits` at the end to byte-align it (where `pad_bits` is less than a byte,
this is a *sub-byte padding* scheme). After the last element boundary there may be
an incomplete unit of data (`some_data`) with a length smaller than `data_bits`
that hasn't been padded. The padding rules are:
  1. Padding is always applied to a full unit of `data_bits`.
  2. A full data unit cannot exist without its corresponding padding.
  3. A unit of padding is complete by definition: padding can only be
     applied fully to each element.
  4. If there is padding present then there has to be an already formed
     element there (an element is full if and only if its data unit is full).

# Last byte

When returning the byte-aligned output generated from the padded *bitstream*
(since the padding is done at the bit-level) the conversion results in the
last byte having (potentially) more bits than desired. At the *bit-level*
the layout of the last byte can either be a complete element (bits of raw
data followed by the corresponding padding bits) or an incomplete unit of
data: some number of *valid* data (D) bits followed by any number of *extra*
bits (X) necessary to complete the byte-aligned stream:

```text
 |   D   D   D   D   X   X   X   X   |
         (data)         (extra)      ^ byte boundary (end of output)
```

(This diagram is just for illustrative purposes, we actually return the output
 in little-endian order, see `BitVecLEu8`).

It's important to distinguish these extra bits (generated as a side
effect of the conversion to a byte-aligned stream) from the padding bits
themselves introduced in the padding process: even though both will be
left with a zero value, these extra bits are a place-holder for the actual
raw data bits needed to complete the current unit of data (and hence also
the element, with the corresponding padding bits added after it). Since
extra bits are only a product of an incomplete unit of data there can't
be extra bits after padding bits.

There's no metadata signaling the number of extra bits present in the
last byte in any given padded layout, this is deduced from the fact
that there's only a single number of valid data bits in the last byte,
and hence a number of data bits in total, that maps to a byte-aligned
(multiple of 8) raw data stream that could have been used as input.

# Example: `FR32_PADDING_MAP`

In this case the `PaddingMap` is defined with a data unit of 254 bits that
are byte aligned to a 256-bit (32-byte) element. If the user writes as input,
say, 40 bytes (320 bits) of raw input data to the padding process the resulting
layout would be, at the element (byte) level:

```text
      (full element: 32 bytes)         (incomplete: 9 bytes)
||  data_bits: 254  pad_bits: 2  ||   some_data: 66 bits (+ extra bits)
                                 ^^
                          element boundary
```

That is, of the original 320 bits (40 bytes) of raw input data, 254 are
padded in the first element and the remaining 66 bits form the incomplete
data unit after it, which is aligned to 9 bytes. At the bit level, that
last incomplete byte will have 2 valid bits and 6 extra bits.

# Alignment of raw data bytes in the padded output

This section is not necessary to use this structure but it does help to
reason about it. By the previous definition, the raw data bits *embedded*
in the padded layout are not necessarily grouped in the same byte units
as in the original raw data input (due to the inclusion of the padding
bits interleaved in that bit stream, which keep shifting the data bits
after them).

This can also be stated as: the offsets of the bits (relative to the byte
they belong to, i.e., *bit-offset*) in the raw data input won't necessarily
match the bit-offsets of the raw data bits embedded in the padded layout.
The consequence is that each raw byte written to the padded layout won't
result in a byte-aligned bit stream output, i.e., it may cause the appearance
of extra bits (to convert the output to a byte-aligned stream).

There are portions of the padded layout, however, where this alignment does
happen. Particularly, when the padded layout accumulates enough padding bits
that they altogether add up to a byte, the following raw data byte written
will result in a byte-aligned output, and the same is true for all the other
raw data byte that follow it up until the element end, where new padding bits
shift away this alignment. (The other obvious case is the first element, which,
with no padded bits in front of it, has by definition all its embedded raw data
bytes aligned, independently of the `data_bits`/`pad_bits` configuration used.)

In the previous example, that happens after the fourth element, where 4 units
of `pad_bits` add up to one byte and all of the raw data bytes in the fifth
element will keep its original alignment from the byte input stream (and the
same will happen with every other element multiple of 4). When that fourth
element is completed we have then 127 bytes of raw data and 1 byte of padding
(totalling 32 * 4 = 128 bytes of padded output), so the interval of raw data
bytes `[127..159]` (indexed like this in the input raw data stream) will keep
its original alignment when embedded in the padded layout, i.e., every raw
data byte written will keep the output bit stream byte-aligned (without extra
bits). (Technically, the last byte actually won't be a full byte since its last
bits will be replaced by padding).

# Key terms

Collection of terms introduced in this documentation (with the format
`*<new-term>*`). This section doesn't provide a self-contained definition
of them (to avoid unnecessary repetition), it just provides (when appropriate)
an additional summary of what was already discussed.

 * Raw data: unpadded user-supplied data (we don't use the *unpadded* term
   to avoid excessive *padding* suffixes in the code). Padding (data) bits.
 * Element: byte-aligned stream consisting of a full unit of data plus the
   padding bits.
 * Full unit of raw `data_bits` (always followed by padding). Incomplete unit,
   not followed by padding, doesn't form an element.
 * Byte-aligned stream: always input and output of the (un)padding process,
   either as raw data or padded (using the term "byte-aligned" and not "byte
   stream" to stress the boundaries of the elements). Bit streams: used internally
   when padding data (never returned as bits).
 * Valid data bits, only in the context of the last byte of a byte-aligned stream
   generated from the padding process. Extra bits: what's left unused of the last
   byte (in a way the extra bits are the padding at the byte-level, but we don't
   use that term here to avoid confusions).
 * Sub-byte padding.
 * Bit-offset: offset of a bit within the byte it belongs to, ranging in `[0..8]`.
 * Embedded raw data: view of the input raw data when it has been decomposed in
   bit streams and padded in the resulting output.

**/
#[derive(Debug)]
pub struct PaddingMap {
    /// The number of bits of raw data in an element.
    data_bits: usize,
    /// Number of bits in an element: `data_bits` + `pad_bits()`. Its value
    /// is fixed to the next byte-aligned size after `data_bits` (sub-byte padding).
    element_bits: usize,
}
// TODO: Optimization: Evaluate saving the state of a (un)padding operation
// inside (e.g., as a cursor like in `BitVec`), maybe not in this structure but
// in a new `Padder` structure which would remember the positions (remaining
// data bits in the element, etc.) to avoid recalculating them each time across
// different (un)pad calls.

// This is the padding map corresponding to Fr32.
// Most of the code in this module is general-purpose and could move elsewhere.
// The application-specific wrappers which implicitly use Fr32 embed the FR32_PADDING_MAP.
pub const FR32_PADDING_MAP: PaddingMap = PaddingMap {
    data_bits: 254,
    element_bits: 256,
};

pub type BitVecLEu8 = BitVec<LittleEndian, u8>;

////////////////////////////////////////////////////////////////////////////////////////////////////
// Convenience interface for API functions – all bundling FR32_PADDING_MAP
// parameter/return types are tuned for current caller convenience.

pub fn target_unpadded_bytes<W: ?Sized>(target: &mut W) -> io::Result<u64>
where
    W: Seek,
{
    let (_, unpadded, _) = FR32_PADDING_MAP.target_offsets(target)?;

    Ok(unpadded)
}

// Leave the actual truncation to caller, since we can't do it generically.
// Return the length to which target should be truncated.
// We might should also handle zero-padding what will become the final byte of target.
// Technically, this should be okay though because that byte will always be overwritten later.
// If we decide this is unnecessary, then we don't need to pass target at all.
pub fn almost_truncate_to_unpadded_bytes<W: ?Sized>(
    _target: &mut W,
    length: u64,
) -> io::Result<usize>
where
    W: Read + Write + Seek,
{
    let padded =
        BitByte::from_bits(FR32_PADDING_MAP.transform_bit_offset((length * 8) as usize, true));
    let real_length = padded.bytes_needed();
    let _final_bit_count = padded.bits;
    Ok(real_length)
}

pub fn to_unpadded_bytes(padded_bytes: u64) -> u64 {
    FR32_PADDING_MAP.transform_byte_offset(padded_bytes as usize, false) as u64
}

pub fn to_padded_bytes(unpadded_bytes: usize) -> usize {
    FR32_PADDING_MAP.transform_byte_offset(unpadded_bytes, true)
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// BitByte represents a size expressed in bytes extended
// with bit precision, that is, not rounded.
// Invariant: it is an error for bits to be > 7.
#[derive(Debug)]
pub struct BitByte {
    bytes: usize,
    bits: usize,
}

impl BitByte {
    // Create a BitByte from number of bits. Guaranteed to return a well-formed value (bits < 8)
    pub fn from_bits(bits: usize) -> BitByte {
        BitByte {
            bytes: bits / 8,
            bits: bits % 8,
        }
    }

    pub fn from_bytes(bytes: usize) -> BitByte {
        Self::from_bits(bytes * 8)
    }

    // How many bits in the BitByte (inverse of from_bits).
    pub fn total_bits(&self) -> usize {
        self.bytes * 8 + self.bits
    }

    // True if the BitByte has no bits component.
    pub fn is_byte_aligned(&self) -> bool {
        self.bits == 0
    }

    // How many distinct bytes are needed to represent data of this size?
    pub fn bytes_needed(&self) -> usize {
        self.bytes + if self.bits == 0 { 0 } else { 1 }
    }
}

impl PaddingMap {
    pub fn new(data_bits: usize, element_bits: usize) -> Result<PaddingMap> {
        // Check that we add less than 1 byte of padding (sub-byte padding).
        ensure!(
            element_bits - data_bits <= 7,
            "Padding (num bits: {}) must be less than 1 byte.",
            element_bits - data_bits
        );
        // Check that the element is byte aligned.
        ensure!(
            element_bits % 8 == 0,
            "Element (num bits: {}) must be byte aligned.",
            element_bits
        );

        Ok(PaddingMap {
            data_bits,
            element_bits,
        })
    }

    pub fn pad(&self, bits_out: &mut BitVecLEu8) {
        for _ in 0..self.pad_bits() {
            bits_out.push(false)
        }
        // TODO: Optimization: Drop this explicit `push` padding, the padding
        // should happen implicitly when byte-aligning the data unit.
    }

    pub fn pad_bits(&self) -> usize {
        self.element_bits - self.data_bits
    }

    // Transform an offset (either a position or a size) *expressed in
    // bits* in a raw byte-aligned data stream to its equivalent in a
    // generated padded bit stream, that is, not byte aligned (so we
    // don't count the extra bits here). If `padding` is `false` calculate
    // the inverse transformation.
    pub fn transform_bit_offset(&self, pos: usize, padding: bool) -> usize {
        // Set the sizes we're converting to and from.
        let (from_size, to_size) = if padding {
            (self.data_bits, self.element_bits)
        } else {
            (self.element_bits, self.data_bits)
        };

        // For both the padding and unpadding cases the operation is the same.
        // The quotient is the number of full, either elements, in the padded layout,
        // or groups of `data_bits`, in the raw data input (that will be converted
        // to full elements).
        // The remainder (in both cases) is the last *incomplete* part of either of
        // the two. Even in the padded layout, if there is an incomplete element it
        // has to consist *only* of data (see `PaddingMap#padded-layout`). That amount
        // of spare raw data doesn't need conversion, it can just be added to the new
        // position.
        let (full_elements, incomplete_data) = div_rem(pos, from_size);
        (full_elements * to_size) + incomplete_data
    }

    // Similar to `transform_bit_pos` this function transforms an offset
    // expressed in bytes, that is, we are taking into account the extra
    // bits here.
    // TODO: Evaluate the relationship between this function and `transform_bit_offset`,
    // it seems the two could be merged, or at least restructured to better expose
    // their differences.
    pub fn transform_byte_offset(&self, pos: usize, padding: bool) -> usize {
        let transformed_bit_pos = self.transform_bit_offset(pos * 8, padding);

        let transformed_byte_pos = transformed_bit_pos as f64 / 8.;
        // TODO: Optimization: It might end up being cheaper to avoid this
        // float conversion and use / and %.

        // When padding, the final bits in the bit stream will grow into the
        // last (potentially incomplete) byte of the byte stream, so round the
        // number up (`ceil`). When unpadding, there's no way to know a priori
        // how many valid bits are in the last byte, we have to choose the number
        // that fits in a byte-aligned raw data stream, so round the number down
        // to that (`floor`).
        (if padding {
            transformed_byte_pos.ceil()
        } else {
            transformed_byte_pos.floor()
        }) as usize
    }

    // From the `position` specified, it returns:
    // - the absolute position of the start of the next element,
    //   in bytes (since elements -with padding- are byte aligned).
    // - the number of bits left to read (write) from (to) the current
    //   data unit (assuming it's full).
    pub fn next_boundary(&self, position: &BitByte) -> (usize, usize) {
        let position_bits = position.total_bits();

        let (_, bits_after_last_boundary) = div_rem(position_bits, self.element_bits);

        let remaining_data_unit_bits = self.data_bits - bits_after_last_boundary;

        let next_element_position_bits = position_bits + remaining_data_unit_bits + self.pad_bits();

        (next_element_position_bits / 8, remaining_data_unit_bits)
    }

    // For a `Seek`able `target` of a byte-aligned padded layout, return:
    // - the size in bytes
    // - the size in bytes of raw data which corresponds to the `target` size
    // - a BitByte representing the number of padded bits contained in the
    //   byte-aligned padded layout
    pub fn target_offsets<W: ?Sized>(&self, target: &mut W) -> io::Result<(u64, u64, BitByte)>
    where
        W: Seek,
    {
        // The current position in `target` is the number of padded bytes already written
        // to the byte-aligned stream.
        let padded_bytes = target.seek(SeekFrom::End(0))?;

        // Deduce the number of input raw bytes that generated that padded byte size.
        let raw_data_bytes = self.transform_byte_offset(padded_bytes as usize, false);

        // With the number of raw data bytes elucidated it can now be specified the
        // number of padding bits in the generated bit stream (before it was converted
        // to a byte-aligned stream), that is, `raw_data_bytes * 8` is not necessarily
        // `padded_bits`).
        let padded_bits = self.transform_bit_offset(raw_data_bytes * 8, true);

        Ok((
            padded_bytes,
            raw_data_bytes as u64,
            BitByte::from_bits(padded_bits),
        ))
        // TODO: Why do we use `usize` internally and `u64` externally?
    }
}

#[inline]
fn div_rem(a: usize, b: usize) -> (usize, usize) {
    let div = a / b;
    let rem = a % b;
    (div, rem)
}

// TODO: The following extraction functions could be moved to a different file.

/** Shift an `amount` of bits from the `input` in the direction indicated by `is_left`.

This function tries to imitate the behavior of `shl` and `shr` of a
`BitVec<LittleEndian, u8>`, where the inner vector is traversed one byte
at a time (`u8`), and inside each byte, bits are traversed (`LittleEndian`)
from LSB ("right") to MSB ("left"). For example, the bits in the this two-byte
slice will be traversed according to their numbering:

```text
ADDR     |  7  6  5  4  3  2  1  0  |

ADDR +1  |  F  E  D  C  B  A  9  8  |
```

`BitVec` uses the opposite naming convention than this function, shifting left
here is equivalent to `shr` there, and shifting right to `shl`.

If shifting in the left direction, the `input` is expanded by one extra byte to
accommodate the overflow (instead of just discarding it, which is what's done
in the right direction).

The maximum `amount` to shift is 7 (and the minimum is 1), that is, we always
shift less than a byte. This precondition is only checked during testing (with
`debug_assert!`) for performance reasons, it is up to the caller to enforce it.

# Examples

Shift the `input` (taken from the diagram above) left by an `amount` of 3 bits,
growing the output slice:

```text
ADDR     |  4  3  2  1  0  _  _  _  |  Filled with zeros.

ADDR +1  |  C  B  A  9  8  7  6  5  |

ADDR +2  |  _  _  _  _  _  F  E  D  |  The overflow of the last input byte
                                               is moved to this (new) byte.
```

Same, but shift right:

```text
ADDR     |  A  9  8  7  6  5  4  3  |  The overflow `[2,1,0]` is just discarded,
                                                         the slice doesn't grow.
ADDR +1  |  _  _  _  F  E  D  C  B  |
```

(Note: `0`, `1`, `2`, etc. are bits identified by their original position,
`_` means a bit left at zero after shifting, to avoid confusions with
the unique bit `0`, that just *started* at that position but doesn't
necessarily carry that value.)

**/
pub fn shift_bits(input: &[u8], amount: usize, is_left: bool) -> Vec<u8> {
    debug_assert!(amount >= 1);
    debug_assert!(amount <= 7);

    // Create the `output` vector from the original input values, extending
    // its size by one if shifting left.
    let mut output = Vec::with_capacity(input.len() + if is_left { 1 } else { 0 });
    output.extend_from_slice(input);
    if is_left {
        output.push(0);
    }
    // TODO: Is there a cleaner way to do this? Is the extra byte worth the initial
    // `with_capacity` call?

    // Split the shift in two parts. First, do a simple bit shift (losing the
    // overflow) for each byte, then, in a second pass, recover the lost overflow
    // from the `input`. The advantage of splitting it like this is that the place-holder
    // spaces are already being cleared with zeros to just join the overflow part with an
    // single `OR` operation (instead of assembling both parts together at the same time
    // which requires an extra clear operation with a mask of zeros).
    for output_byte in output.iter_mut().take(input.len()) {
        if is_left {
            *output_byte <<= amount;
        } else {
            *output_byte >>= amount;
        }
    }

    if is_left {
        // The `output` looks at this point like this (following the original
        // example):
        //
        // ADDR     |  4  3  2  1  0  _  _  _  |
        //
        // ADDR +1  |  C  B  A  9  8  _  _  _  |
        //
        // ADDR +2  |  _  _  _  _  _  _  _  _  |  Extra byte allocated to extend the `input`,
        //                                            hasn't been modified in the first pass.
        //
        // We need to recover the overflow of each shift (e.g., `[7,6,5]` from
        // the first byte and `[F,E,D]` from the second) and move it to the next
        // byte, shifting it to place it at the "start" (in the current ordering
        // that means aligning it to the LSB). For example, the overflow of (also)
        // `amount` bits from the first byte is:
        //
        // ADDR     |  7  6  5  4  3  2  1  0  |
        //             +-----+
        //           overflow lost
        //
        // and it's "recovered" with a shift in the opposite direction, which both
        // positions it in the correct place *and* leaves cleared the rest of the
        // bits to be able to `OR` (join) it with the next byte of `output` (shifted
        // in the first pass):
        //
        // (`output` so far)
        // ADDR +1  |  C  B  A  9  8  _  _  _  |    +
        //                                          |
        // (shifted overflow                        |  join both (`|=`)
        //      from `input`)                       |
        // ADDR     |  _  _  _  _  _  7  6  5  |    V
        //             +------------->
        //
        for i in 0..input.len() {
            let overflow = input[i] >> (8 - amount);
            output[i + 1] |= overflow;
        }
    } else {
        // The overflow handling in the right shift follows the same logic as the left
        // one with just two differences: (1) the overflow goes to the *previous* byte
        // in memory and (2) the overflow of the first byte is discarded (hence the `for`
        // loop iterates just `input.len` *minus one* positions).
        for i in 1..input.len() {
            let overflow = input[i] << (8 - amount);
            output[i - 1] |= overflow;
        }
    }

    // TODO: Optimization: Join both passes in one `for` loop for cache
    // efficiency (do everything we need to do in the same address once).
    // (This is low priority since we normally shift small arrays -32 byte
    // elements- per call.)

    output
}

/** Extract bits and relocate them.

Extract `num_bits` from the `input` starting at absolute `pos` (expressed in
bits). Format the extracted bit stream as a byte stream `output` (in a `Vec<u8>`)
where the extracted bits start at `new_offset` bits in the first byte (i.e.,
`new_offset` can't be bigger than 7) allowing them to be relocated from their
original bit-offset (encoded in `pos`). The rest of the bits (below `new_offset`
and after the extracted `num_bits`) are left at zero (to prepare them to be
joined with another extracted `output`). This function follows the ordering in
`BitVec<LittleEndian, u8>` (see `shift_bits` for more details).

The length of the input must be big enough to perform the extraction
of `num_bits`. This precondition is only checked during testing (with
`debug_assert!`) for performance reasons, it is up to the caller to enforce it.

# Example

Taking as `input` the original two-byte layout from `shift_bits`, extracting 4
`num_bits` from `pos` 12 and relocating them in `new_offset` 2 would result in
an `output` of a single byte like:

```text
ADDR     |  _  _  F  E  D  C  _  _  |
```

(The second byte in `ADDR +1` has been dropped after the extraction
as it's no longer needed.)

**/
//
// TODO: Replace the byte terminology for a generic term that can mean
// anything that implements the `bitvec::Bits` trait (`u8`, `u32`, etc.).
// `BitVec` calls it "element" but that's already used here (this function
// may need to be moved elsewhere which would allow to reuse that term).
// This also will imply removing the hardcoded `8`s (size of byte).
#[inline]
pub fn extract_bits_and_shift(
    input: &[u8],
    pos: usize,
    num_bits: usize,
    new_offset: usize,
) -> Vec<u8> {
    debug_assert!(input.len() * 8 >= pos + num_bits);
    debug_assert!(new_offset <= 7);

    // 1. Trim the whole bytes (before and after) we don't need for the
    //    extraction (we don't want to waste shift operations on them).
    // 2. Shift from the original `pos` to the `new_offset`.
    // 3. Trim the bits in the first and last byte we also don't need.
    //
    // TODO: Does (3) need to happen *after* the shift in (2)? It feels
    // more natural but can't we just trim everything in (1)?

    // Determine from `pos` the number of full bytes that can be completely skipped
    // (`skip_bytes`), and the number of bits within the first byte of interest that
    // we'll start extracting from (`extraction_offset`).
    let (skip_bytes, extraction_offset) = div_rem(pos, 8);

    // (1).
    let input = &input[skip_bytes..];
    let input = &input[..BitByte::from_bits(extraction_offset + num_bits).bytes_needed()];

    // (2).
    use std::cmp::Ordering;
    let mut output = match new_offset.cmp(&extraction_offset) {
        Ordering::Less => {
            // Shift right.
            shift_bits(input, extraction_offset - new_offset, false)
        }
        Ordering::Greater => {
            // Shift left.
            shift_bits(input, new_offset - extraction_offset, true)
        }
        Ordering::Equal => {
            // No shift needed, take the `input` as is.
            input.to_vec()
        }
    };

    // After the shift we may not need the last byte of the `output` (either
    // because the left shift extended it by one byte or because the right shift
    // move the extraction span below that threshold).
    if output.len() > BitByte::from_bits(new_offset + num_bits).bytes_needed() {
        output.pop();
    }
    // TODO: Optimization: A more specialized shift would have just dropped
    // that byte (we would need to pass it the `num_bits` we want).

    // (3).
    if new_offset != 0 {
        clear_right_bits(output.first_mut().unwrap(), new_offset);
    }
    let end_offset = (new_offset + num_bits) % 8;
    if end_offset != 0 {
        clear_left_bits(output.last_mut().unwrap(), end_offset);
    }

    output
}

// Set to zero all the bits to the "left" of the `offset` including
// it, that is, [MSB; `offset`].
#[inline]
pub fn clear_left_bits(byte: &mut u8, offset: usize) {
    *(byte) &= (1 << offset) - 1
}

// Set to zero all the bits to the "right" of the `offset` excluding
// it, that is, (`offset`; LSB].
#[inline]
pub fn clear_right_bits(byte: &mut u8, offset: usize) {
    *(byte) &= !((1 << offset) - 1)
}

/** Padding process.

Read a `source` of raw byte-aligned data, pad it in a bit stream and
write a byte-aligned version of it in the `target`. The `target` needs
to implement (besides `Write`) the `Read` and `Seek` traits since the
last byte written may be incomplete and will need to be rewritten.

The reader will always be byte-aligned, the writer will operate with
bit precision since we may have (when calling this function multiple
times) a written `target` with extra bits (that need to be overwritten)
and also incomplete data units.
The ideal alignment scenario is for the writer to be positioned at the
byte-aligned element boundary and just write whole chunks of `data_chunk_bits`
(full data units) followed by its corresponding padding. To get there then we
need to handle the potential bit-level misalignments:
  1. extra bits: the last byte is only partially valid so we
     need to get some bits from the `source` to overwrite them.
  2. Incomplete data unit: we need to fill the rest of it and add the padding
     to form a element that would position the writer at the desired boundary.
**/

// offset and num_bytes are based on the unpadded data, so
// if [0, 1, ..., 255] was the original unpadded data, offset 3 and len 4 would return
// [3, 4, 5, 6].
pub fn write_unpadded<W: ?Sized>(
    source: &[u8],
    target: &mut W,
    offset: usize,
    len: usize,
) -> io::Result<usize>
where
    W: Write,
{
    // Check that there's actually `len` raw data bytes encoded inside
    // `source` starting at `offset`.
    let read_pos = BitByte::from_bits(FR32_PADDING_MAP.transform_bit_offset(offset * 8, true));
    let raw_data_size = BitByte::from_bits(
        FR32_PADDING_MAP.transform_bit_offset(source.len() * 8 - read_pos.total_bits(), false),
    )
    .bytes_needed();
    if raw_data_size < len {
        return Err(Error::new(
            ErrorKind::Other,
            format!(
                "requested extraction of {} raw data bytes when there's at most {} in the source",
                len, raw_data_size
            ),
        ));
    }

    // In order to optimize alignment in the common case of writing from an aligned start,
    // we should make the chunk a multiple of 128 (4 full elements in the padded layout).
    // n was hand-tuned to do reasonably well in the benchmarks.
    let n = 1000;
    let chunk_size = 128 * n;

    let mut written = 0;

    let mut offset = offset;
    let mut len = len;

    for chunk in source.chunks(chunk_size) {
        let write_len = min(len, chunk.len());

        written += write_unpadded_aux(&FR32_PADDING_MAP, source, target, offset, write_len)?;
        offset += write_len;
        len -= write_len;
    }

    Ok(written)
}

/**  Unpadding process.

Read a `source` of padded data and recover from it the byte-aligned
raw data writing it in `target`, where `write_pos` specifies from which
byte of the raw data stream to start recovering to, up to `max_write_size`
bytes.

There are 3 limits that tell us how much padded data to process in
each iteration (`bits_to_extract`):
1. Element boundary: we can process only one element at a time (to be
   able to skip the padding bits).
2. End of `source`: no more data to read.
3. No more space to write the recovered raw data: we shouldn't write
   into the `target` beyond `max_write_size`.

The reader will generally operate with bit precision, even if the padded
layout is byte-aligned (no extra bits) the data inside it isn't (since
we pad at the bit-level).
**/
pub fn write_unpadded_aux<W: ?Sized>(
    padding_map: &PaddingMap,
    source: &[u8],
    target: &mut W,
    write_pos: usize,
    max_write_size: usize,
) -> io::Result<usize>
where
    W: Write,
{
    // Position of the reader in the padded bit stream layout, deduced from
    // the position of the writer (`write_pos`) in the raw data layout.
    let mut read_pos = BitByte::from_bits(padding_map.transform_bit_offset(write_pos * 8, true));

    // Specify the maximum data to recover (write) in bits, since the data unit
    // in the element (in contrast with the original raw data that generated it)
    // is not byte aligned.
    let max_write_size_bits = max_write_size * 8;

    // Estimate how many bytes we'll need for the `raw_data` to allocate
    // them all at once. We need to take into account both how much do
    // we have left to read *and* write, and even then, since we may start
    // in the middle of an element (`write_pos`) there's some variability
    // as to how many padding bits will be encountered.
    // Allow then an *over*-estimation error of 1 byte: `transform_bit_offset`
    // has the implicit assumption that the data provided is starting at the
    // beginning of an element, i.e., the padding bits are as far as possible,
    // which maximizes the chances of not getting an extra `pad_bits` in the
    // `source` (which are unpadded away and not carried to the `target`). That
    // is, in this context `transform_bit_offset` is optimistic about the number
    // of raw data bits we'll be able to recover from a fixed number of `source`
    // bits.
    let mut raw_data_size = BitByte::from_bits(
        padding_map.transform_bit_offset(source.len() * 8 - read_pos.total_bits(), false),
    )
    .bytes_needed();
    raw_data_size = min(raw_data_size, max_write_size);

    // Recovered raw data unpadded from the `source` which will
    // be written to the `target`.
    let mut raw_data: Vec<u8> = Vec::with_capacity(raw_data_size);

    // Total number of raw data bits we have written (unpadded from the `source`).
    let mut written_bits = 0;
    // Bit offset within the last byte at which the next write needs to happen
    // (derived from `written_bits`), we keep track of this since we write in chunks
    // that may not be byte-aligned.
    let mut write_bit_offset = 0;

    // If there is no more data to read or no more space to write stop.
    while read_pos.bytes < source.len() && written_bits < max_write_size_bits {
        // (1): Find the element boundary and, assuming that there is a full
        //      unit of data (which actually may be incomplete), how many bits
        //      are left to read from `read_pos`.
        let (next_element_position, mut bits_to_extract) = padding_map.next_boundary(&read_pos);

        // (2): As the element may be incomplete check how much data is
        //      actually available so as not to access the `source` past
        //      its limit.
        bits_to_extract = min(bits_to_extract, source.len() * 8 - read_pos.total_bits());

        // (3): Don't read more than `max_write_size`.
        let bits_left_to_write = max_write_size_bits - written_bits;
        bits_to_extract = min(bits_to_extract, bits_left_to_write);

        // Extract the next data unit from the element (or whatever space we
        // have left to write) and reposition it in the `write_bit_offset`.
        // N.B., the bit offset of the data in the original raw data byte
        // stream and the same data in the padded layout are not necessarily
        // the same (since the added padding bits shift it).
        let mut recovered = extract_bits_and_shift(
            &source,
            read_pos.total_bits(),
            bits_to_extract,
            write_bit_offset,
        );

        if write_bit_offset != 0 {
            // Since the two data units we are joining are not byte-aligned we can't
            // just append the whole bytes to `raw_data`, we need to join the last
            // byte of the already written `raw_data` with the first one of data unit
            // `recovered` in this iteration. Since `extract_bits_and_shift` already
            // takes care of setting to zero the bits beyond the extraction limit we
            // can just `OR` the two.
            *(raw_data.last_mut().unwrap()) |= *(recovered.first().unwrap());
            raw_data.append(&mut recovered[1..].to_vec());
        } else {
            raw_data.append(&mut recovered);
        }

        written_bits += bits_to_extract;
        write_bit_offset = written_bits % 8;

        // Position the reader in the next element boundary, this will be ignored
        // if we already hit limits (2) or (3) (in that case this was the last iteration).
        read_pos = BitByte {
            bytes: next_element_position,
            bits: 0,
        };
    }

    // TODO: Don't write the whole output into a huge BitVec.
    // Instead, write it incrementally –
    // but ONLY when the bits waiting in bits_out are byte-aligned. i.e. a multiple of 8

    // Check that our estimated size was correct, allow it to be overestimated
    // (not *under*) by 1 byte.
    debug_assert!(raw_data_size - raw_data.len() <= 1);
    debug_assert!(raw_data_size >= raw_data.len());

    target.write_all(&raw_data)?;

    Ok(raw_data.len())
}

#[cfg(test)]
mod tests {
    use super::*;

    use itertools::Itertools;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_position() {
        let mut bits = 0;
        for i in 0..10 {
            for j in 0..8 {
                let position = BitByte { bytes: i, bits: j };
                assert_eq!(position.total_bits(), bits);
                bits += 1;
            }
        }
    }

    // Test the `extract_bits_le` function against the `BitVec` functionality
    // (assumed to be correct).
    #[test]
    fn test_random_bit_extraction() {
        // Length of the data vector we'll be extracting from.
        let len = 20;

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
        let data: Vec<u8> = (0..len).map(|_| rng.gen()).collect();

        // TODO: Evaluate designing a scattered pattered of `pos` and `num_bits`
        // instead of repeating too many iterations with any number.
        for _ in 0..100 {
            let pos = rng.gen_range(0, data.len() / 2);
            let num_bits = rng.gen_range(1, data.len() * 8 - pos);
            let new_offset = rng.gen_range(0, 8);

            let mut bv = BitVecLEu8::new();
            bv.extend(
                BitVecLEu8::from(&data[..])
                    .into_iter()
                    .skip(pos)
                    .take(num_bits),
            );
            let shifted_bv: BitVecLEu8 = bv >> new_offset;

            assert_eq!(
                shifted_bv.as_slice(),
                &extract_bits_and_shift(&data, pos, num_bits, new_offset)[..],
            );
        }
    }

    // Test the `shift_bits` function against the `BitVec<LittleEndian, u8>`
    // implementation of `shr_assign` and `shl_assign`.
    #[test]
    fn test_bit_shifts() {
        let len = 5;
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for amount in 1..8 {
            for left in [true, false].iter() {
                let data: Vec<u8> = (0..len).map(|_| rng.gen()).collect();

                let shifted_bits = shift_bits(&data, amount, *left);

                let mut bv: BitVec<LittleEndian, u8> = data.into();
                if *left {
                    bv >>= amount;
                } else {
                    bv <<= amount;
                }
                // We use the opposite shift notation (see `shift_bits`).

                assert_eq!(bv.as_slice(), shifted_bits.as_slice());
            }
        }
    }

    // Simple (and slow) padder implementation using `BitVec`.
    // It is technically not quite right to use `BitVec` to test
    // `write_padded` since at the moment that function still uses
    // it for some corner cases, but since largely this implementation
    // has been replaced it seems reasonable.
    fn bit_vec_padding(raw_data: Vec<u8>) -> Box<[u8]> {
        let mut padded_data: BitVec<LittleEndian, u8> = BitVec::new();
        let raw_data: BitVec<LittleEndian, u8> = BitVec::from(raw_data);

        for data_unit in raw_data
            .into_iter()
            .chunks(FR32_PADDING_MAP.data_bits)
            .into_iter()
        {
            padded_data.extend(data_unit.into_iter());

            // To avoid reconverting the iterator, we deduce if we need the padding
            // by the length of `padded_data`: a full data unit would not leave the
            // padded layout aligned (it would leave it unaligned by just `pad_bits()`).
            if padded_data.len() % 8 != 0 {
                for _ in 0..FR32_PADDING_MAP.pad_bits() {
                    padded_data.push(false);
                }
            }
        }

        padded_data.into_boxed_slice()
    }

    // `write_padded` and `write_unpadded` for 1016 bytes of 1s, check the
    // recovered raw data.
    #[test]
    fn test_read_write_padded() {
        let len = 1016; // Use a multiple of 254.
        let data = vec![255u8; len];
        let mut padded = Vec::new();
        let mut reader = crate::fr32_reader::Fr32Reader::new(io::Cursor::new(&data));
        reader.read_to_end(&mut padded).unwrap();

        assert_eq!(
            padded.len(),
            FR32_PADDING_MAP.transform_byte_offset(len, true)
        );

        let mut unpadded = Vec::new();
        let unpadded_written = write_unpadded(&padded, &mut unpadded, 0, len).unwrap();
        assert_eq!(unpadded_written, len);
        assert_eq!(data, unpadded);
        assert_eq!(padded.into_boxed_slice(), bit_vec_padding(data));
    }

    // `write_padded` and `write_unpadded` for 1016 bytes of random data, recover
    // different lengths of raw data at different offset, check integrity.
    #[test]
    fn test_read_write_padded_offset() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let len = 1016;
        let data: Vec<u8> = (0..len).map(|_| rng.gen()).collect();

        let mut padded = Vec::new();
        let mut reader = crate::fr32_reader::Fr32Reader::new(io::Cursor::new(&data));
        reader.read_to_end(&mut padded).unwrap();

        {
            let mut unpadded = Vec::new();
            write_unpadded(&padded, &mut unpadded, 0, 1016).unwrap();
            let expected = &data[0..1016];

            assert_eq!(expected.len(), unpadded.len());
            assert_eq!(expected, &unpadded[..]);
        }

        {
            let mut unpadded = Vec::new();
            write_unpadded(&padded, &mut unpadded, 0, 44).unwrap();
            let expected = &data[0..44];

            assert_eq!(expected.len(), unpadded.len());
            assert_eq!(expected, &unpadded[..]);
        }

        let excessive_len = 35;
        for start in (1016 - excessive_len + 2)..1016 {
            assert!(write_unpadded(&padded, &mut Vec::new(), start, excessive_len).is_err());
        }
    }

    // TODO: Add a test that drops the last part of an element and tries to recover
    // the rest of the data (may already be present in some form in the above tests).
}

'''
'''--- filecoin-proofs/src/fr32_reader.rs ---
use std::io;

const DATA_BITS: u64 = 254;
const TARGET_BITS: u64 = 256;

#[derive(Debug)]
pub struct Fr32Reader<R> {
    /// The source being padded.
    source: R,
    /// How much of the target already was `read` from, in bits.
    target_offset: u64,
    /// Currently read byte.
    buffer: Buffer,
    /// Are we done reading?
    done: bool,
}

impl<R: io::Read> Fr32Reader<R> {
    pub fn new(source: R) -> Self {
        Fr32Reader {
            source,
            target_offset: 0,
            buffer: Default::default(),
            done: false,
        }
    }

    fn read_u8_no_pad(&mut self, target: &mut [u8]) -> io::Result<usize> {
        target[0] = self.buffer.read_u8();
        self.target_offset += 8;

        Ok(1)
    }

    fn read_u16_no_pad(&mut self, target: &mut [u8]) -> io::Result<usize> {
        self.buffer.read_u16_into(&mut target[..2]);
        self.target_offset += 16;

        Ok(2)
    }

    fn read_u32_no_pad(&mut self, target: &mut [u8]) -> io::Result<usize> {
        self.buffer.read_u32_into(&mut target[..4]);
        self.target_offset += 32;

        Ok(4)
    }

    fn read_u64_no_pad(&mut self, target: &mut [u8]) -> io::Result<usize> {
        self.buffer.read_u64_into(&mut target[..8]);
        self.target_offset += 64;

        Ok(8)
    }

    /// Read up to 8 bytes into the targets first element.
    /// Assumes that target is not empty.
    fn read_bytes(&mut self, target: &mut [u8]) -> io::Result<usize> {
        let bit_pos = self.target_offset % TARGET_BITS;
        let bits_to_padding = if bit_pos < DATA_BITS {
            DATA_BITS as usize - bit_pos as usize
        } else {
            0
        };

        if bits_to_padding >= 8 {
            self.fill_buffer()?;
        }

        let available = self.buffer.available();
        if available > 0 {
            let target_len = target.len();
            // Try to avoid padding, and copy as much as possible over at once.

            if bits_to_padding >= 64 && available >= 64 && target_len >= 8 {
                return self.read_u64_no_pad(target);
            }

            if bits_to_padding >= 32 && available >= 32 && target_len >= 4 {
                return self.read_u32_no_pad(target);
            }

            if bits_to_padding >= 16 && available >= 16 && target_len >= 2 {
                return self.read_u16_no_pad(target);
            }

            if bits_to_padding >= 8 && available >= 8 && target_len >= 1 {
                return self.read_u8_no_pad(target);
            }
        }

        self.read_u8_padded(target, bits_to_padding, available)
    }

    fn read_u8_padded(
        &mut self,
        target: &mut [u8],
        bits_to_padding: usize,
        available: u64,
    ) -> io::Result<usize> {
        target[0] = 0;

        if available >= 6 {
            match bits_to_padding {
                6 => {
                    target[0] = self.buffer.read_u8_range(6);
                    self.target_offset += 8;
                    return Ok(1);
                }
                5 => {
                    target[0] = self.buffer.read_u8_range(5);
                    if self.buffer.read_bit() {
                        set_bit(&mut target[0], 7);
                    }
                    self.target_offset += 8;
                    return Ok(1);
                }
                _ => {}
            }
        }

        for i in 0..8 {
            if self.target_offset % TARGET_BITS < DATA_BITS {
                if !self.fill_buffer()? {
                    if i > 0 {
                        return Ok(1);
                    } else {
                        return Ok(0);
                    }
                }

                if self.buffer.read_bit() {
                    set_bit(&mut target[0], i);
                }
            };

            self.target_offset += 1;
        }

        Ok(1)
    }

    /// Fill the inner buffer, only if necessary. Returns `true` if more data is available.
    fn fill_buffer(&mut self) -> io::Result<bool> {
        if self.buffer.available() > 0 {
            // Nothing to do, already some data available.
            return Ok(true);
        }

        let read = self.source.read(&mut self.buffer[..])?;
        self.buffer.reset_available(read as u64 * 8);

        Ok(read > 0)
    }
}

impl<R: io::Read> io::Read for Fr32Reader<R> {
    fn read(&mut self, target: &mut [u8]) -> io::Result<usize> {
        if self.done || target.is_empty() {
            return Ok(0);
        }

        let mut read = 0;
        while read < target.len() {
            let current_read = self.read_bytes(&mut target[read..])?;
            read += current_read;

            if current_read == 0 {
                self.done = true;
                break;
            }
        }

        Ok(read)
    }
}

fn set_bit(x: &mut u8, bit: usize) {
    *x |= 1 << bit
}

use std::ops::{Deref, DerefMut};

#[derive(Debug, Default, Clone, Copy)]
struct Buffer {
    data: u64,
    /// Bits already consumed.
    pos: u64,
    /// Bits available.
    avail: u64,
}

impl Deref for Buffer {
    type Target = [u8; 8];

    fn deref(&self) -> &Self::Target {
        unsafe { &*(&self.data as *const u64 as *const [u8; 8]) }
    }
}

impl DerefMut for Buffer {
    fn deref_mut(&mut self) -> &mut Self::Target {
        unsafe { &mut *(&mut self.data as *mut u64 as *mut [u8; 8]) }
    }
}

impl Buffer {
    /// How many bits are available to read.
    #[inline]
    pub fn available(&self) -> u64 {
        self.avail - self.pos
    }

    pub fn reset_available(&mut self, bits: u64) {
        self.pos = 0;
        self.avail = bits;
    }

    /// Read a single bit at the current position.
    pub fn read_bit(&mut self) -> bool {
        let res = self.data & (1 << self.pos) != 0;
        debug_assert!(self.available() >= 1);
        self.pos += 1;
        res
    }

    #[cfg(target_endian = "little")]
    pub fn read_u8_range(&mut self, len: u64) -> u8 {
        use bitintr::Bextr;
        debug_assert!(self.available() >= len);
        let res = self.data.bextr(self.pos, len) as u8;
        self.pos += len;
        res
    }

    #[cfg(target_endian = "little")]
    pub fn read_u8(&mut self) -> u8 {
        use bitintr::Bextr;
        debug_assert!(self.available() >= 8);
        let res = self.data.bextr(self.pos, 8) as u8;
        self.pos += 8;
        res
    }

    #[cfg(target_endian = "little")]
    pub fn read_u16(&mut self) -> u16 {
        debug_assert!(self.available() >= 16);

        use bitintr::Bextr;
        let res = self.data.bextr(self.pos, 16) as u16;
        self.pos += 16;
        res
    }

    #[cfg(target_endian = "little")]
    pub fn read_u16_into(&mut self, target: &mut [u8]) {
        assert!(target.len() >= 2);

        let value = self.read_u16().to_le_bytes();
        target[0] = value[0];
        target[1] = value[1];
    }

    #[cfg(target_endian = "little")]
    pub fn read_u32(&mut self) -> u32 {
        debug_assert!(self.available() >= 32);

        use bitintr::Bextr;
        let res = self.data.bextr(self.pos, 32) as u32;
        self.pos += 32;
        res
    }

    #[cfg(target_endian = "little")]
    pub fn read_u32_into(&mut self, target: &mut [u8]) {
        assert!(target.len() >= 4);
        let value = self.read_u32().to_le_bytes();
        target[0] = value[0];
        target[1] = value[1];
        target[2] = value[2];
        target[3] = value[3];
    }

    pub fn read_u64(&mut self) -> u64 {
        debug_assert!(self.available() >= 64);

        self.pos += 64;
        self.data
    }

    #[cfg(target_endian = "little")]
    pub fn read_u64_into(&mut self, target: &mut [u8]) {
        assert!(target.len() >= 8);
        let value = self.read_u64().to_le_bytes();
        target[0] = value[0];
        target[1] = value[1];
        target[2] = value[2];
        target[3] = value[3];
        target[4] = value[4];
        target[5] = value[5];
        target[6] = value[6];
        target[7] = value[7];
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use pretty_assertions::assert_eq;
    use std::io::Read;

    #[test]
    fn test_buffer_read_bit() {
        let mut buffer = Buffer::default();
        let val = 12345u64.to_le_bytes();
        buffer.copy_from_slice(&val[..]);
        buffer.reset_available(64);

        for i in 0..8 {
            assert_eq!(buffer.read_bit(), 0 != val[0] & (1 << i));
        }
    }

    #[test]
    fn test_buffer_read_u8() {
        let mut buffer = Buffer::default();
        let val = 12345u64.to_le_bytes();
        buffer.copy_from_slice(&val[..]);
        buffer.reset_available(64);

        for i in 0..8 {
            let read = buffer.read_u8();
            assert_eq!(read, val[i], "failed to read byte {}", i);
        }
    }

    #[test]
    fn test_buffer_read_u16() {
        let mut buffer = Buffer::default();
        let val = 12345u64.to_le_bytes();
        buffer.copy_from_slice(&val[..]);
        buffer.reset_available(64);

        for val in val.chunks(2) {
            let read = buffer.read_u16();
            assert_eq!(read, u16::from_le_bytes([val[0], val[1]]));
        }
    }

    #[test]
    fn test_buffer_read_u32() {
        let mut buffer = Buffer::default();
        let val = 12345u64.to_le_bytes();
        buffer.copy_from_slice(&val[..]);
        buffer.reset_available(64);

        for val in val.chunks(4) {
            let read = buffer.read_u32();
            assert_eq!(read, u32::from_le_bytes([val[0], val[1], val[2], val[3]]));
        }
    }

    #[test]
    fn test_buffer_read_u64() {
        let mut buffer = Buffer::default();
        let val = 12345u64;
        buffer.copy_from_slice(&val.to_le_bytes()[..]);
        buffer.reset_available(64);

        let read = buffer.read_u64();
        assert_eq!(read, val);
    }

    #[test]
    fn test_simple_short() {
        // Source is shorter than 1 padding cycle.
        let data = vec![3u8; 30];
        let mut reader = Fr32Reader::new(io::Cursor::new(&data));
        let mut padded = Vec::new();
        reader.read_to_end(&mut padded).unwrap();
        assert_eq!(&data[..], &padded[..]);

        assert_eq!(padded.into_boxed_slice(), bit_vec_padding(data));
    }

    #[test]
    fn test_simple_single() {
        let data = vec![255u8; 32];
        let mut padded = Vec::new();
        let mut reader = Fr32Reader::new(io::Cursor::new(&data));
        reader.read_to_end(&mut padded).unwrap();

        assert_eq!(&padded[0..31], &data[0..31]);
        assert_eq!(padded[31], 0b0011_1111);
        assert_eq!(padded[32], 0b0000_0011);
        assert_eq!(padded.len(), 33);

        assert_eq!(padded.into_boxed_slice(), bit_vec_padding(data));
    }

    #[test]
    fn test_simple_127() {
        let data = vec![255u8; 127];
        let mut padded = Vec::new();
        let mut reader = Fr32Reader::new(io::Cursor::new(&data));
        reader.read_to_end(&mut padded).unwrap();

        assert_eq!(&padded[0..31], &data[0..31]);
        assert_eq!(padded[31], 0b0011_1111);
        assert_eq!(padded[32], 0b1111_1111);

        assert_eq!(padded.len(), 128);

        assert_eq!(padded.into_boxed_slice(), bit_vec_padding(data));
    }

    #[test]
    fn test_chained_byte_source() {
        let random_bytes: Vec<u8> = (0..127).map(|_| rand::random::<u8>()).collect();

        // read 127 bytes from a non-chained source
        let output_x = {
            let input_x = io::Cursor::new(random_bytes.clone());

            let mut reader = Fr32Reader::new(input_x);
            let mut buf_x = Vec::new();
            reader.read_to_end(&mut buf_x).expect("could not seek");
            buf_x
        };

        for n in 1..127 {
            let random_bytes = random_bytes.clone();

            // read 127 bytes from a n-byte buffer and then the rest
            let output_y = {
                let input_y =
                    io::Cursor::new(random_bytes.iter().take(n).cloned().collect::<Vec<u8>>())
                        .chain(io::Cursor::new(
                            random_bytes.iter().skip(n).cloned().collect::<Vec<u8>>(),
                        ));

                let mut reader = Fr32Reader::new(input_y);
                let mut buf_y = Vec::new();
                reader.read_to_end(&mut buf_y).expect("could not seek");

                buf_y
            };

            assert_eq!(&output_x, &output_y, "should have written same bytes");
            assert_eq!(
                output_x.clone().into_boxed_slice(),
                bit_vec_padding(random_bytes)
            );
        }
    }

    #[test]
    fn test_full() {
        let data = vec![255u8; 127];

        let mut buf = Vec::new();
        let mut reader = Fr32Reader::new(io::Cursor::new(&data));
        reader.read_to_end(&mut buf).unwrap();

        assert_eq!(buf.clone().into_boxed_slice(), bit_vec_padding(data));
        validate_fr32(&buf);
    }

    #[test]
    #[ignore]
    fn test_long() {
        use rand::RngCore;

        let mut rng = rand::thread_rng();
        for i in 1..100 {
            for j in 0..50 {
                let mut data = vec![0u8; i * j];
                rng.fill_bytes(&mut data);

                let mut buf = Vec::new();
                let mut reader = Fr32Reader::new(io::Cursor::new(&data));
                reader.read_to_end(&mut buf).unwrap();

                assert_eq!(buf.clone().into_boxed_slice(), bit_vec_padding(data));
            }
        }
    }

    // Simple (and slow) padder implementation using `BitVec`.
    // It is technically not quite right to use `BitVec` to test this, since at
    // the moment that function still uses
    // it for some corner cases, but since largely this implementation
    // has been replaced it seems reasonable.
    fn bit_vec_padding(raw_data: Vec<u8>) -> Box<[u8]> {
        use bitvec::{order::Lsb0 as LittleEndian, vec::BitVec};
        use itertools::Itertools;

        let mut padded_data: BitVec<LittleEndian, u8> = BitVec::new();
        let raw_data: BitVec<LittleEndian, u8> = BitVec::from(raw_data);

        for data_unit in raw_data.into_iter().chunks(DATA_BITS as usize).into_iter() {
            padded_data.extend(data_unit.into_iter());

            // To avoid reconverting the iterator, we deduce if we need the padding
            // by the length of `padded_data`: a full data unit would not leave the
            // padded layout aligned (it would leave it unaligned by just `pad_bits()`).
            if padded_data.len() % 8 != 0 {
                for _ in 0..(TARGET_BITS - DATA_BITS) {
                    padded_data.push(false);
                }
            }
        }

        padded_data.into_boxed_slice()
    }

    fn validate_fr32(bytes: &[u8]) {
        let chunks = (bytes.len() as f64 / 32 as f64).ceil() as usize;
        for (i, chunk) in bytes.chunks(32).enumerate() {
            let _ = storage_proofs::fr32::bytes_into_fr(chunk).expect(&format!(
                "chunk {}/{} cannot be converted to valid Fr: {:?}",
                i + 1,
                chunks,
                chunk
            ));
        }
    }

    // raw data stream of increasing values and specific
    // outliers (0xFF, 9), check the content of the raw data encoded (with
    // different alignments) in the padded layouts.
    #[test]
    fn test_exotic() {
        let mut source = vec![
            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
            25, 26, 27, 28, 29, 30, 31, 0xff, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
            16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 0xff, 9, 9,
        ];
        source.extend(vec![9, 0xff]);

        let mut buf = Vec::new();
        let mut reader = Fr32Reader::new(io::Cursor::new(&source));
        reader.read_to_end(&mut buf).unwrap();

        for i in 0..31 {
            assert_eq!(buf[i], i as u8 + 1);
        }
        assert_eq!(buf[31], 63); // Six least significant bits of 0xff
        assert_eq!(buf[32], (1 << 2) | 0b11); // 7
        for i in 33..63 {
            assert_eq!(buf[i], (i as u8 - 31) << 2);
        }
        assert_eq!(buf[63], (0x0f << 2)); // 4-bits of ones, half of 0xff, shifted by two, followed by two bits of 0-padding.
        assert_eq!(buf[64], 0x0f | 9 << 4); // The last half of 0xff, 'followed' by 9.
        assert_eq!(buf[65], 9 << 4); // A shifted 9.
        assert_eq!(buf[66], 9 << 4); // Another.
        assert_eq!(buf[67], 0xf0); // The final 0xff is split into two bytes. Here is the first half.
        assert_eq!(buf[68], 0x0f); // And here is the second.

        assert_eq!(buf.into_boxed_slice(), bit_vec_padding(source));
    }
}

'''
'''--- filecoin-proofs/src/lib.rs ---
#![deny(clippy::all, clippy::perf, clippy::correctness)]

mod api;
mod caches;
mod commitment_reader;

pub mod constants;
pub mod fr32;
pub mod fr32_reader;
pub mod param;
pub mod parameters;
pub mod pieces;
pub mod serde_big_array;
pub mod singletons;
pub mod types;

pub use self::api::*;
pub use self::commitment_reader::*;
pub use self::constants::SINGLE_PARTITION_PROOF_LEN;
pub use self::constants::*;
pub use self::param::{ParameterData, ParameterMap};
pub use self::types::*;

pub use storage_proofs;

#[cfg(test)]
pub(crate) const TEST_SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

'''
'''--- filecoin-proofs/src/param.rs ---
use std::collections::BTreeMap;
use std::ffi::OsStr;
use std::fs::File;
use std::io::{stdin, stdout, Write};
use std::path::{Path, PathBuf};

use anyhow::{Context, Result};
use blake2b_simd::State as Blake2b;
use serde::{Deserialize, Serialize};
use storage_proofs::parameter_cache::{
    parameter_cache_dir, CacheEntryMetadata, PARAMETER_METADATA_EXT,
};

const ERROR_STRING: &str = "invalid string";

pub type ParameterMap = BTreeMap<String, ParameterData>;

#[derive(Debug, Deserialize, Serialize)]
pub struct ParameterData {
    pub cid: String,
    pub digest: String,
    pub sector_size: u64,
}

// Produces an absolute path to a file within the cache
pub fn get_full_path_for_file_within_cache(filename: &str) -> PathBuf {
    let mut path = parameter_cache_dir();
    path.push(filename);
    path
}

// Produces a BLAKE2b checksum for a file within the cache
pub fn get_digest_for_file_within_cache(filename: &str) -> Result<String> {
    let path = get_full_path_for_file_within_cache(filename);
    let mut file = File::open(&path).with_context(|| format!("could not open path={:?}", path))?;
    let mut hasher = Blake2b::new();

    std::io::copy(&mut file, &mut hasher)?;

    Ok(hasher.finalize().to_hex()[..32].into())
}

// Prompts the user to approve/reject the message
pub fn choose(message: &str) -> bool {
    loop {
        print!("[y/n] {}: ", message);

        let _ = stdout().flush();
        let mut s = String::new();
        stdin().read_line(&mut s).expect(ERROR_STRING);

        match s.trim().to_uppercase().as_str() {
            "Y" => return true,
            "N" => return false,
            _ => {}
        }
    }
}

// Predicate which matches the provided extension against the given filename
pub fn has_extension<S: AsRef<str>, P: AsRef<Path>>(filename: P, ext: S) -> bool {
    filename
        .as_ref()
        .extension()
        .and_then(OsStr::to_str)
        .map(|s| s == ext.as_ref())
        .unwrap_or(false)
}

// Adds a file extension to the given filename
pub fn add_extension(filename: &str, ext: &str) -> String {
    format!("{}.{}", filename, ext)
}

/// Builds a map from a parameter_id (file in cache) to metadata.
pub fn parameter_id_to_metadata_map(
    parameter_ids: &[String],
) -> Result<BTreeMap<String, CacheEntryMetadata>> {
    let mut map: BTreeMap<String, CacheEntryMetadata> = Default::default();

    for parameter_id in parameter_ids {
        let filename = add_extension(parameter_id, PARAMETER_METADATA_EXT);
        let file_path = get_full_path_for_file_within_cache(&filename);
        let file = File::open(&file_path)
            .with_context(|| format!("could not open path={:?}", file_path))?;

        let meta = serde_json::from_reader(file)?;

        map.insert(parameter_id.to_string(), meta);
    }

    Ok(map)
}

/// Prompts the user to approve/reject the filename
pub fn choose_from<S: AsRef<str>>(
    filenames: &[S],
    lookup: impl Fn(&str) -> Option<u64>,
) -> Result<Vec<String>> {
    let mut chosen_filenames: Vec<String> = vec![];

    for filename in filenames.iter() {
        let sector_size = lookup(filename.as_ref())
            .with_context(|| format!("no sector size found for filename {}", filename.as_ref()))?;

        let msg = format!("(sector size: {}B) {}", sector_size, filename.as_ref());

        if choose(&msg) {
            chosen_filenames.push(filename.as_ref().to_string())
        }
    }

    Ok(chosen_filenames)
}

/// Maps the name of a file in the cache to its parameter id. For example,
/// ABCDEF.vk corresponds to parameter id ABCDEF.
pub fn filename_to_parameter_id<'a, P: AsRef<Path> + 'a>(filename: P) -> Option<String> {
    filename
        .as_ref()
        .file_stem()
        .and_then(OsStr::to_str)
        .map(ToString::to_string)
}

'''
'''--- filecoin-proofs/src/parameters.rs ---
use anyhow::{ensure, Result};
use storage_proofs::porep::stacked::{self, LayerChallenges, StackedDrg};
use storage_proofs::post::fallback;
use storage_proofs::proof::ProofScheme;

use crate::constants::*;
use crate::types::{MerkleTreeTrait, PaddedBytesAmount, PoStConfig};

const DRG_SEED: [u8; 28] = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,
    26, 27,
]; // Arbitrary, need a theory for how to vary this over time.

type WinningPostSetupParams = fallback::SetupParams;
pub type WinningPostPublicParams = fallback::PublicParams;

type WindowPostSetupParams = fallback::SetupParams;
pub type WindowPostPublicParams = fallback::PublicParams;

pub fn public_params<Tree: 'static + MerkleTreeTrait>(
    sector_bytes: PaddedBytesAmount,
    partitions: usize,
) -> Result<stacked::PublicParams<Tree>> {
    StackedDrg::<Tree, DefaultPieceHasher>::setup(&setup_params(sector_bytes, partitions)?)
}

pub fn winning_post_public_params<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
) -> Result<WinningPostPublicParams> {
    fallback::FallbackPoSt::<Tree>::setup(&winning_post_setup_params(&post_config)?)
}

pub fn winning_post_setup_params(post_config: &PoStConfig) -> Result<WinningPostSetupParams> {
    ensure!(
        post_config.challenge_count % post_config.sector_count == 0,
        "sector count must divide challenge count"
    );

    let param_sector_count = post_config.challenge_count / post_config.sector_count;
    let param_challenge_count = post_config.challenge_count / param_sector_count;

    ensure!(
        param_sector_count * param_challenge_count == post_config.challenge_count,
        "invald parameters calculated {} * {} != {}",
        param_sector_count,
        param_challenge_count,
        post_config.challenge_count
    );

    Ok(fallback::SetupParams {
        sector_size: post_config.padded_sector_size().into(),
        challenge_count: param_challenge_count,
        sector_count: param_sector_count,
    })
}

pub fn window_post_public_params<Tree: 'static + MerkleTreeTrait>(
    post_config: &PoStConfig,
) -> Result<WindowPostPublicParams> {
    fallback::FallbackPoSt::<Tree>::setup(&window_post_setup_params(&post_config))
}

pub fn window_post_setup_params(post_config: &PoStConfig) -> WindowPostSetupParams {
    fallback::SetupParams {
        sector_size: post_config.padded_sector_size().into(),
        challenge_count: post_config.challenge_count,
        sector_count: post_config.sector_count,
    }
}

pub fn setup_params(
    sector_bytes: PaddedBytesAmount,
    partitions: usize,
) -> Result<stacked::SetupParams> {
    let layer_challenges = select_challenges(
        partitions,
        *POREP_MINIMUM_CHALLENGES
            .read()
            .unwrap()
            .get(&u64::from(sector_bytes))
            .expect("unknown sector size") as usize,
        *LAYERS
            .read()
            .unwrap()
            .get(&u64::from(sector_bytes))
            .expect("unknown sector size"),
    )?;
    let sector_bytes = u64::from(sector_bytes);

    ensure!(
        sector_bytes % 32 == 0,
        "sector_bytes ({}) must be a multiple of 32",
        sector_bytes,
    );

    let nodes = (sector_bytes / 32) as usize;
    let degree = DRG_DEGREE;
    let expansion_degree = EXP_DEGREE;

    Ok(stacked::SetupParams {
        nodes,
        degree,
        expansion_degree,
        seed: DRG_SEED,
        layer_challenges,
    })
}

fn select_challenges(
    partitions: usize,
    minimum_total_challenges: usize,
    layers: usize,
) -> Result<LayerChallenges> {
    let mut count = 1;
    let mut guess = LayerChallenges::new(layers, count);
    while partitions * guess.challenges_count_all() < minimum_total_challenges {
        count += 1;
        guess = LayerChallenges::new(layers, count);
    }
    Ok(guess)
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::types::PoStType;

    #[test]
    fn partition_layer_challenges_test() {
        let f = |partitions| {
            select_challenges(partitions, 12, 11)
                .unwrap()
                .challenges_count_all()
        };
        // Update to ensure all supported PoRepProofPartitions options are represented here.
        assert_eq!(6, f(usize::from(crate::PoRepProofPartitions(2))));

        assert_eq!(12, f(1));
        assert_eq!(6, f(2));
        assert_eq!(3, f(4));
    }

    #[test]
    fn test_winning_post_params() {
        let config = PoStConfig {
            typ: PoStType::Winning,
            priority: false,
            challenge_count: 66,
            sector_count: 1,
            sector_size: 2048u64.into(),
        };

        let params = winning_post_public_params::<DefaultOctLCTree>(&config).unwrap();
        assert_eq!(params.sector_count, 66);
        assert_eq!(params.challenge_count, 1);
        assert_eq!(params.sector_size, 2048);
    }
}

'''
'''--- filecoin-proofs/src/pieces.rs ---
use std::collections::HashMap;
use std::io::Read;
use std::io::{self, Cursor};
use std::iter::Iterator;
use std::sync::Mutex;

use anyhow::{ensure, Context, Result};
use lazy_static::lazy_static;
use log::info;
use storage_proofs::hasher::{HashFunction, Hasher};
use storage_proofs::util::NODE_SIZE;

use crate::constants::{
    DefaultPieceHasher,
    MINIMUM_RESERVED_BYTES_FOR_PIECE_IN_FULLY_ALIGNED_SECTOR as MINIMUM_PIECE_SIZE,
};
use crate::types::{
    Commitment, PaddedBytesAmount, PieceInfo, SectorSize, UnpaddedByteIndex, UnpaddedBytesAmount,
};

/// Verify that the provided `piece_infos` and `comm_d` match.
pub fn verify_pieces(
    comm_d: &Commitment,
    piece_infos: &[PieceInfo],
    sector_size: SectorSize,
) -> Result<bool> {
    let comm_d_calculated = compute_comm_d(sector_size, piece_infos)?;

    Ok(&comm_d_calculated == comm_d)
}

lazy_static! {
    static ref COMMITMENTS: Mutex<HashMap<SectorSize, Commitment>> = Mutex::new(HashMap::new());
}
use crate::commitment_reader::CommitmentReader;
use crate::fr32_reader::Fr32Reader;

#[derive(Debug, Clone)]
struct EmptySource {
    size: usize,
}

impl EmptySource {
    pub fn new(size: usize) -> Self {
        EmptySource { size }
    }
}

impl Read for EmptySource {
    fn read(&mut self, target: &mut [u8]) -> io::Result<usize> {
        let to_read = std::cmp::min(self.size, target.len());
        self.size -= to_read;
        for val in target {
            *val = 0;
        }

        Ok(to_read)
    }
}

fn empty_comm_d(sector_size: SectorSize) -> Commitment {
    let map = &mut *COMMITMENTS.lock().unwrap();

    *map.entry(sector_size).or_insert_with(|| {
        let size: UnpaddedBytesAmount = sector_size.into();
        let fr32_reader = Fr32Reader::new(EmptySource::new(size.into()));
        let mut commitment_reader = CommitmentReader::new(fr32_reader);
        io::copy(&mut commitment_reader, &mut io::sink()).unwrap();

        let mut comm = [0u8; 32];
        comm.copy_from_slice(
            commitment_reader
                .finish()
                .expect("failed to create commitment")
                .as_ref(),
        );
        comm
    })
}

pub fn compute_comm_d(sector_size: SectorSize, piece_infos: &[PieceInfo]) -> Result<Commitment> {
    info!("verifying {} pieces", piece_infos.len());
    if piece_infos.is_empty() {
        return Ok(empty_comm_d(sector_size));
    }

    let unpadded_sector: UnpaddedBytesAmount = sector_size.into();

    ensure!(
        piece_infos.len() as u64 <= u64::from(unpadded_sector) / MINIMUM_PIECE_SIZE,
        "Too many pieces"
    );

    // make sure the piece sizes are at most a sector size large
    let piece_size: u64 = piece_infos
        .iter()
        .map(|info| u64::from(PaddedBytesAmount::from(info.size)))
        .sum();

    ensure!(
        piece_size <= u64::from(sector_size),
        "Piece is larger than sector."
    );

    let mut stack = Stack::new();

    let first = piece_infos.first().unwrap().clone();
    ensure!(
        u64::from(PaddedBytesAmount::from(first.size)).is_power_of_two(),
        "Piece size ({:?}) must be a power of 2.",
        PaddedBytesAmount::from(first.size)
    );
    stack.shift(first);

    for piece_info in piece_infos.iter().skip(1) {
        ensure!(
            u64::from(PaddedBytesAmount::from(piece_info.size)).is_power_of_two(),
            "Piece size ({:?}) must be a power of 2.",
            PaddedBytesAmount::from(piece_info.size)
        );

        while stack.peek().size < piece_info.size {
            stack.shift_reduce(zero_padding(stack.peek().size)?)?
        }

        stack.shift_reduce(piece_info.clone())?;
    }

    while stack.len() > 1 {
        stack.shift_reduce(zero_padding(stack.peek().size)?)?;
    }

    ensure!(stack.len() == 1, "Stack size ({}) must be 1.", stack.len());

    let comm_d_calculated = stack.pop()?.commitment;

    Ok(comm_d_calculated)
}

/// Stack used for piece reduction.
struct Stack(Vec<PieceInfo>);

impl Stack {
    /// Creates a new stack.
    pub fn new() -> Self {
        Stack(Vec::new())
    }

    /// Pushes a single element onto the stack.
    pub fn shift(&mut self, el: PieceInfo) {
        self.0.push(el)
    }

    /// Look at the last element of the stack.
    pub fn peek(&self) -> &PieceInfo {
        &self.0[self.0.len() - 1]
    }

    /// Look at the second to last element of the stack.
    pub fn peek2(&self) -> &PieceInfo {
        &self.0[self.0.len() - 2]
    }

    /// Pop the last element of the stack.
    pub fn pop(&mut self) -> Result<PieceInfo> {
        self.0.pop().context("empty stack popped")
    }

    pub fn reduce1(&mut self) -> Result<bool> {
        if self.len() < 2 {
            return Ok(false);
        }

        if self.peek().size == self.peek2().size {
            let right = self.pop()?;
            let left = self.pop()?;
            let joined = join_piece_infos(left, right)?;
            self.shift(joined);
            return Ok(true);
        }

        Ok(false)
    }

    pub fn reduce(&mut self) -> Result<()> {
        while self.reduce1()? {}
        Ok(())
    }

    pub fn shift_reduce(&mut self, piece: PieceInfo) -> Result<()> {
        self.shift(piece);
        self.reduce()
    }

    pub fn len(&self) -> usize {
        self.0.len()
    }
}

/// Create a padding `PieceInfo` of size `size`.
fn zero_padding(size: UnpaddedBytesAmount) -> Result<PieceInfo> {
    let padded_size: PaddedBytesAmount = size.into();
    let mut commitment = [0u8; 32];

    // TODO: cache common piece hashes
    let mut hashed_size = 64;
    let h1 = piece_hash(&commitment, &commitment);
    commitment.copy_from_slice(h1.as_ref());

    while hashed_size < u64::from(padded_size) {
        let h = piece_hash(&commitment, &commitment);
        commitment.copy_from_slice(h.as_ref());
        hashed_size *= 2;
    }

    ensure!(
        hashed_size == u64::from(padded_size),
        "Hashed size must equal padded size"
    );

    PieceInfo::new(commitment, size)
}

/// Join two equally sized `PieceInfo`s together, by hashing them and adding their sizes.
fn join_piece_infos(mut left: PieceInfo, right: PieceInfo) -> Result<PieceInfo> {
    ensure!(
        left.size == right.size,
        "Piece sizes must be equal (left: {:?}, right: {:?})",
        left.size,
        right.size
    );
    let h = piece_hash(&left.commitment, &right.commitment);

    left.commitment.copy_from_slice(AsRef::<[u8]>::as_ref(&h));
    left.size = left.size + right.size;
    Ok(left)
}

pub(crate) fn piece_hash(a: &[u8], b: &[u8]) -> <DefaultPieceHasher as Hasher>::Domain {
    let mut buf = [0u8; NODE_SIZE * 2];
    buf[..NODE_SIZE].copy_from_slice(a);
    buf[NODE_SIZE..].copy_from_slice(b);
    <DefaultPieceHasher as Hasher>::Function::hash(&buf)
}

#[derive(Debug, Clone)]
pub struct PieceAlignment {
    pub left_bytes: UnpaddedBytesAmount,
    pub right_bytes: UnpaddedBytesAmount,
}

impl PieceAlignment {
    pub fn sum(&self, piece_size: UnpaddedBytesAmount) -> UnpaddedBytesAmount {
        self.left_bytes + piece_size + self.right_bytes
    }
}

/// Given a list of pieces, sum the number of bytes taken by those pieces in that order.
pub fn sum_piece_bytes_with_alignment(pieces: &[UnpaddedBytesAmount]) -> UnpaddedBytesAmount {
    pieces
        .iter()
        .fold(UnpaddedBytesAmount(0), |acc, piece_bytes| {
            acc + get_piece_alignment(acc, *piece_bytes).sum(*piece_bytes)
        })
}

/// Given a list of pieces, find the byte where a given piece does or would start.
pub fn get_piece_start_byte(
    pieces: &[UnpaddedBytesAmount],
    piece_bytes: UnpaddedBytesAmount,
) -> UnpaddedByteIndex {
    // sum up all the bytes taken by the ordered pieces
    let last_byte = sum_piece_bytes_with_alignment(&pieces);
    let alignment = get_piece_alignment(last_byte, piece_bytes);

    // add only the left padding of the target piece to give the start of that piece's data
    UnpaddedByteIndex::from(last_byte + alignment.left_bytes)
}

/// Given a number of bytes already written to a staged sector (ignoring bit padding) and a number
/// of bytes (before bit padding) to be added, return the alignment required to create a piece where
/// len(piece) == len(sector size)/(2^n) and sufficient left padding to ensure simple merkle proof
/// construction.
pub fn get_piece_alignment(
    written_bytes: UnpaddedBytesAmount,
    piece_bytes: UnpaddedBytesAmount,
) -> PieceAlignment {
    let mut piece_bytes_needed = MINIMUM_PIECE_SIZE as u64;

    // Calculate the next power of two multiple that will fully contain the piece's data.
    // This is required to ensure a clean piece merkle root, without being affected by
    // preceding or following pieces.
    while piece_bytes_needed < u64::from(piece_bytes) {
        piece_bytes_needed *= 2;
    }

    // Calculate the bytes being affected from the left of the piece by the previous piece.
    let encroaching = u64::from(written_bytes) % piece_bytes_needed;

    // Calculate the bytes to push from the left to ensure a clean piece merkle root.
    let left_bytes = if encroaching > 0 {
        piece_bytes_needed - encroaching
    } else {
        0
    };

    let right_bytes = piece_bytes_needed - u64::from(piece_bytes);

    PieceAlignment {
        left_bytes: UnpaddedBytesAmount(left_bytes),
        right_bytes: UnpaddedBytesAmount(right_bytes),
    }
}

/// Wraps a Readable source with null bytes on either end according to a provided PieceAlignment.
fn with_alignment(source: impl Read, piece_alignment: PieceAlignment) -> impl Read {
    let PieceAlignment {
        left_bytes,
        right_bytes,
    } = piece_alignment;

    let left_padding = Cursor::new(vec![0; left_bytes.into()]);
    let right_padding = Cursor::new(vec![0; right_bytes.into()]);

    left_padding.chain(source).chain(right_padding)
}

/// Given an enumeration of pieces in a staged sector and a piece to be added (represented by a Read
/// and corresponding length, in UnpaddedBytesAmount) to the staged sector, produce a new Read and
/// UnpaddedBytesAmount pair which includes the appropriate amount of alignment bytes for the piece
/// to be written to the target staged sector.
pub fn get_aligned_source<T: Read>(
    source: T,
    pieces: &[UnpaddedBytesAmount],
    piece_bytes: UnpaddedBytesAmount,
) -> (UnpaddedBytesAmount, PieceAlignment, impl Read) {
    let written_bytes = sum_piece_bytes_with_alignment(pieces);
    let piece_alignment = get_piece_alignment(written_bytes, piece_bytes);
    let expected_num_bytes_written =
        piece_alignment.left_bytes + piece_bytes + piece_alignment.right_bytes;

    (
        expected_num_bytes_written,
        piece_alignment.clone(),
        with_alignment(source, piece_alignment),
    )
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::api::util::commitment_from_fr;
    use crate::constants::{DRG_DEGREE, EXP_DEGREE};
    use crate::types::DataTree;

    use paired::bls12_381::Fr;
    use rand::{Rng, RngCore, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use storage_proofs::drgraph::{new_seed, Graph};
    use storage_proofs::merkle::create_base_merkle_tree;
    use storage_proofs::porep::stacked::StackedBucketGraph;

    #[test]
    fn test_empty_source() {
        let mut source = EmptySource::new(12);
        let mut target = Vec::new();
        source.read_to_end(&mut target).unwrap();
        assert_eq!(target, vec![0u8; 12]);
    }

    #[test]
    fn test_compute_comm_d_empty() {
        let comm_d = compute_comm_d(SectorSize(2048), &[]).unwrap();
        assert_eq!(
            comm_d,
            [
                252, 126, 146, 130, 150, 229, 22, 250, 173, 233, 134, 178, 143, 146, 212, 74, 79,
                36, 185, 53, 72, 82, 35, 55, 106, 121, 144, 39, 188, 24, 248, 51
            ]
        );

        let comm_d = compute_comm_d(SectorSize(128), &[]).unwrap();
        assert_eq!(
            hex::encode(&comm_d),
            "3731bb99ac689f66eef5973e4a94da188f4ddcae580724fc6f3fd60dfd488333",
        );
    }

    #[test]
    fn test_get_piece_alignment() {
        let table = vec![
            (0, 0, (0, 127)),
            (0, 127, (0, 0)),
            (0, 254, (0, 0)),
            (0, 508, (0, 0)),
            (0, 1016, (0, 0)),
            (127, 127, (0, 0)),
            (127, 254, (127, 0)),
            (127, 508, (381, 0)),
            (100, 100, (27, 27)),
            (200, 200, (54, 54)),
            (300, 300, (208, 208)),
        ];

        for (bytes_in_sector, bytes_in_piece, (expected_left_align, expected_right_align)) in
            table.clone()
        {
            let PieceAlignment {
                left_bytes: UnpaddedBytesAmount(actual_left_align),
                right_bytes: UnpaddedBytesAmount(actual_right_align),
            } = get_piece_alignment(
                UnpaddedBytesAmount(bytes_in_sector),
                UnpaddedBytesAmount(bytes_in_piece),
            );
            assert_eq!(
                (expected_left_align, expected_right_align),
                (actual_left_align, actual_right_align)
            );
        }
    }

    #[test]
    fn test_get_piece_start_byte() {
        let pieces = [
            UnpaddedBytesAmount(31),
            UnpaddedBytesAmount(32),
            UnpaddedBytesAmount(33),
        ];

        assert_eq!(
            get_piece_start_byte(&pieces[..0], pieces[0]),
            UnpaddedByteIndex(0)
        );
        assert_eq!(
            get_piece_start_byte(&pieces[..1], pieces[1]),
            UnpaddedByteIndex(127)
        );
        assert_eq!(
            get_piece_start_byte(&pieces[..2], pieces[2]),
            UnpaddedByteIndex(254)
        );
    }

    #[test]
    fn test_verify_simple_pieces() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        //     g
        //   /  \
        //  e    f
        // / \  / \
        // a  b c  d

        let (a, b, c, d): ([u8; 32], [u8; 32], [u8; 32], [u8; 32]) = rng.gen();

        let mut e = [0u8; 32];
        let h = piece_hash(&a, &b);
        e.copy_from_slice(h.as_ref());

        let mut f = [0u8; 32];
        let h = piece_hash(&c, &d);
        f.copy_from_slice(h.as_ref());

        let mut g = [0u8; 32];
        let h = piece_hash(&e, &f);
        g.copy_from_slice(h.as_ref());
        let a = PieceInfo::new(a, UnpaddedBytesAmount(127)).unwrap();
        let b = PieceInfo::new(b, UnpaddedBytesAmount(127)).unwrap();
        let c = PieceInfo::new(c, UnpaddedBytesAmount(127)).unwrap();
        let d = PieceInfo::new(d, UnpaddedBytesAmount(127)).unwrap();

        let e = PieceInfo::new(e, UnpaddedBytesAmount(254)).unwrap();
        let f = PieceInfo::new(f, UnpaddedBytesAmount(254)).unwrap();
        let g = PieceInfo::new(g, UnpaddedBytesAmount(508)).unwrap();

        let sector_size = SectorSize(4 * 128);
        let comm_d = g.commitment;

        // println!("e: {:?}", e);
        // println!("f: {:?}", f);
        // println!("g: {:?}", g);

        assert!(
            verify_pieces(
                &comm_d,
                &vec![a.clone(), b.clone(), c.clone(), d.clone()],
                sector_size
            )
            .expect("failed to verify"),
            "[a, b, c, d]"
        );

        assert!(
            verify_pieces(&comm_d, &vec![e.clone(), c.clone(), d.clone()], sector_size)
                .expect("failed to verify"),
            "[e, c, d]"
        );

        assert!(
            verify_pieces(&comm_d, &vec![e.clone(), f.clone()], sector_size)
                .expect("failed to verify"),
            "[e, f]"
        );

        assert!(
            verify_pieces(&comm_d, &vec![a.clone(), b.clone(), f.clone()], sector_size)
                .expect("failed to verify"),
            "[a, b, f]"
        );

        assert!(
            verify_pieces(&comm_d, &vec![g], sector_size).expect("failed to verify"),
            "[g]"
        );
    }

    #[test]
    fn test_verify_padded_pieces() {
        // [
        //   {(A0 00) (BB BB)} -> A(1) P(1) P(1) P(1) B(4)
        //   {(CC 00) (00 00)} -> C(2)      P(1) P(1) P(1) P(1) P(1) P(1)
        // ]
        // [
        //   {(DD DD) (DD DD)} -> D(8)
        //   {(00 00) (00 00)} -> P(1) P(1) P(1) P(1) P(1) P(1) P(1) P(1)
        // ]

        let sector_size = SectorSize(32 * 128);
        let pad = zero_padding(UnpaddedBytesAmount(127)).unwrap();

        let pieces = vec![
            PieceInfo::new([1u8; 32], UnpaddedBytesAmount(1 * 127)).unwrap(),
            PieceInfo::new([2u8; 32], UnpaddedBytesAmount(4 * 127)).unwrap(),
            PieceInfo::new([3u8; 32], UnpaddedBytesAmount(2 * 127)).unwrap(),
            PieceInfo::new([4u8; 32], UnpaddedBytesAmount(8 * 127)).unwrap(),
        ];

        let padded_pieces = vec![
            PieceInfo::new([1u8; 32], UnpaddedBytesAmount(1 * 127)).unwrap(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            PieceInfo::new([2u8; 32], UnpaddedBytesAmount(4 * 127)).unwrap(),
            PieceInfo::new([3u8; 32], UnpaddedBytesAmount(2 * 127)).unwrap(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            PieceInfo::new([4u8; 32], UnpaddedBytesAmount(8 * 127)).unwrap(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
            pad.clone(),
        ];

        let hash = |a, b| {
            let hash = piece_hash(a, b);
            let mut res = [0u8; 32];
            res.copy_from_slice(hash.as_ref());
            res
        };

        let layer1: Vec<[u8; 32]> = vec![
            hash(&padded_pieces[0].commitment, &padded_pieces[1].commitment), // 2: H(A(1) | P(1))
            hash(&padded_pieces[2].commitment, &padded_pieces[3].commitment), // 2: H(P(1) | P(1))
            padded_pieces[4].commitment,                                      // 4: B(4)
            padded_pieces[5].commitment,                                      // 2: C(2)
            hash(&padded_pieces[6].commitment, &padded_pieces[7].commitment), // 2: H(P(1) | P(1))
            hash(&padded_pieces[8].commitment, &padded_pieces[9].commitment), // 2: H(P(1) | P(1))
            hash(&padded_pieces[10].commitment, &padded_pieces[11].commitment), // 2: H(P(1) | P(1))
            padded_pieces[12].commitment,                                     // 8: D(8)
            hash(&padded_pieces[13].commitment, &padded_pieces[14].commitment), // 2: H(P(1) | P(1))
            hash(&padded_pieces[15].commitment, &padded_pieces[16].commitment), // 2: H(P(1) | P(1))
            hash(&padded_pieces[17].commitment, &padded_pieces[18].commitment), // 2: H(P(1) | P(1))
            hash(&padded_pieces[19].commitment, &padded_pieces[20].commitment), // 2: H(P(1) | P(1))
        ];

        let layer2: Vec<[u8; 32]> = vec![
            hash(&layer1[0], &layer1[1]),   // 4
            layer1[2],                      // 4
            hash(&layer1[3], &layer1[4]),   // 4
            hash(&layer1[5], &layer1[6]),   // 4
            layer1[7],                      // 8
            hash(&layer1[8], &layer1[9]),   // 4
            hash(&layer1[10], &layer1[11]), // 4
        ];

        let layer3 = vec![
            hash(&layer2[0], &layer2[1]), // 8
            hash(&layer2[2], &layer2[3]), // 8
            layer2[4],                    // 8
            hash(&layer2[5], &layer2[6]), // 8
        ];

        let layer4 = vec![
            hash(&layer3[0], &layer3[1]), // 16
            hash(&layer3[2], &layer3[3]), // 16
        ];

        let comm_d = hash(&layer4[0], &layer4[1]); // 32

        assert!(verify_pieces(&comm_d, &pieces, sector_size).unwrap());
    }

    #[ignore] // slow test
    #[test]
    fn test_verify_random_pieces() -> Result<()> {
        use crate::pieces::*;

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for sector_size in &[
            SectorSize(4 * 128),
            SectorSize(32 * 128),
            SectorSize(1024 * 128),
            SectorSize(1024 * 8 * 128),
        ] {
            println!("--- {:?} ---", sector_size);
            for i in 0..100 {
                println!(" - {} -", i);
                let unpadded_sector_size: UnpaddedBytesAmount = sector_size.clone().into();
                let sector_size = *sector_size;
                let padded_sector_size: PaddedBytesAmount = sector_size.into();

                let mut piece_sizes = Vec::new();
                loop {
                    let sum_piece_sizes: PaddedBytesAmount =
                        sum_piece_bytes_with_alignment(&piece_sizes).into();

                    if sum_piece_sizes > padded_sector_size {
                        piece_sizes.pop();
                        break;
                    }
                    if sum_piece_sizes == padded_sector_size {
                        break;
                    }

                    'inner: loop {
                        // pieces must be power of two
                        let left = u64::from(padded_sector_size) - u64::from(sum_piece_sizes);
                        let left_power_of_two = prev_power_of_two(left as u32);
                        let max_exp = (left_power_of_two as f64).log2() as u32;

                        let padded_exp = if max_exp > 7 {
                            rng.gen_range(
                                7, // 2**7 == 128,
                                max_exp,
                            )
                        } else {
                            7
                        };
                        let padded_piece_size = 2u64.pow(padded_exp);
                        let piece_size: UnpaddedBytesAmount =
                            PaddedBytesAmount(padded_piece_size).into();
                        piece_sizes.push(piece_size);
                        let sum: PaddedBytesAmount =
                            sum_piece_bytes_with_alignment(&piece_sizes).into();

                        if sum > padded_sector_size {
                            // pieces might be too large after padding, so remove them and try again.
                            piece_sizes.pop();
                        } else {
                            break 'inner;
                        }
                    }
                }

                // println!(
                //     "  {:?}",
                //     piece_sizes
                //         .iter()
                //         .map(|s| u64::from(*s) / 127)
                //         .collect::<Vec<_>>()
                // );
                assert!(sum_piece_bytes_with_alignment(&piece_sizes) <= unpadded_sector_size);
                assert!(!piece_sizes.is_empty());

                let (comm_d, piece_infos) = build_sector(&piece_sizes, sector_size)?;

                assert!(
                    verify_pieces(&comm_d, &piece_infos, sector_size)?,
                    "invalid pieces"
                );
            }
        }

        Ok(())
    }

    fn build_sector(
        piece_sizes: &[UnpaddedBytesAmount],
        sector_size: SectorSize,
    ) -> Result<([u8; 32], Vec<PieceInfo>)> {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
        let graph = StackedBucketGraph::<DefaultPieceHasher>::new_stacked(
            u64::from(sector_size) as usize / NODE_SIZE,
            DRG_DEGREE,
            EXP_DEGREE,
            new_seed(),
        )?;

        let mut staged_sector = Vec::with_capacity(u64::from(sector_size) as usize);
        let mut staged_sector_io = std::io::Cursor::new(&mut staged_sector);
        let mut piece_infos = Vec::with_capacity(piece_sizes.len());

        for (i, piece_size) in piece_sizes.iter().enumerate() {
            let piece_size_u = u64::from(*piece_size) as usize;
            let mut piece_bytes = vec![255u8; piece_size_u];
            rng.fill_bytes(&mut piece_bytes);

            let mut piece_file = std::io::Cursor::new(&mut piece_bytes);

            let (piece_info, _) = crate::api::add_piece(
                &mut piece_file,
                &mut staged_sector_io,
                *piece_size,
                &piece_sizes[..i],
            )?;

            piece_infos.push(piece_info);
        }
        assert_eq!(staged_sector.len(), u64::from(sector_size) as usize);

        let data_tree: DataTree =
            create_base_merkle_tree::<DataTree>(None, graph.size(), &staged_sector).unwrap();
        let comm_d_root: Fr = data_tree.root().into();
        let comm_d = commitment_from_fr(comm_d_root);

        Ok((comm_d, piece_infos))
    }

    fn prev_power_of_two(mut x: u32) -> u32 {
        x |= x >> 1;
        x |= x >> 2;
        x |= x >> 4;
        x |= x >> 8;
        x |= x >> 16;
        x - (x >> 1)
    }
}

'''
'''--- filecoin-proofs/src/serde_big_array.rs ---
use serde::de::{Deserialize, Deserializer, Error, SeqAccess, Visitor};
use serde::ser::{Serialize, SerializeTuple, Serializer};
use std::fmt;
use std::marker::PhantomData;

// serde doesn't know how to serialize big arrays out of the box
// see: https://github.com/serde-rs/serde/issues/631

pub trait BigArray<'de>: Sized {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer;
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>;
}

macro_rules! big_array {
    ($($len:expr,)+) => {
        $(
            impl<'de, T> BigArray<'de> for [T; $len]
                where T: Default + Copy + Serialize + Deserialize<'de>
            {
                fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
                    where S: Serializer
                {
                    let mut seq = serializer.serialize_tuple(self.len())?;
                    for elem in &self[..] {
                        seq.serialize_element(elem)?;
                    }
                    seq.end()
                }

                fn deserialize<D>(deserializer: D) -> Result<[T; $len], D::Error>
                    where D: Deserializer<'de>
                {
                    struct ArrayVisitor<T> {
                        element: PhantomData<T>,
                    }

                    impl<'de, T> Visitor<'de> for ArrayVisitor<T>
                        where T: Default + Copy + Deserialize<'de>
                    {
                        type Value = [T; $len];

                        fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
                            formatter.write_str(concat!("an array of length ", $len))
                        }

                        fn visit_seq<A>(self, mut seq: A) -> Result<[T; $len], A::Error>
                            where A: SeqAccess<'de>
                        {
                            let mut arr = [T::default(); $len];
                            for (i, element) in arr.iter_mut().enumerate() {
                                *element = seq.next_element()?.ok_or_else(|| Error::invalid_length(i, &self))?
                            }
                            Ok(arr)
                        }
                    }

                    let visitor = ArrayVisitor { element: PhantomData };
                    deserializer.deserialize_tuple($len, visitor)
                }
            }
        )+
    }
}

big_array! {
    40, 48, 50, 56, 64, 72, 96, 100, 128, 160, 192, 200, 224, 256, 384, 512,
    768, 1024, 2048, 4096, 8192, 16384, 32768, 65536,
}

'''
'''--- filecoin-proofs/src/singletons.rs ---
use ff::PrimeField;
use lazy_static::lazy_static;
use paired::bls12_381::Fr;

use storage_proofs::hasher::pedersen::PedersenDomain;

lazy_static! {
    pub static ref POST_VDF_KEY: PedersenDomain =
        PedersenDomain(Fr::from_str("12345").unwrap().into_repr());
}

'''
'''--- filecoin-proofs/src/types/bytes_amount.rs ---
use std::ops::{Add, Sub};

use serde::{Deserialize, Serialize};

use crate::fr32::{to_padded_bytes, to_unpadded_bytes};

pub struct PoStProofBytesAmount(pub usize);

pub struct PoRepProofBytesAmount(pub usize);

#[derive(Debug, Default, Clone, Copy, PartialEq, PartialOrd, Serialize, Deserialize, Eq, Ord)]
pub struct UnpaddedByteIndex(pub u64);

#[derive(Debug, Default, Clone, Copy, PartialEq, PartialOrd, Serialize, Deserialize, Eq, Ord)]
pub struct UnpaddedBytesAmount(pub u64);

#[derive(Debug, Default, Clone, Copy, PartialEq, PartialOrd, Serialize, Deserialize, Eq, Ord)]
pub struct PaddedBytesAmount(pub u64);

impl From<UnpaddedBytesAmount> for u64 {
    fn from(n: UnpaddedBytesAmount) -> Self {
        n.0
    }
}

impl From<UnpaddedBytesAmount> for usize {
    fn from(n: UnpaddedBytesAmount) -> Self {
        n.0 as usize
    }
}

impl From<UnpaddedBytesAmount> for PaddedBytesAmount {
    fn from(n: UnpaddedBytesAmount) -> Self {
        PaddedBytesAmount(to_padded_bytes(n.0 as usize) as u64)
    }
}

impl From<PaddedBytesAmount> for u64 {
    fn from(n: PaddedBytesAmount) -> Self {
        n.0
    }
}

impl From<PaddedBytesAmount> for usize {
    fn from(n: PaddedBytesAmount) -> Self {
        n.0 as usize
    }
}

impl From<PaddedBytesAmount> for UnpaddedBytesAmount {
    fn from(n: PaddedBytesAmount) -> Self {
        UnpaddedBytesAmount(to_unpadded_bytes(n.0))
    }
}

impl From<UnpaddedBytesAmount> for UnpaddedByteIndex {
    fn from(n: UnpaddedBytesAmount) -> Self {
        UnpaddedByteIndex(n.0)
    }
}

impl From<UnpaddedByteIndex> for UnpaddedBytesAmount {
    fn from(n: UnpaddedByteIndex) -> Self {
        UnpaddedBytesAmount(n.0)
    }
}

impl From<UnpaddedByteIndex> for u64 {
    fn from(n: UnpaddedByteIndex) -> Self {
        n.0
    }
}

impl From<UnpaddedByteIndex> for usize {
    fn from(n: UnpaddedByteIndex) -> Self {
        n.0 as usize
    }
}

impl Add for UnpaddedBytesAmount {
    type Output = UnpaddedBytesAmount;

    fn add(self, other: UnpaddedBytesAmount) -> UnpaddedBytesAmount {
        UnpaddedBytesAmount(self.0 + other.0)
    }
}

impl Add for PaddedBytesAmount {
    type Output = PaddedBytesAmount;

    fn add(self, other: PaddedBytesAmount) -> PaddedBytesAmount {
        PaddedBytesAmount(self.0 + other.0)
    }
}

impl Sub for UnpaddedBytesAmount {
    type Output = UnpaddedBytesAmount;

    fn sub(self, other: UnpaddedBytesAmount) -> UnpaddedBytesAmount {
        UnpaddedBytesAmount(self.0 - other.0)
    }
}

impl Sub for PaddedBytesAmount {
    type Output = PaddedBytesAmount;

    fn sub(self, other: PaddedBytesAmount) -> PaddedBytesAmount {
        PaddedBytesAmount(self.0 - other.0)
    }
}

impl From<PoStProofBytesAmount> for usize {
    fn from(x: PoStProofBytesAmount) -> Self {
        x.0
    }
}

impl From<PoRepProofBytesAmount> for usize {
    fn from(x: PoRepProofBytesAmount) -> Self {
        x.0
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn allowed_operations() {
        let a = UnpaddedBytesAmount(1);
        let b = UnpaddedBytesAmount(2);
        let c = UnpaddedBytesAmount(3);

        let d = PaddedBytesAmount(1);
        let e = PaddedBytesAmount(2);
        let f = PaddedBytesAmount(3);

        // Operations between UnpaddedBytesAmounts are allowed
        assert_eq!(a + b, c);
        assert_eq!(c - b, a);

        // Operations between PaddedBytesAmounts are allowed
        assert_eq!(d + e, f);
        assert_eq!(f - e, d);

        // Mixed operations fail at compile time.
        // assert_eq!(a + b, f);

        // Coercion to primitives work
        assert_eq!(1u64 + u64::from(b), 3u64);
        assert_eq!(1usize + usize::from(b), 3usize);
        assert_eq!(1u64 + u64::from(e), 3u64);
        assert_eq!(1usize + usize::from(e), 3usize);

        // But not between BytesAmount types
        // assert_eq!(a + UnpaddedBytesAmount::from(e), c);
        // assert_eq!(d + UnpaddedBytesAmount::from(b), f);

        // But must be explicit or won't compile.
        // assert_eq!(1u64 + b, 3u64);
        // assert_eq!(1usize + b, 3usize);
        // assert_eq!(1u64 + u64::from(e), 3u64);
        // assert_eq!(1usize + usize::from(e), 3usize);
    }
}

'''
'''--- filecoin-proofs/src/types/mod.rs ---
use serde::{Deserialize, Serialize};
use storage_proofs::hasher::Hasher;
use storage_proofs::porep::stacked;

use crate::constants::*;

mod bytes_amount;
mod piece_info;
mod porep_config;
mod porep_proof_partitions;
mod post_config;
mod post_proof_partitions;
mod sector_class;
mod sector_size;

pub use self::bytes_amount::*;
pub use self::piece_info::*;
pub use self::porep_config::*;
pub use self::porep_proof_partitions::*;
pub use self::post_config::*;
pub use self::post_proof_partitions::*;
pub use self::sector_class::*;
pub use self::sector_size::*;

pub type Commitment = [u8; 32];
pub type ChallengeSeed = [u8; 32];
pub use stacked::PersistentAux;
pub use stacked::TemporaryAux;
pub type ProverId = [u8; 32];
pub type Ticket = [u8; 32];

pub type Tree = storage_proofs::merkle::OctMerkleTree<DefaultTreeHasher>;
pub type LCTree = storage_proofs::merkle::OctLCMerkleTree<DefaultTreeHasher>;

pub use storage_proofs::porep::stacked::Labels;
pub type DataTree = storage_proofs::merkle::BinaryMerkleTree<DefaultPieceHasher>;

pub use storage_proofs::merkle::MerkleTreeTrait;

/// Arity for oct trees, used for comm_r_last.
pub const OCT_ARITY: usize = 8;

/// Arity for binary trees, used for comm_d.
pub const BINARY_ARITY: usize = 2;

#[derive(Debug, Clone)]
pub struct SealPreCommitOutput {
    pub comm_r: Commitment,
    pub comm_d: Commitment,
}

pub type VanillaSealProof<Tree> = storage_proofs::porep::stacked::Proof<Tree, DefaultPieceHasher>;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SealCommitPhase1Output<Tree: MerkleTreeTrait> {
    pub vanilla_proofs: Vec<Vec<VanillaSealProof<Tree>>>,
    pub comm_r: Commitment,
    pub comm_d: Commitment,
    pub replica_id: <Tree::Hasher as Hasher>::Domain,
    pub seed: Ticket,
    pub ticket: Ticket,
}

#[derive(Clone, Debug)]
pub struct SealCommitOutput {
    pub proof: Vec<u8>,
}

pub use merkletree::store::StoreConfig;

#[derive(Debug, Serialize, Deserialize)]
pub struct SealPreCommitPhase1Output<Tree: MerkleTreeTrait> {
    pub labels: Labels<Tree>,
    pub config: StoreConfig,
    pub comm_d: Commitment,
}

'''
'''--- filecoin-proofs/src/types/piece_info.rs ---
use std::fmt;

use anyhow::{ensure, Result};

use crate::types::{Commitment, UnpaddedBytesAmount};

#[derive(Clone, Default, PartialEq, Eq)]
pub struct PieceInfo {
    pub commitment: Commitment,
    pub size: UnpaddedBytesAmount,
}

impl fmt::Debug for PieceInfo {
    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {
        fmt.debug_struct("PieceInfo")
            .field("commitment", &hex::encode(&self.commitment))
            .field("size", &self.size)
            .finish()
    }
}

impl PieceInfo {
    pub fn new(commitment: Commitment, size: UnpaddedBytesAmount) -> Result<Self> {
        ensure!(commitment != [0; 32], "Invalid all zero commitment");
        Ok(PieceInfo { commitment, size })
    }
}

'''
'''--- filecoin-proofs/src/types/porep_config.rs ---
use std::path::PathBuf;

use anyhow::Result;
use storage_proofs::parameter_cache::{self, CacheableParameters};
use storage_proofs::porep::stacked::{StackedCircuit, StackedCompound};

use crate::constants::DefaultPieceHasher;
use crate::types::*;

#[derive(Clone, Copy, Debug)]
pub struct PoRepConfig {
    pub sector_size: SectorSize,
    pub partitions: PoRepProofPartitions,
}

impl From<PoRepConfig> for PaddedBytesAmount {
    fn from(x: PoRepConfig) -> Self {
        let PoRepConfig { sector_size, .. } = x;
        PaddedBytesAmount::from(sector_size)
    }
}

impl From<PoRepConfig> for UnpaddedBytesAmount {
    fn from(x: PoRepConfig) -> Self {
        let PoRepConfig { sector_size, .. } = x;
        PaddedBytesAmount::from(sector_size).into()
    }
}

impl From<PoRepConfig> for PoRepProofPartitions {
    fn from(x: PoRepConfig) -> Self {
        let PoRepConfig { partitions, .. } = x;
        partitions
    }
}

impl From<PoRepConfig> for SectorSize {
    fn from(cfg: PoRepConfig) -> Self {
        let PoRepConfig { sector_size, .. } = cfg;
        sector_size
    }
}

impl PoRepConfig {
    /// Returns the cache identifier as used by `storage-proofs::paramater_cache`.
    pub fn get_cache_identifier<Tree: 'static + MerkleTreeTrait>(&self) -> Result<String> {
        let params = crate::parameters::public_params::<Tree>(
            self.sector_size.into(),
            self.partitions.into(),
        )?;

        Ok(
            <StackedCompound<Tree, DefaultPieceHasher> as CacheableParameters<
                StackedCircuit<Tree, DefaultPieceHasher>,
                _,
            >>::cache_identifier(&params),
        )
    }

    pub fn get_cache_metadata_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_metadata_path(&id))
    }

    pub fn get_cache_verifying_key_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_verifying_key_path(&id))
    }

    pub fn get_cache_params_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_params_path(&id))
    }
}

'''
'''--- filecoin-proofs/src/types/porep_proof_partitions.rs ---
#[derive(Clone, Copy, Debug)]
pub struct PoRepProofPartitions(pub u8);

impl From<PoRepProofPartitions> for usize {
    fn from(x: PoRepProofPartitions) -> Self {
        x.0 as usize
    }
}

'''
'''--- filecoin-proofs/src/types/post_config.rs ---
use std::path::PathBuf;

use anyhow::Result;
use storage_proofs::parameter_cache::{self, CacheableParameters};
use storage_proofs::post::fallback;

use crate::types::*;

#[derive(Clone, Debug)]
pub struct PoStConfig {
    pub sector_size: SectorSize,
    pub challenge_count: usize,
    pub sector_count: usize,
    pub typ: PoStType,
    /// High priority (always runs on GPU) == true
    pub priority: bool,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum PoStType {
    Winning,
    Window,
}

impl From<PoStConfig> for PaddedBytesAmount {
    fn from(x: PoStConfig) -> Self {
        let PoStConfig { sector_size, .. } = x;
        PaddedBytesAmount::from(sector_size)
    }
}

impl From<PoStConfig> for UnpaddedBytesAmount {
    fn from(x: PoStConfig) -> Self {
        let PoStConfig { sector_size, .. } = x;
        PaddedBytesAmount::from(sector_size).into()
    }
}

impl PoStConfig {
    pub fn padded_sector_size(&self) -> PaddedBytesAmount {
        PaddedBytesAmount::from(self.sector_size)
    }

    pub fn unpadded_sector_size(&self) -> UnpaddedBytesAmount {
        PaddedBytesAmount::from(self.sector_size).into()
    }

    /// Returns the cache identifier as used by `storage-proofs::paramater_cache`.
    pub fn get_cache_identifier<Tree: 'static + MerkleTreeTrait>(&self) -> Result<String> {
        match self.typ {
            PoStType::Winning => {
                let params = crate::parameters::winning_post_public_params::<Tree>(self)?;

                Ok(
                    <fallback::FallbackPoStCompound<Tree> as CacheableParameters<
                        fallback::FallbackPoStCircuit<Tree>,
                        _,
                    >>::cache_identifier(&params),
                )
            }
            PoStType::Window => {
                let params = crate::parameters::window_post_public_params::<Tree>(self)?;

                Ok(
                    <fallback::FallbackPoStCompound<Tree> as CacheableParameters<
                        fallback::FallbackPoStCircuit<Tree>,
                        _,
                    >>::cache_identifier(&params),
                )
            }
        }
    }

    pub fn get_cache_metadata_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_metadata_path(&id))
    }

    pub fn get_cache_verifying_key_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_verifying_key_path(&id))
    }

    pub fn get_cache_params_path<Tree: 'static + MerkleTreeTrait>(&self) -> Result<PathBuf> {
        let id = self.get_cache_identifier::<Tree>()?;
        Ok(parameter_cache::parameter_cache_params_path(&id))
    }
}

'''
'''--- filecoin-proofs/src/types/post_proof_partitions.rs ---
use crate::constants::SINGLE_PARTITION_PROOF_LEN;
use crate::types::*;

#[derive(Clone, Copy, Debug)]
pub struct PoStProofPartitions(pub u8);

impl From<PoStProofPartitions> for PoStProofBytesAmount {
    fn from(x: PoStProofPartitions) -> Self {
        PoStProofBytesAmount(SINGLE_PARTITION_PROOF_LEN * usize::from(x))
    }
}

impl From<PoStProofPartitions> for usize {
    fn from(x: PoStProofPartitions) -> Self {
        x.0 as usize
    }
}

'''
'''--- filecoin-proofs/src/types/sector_class.rs ---
use crate::types::*;

#[derive(Clone, Copy, Debug)]
pub struct SectorClass {
    pub sector_size: SectorSize,
    pub partitions: PoRepProofPartitions,
}

impl From<SectorClass> for PoRepConfig {
    fn from(x: SectorClass) -> Self {
        let SectorClass {
            sector_size,
            partitions,
        } = x;
        PoRepConfig {
            sector_size,
            partitions,
        }
    }
}

'''
'''--- filecoin-proofs/src/types/sector_size.rs ---
use crate::fr32::to_unpadded_bytes;
use crate::types::*;

#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
pub struct SectorSize(pub u64);

impl From<u64> for SectorSize {
    fn from(size: u64) -> Self {
        SectorSize(size)
    }
}

impl From<SectorSize> for UnpaddedBytesAmount {
    fn from(x: SectorSize) -> Self {
        UnpaddedBytesAmount(to_unpadded_bytes(x.0))
    }
}

impl From<SectorSize> for PaddedBytesAmount {
    fn from(x: SectorSize) -> Self {
        PaddedBytesAmount(x.0)
    }
}

impl From<SectorSize> for u64 {
    fn from(x: SectorSize) -> Self {
        x.0
    }
}

'''
'''--- filecoin-proofs/tests/api.rs ---
use std::collections::BTreeMap;
use std::io::{Read, Seek, SeekFrom, Write};
use std::sync::Once;

use anyhow::Result;
use ff::Field;
use paired::bls12_381::Fr;
use rand::{Rng, SeedableRng};
use rand_xorshift::XorShiftRng;
use storage_proofs::hasher::Hasher;
use storage_proofs::sector::*;
use tempfile::NamedTempFile;

use filecoin_proofs::*;

static INIT_LOGGER: Once = Once::new();
fn init_logger() {
    INIT_LOGGER.call_once(|| {
        fil_logger::init();
    });
}

const TEST_SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

#[test]
#[ignore]
fn test_seal_lifecycle_2kib_base_8() -> Result<()> {
    seal_lifecycle::<SectorShape2KiB>(SECTOR_SIZE_2_KIB)
}

#[test]
#[ignore]
fn test_seal_lifecycle_4kib_sub_8_2() -> Result<()> {
    seal_lifecycle::<SectorShape4KiB>(SECTOR_SIZE_4_KIB)
}

#[test]
#[ignore]
fn test_seal_lifecycle_16kib_sub_8_2() -> Result<()> {
    seal_lifecycle::<SectorShape16KiB>(SECTOR_SIZE_16_KIB)
}

#[test]
#[ignore]
fn test_seal_lifecycle_32kib_top_8_8_2() -> Result<()> {
    seal_lifecycle::<SectorShape32KiB>(SECTOR_SIZE_32_KIB)
}

// These tests are good to run, but take a long time.

//#[test]
//#[ignore]
//fn test_seal_lifecycle_32gib_top_8_8_0() -> Result<()> {
//    seal_lifecycle::<SectorShape32GiB>(SECTOR_SIZE_32_GIB)
//}

//#[test]
//#[ignore]
//fn test_seal_lifecycle_64gib_top_8_8_2() -> Result<()> {
//    seal_lifecycle::<SectorShape64GiB>(SECTOR_SIZE_64_GIB)
//}

fn seal_lifecycle<Tree: 'static + MerkleTreeTrait>(sector_size: u64) -> Result<()> {
    let rng = &mut XorShiftRng::from_seed(TEST_SEED);
    let prover_fr: DefaultTreeDomain = Fr::random(rng).into();
    let mut prover_id = [0u8; 32];
    prover_id.copy_from_slice(AsRef::<[u8]>::as_ref(&prover_fr));

    create_seal::<_, Tree>(rng, sector_size, prover_id, false)?;
    Ok(())
}

#[test]
#[ignore]
fn test_winning_post_2kib_base_8() -> Result<()> {
    winning_post::<SectorShape2KiB>(SECTOR_SIZE_2_KIB)
}

#[test]
#[ignore]
fn test_winning_post_4kib_sub_8_2() -> Result<()> {
    winning_post::<SectorShape4KiB>(SECTOR_SIZE_4_KIB)
}

#[test]
#[ignore]
fn test_winning_post_16kib_sub_8_8() -> Result<()> {
    winning_post::<SectorShape16KiB>(SECTOR_SIZE_16_KIB)
}

#[test]
#[ignore]
fn test_winning_post_32kib_top_8_8_2() -> Result<()> {
    winning_post::<SectorShape32KiB>(SECTOR_SIZE_32_KIB)
}

#[test]
fn test_winning_post_empty_sector_challenge() -> Result<()> {
    let rng = &mut XorShiftRng::from_seed(TEST_SEED);

    let prover_fr: DefaultTreeDomain = Fr::random(rng).into();
    let mut prover_id = [0u8; 32];
    prover_id.copy_from_slice(AsRef::<[u8]>::as_ref(&prover_fr));

    let sector_count = 0;
    let sector_size = SECTOR_SIZE_2_KIB;

    let (_, _, _, _) = create_seal::<_, SectorShape2KiB>(rng, sector_size, prover_id, true)?;

    let random_fr: DefaultTreeDomain = Fr::random(rng).into();
    let mut randomness = [0u8; 32];
    randomness.copy_from_slice(AsRef::<[u8]>::as_ref(&random_fr));

    let config = PoStConfig {
        sector_size: sector_size.into(),
        sector_count,
        challenge_count: WINNING_POST_CHALLENGE_COUNT,
        typ: PoStType::Winning,
        priority: false,
    };

    assert!(generate_winning_post_sector_challenge::<SectorShape2KiB>(
        &config,
        &randomness,
        sector_count as u64,
        prover_id
    )
    .is_err());

    Ok(())
}

fn winning_post<Tree: 'static + MerkleTreeTrait>(sector_size: u64) -> Result<()> {
    let rng = &mut XorShiftRng::from_seed(TEST_SEED);

    let prover_fr: DefaultTreeDomain = Fr::random(rng).into();
    let mut prover_id = [0u8; 32];
    prover_id.copy_from_slice(AsRef::<[u8]>::as_ref(&prover_fr));

    let (sector_id, replica, comm_r, cache_dir) =
        create_seal::<_, Tree>(rng, sector_size, prover_id, true)?;
    let sector_count = WINNING_POST_SECTOR_COUNT;

    let random_fr: DefaultTreeDomain = Fr::random(rng).into();
    let mut randomness = [0u8; 32];
    randomness.copy_from_slice(AsRef::<[u8]>::as_ref(&random_fr));

    let config = PoStConfig {
        sector_size: sector_size.into(),
        sector_count,
        challenge_count: WINNING_POST_CHALLENGE_COUNT,
        typ: PoStType::Winning,
        priority: false,
    };

    let challenged_sectors = generate_winning_post_sector_challenge::<Tree>(
        &config,
        &randomness,
        sector_count as u64,
        prover_id,
    )?;
    assert_eq!(challenged_sectors.len(), sector_count);
    assert_eq!(challenged_sectors[0], 0); // with a sector_count of 1, the only valid index is 0

    let pub_replicas = vec![(sector_id, PublicReplicaInfo::new(comm_r)?)];
    let priv_replicas = vec![(
        sector_id,
        PrivateReplicaInfo::new(replica.path().into(), comm_r, cache_dir.path().into())?,
    )];

    let proof = generate_winning_post::<Tree>(&config, &randomness, &priv_replicas[..], prover_id)?;

    let valid =
        verify_winning_post::<Tree>(&config, &randomness, &pub_replicas[..], prover_id, &proof)?;
    assert!(valid, "proof did not verify");
    Ok(())
}

#[test]
#[ignore]
fn test_window_post_single_partition_smaller_2kib_base_8() -> Result<()> {
    let sector_size = SECTOR_SIZE_2_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape2KiB>(sector_size, sector_count / 2, sector_count)
}

#[test]
#[ignore]
fn test_window_post_two_partitions_matching_2kib_base_8() -> Result<()> {
    let sector_size = SECTOR_SIZE_2_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape2KiB>(sector_size, 2 * sector_count, sector_count)
}

#[test]
#[ignore]
fn test_window_post_two_partitions_matching_4kib_sub_8_2() -> Result<()> {
    let sector_size = SECTOR_SIZE_4_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape4KiB>(sector_size, 2 * sector_count, sector_count)
}

#[test]
#[ignore]
fn test_window_post_two_partitions_matching_16kib_sub_8_8() -> Result<()> {
    let sector_size = SECTOR_SIZE_16_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape16KiB>(sector_size, 2 * sector_count, sector_count)
}

#[test]
#[ignore]
fn test_window_post_two_partitions_matching_32kib_top_8_8_2() -> Result<()> {
    let sector_size = SECTOR_SIZE_32_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape32KiB>(sector_size, 2 * sector_count, sector_count)
}

#[test]
#[ignore]
fn test_window_post_two_partitions_smaller_2kib_base_8() -> Result<()> {
    let sector_size = SECTOR_SIZE_2_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape2KiB>(sector_size, 2 * sector_count - 1, sector_count)
}

#[test]
#[ignore]
fn test_window_post_single_partition_matching_2kib_base_8() -> Result<()> {
    let sector_size = SECTOR_SIZE_2_KIB;
    let sector_count = *WINDOW_POST_SECTOR_COUNT
        .read()
        .unwrap()
        .get(&sector_size)
        .unwrap();

    window_post::<SectorShape2KiB>(sector_size, sector_count, sector_count)
}

fn window_post<Tree: 'static + MerkleTreeTrait>(
    sector_size: u64,
    total_sector_count: usize,
    sector_count: usize,
) -> Result<()> {
    let rng = &mut XorShiftRng::from_seed(TEST_SEED);

    let mut sectors = Vec::with_capacity(total_sector_count);
    let mut pub_replicas = BTreeMap::new();
    let mut priv_replicas = BTreeMap::new();

    let prover_fr: <Tree::Hasher as Hasher>::Domain = Fr::random(rng).into();
    let mut prover_id = [0u8; 32];
    prover_id.copy_from_slice(AsRef::<[u8]>::as_ref(&prover_fr));

    for _ in 0..total_sector_count {
        let (sector_id, replica, comm_r, cache_dir) =
            create_seal::<_, Tree>(rng, sector_size, prover_id, true)?;
        priv_replicas.insert(
            sector_id,
            PrivateReplicaInfo::new(replica.path().into(), comm_r, cache_dir.path().into())?,
        );
        pub_replicas.insert(sector_id, PublicReplicaInfo::new(comm_r)?);
        sectors.push((sector_id, replica, comm_r, cache_dir, prover_id));
    }
    assert_eq!(priv_replicas.len(), total_sector_count);
    assert_eq!(pub_replicas.len(), total_sector_count);
    assert_eq!(sectors.len(), total_sector_count);

    let random_fr: <Tree::Hasher as Hasher>::Domain = Fr::random(rng).into();
    let mut randomness = [0u8; 32];
    randomness.copy_from_slice(AsRef::<[u8]>::as_ref(&random_fr));

    let config = PoStConfig {
        sector_size: sector_size.into(),
        sector_count,
        challenge_count: WINDOW_POST_CHALLENGE_COUNT,
        typ: PoStType::Window,
        priority: false,
    };

    let proof = generate_window_post::<Tree>(&config, &randomness, &priv_replicas, prover_id)?;

    let valid = verify_window_post::<Tree>(&config, &randomness, &pub_replicas, prover_id, &proof)?;
    assert!(valid, "proof did not verify");
    Ok(())
}

fn create_seal<R: Rng, Tree: 'static + MerkleTreeTrait>(
    rng: &mut R,
    sector_size: u64,
    prover_id: ProverId,
    skip_proof: bool,
) -> Result<(SectorId, NamedTempFile, Commitment, tempfile::TempDir)> {
    init_logger();

    let number_of_bytes_in_piece =
        UnpaddedBytesAmount::from(PaddedBytesAmount(sector_size.clone()));

    let piece_bytes: Vec<u8> = (0..number_of_bytes_in_piece.0)
        .map(|_| rand::random::<u8>())
        .collect();

    let mut piece_file = NamedTempFile::new()?;
    piece_file.write_all(&piece_bytes)?;
    piece_file.as_file_mut().sync_all()?;
    piece_file.as_file_mut().seek(SeekFrom::Start(0))?;

    let piece_info = generate_piece_commitment(piece_file.as_file_mut(), number_of_bytes_in_piece)?;
    piece_file.as_file_mut().seek(SeekFrom::Start(0))?;

    let mut staged_sector_file = NamedTempFile::new()?;
    add_piece(
        &mut piece_file,
        &mut staged_sector_file,
        number_of_bytes_in_piece,
        &[],
    )?;

    let piece_infos = vec![piece_info];

    let sealed_sector_file = NamedTempFile::new()?;
    let mut unseal_file = NamedTempFile::new()?;
    let config = PoRepConfig {
        sector_size: SectorSize(sector_size.clone()),
        partitions: PoRepProofPartitions(
            *POREP_PARTITIONS.read().unwrap().get(&sector_size).unwrap(),
        ),
    };

    let cache_dir = tempfile::tempdir().unwrap();

    let ticket = rng.gen();
    let seed = rng.gen();
    let sector_id = rng.gen::<u64>().into();

    let phase1_output = seal_pre_commit_phase1::<_, _, _, Tree>(
        config,
        cache_dir.path(),
        staged_sector_file.path(),
        sealed_sector_file.path(),
        prover_id,
        sector_id,
        ticket,
        &piece_infos,
    )?;

    validate_cache_for_precommit_phase2(
        cache_dir.path(),
        staged_sector_file.path(),
        &phase1_output,
    )?;

    let pre_commit_output = seal_pre_commit_phase2(
        config,
        phase1_output,
        cache_dir.path(),
        sealed_sector_file.path(),
    )?;

    let comm_d = pre_commit_output.comm_d.clone();
    let comm_r = pre_commit_output.comm_r.clone();

    validate_cache_for_commit::<_, _, Tree>(cache_dir.path(), sealed_sector_file.path())?;

    if skip_proof {
        clear_cache::<Tree>(cache_dir.path())?;
    } else {
        let phase1_output = seal_commit_phase1::<_, Tree>(
            config,
            cache_dir.path(),
            sealed_sector_file.path(),
            prover_id,
            sector_id,
            ticket,
            seed,
            pre_commit_output,
            &piece_infos,
        )?;

        clear_cache::<Tree>(cache_dir.path())?;

        let commit_output = seal_commit_phase2(config, phase1_output, prover_id, sector_id)?;

        let _ = unseal_range::<_, _, _, Tree>(
            config,
            cache_dir.path(),
            &sealed_sector_file,
            &unseal_file,
            prover_id,
            sector_id,
            comm_d,
            ticket,
            UnpaddedByteIndex(508),
            UnpaddedBytesAmount(508),
        )?;

        unseal_file.seek(SeekFrom::Start(0))?;

        let mut contents = vec![];
        assert!(
            unseal_file.read_to_end(&mut contents).is_ok(),
            "failed to populate buffer with unsealed bytes"
        );
        assert_eq!(contents.len(), 508);
        assert_eq!(&piece_bytes[508..508 + 508], &contents[..]);

        let computed_comm_d = compute_comm_d(config.sector_size, &piece_infos)?;

        assert_eq!(
            comm_d, computed_comm_d,
            "Computed and expected comm_d don't match."
        );

        let verified = verify_seal::<Tree>(
            config,
            comm_r,
            comm_d,
            prover_id,
            sector_id,
            ticket,
            seed,
            &commit_output.proof,
        )?;
        assert!(verified, "failed to verify valid seal");
    }

    Ok((sector_id, sealed_sector_file, comm_r, cache_dir))
}

'''
'''--- filecoin-proofs/tests/paramfetch/mod.rs ---
mod support;

pub mod prompts_to_fetch;

'''
'''--- filecoin-proofs/tests/paramfetch/prompts_to_fetch.rs ---
use std::collections::btree_map::BTreeMap;
use std::fs::File;
use std::io::{BufReader, Write};
use std::path::PathBuf;

use failure::Error as FailureError;

use crate::paramfetch::support::session::ParamFetchSessionBuilder;
use crate::support::tmp_manifest;
use blake2b_simd::State as Blake2b;
use filecoin_proofs::param::{ParameterData, ParameterMap};
use rand::Rng;

/// Produce a random sequence of bytes and first 32 characters of hex encoded
/// BLAKE2b checksum. This helper function must be kept up-to-date with the
/// parampublish implementation.
fn rand_bytes_with_blake2b() -> Result<(Vec<u8>, String), FailureError> {
    let bytes = rand::thread_rng().gen::<[u8; 32]>();

    let mut hasher = Blake2b::new();

    let mut as_slice = &bytes[..];

    std::io::copy(&mut as_slice, &mut hasher)?;

    Ok((
        bytes.iter().cloned().collect(),
        hasher.finalize().to_hex()[..32].into(),
    ))
}

#[test]
fn nothing_to_fetch_if_cache_fully_hydrated() -> Result<(), FailureError> {
    let mut manifest: BTreeMap<String, ParameterData> = BTreeMap::new();

    let (aaa_bytes, aaa_checksum) = rand_bytes_with_blake2b()?;
    let mut aaa_bytes: &[u8] = &aaa_bytes;

    // manifest entry checksum matches the BLAKE2b we compute locally
    manifest.insert(
        "aaa.vk".to_string(),
        ParameterData {
            cid: "".to_string(),
            digest: aaa_checksum.clone(),
            sector_size: 1234,
        },
    );

    let manifest_pbuf = tmp_manifest(Some(manifest))?;

    let mut session = ParamFetchSessionBuilder::new(Some(manifest_pbuf))
        .with_session_timeout_ms(1000)
        .with_file_and_bytes("aaa.vk", &mut aaa_bytes)
        .build();

    session.exp_string("checking: aaa.vk")?;
    session.exp_string("0 files to fetch")?;
    session.exp_string("done")?;

    Ok(())
}

#[test]
fn prompts_to_download_if_file_in_manifest_is_missing() -> Result<(), FailureError> {
    let mut manifest: BTreeMap<String, ParameterData> = BTreeMap::new();

    manifest.insert(
        "aaa.vk".to_string(),
        ParameterData {
            cid: "".to_string(),
            digest: "".to_string(),
            sector_size: 1234,
        },
    );

    let manifest_pbuf = tmp_manifest(Some(manifest))?;

    let mut session = ParamFetchSessionBuilder::new(Some(manifest_pbuf))
        .with_session_timeout_ms(1000)
        .build();

    session.exp_string("checking: aaa.vk")?;
    session.exp_string("does file exist... no")?;
    session.exp_string("[y/n] (sector size: 1234B) aaa.vk: ")?;

    Ok(())
}

#[test]
fn prompts_to_download_if_file_checksum_does_not_match_manifest() -> Result<(), FailureError> {
    let mut manifest: BTreeMap<String, ParameterData> = BTreeMap::new();

    let (aaa_bytes, _) = rand_bytes_with_blake2b()?;
    let mut aaa_bytes: &[u8] = &aaa_bytes;

    manifest.insert(
        "aaa.vk".to_string(),
        ParameterData {
            cid: "".to_string(),
            digest: "obviouslywrong".to_string(),
            sector_size: 5555,
        },
    );

    // create a manifest
    let manifest_pbuf = tmp_manifest(Some(manifest))?;

    // start a session
    let mut session = ParamFetchSessionBuilder::new(Some(manifest_pbuf))
        .with_session_timeout_ms(1000)
        .with_file_and_bytes("aaa.vk", &mut aaa_bytes)
        .build();

    session.exp_string("checking: aaa.vk")?;
    session.exp_string("does file exist... yes")?;
    session.exp_string("is file valid... no")?;
    session.exp_string("[y/n] (sector size: 5555B) aaa.vk: ")?;

    Ok(())
}

#[test]
fn fetches_vk_even_if_sector_size_does_not_match() -> Result<(), FailureError> {
    let mut manifest: BTreeMap<String, ParameterData> = BTreeMap::new();

    manifest.insert(
        "aaa.params".to_string(),
        ParameterData {
            cid: "".to_string(),
            digest: "".to_string(),
            sector_size: 1234,
        },
    );

    manifest.insert(
        "aaa.vk".to_string(),
        ParameterData {
            cid: "".to_string(),
            digest: "".to_string(),
            sector_size: 1234,
        },
    );

    let manifest_pbuf = tmp_manifest(Some(manifest))?;

    let mut session = ParamFetchSessionBuilder::new(Some(manifest_pbuf))
        .with_session_timeout_ms(1000)
        .whitelisted_sector_sizes(vec!["6666".to_string(), "4444".to_string()])
        .build();

    session.exp_string("2 files in manifest")?;
    session.exp_string("1 files to check for (re)download")?;
    session.exp_string("checking: aaa.vk")?;
    session.exp_string("does file exist... no")?;

    Ok(())
}

#[test]
fn invalid_json_path_produces_error() -> Result<(), FailureError> {
    let mut session = ParamFetchSessionBuilder::new(Some(PathBuf::from("/invalid/path")))
        .with_session_timeout_ms(1000)
        .build();

    session.exp_string("fatal error: JSON file '/invalid/path' does not exist")?;

    Ok(())
}

#[test]
fn invalid_json_produces_error() -> Result<(), FailureError> {
    let manifest_pbuf = tmp_manifest(None)?;

    let mut file = File::create(&manifest_pbuf)?;
    file.write_all(b"invalid json")?;

    let mut session = ParamFetchSessionBuilder::new(Some(manifest_pbuf))
        .with_session_timeout_ms(1000)
        .build();

    session.exp_string("fatal error: JSON file")?;
    session.exp_string("did not parse correctly")?;

    Ok(())
}

#[test]
fn no_json_path_uses_default_manifest() -> Result<(), FailureError> {
    let file = File::open("parameters.json")?;
    let reader = BufReader::new(file);
    let manifest: ParameterMap = serde_json::from_reader(reader)?;

    let mut session = ParamFetchSessionBuilder::new(None)
        .with_session_timeout_ms(1000)
        .build();

    session.exp_string("using built-in manifest")?;

    for parameter in manifest.keys() {
        session.exp_string(&format!("checking: {}", parameter))?;
    }

    Ok(())
}

'''
'''--- filecoin-proofs/tests/paramfetch/support/mod.rs ---
pub mod session;

'''
'''--- filecoin-proofs/tests/paramfetch/support/session.rs ---
use std::fs::File;
use std::io::Read;
use std::path::{Path, PathBuf};

use failure::SyncFailure;
use rexpect::session::PtyBashSession;
use tempfile;
use tempfile::TempDir;

use crate::support::{cargo_bin, spawn_bash_with_retries};
use storage_proofs::parameter_cache::PARAMETER_CACHE_ENV_VAR;

pub struct ParamFetchSessionBuilder {
    cache_dir: TempDir,
    session_timeout_ms: u64,
    whitelisted_sector_sizes: Option<Vec<String>>,
    manifest: Option<PathBuf>,
    prompt_enabled: bool,
}

impl ParamFetchSessionBuilder {
    pub fn new(manifest: Option<PathBuf>) -> ParamFetchSessionBuilder {
        let temp_dir = tempfile::tempdir().expect("could not create temp dir");

        ParamFetchSessionBuilder {
            cache_dir: temp_dir,
            session_timeout_ms: 1000,
            manifest,
            prompt_enabled: true,
            whitelisted_sector_sizes: None,
        }
    }

    /// Configure the pty timeout (see documentation for `rexpect::spawn_bash`).
    pub fn with_session_timeout_ms(mut self, timeout_ms: u64) -> ParamFetchSessionBuilder {
        self.session_timeout_ms = timeout_ms;
        self
    }

    /// Configure the pty timeout (see documentation for `rexpect::spawn_bash`).
    pub fn whitelisted_sector_sizes(
        mut self,
        sector_sizes: Vec<String>,
    ) -> ParamFetchSessionBuilder {
        self.whitelisted_sector_sizes = Some(sector_sizes);
        self
    }

    /// Create a file with the provided bytes in the cache directory.
    pub fn with_file_and_bytes<P: AsRef<Path>, R: Read>(
        self,
        filename: P,
        r: &mut R,
    ) -> ParamFetchSessionBuilder {
        let mut pbuf = self.cache_dir.path().clone().to_path_buf();
        pbuf.push(filename.as_ref());

        let mut file = File::create(&pbuf).expect("failed to create file in temp dir");

        std::io::copy(r, &mut file).expect("failed to copy bytes to file");

        self
    }

    /// Launch paramfetch in an environment configured by the builder.
    pub fn build(self) -> ParamFetchSession {
        let mut p = spawn_bash_with_retries(10, Some(self.session_timeout_ms))
            .unwrap_or_else(|err| panic!(err));

        let cache_dir_path = format!("{:?}", self.cache_dir.path());

        let paramfetch_path = cargo_bin("paramfetch");

        let whitelist: String = self
            .whitelisted_sector_sizes
            .map(|wl| {
                let mut s = "--params-for-sector-sizes=".to_string();
                s.push_str(&wl.join(","));
                s
            })
            .unwrap_or("".to_string());

        let json_argument = if self.manifest.is_some() {
            format!("--json={:?}", self.manifest.unwrap())
        } else {
            "".to_string()
        };

        let cmd = format!(
            "{}={} {:?} {} {} {} --ipget-bin={:?}",
            PARAMETER_CACHE_ENV_VAR,
            cache_dir_path,
            paramfetch_path,
            if self.prompt_enabled { "" } else { "--all" },
            json_argument,
            whitelist,
            "true"
        );

        p.execute(&cmd, ".*").expect("could not execute paramfetch");

        ParamFetchSession {
            pty_session: p,
            _cache_dir: self.cache_dir,
        }
    }
}

/// An active pseudoterminal (pty) used to interact with paramfetch.
pub struct ParamFetchSession {
    pty_session: PtyBashSession,
    _cache_dir: TempDir,
}

impl ParamFetchSession {
    /// Block until provided string is seen on stdout from paramfetch and
    /// return remaining output.
    pub fn exp_string(
        &mut self,
        needle: &str,
    ) -> Result<String, SyncFailure<rexpect::errors::Error>> {
        self.pty_session
            .exp_string(needle)
            .map_err(SyncFailure::new)
    }
}

'''
'''--- filecoin-proofs/tests/parampublish/mod.rs ---
pub mod prompts_to_publish;
pub mod read_metadata_files;
pub mod write_json_manifest;

pub mod support;

'''
'''--- filecoin-proofs/tests/parampublish/prompts_to_publish.rs ---
use std::collections::HashSet;
use std::iter::FromIterator;

use failure::Error as FailureError;

use storage_proofs::parameter_cache::CacheEntryMetadata;

use crate::parampublish::support::session::ParamPublishSessionBuilder;
use std::collections::btree_map::BTreeMap;

#[test]
fn ignores_files_unrecognized_extensions() {
    Ok::<(), FailureError>(())
        .and_then(|_| {
            // create files with these names in the parameter cache
            let to_create = vec!["aaa.vk", "aaa.params", "bbb.txt", "ddd"];

            // parampublish should prompt user to publish these files
            let to_prompt: HashSet<&str> =
                HashSet::from_iter(vec!["aaa.vk", "aaa.params"].iter().cloned());

            let (mut session, _) = ParamPublishSessionBuilder::new()
                .with_session_timeout_ms(1000)
                .with_files(&to_create)
                .with_metadata("aaa.meta", &CacheEntryMetadata { sector_size: 1234 })
                .build();

            for _ in 0..to_prompt.len() {
                session.exp_string("[y/n] (sector size: 1234B) ")?;
                let prompt_filename = session.exp_string(": ")?;
                let key: &str = &prompt_filename;
                assert_eq!(true, to_prompt.contains(key), "missing {}", key);
                session.send_line("n")?;
            }

            session.exp_string("no files to publish")?;
            session.exp_string("done")?;

            Ok(())
        })
        .expect("parampublish test failed");
}

#[test]
fn displays_sector_size_in_prompt() {
    Ok::<(), FailureError>(())
        .and_then(|_| {
            let to_create = vec!["aaa.vk", "aaa.params", "xxx.vk", "xxx.params"];

            let (mut session, _) = ParamPublishSessionBuilder::new()
                .with_session_timeout_ms(1000)
                .with_files(&to_create)
                .with_metadata("aaa.meta", &CacheEntryMetadata { sector_size: 1234 })
                .with_metadata("xxx.meta", &CacheEntryMetadata { sector_size: 4444 })
                .build();

            let mut map: BTreeMap<&str, String> = BTreeMap::new();
            map.insert("aaa.vk", "1234".to_string());
            map.insert("aaa.params", "1234".to_string());
            map.insert("xxx.vk", "4444".to_string());
            map.insert("xxx.params", "4444".to_string());

            for _ in 0..to_create.len() {
                session.exp_string("[y/n] (sector size: ")?;
                let prompt_sector_size: &str = &session.exp_string("B) ")?;
                let prompt_filename: &str = &session.exp_string(": ")?;
                assert_eq!(map.get(prompt_filename).unwrap(), prompt_sector_size);
                session.send_line("n")?;
            }

            Ok(())
        })
        .expect("parampublish test failed");
}

#[test]
fn no_assets_no_prompt() -> Result<(), FailureError> {
    let (mut session, _) = ParamPublishSessionBuilder::new()
        .with_session_timeout_ms(1000)
        .build();

    session.exp_string("No valid parameters in directory")?;

    Ok(())
}

'''
'''--- filecoin-proofs/tests/parampublish/read_metadata_files.rs ---
use failure::Error as FailureError;

use crate::parampublish::support::session::ParamPublishSessionBuilder;

#[test]
fn fails_if_missing_metadata_file() -> Result<(), FailureError> {
    // missing the corresponding .meta file
    let filenames = vec!["v12-aaa.vk", "v12-aaa.params"];

    let (mut session, _) = ParamPublishSessionBuilder::new()
        .with_session_timeout_ms(1000)
        .with_files(&filenames)
        .with_prompt_disabled()
        .build();

    // error!
    session.exp_string("No valid parameters in directory")?;

    Ok(())
}

#[test]
fn fails_if_malformed_metadata_file() -> Result<(), FailureError> {
    let mut malformed: &[u8] = &vec![42];

    let (mut session, _) = ParamPublishSessionBuilder::new()
        .with_session_timeout_ms(1000)
        .with_files(&vec!["v11-aaa.vk", "v11-aaa.params"])
        .with_file_and_bytes("v11-aaa.meta", &mut malformed)
        .with_prompt_disabled()
        .build();

    // error!
    session.exp_string("fatal error")?;

    Ok(())
}

'''
'''--- filecoin-proofs/tests/parampublish/support/mod.rs ---
pub mod session;

'''
'''--- filecoin-proofs/tests/parampublish/support/session.rs ---
use std::fs::File;
use std::io::{Read, Write};
use std::path::{Path, PathBuf};

use failure::SyncFailure;
use rand::Rng;
use rexpect::session::PtyBashSession;
use tempfile;
use tempfile::TempDir;

use storage_proofs::parameter_cache::{CacheEntryMetadata, PARAMETER_CACHE_ENV_VAR};

use crate::support::{cargo_bin, spawn_bash_with_retries, FakeIpfsBin};

pub struct ParamPublishSessionBuilder {
    cache_dir: TempDir,
    cached_file_pbufs: Vec<PathBuf>,
    session_timeout_ms: u64,
    manifest: PathBuf,
    ipfs_bin_path: PathBuf,
    prompt_enabled: bool,
}

impl ParamPublishSessionBuilder {
    pub fn new() -> ParamPublishSessionBuilder {
        let temp_dir = tempfile::tempdir().expect("could not create temp dir");

        let mut pbuf = temp_dir.path().clone().to_path_buf();
        pbuf.push("parameters.json");

        File::create(&pbuf).expect("failed to create file in temp dir");

        ParamPublishSessionBuilder {
            cache_dir: temp_dir,
            cached_file_pbufs: vec![],
            session_timeout_ms: 1000,
            manifest: pbuf,
            ipfs_bin_path: cargo_bin("fakeipfsadd"),
            prompt_enabled: true,
        }
    }

    /// Configure the path used by `parampublish` to add files to IPFS daemon.
    pub fn with_ipfs_bin(mut self, ipfs_bin: &FakeIpfsBin) -> ParamPublishSessionBuilder {
        let pbuf: PathBuf = PathBuf::from(&ipfs_bin.bin_path());
        self.ipfs_bin_path = pbuf;
        self
    }

    /// Create empty files with the given names in the cache directory.
    pub fn with_files<P: AsRef<Path>>(self, filenames: &[P]) -> ParamPublishSessionBuilder {
        filenames
            .into_iter()
            .fold(self, |acc, item| acc.with_file(item))
    }

    /// Create a file containing 32 random bytes with the given name in the
    /// cache directory.
    pub fn with_file<P: AsRef<Path>>(mut self, filename: P) -> ParamPublishSessionBuilder {
        let mut pbuf = self.cache_dir.path().clone().to_path_buf();
        pbuf.push(filename.as_ref());

        let mut file = File::create(&pbuf).expect("failed to create file in temp dir");

        let random_bytes = rand::thread_rng().gen::<[u8; 32]>();
        file.write(&random_bytes).expect("failed to write bytes");

        self.cached_file_pbufs.push(pbuf);
        self
    }

    /// Create a file with the provided bytes in the cache directory.
    pub fn with_file_and_bytes<P: AsRef<Path>, R: Read>(
        mut self,
        filename: P,
        r: &mut R,
    ) -> ParamPublishSessionBuilder {
        let mut pbuf = self.cache_dir.path().clone().to_path_buf();
        pbuf.push(filename.as_ref());

        let mut file = File::create(&pbuf).expect("failed to create file in temp dir");

        std::io::copy(r, &mut file).expect("failed to copy bytes to file");

        self.cached_file_pbufs.push(pbuf);
        self
    }

    /// Create a metadata file with the provided name in the cache directory.
    pub fn with_metadata<P: AsRef<Path>>(
        self,
        filename: P,
        meta: &CacheEntryMetadata,
    ) -> ParamPublishSessionBuilder {
        let mut meta_bytes: &[u8] = &serde_json::to_vec(meta)
            .expect("failed to serialize CacheEntryMetadata to JSON byte array");

        self.with_file_and_bytes(filename, &mut meta_bytes)
    }

    /// Configure the pty timeout (see documentation for `rexpect::spawn_bash`).
    pub fn with_session_timeout_ms(mut self, timeout_ms: u64) -> ParamPublishSessionBuilder {
        self.session_timeout_ms = timeout_ms;
        self
    }

    /// If prompt is disabled, `--all` flag will be passed to parampublish.
    pub fn with_prompt_disabled(mut self) -> ParamPublishSessionBuilder {
        self.prompt_enabled = false;
        self
    }

    /// When publishing, write JSON manifest to provided path.
    pub fn write_manifest_to(mut self, manifest_dest: PathBuf) -> ParamPublishSessionBuilder {
        self.manifest = manifest_dest;
        self
    }

    /// Launch parampublish in an environment configured by the builder.
    pub fn build(self) -> (ParamPublishSession, Vec<PathBuf>) {
        let mut p = spawn_bash_with_retries(10, Some(self.session_timeout_ms))
            .unwrap_or_else(|err| panic!(err));

        let cache_dir_path = format!("{:?}", self.cache_dir.path());

        let cache_contents: Vec<PathBuf> = std::fs::read_dir(&self.cache_dir)
            .expect(&format!("failed to read cache dir {:?}", self.cache_dir))
            .into_iter()
            .map(|x| x.expect("failed to get dir entry"))
            .map(|x| x.path())
            .collect();

        let parampublish_path = cargo_bin("parampublish");

        let cmd = format!(
            "{}={} {:?} {} --ipfs-bin={:?} --json={:?}",
            PARAMETER_CACHE_ENV_VAR,
            cache_dir_path,
            parampublish_path,
            if self.prompt_enabled { "" } else { "--all" },
            self.ipfs_bin_path,
            self.manifest
        );

        p.execute(&cmd, ".*")
            .expect("could not execute parampublish");

        (
            ParamPublishSession {
                pty_session: p,
                _cache_dir: self.cache_dir,
            },
            cache_contents,
        )
    }
}

/// An active pseudoterminal (pty) used to interact with parampublish.
pub struct ParamPublishSession {
    pty_session: PtyBashSession,
    _cache_dir: TempDir,
}

impl ParamPublishSession {
    /// Send provided string and trailing newline to parampublish.
    pub fn send_line(&mut self, line: &str) -> Result<usize, SyncFailure<rexpect::errors::Error>> {
        self.pty_session.send_line(line).map_err(SyncFailure::new)
    }

    /// Block until provided string is seen on stdout from parampublish and
    /// return remaining output.
    pub fn exp_string(
        &mut self,
        needle: &str,
    ) -> Result<String, SyncFailure<rexpect::errors::Error>> {
        self.pty_session
            .exp_string(needle)
            .map_err(SyncFailure::new)
    }
}

'''
'''--- filecoin-proofs/tests/parampublish/write_json_manifest.rs ---
use std::collections::btree_map::BTreeMap;
use std::fs::File;
use std::path::Path;

use failure::Error as FailureError;

use filecoin_proofs::param::ParameterData;
use storage_proofs::parameter_cache::CacheEntryMetadata;

use crate::parampublish::support::session::ParamPublishSessionBuilder;
use crate::support::{tmp_manifest, FakeIpfsBin};

#[test]
fn writes_json_manifest() -> Result<(), FailureError> {
    let filenames = vec!["v10-aaa.vk", "v10-aaa.params"];

    let manifest_path = tmp_manifest(None)?;

    let ipfs = FakeIpfsBin::new();

    let (mut session, files_in_cache) = ParamPublishSessionBuilder::new()
        .with_session_timeout_ms(1000)
        .with_files(&filenames)
        .with_metadata("v10-aaa.meta", &CacheEntryMetadata { sector_size: 1234 })
        .write_manifest_to(manifest_path.clone())
        .with_ipfs_bin(&ipfs)
        .with_prompt_disabled()
        .build();

    // compute checksums from files added to cache to compare with
    // manifest entries after publishing completes
    let cache_checksums = filename_to_checksum(&ipfs, files_in_cache.as_ref());

    session.exp_string("Select a version")?;
    // There is only one version of parameters, accept that one
    session.send_line("")?;
    //session.exp_regex(".*Select the sizes to publish.*")?;
    session.exp_string("Select the sizes to publish")?;
    // There is only one size, accept that one
    session.send_line("")?;

    // wait for confirmation...
    session.exp_string("publishing 2 files")?;
    session.exp_string("done")?;

    // read the manifest file from disk and verify that it is well
    // formed and contains the expected keys
    let manifest_file = File::open(&manifest_path)?;
    let manifest_map: BTreeMap<String, ParameterData> = serde_json::from_reader(manifest_file)?;

    // ensure that each filename exists in the manifest and that its
    // cid matches that which was produced from the `ipfs add` command
    for filename in filenames.iter().cloned() {
        if let (Some(m_entry), Some(expected)) =
            (manifest_map.get(filename), cache_checksums.get(filename))
        {
            assert_eq!(
                &m_entry.cid, expected,
                "manifest does not include digest produced by ipfs add for {}",
                filename
            );
        } else {
            panic!("{} must be present in both manifest and cache", filename);
        }
    }

    Ok(())
}

/// Produce a map of filename (not path) to the checksum produced by the ipfs
/// binary.
fn filename_to_checksum<P: AsRef<Path>>(
    ipfs_bin: &FakeIpfsBin,
    paths: &[P],
) -> BTreeMap<String, String> {
    paths.iter().fold(BTreeMap::new(), |mut acc, item| {
        acc.insert(
            item.as_ref()
                .file_name()
                .and_then(|os_str| os_str.to_str())
                .map(|s| s.to_string())
                .unwrap_or("".to_string()),
            ipfs_bin
                .compute_checksum(item)
                .expect("failed to compute checksum"),
        );
        acc
    })
}

'''
'''--- filecoin-proofs/tests/suite.rs ---
mod paramfetch;
mod parampublish;
mod support;

'''
'''--- filecoin-proofs/tests/support/mod.rs ---
use std::path::{Path, PathBuf};
use std::{env, thread};

use failure::format_err;
use filecoin_proofs::param::ParameterData;
use rexpect::session::PtyBashSession;
use rexpect::spawn_bash;
use std::collections::btree_map::BTreeMap;
use std::fs::File;
use std::process::Command;
use std::time::Duration;

pub struct FakeIpfsBin {
    bin_path: PathBuf,
}

impl FakeIpfsBin {
    pub fn new() -> FakeIpfsBin {
        FakeIpfsBin {
            bin_path: cargo_bin("fakeipfsadd"),
        }
    }

    pub fn compute_checksum<P: AsRef<Path>>(&self, path: P) -> Result<String, failure::Error> {
        let output = Command::new(&self.bin_path)
            .arg("add")
            .arg("-Q")
            .arg(path.as_ref())
            .output()?;

        if !output.status.success() {
            Err(format_err!(
                "{:?} produced non-zero exit code",
                &self.bin_path
            ))
        } else {
            Ok(String::from_utf8(output.stdout)?.trim().to_string())
        }
    }

    pub fn bin_path(&self) -> &Path {
        &self.bin_path
    }
}

/// Get the path of the target directory.
pub fn target_dir() -> PathBuf {
    env::current_exe()
        .ok()
        .map(|mut path| {
            path.pop();
            if path.ends_with("deps") {
                path.pop();
            }
            path
        })
        .unwrap()
}

/// Look up the path to a cargo-built binary within an integration test.
pub fn cargo_bin<S: AsRef<str>>(name: S) -> PathBuf {
    target_dir().join(format!("{}{}", name.as_ref(), env::consts::EXE_SUFFIX))
}

/// Spawn a pty and, if an error is produced, retry with linear backoff (to 5s).
pub fn spawn_bash_with_retries(
    retries: u8,
    timeout: Option<u64>,
) -> Result<PtyBashSession, rexpect::errors::Error> {
    let result = spawn_bash(timeout);
    if result.is_ok() || retries == 0 {
        result
    } else {
        let sleep_d = Duration::from_millis(5000 / u64::from(retries));
        eprintln!(
            "failed to spawn pty: {} retries remaining - sleeping {:?}",
            retries, sleep_d
        );
        thread::sleep(sleep_d);
        spawn_bash_with_retries(retries - 1, timeout)
    }
}

/// Create a parameters.json manifest file in a temp directory and return its
/// path.
pub fn tmp_manifest(
    opt_manifest: Option<BTreeMap<String, ParameterData>>,
) -> Result<PathBuf, failure::Error> {
    let manifest_dir = tempfile::tempdir()?;
    let mut pbuf = manifest_dir.into_path();
    pbuf.push("parameters.json");

    let mut file = File::create(&pbuf)?;
    if let Some(map) = opt_manifest {
        // JSON encode the manifest and write bytes to temp file
        serde_json::to_writer(&mut file, &map)?;
    }

    Ok(pbuf)
}

'''
'''--- issue_template.md ---
### Description

### Acceptance criteria

### Risks + pitfalls

### Where to begin

'''
'''--- proptest-regressions/crypto/sloth.txt ---
# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
xs 2333654024 1879057395 1148234502 4254212597 # shrinks to key = Fr(FrRepr([0, 0, 0, 0])), plaintext = Fr(FrRepr([6433232347557286543, 14241240406459990354, 3113366375994539378, 2168360237581758600]))

'''
'''--- release.toml ---
pre-release-commit-message = "chore({{crate_name}}): release {{version}}"
pro-release-commit-message = "chore({{crate_name}}): starting development cycle for {{next_version}}"
no-dev-version = true
'''
'''--- scripts/bench-parser.sh ---
#!/usr/bin/env bash
name=""
samples=""
time=""
slope=""
rsqr=""
mean=""
stddev=""
median=""
medabsdev=""

function as_list {
  out=$(echo $@ | sed "s/ /\", \"/g")
  echo "[\"$out\"]"
}

results=[]
index=0

while IFS= read line; do
  if [[ $line =~ ^Benchmarking ]]; then
    if [[ -z $name ]]; then
      name=`echo "$line" | cut -d' ' -f2-`
    fi
  fi
  if [[ "$line" =~ Collecting ]]; then
    samples=$(echo "$line" | cut -d'C' -f2 | cut -d' ' -f2)
  fi
  if [[ "$line" =~ time: ]]; then
    time=$(echo "$line" | cut -d'[' -f2 | cut -d']' -f1 | awk '{ print $1$2, $3$4, $5$6 }')
  fi
  if [[ "$line" =~ ^slope ]]; then
    slope=$(echo "$line" | cut -d'[' -f2 | cut -d']' -f1 | awk '{ print $1$2, $3$4 }')
    rsqr=$(echo "$line" | cut -d'[' -f3 | cut -d']' -f1 | awk '{ print $1, $2 }')
  fi
  if [[ "$line" =~ ^mean ]]; then
    mean=$(echo "$line" | cut -d'[' -f2 | cut -d']' -f1 | awk '{ print $1$2, $3$4 }')
    stddev=$(echo "$line" | cut -d'[' -f3 | cut -d']' -f1 | awk '{ print $1$2, $3$4 }')
  fi
  if [[ "$line" =~ ^median ]]; then
    median=$(echo "$line" | cut -d'[' -f2 | cut -d']' -f1 | awk '{ print $1$2, $3$4 }')
    medabsdev=$(echo "$line" | cut -d'[' -f3 | cut -d']' -f1 | awk '{ print $1$2, $3$4 }')
    results[index]="  {
    \"name\": "\"$name\"",
    \"samples\": $samples,
    \"time\": $(as_list $time),
    \"slope\": $(as_list $slope),
    \"R^2\": $(as_list $rsqr),
    \"mean\": $(as_list $mean),
    \"std. dev.\": $(as_list $stddev),
    \"median\": $(as_list $median),
    \"med. abs. dev.\": $(as_list $medabsdev)
  }"
    name=""
    index=$((index+1))
  fi
done

count=$((index-1))

if [ "$count" -ge "1" ]; then
  echo "["
  for n in ${!results[@]}; do
    printf "${results[$n]}"
    if [ "$n" -ne "$count" ]; then
      echo ", "
    else
      echo
    fi
  done
  echo "]"
fi

'''
'''--- scripts/package-release.sh ---
#!/usr/bin/env bash

set -Eeuo pipefail

if [ -z "$1" ]; then
  TAR_FILE=`mktemp`.tar.gz
else
  TAR_FILE=$1
fi

TAR_PATH=`mktemp -d`

mkdir -p $TAR_PATH
mkdir -p $TAR_PATH/bin
mkdir -p $TAR_PATH/misc

cp filecoin-proofs/parameters.json $TAR_PATH/misc/
cp target/release/paramcache $TAR_PATH/bin/
cp target/release/paramfetch $TAR_PATH/bin/

pushd $TAR_PATH

tar -czf $TAR_FILE ./*

popd

rm -rf $TAR_PATH

echo $TAR_FILE

'''
'''--- scripts/pin-params.sh ---
#!/usr/bin/env bash
set -Eeuo pipefail

# pin-params.sh
#
# - Post the directory of params to cluster.ipfs.io
# - Grab the CID for the previous params from proofs.filecoin.io
# - Add the old params as a `prev` dir to the new params dir to keep them around.
# - Pin the new cid on cluster
# - Publish the new cid as a dnslink to proofs.filecoin.io
# - The gateways will pin the new dir by checking proofs.filecoin.io hourly.
#
# Requires:
#  - `ipfs-cluster-ctl` - download from https://dist.ipfs.io/#ipfs-cluster-ctl
#  - `npx`, as provide `npm` >= v6
#  - `ipfs`
#
# You _must_ provide the following env vars
#
#  - CLUSTER_TOKEN - the basic auth string as "username:password"
#  - DNSIMPLE_TOKEN - an api key for a dnsimple account with a zone for proofs.filecoin.io
#
# Optional: you can override the input dir by passing a path as the first param.
#
# Usage:
#   CLUSTER_TOKEN="user:pass" DNSIMPLE_TOKEN="xyz" ./pin-params.sh
#

INPUT_DIR=${1:-"/var/tmp/filecoin-proof-parameters"}
: "${CLUSTER_TOKEN:?please set CLUSTER_TOKEN env var}"
: "${DNSIMPLE_TOKEN:?please set DNSIMPLE_TOKEN env var}"

echo "checking $INPUT_DIR"

# Grab the version number from the files in the dir.
# Fail if more than 1 version or doesnt match a version string like vNN, e.g v12
if ls -A $INPUT_DIR &> /dev/null; then
  # version will be a list if there is more than one...
  VERSION=$(ls $INPUT_DIR | sort -r | cut -c 1-3 | uniq)
  echo found $VERSION

  if [[ $(echo $VERSION | wc -w) -eq 1 && $VERSION =~ ^v[0-9]+ ]]; then
    # we have 1 version, lets go...
    COUNT=$(ls -l $INPUT_DIR | wc -l | xargs echo -n)
    echo "adding $COUNT files to ipfs..."

  else
    echo "Error: input dir should contain just the current version of the params"
    exit 1
  fi
else
  echo "Error: input dir '$INPUT_DIR' should contain the params"
  exit 1
fi

CLUSTER_HOST="/dnsaddr/cluster.ipfs.io"
CLUSTER_PIN_NAME="filecoin-proof-parameters-$VERSION"
DNSLINK_DOMAIN="proofs.filecoin.io"

# Pin to cluster
ROOT_CID=$(ipfs-cluster-ctl \
  --host $CLUSTER_HOST \
  --basic-auth $CLUSTER_TOKEN \
  add --quieter \
  --name $CLUSTER_PIN_NAME \
  --recursive $INPUT_DIR )

echo "ok! root cid is $ROOT_CID"

# Publist the new cid to the dnslink
npx dnslink-dnsimple --domain $DNSLINK_DOMAIN --link "/ipfs/$ROOT_CID"

echo "done!"

'''
'''--- scripts/publish-release.sh ---
#!/usr/bin/env bash

set -Eeuo pipefail

RELEASE_NAME="$CIRCLE_PROJECT_REPONAME-`uname`"
RELEASE_FILE="/tmp/$RELEASE_NAME.tar.gz"
RELEASE_TAG="${CIRCLE_SHA1:0:16}"

# make sure we have a token set, api requests won't work otherwise
if [ -z $GITHUB_TOKEN ]; then
  echo "\$GITHUB_TOKEN not set, publish failed"
  exit 1
fi

echo "preparing release file"

`dirname $0`/package-release.sh $RELEASE_FILE

echo "release file created: $RELEASE_FILE"

# see if the release already exists by tag
RELEASE_RESPONSE=`
  curl \
    --header "Authorization: token $GITHUB_TOKEN" \
    "https://api.github.com/repos/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/releases/tags/$RELEASE_TAG"
`

RELEASE_ID=`echo $RELEASE_RESPONSE | jq '.id'`

if [ "$RELEASE_ID" = "null" ]; then
  echo "creating release"

  RELEASE_DATA="{
    \"tag_name\": \"$RELEASE_TAG\",
    \"target_commitish\": \"$CIRCLE_SHA1\",
    \"name\": \"$RELEASE_TAG\",
    \"body\": \"\"
  }"

  # create it if it doesn't exist yet
  RELEASE_RESPONSE=`
    curl \
      --request POST \
      --header "Authorization: token $GITHUB_TOKEN" \
      --header "Content-Type: application/json" \
      --data "$RELEASE_DATA" \
      "https://api.github.com/repos/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/releases"
  `
else
  echo "release already exists"
fi

RELEASE_UPLOAD_URL=`echo $RELEASE_RESPONSE | jq -r '.upload_url' | cut -d'{' -f1`

curl \
  --request POST \
  --header "Authorization: token $GITHUB_TOKEN" \
  --header "Content-Type: application/octet-stream" \
  --data-binary "@$RELEASE_FILE" \
  "$RELEASE_UPLOAD_URL?name=$(basename $RELEASE_FILE)"

echo "release file uploaded"

'''
'''--- sha2raw/Cargo.toml ---
[package]
name = "sha2raw"
version = "1.0.0"
authors = ["RustCrypto Developers", "Friedel Ziegelmayer <me@dignifiedquire.com>"]
license = "MIT OR Apache-2.0"
description = "SHA-2 hash function"
documentation = "https://docs.rs/sha2raw"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
keywords = ["crypto", "sha2", "hash", "digest"]
categories = ["cryptography", "no-std"]
edition = "2018"

[dependencies]
digest = "0.8"
block-buffer = "0.7"
fake-simd = "0.1"
opaque-debug = "0.2"
sha2-asm = { version = "0.5", optional = true }
raw-cpuid = "7.0.3"

[dependencies.lazy_static]
version = "1.4.0"

[dev-dependencies]
digest = { version = "0.8", features = ["dev", "std"] }
hex-literal = "0.1"
sha2 = "0.8.1"
rand = "0.7.3"
rand_xorshift = "0.2.0"

[features]
default = []
asm = ["sha2-asm"]

'''
'''--- sha2raw/README.md ---
# sha2raw

> Implementation of Sha256 with a focus on hashing fixed sizes chunks, that do not require padding. Based on [sha2](https://docs.rs/sha2).

'''
'''--- sha2raw/src/consts.rs ---
use fake_simd::u32x4;

pub const STATE_LEN: usize = 8;
pub const BLOCK_LEN: usize = 16;

/// Constants necessary for SHA-256 family of digests.
pub const K32: [u32; 64] = [
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2,
];

/// Constants necessary for SHA-256 family of digests.
pub const K32X4: [u32x4; 16] = [
    u32x4(K32[3], K32[2], K32[1], K32[0]),
    u32x4(K32[7], K32[6], K32[5], K32[4]),
    u32x4(K32[11], K32[10], K32[9], K32[8]),
    u32x4(K32[15], K32[14], K32[13], K32[12]),
    u32x4(K32[19], K32[18], K32[17], K32[16]),
    u32x4(K32[23], K32[22], K32[21], K32[20]),
    u32x4(K32[27], K32[26], K32[25], K32[24]),
    u32x4(K32[31], K32[30], K32[29], K32[28]),
    u32x4(K32[35], K32[34], K32[33], K32[32]),
    u32x4(K32[39], K32[38], K32[37], K32[36]),
    u32x4(K32[43], K32[42], K32[41], K32[40]),
    u32x4(K32[47], K32[46], K32[45], K32[44]),
    u32x4(K32[51], K32[50], K32[49], K32[48]),
    u32x4(K32[55], K32[54], K32[53], K32[52]),
    u32x4(K32[59], K32[58], K32[57], K32[56]),
    u32x4(K32[63], K32[62], K32[61], K32[60]),
];

pub static H256: [u32; STATE_LEN] = [
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19,
];

'''
'''--- sha2raw/src/lib.rs ---
//! An implementation of the [SHA-2][1] cryptographic hash algorithms.

// Give relevant error messages if the user tries to enable AArch64 asm on unsupported platforms.

#![deny(clippy::all, clippy::perf, clippy::correctness)]
#![allow(clippy::unreadable_literal)]

mod consts;

mod platform;
mod sha256;
#[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
mod sha256_intrinsics;
mod sha256_utils;

pub use digest::Digest;
pub use sha256::Sha256;

'''
'''--- sha2raw/src/platform.rs ---
use raw_cpuid::CpuId;

#[allow(dead_code)]
#[derive(Clone, Copy, Debug, Eq, PartialEq)]
enum Platform {
    Portable,
    #[cfg(feature = "asm")]
    Asm,
    #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
    Sha,
}

#[derive(Clone, Copy, Debug)]
pub struct Implementation(Platform);

impl Implementation {
    pub fn detect() -> Self {
        // Try the different implementations in order of how fast/modern they are.
        #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
        {
            if let Some(sha_impl) = Self::sha_if_supported() {
                return sha_impl;
            }
        }
        #[cfg(feature = "asm")]
        {
            if let Some(asm_impl) = Self::asm_if_supported() {
                return asm_impl;
            }
        }

        Self::portable()
    }

    pub fn portable() -> Self {
        Implementation(Platform::Portable)
    }

    #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
    #[allow(unreachable_code)]
    pub fn sha_if_supported() -> Option<Self> {
        // Use raw_cpuid instead of is_x86_feature_detected, to ensure the check
        // never happens at compile time.
        let cpuid = CpuId::new();
        let is_runtime_ok = cpuid
            .get_extended_feature_info()
            .map(|info| info.has_sha())
            .unwrap_or_default();

        #[cfg(target_feature = "sha")]
        {
            if !is_runtime_ok {
                println!("WARN: sha-ni not available, falling back");
            }
        }

        // Make sure this computer actually supports it
        if is_runtime_ok {
            return Some(Implementation(Platform::Sha));
        }

        None
    }

    #[cfg(feature = "asm")]
    pub fn asm_if_supported() -> Option<Self> {
        Some(Implementation(Platform::Asm))
    }

    #[inline]
    pub fn compress256(self, state: &mut [u32; 8], blocks: &[&[u8]]) {
        match self.0 {
            Platform::Portable => {
                use crate::sha256_utils;
                sha256_utils::compress256(state, blocks);
            }
            #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
            Platform::Sha => {
                use crate::sha256_intrinsics;
                unsafe { sha256_intrinsics::compress256(state, blocks) };
            }
            #[cfg(feature = "asm")]
            Platform::Asm => {
                let mut buffer = [0u8; 64];
                for block in blocks.chunks(2) {
                    buffer[..32].copy_from_slice(&block[0]);
                    buffer[32..].copy_from_slice(&block[1]);
                    sha2_asm::compress256(state, &buffer);
                }
            }
        }
    }
}

'''
'''--- sha2raw/src/sha256.rs ---
use block_buffer::byteorder::{ByteOrder, BE};

use crate::consts::H256;
use crate::platform::Implementation;

lazy_static::lazy_static! {
    static ref IMPL: Implementation = Implementation::detect();
}

#[derive(Clone)]
pub struct Sha256 {
    len: u64,
    state: [u32; 8],
}

impl Default for Sha256 {
    fn default() -> Self {
        Sha256 {
            len: 0,
            state: H256,
        }
    }
}

impl Sha256 {
    pub fn new() -> Self {
        Sha256::default()
    }

    pub fn digest(blocks: &[&[u8]]) -> [u8; 32] {
        let mut sha = Sha256::new();
        sha.input(blocks);
        sha.finish()
    }

    pub fn input(&mut self, blocks: &[&[u8]]) {
        debug_assert_eq!(blocks.len() % 2, 0, "invalid block length");

        self.len += (blocks.len() as u64) << 8;

        IMPL.compress256(&mut self.state, blocks);
    }

    pub fn finish(mut self) -> [u8; 32] {
        let mut block0 = [0u8; 32];
        let mut block1 = [0u8; 32];

        // Append single 1 bit
        block0[0] = 0b1000_0000;

        // Write L as 64 big endian integer
        let l = self.len;
        block1[32 - 8..].copy_from_slice(&l.to_be_bytes()[..]);

        IMPL.compress256(&mut self.state, &[&block0[..], &block1[..]][..]);

        let mut out = [0u8; 32];
        BE::write_u32_into(&self.state, &mut out);
        out
    }

    pub fn finish_with(mut self, block0: &[u8]) -> [u8; 32] {
        debug_assert_eq!(block0.len(), 32);

        let mut block1 = [0u8; 32];

        // Append single 1 bit
        block1[0] = 0b1000_0000;

        // Write L as 64 big endian integer
        let l = self.len + 256;
        block1[32 - 8..].copy_from_slice(&l.to_be_bytes()[..]);

        IMPL.compress256(&mut self.state, &[block0, &block1[..]][..]);

        let mut out = [0u8; 32];
        BE::write_u32_into(&self.state, &mut out);
        out
    }
}

opaque_debug::impl_opaque_debug!(Sha256);

#[cfg(test)]
mod tests {
    use super::*;

    use rand::{RngCore, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use sha2::{Digest, Sha256 as Original};

    #[test]
    fn test_fuzz_simple() {
        fuzz(10);
    }

    #[test]
    #[ignore]
    fn test_fuzz_long() {
        fuzz(1_000);
    }

    fn fuzz(n: usize) {
        let rng = &mut XorShiftRng::from_seed([
            0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06,
            0xbc, 0xe5,
        ]);
        for k in 1..n {
            for _ in 0..100 {
                let mut input = vec![0u8; 64 * k];
                rng.fill_bytes(&mut input);
                let chunked = input.chunks(32).collect::<Vec<_>>();
                assert_eq!(&Sha256::digest(&chunked)[..], &Original::digest(&input)[..])
            }
        }

        for k in (1..n).step_by(2) {
            for _ in 0..100 {
                let mut input = vec![0u8; 32 * k];
                rng.fill_bytes(&mut input);
                let mut hasher = Sha256::new();
                for chunk in input.chunks(64) {
                    if chunk.len() == 64 {
                        hasher.input(&[&chunk[..32], &chunk[32..]]);
                    }
                }
                assert_eq!(input.len() % 64, 32);
                let hash = hasher.finish_with(&input[input.len() - 32..]);

                assert_eq!(
                    &hash[..],
                    &Original::digest(&input)[..],
                    "input: {:?}",
                    &input
                );
            }
        }
    }
}

'''
'''--- sha2raw/src/sha256_intrinsics.rs ---
#![allow(clippy::many_single_char_names)]
#![allow(clippy::cast_ptr_alignment)] // Safe to cast without alignment checks as the loads and stores do not require alignment.

#[cfg(target_arch = "x86")]
use std::arch::x86::*;
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

/// Process a block with the SHA-256 algorithm.
/// Based on https://github.com/noloader/SHA-Intrinsics/blob/master/sha256-x86.c
#[inline(always)]
pub unsafe fn compress256(state: &mut [u32; 8], blocks: &[&[u8]]) {
    assert_eq!(blocks.len() % 2, 0);

    let mut state0: __m128i;
    let mut state1: __m128i;

    let mut msg: __m128i;
    let mut tmp: __m128i;

    let mut msg0: __m128i;
    let mut msg1: __m128i;
    let mut msg2: __m128i;
    let mut msg3: __m128i;

    let mut abef_save: __m128i;
    let mut cdgh_save: __m128i;

    #[allow(non_snake_case)]
    let MASK: __m128i = _mm_set_epi64x(
        0x0c0d_0e0f_0809_0a0bu64 as i64,
        0x0405_0607_0001_0203u64 as i64,
    );

    // Load initial values
    tmp = _mm_loadu_si128(state.as_ptr().add(0) as *const __m128i);
    state1 = _mm_loadu_si128(state.as_ptr().add(4) as *const __m128i);

    tmp = _mm_shuffle_epi32(tmp, 0xB1); // CDAB
    state1 = _mm_shuffle_epi32(state1, 0x1B); // EFGH
    state0 = _mm_alignr_epi8(tmp, state1, 8); // ABEF
    state1 = _mm_blend_epi16(state1, tmp, 0xF0); // CDGH

    for i in (0..blocks.len()).step_by(2) {
        // Save current state
        abef_save = state0;
        cdgh_save = state1;

        // Rounds 0-3
        msg = _mm_loadu_si128(blocks[i].as_ptr().add(0) as *const __m128i);
        msg0 = _mm_shuffle_epi8(msg, MASK);
        msg = _mm_add_epi32(
            msg0,
            _mm_set_epi64x(0xE9B5DBA5B5C0FBCFu64 as i64, 0x71374491428A2F98u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);

        // Rounds 4-7
        msg1 = _mm_loadu_si128(blocks[i].as_ptr().add(16) as *const __m128i);
        msg1 = _mm_shuffle_epi8(msg1, MASK);
        msg = _mm_add_epi32(
            msg1,
            _mm_set_epi64x(0xAB1C5ED5923F82A4u64 as i64, 0x59F111F13956C25Bu64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg0 = _mm_sha256msg1_epu32(msg0, msg1);

        // Rounds 8-11
        msg2 = _mm_loadu_si128(blocks[i + 1].as_ptr().add(0) as *const __m128i);
        msg2 = _mm_shuffle_epi8(msg2, MASK);
        msg = _mm_add_epi32(
            msg2,
            _mm_set_epi64x(0x550C7DC3243185BEu64 as i64, 0x12835B01D807AA98u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg1 = _mm_sha256msg1_epu32(msg1, msg2);

        // Rounds 12-15
        msg3 = _mm_loadu_si128(blocks[i + 1].as_ptr().add(16) as *const __m128i);
        msg3 = _mm_shuffle_epi8(msg3, MASK);
        msg = _mm_add_epi32(
            msg3,
            _mm_set_epi64x(0xC19BF1749BDC06A7u64 as i64, 0x80DEB1FE72BE5D74u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg3, msg2, 4);
        msg0 = _mm_add_epi32(msg0, tmp);
        msg0 = _mm_sha256msg2_epu32(msg0, msg3);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg2 = _mm_sha256msg1_epu32(msg2, msg3);

        // Rounds 16-19
        msg = _mm_add_epi32(
            msg0,
            _mm_set_epi64x(0x240CA1CC0FC19DC6u64 as i64, 0xEFBE4786E49B69C1u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg0, msg3, 4);
        msg1 = _mm_add_epi32(msg1, tmp);
        msg1 = _mm_sha256msg2_epu32(msg1, msg0);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg3 = _mm_sha256msg1_epu32(msg3, msg0);

        // Rounds 20-23
        msg = _mm_add_epi32(
            msg1,
            _mm_set_epi64x(0x76F988DA5CB0A9DCu64 as i64, 0x4A7484AA2DE92C6Fu64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg1, msg0, 4);
        msg2 = _mm_add_epi32(msg2, tmp);
        msg2 = _mm_sha256msg2_epu32(msg2, msg1);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg0 = _mm_sha256msg1_epu32(msg0, msg1);

        // Rounds 24-27
        msg = _mm_add_epi32(
            msg2,
            _mm_set_epi64x(0xBF597FC7B00327C8u64 as i64, 0xA831C66D983E5152u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg2, msg1, 4);
        msg3 = _mm_add_epi32(msg3, tmp);
        msg3 = _mm_sha256msg2_epu32(msg3, msg2);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg1 = _mm_sha256msg1_epu32(msg1, msg2);

        // Rounds 28-31
        msg = _mm_add_epi32(
            msg3,
            _mm_set_epi64x(0x1429296706CA6351u64 as i64, 0xD5A79147C6E00BF3u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg3, msg2, 4);
        msg0 = _mm_add_epi32(msg0, tmp);
        msg0 = _mm_sha256msg2_epu32(msg0, msg3);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg2 = _mm_sha256msg1_epu32(msg2, msg3);

        // Rounds 32-35
        msg = _mm_add_epi32(
            msg0,
            _mm_set_epi64x(0x53380D134D2C6DFCu64 as i64, 0x2E1B213827B70A85u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg0, msg3, 4);
        msg1 = _mm_add_epi32(msg1, tmp);
        msg1 = _mm_sha256msg2_epu32(msg1, msg0);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg3 = _mm_sha256msg1_epu32(msg3, msg0);

        // Rounds 36-39
        msg = _mm_add_epi32(
            msg1,
            _mm_set_epi64x(0x92722C8581C2C92Eu64 as i64, 0x766A0ABB650A7354u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg1, msg0, 4);
        msg2 = _mm_add_epi32(msg2, tmp);
        msg2 = _mm_sha256msg2_epu32(msg2, msg1);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg0 = _mm_sha256msg1_epu32(msg0, msg1);

        // Rounds 40-43
        msg = _mm_add_epi32(
            msg2,
            _mm_set_epi64x(0xC76C51A3C24B8B70u64 as i64, 0xA81A664BA2BFE8A1u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg2, msg1, 4);
        msg3 = _mm_add_epi32(msg3, tmp);
        msg3 = _mm_sha256msg2_epu32(msg3, msg2);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg1 = _mm_sha256msg1_epu32(msg1, msg2);

        // Rounds 44-47
        msg = _mm_add_epi32(
            msg3,
            _mm_set_epi64x(0x106AA070F40E3585u64 as i64, 0xD6990624D192E819u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg3, msg2, 4);
        msg0 = _mm_add_epi32(msg0, tmp);
        msg0 = _mm_sha256msg2_epu32(msg0, msg3);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg2 = _mm_sha256msg1_epu32(msg2, msg3);

        // Rounds 48-51
        msg = _mm_add_epi32(
            msg0,
            _mm_set_epi64x(0x34B0BCB52748774Cu64 as i64, 0x1E376C0819A4C116u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg0, msg3, 4);
        msg1 = _mm_add_epi32(msg1, tmp);
        msg1 = _mm_sha256msg2_epu32(msg1, msg0);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);
        msg3 = _mm_sha256msg1_epu32(msg3, msg0);

        // Rounds 52-55
        msg = _mm_add_epi32(
            msg1,
            _mm_set_epi64x(0x682E6FF35B9CCA4Fu64 as i64, 0x4ED8AA4A391C0CB3u64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg1, msg0, 4);
        msg2 = _mm_add_epi32(msg2, tmp);
        msg2 = _mm_sha256msg2_epu32(msg2, msg1);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);

        // Rounds 56-59
        msg = _mm_add_epi32(
            msg2,
            _mm_set_epi64x(0x8CC7020884C87814u64 as i64, 0x78A5636F748F82EEu64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        tmp = _mm_alignr_epi8(msg2, msg1, 4);
        msg3 = _mm_add_epi32(msg3, tmp);
        msg3 = _mm_sha256msg2_epu32(msg3, msg2);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);

        // Rounds 60-63
        msg = _mm_add_epi32(
            msg3,
            _mm_set_epi64x(0xC67178F2BEF9A3F7u64 as i64, 0xA4506CEB90BEFFFAu64 as i64),
        );
        state1 = _mm_sha256rnds2_epu32(state1, state0, msg);
        msg = _mm_shuffle_epi32(msg, 0x0E);
        state0 = _mm_sha256rnds2_epu32(state0, state1, msg);

        // Combine state
        state0 = _mm_add_epi32(state0, abef_save);
        state1 = _mm_add_epi32(state1, cdgh_save);
    }

    tmp = _mm_shuffle_epi32(state0, 0x1B); // FEBA
    state1 = _mm_shuffle_epi32(state1, 0xB1); // DCHG
    state0 = _mm_blend_epi16(tmp, state1, 0xF0); // DCBA
    state1 = _mm_alignr_epi8(state1, tmp, 8); // ABEF

    // Save state
    _mm_storeu_si128(state.as_ptr().add(0) as *mut __m128i, state0);
    _mm_storeu_si128(state.as_ptr().add(4) as *mut __m128i, state1);
}

'''
'''--- sha2raw/src/sha256_utils.rs ---
#![allow(clippy::many_single_char_names)]

use fake_simd::u32x4;

/// Not an intrinsic, but works like an unaligned load.
#[inline]
fn sha256load(v2: u32x4, v3: u32x4) -> u32x4 {
    u32x4(v3.3, v2.0, v2.1, v2.2)
}

/// Not an intrinsic, but useful for swapping vectors.
#[inline]
fn sha256swap(v0: u32x4) -> u32x4 {
    u32x4(v0.2, v0.3, v0.0, v0.1)
}

/// Emulates `llvm.x86.sha256msg1` intrinsic.
// #[inline]
fn sha256msg1(v0: u32x4, v1: u32x4) -> u32x4 {
    // sigma 0 on vectors
    #[inline]
    fn sigma0x4(x: u32x4) -> u32x4 {
        ((x >> u32x4(7, 7, 7, 7)) | (x << u32x4(25, 25, 25, 25)))
            ^ ((x >> u32x4(18, 18, 18, 18)) | (x << u32x4(14, 14, 14, 14)))
            ^ (x >> u32x4(3, 3, 3, 3))
    }

    v0 + sigma0x4(sha256load(v0, v1))
}

/// Emulates `llvm.x86.sha256msg2` intrinsic.
// #[inline]
fn sha256msg2(v4: u32x4, v3: u32x4) -> u32x4 {
    macro_rules! sigma1 {
        ($a:expr) => {
            $a.rotate_right(17) ^ $a.rotate_right(19) ^ ($a >> 10)
        };
    }

    let u32x4(x3, x2, x1, x0) = v4;
    let u32x4(w15, w14, _, _) = v3;

    let w16 = x0.wrapping_add(sigma1!(w14));
    let w17 = x1.wrapping_add(sigma1!(w15));
    let w18 = x2.wrapping_add(sigma1!(w16));
    let w19 = x3.wrapping_add(sigma1!(w17));

    u32x4(w19, w18, w17, w16)
}

/*
/// Performs 4 rounds of the SHA-256 message schedule update.
fn sha256_schedule_x4(v0: u32x4, v1: u32x4, v2: u32x4, v3: u32x4) -> u32x4 {
    sha256msg2(sha256msg1(v0, v1) + sha256load(v2, v3), v3)
}*/

/// Emulates `llvm.x86.sha256rnds2` intrinsic.
// #[inline]
fn sha256_digest_round_x2(cdgh: u32x4, abef: u32x4, wk: u32x4) -> u32x4 {
    macro_rules! big_sigma0 {
        ($a:expr) => {
            ($a.rotate_right(2) ^ $a.rotate_right(13) ^ $a.rotate_right(22))
        };
    }
    macro_rules! big_sigma1 {
        ($a:expr) => {
            ($a.rotate_right(6) ^ $a.rotate_right(11) ^ $a.rotate_right(25))
        };
    }
    macro_rules! bool3ary_202 {
        ($a:expr, $b:expr, $c:expr) => {
            $c ^ ($a & ($b ^ $c))
        };
    } // Choose, MD5F, SHA1C
    macro_rules! bool3ary_232 {
        ($a:expr, $b:expr, $c:expr) => {
            ($a & $b) ^ ($a & $c) ^ ($b & $c)
        };
    } // Majority, SHA1M

    let u32x4(_, _, wk1, wk0) = wk;
    let u32x4(a0, b0, e0, f0) = abef;
    let u32x4(c0, d0, g0, h0) = cdgh;

    // a round
    let x0 = big_sigma1!(e0)
        .wrapping_add(bool3ary_202!(e0, f0, g0))
        .wrapping_add(wk0)
        .wrapping_add(h0);
    let y0 = big_sigma0!(a0).wrapping_add(bool3ary_232!(a0, b0, c0));
    let (a1, b1, c1, d1, e1, f1, g1, h1) = (
        x0.wrapping_add(y0),
        a0,
        b0,
        c0,
        x0.wrapping_add(d0),
        e0,
        f0,
        g0,
    );

    // a round
    let x1 = big_sigma1!(e1)
        .wrapping_add(bool3ary_202!(e1, f1, g1))
        .wrapping_add(wk1)
        .wrapping_add(h1);
    let y1 = big_sigma0!(a1).wrapping_add(bool3ary_232!(a1, b1, c1));
    let (a2, b2, _, _, e2, f2, _, _) = (
        x1.wrapping_add(y1),
        a1,
        b1,
        c1,
        x1.wrapping_add(d1),
        e1,
        f1,
        g1,
    );

    u32x4(a2, b2, e2, f2)
}

/// Process a block with the SHA-256 algorithm.
fn sha256_digest_block_u32(state: &mut [u32; 8], block: &[u32; 16]) {
    use crate::consts;

    let k = &consts::K32X4;

    macro_rules! schedule {
        ($v0:expr, $v1:expr, $v2:expr, $v3:expr) => {
            sha256msg2(sha256msg1($v0, $v1) + sha256load($v2, $v3), $v3)
        };
    }

    macro_rules! rounds4 {
        ($abef:ident, $cdgh:ident, $rest:expr) => {{
            $cdgh = sha256_digest_round_x2($cdgh, $abef, $rest);
            $abef = sha256_digest_round_x2($abef, $cdgh, sha256swap($rest));
        }};
    }

    let mut abef = u32x4(state[0], state[1], state[4], state[5]);
    let mut cdgh = u32x4(state[2], state[3], state[6], state[7]);

    // Rounds 0..64
    let mut w0 = u32x4(block[3], block[2], block[1], block[0]);
    rounds4!(abef, cdgh, k[0] + w0);
    let mut w1 = u32x4(block[7], block[6], block[5], block[4]);
    rounds4!(abef, cdgh, k[1] + w1);
    let mut w2 = u32x4(block[11], block[10], block[9], block[8]);
    rounds4!(abef, cdgh, k[2] + w2);
    let mut w3 = u32x4(block[15], block[14], block[13], block[12]);
    rounds4!(abef, cdgh, k[3] + w3);
    let mut w4 = schedule!(w0, w1, w2, w3);
    rounds4!(abef, cdgh, k[4] + w4);
    w0 = schedule!(w1, w2, w3, w4);
    rounds4!(abef, cdgh, k[5] + w0);
    w1 = schedule!(w2, w3, w4, w0);
    rounds4!(abef, cdgh, k[6] + w1);
    w2 = schedule!(w3, w4, w0, w1);
    rounds4!(abef, cdgh, k[7] + w2);
    w3 = schedule!(w4, w0, w1, w2);
    rounds4!(abef, cdgh, k[8] + w3);
    w4 = schedule!(w0, w1, w2, w3);
    rounds4!(abef, cdgh, k[9] + w4);
    w0 = schedule!(w1, w2, w3, w4);
    rounds4!(abef, cdgh, k[10] + w0);
    w1 = schedule!(w2, w3, w4, w0);
    rounds4!(abef, cdgh, k[11] + w1);
    w2 = schedule!(w3, w4, w0, w1);
    rounds4!(abef, cdgh, k[12] + w2);
    w3 = schedule!(w4, w0, w1, w2);
    rounds4!(abef, cdgh, k[13] + w3);
    w4 = schedule!(w0, w1, w2, w3);
    rounds4!(abef, cdgh, k[14] + w4);
    w0 = schedule!(w1, w2, w3, w4);
    rounds4!(abef, cdgh, k[15] + w0);

    let u32x4(a, b, e, f) = abef;
    let u32x4(c, d, g, h) = cdgh;

    state[0] = state[0].wrapping_add(a);
    state[1] = state[1].wrapping_add(b);
    state[2] = state[2].wrapping_add(c);
    state[3] = state[3].wrapping_add(d);
    state[4] = state[4].wrapping_add(e);
    state[5] = state[5].wrapping_add(f);
    state[6] = state[6].wrapping_add(g);
    state[7] = state[7].wrapping_add(h);
}

/// Process a block with the SHA-256 algorithm. (See more...)
///
/// Internally, this uses functions which resemble the new Intel SHA instruction
/// sets, and so it's data locality properties may improve performance. However,
/// to benefit the most from this implementation, replace these functions with
/// x86 intrinsics to get a possible speed boost.
///
/// # Implementation
///
/// The `Sha256` algorithm is implemented with functions that resemble the new
/// Intel SHA instruction set extensions. These intructions fall into two
/// categories: message schedule calculation, and the message block 64-round
/// digest calculation. The schedule-related instructions allow 4 rounds to be
/// calculated as:
///
/// ```compile_fail
/// use std::simd::u32x4;
/// use self::crypto::sha2::{
///     sha256msg1,
///     sha256msg2,
///     sha256load
/// };
///
/// fn schedule4_data(work: &mut [u32x4], w: &[u32]) {
///
///     // this is to illustrate the data order
///     work[0] = u32x4(w[3], w[2], w[1], w[0]);
///     work[1] = u32x4(w[7], w[6], w[5], w[4]);
///     work[2] = u32x4(w[11], w[10], w[9], w[8]);
///     work[3] = u32x4(w[15], w[14], w[13], w[12]);
/// }
///
/// fn schedule4_work(work: &mut [u32x4], t: usize) {
///
///     // this is the core expression
///     work[t] = sha256msg2(sha256msg1(work[t - 4], work[t - 3]) +
///                          sha256load(work[t - 2], work[t - 1]),
///                          work[t - 1])
/// }
/// ```
///
/// instead of 4 rounds of:
///
/// ```compile_fail
/// fn schedule_work(w: &mut [u32], t: usize) {
///     w[t] = sigma1!(w[t - 2]) + w[t - 7] + sigma0!(w[t - 15]) + w[t - 16];
/// }
/// ```
///
/// and the digest-related instructions allow 4 rounds to be calculated as:
///
/// ```compile_fail
/// use std::simd::u32x4;
/// use self::crypto::sha2::{K32X4,
///     sha256rnds2,
///     sha256swap
/// };
///
/// fn rounds4(state: &mut [u32; 8], work: &mut [u32x4], t: usize) {
///     let [a, b, c, d, e, f, g, h]: [u32; 8] = *state;
///
///     // this is to illustrate the data order
///     let mut abef = u32x4(a, b, e, f);
///     let mut cdgh = u32x4(c, d, g, h);
///     let temp = K32X4[t] + work[t];
///
///     // this is the core expression
///     cdgh = sha256rnds2(cdgh, abef, temp);
///     abef = sha256rnds2(abef, cdgh, sha256swap(temp));
///
///     *state = [abef.0, abef.1, cdgh.0, cdgh.1,
///               abef.2, abef.3, cdgh.2, cdgh.3];
/// }
/// ```
///
/// instead of 4 rounds of:
///
/// ```compile_fail
/// fn round(state: &mut [u32; 8], w: &mut [u32], t: usize) {
///     let [a, b, c, mut d, e, f, g, mut h]: [u32; 8] = *state;
///
///     h += big_sigma1!(e) +   choose!(e, f, g) + K32[t] + w[t]; d += h;
///     h += big_sigma0!(a) + majority!(a, b, c);
///
///     *state = [h, a, b, c, d, e, f, g];
/// }
/// ```
///
/// **NOTE**: It is important to note, however, that these instructions are not
/// implemented by any CPU (at the time of this writing), and so they are
/// emulated in this library until the instructions become more common, and gain
///  support in LLVM (and GCC, etc.).
#[inline]
pub fn compress256(state: &mut [u32; 8], blocks: &[&[u8]]) {
    use crate::consts::BLOCK_LEN;
    use block_buffer::byteorder::{ByteOrder, BE};

    let mut block_u32 = [0u32; BLOCK_LEN];

    for block in blocks.chunks(2) {
        assert_eq!(block[0].len(), 32);
        assert_eq!(block[1].len(), 32);
        BE::read_u32_into(&block[0], &mut block_u32[..BLOCK_LEN / 2]);
        BE::read_u32_into(&block[1], &mut block_u32[BLOCK_LEN / 2..]);

        sha256_digest_block_u32(state, &block_u32);
    }
}

'''
'''--- storage-proofs/Cargo.toml ---
[package]
name = "storage-proofs"
description = "Implementations of Proofs of Storage"
version = "2.0.0"
authors = ["dignifiedquire <dignifiedquire@gmail.com>", "laser <l@s3r.com>", "porcuquine <porcuquine@users.noreply.github.com>"]
license = "MIT OR Apache-2.0"
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[dependencies]
storage-proofs-core = { path = "./core", version = "2.0.0" }
storage-proofs-post = { path = "./post", version = "2.0.0" }
storage-proofs-porep = { path = "./porep", version = "2.0.0" }

[features]
default = ["gpu"]
simd = ["storage-proofs-core/simd"]
asm = ["storage-proofs-core/asm"]
gpu = ["storage-proofs-core/gpu"]
measurements = ["storage-proofs-core/measurements"]
profile = ["measurements"]

'''
'''--- storage-proofs/README.md ---
# Storage Proofs

> Implementations of Proofs of Storage.

## License

MIT or Apache 2.0

'''
'''--- storage-proofs/build.rs ---
fn is_compiled_for_64_bit_arch() -> bool {
    cfg!(target_pointer_width = "64")
}

fn main() {
    assert!(
        is_compiled_for_64_bit_arch(),
        "must be built for 64-bit architectures"
    );
}

'''
'''--- storage-proofs/core/Cargo.toml ---
[package]
name = "storage-proofs-core"
version = "2.0.0"
authors = ["dignifiedquire <me@dignifiedquire.com>"]
description = "Core parts for proofs of storage"
license = "MIT OR Apache-2.0"
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[lib]
bench = false

[dependencies]
rand = "0.7"
merkletree = "0.20.0"
byteorder = "1"
config = "0.9.3"
itertools = "0.9"
lazy_static = "1.2"
memmap = "0.7"
aes = "0.3"
block-modes = "0.3"
sha2 = { version = "0.8.3", package = "sha2ni" }
tempfile = "3"
fs2 = "0.4"
rayon = "1.0.0"
serde = { version = "1.0", features = ["derive"]}
blake2b_simd = "0.5"
blake2s_simd = "0.5"
toml = "0.5"
ff = { version = "0.2.1", package = "fff" }
bellperson = "0.8.0"
paired = { version = "0.19.0", features = ["serde"] }
fil-sapling-crypto = "0.6.0"
serde_json = "1.0"
log = "0.4.7"
rand_chacha = "0.2.1"
hex = "0.4.0"
generic-array = "0.13.2"
anyhow = "1.0.23"
thiserror = "1.0.6"
neptune = { version = "0.7.1", features = ["gpu"] }
cpu-time = { version = "1.0", optional = true }
gperftools = { version = "0.2", optional = true }

[dev-dependencies]
proptest = "0.7"
criterion = "0.3"
femme = "1.2.0"
bitvec = "0.17"
rand_xorshift = "0.2.0"
pretty_assertions = "0.6.1"
sha2raw = { path = "../../sha2raw", version = "1.0.0" }

[features]
default = ["gpu"]
simd = []
asm = ["sha2/sha2-asm"]
big-sector-sizes-bench = []
gpu = ["bellperson/gpu", "fil-sapling-crypto/gpu"]
measurements = ["cpu-time", "gperftools"]
profile = ["measurements"]

[[bench]]
name = "pedersen"
harness = false

[[bench]]
name = "sha256"
harness = false

[[bench]]
name = "blake2s"
harness = false

[[bench]]
name = "drgraph"
harness = false

[[bench]]
name = "xor"
harness = false

[[bench]]
name = "fr"
harness = false

[[bench]]
name = "merkle"
harness = false

[[bench]]
name = "misc"
harness = false

'''
'''--- storage-proofs/core/README.md ---
# Storage Proofs Core

## License

MIT or Apache 2.0

'''
'''--- storage-proofs/core/benches/blake2s.rs ---
use bellperson::gadgets::boolean::{self, Boolean};
use bellperson::groth16::*;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use paired::bls12_381::Bls12;
use rand::{thread_rng, Rng};
use storage_proofs_core::gadgets::BenchCS;

struct Blake2sExample<'a> {
    data: &'a [Option<bool>],
}

impl<'a> Circuit<Bls12> for Blake2sExample<'a> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let data: Vec<Boolean> = self
            .data
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        let cs = cs.namespace(|| "blake2s");
        let personalization = vec![0u8; 8];
        let _res = bellperson::gadgets::blake2s::blake2s(cs, &data, &personalization)?;
        Ok(())
    }
}

fn blake2s_benchmark(c: &mut Criterion) {
    let params = vec![32, 64, 10 * 32];

    c.bench(
        "hash-blake2s",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                b.iter(|| black_box(blake2s_simd::blake2s(&data)))
            },
            params,
        ),
    );
}

fn blake2s_circuit_benchmark(c: &mut Criterion) {
    let mut rng1 = thread_rng();
    let groth_params = generate_random_parameters::<Bls12, _, _>(
        Blake2sExample {
            data: &vec![None; 256],
        },
        &mut rng1,
    )
    .unwrap();

    let params = vec![32];

    c.bench(
        "hash-blake2s-circuit",
        ParameterizedBenchmark::new(
            "create-proof",
            move |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

                b.iter(|| {
                    let proof = create_random_proof(
                        Blake2sExample {
                            data: data.as_slice(),
                        },
                        &groth_params,
                        &mut rng,
                    )
                    .unwrap();

                    black_box(proof)
                });
            },
            params,
        )
        .with_function("synthesize", move |b, bytes| {
            let mut rng = thread_rng();
            let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();
            b.iter(|| {
                let mut cs = BenchCS::<Bls12>::new();

                Blake2sExample {
                    data: data.as_slice(),
                }
                .synthesize(&mut cs)
                .unwrap();

                black_box(cs)
            });
        })
        .sample_size(20),
    );
}

criterion_group!(benches, blake2s_benchmark, blake2s_circuit_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/drgraph.rs ---
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use storage_proofs_core::drgraph::*;
use storage_proofs_core::hasher::pedersen::*;

fn drgraph(c: &mut Criterion) {
    let params = vec![12, 24, 128, 1024];

    c.bench(
        "sample",
        ParameterizedBenchmark::new(
            "bucket/m=6",
            |b, n| {
                let graph =
                    BucketGraph::<PedersenHasher>::new(*n, BASE_DEGREE, 0, new_seed()).unwrap();

                b.iter(|| {
                    let mut parents = vec![0; 6];
                    black_box(graph.parents(2, &mut parents).unwrap());
                })
            },
            params,
        ),
    );
}

criterion_group!(benches, drgraph);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/fr.rs ---
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ff::Field;
use paired::bls12_381::Fr;
use rand::thread_rng;
use storage_proofs_core::fr32::{bytes_into_fr, fr_into_bytes};

fn fr_benchmark(c: &mut Criterion) {
    c.bench_function("fr-to-bytes-32", move |b| {
        let mut rng = thread_rng();
        let fr = Fr::random(&mut rng);

        b.iter(|| black_box(fr_into_bytes(&fr)))
    });

    c.bench_function("bytes-32-to-fr", move |b| {
        let mut rng = thread_rng();
        let fr = Fr::random(&mut rng);
        let bytes = fr_into_bytes(&fr);

        b.iter(|| black_box(bytes_into_fr(&bytes).unwrap()))
    });
}

criterion_group!(benches, fr_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/merkle.rs ---
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use rand::{thread_rng, Rng};
use storage_proofs_core::hasher::{PoseidonHasher, Sha256Hasher};
use storage_proofs_core::merkle::{create_base_merkle_tree, BinaryMerkleTree};

fn merkle_benchmark(c: &mut Criterion) {
    #[cfg(feature = "big-sector-sizes-bench")]
    let params = vec![128, 1024, 1048576];
    #[cfg(not(feature = "big-sector-sizes-bench"))]
    let params = vec![128, 1024];

    c.bench(
        "merkletree-binary",
        ParameterizedBenchmark::new(
            "sha256",
            move |b, n_nodes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..32 * *n_nodes).map(|_| rng.gen()).collect();
                b.iter(|| {
                    black_box(
                        create_base_merkle_tree::<BinaryMerkleTree<Sha256Hasher>>(
                            None, *n_nodes, &data,
                        )
                        .unwrap(),
                    )
                })
            },
            params,
        )
        .with_function("poseidon", move |b, n_nodes| {
            let mut rng = thread_rng();
            let data: Vec<u8> = (0..32 * *n_nodes).map(|_| rng.gen()).collect();

            b.iter(|| {
                black_box(
                    create_base_merkle_tree::<BinaryMerkleTree<PoseidonHasher>>(
                        None, *n_nodes, &data,
                    )
                    .unwrap(),
                )
            })
        })
        .sample_size(20),
    );
}

criterion_group!(benches, merkle_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/misc.rs ---
use std::io::{Read, Seek, Write};

use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use rand::{thread_rng, Rng};
use tempfile::tempfile;

fn read_bytes_benchmark(c: &mut Criterion) {
    let params = vec![32, 64, 512, 1024, 64 * 1024];

    c.bench(
        "read",
        ParameterizedBenchmark::new(
            "from_disk",
            |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                let mut f = tempfile().unwrap();
                f.write_all(&data).unwrap();
                f.sync_all().unwrap();

                b.iter(|| {
                    let mut res = vec![0u8; *bytes];
                    f.seek(std::io::SeekFrom::Start(0)).unwrap();
                    f.read_exact(&mut res).unwrap();

                    black_box(res)
                })
            },
            params,
        ),
    );
}

criterion_group!(benches, read_bytes_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/pedersen.rs ---
use bellperson::gadgets::boolean::{self, Boolean};
use bellperson::groth16::*;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use paired::bls12_381::Bls12;
use rand::{thread_rng, Rng};
use storage_proofs_core::crypto::pedersen;
use storage_proofs_core::gadgets::{self, BenchCS};

struct PedersenExample<'a> {
    data: &'a [Option<bool>],
}

impl<'a> Circuit<Bls12> for PedersenExample<'a> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let data: Vec<Boolean> = self
            .data
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        let cs = cs.namespace(|| "pedersen");
        let res = gadgets::pedersen::pedersen_compression_num(cs, &data)?;
        // please compiler don't optimize the result away
        // only check if we actually have input data
        if self.data[0].is_some() {
            res.get_value().unwrap();
        }

        Ok(())
    }
}

struct PedersenMdExample<'a> {
    data: &'a [Option<bool>],
}

impl<'a> Circuit<Bls12> for PedersenMdExample<'a> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let data: Vec<Boolean> = self
            .data
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        let cs = cs.namespace(|| "pedersen");
        let res = gadgets::pedersen::pedersen_md_no_padding(cs, &data)?;
        // please compiler don't optimize the result away
        // only check if we actually have input data
        if self.data[0].is_some() {
            res.get_value().unwrap();
        }

        Ok(())
    }
}

fn pedersen_benchmark(c: &mut Criterion) {
    let params = vec![32];

    c.bench(
        "hash-pedersen",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                b.iter(|| black_box(pedersen::pedersen(&data)))
            },
            params,
        ),
    );
}

fn pedersen_md_benchmark(c: &mut Criterion) {
    let params = vec![32, 2 * 32, 4 * 32, 8 * 32, 11 * 32];

    c.bench(
        "hash-pedersen-md",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                b.iter(|| black_box(pedersen::pedersen_md_no_padding(&data)))
            },
            params,
        ),
    );
}

fn pedersen_circuit_benchmark(c: &mut Criterion) {
    let mut rng1 = thread_rng();
    let groth_params = generate_random_parameters::<Bls12, _, _>(
        PedersenExample {
            data: &vec![None; 256],
        },
        &mut rng1,
    )
    .unwrap();

    let params = vec![32];

    c.bench(
        "hash-pedersen-circuit",
        ParameterizedBenchmark::new(
            "create-proof",
            move |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

                b.iter(|| {
                    let proof = create_random_proof(
                        PedersenExample {
                            data: data.as_slice(),
                        },
                        &groth_params,
                        &mut rng,
                    )
                    .unwrap();

                    black_box(proof)
                });
            },
            params,
        )
        .with_function("synthesize", move |b, bytes| {
            let mut rng = thread_rng();
            let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

            b.iter(|| {
                let mut cs = BenchCS::<Bls12>::new();
                PedersenExample {
                    data: data.as_slice(),
                }
                .synthesize(&mut cs)
                .unwrap();

                black_box(cs)
            });
        })
        .sample_size(20),
    );
}

fn pedersen_md_circuit_benchmark(c: &mut Criterion) {
    let mut rng1 = thread_rng();
    let groth_params = generate_random_parameters::<Bls12, _, _>(
        PedersenMdExample {
            data: &vec![None; 256],
        },
        &mut rng1,
    )
    .unwrap();

    let params = vec![64];

    c.bench(
        "hash-pedersen-md-circuit",
        ParameterizedBenchmark::new(
            "create-proof",
            move |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

                b.iter(|| {
                    let proof = create_random_proof(
                        PedersenMdExample {
                            data: data.as_slice(),
                        },
                        &groth_params,
                        &mut rng,
                    )
                    .unwrap();

                    black_box(proof)
                });
            },
            params,
        )
        .with_function("synthesize", move |b, bytes| {
            let mut rng = thread_rng();
            let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

            b.iter(|| {
                let mut cs = BenchCS::<Bls12>::new();
                PedersenMdExample {
                    data: data.as_slice(),
                }
                .synthesize(&mut cs)
                .unwrap();

                black_box(cs)
            });
        })
        .sample_size(20),
    );
}

criterion_group!(
    benches,
    pedersen_benchmark,
    pedersen_md_benchmark,
    pedersen_circuit_benchmark,
);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/sha256.rs ---
use bellperson::gadgets::boolean::{self, Boolean};
use bellperson::groth16::*;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use criterion::{
    black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark, Throughput,
};
use paired::bls12_381::Bls12;
use rand::{thread_rng, Rng};
use sha2::{Digest, Sha256};
use storage_proofs_core::gadgets::BenchCS;

struct Sha256Example<'a> {
    data: &'a [Option<bool>],
}

impl<'a> Circuit<Bls12> for Sha256Example<'a> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let data: Vec<Boolean> = self
            .data
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        let cs = cs.namespace(|| "sha256");

        let _res = bellperson::gadgets::sha256::sha256(cs, &data)?;
        Ok(())
    }
}

fn sha256_benchmark(c: &mut Criterion) {
    let params = vec![32, 64, 10 * 32, 37 * 32];

    c.bench(
        "hash-sha256-base",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                b.iter(|| black_box(Sha256::digest(&data)))
            },
            params,
        )
        .throughput(|bytes| Throughput::Bytes(*bytes as u64)),
    );
}

fn sha256_raw_benchmark(c: &mut Criterion) {
    let params = vec![64, 10 * 32, 38 * 32];

    c.bench(
        "hash-sha256-raw",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                use sha2raw::Sha256;

                let mut rng = thread_rng();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();
                let chunks = data.chunks(32).collect::<Vec<_>>();

                b.iter(|| black_box(Sha256::digest(&chunks)))
            },
            params,
        )
        .throughput(|bytes| Throughput::Bytes(*bytes as u64)),
    );
}

fn sha256_circuit_benchmark(c: &mut Criterion) {
    let mut rng1 = thread_rng();

    let params = vec![32, 64];

    c.bench(
        "hash-sha256-circuit",
        ParameterizedBenchmark::new(
            "create-proof",
            move |b, bytes| {
                let groth_params = generate_random_parameters::<Bls12, _, _>(
                    Sha256Example {
                        data: &vec![None; *bytes as usize * 8],
                    },
                    &mut rng1,
                )
                .unwrap();

                let mut rng = thread_rng();
                let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

                b.iter(|| {
                    let proof = create_random_proof(
                        Sha256Example {
                            data: data.as_slice(),
                        },
                        &groth_params,
                        &mut rng,
                    )
                    .unwrap();

                    black_box(proof)
                });
            },
            params,
        )
        .with_function("synthesize", move |b, bytes| {
            let mut rng = thread_rng();
            let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

            b.iter(|| {
                let mut cs = BenchCS::<Bls12>::new();
                Sha256Example {
                    data: data.as_slice(),
                }
                .synthesize(&mut cs)
                .unwrap();

                black_box(cs)
            });
        })
        .sample_size(20),
    );
}

criterion_group!(
    benches,
    sha256_benchmark,
    sha256_raw_benchmark,
    sha256_circuit_benchmark
);
criterion_main!(benches);

'''
'''--- storage-proofs/core/benches/xor.rs ---
use bellperson::gadgets::boolean::{self, Boolean};
use bellperson::groth16::*;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use paired::bls12_381::Bls12;
use rand::{thread_rng, Rng};
use storage_proofs_core::crypto::xor;
use storage_proofs_core::gadgets;
use storage_proofs_core::gadgets::BenchCS;

struct XorExample<'a> {
    key: &'a [Option<bool>],
    data: &'a [Option<bool>],
}

impl<'a> Circuit<Bls12> for XorExample<'a> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let key: Vec<Boolean> = self
            .key
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("key_bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;
        let data: Vec<Boolean> = self
            .data
            .into_iter()
            .enumerate()
            .map(|(i, b)| {
                Ok(Boolean::from(boolean::AllocatedBit::alloc(
                    cs.namespace(|| format!("data_bit {}", i)),
                    *b,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        let mut cs = cs.namespace(|| "xor");
        let _res = gadgets::xor::xor(&mut cs, &key, &data)?;

        Ok(())
    }
}

fn xor_benchmark(c: &mut Criterion) {
    let params = vec![32, 64, 10 * 32];

    c.bench(
        "xor",
        ParameterizedBenchmark::new(
            "non-circuit",
            |b, bytes| {
                let mut rng = thread_rng();
                let key: Vec<u8> = (0..32).map(|_| rng.gen()).collect();
                let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

                b.iter(|| black_box(xor::encode(&key, &data)))
            },
            params,
        ),
    );
}

fn xor_circuit_benchmark(c: &mut Criterion) {
    let mut rng1 = thread_rng();
    let groth_params = generate_random_parameters::<Bls12, _, _>(
        XorExample {
            key: &vec![None; 8 * 32],
            data: &vec![None; 256],
        },
        &mut rng1,
    )
    .unwrap();

    let params = vec![32];

    c.bench(
        "xor-circuit",
        ParameterizedBenchmark::new(
            "create-proof",
            move |b, bytes| {
                let mut rng = thread_rng();
                let key: Vec<Option<bool>> = (0..32 * 8).map(|_| Some(rng.gen())).collect();
                let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

                b.iter(|| {
                    let proof = create_random_proof(
                        XorExample {
                            key: key.as_slice(),
                            data: data.as_slice(),
                        },
                        &groth_params,
                        &mut rng,
                    )
                    .unwrap();

                    black_box(proof)
                });
            },
            params,
        )
        .with_function("synthesize", move |b, bytes| {
            let mut rng = thread_rng();
            let key: Vec<Option<bool>> = (0..32 * 8).map(|_| Some(rng.gen())).collect();
            let data: Vec<Option<bool>> = (0..bytes * 8).map(|_| Some(rng.gen())).collect();

            b.iter(|| {
                let mut cs = BenchCS::<Bls12>::new();
                XorExample {
                    key: key.as_slice(),
                    data: data.as_slice(),
                }
                .synthesize(&mut cs)
                .unwrap();

                black_box(cs)
            });
        })
        .sample_size(20),
    );
}

criterion_group!(benches, xor_benchmark, xor_circuit_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/core/src/cache_key.rs ---
use std::fmt;

#[derive(Debug, Copy, Clone)]
pub enum CacheKey {
    PAux,
    TAux,
    CommDTree,
    CommCTree,
    CommRLastTree,
}

impl fmt::Display for CacheKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            CacheKey::PAux => write!(f, "p_aux"),
            CacheKey::TAux => write!(f, "t_aux"),
            CacheKey::CommDTree => write!(f, "tree-d"),
            CacheKey::CommCTree => write!(f, "tree-c"),
            CacheKey::CommRLastTree => write!(f, "tree-r-last"),
        }
    }
}

impl CacheKey {
    pub fn label_layer(layer: usize) -> String {
        format!("layer-{}", layer)
    }
}

'''
'''--- storage-proofs/core/src/compound_proof.rs ---
use anyhow::{ensure, Context};
use bellperson::{groth16, Circuit};
use log::info;
use paired::bls12_381::{Bls12, Fr};
use rand::{rngs::OsRng, RngCore};
use rayon::prelude::*;

use crate::error::Result;
use crate::multi_proof::MultiProof;
use crate::parameter_cache::{CacheableParameters, ParameterSetMetadata};
use crate::partitions;
use crate::proof::ProofScheme;

#[derive(Clone)]
pub struct SetupParams<'a, S: ProofScheme<'a>> {
    pub vanilla_params: <S as ProofScheme<'a>>::SetupParams,
    pub partitions: Option<usize>,
    /// High priority (always runs on GPU) == true
    pub priority: bool,
}

#[derive(Clone)]
pub struct PublicParams<'a, S: ProofScheme<'a>> {
    pub vanilla_params: S::PublicParams,
    pub partitions: Option<usize>,
    pub priority: bool,
}

/// CircuitComponent exists so parent components can pass private inputs to their subcomponents
/// when calling CompoundProof::circuit directly. In general, there are no internal private inputs,
/// and a default value will be passed. CompoundProof::circuit implementations should exhibit
/// default behavior when passed a default ComponentPrivateinputs.
pub trait CircuitComponent {
    type ComponentPrivateInputs: Default + Clone;
}

/// The CompoundProof trait bundles a proof::ProofScheme and a bellperson::Circuit together.
/// It provides methods equivalent to those provided by proof::ProofScheme (setup, prove, verify).
/// See documentation at proof::ProofScheme for details.
/// Implementations should generally only need to supply circuit and generate_public_inputs.
/// The remaining trait methods are used internally and implement the necessary plumbing.
pub trait CompoundProof<'a, S: ProofScheme<'a>, C: Circuit<Bls12> + CircuitComponent + Send>
where
    S::Proof: Sync + Send,
    S::PublicParams: ParameterSetMetadata + Sync + Send,
    S::PublicInputs: Clone + Sync,
    Self: CacheableParameters<C, S::PublicParams>,
{
    // setup is equivalent to ProofScheme::setup.
    fn setup(sp: &SetupParams<'a, S>) -> Result<PublicParams<'a, S>> {
        Ok(PublicParams {
            vanilla_params: S::setup(&sp.vanilla_params)?,
            partitions: sp.partitions,
            priority: sp.priority,
        })
    }

    fn partition_count(public_params: &PublicParams<'a, S>) -> usize {
        match public_params.partitions {
            None => 1,
            Some(0) => panic!("cannot specify zero partitions"),
            Some(k) => k,
        }
    }

    /// prove is equivalent to ProofScheme::prove.
    fn prove<'b>(
        pub_params: &PublicParams<'a, S>,
        pub_in: &S::PublicInputs,
        priv_in: &S::PrivateInputs,
        groth_params: &'b groth16::MappedParameters<Bls12>,
    ) -> Result<MultiProof<'b>> {
        let partition_count = Self::partition_count(pub_params);

        // This will always run at least once, since there cannot be zero partitions.
        ensure!(partition_count > 0, "There must be partitions");

        info!("vanilla_proof:start");
        let vanilla_proofs = S::prove_all_partitions(
            &pub_params.vanilla_params,
            &pub_in,
            priv_in,
            partition_count,
        )?;

        info!("vanilla_proof:finish");

        let sanity_check =
            S::verify_all_partitions(&pub_params.vanilla_params, &pub_in, &vanilla_proofs)?;
        ensure!(sanity_check, "sanity check failed");

        info!("snark_proof:start");
        let groth_proofs = Self::circuit_proofs(
            pub_in,
            vanilla_proofs,
            &pub_params.vanilla_params,
            groth_params,
            pub_params.priority,
        )?;
        info!("snark_proof:finish");

        Ok(MultiProof::new(groth_proofs, &groth_params.vk))
    }

    // verify is equivalent to ProofScheme::verify.
    fn verify<'b>(
        public_params: &PublicParams<'a, S>,
        public_inputs: &S::PublicInputs,
        multi_proof: &MultiProof<'b>,
        requirements: &S::Requirements,
    ) -> Result<bool> {
        ensure!(
            multi_proof.circuit_proofs.len() == Self::partition_count(public_params),
            "Inconsistent inputs"
        );

        let vanilla_public_params = &public_params.vanilla_params;
        let pvk = groth16::prepare_batch_verifying_key(&multi_proof.verifying_key);

        if !<S as ProofScheme>::satisfies_requirements(
            &public_params.vanilla_params,
            requirements,
            multi_proof.circuit_proofs.len(),
        ) {
            return Ok(false);
        }

        let inputs: Vec<_> = (0..multi_proof.circuit_proofs.len())
            .into_par_iter()
            .map(|k| Self::generate_public_inputs(public_inputs, vanilla_public_params, Some(k)))
            .collect::<Result<_>>()?;
        let proofs: Vec<_> = multi_proof.circuit_proofs.iter().collect();

        let res = groth16::verify_proofs_batch(&pvk, &mut rand::rngs::OsRng, &proofs, &inputs)?;
        Ok(res)
    }

    /// Efficiently verify multiple proofs.
    fn batch_verify<'b>(
        public_params: &PublicParams<'a, S>,
        public_inputs: &[S::PublicInputs],
        multi_proofs: &[MultiProof<'b>],
        requirements: &S::Requirements,
    ) -> Result<bool> {
        ensure!(
            public_inputs.len() == multi_proofs.len(),
            "Inconsistent inputs"
        );
        for proof in multi_proofs {
            ensure!(
                proof.circuit_proofs.len() == Self::partition_count(public_params),
                "Inconsistent inputs"
            );
        }
        ensure!(!public_inputs.is_empty(), "Cannot verify empty proofs");

        let vanilla_public_params = &public_params.vanilla_params;
        // just use the first one, the must be equal any way
        let pvk = groth16::prepare_batch_verifying_key(&multi_proofs[0].verifying_key);

        for multi_proof in multi_proofs.iter() {
            if !<S as ProofScheme>::satisfies_requirements(
                &public_params.vanilla_params,
                requirements,
                multi_proof.circuit_proofs.len(),
            ) {
                return Ok(false);
            }
        }

        let inputs: Vec<_> = multi_proofs
            .par_iter()
            .zip(public_inputs.par_iter())
            .flat_map(|(multi_proof, pub_inputs)| {
                (0..multi_proof.circuit_proofs.len())
                    .into_par_iter()
                    .map(|k| {
                        Self::generate_public_inputs(pub_inputs, vanilla_public_params, Some(k))
                    })
                    .collect::<Result<Vec<_>>>()
                    .expect("Invalid public inputs") // TODO: improve error handling
            })
            .collect::<Vec<_>>();
        let circuit_proofs: Vec<_> = multi_proofs
            .iter()
            .flat_map(|m| m.circuit_proofs.iter())
            .collect();

        let res = groth16::verify_proofs_batch(
            &pvk,
            &mut rand::rngs::OsRng,
            &circuit_proofs[..],
            &inputs,
        )?;

        Ok(res)
    }

    /// circuit_proof creates and synthesizes a circuit from concrete params/inputs, then generates a
    /// groth proof from it. It returns a groth proof.
    /// circuit_proof is used internally and should neither be called nor implemented outside of
    /// default trait methods.
    fn circuit_proofs(
        pub_in: &S::PublicInputs,
        vanilla_proof: Vec<S::Proof>,
        pub_params: &S::PublicParams,
        groth_params: &groth16::MappedParameters<Bls12>,
        priority: bool,
    ) -> Result<Vec<groth16::Proof<Bls12>>> {
        let mut rng = OsRng;
        ensure!(
            !vanilla_proof.is_empty(),
            "cannot create a circuit proof over missing vanilla proofs"
        );

        let circuits = vanilla_proof
            .into_par_iter()
            .enumerate()
            .map(|(k, vanilla_proof)| {
                Self::circuit(
                    &pub_in,
                    C::ComponentPrivateInputs::default(),
                    &vanilla_proof,
                    &pub_params,
                    Some(k),
                )
            })
            .collect::<Result<Vec<_>>>()?;

        let groth_proofs = if priority {
            groth16::create_random_proof_batch_in_priority(circuits, groth_params, &mut rng)?
        } else {
            groth16::create_random_proof_batch(circuits, groth_params, &mut rng)?
        };

        groth_proofs
            .into_iter()
            .map(|groth_proof| {
                let mut proof_vec = vec![];
                groth_proof.write(&mut proof_vec)?;
                let gp = groth16::Proof::<Bls12>::read(&proof_vec[..])?;
                Ok(gp)
            })
            .collect()
    }

    /// generate_public_inputs generates public inputs suitable for use as input during verification
    /// of a proof generated from this CompoundProof's bellperson::Circuit (C). These inputs correspond
    /// to those allocated when C is synthesized.
    fn generate_public_inputs(
        pub_in: &S::PublicInputs,
        pub_params: &S::PublicParams,
        partition_k: Option<usize>,
    ) -> Result<Vec<Fr>>;

    /// circuit constructs an instance of this CompoundProof's bellperson::Circuit.
    /// circuit takes PublicInputs, PublicParams, and Proof from this CompoundProof's proof::ProofScheme (S)
    /// and uses them to initialize Circuit fields which will be used to construct public and private
    /// inputs during circuit synthesis.
    fn circuit(
        public_inputs: &S::PublicInputs,
        component_private_inputs: C::ComponentPrivateInputs,
        vanilla_proof: &S::Proof,
        public_param: &S::PublicParams,
        partition_k: Option<usize>,
    ) -> Result<C>;

    fn blank_circuit(public_params: &S::PublicParams) -> C;

    /// If the rng option argument is set, parameters will be
    /// generated using it.  This is used for testing only, or where
    /// parameters are otherwise unavailable (e.g. benches).  If rng
    /// is not set, an error will result if parameters are not
    /// present.
    fn groth_params<R: RngCore>(
        rng: Option<&mut R>,
        public_params: &S::PublicParams,
    ) -> Result<groth16::MappedParameters<Bls12>> {
        Self::get_groth_params(rng, Self::blank_circuit(public_params), public_params)
    }

    /// If the rng option argument is set, parameters will be
    /// generated using it.  This is used for testing only, or where
    /// parameters are otherwise unavailable (e.g. benches).  If rng
    /// is not set, an error will result if parameters are not
    /// present.
    fn verifying_key<R: RngCore>(
        rng: Option<&mut R>,
        public_params: &S::PublicParams,
    ) -> Result<groth16::VerifyingKey<Bls12>> {
        Self::get_verifying_key(rng, Self::blank_circuit(public_params), public_params)
    }

    fn circuit_for_test(
        public_parameters: &PublicParams<'a, S>,
        public_inputs: &S::PublicInputs,
        private_inputs: &S::PrivateInputs,
    ) -> Result<(C, Vec<Fr>)> {
        let vanilla_params = &public_parameters.vanilla_params;
        let partition_count = partitions::partition_count(public_parameters.partitions);
        let vanilla_proofs = S::prove_all_partitions(
            vanilla_params,
            public_inputs,
            private_inputs,
            partition_count,
        )
        .context("failed to generate partition proofs")?;

        ensure!(
            vanilla_proofs.len() == partition_count,
            "Vanilla proofs didn't match number of partitions."
        );

        let partitions_are_verified =
            S::verify_all_partitions(vanilla_params, &public_inputs, &vanilla_proofs)
                .context("failed to verify partition proofs")?;

        ensure!(partitions_are_verified, "Vanilla proof didn't verify.");

        // Some(0) because we only return a circuit and inputs for the first partition.
        // It would be more thorough to return all, though just checking one is probably
        // fine for verifying circuit construction.
        let partition_pub_in = S::with_partition(public_inputs.clone(), Some(0));
        let inputs = Self::generate_public_inputs(&partition_pub_in, vanilla_params, Some(0))?;

        let circuit = Self::circuit(
            &partition_pub_in,
            C::ComponentPrivateInputs::default(),
            &vanilla_proofs[0],
            vanilla_params,
            Some(0),
        )?;

        Ok((circuit, inputs))
    }

    /// Like circuit_for_test but returns values for all partitions.
    fn circuit_for_test_all(
        public_parameters: &PublicParams<'a, S>,
        public_inputs: &S::PublicInputs,
        private_inputs: &S::PrivateInputs,
    ) -> Result<Vec<(C, Vec<Fr>)>> {
        let vanilla_params = &public_parameters.vanilla_params;
        let partition_count = partitions::partition_count(public_parameters.partitions);
        let vanilla_proofs = S::prove_all_partitions(
            vanilla_params,
            public_inputs,
            private_inputs,
            partition_count,
        )
        .context("failed to generate partition proofs")?;

        ensure!(
            vanilla_proofs.len() == partition_count,
            "Vanilla proofs didn't match number of partitions."
        );

        let partitions_are_verified =
            S::verify_all_partitions(vanilla_params, &public_inputs, &vanilla_proofs)
                .context("failed to verify partition proofs")?;

        ensure!(partitions_are_verified, "Vanilla proof didn't verify.");

        let mut res = Vec::with_capacity(partition_count);
        for (partition, vanilla_proof) in vanilla_proofs.iter().enumerate() {
            let partition_pub_in = S::with_partition(public_inputs.clone(), Some(partition));
            let inputs =
                Self::generate_public_inputs(&partition_pub_in, vanilla_params, Some(partition))?;

            let circuit = Self::circuit(
                &partition_pub_in,
                C::ComponentPrivateInputs::default(),
                vanilla_proof,
                vanilla_params,
                Some(partition),
            )?;
            res.push((circuit, inputs));
        }
        Ok(res)
    }
}

'''
'''--- storage-proofs/core/src/crypto/aes.rs ---
use aes::Aes256;
use anyhow::{ensure, Context};
use block_modes::block_padding::ZeroPadding;
use block_modes::{BlockMode, Cbc};

use crate::error::Result;

const IV: [u8; 16] = [0u8; 16];

pub fn encode(key: &[u8], plaintext: &[u8]) -> Result<Vec<u8>> {
    ensure!(key.len() == 32, "invalid key length");

    let mode = Cbc::<Aes256, ZeroPadding>::new_var(key, &IV).context("invalid key")?;

    Ok(mode.encrypt_vec(plaintext))
}

pub fn decode(key: &[u8], ciphertext: &[u8]) -> Result<Vec<u8>> {
    ensure!(key.len() == 32, "invalid key length");

    let mode = Cbc::<Aes256, ZeroPadding>::new_var(key, &IV).context("invalid key")?;

    let res = mode.decrypt_vec(ciphertext).context("failed to decrypt")?;
    Ok(res)
}

#[cfg(test)]
mod tests {
    use super::*;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_aes() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 0..10 {
            let key: Vec<u8> = (0..32).map(|_| rng.gen()).collect();
            let plaintext: Vec<u8> = (0..(i + 1) * 32).map(|_| rng.gen()).collect();

            let ciphertext = encode(key.as_slice(), plaintext.as_slice()).unwrap();

            assert_ne!(
                plaintext, ciphertext,
                "plaintext and ciphertext are identical"
            );
            assert_eq!(plaintext.len(), ciphertext.len());

            let roundtrip = decode(key.as_slice(), ciphertext.as_slice()).unwrap();
            assert_eq!(plaintext, roundtrip, "failed to roundtrip");
        }
    }
}

'''
'''--- storage-proofs/core/src/crypto/feistel.rs ---
use blake2b_simd::blake2b;
use std::mem;

pub const FEISTEL_ROUNDS: usize = 3;
// 3 rounds is an acceptable value for a pseudo-random permutation,
// see https://github.com/filecoin-project/rust-proofs/issues/425
// (and also https://en.wikipedia.org/wiki/Feistel_cipher#Theoretical_work).

pub type Index = u64;

pub type FeistelPrecomputed = (Index, Index, Index);

// Find the minimum number of even bits to represent `num_elements`
// within a `u32` maximum. Returns the left and right masks evenly
// distributed that together add up to that minimum number of bits.
pub fn precompute(num_elements: Index) -> FeistelPrecomputed {
    let mut next_pow4: Index = 4;
    let mut log4 = 1;
    while next_pow4 < num_elements {
        next_pow4 *= 4;
        log4 += 1;
    }

    let left_mask = ((1 << log4) - 1) << log4;
    let right_mask = (1 << log4) - 1;
    let half_bits = log4;

    (left_mask, right_mask, half_bits)
}

// Pseudo-randomly shuffle an input from a starting position to another
// one within the `[0, num_elements)` range using a `key` that will allow
// the reverse operation to take place.
pub fn permute(
    num_elements: Index,
    index: Index,
    keys: &[Index],
    precomputed: FeistelPrecomputed,
) -> Index {
    let mut u = encode(index, keys, precomputed);

    while u >= num_elements {
        u = encode(u, keys, precomputed)
    }
    // Since we are representing `num_elements` using an even number of bits,
    // that can encode many values above it, so keep repeating the operation
    // until we land in the permitted range.

    u
}

// Inverts the `permute` result to its starting value for the same `key`.
pub fn invert_permute(
    num_elements: Index,
    index: Index,
    keys: &[Index],
    precomputed: FeistelPrecomputed,
) -> Index {
    let mut u = decode(index, keys, precomputed);

    while u >= num_elements {
        u = decode(u, keys, precomputed);
    }
    u
}

/// common_setup performs common calculations on inputs shared by encode and decode.
/// Decompress the `precomputed` part of the algorithm into the initial `left` and
/// `right` pieces `(L_0, R_0)` with the `right_mask` and `half_bits` to manipulate
/// them.
fn common_setup(index: Index, precomputed: FeistelPrecomputed) -> (Index, Index, Index, Index) {
    let (left_mask, right_mask, half_bits) = precomputed;

    let left = (index & left_mask) >> half_bits;
    let right = index & right_mask;

    (left, right, right_mask, half_bits)
}

fn encode(index: Index, keys: &[Index], precomputed: FeistelPrecomputed) -> Index {
    let (mut left, mut right, right_mask, half_bits) = common_setup(index, precomputed);

    for key in keys.iter().take(FEISTEL_ROUNDS) {
        let (l, r) = (right, left ^ feistel(right, *key, right_mask));
        left = l;
        right = r;
    }

    (left << half_bits) | right
}

fn decode(index: Index, keys: &[Index], precomputed: FeistelPrecomputed) -> Index {
    let (mut left, mut right, right_mask, half_bits) = common_setup(index, precomputed);

    for i in (0..FEISTEL_ROUNDS).rev() {
        let (l, r) = ((right ^ feistel(left, keys[i], right_mask)), left);
        left = l;
        right = r;
    }

    (left << half_bits) | right
}

const HALF_FEISTEL_BYTES: usize = mem::size_of::<Index>();
const FEISTEL_BYTES: usize = 2 * HALF_FEISTEL_BYTES;

// Round function of the Feistel network: `F(Ri, Ki)`. Joins the `right`
// piece and the `key`, hashes it and returns the lower `u32` part of
// the hash filtered trough the `right_mask`.
fn feistel(right: Index, key: Index, right_mask: Index) -> Index {
    let mut data: [u8; FEISTEL_BYTES] = [0; FEISTEL_BYTES];

    // So ugly, but the price of (relative) speed.
    let r = if FEISTEL_BYTES <= 8 {
        data[0] = (right >> 24) as u8;
        data[1] = (right >> 16) as u8;
        data[2] = (right >> 8) as u8;
        data[3] = right as u8;

        data[4] = (key >> 24) as u8;
        data[5] = (key >> 16) as u8;
        data[6] = (key >> 8) as u8;
        data[7] = key as u8;

        let raw = blake2b(&data);
        let hash = raw.as_bytes();

        Index::from(hash[0]) << 24
            | Index::from(hash[1]) << 16
            | Index::from(hash[2]) << 8
            | Index::from(hash[3])
    } else {
        data[0] = (right >> 56) as u8;
        data[1] = (right >> 48) as u8;
        data[2] = (right >> 40) as u8;
        data[3] = (right >> 32) as u8;
        data[4] = (right >> 24) as u8;
        data[5] = (right >> 16) as u8;
        data[6] = (right >> 8) as u8;
        data[7] = right as u8;

        data[8] = (key >> 56) as u8;
        data[9] = (key >> 48) as u8;
        data[10] = (key >> 40) as u8;
        data[11] = (key >> 32) as u8;
        data[12] = (key >> 24) as u8;
        data[13] = (key >> 16) as u8;
        data[14] = (key >> 8) as u8;
        data[15] = key as u8;

        let raw = blake2b(&data);
        let hash = raw.as_bytes();

        Index::from(hash[0]) << 56
            | Index::from(hash[1]) << 48
            | Index::from(hash[2]) << 40
            | Index::from(hash[3]) << 32
            | Index::from(hash[4]) << 24
            | Index::from(hash[5]) << 16
            | Index::from(hash[6]) << 8
            | Index::from(hash[7])
    };

    r & right_mask
}

#[cfg(test)]
mod tests {
    use super::*;

    // Some sample n-values which are not powers of four and also don't coincidentally happen to
    // encode/decode correctly.
    const BAD_NS: &[Index] = &[5, 6, 8, 12, 17]; //
                                                 //
    fn encode_decode(n: Index, expect_success: bool) {
        let mut failed = false;
        let precomputed = precompute(n);
        for i in 0..n {
            let p = encode(i, &[1, 2, 3, 4], precomputed);
            let v = decode(p, &[1, 2, 3, 4], precomputed);
            let equal = i == v;
            let in_range = p <= n;
            if expect_success {
                assert!(equal, "failed to permute (n = {})", n);
                assert!(in_range, "output number is too big (n = {})", n);
            } else {
                if !equal || !in_range {
                    failed = true;
                }
            }
        }
        if !expect_success {
            assert!(failed, "expected failure (n = {})", n);
        }
    }

    #[test]
    fn test_feistel_power_of_4() {
        // Our implementation is guaranteed to produce a permutation when input size (number of elements)
        // is a power of our.
        let mut n = 1;

        // Powers of 4 always succeed.
        for _ in 0..4 {
            n *= 4;
            encode_decode(n, true);
        }

        // Some non-power-of 4 also succeed, but here is a selection of examples values showing
        // that this is not guaranteed.
        for i in BAD_NS.iter() {
            encode_decode(*i, false);
        }
    }

    #[test]
    fn test_feistel_on_arbitrary_set() {
        for n in BAD_NS.iter() {
            let precomputed = precompute(*n as Index);
            for i in 0..*n {
                let p = permute(*n, i, &[1, 2, 3, 4], precomputed);
                let v = invert_permute(*n, p, &[1, 2, 3, 4], precomputed);
                // Since every element in the set is reversibly mapped to another element also in the set,
                // this is indeed a permutation.
                assert_eq!(i, v, "failed to permute");
                assert!(p <= *n, "output number is too big");
            }
        }
    }
}

'''
'''--- storage-proofs/core/src/crypto/mod.rs ---
pub mod aes;
pub mod feistel;
pub mod pedersen;
pub mod sloth;
pub mod xor;

'''
'''--- storage-proofs/core/src/crypto/pedersen.rs ---
use anyhow::{ensure, Context};
use ff::PrimeFieldRepr;
use fil_sapling_crypto::jubjub::JubjubBls12;
use fil_sapling_crypto::pedersen_hash::Personalization;
use lazy_static::lazy_static;
use paired::bls12_381::{Bls12, Fr, FrRepr};

use crate::error::Result;
use crate::fr32::bytes_into_frs;
use crate::settings;

lazy_static! {
    pub static ref JJ_PARAMS: JubjubBls12 = JubjubBls12::new_with_window_size(
        settings::SETTINGS
            .lock()
            .unwrap()
            .pedersen_hash_exp_window_size
    );
}

pub const PEDERSEN_BLOCK_SIZE: usize = 256;
pub const PEDERSEN_BLOCK_BYTES: usize = PEDERSEN_BLOCK_SIZE / 8;

pub fn pedersen(data: &[u8]) -> Fr {
    pedersen_bits(Bits::new(data))
}

pub fn pedersen_bits<'a, S: Iterator<Item = &'a [u8]>>(data: Bits<&'a [u8], S>) -> Fr {
    let digest = if cfg!(target_arch = "x86_64") {
        use fil_sapling_crypto::pedersen_hash::pedersen_hash_bls12_381_with_precomp;
        pedersen_hash_bls12_381_with_precomp::<_>(Personalization::None, data, &JJ_PARAMS)
    } else {
        use fil_sapling_crypto::pedersen_hash::pedersen_hash;
        pedersen_hash::<Bls12, _>(Personalization::None, data, &JJ_PARAMS)
    };

    digest.into_xy().0
}

/// Pedersen hashing for inputs that have length mulitple of the block size `256`. Based on pedersen hashes and a Merkle-Damgard construction.
pub fn pedersen_md_no_padding(data: &[u8]) -> Fr {
    pedersen_md_no_padding_bits(Bits::new(data))
}

pub fn pedersen_md_no_padding_bits<T: AsRef<[u8]>, S: Iterator<Item = T>>(
    mut data: Bits<T, S>,
) -> Fr {
    let mut cur = Vec::with_capacity(PEDERSEN_BLOCK_SIZE);

    // hash the first two blocks
    let first = pedersen_compression_bits(data.ref_take(2 * PEDERSEN_BLOCK_SIZE));
    first
        .write_le(&mut cur)
        .expect("failed to write result hash");

    while !data.is_done() {
        let r = data.ref_take(PEDERSEN_BLOCK_SIZE);
        let x = pedersen_compression_bits(Bits::new(&cur).chain(r));

        cur.truncate(0);
        x.write_le(&mut cur).expect("failed to write result hash");
    }

    let frs = bytes_into_frs(&cur).expect("pedersen must generate valid fr elements");
    assert_eq!(frs.len(), 1);
    frs[0]
}

fn pedersen_compression_bits<T>(bits: T) -> FrRepr
where
    T: IntoIterator<Item = bool>,
{
    let digest = if cfg!(target_arch = "x86_64") {
        use fil_sapling_crypto::pedersen_hash::pedersen_hash_bls12_381_with_precomp;
        pedersen_hash_bls12_381_with_precomp::<_>(Personalization::None, bits, &JJ_PARAMS)
    } else {
        use fil_sapling_crypto::pedersen_hash::pedersen_hash;
        pedersen_hash::<Bls12, _>(Personalization::None, bits, &JJ_PARAMS)
    };

    digest.into_xy().0.into()
}

#[derive(Debug, Clone)]
pub struct Hasher {
    curr: Option<[u8; 32]>,
}

impl Hasher {
    pub fn new(data: &[u8]) -> Result<Self> {
        ensure!(data.len() == 32, "Data must be 32 bytes.");
        let mut curr = [0u8; 32];
        curr.copy_from_slice(data);

        Ok(Hasher { curr: Some(curr) })
    }

    pub fn new_empty() -> Self {
        Hasher { curr: None }
    }

    pub fn update(&mut self, data: &[u8]) -> Result<()> {
        ensure!(data.len() == 32, "Data must be 32 bytes.");

        if let Some(ref mut curr) = self.curr {
            let source = [curr, data];
            let data = Bits::new_many(source.iter());
            let x = pedersen_compression_bits(data);
            x.write_le(std::io::Cursor::new(&mut curr[..]))
                .context("failed to write result")?;
        } else {
            let data = Bits::new(data);
            let x = pedersen_compression_bits(data);
            let mut curr = [0u8; 32];
            x.write_le(std::io::Cursor::new(&mut curr[..]))
                .context("failed to write result")?;
            self.curr = Some(curr);
        }

        Ok(())
    }

    pub fn finalize_bytes(self) -> [u8; 32] {
        let Hasher { curr } = self;
        curr.expect("missed init")
    }

    pub fn finalize(self) -> Result<Fr> {
        let frs = bytes_into_frs(&self.curr.expect("missed init"))
            .context("pedersen must generate valid fr elements")?;
        ensure!(frs.len() == 1, "There must be a single fr element.");
        Ok(frs[0])
    }
}

/// Creates an iterator over the byte slices in little endian format.
#[derive(Debug, Clone)]
pub struct Bits<K: AsRef<[u8]>, S: Iterator<Item = K>> {
    /// The individual parts that make up the data that is being iterated over.
    parts: ManyOrSingle<K, S>,
    /// How many bytes we are into the `current_part`
    position_byte: usize,
    /// How many bits we are into the `current_byte`.
    position_bit: u8,
    /// The current part we are reading from.
    current_part: Option<K>,
    /// Track the first iteration.
    first: bool,
    /// Are we done yet?
    done: bool,
}

/// Abstraction over either an iterator or a single element.
#[derive(Debug, Clone)]
enum ManyOrSingle<T, S = <Vec<T> as IntoIterator>::IntoIter>
where
    S: Iterator<Item = T>,
{
    Many(S),
    Single(Option<T>),
}

impl<T: AsRef<[u8]>> Bits<T, <Vec<T> as IntoIterator>::IntoIter> {
    pub fn new(parts: T) -> Self {
        Bits {
            parts: ManyOrSingle::<T, <Vec<T> as IntoIterator>::IntoIter>::Single(Some(parts)),
            position_byte: 0,
            position_bit: 0,
            current_part: None,
            first: true,
            done: false,
        }
    }
}

impl<T: AsRef<[u8]>, S: Iterator<Item = T>> Bits<T, S> {
    pub fn new_many(parts: S) -> Self {
        Bits {
            parts: ManyOrSingle::Many(parts),
            position_byte: 0,
            position_bit: 0,
            current_part: None,
            first: true,
            done: false,
        }
    }

    pub fn is_done(&self) -> bool {
        self.done
    }

    fn inc_part(&mut self) {
        self.current_part = match self.parts {
            ManyOrSingle::Many(ref mut parts) => {
                if self.first {
                    self.first = false;
                }
                parts.next()
            }
            ManyOrSingle::Single(ref mut part) => {
                if self.first {
                    self.first = false;
                    part.take()
                } else {
                    None
                }
            }
        }
    }

    /// Increments the inner positions by 1 bit.
    fn inc(&mut self) {
        if self.position_bit < 7 {
            self.position_bit += 1;
            return;
        }

        self.position_bit = 0;
        if let Some(ref part) = self.current_part {
            if self.position_byte + 1 < part.as_ref().len() {
                self.position_byte += 1;
                return;
            }
        }

        self.inc_part();
        self.position_byte = 0;
        self.done = self.current_part.is_none();
    }

    fn ref_take(&mut self, take: usize) -> BitsTake<'_, T, S> {
        BitsTake::new(self, take)
    }
}

#[derive(Debug)]
struct BitsTake<'a, T: AsRef<[u8]>, S: Iterator<Item = T>> {
    iter: &'a mut Bits<T, S>,
    take: usize,
}

impl<'a, T: AsRef<[u8]>, S: Iterator<Item = T>> BitsTake<'a, T, S> {
    pub fn new(iter: &'a mut Bits<T, S>, take: usize) -> Self {
        BitsTake { iter, take }
    }
}

impl<'a, T: AsRef<[u8]>, S: Iterator<Item = T> + std::iter::FusedIterator> std::iter::FusedIterator
    for BitsTake<'a, T, S>
{
}

impl<'a, T: AsRef<[u8]>, S: Iterator<Item = T>> Iterator for BitsTake<'a, T, S> {
    type Item = bool;

    fn next(&mut self) -> Option<Self::Item> {
        if self.take == 0 {
            return None;
        }

        self.take -= 1;
        self.iter.next()
    }
}

impl<T: AsRef<[u8]>, S: Iterator<Item = T> + std::iter::FusedIterator> std::iter::FusedIterator
    for Bits<T, S>
{
}

impl<T: AsRef<[u8]>, S: Iterator<Item = T>> Iterator for Bits<T, S> {
    type Item = bool;

    fn next(&mut self) -> Option<Self::Item> {
        if self.done {
            return None;
        }

        if self.first {
            // first time
            self.inc_part();
        }

        let byte = match self.current_part {
            Some(ref part) => part.as_ref()[self.position_byte],
            None => {
                self.done = true;
                return None;
            }
        };

        let res = (byte >> self.position_bit) & 1u8 == 1u8;
        self.inc();

        Some(res)
    }

    // optimized nth method so we can use it to skip forward easily
    fn nth(&mut self, n: usize) -> Option<Self::Item> {
        for _ in 0..n {
            // TODO: implement optimized inc for n bits.
            self.inc();
        }
        self.next()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::util::bytes_into_bits;
    use bitvec::{bitvec, order::Lsb0};
    use ff::Field;
    use paired::bls12_381::Fr;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_bit_vec_le() {
        let bytes = b"ABC";
        let bits = bytes_into_bits(bytes);

        let mut bits2 = bitvec![Lsb0, u8; 0; bits.len()];
        bits2.as_mut_slice()[0..bytes.len()].copy_from_slice(&bytes[..]);

        assert_eq!(bits, bits2.iter().copied().collect::<Vec<bool>>());
    }

    #[test]
    fn test_pedersen_compression() {
        let bytes = Bits::new(b"some bytes");

        let x = pedersen_compression_bits(bytes);
        let mut data = Vec::new();
        x.write_le(&mut data).unwrap();

        let expected = vec![
            237, 70, 41, 231, 39, 180, 131, 120, 36, 36, 119, 199, 200, 225, 153, 242, 106, 116,
            70, 9, 12, 249, 169, 84, 105, 38, 225, 115, 165, 188, 98, 25,
        ];
        assert_eq!(expected, data);
    }

    #[test]
    fn test_pedersen_md_no_padding() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 2..5 {
            let x: Vec<u8> = (0..i * 32).map(|_| rng.gen()).collect();
            let hashed = pedersen_md_no_padding(x.as_slice());
            assert_ne!(hashed, Fr::zero());
        }
    }

    #[test]
    fn test_bits_collect() {
        let bytes = b"hello";
        let bits = bytes_into_bits(bytes);

        let bits_iter = Bits::new(bytes);
        let bits_iter_collected: Vec<bool> = bits_iter.collect();

        assert_eq!(bits, bits_iter_collected);

        let bytes = b"hello world these are some bytes";
        let bits = bytes_into_bits(bytes);

        let parts: Vec<&[u8]> = vec![b"hello ", b"world", b" these are some bytes"];
        let bits_iter = Bits::new_many(parts.into_iter());

        let bits_iter_collected: Vec<bool> = bits_iter.collect();

        assert_eq!(bits, bits_iter_collected);
    }

    #[test]
    fn test_bits_take() {
        let bytes = b"hello world these are some bytes";
        let bits = bytes_into_bits(bytes);

        let parts: Vec<&[u8]> = vec![b"hello ", b"world", b" these are some bytes"];
        let mut bits_iter = Bits::new_many(parts.into_iter());

        let bits_collected: Vec<bool> = vec![
            bits_iter.ref_take(8).collect::<Vec<bool>>(),
            bits_iter.ref_take(8).collect::<Vec<bool>>(),
            bits_iter.ref_take(bits.len() - 16).collect::<Vec<bool>>(),
        ]
        .into_iter()
        .flatten()
        .collect();

        assert_eq!(bits, bits_collected);
    }

    #[test]
    fn test_pedersen_hasher_update() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 2..5 {
            let x: Vec<Vec<u8>> = (0..5)
                .map(|_| (0..32).map(|_| rng.gen()).collect())
                .collect();
            let flat: Vec<u8> = x.iter().flatten().copied().collect();
            let hashed = pedersen_md_no_padding(&flat);

            let mut hasher = Hasher::new(&x[0]).unwrap();
            for k in 1..5 {
                hasher.update(&x[k]).unwrap();
            }

            let hasher_final = hasher.finalize().unwrap();

            assert_eq!(hashed, hasher_final);
        }
    }
}

'''
'''--- storage-proofs/core/src/crypto/sloth.rs ---
use ff::Field;
use paired::bls12_381::Fr;

/// Sloth based encoding.
#[inline]
pub fn encode(key: &Fr, plaintext: &Fr) -> Fr {
    let mut ciphertext = *plaintext;

    ciphertext.add_assign(key); // c + k
    ciphertext
}

/// Sloth based decoding.
#[inline]
pub fn decode(key: &Fr, ciphertext: &Fr) -> Fr {
    let mut plaintext = *ciphertext;

    plaintext.sub_assign(key); // c - k

    plaintext
}

#[cfg(test)]
mod tests {
    use super::*;
    use ff::PrimeField;
    use paired::bls12_381::{Fr, FrRepr};
    use proptest::{prop_compose, proptest, proptest_helper};

    // the modulus from `bls12_381::Fr`
    // The definition of MODULUS and comment defining r come from paired/src/bls_12_381/fr.rs.
    // r = 52435875175126190479447740508185965837690552500527637822603658699938581184513
    const MODULUS: [u64; 4] = [
        0xffffffff00000001,
        0x53bda402fffe5bfe,
        0x3339d80809a1d805,
        0x73eda753299d7d48,
    ];

    #[test]
    fn sloth_bls_12() {
        let key = Fr::from_str("11111111").unwrap();
        let plaintext = Fr::from_str("123456789").unwrap();
        let ciphertext = encode(&key, &plaintext);
        let decrypted = decode(&key, &ciphertext);
        assert_eq!(plaintext, decrypted);
        assert_ne!(plaintext, ciphertext);
    }

    #[test]
    fn sloth_bls_12_fake() {
        let key = Fr::from_str("11111111").unwrap();
        let key_fake = Fr::from_str("11111112").unwrap();
        let plaintext = Fr::from_str("123456789").unwrap();
        let ciphertext = encode(&key, &plaintext);
        let decrypted = decode(&key_fake, &ciphertext);
        assert_ne!(plaintext, decrypted);
    }

    prop_compose! {
        fn arb_fr()(a in 0..MODULUS[0], b in 0..MODULUS[1], c in 0..MODULUS[2], d in 0..MODULUS[3]) -> Fr {
            Fr::from_repr(FrRepr([a, b, c, d])).unwrap()
        }
    }
    proptest! {
        #[test]
        fn sloth_bls_roundtrip(key in arb_fr(), plaintext in arb_fr()) {
            let ciphertext = encode(&key, &plaintext);
            assert_eq!(decode(&key, &ciphertext), plaintext);
        }
    }
}

'''
'''--- storage-proofs/core/src/crypto/xor.rs ---
use crate::error::Result;
use anyhow::ensure;

/// Encodes plaintext by elementwise xoring with the passed in key.
pub fn encode(key: &[u8], plaintext: &[u8]) -> Result<Vec<u8>> {
    xor(key, plaintext)
}

/// Decodes ciphertext by elementwise xoring with the passed in key.
pub fn decode(key: &[u8], ciphertext: &[u8]) -> Result<Vec<u8>> {
    xor(key, ciphertext)
}

fn xor(key: &[u8], input: &[u8]) -> Result<Vec<u8>> {
    let key_len = key.len();
    ensure!(key_len == 32, "Key must be 32 bytes.");

    Ok(input
        .iter()
        .enumerate()
        .map(|(i, byte)| byte ^ key[i % key_len])
        .collect())
}

#[cfg(test)]
mod tests {
    use super::*;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_xor() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 0..10 {
            let key: Vec<u8> = (0..32).map(|_| rng.gen()).collect();
            let plaintext: Vec<u8> = (0..(i + 1) * 32).map(|_| rng.gen()).collect();

            let ciphertext = encode(key.as_slice(), plaintext.as_slice()).unwrap();

            assert_ne!(
                plaintext, ciphertext,
                "plaintext and ciphertext are identical"
            );
            assert_eq!(plaintext.len(), ciphertext.len());

            let roundtrip = decode(key.as_slice(), ciphertext.as_slice()).unwrap();
            assert_eq!(plaintext, roundtrip, "failed to roundtrip");
        }
    }
}

'''
'''--- storage-proofs/core/src/data.rs ---
use std::path::PathBuf;

use anyhow::{ensure, Context, Result};
use log::info;

/// A wrapper around data either on disk or a slice in memory, that can be dropped and read back into memory,
/// to allow for better control of memory consumption.
#[derive(Debug)]
pub struct Data<'a> {
    raw: Option<RawData<'a>>,
    path: Option<PathBuf>,
    len: usize,
}

#[derive(Debug)]
enum RawData<'a> {
    Slice(&'a mut [u8]),
    Mmap(memmap::MmapMut),
}

use std::ops::{Deref, DerefMut};

impl<'a> Deref for RawData<'a> {
    type Target = [u8];

    fn deref(&self) -> &Self::Target {
        match self {
            RawData::Slice(ref raw) => raw,
            RawData::Mmap(ref raw) => raw,
        }
    }
}

impl<'a> DerefMut for RawData<'a> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        match self {
            RawData::Slice(ref mut raw) => raw,
            RawData::Mmap(ref mut raw) => raw,
        }
    }
}

impl<'a> From<&'a mut [u8]> for Data<'a> {
    fn from(raw: &'a mut [u8]) -> Self {
        let len = raw.len();
        Data {
            raw: Some(RawData::Slice(raw)),
            path: None,
            len,
        }
    }
}

impl<'a> From<(memmap::MmapMut, PathBuf)> for Data<'a> {
    fn from(raw: (memmap::MmapMut, PathBuf)) -> Self {
        let len = raw.0.len();
        Data {
            raw: Some(RawData::Mmap(raw.0)),
            path: Some(raw.1),
            len,
        }
    }
}

impl<'a> AsRef<[u8]> for Data<'a> {
    fn as_ref(&self) -> &[u8] {
        match self.raw {
            Some(ref raw) => raw,
            None => panic!("figure it out"),
        }
    }
}

impl<'a> AsMut<[u8]> for Data<'a> {
    fn as_mut(&mut self) -> &mut [u8] {
        match self.raw {
            Some(ref mut raw) => raw,
            None => panic!("figure it out"),
        }
    }
}

impl<'a> Data<'a> {
    pub fn from_path(path: PathBuf) -> Self {
        Data {
            raw: None,
            path: Some(path),
            len: 0,
        }
    }

    pub fn new(raw: &'a mut [u8], path: PathBuf) -> Self {
        let len = raw.len();

        Data {
            raw: Some(RawData::Slice(raw)),
            path: Some(path),
            len,
        }
    }

    pub fn len(&self) -> usize {
        self.len
    }

    pub fn is_empty(&self) -> bool {
        self.len == 0
    }

    /// Recover the data.
    pub fn ensure_data(&mut self) -> Result<()> {
        match self.raw {
            Some(..) => {}
            None => {
                ensure!(self.path.is_some(), "Missing path");
                let path = self.path.as_ref().unwrap();

                info!("restoring {}", path.display());

                let f_data = std::fs::OpenOptions::new()
                    .read(true)
                    .write(true)
                    .open(path)
                    .with_context(|| format!("could not open path={:?}", path))?;
                let data = unsafe {
                    memmap::MmapOptions::new()
                        .map_mut(&f_data)
                        .with_context(|| format!("could not mmap path={:?}", path))?
                };

                self.len = data.len();
                self.raw = Some(RawData::Mmap(data));
            }
        }

        Ok(())
    }

    /// Drops the actual data, if we can recover it.
    pub fn drop_data(&mut self) {
        if let Some(ref p) = self.path {
            info!("dropping data {}", p.display());
            self.raw.take();
        }
    }
}

'''
'''--- storage-proofs/core/src/drgraph.rs ---
use std::cmp::{max, min};
use std::marker::PhantomData;

use anyhow::ensure;
use generic_array::typenum;
use rand::{rngs::OsRng, Rng, SeedableRng};
use rand_chacha::ChaCha8Rng;
use sha2::{Digest, Sha256};

use crate::error::*;
use crate::fr32::bytes_into_fr_repr_safe;
use crate::hasher::{Hasher, PoseidonArity};
use crate::parameter_cache::ParameterSetMetadata;
use crate::util::{data_at_node_offset, NODE_SIZE};

pub const PARALLEL_MERKLE: bool = true;

/// The base degree used for all DRG graphs. One degree from this value is used to ensure that a
/// given node always has its immediate predecessor as a parent, thus ensuring unique topological
/// ordering of the graph nodes.
pub const BASE_DEGREE: usize = 6;

/// A depth robust graph.
pub trait Graph<H: Hasher>: ::std::fmt::Debug + Clone + PartialEq + Eq {
    type Key: std::fmt::Debug;

    /// Returns the expected size of all nodes in the graph.
    fn expected_size(&self) -> usize {
        self.size() * NODE_SIZE
    }

    /// Returns the merkle tree depth.
    fn merkle_tree_depth<U: 'static + PoseidonArity>(&self) -> u64 {
        graph_height::<U>(self.size()) as u64
    }

    /// Returns a sorted list of all parents of this node. The parents may be repeated.
    ///
    /// If a node doesn't have any parents, then this vector needs to return a vector where
    /// the first element is the requested node. This will be used as indicator for nodes
    /// without parents.
    ///
    /// The `parents` parameter is used to store the result. This is done fore performance
    /// reasons, so that the vector can be allocated outside this call.
    fn parents(&self, node: usize, parents: &mut [u32]) -> Result<()>;

    /// Returns the size of the graph (number of nodes).
    fn size(&self) -> usize;

    /// Returns the number of parents of each node in the graph.
    fn degree(&self) -> usize;

    fn new(
        nodes: usize,
        base_degree: usize,
        expansion_degree: usize,
        seed: [u8; 28],
    ) -> Result<Self>;
    fn seed(&self) -> [u8; 28];

    /// Creates the encoding key.
    /// The algorithm for that is `Sha256(id | encodedParentNode1 | encodedParentNode1 | ...)`.
    fn create_key(
        &self,
        id: &H::Domain,
        node: usize,
        parents: &[u32],
        parents_data: &[u8],
        exp_parents_data: Option<&[u8]>,
    ) -> Result<Self::Key>;
}

pub fn graph_height<U: typenum::Unsigned>(number_of_leafs: usize) -> usize {
    merkletree::merkle::get_merkle_tree_row_count(number_of_leafs, U::to_usize())
}

/// Bucket sampling algorithm.
#[derive(Clone, Debug, PartialEq, Eq, Copy)]
pub struct BucketGraph<H: Hasher> {
    nodes: usize,
    base_degree: usize,
    seed: [u8; 28],
    _h: PhantomData<H>,
}

impl<H: Hasher> ParameterSetMetadata for BucketGraph<H> {
    fn identifier(&self) -> String {
        // NOTE: Seed is not included because it does not influence parameter generation.
        format!(
            "drgraph::BucketGraph{{size: {}; degree: {}; hasher: {}}}",
            self.nodes,
            self.degree(),
            H::name(),
        )
    }

    fn sector_size(&self) -> u64 {
        (self.nodes * NODE_SIZE) as u64
    }
}

impl<H: Hasher> Graph<H> for BucketGraph<H> {
    type Key = H::Domain;

    fn create_key(
        &self,
        id: &H::Domain,
        node: usize,
        parents: &[u32],
        base_parents_data: &[u8],
        _exp_parents_data: Option<&[u8]>,
    ) -> Result<Self::Key> {
        let mut hasher = Sha256::new();
        hasher.input(AsRef::<[u8]>::as_ref(id));

        // The hash is about the parents, hence skip if a node doesn't have any parents
        if node != parents[0] as usize {
            for parent in parents.iter() {
                let offset = data_at_node_offset(*parent as usize);
                hasher.input(&base_parents_data[offset..offset + NODE_SIZE]);
            }
        }

        let hash = hasher.result();
        Ok(bytes_into_fr_repr_safe(hash.as_ref()).into())
    }

    #[inline]
    fn parents(&self, node: usize, parents: &mut [u32]) -> Result<()> {
        let m = self.degree();

        match node {
            // There are special cases for the first and second node: the first node self
            // references, the second node only references the first node.
            0 | 1 => {
                // Use the degree of the current graph (`m`) as `parents.len()` might be bigger than
                // that (that's the case for Stacked Graph).
                for parent in parents.iter_mut().take(m) {
                    *parent = 0;
                }
                Ok(())
            }
            _ => {
                // DRG node indexes are guaranteed to fit within a `u32`.
                let node = node as u32;

                let mut seed = [0u8; 32];
                seed[..28].copy_from_slice(&self.seed);
                seed[28..].copy_from_slice(&node.to_le_bytes());
                let mut rng = ChaCha8Rng::from_seed(seed);

                let m_prime = m - 1;
                // Large sector sizes require that metagraph node indexes are `u64`.
                let metagraph_node = node as u64 * m_prime as u64;
                let n_buckets = (metagraph_node as f64).log2().ceil() as u64;

                for parent in parents.iter_mut().take(m_prime) {
                    let bucket_index = (rng.gen::<u64>() % n_buckets) + 1;
                    let largest_distance_in_bucket = min(metagraph_node, 1 << bucket_index);
                    let smallest_distance_in_bucket = max(2, largest_distance_in_bucket >> 1);

                    // Add 1 becuase the number of distances in the bucket is inclusive.
                    let n_distances_in_bucket =
                        largest_distance_in_bucket - smallest_distance_in_bucket + 1;

                    let distance =
                        smallest_distance_in_bucket + (rng.gen::<u64>() % n_distances_in_bucket);

                    let metagraph_parent = metagraph_node - distance;

                    // Any metagraph node mapped onto the DRG can be safely cast back to `u32`.
                    let mapped_parent = (metagraph_parent / m_prime as u64) as u32;

                    *parent = if mapped_parent == node {
                        node - 1
                    } else {
                        mapped_parent
                    };
                }

                parents[m_prime] = node - 1;
                Ok(())
            }
        }
    }

    #[inline]
    fn size(&self) -> usize {
        self.nodes
    }

    /// Returns the degree of the graph.
    #[inline]
    fn degree(&self) -> usize {
        self.base_degree
    }

    fn seed(&self) -> [u8; 28] {
        self.seed
    }

    fn new(
        nodes: usize,
        base_degree: usize,
        expansion_degree: usize,
        seed: [u8; 28],
    ) -> Result<Self> {
        ensure!(expansion_degree == 0, "Expension degree must be zero.");

        // The number of metagraph nodes must be less than `2u64^54` as to not incur rounding errors
        // when casting metagraph node indexes from `u64` to `f64` during parent generation.
        let m_prime = base_degree - 1;
        let n_metagraph_nodes = nodes as u64 * m_prime as u64;
        ensure!(
            n_metagraph_nodes <= 1u64 << 54,
            "The number of metagraph nodes must be precisely castable to `f64`"
        );

        Ok(BucketGraph {
            nodes,
            base_degree,
            seed,
            _h: PhantomData,
        })
    }
}

pub fn new_seed() -> [u8; 28] {
    OsRng.gen()
}

#[cfg(test)]
mod tests {
    use super::*;

    use memmap::MmapMut;
    use memmap::MmapOptions;
    use merkletree::store::StoreConfig;

    use crate::drgraph::new_seed;
    use crate::hasher::{
        Blake2sHasher, PedersenHasher, PoseidonArity, PoseidonHasher, Sha256Hasher,
    };
    use crate::merkle::{
        create_base_merkle_tree, DiskStore, MerkleProofTrait, MerkleTreeTrait, MerkleTreeWrapper,
    };

    // Create and return an object of MmapMut backed by in-memory copy of data.
    pub fn mmap_from(data: &[u8]) -> MmapMut {
        let mut mm = MmapOptions::new()
            .len(data.len())
            .map_anon()
            .expect("Failed to create memory map");
        mm.copy_from_slice(data);
        mm
    }

    fn graph_bucket<H: Hasher>() {
        let degree = BASE_DEGREE;

        for size in vec![4, 16, 256, 2048] {
            let g = BucketGraph::<H>::new(size, degree, 0, new_seed()).unwrap();

            assert_eq!(g.size(), size, "wrong nodes count");

            let mut parents = vec![0; degree];
            g.parents(0, &mut parents).unwrap();
            assert_eq!(parents, vec![0; degree as usize]);
            parents = vec![0; degree];
            g.parents(1, &mut parents).unwrap();
            assert_eq!(parents, vec![0; degree as usize]);

            for i in 2..size {
                let mut pa1 = vec![0; degree];
                g.parents(i, &mut pa1).unwrap();
                let mut pa2 = vec![0; degree];
                g.parents(i, &mut pa2).unwrap();

                assert_eq!(pa1.len(), degree);
                assert_eq!(pa1, pa2, "different parents on the same node");

                let mut p1 = vec![0; degree];
                g.parents(i, &mut p1).unwrap();
                let mut p2 = vec![0; degree];
                g.parents(i, &mut p2).unwrap();

                for parent in p1 {
                    // TODO: fix me
                    assert_ne!(i, parent as usize, "self reference found");
                }
            }
        }
    }

    #[test]
    fn graph_bucket_sha256() {
        graph_bucket::<Sha256Hasher>();
    }

    #[test]
    fn graph_bucket_blake2s() {
        graph_bucket::<Blake2sHasher>();
    }

    #[test]
    fn graph_bucket_pedersen() {
        graph_bucket::<PedersenHasher>();
    }

    fn gen_proof<H: 'static + Hasher, U: 'static + PoseidonArity>(config: Option<StoreConfig>) {
        let leafs = 64;
        let g = BucketGraph::<H>::new(leafs, BASE_DEGREE, 0, new_seed()).unwrap();
        let data = vec![2u8; NODE_SIZE * leafs];

        let mmapped = &mmap_from(&data);
        let tree = create_base_merkle_tree::<
            MerkleTreeWrapper<H, DiskStore<H::Domain>, U, typenum::U0, typenum::U0>,
        >(config, g.size(), mmapped)
        .unwrap();
        let proof = tree.gen_proof(2).unwrap();

        assert!(proof.verify());
    }

    #[test]
    fn gen_proof_pedersen_binary() {
        gen_proof::<PedersenHasher, typenum::U2>(None);
    }

    #[test]
    fn gen_proof_poseidon_binary() {
        gen_proof::<PoseidonHasher, typenum::U2>(None);
    }

    #[test]
    fn gen_proof_sha256_binary() {
        gen_proof::<Sha256Hasher, typenum::U2>(None);
    }

    #[test]
    fn gen_proof_blake2s_binary() {
        gen_proof::<Blake2sHasher, typenum::U2>(None);
    }

    #[test]
    fn gen_proof_pedersen_quad() {
        gen_proof::<PedersenHasher, typenum::U4>(None);
    }

    #[test]
    fn gen_proof_poseidon_quad() {
        gen_proof::<PoseidonHasher, typenum::U4>(None);
    }

    #[test]
    fn gen_proof_sha256_quad() {
        gen_proof::<Sha256Hasher, typenum::U4>(None);
    }

    #[test]
    fn gen_proof_blake2s_quad() {
        gen_proof::<Blake2sHasher, typenum::U4>(None);
    }

    #[test]
    fn gen_proof_pedersen_oct() {
        gen_proof::<PedersenHasher, typenum::U8>(None);
    }

    #[test]
    fn gen_proof_poseidon_oct() {
        gen_proof::<PoseidonHasher, typenum::U8>(None);
    }
}

'''
'''--- storage-proofs/core/src/error.rs ---
use std::any::Any;

use bellperson::SynthesisError;

pub use anyhow::Result;

/// Custom error types
#[derive(Debug, thiserror::Error)]
pub enum Error {
    #[error("Bytes could not be converted to Fr")]
    BadFrBytes,
    #[error("Could not create PieceInclusionProof (probably bad piece commitment: comm_p)")]
    BadPieceCommitment,
    #[error("Out of bounds access {} > {}", _0, _1)]
    OutOfBounds(usize, usize),
    #[error("mismatch of data, node_size and nodes {} != {} * {}", _0, _1, _2)]
    InvalidMerkleTreeArgs(usize, usize, usize),
    #[error("{}", _0)]
    Synthesis(#[from] SynthesisError),
    #[error("{}", _0)]
    Io(#[from] ::std::io::Error),
    #[error("tree root and commitment do not match")]
    InvalidCommitment,
    #[error("malformed input")]
    MalformedInput,
    #[error("malformed merkle tree")]
    MalformedMerkleTree,
    #[error("invalid input size")]
    InvalidInputSize,
    #[error("merkle tree generation error: {}", _0)]
    MerkleTreeGenerationError(String),
    #[error("Cannot (yet) generate inclusion proof for unaligned piece.")]
    UnalignedPiece,
    #[error("{}", _0)]
    Serde(#[from] serde_json::error::Error),
    #[error("unclassified error: {}", _0)]
    Unclassified(String),
    #[error("Missing Private Input {0} for sector {1}")]
    MissingPrivateInput(&'static str, u64),
}

impl From<Box<dyn Any + Send>> for Error {
    fn from(inner: Box<dyn Any + Send>) -> Error {
        Error::Unclassified(format!("{:?}", dbg!(inner)))
    }
}

'''
'''--- storage-proofs/core/src/fr32.rs ---
use crate::error::*;

use anyhow::{ensure, Context};
use byteorder::{ByteOrder, LittleEndian, WriteBytesExt};
use ff::{PrimeField, PrimeFieldRepr};
use paired::bls12_381::{Fr, FrRepr};

// Contains 32 bytes whose little-endian value represents an Fr.
// Invariants:
// - Value MUST represent a valid Fr.
// - Length must be 32.
pub type Fr32 = [u8];

// Contains one or more 32-byte chunks whose little-endian values represent Frs.
// Invariants:
// - Value of each 32-byte chunks MUST represent valid Frs.
// - Total length must be a multiple of 32.
// That is to say: each 32-byte chunk taken alone must be a valid Fr32.
pub type Fr32Vec = Vec<u8>;

// Array whose little-endian value represents an Fr.
// Invariants:
// - Value MUST represent a valid Fr.
pub type Fr32Ary = [u8; 32];

// Takes a slice of bytes and returns an Fr if byte slice is exactly 32 bytes and does not overflow.
// Otherwise, returns a BadFrBytesError.
pub fn bytes_into_fr(bytes: &[u8]) -> Result<Fr> {
    ensure!(bytes.len() == 32, Error::BadFrBytes);

    let mut fr_repr = <<Fr as PrimeField>::Repr as Default>::default();
    fr_repr.read_le(bytes).context(Error::BadFrBytes)?;

    Fr::from_repr(fr_repr).map_err(|_| Error::BadFrBytes.into())
}

#[inline]
pub fn trim_bytes_to_fr_safe(r: &[u8]) -> Result<Vec<u8>> {
    ensure!(r.len() == 32, Error::BadFrBytes);
    let mut res = r[..32].to_vec();
    // strip last two bits, to ensure result is in Fr.
    res[31] &= 0b0011_1111;
    Ok(res)
}

#[inline]
pub fn bytes_into_fr_repr_safe(r: &[u8]) -> FrRepr {
    debug_assert!(r.len() == 32);

    let repr: [u64; 4] = [
        LittleEndian::read_u64(&r[0..8]),
        LittleEndian::read_u64(&r[8..16]),
        LittleEndian::read_u64(&r[16..24]),
        u64::from(r[31] & 0b0011_1111) << 56
            | u64::from(r[30]) << 48
            | u64::from(r[29]) << 40
            | u64::from(r[28]) << 32
            | u64::from(r[27]) << 24
            | u64::from(r[26]) << 16
            | u64::from(r[25]) << 8
            | u64::from(r[24]),
    ];

    FrRepr(repr)
}

// Takes an Fr and returns a vector of exactly 32 bytes guaranteed to contain a valid Fr.
pub fn fr_into_bytes(fr: &Fr) -> Fr32Vec {
    let mut out = Vec::with_capacity(32);
    fr.into_repr().write_le(&mut out).unwrap();
    out
}

// Takes a slice of bytes and returns a vector of Fr -- or an error if either bytes is not a multiple of 32 bytes
// or any 32-byte chunk overflows and does not contain a valid Fr.
pub fn bytes_into_frs(bytes: &[u8]) -> Result<Vec<Fr>> {
    bytes
        .chunks(32)
        .map(|ref chunk| bytes_into_fr(chunk))
        .collect()
}

// Takes a slice of Frs and returns a vector of bytes, guaranteed to have a size which is a multiple of 32,
// with every 32-byte chunk representing a valid Fr.
pub fn frs_into_bytes(frs: &[Fr]) -> Fr32Vec {
    frs.iter().flat_map(|fr| fr_into_bytes(fr)).collect()
}

// Takes a u32 and returns an Fr.
pub fn u32_into_fr(n: u32) -> Fr {
    let mut buf: Fr32Vec = vec![0u8; 32];
    let mut w = &mut buf[0..4];
    w.write_u32::<LittleEndian>(n).unwrap();

    bytes_into_fr(&buf).expect("should never fail since u32 is in the field")
}

// Takes a u64 and returns an Fr.
pub fn u64_into_fr(n: u64) -> Fr {
    let mut buf: Fr32Vec = vec![0u8; 32];
    let mut w = &mut buf[0..8];
    w.write_u64::<LittleEndian>(n).unwrap();

    bytes_into_fr(&buf).expect("should never fail since u64 is in the field")
}

#[cfg(test)]
mod tests {
    use super::*;

    fn bytes_fr_test(bytes: Fr32Ary, expect_success: bool) {
        let mut b = &bytes[..];
        let fr_result = bytes_into_fr(&mut b);
        if expect_success {
            let f = fr_result.expect("Failed to convert bytes to `Fr`");
            let b2 = fr_into_bytes(&f);

            assert_eq!(bytes.to_vec(), b2);
        } else {
            assert!(fr_result.is_err(), "expected a decoding error")
        }
    }
    #[test]
    fn test_bytes_into_fr_into_bytes() {
        bytes_fr_test(
            [
                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,
                23, 24, 25, 26, 27, 28, 29, 30, 31,
            ],
            true,
        );
        bytes_fr_test(
            // Some bytes fail because they are not in the field.
            [
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 115,
            ],
            false,
        );
        bytes_fr_test(
            // This is okay.
            [
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 114,
            ],
            true,
        );
        bytes_fr_test(
            // So is this.
            [
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 236, 115,
            ],
            true,
        );
        bytes_fr_test(
            // But not this.
            [
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
                255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 237, 115,
            ],
            false,
        );
    }

    fn bytes_into_frs_into_bytes_test(bytes: &Fr32) {
        let mut bytes = bytes.clone();
        let frs = bytes_into_frs(&mut bytes).expect("Failed to convert bytes into a `Vec<Fr>`");
        assert!(frs.len() == 3);
        let bytes_back = frs_into_bytes(&frs);
        assert!(bytes.to_vec() == bytes_back);
    }

    #[test]
    fn test_bytes_into_frs_into_bytes() {
        let bytes = b"012345678901234567890123456789--012345678901234567890123456789--012345678901234567890123456789--";
        bytes_into_frs_into_bytes_test(&bytes[..]);

        let _short_bytes = b"012345678901234567890123456789--01234567890123456789";
        // This will panic because _short_bytes is not a multiple of 32 bytes.
        // bytes_into_frs_into_bytes_test(&_short_bytes[..]);
    }
}

'''
'''--- storage-proofs/core/src/gadgets/bench/mod.rs ---
use std::marker::PhantomData;

use bellperson::{ConstraintSystem, Index, LinearCombination, SynthesisError, Variable};
use paired::Engine;

#[derive(Debug)]
pub struct BenchCS<E: Engine> {
    inputs: usize,
    aux: usize,
    a: usize,
    b: usize,
    c: usize,
    _e: PhantomData<E>,
}

impl<E: Engine> BenchCS<E> {
    pub fn new() -> Self {
        BenchCS::default()
    }

    pub fn num_constraints(&self) -> usize {
        self.a
    }

    pub fn num_inputs(&self) -> usize {
        self.inputs
    }
}

impl<E: Engine> Default for BenchCS<E> {
    fn default() -> Self {
        BenchCS {
            inputs: 1,
            aux: 0,
            a: 0,
            b: 0,
            c: 0,
            _e: PhantomData,
        }
    }
}

impl<E: Engine> ConstraintSystem<E> for BenchCS<E> {
    type Root = Self;

    fn alloc<F, A, AR>(&mut self, _: A, _f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        // don't invoke f, we just count
        self.aux += 1;

        Ok(Variable::new_unchecked(Index::Aux(self.aux - 1)))
    }

    fn alloc_input<F, A, AR>(&mut self, _: A, _f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        // don't invoke f, we just count
        self.inputs += 1;

        Ok(Variable::new_unchecked(Index::Input(self.inputs - 1)))
    }

    fn enforce<A, AR, LA, LB, LC>(&mut self, _: A, _a: LA, _b: LB, _c: LC)
    where
        A: FnOnce() -> AR,
        AR: Into<String>,
        LA: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LB: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LC: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
    {
        self.a += 1;
        self.b += 1;
        self.c += 1;
    }

    fn push_namespace<NR, N>(&mut self, _: N)
    where
        NR: Into<String>,
        N: FnOnce() -> NR,
    {
    }

    fn pop_namespace(&mut self) {}

    fn get_root(&mut self) -> &mut Self::Root {
        self
    }
}

'''
'''--- storage-proofs/core/src/gadgets/constraint.rs ---
use bellperson::{gadgets::num, ConstraintSystem, SynthesisError};
use ff::Field;
use paired::Engine;

/// Adds a constraint to CS, enforcing an equality relationship between the allocated numbers a and b.
///
/// a == b
pub fn equal<E: Engine, A, AR, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    annotation: A,
    a: &num::AllocatedNum<E>,
    b: &num::AllocatedNum<E>,
) where
    A: FnOnce() -> AR,
    AR: Into<String>,
{
    // a * 1 = b
    cs.enforce(
        annotation,
        |lc| lc + a.get_variable(),
        |lc| lc + CS::one(),
        |lc| lc + b.get_variable(),
    );
}

/// Adds a constraint to CS, enforcing a add relationship between the allocated numbers a, b, and sum.
///
/// a + b = sum
pub fn sum<E: Engine, A, AR, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    annotation: A,
    a: &num::AllocatedNum<E>,
    b: &num::AllocatedNum<E>,
    sum: &num::AllocatedNum<E>,
) where
    A: FnOnce() -> AR,
    AR: Into<String>,
{
    // (a + b) * 1 = sum
    cs.enforce(
        annotation,
        |lc| lc + a.get_variable() + b.get_variable(),
        |lc| lc + CS::one(),
        |lc| lc + sum.get_variable(),
    );
}

pub fn add<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    a: &num::AllocatedNum<E>,
    b: &num::AllocatedNum<E>,
) -> Result<num::AllocatedNum<E>, SynthesisError> {
    let res = num::AllocatedNum::alloc(cs.namespace(|| "add_num"), || {
        let mut tmp = a
            .get_value()
            .ok_or_else(|| SynthesisError::AssignmentMissing)?;
        tmp.add_assign(
            &b.get_value()
                .ok_or_else(|| SynthesisError::AssignmentMissing)?,
        );

        Ok(tmp)
    })?;

    // a + b = res
    sum(&mut cs, || "sum constraint", &a, &b, &res);

    Ok(res)
}

pub fn sub<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    a: &num::AllocatedNum<E>,
    b: &num::AllocatedNum<E>,
) -> Result<num::AllocatedNum<E>, SynthesisError> {
    let res = num::AllocatedNum::alloc(cs.namespace(|| "sub_num"), || {
        let mut tmp = a
            .get_value()
            .ok_or_else(|| SynthesisError::AssignmentMissing)?;
        tmp.sub_assign(
            &b.get_value()
                .ok_or_else(|| SynthesisError::AssignmentMissing)?,
        );

        Ok(tmp)
    })?;

    // a - b = res
    difference(&mut cs, || "subtraction constraint", &a, &b, &res);

    Ok(res)
}

/// Adds a constraint to CS, enforcing a difference relationship between the allocated numbers a, b, and difference.
///
/// a - b = difference
pub fn difference<E: Engine, A, AR, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    annotation: A,
    a: &num::AllocatedNum<E>,
    b: &num::AllocatedNum<E>,
    difference: &num::AllocatedNum<E>,
) where
    A: FnOnce() -> AR,
    AR: Into<String>,
{
    //    difference = a-b
    // => difference + b = a
    // => (difference + b) * 1 = a
    cs.enforce(
        annotation,
        |lc| lc + difference.get_variable() + b.get_variable(),
        |lc| lc + CS::one(),
        |lc| lc + a.get_variable(),
    );
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::gadgets::TestConstraintSystem;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    #[test]
    fn add_constraint() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..100 {
            let mut cs = TestConstraintSystem::<Bls12>::new();

            let a = num::AllocatedNum::alloc(cs.namespace(|| "a"), || Ok(Fr::random(rng))).unwrap();
            let b = num::AllocatedNum::alloc(cs.namespace(|| "b"), || Ok(Fr::random(rng))).unwrap();

            let res = add(cs.namespace(|| "a+b"), &a, &b).expect("add failed");

            let mut tmp = a.get_value().unwrap().clone();
            tmp.add_assign(&b.get_value().unwrap());

            assert_eq!(res.get_value().unwrap(), tmp);
            assert!(cs.is_satisfied());
        }
    }

    #[test]
    fn sub_constraint() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..100 {
            let mut cs = TestConstraintSystem::<Bls12>::new();

            let a = num::AllocatedNum::alloc(cs.namespace(|| "a"), || Ok(Fr::random(rng))).unwrap();
            let b = num::AllocatedNum::alloc(cs.namespace(|| "b"), || Ok(Fr::random(rng))).unwrap();

            let res = sub(cs.namespace(|| "a-b"), &a, &b).expect("subtraction failed");

            let mut tmp = a.get_value().unwrap().clone();
            tmp.sub_assign(&b.get_value().unwrap());

            assert_eq!(res.get_value().unwrap(), tmp);
            assert!(cs.is_satisfied());
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/encode.rs ---
use bellperson::gadgets::num;
use bellperson::{ConstraintSystem, SynthesisError};
use paired::Engine;

use crate::gadgets::constraint;

pub fn encode<E, CS>(
    mut cs: CS,
    key: &num::AllocatedNum<E>,
    value: &num::AllocatedNum<E>,
) -> Result<num::AllocatedNum<E>, SynthesisError>
where
    E: Engine,
    CS: ConstraintSystem<E>,
{
    constraint::add(cs.namespace(|| "encode_add"), key, value)
}

pub fn decode<E, CS>(
    mut cs: CS,
    key: &num::AllocatedNum<E>,
    value: &num::AllocatedNum<E>,
) -> Result<num::AllocatedNum<E>, SynthesisError>
where
    E: Engine,
    CS: ConstraintSystem<E>,
{
    constraint::sub(cs.namespace(|| "decode_sub"), value, key)
}

'''
'''--- storage-proofs/core/src/gadgets/insertion.rs ---
//! Insertion Permutation
//!
//! Insert an `AllocatedNum` into a sequence of `AllocatedNums` at an arbitrary position.
//! This can be thought of as a generalization of `AllocatedNum::conditionally_reverse` and reduces to it in the binary case.

use bellperson::gadgets::boolean::{AllocatedBit, Boolean};
use bellperson::gadgets::num::AllocatedNum;
use bellperson::{ConstraintSystem, SynthesisError};
use ff::Field;
use paired::Engine;

/// Insert `element` after the nth 1-indexed element of `elements`, where `path_bits` represents n, least-significant bit first.
/// The returned result contains a new vector of `AllocatedNum`s with `element` inserted, and constraints are enforced.
/// `elements.len() + 1` must be a power of two.
pub fn insert<E: Engine, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    element: &AllocatedNum<E>,
    bits: &[Boolean],
    elements: &[AllocatedNum<E>],
) -> Result<Vec<AllocatedNum<E>>, SynthesisError> {
    let size = elements.len() + 1;
    assert_eq!(1 << bits.len(), size);

    // For the sizes we know we need, we can take advantage of redundancy in the candidate selection at each position.
    // This allows us to accomplish insertion with fewer constraints, if we hand-optimize.
    // We don't need a special case for size 2 because the general algorithm
    // collapses to `conditionally_reverse` when size = 2.
    //
    // If no special cases have been hand-coded, use the general algorithm.
    // This costs size * (size - 1) constraints.
    //
    // Future work: In theory, we could compile arbitrary lookup tables to minimize constraints and avoid
    // the most general case except when actually required — which it never is for simple insertion.
    if size == 2 {
        return insert_2(cs, element, bits, elements);
    } else if size == 4 {
        return insert_4(cs, element, bits, elements);
    } else if size == 8 {
        return insert_8(cs, element, bits, elements);
    };

    // Running example choices, represent inserting x into [1, 2, 3].

    // An indexed sequence of correct results, one of which (the indexed one) will be selected.
    let mut potential_results = Vec::new();
    for index in 0..size {
        // These are the results when bits corresponds to index.
        //
        // index | result
        //-------+-------
        // 0     | x 1 2 3
        // 1     | 1 x 2 3
        // 2     | 1 2 x 3
        // 3     | 1 2 3 x
        let mut result = Vec::new();
        (0..index).for_each(|i| result.push(elements[i].clone()));
        result.push(element.clone());
        (index..elements.len()).for_each(|i| result.push(elements[i].clone()));

        potential_results.push(result);
    }

    let mut result = Vec::new();
    for pos in 0..size {
        // These are the choices needed such that for each position in the selected result,
        // the value is column-for-pos[index].
        //
        // This table is constructed by reading columns from the index-result table above.
        // Reading columns from this table yields the result table.

        // pos   column
        // 0     x 1 1 1
        // 1     1 x 2 2
        // 2     2 2 x 3
        // 3     3 3 3 x
        let choices = (0..size)
            .map(|index| potential_results[index][pos].clone())
            .collect::<Vec<_>>();

        result.push(select(
            cs.namespace(|| format!("choice at {}", pos)),
            &choices,
            bits,
        )?);
    }

    Ok(result)
}

pub fn insert_2<E: Engine, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    element: &AllocatedNum<E>,
    bits: &[Boolean],
    elements: &[AllocatedNum<E>],
) -> Result<Vec<AllocatedNum<E>>, SynthesisError> {
    assert_eq!(elements.len() + 1, 2);
    assert_eq!(bits.len(), 1);

    Ok(vec![
        pick(
            cs.namespace(|| "binary insert 0"),
            &bits[0],
            &elements[0],
            &element,
        )?,
        pick(
            cs.namespace(|| "binary insert 1"),
            &bits[0],
            &element,
            &elements[0],
        )?,
    ])
}

pub fn insert_4<E: Engine, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    element: &AllocatedNum<E>,
    bits: &[Boolean],
    elements: &[AllocatedNum<E>],
) -> Result<Vec<AllocatedNum<E>>, SynthesisError> {
    assert_eq!(elements.len() + 1, 4);
    assert_eq!(bits.len(), 2);

    /*
    To insert A into [b, c, d] at position n of bits, represented by booleans [b0, b1, b2].
    n [b0, b1] pos 0 1 2 3
    0 [0, 0]       A b c d
    1 [1, 0]       b A c d
    2 [0, 1]       b c A d
    3 [1, 1]       b c d A

    A = element
    b = elements[0]
    c = elements[1]
    d = elements[2]
     */
    let (b0, b1) = (&bits[0], &bits[1]);
    let (a, b, c, d) = (&element, &elements[0], &elements[1], &elements[2]);

    /// Define witness macro to allow legible definition of positional constraints.
    /// See example expansions in comment to first usages below.
    macro_rules! witness {
        ( $var:ident <== if $cond:ident { $a:expr } else { $b:expr }) => {
            let $var = pick(cs.namespace(|| stringify!($var)), $cond, $a, $b)?;
        };
    }

    // Witness naming convention:
    // `p0_x0` means "Output position 0 when b0 is unknown (x) and b1 is 0."

    // Declaration:
    witness!(p0_x0 <== if b0 { b } else { a });
    witness!(p0 <== if b1 { b } else { &p0_x0 });
    // Expansion:
    // let p0_x0 = pick(cs.namespace(|| "p0_x0"), b0, b, a)?;
    // let p0 = pick(cs.namespace(|| "p0"), b1, b, &p0_x0)?;

    witness!(p1_x0 <== if b0 { a } else { b });
    witness!(p1 <== if b1 { c } else { &p1_x0 });

    witness!(p2_x1 <== if b0 { d } else { a });
    witness!(p2 <== if b1 { &p2_x1 } else {c });

    witness!(p3_x1 <== if b0 { a } else { d });
    witness!(p3 <== if b1 { &p3_x1 } else { d });

    Ok(vec![p0, p1, p2, p3])
}

pub fn insert_8<E: Engine, CS: ConstraintSystem<E>>(
    cs: &mut CS,
    element: &AllocatedNum<E>,
    bits: &[Boolean],
    elements: &[AllocatedNum<E>],
) -> Result<Vec<AllocatedNum<E>>, SynthesisError> {
    assert_eq!(elements.len() + 1, 8);
    assert_eq!(bits.len(), 3);
    /*
    To insert A into [b, c, d, e, f, g, h] at position n of bits, represented by booleans [b0, b1, b2].
    n [b0, b1, b2] pos 0 1 2 3 4 5 6 7
    0 [0, 0, 0]        A b c d e f g h
    1 [1, 0, 0]        b A c d e f g h
    2 [0, 1, 0]        b c A d e f g h
    3 [1, 1, 0]        b c d A e f g h
    4 [0, 0, 1]        b c d e A f g h
    5 [1, 0, 1]        b c d e f A g h
    6 [0, 1, 1]        b c d e f g A h
    7 [1, 1, 1]        b c d e f g h A

    A = element
    b = elements[0]
    c = elements[1]
    d = elements[2]
    e = elements[3]
    f = elements[4]
    g = elements[5]
    h = elements[6]
     */

    let (b0, b1, b2) = (&bits[0], &bits[1], &bits[2]);
    let (a, b, c, d, e, f, g, h) = (
        &element,
        &elements[0],
        &elements[1],
        &elements[2],
        &elements[3],
        &elements[4],
        &elements[5],
        &elements[6],
    );

    // true if booleans b0 and b1 are both false: `(not b0) and (not b1)`
    // (1 - b0) * (1 - b1) = 1
    let b0_nor_b1 = match (b0, b1) {
        (Boolean::Is(ref b0), Boolean::Is(ref b1)) => {
            Boolean::Is(AllocatedBit::nor(cs.namespace(|| "b0 nor b1"), b0, b1)?)
        }
        _ => panic!("bits must be allocated and unnegated"),
    };

    // true if booleans b0 and b1 are both true: `b0 and b1`
    // b0 * b1 = 1
    let b0_and_b1 = match (&bits[0], &bits[1]) {
        (Boolean::Is(ref b0), Boolean::Is(ref b1)) => {
            Boolean::Is(AllocatedBit::and(cs.namespace(|| "b0 and b1"), b0, b1)?)
        }
        _ => panic!("bits must be allocated and unnegated"),
    };

    /// Define witness macro to allow legible definition of positional constraints.
    /// See example expansions in comment to first usages below.
    macro_rules! witness {
        ( $var:ident <== if $cond:ident { $a:expr } else { $b:expr }) => {
            let $var = pick(cs.namespace(|| stringify!($var)), $cond, $a, $b)?;
        };

        // Match condition terms which are explict syntactic references.
        ( $var:ident <== if &$cond:ident { $a:expr } else { $b:expr }) => {
            let $var = pick(cs.namespace(|| stringify!($var)), &$cond, $a, $b)?;
        };
    }

    // Declaration:
    witness!(p0_xx0 <== if &b0_nor_b1 { a } else { b });
    witness!(p0 <== if b2 { b } else { &p0_xx0 });
    // Expansion:
    // let p0_xx0 = pick(cs.namespace(|| "p0_xx0"), &b0_nor_b1, a, b)?;
    // let p0 = pick(cs.namespace(|| "p0"), b2, b, &p0_xx0)?;

    witness!(p1_x00 <== if b0 { a } else { b });
    witness!(p1_xx0 <== if b1 { c } else { &p1_x00 });
    witness!(p1 <== if b2 { c } else { &p1_xx0 });

    witness!(p2_x10 <== if b0 { d } else { a });
    witness!(p2_xx0 <== if b1 { &p2_x10 } else { c });
    witness!(p2 <== if b2 { d } else { &p2_xx0 });

    witness!(p3_xx0 <== if &b0_and_b1 { a } else { d });
    witness!(p3 <== if b2 { e } else { &p3_xx0 });

    witness!(p4_xx1 <== if &b0_nor_b1 { a } else { f });
    witness!(p4 <== if b2 { &p4_xx1 } else { e });

    witness!(p5_x01 <== if b0 { a } else { f });
    witness!(p5_xx1 <== if b1 { g } else { &p5_x01 });
    witness!(p5 <== if b2 { &p5_xx1 } else { f });

    witness!(p6_x11 <== if b0 { h } else { a });
    witness!(p6_xx1 <== if b1 { &p6_x11 } else { g });
    witness!(p6 <== if b2 { &p6_xx1 } else { g });

    witness!(p7_xx1 <== if &b0_and_b1 { a } else { h });
    witness!(p7 <== if b2 { &p7_xx1 } else { h });

    Ok(vec![p0, p1, p2, p3, p4, p5, p6, p7])
}

/// Select the nth element of `from`, where `path_bits` represents n, least-significant bit first.
/// The returned result contains the selected element, and constraints are enforced.
/// `from.len()` must be a power of two.
pub fn select<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    from: &[AllocatedNum<E>],
    path_bits: &[Boolean],
) -> Result<AllocatedNum<E>, SynthesisError> {
    let pathlen = path_bits.len();
    assert_eq!(1 << pathlen, from.len());

    let mut state = Vec::new();
    for elt in from {
        state.push(elt.clone())
    }
    let mut half_size = from.len() / 2;

    // We reverse the path bits because the contained algorithm consumes most significant bit first.
    for (i, bit) in path_bits.iter().rev().enumerate() {
        let mut new_state = Vec::new();
        for j in 0..half_size {
            new_state.push(pick(
                cs.namespace(|| format!("pick {}, {}", i, j)),
                bit,
                &state[half_size + j],
                &state[j],
            )?);
        }
        state = new_state;
        half_size /= 2;
    }

    Ok(state.remove(0))
}

/// Takes two allocated numbers (`a`, `b`) and returns `a` if the condition is true, and `b` otherwise.
pub fn pick<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    condition: &Boolean,
    a: &AllocatedNum<E>,
    b: &AllocatedNum<E>,
) -> Result<AllocatedNum<E>, SynthesisError>
where
    CS: ConstraintSystem<E>,
{
    let c = AllocatedNum::alloc(cs.namespace(|| "pick result"), || {
        if condition
            .get_value()
            .ok_or(SynthesisError::AssignmentMissing)?
        {
            Ok(a.get_value().ok_or(SynthesisError::AssignmentMissing)?)
        } else {
            Ok(b.get_value().ok_or(SynthesisError::AssignmentMissing)?)
        }
    })?;

    // Constrain (b - a) * condition = (b - c), ensuring c = a iff
    // condition is true, otherwise c = b.
    cs.enforce(
        || "pick",
        |lc| lc + b.get_variable() - a.get_variable(),
        |_| condition.lc(CS::one(), E::Fr::one()),
        |lc| lc + b.get_variable() - c.get_variable(),
    );

    Ok(c)
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::gadgets::TestConstraintSystem;
    use bellperson::gadgets::boolean::AllocatedBit;
    use ff::Field;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_select() {
        for log_size in 1..5 {
            let size = 1 << log_size;
            for index in 0..size {
                // Initialize rng in loop to simplify debugging with consistent elements.
                let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
                let mut cs = TestConstraintSystem::new();

                let elements: Vec<_> = (0..size)
                    .map(|i| {
                        AllocatedNum::<Bls12>::alloc(
                            &mut cs.namespace(|| format!("element {}", i)),
                            || {
                                let elt = <Fr as Field>::random(rng);
                                Ok(elt)
                            },
                        )
                        .unwrap()
                    })
                    .collect();

                let path_bits = (0..log_size)
                    .map(|i| {
                        <Boolean as std::convert::From<AllocatedBit>>::from(
                            AllocatedBit::alloc(cs.namespace(|| format!("index bit {}", i)), {
                                let bit = ((index >> i) & 1) == 1;
                                Some(bit)
                            })
                            .unwrap(),
                        )
                    })
                    .collect::<Vec<_>>();

                let test_constraints = cs.num_constraints();
                assert_eq!(log_size, test_constraints);

                let selected = select(cs.namespace(|| "select"), &elements, &path_bits).unwrap();

                assert!(cs.is_satisfied());
                assert_eq!(elements[index].get_value(), selected.get_value());

                // One constraint per non-leaf node of a binary tree with `size` leaves.
                let expected_constraints = size - 1;

                let actual_constraints = cs.num_constraints() - test_constraints;
                assert_eq!(expected_constraints, actual_constraints);
            }
        }
    }

    #[test]
    fn test_insert() {
        for log_size in 1..=4 {
            let size = 1 << log_size;
            for index in 0..size {
                // Initialize rng in loop to simplify debugging with consistent elements.
                let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
                let mut cs = TestConstraintSystem::new();

                let elements: Vec<_> = (0..size - 1)
                    .map(|i| {
                        AllocatedNum::<Bls12>::alloc(
                            &mut cs.namespace(|| format!("element {}", i)),
                            || {
                                let elt = <Fr as Field>::random(rng);
                                Ok(elt)
                            },
                        )
                        .unwrap()
                    })
                    .collect();

                let to_insert =
                    AllocatedNum::<Bls12>::alloc(&mut cs.namespace(|| "insert"), || {
                        let elt_to_insert = <Fr as Field>::random(rng);
                        Ok(elt_to_insert)
                    })
                    .unwrap();

                let index_bits = (0..log_size)
                    .map(|i| {
                        <Boolean as std::convert::From<AllocatedBit>>::from(
                            AllocatedBit::alloc(cs.namespace(|| format!("index bit {}", i)), {
                                let bit = ((index >> i) & 1) == 1;
                                Some(bit)
                            })
                            .unwrap(),
                        )
                    })
                    .collect::<Vec<_>>();

                let test_constraints = cs.num_constraints();
                assert_eq!(log_size, test_constraints);

                let mut inserted = insert(
                    &mut cs,
                    &to_insert.clone(),
                    index_bits.as_slice(),
                    &elements.as_slice(),
                )
                .unwrap();

                assert!(cs.is_satisfied());

                let extracted = inserted.remove(index);
                assert_eq!(to_insert.get_value(), extracted.get_value(),);

                for i in 0..size - 1 {
                    let a = elements[i].get_value();
                    let b = inserted[i].get_value();
                    assert_eq!(a, b)
                }

                // One selection for each element of the result.
                let expected_constraints = match size {
                    8 => 22, // unoptimized, would be 56
                    4 => 8,  // unoptimized, would be 12
                    _ => size * (size - 1),
                };

                let actual_constraints = cs.num_constraints() - test_constraints;
                assert_eq!(expected_constraints, actual_constraints);
            }
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/metric/mod.rs ---
use bellperson::{ConstraintSystem, Index, LinearCombination, SynthesisError, Variable};
use paired::Engine;
use std::cmp::Ordering;
use std::collections::HashMap;

#[derive(Clone, Copy)]
struct OrderedVariable(Variable);

#[derive(Debug)]
enum NamedObject {
    Constraint(usize),
    Var(Variable),
    Namespace,
}

impl Eq for OrderedVariable {}
impl PartialEq for OrderedVariable {
    fn eq(&self, other: &OrderedVariable) -> bool {
        match (self.0.get_unchecked(), other.0.get_unchecked()) {
            (Index::Input(ref a), Index::Input(ref b)) => a == b,
            (Index::Aux(ref a), Index::Aux(ref b)) => a == b,
            _ => false,
        }
    }
}
impl PartialOrd for OrderedVariable {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}
impl Ord for OrderedVariable {
    fn cmp(&self, other: &Self) -> Ordering {
        match (self.0.get_unchecked(), other.0.get_unchecked()) {
            (Index::Input(ref a), Index::Input(ref b)) => a.cmp(b),
            (Index::Aux(ref a), Index::Aux(ref b)) => a.cmp(b),
            (Index::Input(_), Index::Aux(_)) => Ordering::Less,
            (Index::Aux(_), Index::Input(_)) => Ordering::Greater,
        }
    }
}

pub struct MetricCS<E: Engine> {
    named_objects: HashMap<String, NamedObject>,
    current_namespace: Vec<String>,
    #[allow(clippy::type_complexity)]
    constraints: Vec<(
        LinearCombination<E>,
        LinearCombination<E>,
        LinearCombination<E>,
        String,
    )>,
    inputs: Vec<String>,
    aux: Vec<String>,
}

impl<E: Engine> MetricCS<E> {
    pub fn new() -> Self {
        MetricCS::default()
    }

    pub fn num_constraints(&self) -> usize {
        self.constraints.len()
    }

    pub fn num_inputs(&self) -> usize {
        self.inputs.len()
    }

    pub fn pretty_print_list(&self) -> Vec<String> {
        let mut result = Vec::new();

        for input in &self.inputs {
            result.push(format!("INPUT {}", input));
        }
        for aux in &self.aux {
            result.push(format!("AUX {}", aux));
        }

        for &(ref _a, ref _b, ref _c, ref name) in &self.constraints {
            result.push(name.to_string());
        }

        result
    }

    pub fn pretty_print(&self) -> String {
        let res = self.pretty_print_list();

        res.join("\n")
    }

    fn set_named_obj(&mut self, path: String, to: NamedObject) {
        if self.named_objects.contains_key(&path) {
            panic!("tried to create object at existing path: {}", path);
        }

        self.named_objects.insert(path, to);
    }
}

impl<E: Engine> Default for MetricCS<E> {
    fn default() -> Self {
        let mut map = HashMap::new();
        map.insert("ONE".into(), NamedObject::Var(MetricCS::<E>::one()));
        MetricCS {
            named_objects: map,
            current_namespace: vec![],
            constraints: vec![],
            inputs: vec![String::from("ONE")],
            aux: vec![],
        }
    }
}

impl<E: Engine> ConstraintSystem<E> for MetricCS<E> {
    type Root = Self;

    fn alloc<F, A, AR>(&mut self, annotation: A, _f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        let path = compute_path(&self.current_namespace, &annotation().into());
        self.aux.push(path);

        Ok(Variable::new_unchecked(Index::Aux(self.aux.len() - 1)))
    }

    fn alloc_input<F, A, AR>(&mut self, annotation: A, _f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        let path = compute_path(&self.current_namespace, &annotation().into());
        self.inputs.push(path);

        Ok(Variable::new_unchecked(Index::Input(self.inputs.len() - 1)))
    }

    fn enforce<A, AR, LA, LB, LC>(&mut self, annotation: A, a: LA, b: LB, c: LC)
    where
        A: FnOnce() -> AR,
        AR: Into<String>,
        LA: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LB: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LC: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
    {
        let path = compute_path(&self.current_namespace, &annotation().into());
        let index = self.constraints.len();
        self.set_named_obj(path.clone(), NamedObject::Constraint(index));

        let a = a(LinearCombination::zero());
        let b = b(LinearCombination::zero());
        let c = c(LinearCombination::zero());

        self.constraints.push((a, b, c, path));
    }

    fn push_namespace<NR, N>(&mut self, name_fn: N)
    where
        NR: Into<String>,
        N: FnOnce() -> NR,
    {
        let name = name_fn().into();
        let path = compute_path(&self.current_namespace, &name);
        self.set_named_obj(path, NamedObject::Namespace);
        self.current_namespace.push(name);
    }

    fn pop_namespace(&mut self) {
        assert!(self.current_namespace.pop().is_some());
    }

    fn get_root(&mut self) -> &mut Self::Root {
        self
    }
}

fn compute_path(ns: &[String], this: &str) -> String {
    if this.chars().any(|a| a == '/') {
        panic!("'/' is not allowed in names");
    }

    let mut name = String::new();

    let mut needs_separation = false;
    for ns in ns.iter().chain(Some(this.to_string()).iter()) {
        if needs_separation {
            name += "/";
        }

        name += ns;
        needs_separation = true;
    }

    name
}

'''
'''--- storage-proofs/core/src/gadgets/mod.rs ---
mod bench;
mod metric;
mod test;

pub mod constraint;
pub mod encode;
pub mod insertion;
pub mod multipack;
pub mod pedersen;
pub mod por;
pub mod uint64;
pub mod variables;
pub mod xor;

pub use self::bench::*;
pub use self::metric::*;
pub use self::test::*;

'''
'''--- storage-proofs/core/src/gadgets/multipack.rs ---
use bellperson::gadgets::{
    boolean::Boolean,
    num::{AllocatedNum, Num},
};
use bellperson::{ConstraintSystem, SynthesisError};
use ff::{Field, PrimeField, ScalarEngine};

/// Takes a sequence of booleans and exposes them as a single compact Num.
pub fn pack_bits<E, CS>(mut cs: CS, bits: &[Boolean]) -> Result<AllocatedNum<E>, SynthesisError>
where
    E: ScalarEngine,
    CS: ConstraintSystem<E>,
{
    let mut num = Num::<E>::zero();
    let mut coeff = E::Fr::one();
    for bit in bits.iter().take(E::Fr::CAPACITY as usize) {
        num = num.add_bool_with_coeff(CS::one(), &bit, coeff);

        coeff.double();
    }

    let alloc_num = AllocatedNum::alloc(cs.namespace(|| "input"), || {
        num.get_value()
            .ok_or_else(|| SynthesisError::AssignmentMissing)
    })?;

    // num * 1 = input
    cs.enforce(
        || "packing constraint",
        |_| num.lc(E::Fr::one()),
        |lc| lc + CS::one(),
        |lc| lc + alloc_num.get_variable(),
    );

    Ok(alloc_num)
}

'''
'''--- storage-proofs/core/src/gadgets/pedersen.rs ---
use bellperson::gadgets::{boolean::Boolean, num};
use bellperson::{ConstraintSystem, SynthesisError};
use fil_sapling_crypto::circuit::pedersen_hash;
use paired::bls12_381::Bls12;

use crate::crypto::pedersen::{JJ_PARAMS, PEDERSEN_BLOCK_SIZE};

/// Pedersen hashing for inputs with length multiple of the block size. Based on a Merkle-Damgard construction.
pub fn pedersen_md_no_padding<CS>(
    mut cs: CS,
    data: &[Boolean],
) -> Result<num::AllocatedNum<Bls12>, SynthesisError>
where
    CS: ConstraintSystem<Bls12>,
{
    assert!(
        data.len() >= 2 * PEDERSEN_BLOCK_SIZE,
        "must be at least 2 block sizes long ({})",
        data.len()
    );

    assert_eq!(
        data.len() % PEDERSEN_BLOCK_SIZE,
        0,
        "data must be a multiple of the block size ({})",
        data.len()
    );

    let mut chunks = data.chunks(PEDERSEN_BLOCK_SIZE);
    let mut cur: Vec<Boolean> = chunks.next().unwrap().to_vec();
    let chunks_len = chunks.len();

    for (i, block) in chunks.enumerate() {
        let mut cs = cs.namespace(|| format!("block {}", i));
        for b in block {
            // TODO: no cloning
            cur.push(b.clone());
        }
        if i == chunks_len - 1 {
            // last round, skip
        } else {
            cur = pedersen_compression(cs.namespace(|| "hash"), &cur)?;
        }
    }

    // hash and return a num at the end
    pedersen_compression_num(cs.namespace(|| "last hash"), &cur)
}

pub fn pedersen_compression_num<CS: ConstraintSystem<Bls12>>(
    mut cs: CS,
    bits: &[Boolean],
) -> Result<num::AllocatedNum<Bls12>, SynthesisError> {
    Ok(pedersen_hash::pedersen_hash(
        cs.namespace(|| "inner hash"),
        pedersen_hash::Personalization::None,
        &bits,
        &*JJ_PARAMS,
    )?
    .get_x()
    .clone())
}

pub fn pedersen_compression<CS: ConstraintSystem<Bls12>>(
    mut cs: CS,
    bits: &[Boolean],
) -> Result<Vec<Boolean>, SynthesisError> {
    let h = pedersen_compression_num(cs.namespace(|| "compression"), bits)?;
    let mut out = h.to_bits_le(cs.namespace(|| "h into bits"))?;

    // needs padding, because x does not always translate to exactly 256 bits
    while out.len() < PEDERSEN_BLOCK_SIZE {
        out.push(Boolean::Constant(false));
    }

    Ok(out)
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::crypto;
    use crate::gadgets::TestConstraintSystem;
    use crate::util::bytes_into_boolean_vec;
    use bellperson::gadgets::boolean::Boolean;
    use bellperson::ConstraintSystem;
    use paired::bls12_381::Bls12;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_pedersen_single_input_circut() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        let cases = [(32, 689), (64, 1376)];

        for (bytes, constraints) in &cases {
            let mut cs = TestConstraintSystem::<Bls12>::new();
            let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

            let data_bits: Vec<Boolean> = {
                let mut cs = cs.namespace(|| "data");
                bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), data.len()).unwrap()
            };
            let out =
                pedersen_compression_num(&mut cs, &data_bits).expect("pedersen hashing failed");

            assert!(cs.is_satisfied(), "constraints not satisfied");
            assert_eq!(
                cs.num_constraints(),
                *constraints,
                "constraint size changed for {} bytes",
                *bytes
            );

            let expected = crypto::pedersen::pedersen(data.as_slice());

            assert_eq!(
                expected,
                out.get_value().unwrap(),
                "circuit and non circuit do not match"
            );
        }
    }

    #[test]
    fn test_pedersen_md_input_circut() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        let cases = [
            (64, 1376),   // 64 bytes
            (96, 2751),   // 96 bytes
            (128, 4126),  // 128 bytes
            (160, 5501),  // 160 bytes
            (256, 9626),  // 160 bytes
            (512, 20626), // 512 bytes
        ];

        for (bytes, constraints) in &cases {
            let mut cs = TestConstraintSystem::<Bls12>::new();
            let data: Vec<u8> = (0..*bytes).map(|_| rng.gen()).collect();

            let data_bits: Vec<Boolean> = {
                let mut cs = cs.namespace(|| "data");
                bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), data.len()).unwrap()
            };
            let out = pedersen_md_no_padding(cs.namespace(|| "pedersen"), &data_bits)
                .expect("pedersen hashing failed");

            assert!(cs.is_satisfied(), "constraints not satisfied");
            assert_eq!(
                cs.num_constraints(),
                *constraints,
                "constraint size changed {}",
                bytes
            );

            let expected = crypto::pedersen::pedersen_md_no_padding(data.as_slice());

            assert_eq!(
                expected,
                out.get_value().unwrap(),
                "circuit and non circuit do not match {} bytes",
                bytes
            );
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/por.rs ---
use std::marker::PhantomData;

use anyhow::ensure;
use bellperson::gadgets::boolean::{AllocatedBit, Boolean};
use bellperson::gadgets::{multipack, num};
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use generic_array::typenum::Unsigned;
use paired::bls12_381::{Bls12, Fr};

use crate::compound_proof::{CircuitComponent, CompoundProof};
use crate::error::Result;
use crate::gadgets::constraint;
use crate::gadgets::insertion::insert;
use crate::gadgets::variables::Root;
use crate::hasher::{HashFunction, Hasher, PoseidonArity};
use crate::merkle::{base_path_length, MerkleProofTrait, MerkleTreeTrait};
use crate::parameter_cache::{CacheableParameters, ParameterSetMetadata};
use crate::por::PoR;
use crate::proof::ProofScheme;

/// Proof of retrievability.
///
/// # Fields
///
/// * `params` - The params for the bls curve.
/// * `value` - The value of the leaf.
/// * `auth_path` - The authentication path of the leaf in the tree.
/// * `root` - The merkle root of the tree.
///
pub struct PoRCircuit<Tree: MerkleTreeTrait> {
    value: Root<Bls12>,
    auth_path: AuthPath<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    root: Root<Bls12>,
    private: bool,
    _tree: PhantomData<Tree>,
}

#[derive(Debug, Clone)]
pub struct AuthPath<
    H: Hasher,
    U: 'static + PoseidonArity,
    V: 'static + PoseidonArity,
    W: 'static + PoseidonArity,
> {
    base: SubPath<H, U>,
    sub: SubPath<H, V>,
    top: SubPath<H, W>,
}

impl<
        H: Hasher,
        U: 'static + PoseidonArity,
        V: 'static + PoseidonArity,
        W: 'static + PoseidonArity,
    > From<Vec<(Vec<Option<Fr>>, Option<usize>)>> for AuthPath<H, U, V, W>
{
    fn from(mut base_opts: Vec<(Vec<Option<Fr>>, Option<usize>)>) -> Self {
        let has_top = W::to_usize() > 0;
        let has_sub = V::to_usize() > 0;
        let len = base_opts.len();

        let x = if has_top {
            2
        } else if has_sub {
            1
        } else {
            0
        };
        let mut opts = base_opts.split_off(len - x);

        let base = base_opts
            .into_iter()
            .map(|(hashes, index)| PathElement {
                hashes,
                index,
                _a: Default::default(),
                _h: Default::default(),
            })
            .collect();

        let top = if has_top {
            let (hashes, index) = opts.pop().unwrap();
            vec![PathElement {
                hashes,
                index,
                _a: Default::default(),
                _h: Default::default(),
            }]
        } else {
            Vec::new()
        };

        let sub = if has_sub {
            let (hashes, index) = opts.pop().unwrap();
            vec![PathElement {
                hashes,
                index,
                _a: Default::default(),
                _h: Default::default(),
            }]
        } else {
            Vec::new()
        };

        assert!(opts.is_empty());

        AuthPath {
            base: SubPath { path: base },
            sub: SubPath { path: sub },
            top: SubPath { path: top },
        }
    }
}

#[derive(Debug, Clone)]
struct SubPath<H: Hasher, Arity: 'static + PoseidonArity> {
    path: Vec<PathElement<H, Arity>>,
}

#[derive(Debug, Clone)]
struct PathElement<H: Hasher, Arity: 'static + PoseidonArity> {
    hashes: Vec<Option<Fr>>,
    index: Option<usize>,
    _a: PhantomData<Arity>,
    _h: PhantomData<H>,
}

impl<H: Hasher, Arity: 'static + PoseidonArity> SubPath<H, Arity> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(
        self,
        mut cs: CS,
        mut cur: num::AllocatedNum<Bls12>,
    ) -> Result<(num::AllocatedNum<Bls12>, Vec<Boolean>), SynthesisError> {
        let arity = Arity::to_usize();

        if arity == 0 {
            // Nothing to do here.
            assert!(self.path.is_empty());
            return Ok((cur, vec![]));
        }

        assert_eq!(1, arity.count_ones(), "arity must be a power of two");
        let index_bit_count = arity.trailing_zeros() as usize;

        let mut auth_path_bits = Vec::with_capacity(self.path.len());

        for (i, path_element) in self.path.into_iter().enumerate() {
            let path_hashes = path_element.hashes;
            let optional_index = path_element.index; // Optional because of Bellman blank-circuit construction mechanics.

            let cs = &mut cs.namespace(|| format!("merkle tree hash {}", i));

            let mut index_bits = Vec::with_capacity(index_bit_count);

            for i in 0..index_bit_count {
                let bit = AllocatedBit::alloc(cs.namespace(|| format!("index bit {}", i)), {
                    optional_index.map(|index| ((index >> i) & 1) == 1)
                })?;

                index_bits.push(Boolean::from(bit));
            }

            auth_path_bits.extend_from_slice(&index_bits);

            // Witness the authentication path elements adjacent at this depth.
            let path_hash_nums = path_hashes
                .iter()
                .enumerate()
                .map(|(i, elt)| {
                    num::AllocatedNum::alloc(cs.namespace(|| format!("path element {}", i)), || {
                        elt.ok_or_else(|| SynthesisError::AssignmentMissing)
                    })
                })
                .collect::<Result<Vec<_>, _>>()?;

            let inserted = insert(cs, &cur, &index_bits, &path_hash_nums)?;

            // Compute the new subtree value
            cur = H::Function::hash_multi_leaf_circuit::<Arity, _>(
                cs.namespace(|| "computation of commitment hash"),
                &inserted,
                i,
            )?;
        }

        Ok((cur, auth_path_bits))
    }
}

impl<H: Hasher, U: PoseidonArity, V: PoseidonArity, W: PoseidonArity> AuthPath<H, U, V, W> {
    pub fn blank(leaves: usize) -> Self {
        let has_sub = V::to_usize() > 0;
        let has_top = W::to_usize() > 0;
        let base_elements = base_path_length::<U, V, W>(leaves);

        let base = vec![
            PathElement::<H, U> {
                hashes: vec![None; U::to_usize() - 1],
                index: None,
                _a: Default::default(),
                _h: Default::default(),
            };
            base_elements
        ];

        let sub = if has_sub {
            vec![PathElement::<H, V> {
                hashes: vec![None; V::to_usize() - 1],
                index: None,
                _a: Default::default(),
                _h: Default::default(),
            }]
        } else {
            Vec::new()
        };

        let top = if has_top {
            vec![PathElement::<H, W> {
                hashes: vec![None; W::to_usize() - 1],
                index: None,
                _a: Default::default(),
                _h: Default::default(),
            }]
        } else {
            Vec::new()
        };

        AuthPath {
            base: SubPath { path: base },
            sub: SubPath { path: sub },
            top: SubPath { path: top },
        }
    }
}

impl<Tree: MerkleTreeTrait> CircuitComponent for PoRCircuit<Tree> {
    type ComponentPrivateInputs = Option<Root<Bls12>>;
}

pub struct PoRCompound<Tree: MerkleTreeTrait> {
    _tree: PhantomData<Tree>,
}

fn to_bits(bit_count: u32, n: usize) -> Vec<bool> {
    (0..bit_count).map(|i| (n >> i) & 1 == 1).collect()
}

pub fn challenge_into_auth_path_bits(challenge: usize, leaves: usize) -> Vec<bool> {
    assert_eq!(1, leaves.count_ones());

    to_bits(leaves.trailing_zeros(), challenge)
}

impl<C: Circuit<Bls12>, P: ParameterSetMetadata, Tree: MerkleTreeTrait> CacheableParameters<C, P>
    for PoRCompound<Tree>
{
    fn cache_prefix() -> String {
        format!("proof-of-retrievability-{}", Tree::display())
    }
}

// can only implment for Bls12 because por is not generic over the engine.
impl<'a, Tree: 'static + MerkleTreeTrait> CompoundProof<'a, PoR<Tree>, PoRCircuit<Tree>>
    for PoRCompound<Tree>
{
    fn circuit<'b>(
        public_inputs: &<PoR<Tree> as ProofScheme<'a>>::PublicInputs,
        _component_private_inputs: <PoRCircuit<Tree> as CircuitComponent>::ComponentPrivateInputs,
        proof: &'b <PoR<Tree> as ProofScheme<'a>>::Proof,
        public_params: &'b <PoR<Tree> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<PoRCircuit<Tree>> {
        let (root, private) = match (*public_inputs).commitment {
            None => (Root::Val(Some(proof.proof.root().into())), true),
            Some(commitment) => (Root::Val(Some(commitment.into())), false),
        };

        ensure!(
            private == public_params.private,
            "Inputs must be consistent with public params"
        );

        Ok(PoRCircuit::<Tree> {
            value: Root::Val(Some(proof.data.into())),
            auth_path: proof.proof.as_options().into(),
            root,
            private,
            _tree: PhantomData,
        })
    }

    fn blank_circuit(
        public_params: &<PoR<Tree> as ProofScheme<'a>>::PublicParams,
    ) -> PoRCircuit<Tree> {
        PoRCircuit::<Tree> {
            value: Root::Val(None),
            auth_path: AuthPath::blank(public_params.leaves),
            root: Root::Val(None),
            private: public_params.private,
            _tree: PhantomData,
        }
    }

    fn generate_public_inputs(
        pub_inputs: &<PoR<Tree> as ProofScheme<'a>>::PublicInputs,
        pub_params: &<PoR<Tree> as ProofScheme<'a>>::PublicParams,
        _k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let mut inputs = Vec::new();
        let path_bits = challenge_into_auth_path_bits(pub_inputs.challenge, pub_params.leaves);

        inputs.extend(multipack::compute_multipacking::<Bls12>(&path_bits));

        if let Some(commitment) = pub_inputs.commitment {
            ensure!(!pub_params.private, "Params must be public");
            inputs.push(commitment.into());
        } else {
            ensure!(pub_params.private, "Params must be private");
        }

        Ok(inputs)
    }
}

impl<'a, Tree: MerkleTreeTrait> Circuit<Bls12> for PoRCircuit<Tree> {
    /// # Public Inputs
    ///
    /// This circuit expects the following public inputs.
    ///
    /// * [0] - packed version of the `is_right` components of the auth_path.
    /// * [1] - the merkle root of the tree.
    ///
    /// This circuit derives the following private inputs from its fields:
    /// * value_num - packed version of `value` as bits. (might be more than one Fr)
    ///
    /// Note: All public inputs must be provided as `E::Fr`.
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let value = self.value;
        let auth_path = self.auth_path;
        let root = self.root;

        let base_arity = Tree::Arity::to_usize();
        let sub_arity = Tree::SubTreeArity::to_usize();
        let top_arity = Tree::TopTreeArity::to_usize();

        // All arities must be powers of two or circuits cannot be generated.
        assert_eq!(
            1,
            base_arity.count_ones(),
            "base arity must be power of two"
        );
        if sub_arity > 0 {
            assert_eq!(
                1,
                sub_arity.count_ones(),
                "subtree arity must be power of two"
            );
        }
        if top_arity > 0 {
            assert_eq!(
                1,
                top_arity.count_ones(),
                "top tree arity must be power of two"
            );
        }

        {
            let value_num = value.allocated(cs.namespace(|| "value"))?;
            let cur = value_num;

            // Ascend the merkle tree authentication path

            // base tree
            let (cur, base_auth_path_bits) =
                auth_path.base.synthesize(cs.namespace(|| "base"), cur)?;

            // sub
            let (cur, sub_auth_path_bits) =
                auth_path.sub.synthesize(cs.namespace(|| "sub"), cur)?;

            // top
            let (computed_root, top_auth_path_bits) =
                auth_path.top.synthesize(cs.namespace(|| "top"), cur)?;

            let mut auth_path_bits = Vec::new();
            auth_path_bits.extend(base_auth_path_bits);
            auth_path_bits.extend(sub_auth_path_bits);
            auth_path_bits.extend(top_auth_path_bits);

            multipack::pack_into_inputs(cs.namespace(|| "path"), &auth_path_bits)?;
            {
                // Validate that the root of the merkle tree that we calculated is the same as the input.
                let rt = root.allocated(cs.namespace(|| "root_value"))?;
                constraint::equal(cs, || "enforce root is correct", &computed_root, &rt);

                if !self.private {
                    // Expose the root
                    rt.inputize(cs.namespace(|| "root"))?;
                }
            }

            Ok(())
        }
    }
}

impl<'a, Tree: MerkleTreeTrait> PoRCircuit<Tree> {
    #[allow(clippy::type_complexity)]
    pub fn synthesize<CS>(
        mut cs: CS,
        value: Root<Bls12>,
        auth_path: AuthPath<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
        root: Root<Bls12>,
        private: bool,
    ) -> Result<(), SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        let por = Self {
            value,
            auth_path,
            root,
            private,
            _tree: PhantomData,
        };

        por.synthesize(&mut cs)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use bellperson::gadgets::multipack;
    use ff::Field;
    use generic_array::typenum;
    use merkletree::store::VecStore;
    use pretty_assertions::assert_eq;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    use crate::compound_proof;
    use crate::fr32::{bytes_into_fr, fr_into_bytes};
    use crate::gadgets::{MetricCS, TestConstraintSystem};
    use crate::hasher::{
        Blake2sHasher, Domain, Hasher, PedersenHasher, PoseidonHasher, Sha256Hasher,
    };
    use crate::merkle::{
        create_base_merkle_tree, generate_tree, get_base_tree_count, MerkleProofTrait,
        MerkleTreeWrapper, ResTree,
    };
    use crate::por;
    use crate::proof::NoRequirements;
    use crate::proof::ProofScheme;
    use crate::util::data_at_node;

    type TestTree<H, A> =
        MerkleTreeWrapper<H, VecStore<<H as Hasher>::Domain>, A, typenum::U0, typenum::U0>;

    type TestTree2<H, A, B> =
        MerkleTreeWrapper<H, VecStore<<H as Hasher>::Domain>, A, B, typenum::U0>;

    type TestTree3<H, A, B, C> = MerkleTreeWrapper<H, VecStore<<H as Hasher>::Domain>, A, B, C>;

    #[test]
    #[ignore] // Slow test – run only when compiled for release.
    fn por_test_compound_poseidon_base_8() {
        por_compound::<TestTree<PoseidonHasher, typenum::U8>>();
    }

    fn por_compound<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();

        let data: Vec<u8> = (0..leaves)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();
        let tree = create_base_merkle_tree::<Tree>(None, leaves, data.as_slice()).unwrap();

        let public_inputs = por::PublicInputs {
            challenge: 2,
            commitment: Some(tree.root()),
        };

        let setup_params = compound_proof::SetupParams {
            vanilla_params: por::SetupParams {
                leaves,
                private: false,
            },
            partitions: None,
            priority: false,
        };
        let public_params = PoRCompound::<Tree>::setup(&setup_params).expect("setup failed");

        let private_inputs = por::PrivateInputs::<Tree>::new(
            bytes_into_fr(data_at_node(data.as_slice(), public_inputs.challenge).unwrap())
                .expect("failed to create Fr from node data")
                .into(),
            &tree,
        );

        let gparams = PoRCompound::<Tree>::groth_params(Some(rng), &public_params.vanilla_params)
            .expect("failed to generate groth params");

        let proof =
            PoRCompound::<Tree>::prove(&public_params, &public_inputs, &private_inputs, &gparams)
                .expect("failed while proving");

        let verified =
            PoRCompound::<Tree>::verify(&public_params, &public_inputs, &proof, &NoRequirements)
                .expect("failed while verifying");
        assert!(verified);

        let (circuit, inputs) =
            PoRCompound::<Tree>::circuit_for_test(&public_params, &public_inputs, &private_inputs)
                .unwrap();

        let mut cs = TestConstraintSystem::new();

        circuit.synthesize(&mut cs).expect("failed to synthesize");
        assert!(cs.is_satisfied());
        assert!(cs.verify(&inputs));
    }

    #[test]
    fn test_por_circuit_pedersen_base_2() {
        test_por_circuit::<TestTree<PedersenHasher, typenum::U2>>(3, 8_247);
    }

    #[test]
    fn test_por_circuit_blake2s_base_2() {
        test_por_circuit::<TestTree<Blake2sHasher, typenum::U2>>(3, 129_135);
    }

    #[test]
    fn test_por_circuit_sha256_base_2() {
        test_por_circuit::<TestTree<Sha256Hasher, typenum::U2>>(3, 272_295);
    }

    #[test]
    fn test_por_circuit_poseidon_base_2() {
        test_por_circuit::<TestTree<PoseidonHasher, typenum::U2>>(3, 1_905);
    }

    #[test]
    fn test_por_circuit_pedersen_base_4() {
        test_por_circuit::<TestTree<PedersenHasher, typenum::U4>>(3, 12_399);
    }

    #[test]
    fn test_por_circuit_pedersen_sub_8_2() {
        test_por_circuit::<TestTree2<PedersenHasher, typenum::U8, typenum::U2>>(3, 20_663);
    }

    #[test]
    fn test_por_circuit_pedersen_top_8_4_2() {
        test_por_circuit::<TestTree3<PedersenHasher, typenum::U8, typenum::U4, typenum::U2>>(
            3, 24_795,
        );
    }

    #[test]
    fn test_por_circuit_pedersen_top_8_2_4() {
        // We can handle top-heavy trees with a non-zero subtree arity.
        // These should never be produced, though.
        test_por_circuit::<TestTree3<PedersenHasher, typenum::U8, typenum::U2, typenum::U4>>(
            3, 24_795,
        );
    }

    #[test]
    fn test_por_circuit_blake2s_base_4() {
        test_por_circuit::<TestTree<Blake2sHasher, typenum::U4>>(3, 130_296);
    }

    #[test]
    fn test_por_circuit_sha256_base_4() {
        test_por_circuit::<TestTree<Sha256Hasher, typenum::U4>>(3, 216_258);
    }

    #[test]
    fn test_por_circuit_poseidon_base_4() {
        test_por_circuit::<TestTree<PoseidonHasher, typenum::U4>>(3, 1_173);
    }

    #[test]
    fn test_por_circuit_pedersen_base_8() {
        test_por_circuit::<TestTree<PedersenHasher, typenum::U8>>(3, 19_289);
    }

    #[test]
    fn test_por_circuit_blake2s_base_8() {
        test_por_circuit::<TestTree<Blake2sHasher, typenum::U8>>(3, 174_503);
    }

    #[test]
    fn test_por_circuit_sha256_base_8() {
        test_por_circuit::<TestTree<Sha256Hasher, typenum::U8>>(3, 250_987);
    }

    #[test]
    fn test_por_circuit_poseidon_base_8() {
        test_por_circuit::<TestTree<PoseidonHasher, typenum::U8>>(3, 1_069);
    }

    #[test]
    fn test_por_circuit_poseidon_sub_8_2() {
        test_por_circuit::<TestTree2<PoseidonHasher, typenum::U8, typenum::U2>>(3, 1_386);
    }

    #[test]
    fn test_por_circuit_poseidon_top_8_4_2() {
        test_por_circuit::<TestTree3<PoseidonHasher, typenum::U8, typenum::U4, typenum::U2>>(
            3, 1_776,
        );
    }

    #[test]
    fn test_por_circuit_poseidon_top_8_8() {
        // This is the shape we want for 32GiB sectors.
        test_por_circuit::<TestTree2<PoseidonHasher, typenum::U8, typenum::U8>>(3, 1_602);
    }
    #[test]
    fn test_por_circuit_poseidon_top_8_8_2() {
        // This is the shape we want for 64GiB secotrs.
        test_por_circuit::<TestTree3<PoseidonHasher, typenum::U8, typenum::U8, typenum::U2>>(
            3, 1_919,
        );
    }

    #[test]
    fn test_por_circuit_poseidon_top_8_2_4() {
        // We can handle top-heavy trees with a non-zero subtree arity.
        // These should never be produced, though.
        test_por_circuit::<TestTree3<PoseidonHasher, typenum::U8, typenum::U2, typenum::U4>>(
            3, 1_776,
        );
    }

    fn test_por_circuit<Tree: 'static + MerkleTreeTrait>(
        num_inputs: usize,
        num_constraints: usize,
    ) {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        // Ensure arity will evenly fill tree.
        let leaves = 64 * get_base_tree_count::<Tree>();

        // -- Basic Setup
        let (data, tree) = generate_tree::<Tree, _>(rng, leaves, None);

        for i in 0..leaves {
            //println!("challenge: {}, ({})", i, leaves);

            // -- PoR
            let pub_params = por::PublicParams {
                leaves,
                private: false,
            };
            let pub_inputs = por::PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
                challenge: i,
                commitment: Some(tree.root()),
            };
            let leaf = data_at_node(data.as_slice(), pub_inputs.challenge).unwrap();
            let leaf_element = <Tree::Hasher as Hasher>::Domain::try_from_bytes(leaf).unwrap();
            let priv_inputs = por::PrivateInputs::<ResTree<Tree>>::new(leaf_element, &tree);
            let p = tree.gen_proof(i).unwrap();
            assert!(p.verify());

            // create a non circuit proof
            let proof = por::PoR::<ResTree<Tree>>::prove(&pub_params, &pub_inputs, &priv_inputs)
                .expect("proving failed");

            // make sure it verifies
            let is_valid = por::PoR::<ResTree<Tree>>::verify(&pub_params, &pub_inputs, &proof)
                .expect("verification failed");
            assert!(is_valid, "failed to verify por proof");

            // -- Circuit

            let mut cs = TestConstraintSystem::<Bls12>::new();
            let por = PoRCircuit::<ResTree<Tree>> {
                value: Root::Val(Some(proof.data.into())),
                auth_path: proof.proof.as_options().into(),
                root: Root::Val(Some(pub_inputs.commitment.unwrap().into())),
                private: false,
                _tree: PhantomData,
            };

            por.synthesize(&mut cs).expect("circuit synthesis failed");
            assert!(cs.is_satisfied(), "constraints not satisfied");

            assert_eq!(cs.num_inputs(), num_inputs, "wrong number of inputs");
            assert_eq!(
                cs.num_constraints(),
                num_constraints,
                "wrong number of constraints"
            );

            let generated_inputs = PoRCompound::<ResTree<Tree>>::generate_public_inputs(
                &pub_inputs,
                &pub_params,
                None,
            )
            .unwrap();

            let expected_inputs = cs.get_inputs();

            for ((input, label), generated_input) in
                expected_inputs.iter().skip(1).zip(generated_inputs.iter())
            {
                assert_eq!(input, generated_input, "{}", label);
            }

            assert_eq!(
                generated_inputs.len(),
                expected_inputs.len() - 1,
                "inputs are not the same length"
            );

            assert!(cs.verify(&generated_inputs), "failed to verify inputs");
        }
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_pedersen_base_2() {
        private_por_test_compound::<TestTree<PedersenHasher, typenum::U2>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_pedersen_base_4() {
        private_por_test_compound::<TestTree<PedersenHasher, typenum::U4>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_base_2() {
        private_por_test_compound::<TestTree<PoseidonHasher, typenum::U2>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_base_4() {
        private_por_test_compound::<TestTree<PoseidonHasher, typenum::U4>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_sub_8_2() {
        private_por_test_compound::<TestTree2<PoseidonHasher, typenum::U8, typenum::U2>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_top_8_4_2() {
        private_por_test_compound::<TestTree3<PoseidonHasher, typenum::U8, typenum::U4, typenum::U2>>(
        );
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_top_8_8() {
        private_por_test_compound::<TestTree2<PoseidonHasher, typenum::U8, typenum::U8>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_top_8_8_2() {
        private_por_test_compound::<TestTree3<PoseidonHasher, typenum::U8, typenum::U8, typenum::U2>>(
        );
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn test_private_por_compound_poseidon_top_8_2_4() {
        private_por_test_compound::<TestTree3<PoseidonHasher, typenum::U8, typenum::U2, typenum::U4>>(
        );
    }

    fn private_por_test_compound<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        // Ensure arity will evenly fill tree.
        let leaves = 64 * get_base_tree_count::<Tree>();

        // -- Basic Setup
        let (data, tree) = generate_tree::<Tree, _>(rng, leaves, None);

        for i in 0..3 {
            let public_inputs = por::PublicInputs {
                challenge: i,
                commitment: None,
            };

            let setup_params = compound_proof::SetupParams {
                vanilla_params: por::SetupParams {
                    leaves,
                    private: true,
                },
                partitions: None,
                priority: false,
            };
            let public_params =
                PoRCompound::<ResTree<Tree>>::setup(&setup_params).expect("setup failed");

            let private_inputs = por::PrivateInputs::<ResTree<Tree>>::new(
                bytes_into_fr(data_at_node(data.as_slice(), public_inputs.challenge).unwrap())
                    .expect("failed to create Fr from node data")
                    .into(),
                &tree,
            );

            {
                let (circuit, inputs) =
                    PoRCompound::circuit_for_test(&public_params, &public_inputs, &private_inputs)
                        .unwrap();

                let mut cs = TestConstraintSystem::new();

                circuit.synthesize(&mut cs).expect("failed to synthesize");

                if !cs.is_satisfied() {
                    panic!(
                        "failed to satisfy: {:?}",
                        cs.which_is_unsatisfied().unwrap()
                    );
                }
                assert!(
                    cs.verify(&inputs),
                    "verification failed with TestContraintSystem and generated inputs"
                );
            }
            // NOTE: This diagnostic code currently fails, even though the proof generated from the blank circuit verifies.
            // Use this to debug differences between blank and regular circuit generation.
            {
                let (circuit1, _inputs) =
                    PoRCompound::circuit_for_test(&public_params, &public_inputs, &private_inputs)
                        .unwrap();
                let blank_circuit =
                    PoRCompound::<ResTree<Tree>>::blank_circuit(&public_params.vanilla_params);

                let mut cs_blank = MetricCS::new();
                blank_circuit
                    .synthesize(&mut cs_blank)
                    .expect("failed to synthesize");

                let a = cs_blank.pretty_print_list();

                let mut cs1 = TestConstraintSystem::new();
                circuit1.synthesize(&mut cs1).expect("failed to synthesize");
                let b = cs1.pretty_print_list();

                for (i, (a, b)) in a.chunks(100).zip(b.chunks(100)).enumerate() {
                    assert_eq!(a, b, "failed at chunk {}", i);
                }
            }

            let blank_groth_params = PoRCompound::<ResTree<Tree>>::groth_params(
                Some(rng),
                &public_params.vanilla_params,
            )
            .expect("failed to generate groth params");

            let proof = PoRCompound::prove(
                &public_params,
                &public_inputs,
                &private_inputs,
                &blank_groth_params,
            )
            .expect("failed while proving");

            let verified =
                PoRCompound::verify(&public_params, &public_inputs, &proof, &NoRequirements)
                    .expect("failed while verifying");

            assert!(verified);
        }
    }

    #[test]
    fn test_private_por_input_circuit_pedersen_binary() {
        test_private_por_input_circuit::<TestTree<PedersenHasher, typenum::U2>>(8_246);
    }

    #[test]
    fn test_private_por_input_circuit_poseidon_binary() {
        test_private_por_input_circuit::<TestTree<PoseidonHasher, typenum::U2>>(1_904);
    }

    #[test]
    fn test_private_por_input_circuit_pedersen_quad() {
        test_private_por_input_circuit::<TestTree<PedersenHasher, typenum::U4>>(12_398);
    }

    #[test]
    fn test_private_por_input_circuit_poseidon_quad() {
        test_private_por_input_circuit::<TestTree<PoseidonHasher, typenum::U4>>(1_172);
    }

    #[test]
    fn test_private_por_input_circuit_poseidon_oct() {
        test_private_por_input_circuit::<TestTree<PoseidonHasher, typenum::U8>>(1_068);
    }

    fn test_private_por_input_circuit<Tree: MerkleTreeTrait>(num_constraints: usize) {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        for i in 0..leaves {
            // -- Basic Setup

            let data: Vec<u8> = (0..leaves)
                .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
                .collect();

            let tree = create_base_merkle_tree::<Tree>(None, leaves, data.as_slice()).unwrap();

            // -- PoR

            let pub_params = por::PublicParams {
                leaves,
                private: true,
            };
            let pub_inputs = por::PublicInputs {
                challenge: i,
                commitment: None,
            };

            let priv_inputs = por::PrivateInputs::<Tree>::new(
                bytes_into_fr(data_at_node(data.as_slice(), pub_inputs.challenge).unwrap())
                    .unwrap()
                    .into(),
                &tree,
            );

            // create a non circuit proof
            let proof = por::PoR::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
                .expect("proving failed");

            // make sure it verifies
            let is_valid = por::PoR::<Tree>::verify(&pub_params, &pub_inputs, &proof)
                .expect("verification failed");
            assert!(is_valid, "failed to verify por proof");

            // -- Circuit

            let mut cs = TestConstraintSystem::<Bls12>::new();

            let por = PoRCircuit::<Tree> {
                value: Root::Val(Some(proof.data.into())),
                auth_path: proof.proof.as_options().into(),
                root: Root::Val(Some(tree.root().into())),
                private: true,
                _tree: PhantomData,
            };

            por.synthesize(&mut cs).expect("circuit synthesis failed");
            assert!(cs.is_satisfied(), "constraints not satisfied");

            assert_eq!(cs.num_inputs(), 2, "wrong number of inputs");
            assert_eq!(
                cs.num_constraints(),
                num_constraints,
                "wrong number of constraints"
            );

            let auth_path_bits =
                challenge_into_auth_path_bits(pub_inputs.challenge, pub_params.leaves);
            let packed_auth_path = multipack::compute_multipacking::<Bls12>(&auth_path_bits);

            let mut expected_inputs = Vec::new();
            expected_inputs.extend(packed_auth_path);

            assert_eq!(cs.get_input(0, "ONE"), Fr::one(), "wrong input 0");

            assert_eq!(
                cs.get_input(1, "path/input 0"),
                expected_inputs[0],
                "wrong packed_auth_path"
            );

            assert!(cs.is_satisfied(), "constraints are not all satisfied");
            assert!(cs.verify(&expected_inputs), "failed to verify inputs");
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/test/mod.rs ---
use std::cmp::Ordering;
use std::collections::BTreeMap;
use std::collections::HashMap;

use bellperson::{ConstraintSystem, Index, LinearCombination, SynthesisError, Variable};
use blake2s_simd::State as Blake2s;
use byteorder::{BigEndian, ByteOrder};
use ff::{Field, PrimeField, PrimeFieldRepr};
use paired::Engine;

#[derive(Debug)]
enum NamedObject {
    Constraint(usize),
    Var(Variable),
    Namespace,
}

/// Constraint system for testing purposes.
pub struct TestConstraintSystem<E: Engine> {
    named_objects: HashMap<String, NamedObject>,
    current_namespace: Vec<String>,
    #[allow(clippy::type_complexity)]
    constraints: Vec<(
        LinearCombination<E>,
        LinearCombination<E>,
        LinearCombination<E>,
        String,
    )>,
    inputs: Vec<(E::Fr, String)>,
    aux: Vec<(E::Fr, String)>,
}

#[derive(Clone, Copy)]
struct OrderedVariable(Variable);

impl Eq for OrderedVariable {}
impl PartialEq for OrderedVariable {
    fn eq(&self, other: &OrderedVariable) -> bool {
        match (self.0.get_unchecked(), other.0.get_unchecked()) {
            (Index::Input(ref a), Index::Input(ref b)) => a == b,
            (Index::Aux(ref a), Index::Aux(ref b)) => a == b,
            _ => false,
        }
    }
}
impl PartialOrd for OrderedVariable {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}
impl Ord for OrderedVariable {
    fn cmp(&self, other: &Self) -> Ordering {
        match (self.0.get_unchecked(), other.0.get_unchecked()) {
            (Index::Input(ref a), Index::Input(ref b)) => a.cmp(b),
            (Index::Aux(ref a), Index::Aux(ref b)) => a.cmp(b),
            (Index::Input(_), Index::Aux(_)) => Ordering::Less,
            (Index::Aux(_), Index::Input(_)) => Ordering::Greater,
        }
    }
}

fn proc_lc<E: Engine>(terms: &LinearCombination<E>) -> BTreeMap<OrderedVariable, E::Fr> {
    let mut map = BTreeMap::new();
    for (&var, &coeff) in terms.iter() {
        map.entry(OrderedVariable(var))
            .or_insert_with(E::Fr::zero)
            .add_assign(&coeff);
    }

    // Remove terms that have a zero coefficient to normalize
    let mut to_remove = vec![];
    for (var, coeff) in map.iter() {
        if coeff.is_zero() {
            to_remove.push(var.clone())
        }
    }

    for var in to_remove {
        map.remove(&var);
    }

    map
}

fn hash_lc<E: Engine>(terms: &LinearCombination<E>, h: &mut Blake2s) {
    let map = proc_lc::<E>(terms);

    let mut buf = [0u8; 9 + 32];
    BigEndian::write_u64(&mut buf[0..8], map.len() as u64);
    h.update(&buf[0..8]);

    for (var, coeff) in map {
        match var.0.get_unchecked() {
            Index::Input(i) => {
                buf[0] = b'I';
                BigEndian::write_u64(&mut buf[1..9], i as u64);
            }
            Index::Aux(i) => {
                buf[0] = b'A';
                BigEndian::write_u64(&mut buf[1..9], i as u64);
            }
        }

        coeff
            .into_repr()
            .write_be(&mut buf[9..])
            .expect("failed to write coeff");

        h.update(&buf[..]);
    }
}

fn _eval_lc2<E: Engine>(terms: &LinearCombination<E>, inputs: &[E::Fr], aux: &[E::Fr]) -> E::Fr {
    let mut acc = E::Fr::zero();

    for (&var, coeff) in terms.iter() {
        let mut tmp = match var.get_unchecked() {
            Index::Input(index) => inputs[index],
            Index::Aux(index) => aux[index],
        };

        tmp.mul_assign(&coeff);
        acc.add_assign(&tmp);
    }

    acc
}

fn eval_lc<E: Engine>(
    terms: &LinearCombination<E>,
    inputs: &[(E::Fr, String)],
    aux: &[(E::Fr, String)],
) -> E::Fr {
    let mut acc = E::Fr::zero();

    for (&var, coeff) in terms.iter() {
        let mut tmp = match var.get_unchecked() {
            Index::Input(index) => inputs[index].0,
            Index::Aux(index) => aux[index].0,
        };

        tmp.mul_assign(&coeff);
        acc.add_assign(&tmp);
    }

    acc
}

impl<E: Engine> Default for TestConstraintSystem<E> {
    fn default() -> Self {
        let mut map = HashMap::new();
        map.insert(
            "ONE".into(),
            NamedObject::Var(TestConstraintSystem::<E>::one()),
        );

        TestConstraintSystem {
            named_objects: map,
            current_namespace: vec![],
            constraints: vec![],
            inputs: vec![(E::Fr::one(), "ONE".into())],
            aux: vec![],
        }
    }
}

impl<E: Engine> TestConstraintSystem<E> {
    pub fn new() -> Self {
        Default::default()
    }

    pub fn pretty_print_list(&self) -> Vec<String> {
        let mut result = Vec::new();

        for input in &self.inputs {
            result.push(format!("INPUT {}", input.1));
        }
        for aux in &self.aux {
            result.push(format!("AUX {}", aux.1));
        }

        for &(ref _a, ref _b, ref _c, ref name) in &self.constraints {
            result.push(name.to_string());
        }

        result
    }

    pub fn pretty_print(&self) -> String {
        let res = self.pretty_print_list();

        res.join("\n")
    }

    pub fn hash(&self) -> String {
        let mut h = Blake2s::new();
        {
            let mut buf = [0u8; 24];

            BigEndian::write_u64(&mut buf[0..8], self.inputs.len() as u64);
            BigEndian::write_u64(&mut buf[8..16], self.aux.len() as u64);
            BigEndian::write_u64(&mut buf[16..24], self.constraints.len() as u64);
            h.update(&buf);
        }

        for constraint in &self.constraints {
            hash_lc::<E>(&constraint.0, &mut h);
            hash_lc::<E>(&constraint.1, &mut h);
            hash_lc::<E>(&constraint.2, &mut h);
        }

        let mut s = String::new();
        for b in h.finalize().as_ref() {
            s += &format!("{:02x}", b);
        }

        s
    }

    pub fn which_is_unsatisfied(&self) -> Option<&str> {
        for &(ref a, ref b, ref c, ref path) in &self.constraints {
            let mut a = eval_lc::<E>(a, &self.inputs, &self.aux);
            let b = eval_lc::<E>(b, &self.inputs, &self.aux);
            let c = eval_lc::<E>(c, &self.inputs, &self.aux);

            a.mul_assign(&b);

            if a != c {
                return Some(&*path);
            }
        }

        None
    }

    pub fn is_satisfied(&self) -> bool {
        match self.which_is_unsatisfied() {
            Some(b) => {
                println!("fail: {:?}", b);
                false
            }
            None => true,
        }
        // self.which_is_unsatisfied().is_none()
    }

    pub fn num_constraints(&self) -> usize {
        self.constraints.len()
    }

    pub fn set(&mut self, path: &str, to: E::Fr) {
        match self.named_objects.get(path) {
            Some(&NamedObject::Var(ref v)) => match v.get_unchecked() {
                Index::Input(index) => self.inputs[index].0 = to,
                Index::Aux(index) => self.aux[index].0 = to,
            },
            Some(e) => panic!(
                "tried to set path `{}` to value, but `{:?}` already exists there.",
                path, e
            ),
            _ => panic!("no variable exists at path: {}", path),
        }
    }

    pub fn verify(&self, expected: &[E::Fr]) -> bool {
        assert_eq!(expected.len() + 1, self.inputs.len());
        for (a, b) in self.inputs.iter().skip(1).zip(expected.iter()) {
            if &a.0 != b {
                return false;
            }
        }

        true
    }

    pub fn num_inputs(&self) -> usize {
        self.inputs.len()
    }

    pub fn get_input(&mut self, index: usize, path: &str) -> E::Fr {
        let (assignment, name) = self.inputs[index].clone();

        assert_eq!(path, name);

        assignment
    }

    pub fn get_inputs(&self) -> &[(E::Fr, String)] {
        &self.inputs[..]
    }

    pub fn get(&mut self, path: &str) -> E::Fr {
        match self.named_objects.get(path) {
            Some(&NamedObject::Var(ref v)) => match v.get_unchecked() {
                Index::Input(index) => self.inputs[index].0,
                Index::Aux(index) => self.aux[index].0,
            },
            Some(e) => panic!(
                "tried to get value of path `{}`, but `{:?}` exists there (not a variable)",
                path, e
            ),
            _ => panic!("no variable exists at path: {}", path),
        }
    }

    fn set_named_obj(&mut self, path: String, to: NamedObject) {
        if self.named_objects.contains_key(&path) {
            panic!("tried to create object at existing path: {}", path);
        }

        self.named_objects.insert(path, to);
    }
}

fn compute_path(ns: &[String], this: &str) -> String {
    assert!(
        !this.chars().any(|a| a == '/'),
        "'/' is not allowed in names"
    );

    if ns.is_empty() {
        return this.to_string();
    }

    let name = ns.join("/");
    format!("{}/{}", name, this)
}

impl<E: Engine> ConstraintSystem<E> for TestConstraintSystem<E> {
    type Root = Self;

    fn alloc<F, A, AR>(&mut self, annotation: A, f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        let index = self.aux.len();
        let path = compute_path(&self.current_namespace, &annotation().into());
        self.aux.push((f()?, path.clone()));
        let var = Variable::new_unchecked(Index::Aux(index));
        self.set_named_obj(path, NamedObject::Var(var));

        Ok(var)
    }

    fn alloc_input<F, A, AR>(&mut self, annotation: A, f: F) -> Result<Variable, SynthesisError>
    where
        F: FnOnce() -> Result<E::Fr, SynthesisError>,
        A: FnOnce() -> AR,
        AR: Into<String>,
    {
        let index = self.inputs.len();
        let path = compute_path(&self.current_namespace, &annotation().into());
        self.inputs.push((f()?, path.clone()));
        let var = Variable::new_unchecked(Index::Input(index));
        self.set_named_obj(path, NamedObject::Var(var));

        Ok(var)
    }

    fn enforce<A, AR, LA, LB, LC>(&mut self, annotation: A, a: LA, b: LB, c: LC)
    where
        A: FnOnce() -> AR,
        AR: Into<String>,
        LA: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LB: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
        LC: FnOnce(LinearCombination<E>) -> LinearCombination<E>,
    {
        let path = compute_path(&self.current_namespace, &annotation().into());
        let index = self.constraints.len();
        self.set_named_obj(path.clone(), NamedObject::Constraint(index));

        let a = a(LinearCombination::zero());
        let b = b(LinearCombination::zero());
        let c = c(LinearCombination::zero());

        self.constraints.push((a, b, c, path));
    }

    fn push_namespace<NR, N>(&mut self, name_fn: N)
    where
        NR: Into<String>,
        N: FnOnce() -> NR,
    {
        let name = name_fn().into();
        let path = compute_path(&self.current_namespace, &name);
        self.set_named_obj(path, NamedObject::Namespace);
        self.current_namespace.push(name);
    }

    fn pop_namespace(&mut self) {
        assert!(self.current_namespace.pop().is_some());
    }

    fn get_root(&mut self) -> &mut Self::Root {
        self
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compute_path() {
        assert_eq!(
            compute_path(
                &[
                    "hello".to_string(),
                    "world".to_string(),
                    "things".to_string()
                ],
                "thing"
            ),
            "hello/world/things/thing"
        );
    }

    #[test]
    fn test_cs() {
        use ff::PrimeField;
        use paired::bls12_381::{Bls12, Fr};

        let mut cs = TestConstraintSystem::<Bls12>::new();
        assert!(cs.is_satisfied());
        assert_eq!(cs.num_constraints(), 0);
        let a = cs
            .namespace(|| "a")
            .alloc(|| "var", || Ok(Fr::from_str("10").unwrap()))
            .unwrap();
        let b = cs
            .namespace(|| "b")
            .alloc(|| "var", || Ok(Fr::from_str("4").unwrap()))
            .unwrap();
        let c = cs
            .alloc(|| "product", || Ok(Fr::from_str("40").unwrap()))
            .unwrap();

        cs.enforce(|| "mult", |lc| lc + a, |lc| lc + b, |lc| lc + c);
        assert!(cs.is_satisfied());
        assert_eq!(cs.num_constraints(), 1);

        cs.set("a/var", Fr::from_str("4").unwrap());

        let one = TestConstraintSystem::<Bls12>::one();
        cs.enforce(|| "eq", |lc| lc + a, |lc| lc + one, |lc| lc + b);

        assert!(!cs.is_satisfied());
        assert!(cs.which_is_unsatisfied() == Some("mult"));

        assert!(cs.get("product") == Fr::from_str("40").unwrap());

        cs.set("product", Fr::from_str("16").unwrap());
        assert!(cs.is_satisfied());

        {
            let mut cs = cs.namespace(|| "test1");
            let mut cs = cs.namespace(|| "test2");
            cs.alloc(|| "hehe", || Ok(Fr::one())).unwrap();
        }

        assert!(cs.get("test1/test2/hehe") == Fr::one());
    }
}

'''
'''--- storage-proofs/core/src/gadgets/uint64.rs ---
use bellperson::gadgets::boolean::{AllocatedBit, Boolean};
use bellperson::gadgets::multipack::pack_into_inputs;
use bellperson::{ConstraintSystem, SynthesisError};
use paired::Engine;

/// Represents an interpretation of 64 `Boolean` objects as an unsigned integer.
#[derive(Clone)]
pub struct UInt64 {
    // Least significant bit first
    bits: Vec<Boolean>,
    value: Option<u64>,
}

impl UInt64 {
    /// Construct a constant `UInt64` from a `u64`
    pub fn constant(value: u64) -> Self {
        let mut bits = Vec::with_capacity(64);

        let mut tmp = value;
        for _ in 0..64 {
            if tmp & 1 == 1 {
                bits.push(Boolean::constant(true))
            } else {
                bits.push(Boolean::constant(false))
            }

            tmp >>= 1;
        }

        UInt64 {
            bits,
            value: Some(value),
        }
    }

    pub fn get_value(&self) -> Option<u64> {
        self.value
    }

    pub fn pack_into_input<E, CS>(&self, cs: CS) -> Result<(), SynthesisError>
    where
        E: Engine,
        CS: ConstraintSystem<E>,
    {
        pack_into_inputs(cs, &self.bits)
    }

    /// Allocate a `UInt64` in the constraint system
    pub fn alloc<E, CS>(mut cs: CS, value: Option<u64>) -> Result<Self, SynthesisError>
    where
        E: Engine,
        CS: ConstraintSystem<E>,
    {
        let values = match value {
            Some(mut val) => {
                let mut v = Vec::with_capacity(64);

                for _ in 0..64 {
                    v.push(Some(val & 1 == 1));
                    val >>= 1;
                }

                v
            }
            None => vec![None; 64],
        };

        let bits = values
            .into_iter()
            .enumerate()
            .map(|(i, v)| {
                Ok(Boolean::from(AllocatedBit::alloc(
                    cs.namespace(|| format!("allocated bit {}", i)),
                    v,
                )?))
            })
            .collect::<Result<Vec<_>, SynthesisError>>()?;

        Ok(UInt64 { bits, value })
    }

    pub fn to_bits_be(&self) -> Vec<Boolean> {
        self.bits.iter().rev().cloned().collect()
    }

    pub fn from_bits_be(bits: &[Boolean]) -> Self {
        assert_eq!(bits.len(), 64);

        let mut value = Some(0u64);
        for b in bits {
            if let Some(v) = value.as_mut() {
                *v <<= 1;
            }

            match b.get_value() {
                Some(true) => {
                    if let Some(v) = value.as_mut() {
                        *v |= 1;
                    }
                }
                Some(false) => {}
                None => {
                    value = None;
                }
            }
        }

        UInt64 {
            value,
            bits: bits.iter().rev().cloned().collect(),
        }
    }

    /// Turns this `UInt64` into its little-endian byte order representation.
    pub fn to_bits_le(&self) -> Vec<Boolean> {
        self.bits.clone()
    }

    /// Converts a little-endian byte order representation of bits into a
    /// `UInt64`.
    pub fn from_bits(bits: &[Boolean]) -> Self {
        assert_eq!(bits.len(), 64);

        let new_bits = bits.to_vec();

        let mut value = Some(0u64);
        for b in new_bits.iter().rev() {
            if let Some(v) = value.as_mut() {
                *v <<= 1;
            }

            match *b {
                Boolean::Constant(b) => {
                    if b {
                        if let Some(v) = value.as_mut() {
                            *v |= 1
                        }
                    }
                }
                Boolean::Is(ref b) => match b.get_value() {
                    Some(true) => {
                        if let Some(v) = value.as_mut() {
                            *v |= 1;
                        }
                    }
                    Some(false) => {}
                    None => value = None,
                },
                Boolean::Not(ref b) => match b.get_value() {
                    Some(false) => {
                        if let Some(v) = value.as_mut() {
                            *v |= 1;
                        }
                    }
                    Some(true) => {}
                    None => value = None,
                },
            }
        }

        UInt64 {
            value,
            bits: new_bits,
        }
    }
}

#[cfg(test)]
mod test {
    use super::*;

    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_uint64_from_bits_be() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..1000 {
            let v = (0..64)
                .map(|_| Boolean::constant(rng.gen()))
                .collect::<Vec<_>>();

            let b = UInt64::from_bits_be(&v);

            for (i, bit) in b.bits.iter().enumerate() {
                match bit {
                    &Boolean::Constant(bit) => {
                        assert!(bit == ((b.value.unwrap() >> i) & 1 == 1));
                    }
                    _ => unreachable!(),
                }
            }

            let expected_to_be_same = b.to_bits_be();

            for x in v.iter().zip(expected_to_be_same.iter()) {
                match x {
                    (&Boolean::Constant(true), &Boolean::Constant(true)) => {}
                    (&Boolean::Constant(false), &Boolean::Constant(false)) => {}
                    _ => unreachable!(),
                }
            }
        }
    }

    #[test]
    fn test_uint64_from_bits() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..1000 {
            let v = (0..64)
                .map(|_| Boolean::constant(rng.gen()))
                .collect::<Vec<_>>();

            let b = UInt64::from_bits(&v);

            for (i, bit) in b.bits.iter().enumerate() {
                match bit {
                    &Boolean::Constant(bit) => {
                        assert!(bit == ((b.value.unwrap() >> i) & 1 == 1));
                    }
                    _ => unreachable!(),
                }
            }

            let expected_to_be_same = b.to_bits_le();

            for x in v.iter().zip(expected_to_be_same.iter()) {
                match x {
                    (&Boolean::Constant(true), &Boolean::Constant(true)) => {}
                    (&Boolean::Constant(false), &Boolean::Constant(false)) => {}
                    _ => unreachable!(),
                }
            }
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/variables.rs ---
use std::fmt;

use anyhow::Result;

use bellperson::gadgets::num::AllocatedNum;
use bellperson::{ConstraintSystem, SynthesisError};
use paired::Engine;

/// Root represents a root commitment which may be either a raw value or an already-allocated number.
/// This allows subcomponents to depend on roots which may optionally be shared with their parent
/// or sibling components.
#[derive(Clone)]
pub enum Root<E: Engine> {
    Var(AllocatedNum<E>),
    Val(Option<E::Fr>),
}

impl<E: Engine> fmt::Debug for Root<E> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            Root::Var(num) => write!(f, "Root::Var({:?})", num.get_value()),
            Root::Val(val) => write!(f, "Root::Val({:?})", val),
        }
    }
}

impl<E: Engine> Root<E> {
    pub fn from_allocated<CS: ConstraintSystem<E>>(allocated: AllocatedNum<E>) -> Self {
        Root::Var(allocated)
    }

    pub fn allocated<CS: ConstraintSystem<E>>(
        &self,
        cs: CS,
    ) -> Result<AllocatedNum<E>, SynthesisError> {
        match self {
            Root::Var(allocated) => Ok(allocated.clone()),
            Root::Val(fr) => {
                AllocatedNum::alloc(cs, || fr.ok_or_else(|| SynthesisError::AssignmentMissing))
            }
        }
    }

    pub fn var<CS: ConstraintSystem<E>>(cs: CS, fr: E::Fr) -> Result<Self> {
        Ok(Root::Var(AllocatedNum::alloc(cs, || Ok(fr))?))
    }

    pub fn is_some(&self) -> bool {
        match self {
            Root::Var(_) => true,
            Root::Val(Some(_)) => true,
            Root::Val(None) => false,
        }
    }
}

'''
'''--- storage-proofs/core/src/gadgets/xor.rs ---
use bellperson::gadgets::boolean::Boolean;
use bellperson::{ConstraintSystem, SynthesisError};
use fil_sapling_crypto::jubjub::JubjubEngine;

pub fn xor<E, CS>(
    cs: &mut CS,
    key: &[Boolean],
    input: &[Boolean],
) -> Result<Vec<Boolean>, SynthesisError>
where
    E: JubjubEngine,
    CS: ConstraintSystem<E>,
{
    let key_len = key.len();
    assert_eq!(key_len, 32 * 8);

    input
        .iter()
        .enumerate()
        .map(|(i, byte)| {
            Boolean::xor(
                cs.namespace(|| format!("xor bit: {}", i)),
                byte,
                &key[i % key_len],
            )
        })
        .collect::<Result<Vec<_>, SynthesisError>>()
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::crypto;
    use crate::gadgets::TestConstraintSystem;
    use crate::util::{bits_to_bytes, bytes_into_boolean_vec};
    use bellperson::gadgets::boolean::Boolean;
    use bellperson::ConstraintSystem;
    use paired::bls12_381::Bls12;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_xor_input_circut() {
        let mut rng = XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 0..10 {
            let mut cs = TestConstraintSystem::<Bls12>::new();

            let key: Vec<u8> = (0..32).map(|_| rng.gen()).collect();
            let data: Vec<u8> = (0..(i + 1) * 32).map(|_| rng.gen()).collect();

            let key_bits: Vec<Boolean> = {
                let mut cs = cs.namespace(|| "key");
                bytes_into_boolean_vec(&mut cs, Some(key.as_slice()), key.len()).unwrap()
            };

            let data_bits: Vec<Boolean> = {
                let mut cs = cs.namespace(|| "data bits");
                bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), data.len()).unwrap()
            };

            let out_bits =
                xor(&mut cs, key_bits.as_slice(), data_bits.as_slice()).expect("xor failed");

            assert!(cs.is_satisfied(), "constraints not satisfied");
            assert_eq!(out_bits.len(), data_bits.len(), "invalid output length");

            // convert Vec<Boolean> to Vec<u8>
            let actual = bits_to_bytes(
                out_bits
                    .iter()
                    .map(|v| v.get_value().unwrap())
                    .collect::<Vec<bool>>()
                    .as_slice(),
            );

            let expected = crypto::xor::encode(key.as_slice(), data.as_slice()).unwrap();

            assert_eq!(expected, actual, "circuit and non circuit do not match");

            // -- roundtrip
            let roundtrip_bits = {
                let mut cs = cs.namespace(|| "roundtrip");
                xor(&mut cs, key_bits.as_slice(), out_bits.as_slice()).expect("xor faield")
            };

            let roundtrip = bits_to_bytes(
                roundtrip_bits
                    .iter()
                    .map(|v| v.get_value().unwrap())
                    .collect::<Vec<bool>>()
                    .as_slice(),
            );

            assert_eq!(data, roundtrip, "failed to roundtrip");
        }
    }
}

'''
'''--- storage-proofs/core/src/hasher/blake2s.rs ---
use std::fmt;
use std::hash::Hasher as StdHasher;

use anyhow::ensure;
use bellperson::gadgets::{blake2s as blake2s_circuit, boolean, num};
use bellperson::{ConstraintSystem, SynthesisError};
use blake2s_simd::{Hash as Blake2sHash, Params as Blake2s, State};
use ff::{Field, PrimeField, PrimeFieldRepr};
use merkletree::hash::{Algorithm, Hashable};
use merkletree::merkle::Element;
use paired::bls12_381::{Bls12, Fr, FrRepr};
use rand::RngCore;
use serde::{Deserialize, Serialize};

use super::{Domain, HashFunction, Hasher};
use crate::crypto::sloth;
use crate::error::*;
use crate::gadgets::multipack;

#[derive(Default, Copy, Clone, PartialEq, Eq, Debug)]
pub struct Blake2sHasher {}

impl Hasher for Blake2sHasher {
    type Domain = Blake2sDomain;
    type Function = Blake2sFunction;

    fn name() -> String {
        "Blake2sHasher".into()
    }

    fn sloth_encode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // TODO: validate this is how sloth should work in this case
        let k = (*key).into();
        let c = (*ciphertext).into();

        Ok(sloth::encode(&k, &c).into())
    }

    fn sloth_decode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // TODO: validate this is how sloth should work in this case
        Ok(sloth::decode(&(*key).into(), &(*ciphertext).into()).into())
    }
}

#[derive(Clone)]
pub struct Blake2sFunction(State);

impl Default for Blake2sFunction {
    fn default() -> Self {
        Blake2sFunction(Blake2s::new().hash_length(32).to_state())
    }
}

impl PartialEq for Blake2sFunction {
    fn eq(&self, other: &Self) -> bool {
        format!("{:?}", self) == format!("{:?}", other)
    }
}

impl Eq for Blake2sFunction {}

impl fmt::Debug for Blake2sFunction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "Blake2sFunction({:?})", self.0)
    }
}

impl StdHasher for Blake2sFunction {
    #[inline]
    fn write(&mut self, msg: &[u8]) {
        self.0.update(msg);
    }

    #[inline]
    fn finish(&self) -> u64 {
        unreachable!("unused by Function -- should never be called")
    }
}

#[derive(
    Copy, Clone, PartialEq, Eq, Debug, PartialOrd, Ord, Default, Serialize, Deserialize, Hash,
)]
pub struct Blake2sDomain(pub [u8; 32]);

impl AsRef<Blake2sDomain> for Blake2sDomain {
    fn as_ref(&self) -> &Self {
        self
    }
}

impl Blake2sDomain {
    pub fn trim_to_fr32(&mut self) {
        // strip last two bits, to ensure result is in Fr.
        self.0[31] &= 0b0011_1111;
    }
}

impl AsRef<[u8]> for Blake2sDomain {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl Hashable<Blake2sFunction> for Blake2sDomain {
    fn hash(&self, state: &mut Blake2sFunction) {
        state.write(self.as_ref())
    }
}

impl From<Fr> for Blake2sDomain {
    fn from(val: Fr) -> Self {
        let mut res = Self::default();
        val.into_repr().write_le(&mut res.0[0..32]).unwrap();

        res
    }
}

impl From<FrRepr> for Blake2sDomain {
    fn from(val: FrRepr) -> Self {
        let mut res = Self::default();
        val.write_le(&mut res.0[0..32]).unwrap();

        res
    }
}

impl Element for Blake2sDomain {
    fn byte_len() -> usize {
        32
    }

    fn from_slice(bytes: &[u8]) -> Self {
        match Blake2sDomain::try_from_bytes(bytes) {
            Ok(res) => res,
            Err(err) => panic!(err),
        }
    }

    fn copy_to_slice(&self, bytes: &mut [u8]) {
        bytes.copy_from_slice(&self.0);
    }
}

impl From<Blake2sDomain> for Fr {
    fn from(val: Blake2sDomain) -> Self {
        let mut res = FrRepr::default();
        res.read_le(&val.0[0..32]).unwrap();

        Fr::from_repr(res).unwrap()
    }
}

impl Domain for Blake2sDomain {
    fn into_bytes(&self) -> Vec<u8> {
        self.0.to_vec()
    }

    fn try_from_bytes(raw: &[u8]) -> Result<Self> {
        ensure!(
            raw.len() == 32 && u32::from(raw[31]) <= Fr::NUM_BITS,
            Error::InvalidInputSize
        );

        let mut res = Blake2sDomain::default();
        res.0.copy_from_slice(&raw[0..32]);
        Ok(res)
    }

    fn write_bytes(&self, dest: &mut [u8]) -> Result<()> {
        ensure!(dest.len() >= 32, Error::InvalidInputSize);
        dest[0..32].copy_from_slice(&self.0[..]);
        Ok(())
    }

    fn random<R: RngCore>(rng: &mut R) -> Self {
        // generating an Fr and converting it, to ensure we stay in the field
        Fr::random(rng).into()
    }
}

impl Into<Blake2sDomain> for Blake2sHash {
    fn into(self) -> Blake2sDomain {
        let mut res = Blake2sDomain::default();
        res.0[..].copy_from_slice(self.as_ref());
        res.trim_to_fr32();

        res
    }
}

impl HashFunction<Blake2sDomain> for Blake2sFunction {
    fn hash(data: &[u8]) -> Blake2sDomain {
        Blake2s::new()
            .hash_length(32)
            .to_state()
            .update(data)
            .finalize()
            .into()
    }

    fn hash2(a: &Blake2sDomain, b: &Blake2sDomain) -> Blake2sDomain {
        Blake2s::new()
            .hash_length(32)
            .to_state()
            .update(a.as_ref())
            .update(b.as_ref())
            .finalize()
            .into()
    }

    fn hash_multi_leaf_circuit<Arity, CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        leaves: &[num::AllocatedNum<Bls12>],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let mut bits = Vec::with_capacity(leaves.len() * Fr::CAPACITY as usize);
        for (i, leaf) in leaves.iter().enumerate() {
            bits.extend_from_slice(
                &leaf.to_bits_le(cs.namespace(|| format!("{}_num_into_bits", i)))?,
            );
            while bits.len() % 8 != 0 {
                bits.push(boolean::Boolean::Constant(false));
            }
        }
        Self::hash_circuit(cs, &bits)
    }

    fn hash_leaf_bits_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        left: &[boolean::Boolean],
        right: &[boolean::Boolean],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let mut preimage: Vec<boolean::Boolean> = vec![];

        preimage.extend_from_slice(left);
        while preimage.len() % 8 != 0 {
            preimage.push(boolean::Boolean::Constant(false));
        }

        preimage.extend_from_slice(right);
        while preimage.len() % 8 != 0 {
            preimage.push(boolean::Boolean::Constant(false));
        }

        Self::hash_circuit(cs, &preimage[..])
    }

    fn hash_circuit<CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        bits: &[boolean::Boolean],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let personalization = vec![0u8; 8];
        let alloc_bits =
            blake2s_circuit::blake2s(cs.namespace(|| "hash"), &bits[..], &personalization)?;

        multipack::pack_bits(cs.namespace(|| "pack"), &alloc_bits)
    }

    fn hash2_circuit<CS>(
        mut cs: CS,
        a_num: &num::AllocatedNum<Bls12>,
        b_num: &num::AllocatedNum<Bls12>,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        // Allocate as booleans
        let a = a_num.to_bits_le(cs.namespace(|| "a_bits"))?;
        let b = b_num.to_bits_le(cs.namespace(|| "b_bits"))?;

        let mut preimage: Vec<boolean::Boolean> = vec![];

        preimage.extend_from_slice(&a);
        while preimage.len() % 8 != 0 {
            preimage.push(boolean::Boolean::Constant(false));
        }

        preimage.extend_from_slice(&b);
        while preimage.len() % 8 != 0 {
            preimage.push(boolean::Boolean::Constant(false));
        }

        Self::hash_circuit(cs, &preimage[..])
    }
}

impl Algorithm<Blake2sDomain> for Blake2sFunction {
    #[inline]
    fn hash(&mut self) -> Blake2sDomain {
        self.0.clone().finalize().into()
    }

    #[inline]
    fn reset(&mut self) {
        self.0 = Blake2s::new().hash_length(32).to_state()
    }

    fn leaf(&mut self, leaf: Blake2sDomain) -> Blake2sDomain {
        leaf
    }

    fn node(&mut self, left: Blake2sDomain, right: Blake2sDomain, _height: usize) -> Blake2sDomain {
        left.hash(self);
        right.hash(self);
        self.hash()
    }

    fn multi_node(&mut self, parts: &[Blake2sDomain], _height: usize) -> Blake2sDomain {
        for part in parts {
            part.hash(self)
        }
        self.hash()
    }
}

impl From<[u8; 32]> for Blake2sDomain {
    #[inline]
    fn from(val: [u8; 32]) -> Self {
        Blake2sDomain(val)
    }
}

impl From<Blake2sDomain> for [u8; 32] {
    #[inline]
    fn from(val: Blake2sDomain) -> Self {
        val.0
    }
}

'''
'''--- storage-proofs/core/src/hasher/mod.rs ---
pub mod blake2s;
pub mod pedersen;
pub mod poseidon;
pub mod sha256;

pub mod types;

pub use self::blake2s::*;
pub use self::pedersen::*;
pub use self::poseidon::*;
pub use self::sha256::*;
pub use self::types::*;

'''
'''--- storage-proofs/core/src/hasher/pedersen.rs ---
use std::hash::Hasher as StdHasher;

use anyhow::ensure;
use bellperson::gadgets::{boolean, num};
use bellperson::{ConstraintSystem, SynthesisError};
use ff::{Field, PrimeField, PrimeFieldRepr};
use fil_sapling_crypto::circuit::pedersen_hash as pedersen_hash_circuit;
use fil_sapling_crypto::pedersen_hash::Personalization;
use merkletree::hash::{Algorithm as LightAlgorithm, Hashable};
use merkletree::merkle::Element;
use paired::bls12_381::{Bls12, Fr, FrRepr};
use serde::{Deserialize, Serialize};

use crate::crypto::{pedersen, sloth};
use crate::error::{Error, Result};
use crate::gadgets::pedersen::{pedersen_compression_num, pedersen_md_no_padding};
use crate::hasher::{Domain, HashFunction, Hasher};

#[derive(Default, Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct PedersenHasher {}

impl Hasher for PedersenHasher {
    type Domain = PedersenDomain;
    type Function = PedersenFunction;

    fn name() -> String {
        "PedersenHasher".into()
    }

    #[inline]
    fn sloth_encode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // Unrapping here is safe; `Fr` elements and hash domain elements are the same byte length.
        let key = Fr::from_repr(key.0)?;
        let ciphertext = Fr::from_repr(ciphertext.0)?;
        Ok(sloth::encode(&key, &ciphertext).into())
    }

    #[inline]
    fn sloth_decode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // Unrapping here is safe; `Fr` elements and hash domain elements are the same byte length.
        let key = Fr::from_repr(key.0)?;
        let ciphertext = Fr::from_repr(ciphertext.0)?;

        Ok(sloth::decode(&key, &ciphertext).into())
    }
}

#[derive(Copy, Clone, Debug, PartialEq, Eq)]
pub struct PedersenFunction(Fr);

impl Default for PedersenFunction {
    fn default() -> PedersenFunction {
        PedersenFunction(Fr::from_repr(FrRepr::default()).expect("failed default"))
    }
}

impl Hashable<PedersenFunction> for Fr {
    fn hash(&self, state: &mut PedersenFunction) {
        let mut bytes = Vec::with_capacity(32);
        self.into_repr().write_le(&mut bytes).unwrap();
        state.write(&bytes);
    }
}

impl Hashable<PedersenFunction> for PedersenDomain {
    fn hash(&self, state: &mut PedersenFunction) {
        let mut bytes = Vec::with_capacity(32);
        self.0
            .write_le(&mut bytes)
            .expect("Failed to write `FrRepr`");
        state.write(&bytes);
    }
}

#[derive(Copy, Clone, Debug, Serialize, Deserialize)]
pub struct PedersenDomain(pub FrRepr);

impl AsRef<PedersenDomain> for PedersenDomain {
    fn as_ref(&self) -> &PedersenDomain {
        self
    }
}

impl std::hash::Hash for PedersenDomain {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        let raw: &[u64] = self.0.as_ref();
        std::hash::Hash::hash(raw, state);
    }
}

impl PartialEq for PedersenDomain {
    fn eq(&self, other: &Self) -> bool {
        self.0.as_ref() == other.0.as_ref()
    }
}

impl Eq for PedersenDomain {}

impl Default for PedersenDomain {
    fn default() -> PedersenDomain {
        PedersenDomain(FrRepr::default())
    }
}

impl Ord for PedersenDomain {
    #[inline(always)]
    fn cmp(&self, other: &PedersenDomain) -> ::std::cmp::Ordering {
        (self.0).cmp(&other.0)
    }
}

impl PartialOrd for PedersenDomain {
    #[inline(always)]
    fn partial_cmp(&self, other: &PedersenDomain) -> Option<::std::cmp::Ordering> {
        Some((self.0).cmp(&other.0))
    }
}

impl AsRef<[u8]> for PedersenDomain {
    #[inline]
    fn as_ref(&self) -> &[u8] {
        as_ref(&(self.0).0)
    }
}

// This is unsafe, and I wish it wasn't here, but I really need AsRef<[u8]> to work, without allocating.
// https://internals.rust-lang.org/t/safe-trasnsmute-for-slices-e-g-u64-u32-particularly-simd-types/2871
// https://github.com/briansmith/ring/blob/abb3fdfc08562f3f02e95fb551604a871fd4195e/src/polyfill.rs#L93-L110
#[inline(always)]
#[allow(clippy::needless_lifetimes)]
fn as_ref<'a>(src: &'a [u64; 4]) -> &'a [u8] {
    unsafe {
        std::slice::from_raw_parts(
            src.as_ptr() as *const u8,
            src.len() * std::mem::size_of::<u64>(),
        )
    }
}

impl Domain for PedersenDomain {
    fn into_bytes(&self) -> Vec<u8> {
        let mut out = Vec::with_capacity(PedersenDomain::byte_len());
        self.0.write_le(&mut out).unwrap();

        out
    }

    fn try_from_bytes(raw: &[u8]) -> Result<Self> {
        ensure!(raw.len() == PedersenDomain::byte_len(), Error::BadFrBytes);
        let mut res: FrRepr = Default::default();
        res.read_le(raw)?;

        Ok(PedersenDomain(res))
    }

    fn write_bytes(&self, dest: &mut [u8]) -> Result<()> {
        self.0.write_le(dest)?;
        Ok(())
    }

    fn random<R: rand::RngCore>(rng: &mut R) -> Self {
        // generating an Fr and converting it, to ensure we stay in the field
        Fr::random(rng).into()
    }
}

impl Element for PedersenDomain {
    fn byte_len() -> usize {
        32
    }

    fn from_slice(bytes: &[u8]) -> Self {
        PedersenDomain::try_from_bytes(bytes).expect("invalid bytes")
    }

    fn copy_to_slice(&self, bytes: &mut [u8]) {
        bytes.copy_from_slice(&self.into_bytes());
    }
}

impl StdHasher for PedersenFunction {
    #[inline]
    fn write(&mut self, msg: &[u8]) {
        self.0 = pedersen::pedersen(msg);
    }

    #[inline]
    fn finish(&self) -> u64 {
        unimplemented!()
    }
}

impl HashFunction<PedersenDomain> for PedersenFunction {
    fn hash(data: &[u8]) -> PedersenDomain {
        pedersen::pedersen_md_no_padding(data).into()
    }

    fn hash2(a: &PedersenDomain, b: &PedersenDomain) -> PedersenDomain {
        let data = NodeBits::new(&(a.0).0[..], &(b.0).0[..]);

        let digest = if cfg!(target_arch = "x86_64") {
            use fil_sapling_crypto::pedersen_hash::pedersen_hash_bls12_381_with_precomp;
            pedersen_hash_bls12_381_with_precomp::<_>(
                Personalization::None,
                data,
                &pedersen::JJ_PARAMS,
            )
        } else {
            use fil_sapling_crypto::pedersen_hash::pedersen_hash;
            pedersen_hash::<Bls12, _>(Personalization::None, data, &pedersen::JJ_PARAMS)
        };
        digest.into_xy().0.into()
    }

    fn hash_multi_leaf_circuit<Arity, CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        leaves: &[num::AllocatedNum<Bls12>],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let is_binary = leaves.len() == 2;

        let mut bits = Vec::with_capacity(leaves.len() * Fr::CAPACITY as usize);
        for (i, leaf) in leaves.iter().enumerate() {
            bits.extend_from_slice(
                &leaf.to_bits_le(cs.namespace(|| format!("{}_num_into_bits", i)))?,
            );
            if !is_binary {
                while bits.len() % 8 != 0 {
                    bits.push(boolean::Boolean::Constant(false));
                }
            }
        }

        if is_binary {
            Ok(pedersen_hash_circuit::pedersen_hash(
                cs,
                Personalization::None,
                &bits,
                &*pedersen::JJ_PARAMS,
            )?
            .get_x()
            .clone())
        } else {
            Self::hash_circuit(cs, &bits)
        }
    }

    fn hash_leaf_bits_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        left: &[boolean::Boolean],
        right: &[boolean::Boolean],
        _height: usize,
    ) -> ::std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let mut preimage: Vec<boolean::Boolean> = vec![];
        preimage.extend_from_slice(left);
        preimage.extend_from_slice(right);

        Ok(pedersen_hash_circuit::pedersen_hash(
            cs,
            Personalization::None,
            &preimage,
            &*pedersen::JJ_PARAMS,
        )?
        .get_x()
        .clone())
    }

    fn hash_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        bits: &[boolean::Boolean],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        pedersen_md_no_padding(cs, bits)
    }

    fn hash2_circuit<CS>(
        mut cs: CS,
        a_num: &num::AllocatedNum<Bls12>,
        b_num: &num::AllocatedNum<Bls12>,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        // Allocate as booleans
        let a = a_num.to_bits_le(cs.namespace(|| "a_bits"))?;
        let b = b_num.to_bits_le(cs.namespace(|| "b_bits"))?;

        let mut values = Vec::new();
        values.extend_from_slice(&a);
        values.extend_from_slice(&b);

        if values.is_empty() {
            // can happen with small layers
            num::AllocatedNum::alloc(cs.namespace(|| "pedersen_hash1"), || Ok(Fr::zero()))
        } else {
            pedersen_compression_num(cs.namespace(|| "pedersen_hash1"), &values)
        }
    }
}

impl LightAlgorithm<PedersenDomain> for PedersenFunction {
    #[inline]
    fn hash(&mut self) -> PedersenDomain {
        self.0.into()
    }

    #[inline]
    fn reset(&mut self) {
        self.0 = Fr::from_repr(FrRepr::from(0)).expect("failed 0");
    }

    fn leaf(&mut self, leaf: PedersenDomain) -> PedersenDomain {
        leaf
    }

    fn node(
        &mut self,
        left: PedersenDomain,
        right: PedersenDomain,
        _height: usize,
    ) -> PedersenDomain {
        let node_bits = NodeBits::new(&(left.0).0[..], &(right.0).0[..]);

        let digest = if cfg!(target_arch = "x86_64") {
            use fil_sapling_crypto::pedersen_hash::pedersen_hash_bls12_381_with_precomp;
            pedersen_hash_bls12_381_with_precomp::<_>(
                Personalization::None,
                node_bits,
                &pedersen::JJ_PARAMS,
            )
        } else {
            use fil_sapling_crypto::pedersen_hash::pedersen_hash;
            pedersen_hash::<Bls12, _>(Personalization::None, node_bits, &pedersen::JJ_PARAMS)
        };

        digest.into_xy().0.into()
    }

    fn multi_node(&mut self, parts: &[PedersenDomain], height: usize) -> PedersenDomain {
        match parts.len() {
            2 => self.node(parts[0], parts[1], height),
            _ => {
                use crate::crypto::pedersen::*;

                pedersen_md_no_padding_bits(Bits::new_many(parts.iter())).into()
            }
        }
    }
}

/// Helper to iterate over a pair of `Fr`.
struct NodeBits<'a> {
    // 256 bits
    lhs: &'a [u64],
    // 256 bits
    rhs: &'a [u64],
    index: usize,
}

impl<'a> NodeBits<'a> {
    pub fn new(lhs: &'a [u64], rhs: &'a [u64]) -> Self {
        NodeBits { lhs, rhs, index: 0 }
    }
}

impl<'a> Iterator for NodeBits<'a> {
    type Item = bool;

    #[inline]
    fn next(&mut self) -> Option<Self::Item> {
        if self.index < 255 {
            // return lhs
            let a = self.index / 64;
            let b = self.index % 64;
            let res = (self.lhs[a] & (1 << b)) != 0;
            self.index += 1;
            return Some(res);
        }

        if self.index < 2 * 255 {
            // return rhs
            let a = (self.index - 255) / 64;
            let b = (self.index - 255) % 64;
            let res = (self.rhs[a] & (1 << b)) != 0;
            self.index += 1;
            return Some(res);
        }

        None
    }
}

impl From<Fr> for PedersenDomain {
    #[inline]
    fn from(val: Fr) -> Self {
        PedersenDomain(val.into_repr())
    }
}

impl From<FrRepr> for PedersenDomain {
    #[inline]
    fn from(val: FrRepr) -> Self {
        PedersenDomain(val)
    }
}

impl From<PedersenDomain> for Fr {
    #[inline]
    fn from(val: PedersenDomain) -> Self {
        Fr::from_repr(val.0).unwrap()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::mem;

    // use merkletree::hash::Hashable;

    // use crate::merkle::BinaryMerkleTree;

    // These two tests need to be rewritten not to use from_data, or from_data needs to be fixed to not hash its contents
    // before it is restored to MerkleTreeTrait.
    // #[test]
    // fn test_path() {
    //     let values = ["hello", "world", "you", "two"];
    //     let t = BinaryMerkleTree::<PedersenHasher>::from_data(values.iter()).unwrap();

    //     let p = t.gen_proof(0).unwrap(); // create a proof for the first value = "hello"
    //     assert_eq!(*p.path(), vec![0, 0]);
    //     assert_eq!(
    //         p.validate::<PedersenFunction>()
    //             .expect("failed to validate"),
    //         true
    //     );
    // }

    // #[test]
    // fn test_pedersen_hasher() {
    //     let values = ["hello", "world", "you", "two"];

    //     let t = BinaryMerkleTree::<PedersenHasher>::from_data(values.iter()).unwrap();

    //     assert_eq!(t.leafs(), 4);

    //     let mut a = PedersenFunction::default();
    //     let leaves: Vec<PedersenDomain> = values
    //         .iter()
    //         .map(|v| {
    //             v.hash(&mut a);
    //             let h = a.hash();
    //             a.reset();
    //             h
    //         })
    //         .collect();

    //     assert_eq!(t.read_at(0).unwrap(), leaves[0]);
    //     assert_eq!(t.read_at(1).unwrap(), leaves[1]);
    //     assert_eq!(t.read_at(2).unwrap(), leaves[2]);
    //     assert_eq!(t.read_at(3).unwrap(), leaves[3]);

    //     let i1 = a.node(leaves[0], leaves[1], 0);
    //     a.reset();
    //     let i2 = a.node(leaves[2], leaves[3], 0);
    //     a.reset();

    //     assert_eq!(t.read_at(4).unwrap(), i1);
    //     assert_eq!(t.read_at(5).unwrap(), i2);

    //     let root = a.node(i1, i2, 1);
    //     a.reset();

    //     assert_eq!(
    //         t.read_at(0).unwrap().0,
    //         FrRepr([
    //             8141980337328041169,
    //             4041086031096096197,
    //             4135265344031344584,
    //             7650472305044950055
    //         ])
    //     );

    //     let expected = FrRepr([
    //         11371136130239400769,
    //         4290566175630177573,
    //         11576422143286805197,
    //         2687080719931344767,
    //     ]);
    //     let actual = t.read_at(6).unwrap().0;

    //     assert_eq!(actual, expected);
    //     assert_eq!(t.read_at(6).unwrap(), root);
    // }

    #[test]
    fn test_as_ref() {
        let cases: Vec<[u64; 4]> = vec![
            [0, 0, 0, 0],
            [
                14963070332212552755,
                2414807501862983188,
                16116531553419129213,
                6357427774790868134,
            ],
        ];

        for case in cases.into_iter() {
            let repr = FrRepr(case);
            let val = PedersenDomain(repr);

            for _ in 0..100 {
                assert_eq!(val.into_bytes(), val.into_bytes());
            }

            let raw: &[u8] = val.as_ref();

            for i in 0..4 {
                assert_eq!(case[i], unsafe {
                    let mut val = [0u8; 8];
                    val.clone_from_slice(&raw[i * 8..(i + 1) * 8]);
                    mem::transmute::<[u8; 8], u64>(val)
                });
            }
        }
    }

    #[test]
    fn test_serialize() {
        let repr = FrRepr([1, 2, 3, 4]);
        let val = PedersenDomain(repr);

        let ser = serde_json::to_string(&val)
            .expect("Failed to serialize `PedersenDomain` element to JSON string");
        let val_back = serde_json::from_str(&ser)
            .expect("Failed to deserialize JSON string to `PedersenDomain`");

        assert_eq!(val, val_back);
    }
}

'''
'''--- storage-proofs/core/src/hasher/poseidon.rs ---
use std::hash::Hasher as StdHasher;

use crate::crypto::sloth;
use crate::error::{Error, Result};
use crate::hasher::types::{
    PoseidonArity, PoseidonMDArity, POSEIDON_CONSTANTS_16, POSEIDON_CONSTANTS_2,
    POSEIDON_CONSTANTS_4, POSEIDON_CONSTANTS_8, POSEIDON_MD_CONSTANTS,
};
use crate::hasher::{Domain, HashFunction, Hasher};
use anyhow::ensure;
use bellperson::gadgets::{boolean, num};
use bellperson::{ConstraintSystem, SynthesisError};
use ff::{Field, PrimeField, PrimeFieldRepr, ScalarEngine};
use generic_array::typenum;
use generic_array::typenum::marker_traits::Unsigned;
use merkletree::hash::{Algorithm as LightAlgorithm, Hashable};
use merkletree::merkle::Element;
use neptune::circuit::poseidon_hash;
use neptune::poseidon::Poseidon;
use paired::bls12_381::{Bls12, Fr, FrRepr};
use serde::{Deserialize, Serialize};

#[derive(Default, Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct PoseidonHasher {}

impl Hasher for PoseidonHasher {
    type Domain = PoseidonDomain;
    type Function = PoseidonFunction;

    fn name() -> String {
        "poseidon_hasher".into()
    }

    #[inline]
    fn sloth_encode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // Unrapping here is safe; `Fr` elements and hash domain elements are the same byte length.
        let key = Fr::from_repr(key.0)?;
        let ciphertext = Fr::from_repr(ciphertext.0)?;
        Ok(sloth::encode(&key, &ciphertext).into())
    }

    #[inline]
    fn sloth_decode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // Unrapping here is safe; `Fr` elements and hash domain elements are the same byte length.
        let key = Fr::from_repr(key.0)?;
        let ciphertext = Fr::from_repr(ciphertext.0)?;

        Ok(sloth::decode(&key, &ciphertext).into())
    }
}

#[derive(Copy, Clone, Debug, PartialEq, Eq)]
pub struct PoseidonFunction(Fr);

impl Default for PoseidonFunction {
    fn default() -> PoseidonFunction {
        PoseidonFunction(Fr::from_repr(FrRepr::default()).expect("failed default"))
    }
}

impl Hashable<PoseidonFunction> for Fr {
    fn hash(&self, state: &mut PoseidonFunction) {
        let mut bytes = Vec::with_capacity(32);
        self.into_repr().write_le(&mut bytes).unwrap();
        state.write(&bytes);
    }
}

impl Hashable<PoseidonFunction> for PoseidonDomain {
    fn hash(&self, state: &mut PoseidonFunction) {
        let mut bytes = Vec::with_capacity(32);
        self.0
            .write_le(&mut bytes)
            .expect("Failed to write `FrRepr`");
        state.write(&bytes);
    }
}

#[derive(Copy, Clone, Debug, Serialize, Deserialize)]
pub struct PoseidonDomain(pub FrRepr);

impl AsRef<PoseidonDomain> for PoseidonDomain {
    fn as_ref(&self) -> &PoseidonDomain {
        self
    }
}

impl std::hash::Hash for PoseidonDomain {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        let raw: &[u64] = self.0.as_ref();
        std::hash::Hash::hash(raw, state);
    }
}

impl PartialEq for PoseidonDomain {
    fn eq(&self, other: &Self) -> bool {
        self.0.as_ref() == other.0.as_ref()
    }
}

impl Eq for PoseidonDomain {}

impl Default for PoseidonDomain {
    fn default() -> PoseidonDomain {
        PoseidonDomain(FrRepr::default())
    }
}

impl Ord for PoseidonDomain {
    #[inline(always)]
    fn cmp(&self, other: &PoseidonDomain) -> ::std::cmp::Ordering {
        (self.0).cmp(&other.0)
    }
}

impl PartialOrd for PoseidonDomain {
    #[inline(always)]
    fn partial_cmp(&self, other: &PoseidonDomain) -> Option<::std::cmp::Ordering> {
        Some((self.0).cmp(&other.0))
    }
}

impl AsRef<[u8]> for PoseidonDomain {
    #[inline]
    fn as_ref(&self) -> &[u8] {
        as_ref(&(self.0).0)
    }
}

// This is unsafe, and I wish it wasn't here, but I really need AsRef<[u8]> to work, without allocating.
// https://internals.rust-lang.org/t/safe-trasnsmute-for-slices-e-g-u64-u32-particularly-simd-types/2871
// https://github.com/briansmith/ring/blob/abb3fdfc08562f3f02e95fb551604a871fd4195e/src/polyfill.rs#L93-L110
#[inline(always)]
#[allow(clippy::needless_lifetimes)]
fn as_ref<'a>(src: &'a [u64; 4]) -> &'a [u8] {
    unsafe {
        std::slice::from_raw_parts(
            src.as_ptr() as *const u8,
            src.len() * std::mem::size_of::<u64>(),
        )
    }
}

impl Domain for PoseidonDomain {
    fn into_bytes(&self) -> Vec<u8> {
        let mut out = Vec::with_capacity(PoseidonDomain::byte_len());
        self.0.write_le(&mut out).unwrap();

        out
    }

    fn try_from_bytes(raw: &[u8]) -> Result<Self> {
        ensure!(raw.len() == PoseidonDomain::byte_len(), Error::BadFrBytes);
        let mut res: FrRepr = Default::default();
        res.read_le(raw)?;

        Ok(PoseidonDomain(res))
    }

    fn write_bytes(&self, dest: &mut [u8]) -> Result<()> {
        self.0.write_le(dest)?;
        Ok(())
    }

    fn random<R: rand::RngCore>(rng: &mut R) -> Self {
        // generating an Fr and converting it, to ensure we stay in the field
        Fr::random(rng).into()
    }
}

impl Element for PoseidonDomain {
    fn byte_len() -> usize {
        32
    }

    fn from_slice(bytes: &[u8]) -> Self {
        match PoseidonDomain::try_from_bytes(bytes) {
            Ok(res) => res,
            Err(err) => panic!(err),
        }
    }

    fn copy_to_slice(&self, bytes: &mut [u8]) {
        bytes.copy_from_slice(&self.into_bytes());
    }
}

impl StdHasher for PoseidonFunction {
    #[inline]
    fn write(&mut self, msg: &[u8]) {
        self.0 = Fr::from_repr(shared_hash(msg).0).unwrap();
    }

    #[inline]
    fn finish(&self) -> u64 {
        unimplemented!()
    }
}

fn shared_hash(data: &[u8]) -> PoseidonDomain {
    // FIXME: We shouldn't unwrap here, but doing otherwise will require an interface change.
    // We could truncate so `bytes_into_frs` cannot fail, then ensure `data` is always `fr_safe`.
    let preimage = data
        .chunks(32)
        .map(|ref chunk| {
            <Bls12 as ff::ScalarEngine>::Fr::from_repr(PoseidonDomain::from_slice(chunk).0).unwrap()
        })
        .collect::<Vec<_>>();

    shared_hash_frs(&preimage).into()
}

fn shared_hash_frs(
    preimage: &[<Bls12 as ff::ScalarEngine>::Fr],
) -> <Bls12 as ff::ScalarEngine>::Fr {
    match preimage.len() {
        2 => {
            let mut p = Poseidon::new_with_preimage(&preimage, &POSEIDON_CONSTANTS_2);
            p.hash()
        }
        4 => {
            let mut p = Poseidon::new_with_preimage(&preimage, &POSEIDON_CONSTANTS_4);
            p.hash()
        }
        8 => {
            let mut p = Poseidon::new_with_preimage(&preimage, &POSEIDON_CONSTANTS_8);
            p.hash()
        }
        16 => {
            let mut p = Poseidon::new_with_preimage(&preimage, &POSEIDON_CONSTANTS_16);
            p.hash()
        }

        _ => panic!("Unsupported arity for Poseidon hasher: {}", preimage.len()),
    }
}

impl HashFunction<PoseidonDomain> for PoseidonFunction {
    fn hash(data: &[u8]) -> PoseidonDomain {
        shared_hash(data)
    }

    fn hash2(a: &PoseidonDomain, b: &PoseidonDomain) -> PoseidonDomain {
        let mut p =
            Poseidon::new_with_preimage(&[(*a).into(), (*b).into()][..], &*POSEIDON_CONSTANTS_2);
        let fr: <Bls12 as ScalarEngine>::Fr = p.hash();
        fr.into()
    }

    fn hash_md(input: &[PoseidonDomain]) -> PoseidonDomain {
        assert!(input.len() > 1, "hash_md needs more than one element.");
        let arity = PoseidonMDArity::to_usize();

        let mut p = Poseidon::new(&*POSEIDON_MD_CONSTANTS);

        let fr_input = input
            .iter()
            .map(|x| <Bls12 as ScalarEngine>::Fr::from_repr(x.0).unwrap())
            .collect::<Vec<_>>();

        fr_input[1..]
            .chunks(arity - 1)
            .fold(fr_input[0], |acc, elts| {
                p.reset();
                p.input(acc).unwrap(); // These unwraps will panic iff arity is incorrect, but it was checked above.
                elts.iter().for_each(|elt| {
                    let _ = p.input(*elt).unwrap();
                });
                p.hash()
            })
            .into()
    }

    fn hash_leaf_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        left: &num::AllocatedNum<Bls12>,
        right: &num::AllocatedNum<Bls12>,
        _height: usize,
    ) -> ::std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let preimage = vec![left.clone(), right.clone()];

        poseidon_hash::<CS, Bls12, typenum::U2>(cs, preimage, typenum::U2::PARAMETERS())
    }

    fn hash_multi_leaf_circuit<Arity: 'static + PoseidonArity, CS: ConstraintSystem<Bls12>>(
        cs: CS,
        leaves: &[num::AllocatedNum<Bls12>],
        _height: usize,
    ) -> ::std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let params = Arity::PARAMETERS();
        poseidon_hash::<CS, Bls12, Arity>(cs, leaves.to_vec(), params)
    }

    fn hash_md_circuit<CS: ConstraintSystem<Bls12>>(
        cs: &mut CS,
        elements: &[num::AllocatedNum<Bls12>],
    ) -> ::std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let params = PoseidonMDArity::PARAMETERS();
        let arity = PoseidonMDArity::to_usize();

        let mut hash = elements[0].clone();
        let mut preimage = vec![hash.clone(); arity]; // Allocate. This will be overwritten.
        let mut hash_num = 0;
        for elts in elements[1..].chunks(arity - 1) {
            preimage[0] = hash;
            for (i, elt) in elts.iter().enumerate() {
                preimage[i + 1] = elt.clone();
            }
            // any terminal padding
            #[allow(clippy::needless_range_loop)]
            for i in (elts.len() + 1)..arity {
                preimage[i] =
                    num::AllocatedNum::alloc(cs.namespace(|| format!("padding {}", i)), || {
                        Ok(Fr::zero())
                    })
                    .unwrap();
            }
            let cs = cs.namespace(|| format!("hash md {}", hash_num));
            hash =
                poseidon_hash::<_, Bls12, PoseidonMDArity>(cs, preimage.clone(), params)?.clone();
            hash_num += 1;
        }

        Ok(hash)
    }

    fn hash_circuit<CS: ConstraintSystem<Bls12>>(
        _cs: CS,
        _bits: &[boolean::Boolean],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        unimplemented!();
    }

    fn hash2_circuit<CS>(
        cs: CS,
        a: &num::AllocatedNum<Bls12>,
        b: &num::AllocatedNum<Bls12>,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        let preimage = vec![a.clone(), b.clone()];
        poseidon_hash::<CS, Bls12, typenum::U2>(cs, preimage, typenum::U2::PARAMETERS())
    }
}

impl LightAlgorithm<PoseidonDomain> for PoseidonFunction {
    #[inline]
    fn hash(&mut self) -> PoseidonDomain {
        self.0.into()
    }

    #[inline]
    fn reset(&mut self) {
        self.0 = Fr::from_repr(FrRepr::from(0)).expect("failed 0");
    }

    fn leaf(&mut self, leaf: PoseidonDomain) -> PoseidonDomain {
        leaf
    }

    fn node(
        &mut self,
        left: PoseidonDomain,
        right: PoseidonDomain,
        _height: usize,
    ) -> PoseidonDomain {
        shared_hash_frs(&[
            <Bls12 as ff::ScalarEngine>::Fr::from_repr(left.0).unwrap(),
            <Bls12 as ff::ScalarEngine>::Fr::from_repr(right.0).unwrap(),
        ])
        .into()
    }

    fn multi_node(&mut self, parts: &[PoseidonDomain], _height: usize) -> PoseidonDomain {
        match parts.len() {
            1 | 2 | 4 | 8 | 16 => shared_hash_frs(
                &parts
                    .iter()
                    .map(|x| <Bls12 as ff::ScalarEngine>::Fr::from_repr(x.0).unwrap())
                    .collect::<Vec<_>>(),
            )
            .into(),
            arity => panic!("unsupported arity {}", arity),
        }
    }
}

impl From<Fr> for PoseidonDomain {
    #[inline]
    fn from(val: Fr) -> Self {
        PoseidonDomain(val.into_repr())
    }
}

impl From<FrRepr> for PoseidonDomain {
    #[inline]
    fn from(val: FrRepr) -> Self {
        PoseidonDomain(val)
    }
}

impl From<PoseidonDomain> for Fr {
    #[inline]
    fn from(val: PoseidonDomain) -> Self {
        Fr::from_repr(val.0).unwrap()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::mem;

    use crate::gadgets::{constraint, TestConstraintSystem};
    use crate::merkle::MerkleTree;
    use bellperson::gadgets::num;

    #[test]
    fn test_path() {
        let values = [
            PoseidonDomain(Fr::one().into_repr()),
            PoseidonDomain(Fr::one().into_repr()),
            PoseidonDomain(Fr::one().into_repr()),
            PoseidonDomain(Fr::one().into_repr()),
        ];

        let t = MerkleTree::<PoseidonHasher, typenum::U2>::new(values.iter().map(|x| *x)).unwrap();

        let p = t.gen_proof(0).unwrap(); // create a proof for the first value =k Fr::one()

        assert_eq!(*p.path(), vec![0, 0]);
        assert_eq!(
            p.validate::<PoseidonFunction>()
                .expect("failed to validate"),
            true
        );
    }

    // #[test]
    // fn test_poseidon_quad() {
    //     let leaves = [Fr::one(), Fr::zero(), Fr::zero(), Fr::one()];

    //     assert_eq!(Fr::zero().into_repr(), shared_hash_frs(&leaves[..]).0);
    // }

    #[test]
    fn test_poseidon_hasher() {
        let leaves = [
            PoseidonDomain(Fr::one().into_repr()),
            PoseidonDomain(Fr::zero().into_repr()),
            PoseidonDomain(Fr::zero().into_repr()),
            PoseidonDomain(Fr::one().into_repr()),
        ];

        let t = MerkleTree::<PoseidonHasher, typenum::U2>::new(leaves.iter().map(|x| *x)).unwrap();

        assert_eq!(t.leafs(), 4);

        let mut a = PoseidonFunction::default();

        assert_eq!(t.read_at(0).unwrap(), leaves[0]);
        assert_eq!(t.read_at(1).unwrap(), leaves[1]);
        assert_eq!(t.read_at(2).unwrap(), leaves[2]);
        assert_eq!(t.read_at(3).unwrap(), leaves[3]);

        let i1 = a.node(leaves[0], leaves[1], 0);
        a.reset();
        let i2 = a.node(leaves[2], leaves[3], 0);
        a.reset();

        assert_eq!(t.read_at(4).unwrap(), i1);
        assert_eq!(t.read_at(5).unwrap(), i2);

        let root = a.node(i1, i2, 1);
        a.reset();

        assert_eq!(
            t.read_at(4).unwrap().0,
            FrRepr([
                0xf8a4092bef029be0,
                0x2deffc4feff5a3e0,
                0x60949ee3e7f39a7d,
                0x2df335798cd6ce2e
            ])
        );

        let expected = FrRepr([
            0x7f422271ae4eac64,
            0x767b7565e9472cdd,
            0x0354271e16d4c223,
            0x5acce8e6359804c0,
        ]);
        let actual = t.read_at(6).unwrap().0;

        assert_eq!(actual, expected);
        assert_eq!(t.read_at(6).unwrap(), root);
    }

    #[test]
    fn test_as_ref() {
        let cases: Vec<[u64; 4]> = vec![
            [0, 0, 0, 0],
            [
                14963070332212552755,
                2414807501862983188,
                16116531553419129213,
                6357427774790868134,
            ],
        ];

        for case in cases.into_iter() {
            let repr = FrRepr(case);
            let val = PoseidonDomain(repr);

            for _ in 0..100 {
                assert_eq!(val.into_bytes(), val.into_bytes());
            }

            let raw: &[u8] = val.as_ref();

            for i in 0..4 {
                assert_eq!(case[i], unsafe {
                    let mut val = [0u8; 8];
                    val.clone_from_slice(&raw[i * 8..(i + 1) * 8]);
                    mem::transmute::<[u8; 8], u64>(val)
                });
            }
        }
    }

    #[test]
    fn test_serialize() {
        let repr = FrRepr([1, 2, 3, 4]);
        let val = PoseidonDomain(repr);

        let ser = serde_json::to_string(&val)
            .expect("Failed to serialize `PoseidonDomain` element to JSON string");
        let val_back = serde_json::from_str(&ser)
            .expect("Failed to deserialize JSON string to `PoseidonnDomain`");

        assert_eq!(val, val_back);
    }

    #[test]
    fn test_hash_md() {
        // let arity = PoseidonMDArity::to_usize();
        let n = 71;
        let data = vec![PoseidonDomain(Fr::one().into_repr()); n];
        let hashed = PoseidonFunction::hash_md(&data);

        assert_eq!(
            hashed,
            PoseidonDomain(FrRepr([
                0x23ff11d2d2a54e3a,
                0x1393376e3c10d281,
                0xca9aed2681cc9081,
                0x04f01dc7b8b9b562
            ]))
        );
    }
    #[test]
    fn test_hash_md_circuit() {
        // let arity = PoseidonMDArity::to_usize();
        let n = 71;
        let data = vec![PoseidonDomain(Fr::one().into_repr()); n];

        let mut cs = TestConstraintSystem::<Bls12>::new();
        let circuit_data = (0..n)
            .map(|n| {
                num::AllocatedNum::alloc(cs.namespace(|| format!("input {}", n)), || Ok(Fr::one()))
                    .unwrap()
            })
            .collect::<Vec<_>>();

        let hashed = PoseidonFunction::hash_md(&data);
        let hashed_fr = Fr::from_repr(hashed.0).unwrap();

        let circuit_hashed =
            PoseidonFunction::hash_md_circuit(&mut cs, circuit_data.as_slice()).unwrap();
        let hashed_alloc =
            &num::AllocatedNum::alloc(cs.namespace(|| "calculated"), || Ok(hashed_fr)).unwrap();
        constraint::equal(
            &mut cs.namespace(|| "enforce correct"),
            || "correct result",
            &hashed_alloc,
            &circuit_hashed,
        );

        assert!(cs.is_satisfied());
        let expected_constraints = 2_777;
        let actual_constraints = cs.num_constraints();

        assert_eq!(expected_constraints, actual_constraints);

        assert_eq!(hashed_fr, circuit_hashed.get_value().unwrap());
    }
}

'''
'''--- storage-proofs/core/src/hasher/sha256.rs ---
use std::hash::Hasher as StdHasher;

use anyhow::ensure;
use bellperson::gadgets::{boolean, num, sha256::sha256 as sha256_circuit};
use bellperson::{ConstraintSystem, SynthesisError};
use ff::{Field, PrimeField, PrimeFieldRepr};
use merkletree::hash::{Algorithm, Hashable};
use merkletree::merkle::Element;
use paired::bls12_381::{Bls12, Fr, FrRepr};
use rand::RngCore;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

use super::{Domain, HashFunction, Hasher};
use crate::crypto::sloth;
use crate::error::*;
use crate::gadgets::multipack;

#[derive(Default, Copy, Clone, Debug, PartialEq, Eq)]
pub struct Sha256Hasher {}

impl Hasher for Sha256Hasher {
    type Domain = Sha256Domain;
    type Function = Sha256Function;

    fn name() -> String {
        "sha256_hasher".into()
    }

    fn sloth_encode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // TODO: validate this is how sloth should work in this case
        let k = (*key).into();
        let c = (*ciphertext).into();

        Ok(sloth::encode(&k, &c).into())
    }

    fn sloth_decode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain> {
        // TODO: validate this is how sloth should work in this case
        Ok(sloth::decode(&(*key).into(), &(*ciphertext).into()).into())
    }
}

#[derive(Default, Clone, Debug)]
pub struct Sha256Function(Sha256);

impl StdHasher for Sha256Function {
    #[inline]
    fn write(&mut self, msg: &[u8]) {
        self.0.input(msg)
    }

    #[inline]
    fn finish(&self) -> u64 {
        unreachable!("unused by Function -- should never be called")
    }
}

#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Default, Serialize, Deserialize, Hash)]
pub struct Sha256Domain(pub [u8; 32]);

impl std::fmt::Debug for Sha256Domain {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "Sha256Domain({})", hex::encode(&self.0))
    }
}

impl AsRef<Sha256Domain> for Sha256Domain {
    fn as_ref(&self) -> &Self {
        self
    }
}

impl Sha256Domain {
    fn trim_to_fr32(&mut self) {
        // strip last two bits, to ensure result is in Fr.
        self.0[31] &= 0b0011_1111;
    }
}

impl AsRef<[u8]> for Sha256Domain {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl Hashable<Sha256Function> for Sha256Domain {
    fn hash(&self, state: &mut Sha256Function) {
        state.write(self.as_ref())
    }
}

impl From<Fr> for Sha256Domain {
    fn from(val: Fr) -> Self {
        let mut res = Self::default();
        val.into_repr().write_le(&mut res.0[0..32]).unwrap();

        res
    }
}

impl From<FrRepr> for Sha256Domain {
    fn from(val: FrRepr) -> Self {
        let mut res = Self::default();
        val.write_le(&mut res.0[0..32]).unwrap();

        res
    }
}

impl From<Sha256Domain> for Fr {
    fn from(val: Sha256Domain) -> Self {
        let mut res = FrRepr::default();
        res.read_le(&val.0[0..32]).unwrap();

        Fr::from_repr(res).unwrap()
    }
}

impl Domain for Sha256Domain {
    fn into_bytes(&self) -> Vec<u8> {
        self.0.to_vec()
    }

    fn try_from_bytes(raw: &[u8]) -> Result<Self> {
        ensure!(
            raw.len() == Sha256Domain::byte_len(),
            Error::InvalidInputSize
        );

        let mut res = Sha256Domain::default();
        res.0.copy_from_slice(&raw[0..Sha256Domain::byte_len()]);
        Ok(res)
    }

    fn write_bytes(&self, dest: &mut [u8]) -> Result<()> {
        ensure!(
            dest.len() >= Sha256Domain::byte_len(),
            Error::InvalidInputSize
        );

        dest[0..Sha256Domain::byte_len()].copy_from_slice(&self.0[..]);
        Ok(())
    }

    fn random<R: RngCore>(rng: &mut R) -> Self {
        // generating an Fr and converting it, to ensure we stay in the field
        Fr::random(rng).into()
    }
}

impl Element for Sha256Domain {
    fn byte_len() -> usize {
        32
    }

    fn from_slice(bytes: &[u8]) -> Self {
        match Sha256Domain::try_from_bytes(bytes) {
            Ok(res) => res,
            Err(err) => panic!(err),
        }
    }

    fn copy_to_slice(&self, bytes: &mut [u8]) {
        bytes.copy_from_slice(&self.0);
    }
}

impl HashFunction<Sha256Domain> for Sha256Function {
    fn hash(data: &[u8]) -> Sha256Domain {
        let hashed = Sha256::digest(data);
        let mut res = Sha256Domain::default();
        res.0.copy_from_slice(&hashed[..]);
        res.trim_to_fr32();
        res
    }

    fn hash2(a: &Sha256Domain, b: &Sha256Domain) -> Sha256Domain {
        let hashed = Sha256::new()
            .chain(AsRef::<[u8]>::as_ref(a))
            .chain(AsRef::<[u8]>::as_ref(b))
            .result();
        let mut res = Sha256Domain::default();
        res.0.copy_from_slice(&hashed[..]);
        res.trim_to_fr32();
        res
    }

    fn hash_multi_leaf_circuit<Arity, CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        leaves: &[num::AllocatedNum<Bls12>],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let mut bits = Vec::with_capacity(leaves.len() * Fr::CAPACITY as usize);
        for (i, leaf) in leaves.iter().enumerate() {
            let mut padded = leaf.to_bits_le(cs.namespace(|| format!("{}_num_into_bits", i)))?;
            while padded.len() % 8 != 0 {
                padded.push(boolean::Boolean::Constant(false));
            }

            bits.extend(
                padded
                    .chunks_exact(8)
                    .flat_map(|chunk| chunk.iter().rev())
                    .cloned(),
            );
        }
        Self::hash_circuit(cs, &bits)
    }

    fn hash_leaf_bits_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        left: &[boolean::Boolean],
        right: &[boolean::Boolean],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let mut preimage: Vec<boolean::Boolean> = vec![];

        let mut left_padded = left.to_vec();
        while left_padded.len() % 8 != 0 {
            left_padded.push(boolean::Boolean::Constant(false));
        }

        preimage.extend(
            left_padded
                .chunks_exact(8)
                .flat_map(|chunk| chunk.iter().rev())
                .cloned(),
        );

        let mut right_padded = right.to_vec();
        while right_padded.len() % 8 != 0 {
            right_padded.push(boolean::Boolean::Constant(false));
        }

        preimage.extend(
            right_padded
                .chunks_exact(8)
                .flat_map(|chunk| chunk.iter().rev())
                .cloned(),
        );

        Self::hash_circuit(cs, &preimage[..])
    }

    fn hash_circuit<CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        bits: &[boolean::Boolean],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let be_bits = sha256_circuit(cs.namespace(|| "hash"), &bits[..])?;
        let le_bits = be_bits
            .chunks(8)
            .flat_map(|chunk| chunk.iter().rev())
            .cloned()
            .take(Fr::CAPACITY as usize)
            .collect::<Vec<_>>();
        multipack::pack_bits(cs.namespace(|| "pack_le"), &le_bits)
    }

    fn hash2_circuit<CS>(
        mut cs: CS,
        a_num: &num::AllocatedNum<Bls12>,
        b_num: &num::AllocatedNum<Bls12>,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        // Allocate as booleans
        let a = a_num.to_bits_le(cs.namespace(|| "a_bits"))?;
        let b = b_num.to_bits_le(cs.namespace(|| "b_bits"))?;

        let mut preimage: Vec<boolean::Boolean> = vec![];

        let mut a_padded = a.to_vec();
        while a_padded.len() % 8 != 0 {
            a_padded.push(boolean::Boolean::Constant(false));
        }

        preimage.extend(
            a_padded
                .chunks_exact(8)
                .flat_map(|chunk| chunk.iter().rev())
                .cloned(),
        );

        let mut b_padded = b.to_vec();
        while b_padded.len() % 8 != 0 {
            b_padded.push(boolean::Boolean::Constant(false));
        }

        preimage.extend(
            b_padded
                .chunks_exact(8)
                .flat_map(|chunk| chunk.iter().rev())
                .cloned(),
        );

        Self::hash_circuit(cs, &preimage[..])
    }
}

impl Algorithm<Sha256Domain> for Sha256Function {
    #[inline]
    fn hash(&mut self) -> Sha256Domain {
        let mut h = [0u8; 32];
        h.copy_from_slice(self.0.clone().result().as_ref());
        let mut dd = Sha256Domain::from(h);
        dd.trim_to_fr32();
        dd
    }

    #[inline]
    fn reset(&mut self) {
        self.0.reset();
    }

    fn leaf(&mut self, leaf: Sha256Domain) -> Sha256Domain {
        leaf
    }

    fn node(&mut self, left: Sha256Domain, right: Sha256Domain, _height: usize) -> Sha256Domain {
        left.hash(self);
        right.hash(self);
        self.hash()
    }

    fn multi_node(&mut self, parts: &[Sha256Domain], _height: usize) -> Sha256Domain {
        for part in parts {
            part.hash(self)
        }
        self.hash()
    }
}

impl From<[u8; 32]> for Sha256Domain {
    #[inline]
    fn from(val: [u8; 32]) -> Self {
        Sha256Domain(val)
    }
}

impl From<Sha256Domain> for [u8; 32] {
    #[inline]
    fn from(val: Sha256Domain) -> Self {
        val.0
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::fr32::fr_into_bytes;
    use crate::gadgets::TestConstraintSystem;
    use crate::util::bytes_into_boolean_vec;

    use bellperson::gadgets::boolean::Boolean;
    use bellperson::ConstraintSystem;
    use ff::Field;
    use merkletree::hash::Algorithm;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    #[test]
    fn hash_leaf_bits_circuit() {
        let mut cs = TestConstraintSystem::<Bls12>::new();
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let left_fr = Fr::random(rng);
        let right_fr = Fr::random(rng);
        let left: Vec<u8> = fr_into_bytes(&left_fr);
        let right: Vec<u8> = fr_into_bytes(&right_fr);
        let height = 1;

        let left_bits: Vec<Boolean> = {
            let mut cs = cs.namespace(|| "left");
            bytes_into_boolean_vec(&mut cs, Some(left.as_slice()), 256).unwrap()
        };

        let right_bits: Vec<Boolean> = {
            let mut cs = cs.namespace(|| "right");
            bytes_into_boolean_vec(&mut cs, Some(right.as_slice()), 256).unwrap()
        };

        let out = Sha256Function::hash_leaf_bits_circuit(
            cs.namespace(|| "hash_leaf_circuit"),
            &left_bits,
            &right_bits,
            height,
        )
        .expect("key derivation function failed");

        assert!(cs.is_satisfied(), "constraints not satisfied");
        assert_eq!(cs.num_constraints(), 45_387);

        let expected: Fr = Sha256Function::default()
            .node(left_fr.into(), right_fr.into(), height)
            .into();

        assert_eq!(
            expected,
            out.get_value().unwrap(),
            "circuit and non circuit do not match"
        );
    }
}

'''
'''--- storage-proofs/core/src/hasher/types.rs ---
use bellperson::gadgets::{boolean, num};
use bellperson::{ConstraintSystem, SynthesisError};
use generic_array::typenum::{U0, U11, U16, U2, U24, U36, U4, U8};
use lazy_static::lazy_static;
use merkletree::hash::{Algorithm as LightAlgorithm, Hashable as LightHashable};
use merkletree::merkle::Element;
use neptune::poseidon::PoseidonConstants;
use paired::bls12_381::{Bls12, Fr, FrRepr};
use serde::de::DeserializeOwned;
use serde::ser::Serialize;

use crate::error::Result;

pub type PoseidonBinaryArity = U2;
pub type PoseidonQuadArity = U4;
pub type PoseidonOctArity = U8;

/// Arity to use by default for `hash_md` with poseidon.
pub type PoseidonMDArity = U36;

/// Arity to use for hasher implementations (Poseidon) which are specialized at compile time.
/// Must match PoseidonArity
pub const MERKLE_TREE_ARITY: usize = 2;

lazy_static! {
    pub static ref POSEIDON_CONSTANTS_2: PoseidonConstants::<Bls12, U2> = PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_4: PoseidonConstants::<Bls12, U4> = PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_8: PoseidonConstants::<Bls12, U8> = PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_16: PoseidonConstants::<Bls12, U16> =
        PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_24: PoseidonConstants::<Bls12, U24> =
        PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_36: PoseidonConstants::<Bls12, U36> =
        PoseidonConstants::new();
    pub static ref POSEIDON_CONSTANTS_11: PoseidonConstants::<Bls12, U11> =
        PoseidonConstants::new();
    pub static ref POSEIDON_MD_CONSTANTS: PoseidonConstants::<Bls12, PoseidonMDArity> =
        PoseidonConstants::new();
}

pub trait PoseidonArity: neptune::Arity<Fr> + Send + Sync + Clone + std::fmt::Debug {
    #[allow(non_snake_case)]
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self>;
}

impl PoseidonArity for U0 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        unreachable!("dummy implementation, do not ever call me")
    }
}

impl PoseidonArity for U2 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_2
    }
}

impl PoseidonArity for U4 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_4
    }
}

impl PoseidonArity for U8 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_8
    }
}

impl PoseidonArity for U11 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_11
    }
}

impl PoseidonArity for U16 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_16
    }
}
impl PoseidonArity for U24 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_24
    }
}
impl PoseidonArity for U36 {
    fn PARAMETERS() -> &'static PoseidonConstants<Bls12, Self> {
        &*POSEIDON_CONSTANTS_36
    }
}

pub trait Domain:
    Ord
    + Copy
    + Clone
    + AsRef<[u8]>
    + Default
    + ::std::fmt::Debug
    + Eq
    + Send
    + Sync
    + From<Fr>
    + From<FrRepr>
    + Into<Fr>
    + Serialize
    + DeserializeOwned
    + Element
    + std::hash::Hash
{
    fn into_bytes(&self) -> Vec<u8>;
    fn try_from_bytes(raw: &[u8]) -> Result<Self>;
    /// Write itself into the given slice, LittleEndian bytes.
    fn write_bytes(&self, _: &mut [u8]) -> Result<()>;

    fn random<R: rand::RngCore>(rng: &mut R) -> Self;
}

pub trait HashFunction<T: Domain>:
    Clone + ::std::fmt::Debug + Send + Sync + LightAlgorithm<T>
{
    fn hash(data: &[u8]) -> T;
    fn hash2(a: &T, b: &T) -> T;
    fn hash_md(input: &[T]) -> T {
        // Default to binary.
        assert!(input.len() > 1, "hash_md needs more than one element.");
        input
            .iter()
            .skip(1)
            .fold(input[0], |acc, elt| Self::hash2(&acc, elt))
    }

    fn hash_leaf(data: &dyn LightHashable<Self>) -> T {
        let mut a = Self::default();
        data.hash(&mut a);
        let item_hash = a.hash();
        a.leaf(item_hash)
    }

    fn hash_single_node(data: &dyn LightHashable<Self>) -> T {
        let mut a = Self::default();
        data.hash(&mut a);
        a.hash()
    }

    fn hash_leaf_circuit<CS: ConstraintSystem<Bls12>>(
        mut cs: CS,
        left: &num::AllocatedNum<Bls12>,
        right: &num::AllocatedNum<Bls12>,
        height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        let left_bits = left.to_bits_le(cs.namespace(|| "left num into bits"))?;
        let right_bits = right.to_bits_le(cs.namespace(|| "right num into bits"))?;

        Self::hash_leaf_bits_circuit(cs, &left_bits, &right_bits, height)
    }

    fn hash_multi_leaf_circuit<Arity: 'static + PoseidonArity, CS: ConstraintSystem<Bls12>>(
        cs: CS,
        leaves: &[num::AllocatedNum<Bls12>],
        height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>;

    fn hash_md_circuit<CS: ConstraintSystem<Bls12>>(
        _cs: &mut CS,
        _elements: &[num::AllocatedNum<Bls12>],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        unimplemented!();
    }

    fn hash_leaf_bits_circuit<CS: ConstraintSystem<Bls12>>(
        _cs: CS,
        _left: &[boolean::Boolean],
        _right: &[boolean::Boolean],
        _height: usize,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError> {
        unimplemented!();
    }

    fn hash_circuit<CS: ConstraintSystem<Bls12>>(
        cs: CS,
        bits: &[boolean::Boolean],
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>;

    fn hash2_circuit<CS>(
        cs: CS,
        a: &num::AllocatedNum<Bls12>,
        b: &num::AllocatedNum<Bls12>,
    ) -> std::result::Result<num::AllocatedNum<Bls12>, SynthesisError>
    where
        CS: ConstraintSystem<Bls12>;
}

pub trait Hasher: Clone + ::std::fmt::Debug + Eq + Default + Send + Sync {
    type Domain: Domain + LightHashable<Self::Function> + AsRef<Self::Domain>;
    type Function: HashFunction<Self::Domain>;

    fn sloth_encode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain>;
    fn sloth_decode(key: &Self::Domain, ciphertext: &Self::Domain) -> Result<Self::Domain>;

    fn name() -> String;
}

'''
'''--- storage-proofs/core/src/lib.rs ---
#![deny(clippy::all, clippy::perf, clippy::correctness)]
#![allow(clippy::many_single_char_names)]
#![allow(clippy::unreadable_literal)]
#![allow(clippy::type_repetition_in_bounds)]

#[macro_use]
pub mod test_helper;

pub mod cache_key;
pub mod compound_proof;
pub mod crypto;
pub mod data;
pub mod drgraph;
pub mod error;
pub mod fr32;
pub mod gadgets;
pub mod hasher;
pub mod measurements;
pub mod merkle;
pub mod multi_proof;
pub mod parameter_cache;
pub mod partitions;
pub mod pieces;
pub mod por;
pub mod proof;
pub mod sector;
pub mod settings;
pub mod util;

pub use self::data::Data;

#[cfg(test)]
pub(crate) const TEST_SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

'''
'''--- storage-proofs/core/src/measurements.rs ---
#[cfg(feature = "measurements")]
use std::sync::mpsc::{channel, Receiver, Sender};
#[cfg(feature = "measurements")]
use std::sync::Mutex;
#[cfg(not(feature = "measurements"))]
use std::time::Duration;
#[cfg(feature = "measurements")]
use std::time::{Duration, Instant};

#[cfg(feature = "measurements")]
use cpu_time::ProcessTime;

use serde::Serialize;

#[cfg(feature = "measurements")]
use lazy_static::lazy_static;

#[cfg(feature = "measurements")]
lazy_static! {
    pub static ref OP_MEASUREMENTS: (
        Mutex<Option<Sender<OpMeasurement>>>,
        Mutex<Receiver<OpMeasurement>>
    ) = {
        // create asynchronous channel with unlimited buffer
        let (tx, rx) = channel();
        (Mutex::new(Some(tx)), Mutex::new(rx))
    };
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "kebab-case")]
pub struct OpMeasurement {
    pub op: Operation,
    pub cpu_time: Duration,
    pub wall_time: Duration,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "kebab-case")]
pub enum Operation {
    AddPiece,
    GeneratePieceCommitment,
    GenerateTreeC,
    GenerateTreeRLast,
    CommD,
    EncodeWindowTimeAll,
    WindowCommLeavesTime,
    PorepCommitTime,
    PostInclusionProofs,
    PostFinalizeTicket,
    PostReadChallengedRange,
    PostPartialTicketHash,
}

#[cfg(feature = "measurements")]
pub fn measure_op<T, F>(op: Operation, f: F) -> T
where
    F: FnOnce() -> T,
{
    let cpu_time_start = ProcessTime::now();
    let wall_start_time = Instant::now();

    #[cfg(feature = "profile")]
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .start(format!("./{:?}.profile", op))
        .unwrap();
    let x = f();
    #[cfg(feature = "profile")]
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .stop()
        .unwrap();

    let opt_tx = OP_MEASUREMENTS
        .0
        .lock()
        .expect("acquire lock on tx side of perf channel");

    if let Some(tx) = opt_tx.as_ref() {
        tx.clone()
            .send(OpMeasurement {
                op,
                cpu_time: cpu_time_start.elapsed(),
                wall_time: wall_start_time.elapsed(),
            })
            .expect("failed to send to perf channel");
    }

    x
}

#[cfg(not(feature = "measurements"))]
pub fn measure_op<T, F>(_: Operation, f: F) -> T
where
    F: FnOnce() -> T,
{
    f()
}

'''
'''--- storage-proofs/core/src/merkle/builders.rs ---
use std::io::Write;
use std::path::PathBuf;

use anyhow::{ensure, Result};
use generic_array::typenum::{self, Unsigned};
use log::trace;
use merkletree::merkle;
use merkletree::merkle::{
    get_merkle_tree_leafs, is_merkle_tree_size_valid, FromIndexedParallelIterator,
};
use merkletree::store::{ExternalReader, ReplicaConfig, Store, StoreConfig};
use rayon::prelude::*;

use crate::error::*;
use crate::hasher::{Domain, Hasher, PoseidonArity};
use crate::util::{data_at_node, NODE_SIZE};

use super::*;

// Create a DiskTree from the provided config(s), each representing a 'base' layer tree with 'base_tree_len' elements.
pub fn create_disk_tree<Tree: MerkleTreeTrait>(
    base_tree_len: usize,
    configs: &[StoreConfig],
) -> Result<DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>> {
    let base_tree_leafs = get_merkle_tree_leafs(base_tree_len, Tree::Arity::to_usize())?;

    if Tree::TopTreeArity::to_usize() > 0 {
        ensure!(
            Tree::SubTreeArity::to_usize() > 0,
            "Invalid top arity specified without sub arity"
        );

        DiskTree::from_sub_tree_store_configs(base_tree_leafs, configs)
    } else if Tree::SubTreeArity::to_usize() > 0 {
        ensure!(
            !configs.is_empty(),
            "Cannot create sub-tree with a single tree config"
        );

        DiskTree::from_store_configs(base_tree_leafs, configs)
    } else {
        ensure!(configs.len() == 1, "Invalid tree-shape specified");
        let store = DiskStore::new_from_disk(base_tree_len, Tree::Arity::to_usize(), &configs[0])?;

        DiskTree::from_data_store(store, base_tree_leafs)
    }
}

// Create an LCTree from the provided config(s) and replica(s), each representing a 'base' layer tree with 'base_tree_len' elements.
pub fn create_lc_tree<Tree: MerkleTreeTrait>(
    base_tree_len: usize,
    configs: &[StoreConfig],
    replica_config: &ReplicaConfig,
) -> Result<LCTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>> {
    let base_tree_leafs = get_merkle_tree_leafs(base_tree_len, Tree::Arity::to_usize())?;

    if Tree::TopTreeArity::to_usize() > 0 {
        ensure!(
            Tree::SubTreeArity::to_usize() > 0,
            "Invalid top arity specified without sub arity"
        );

        LCTree::from_sub_tree_store_configs_and_replica(base_tree_leafs, configs, replica_config)
    } else if Tree::SubTreeArity::to_usize() > 0 {
        ensure!(
            !configs.is_empty(),
            "Cannot create sub-tree with a single tree config"
        );

        LCTree::from_store_configs_and_replica(base_tree_leafs, configs, replica_config)
    } else {
        ensure!(configs.len() == 1, "Invalid tree-shape specified");
        let store = LCStore::new_from_disk_with_reader(
            base_tree_len,
            Tree::Arity::to_usize(),
            &configs[0],
            ExternalReader::new_from_path(&replica_config.path)?,
        )?;

        LCTree::from_data_store(store, base_tree_leafs)
    }
}

// Given base tree configs and optionally a replica_config, returns
// either a disktree or an lctree, specified by Tree.
pub fn create_tree<Tree: MerkleTreeTrait>(
    base_tree_len: usize,
    configs: &[StoreConfig],
    replica_config: Option<&ReplicaConfig>,
) -> Result<
    MerkleTreeWrapper<
        <Tree as MerkleTreeTrait>::Hasher,
        <Tree as MerkleTreeTrait>::Store,
        <Tree as MerkleTreeTrait>::Arity,
        <Tree as MerkleTreeTrait>::SubTreeArity,
        <Tree as MerkleTreeTrait>::TopTreeArity,
    >,
>
where
    Tree::Store: 'static,
{
    use std::any::Any;

    let base_tree_leafs = get_base_tree_leafs::<Tree>(base_tree_len)?;
    let mut trees = Vec::with_capacity(configs.len());
    for i in 0..configs.len() {
        let mut store = Tree::Store::new_with_config(
            base_tree_len,
            Tree::Arity::to_usize(),
            configs[i].clone(),
        )?;
        if let Some(lc_store) = Any::downcast_mut::<
            merkletree::store::LevelCacheStore<<Tree::Hasher as Hasher>::Domain, std::fs::File>,
        >(&mut store)
        {
            ensure!(
                replica_config.is_some(),
                "Cannot create LCTree without replica paths"
            );
            let replica_config = replica_config.unwrap();
            lc_store.set_external_reader(ExternalReader::new_from_config(&replica_config, i)?)?;
        }

        if configs.len() == 1 {
            return MerkleTreeWrapper::<
                Tree::Hasher,
                Tree::Store,
                Tree::Arity,
                Tree::SubTreeArity,
                Tree::TopTreeArity,
            >::from_data_store(store, base_tree_leafs);
        } else {
            trees.push(MerkleTreeWrapper::<
                Tree::Hasher,
                Tree::Store,
                Tree::Arity,
                typenum::U0,
                typenum::U0,
            >::from_data_store(store, base_tree_leafs)?);
        }
    }

    ensure!(
        Tree::TopTreeArity::to_usize() > 0 || Tree::SubTreeArity::to_usize() > 0,
        "Cannot have a sub/top tree without more than 1 config"
    );
    if Tree::TopTreeArity::to_usize() > 0 {
        ensure!(
            Tree::SubTreeArity::to_usize() > 0,
            "Invalid top arity specified without sub arity"
        );

        MerkleTreeWrapper::<
            Tree::Hasher,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >::from_sub_trees_as_trees(trees)
    } else {
        ensure!(
            !configs.is_empty(),
            "Cannot create sub-tree with a single tree config"
        );

        MerkleTreeWrapper::from_trees(trees)
    }
}

pub fn create_base_merkle_tree<Tree: MerkleTreeTrait>(
    config: Option<StoreConfig>,
    size: usize,
    data: &[u8],
) -> Result<Tree> {
    ensure!(
        data.len() == (NODE_SIZE * size) as usize,
        Error::InvalidMerkleTreeArgs(data.len(), NODE_SIZE, size)
    );

    trace!("create_merkle_tree called with size {}", size);
    trace!(
        "is_merkle_tree_size_valid({}, arity {}) = {}",
        size,
        Tree::Arity::to_usize(),
        is_merkle_tree_size_valid(size, Tree::Arity::to_usize())
    );
    ensure!(
        is_merkle_tree_size_valid(size, Tree::Arity::to_usize()),
        "Invalid merkle tree size given the arity"
    );

    let f = |i| {
        // TODO Replace `expect()` with `context()` (problem is the parallel iterator)
        let d = data_at_node(&data, i).expect("data_at_node math failed");
        // TODO/FIXME: This can panic. FOR NOW, let's leave this since we're experimenting with
        // optimization paths. However, we need to ensure that bad input will not lead to a panic
        // that isn't caught by the FPS API.
        // Unfortunately, it's not clear how to perform this error-handling in the parallel
        // iterator case.
        <Tree::Hasher as Hasher>::Domain::try_from_bytes(d)
            .expect("failed to convert node data to domain element")
    };

    let tree = match config {
        Some(x) => merkle::MerkleTree::<
            <Tree::Hasher as Hasher>::Domain,
            <Tree::Hasher as Hasher>::Function,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >::from_par_iter_with_config((0..size).into_par_iter().map(f), x),
        None => merkle::MerkleTree::<
            <Tree::Hasher as Hasher>::Domain,
            <Tree::Hasher as Hasher>::Function,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >::from_par_iter((0..size).into_par_iter().map(f)),
    }?;

    Ok(Tree::from_merkle(tree))
}

/// Construct a new level cache merkle tree, given the specified
/// config.
///
/// Note that while we don't need to pass both the data AND the
/// replica path (since the replica file will contain the same data),
/// we pass both since we have access from all callers and this avoids
/// reading that data from the replica_config here.
pub fn create_base_lcmerkle_tree<H: Hasher, BaseTreeArity: 'static + PoseidonArity>(
    config: StoreConfig,
    size: usize,
    data: &[u8],
    replica_config: &ReplicaConfig,
) -> Result<LCMerkleTree<H, BaseTreeArity>> {
    trace!("create_base_lcmerkle_tree called with size {}", size);
    trace!(
        "is_merkle_tree_size_valid({}, arity {}) = {}",
        size,
        BaseTreeArity::to_usize(),
        is_merkle_tree_size_valid(size, BaseTreeArity::to_usize())
    );
    ensure!(
        is_merkle_tree_size_valid(size, BaseTreeArity::to_usize()),
        "Invalid merkle tree size given the arity"
    );
    ensure!(
        data.len() == size * std::mem::size_of::<H::Domain>(),
        "Invalid data length for merkle tree"
    );

    let f = |i| {
        let d = data_at_node(&data, i)?;
        H::Domain::try_from_bytes(d)
    };

    let mut lc_tree: LCMerkleTree<H, BaseTreeArity> =
        LCMerkleTree::<H, BaseTreeArity>::try_from_iter_with_config((0..size).map(f), config)?;

    lc_tree.set_external_reader_path(&replica_config.path)?;

    Ok(lc_tree)
}

// Given a StoreConfig, generate additional ones with appended numbers
// to uniquely identify them and return the results.  If count is 1,
// the original config is not modified.
pub fn split_config(config: StoreConfig, count: usize) -> Result<Vec<StoreConfig>> {
    if count == 1 {
        return Ok(vec![config]);
    }

    let mut configs = Vec::with_capacity(count);
    for i in 0..count {
        configs.push(StoreConfig::from_config(
            &config,
            format!("{}-{}", config.id, i),
            None,
        ));
        configs[i].rows_to_discard = config.rows_to_discard;
    }

    Ok(configs)
}

// Given a StoreConfig, generate additional ones with appended numbers
// to uniquely identify them and return the results.  If count is 1,
// the original config is not modified.
//
// Useful for testing, where there the config may be None.
pub fn split_config_wrapped(
    config: Option<StoreConfig>,
    count: usize,
) -> Result<Vec<Option<StoreConfig>>> {
    if count == 1 {
        return Ok(vec![config]);
    }

    match config {
        Some(c) => {
            let mut configs = Vec::with_capacity(count);
            for i in 0..count {
                configs.push(Some(StoreConfig::from_config(
                    &c,
                    format!("{}-{}", c.id, i),
                    None,
                )));
            }
            Ok(configs)
        }
        None => Ok(vec![None]),
    }
}

// Given a StoreConfig, replica path and tree_width (leaf nodes),
// append numbers to each StoreConfig to uniquely identify them and
// return the results along with a ReplicaConfig using calculated
// offsets into the single replica path specified for later use with
// external readers.  If count is 1, the original config is not
// modified.
pub fn split_config_and_replica(
    config: StoreConfig,
    replica_path: PathBuf,
    sub_tree_width: usize, // nodes, not bytes
    count: usize,
) -> Result<(Vec<StoreConfig>, ReplicaConfig)> {
    if count == 1 {
        return Ok((
            vec![config],
            ReplicaConfig {
                path: replica_path,
                offsets: vec![0],
            },
        ));
    }

    let mut configs = Vec::with_capacity(count);
    let mut replica_offsets = Vec::with_capacity(count);

    for i in 0..count {
        configs.push(StoreConfig::from_config(
            &config,
            format!("{}-{}", config.id, i),
            None,
        ));
        configs[i].rows_to_discard = config.rows_to_discard;

        replica_offsets.push(i * sub_tree_width * NODE_SIZE);
    }

    Ok((
        configs,
        ReplicaConfig {
            path: replica_path,
            offsets: replica_offsets,
        },
    ))
}

pub fn get_base_tree_count<Tree: MerkleTreeTrait>() -> usize {
    if Tree::TopTreeArity::to_usize() == 0 && Tree::SubTreeArity::to_usize() == 0 {
        return 1;
    }

    if Tree::TopTreeArity::to_usize() > 0 {
        assert!(Tree::SubTreeArity::to_usize() != 0);

        Tree::TopTreeArity::to_usize() * Tree::SubTreeArity::to_usize()
    } else {
        Tree::SubTreeArity::to_usize()
    }
}

pub fn get_base_tree_leafs<Tree: MerkleTreeTrait>(base_tree_size: usize) -> Result<usize> {
    get_merkle_tree_leafs(base_tree_size, Tree::Arity::to_usize())
}

pub type ResTree<Tree> = MerkleTreeWrapper<
    <Tree as MerkleTreeTrait>::Hasher,
    <Tree as MerkleTreeTrait>::Store,
    <Tree as MerkleTreeTrait>::Arity,
    <Tree as MerkleTreeTrait>::SubTreeArity,
    <Tree as MerkleTreeTrait>::TopTreeArity,
>;

fn generate_base_tree<R: rand::Rng, Tree: MerkleTreeTrait>(
    rng: &mut R,
    nodes: usize,
    temp_path: Option<PathBuf>,
) -> (Vec<u8>, ResTree<Tree>)
where
    Tree::Store: 'static,
{
    let elements = (0..nodes)
        .map(|_| <Tree::Hasher as Hasher>::Domain::random(rng))
        .collect::<Vec<_>>();

    let mut data = Vec::new();
    for el in &elements {
        data.extend_from_slice(AsRef::<[u8]>::as_ref(el));
    }

    if let Some(ref temp_path) = temp_path {
        let id: u64 = rng.gen();
        let replica_path = temp_path.join(format!("replica-path-{}", id));
        let config = StoreConfig::new(
            &temp_path,
            format!("test-lc-tree-{}", id),
            StoreConfig::default_rows_to_discard(nodes, Tree::Arity::to_usize()),
        );

        let mut tree =
            MerkleTreeWrapper::try_from_iter_with_config(elements.iter().map(|v| (Ok(*v))), config)
                .unwrap();

        // Write out the replica data.
        let mut f = std::fs::File::create(&replica_path).unwrap();
        f.write_all(&data).unwrap();

        {
            // Beware: evil dynamic downcasting RUST MAGIC down below.
            use std::any::Any;

            if let Some(lc_tree) = Any::downcast_mut::<
                merkle::MerkleTree<
                    <Tree::Hasher as Hasher>::Domain,
                    <Tree::Hasher as Hasher>::Function,
                    merkletree::store::LevelCacheStore<
                        <Tree::Hasher as Hasher>::Domain,
                        std::fs::File,
                    >,
                    Tree::Arity,
                    Tree::SubTreeArity,
                    Tree::TopTreeArity,
                >,
            >(&mut tree.inner)
            {
                lc_tree.set_external_reader_path(&replica_path).unwrap();
            }
        }

        (data, tree)
    } else {
        (
            data,
            MerkleTreeWrapper::try_from_iter(elements.iter().map(|v| Ok(*v))).unwrap(),
        )
    }
}

fn generate_sub_tree<R: rand::Rng, Tree: MerkleTreeTrait>(
    rng: &mut R,
    nodes: usize,
    temp_path: Option<PathBuf>,
) -> (Vec<u8>, ResTree<Tree>)
where
    Tree::Store: 'static,
{
    let base_tree_count = Tree::SubTreeArity::to_usize();
    let base_tree_size = nodes / base_tree_count;
    let mut trees = Vec::with_capacity(base_tree_count);
    let mut data = Vec::new();

    for _ in 0..base_tree_count {
        let (inner_data, tree) = generate_base_tree::<
            R,
            MerkleTreeWrapper<Tree::Hasher, Tree::Store, Tree::Arity>,
        >(rng, base_tree_size, temp_path.clone());
        trees.push(tree);
        data.extend(inner_data);
    }

    (data, MerkleTreeWrapper::from_trees(trees).unwrap())
}

/// Only used for testing, but can't cfg-test it as that stops exports.
pub fn generate_tree<Tree: MerkleTreeTrait, R: rand::Rng>(
    rng: &mut R,
    nodes: usize,
    temp_path: Option<PathBuf>,
) -> (Vec<u8>, ResTree<Tree>)
where
    Tree::Store: 'static,
{
    let sub_tree_arity = Tree::SubTreeArity::to_usize();
    let top_tree_arity = Tree::TopTreeArity::to_usize();

    if top_tree_arity > 0 {
        assert!(
            sub_tree_arity != 0,
            "malformed tree with TopTreeArity > 0 and SubTreeARity == 0"
        );

        let mut sub_trees = Vec::with_capacity(top_tree_arity);
        let mut data = Vec::new();
        for _i in 0..top_tree_arity {
            let (inner_data, tree) = generate_sub_tree::<
                R,
                MerkleTreeWrapper<
                    Tree::Hasher,
                    Tree::Store,
                    Tree::Arity,
                    Tree::SubTreeArity,
                    typenum::U0,
                >,
            >(rng, nodes / top_tree_arity, temp_path.clone());

            sub_trees.push(tree);
            data.extend(inner_data);
        }
        (data, MerkleTreeWrapper::from_sub_trees(sub_trees).unwrap())
    } else if sub_tree_arity > 0 {
        generate_sub_tree::<R, Tree>(rng, nodes, temp_path)
    } else {
        generate_base_tree::<R, Tree>(rng, nodes, temp_path)
    }
}

'''
'''--- storage-proofs/core/src/merkle/mod.rs ---
#![allow(clippy::len_without_is_empty)]

use generic_array::typenum::{U0, U2, U4, U8};

use crate::hasher::Hasher;

mod builders;
mod proof;
mod tree;

pub use builders::*;
pub use proof::*;
pub use tree::*;

// Reexport here, so we don't depend on merkletree directly in other places.
pub use merkletree::store::{ExternalReader, Store};

pub type DiskStore<E> = merkletree::store::DiskStore<E>;
pub type LCStore<E> = merkletree::store::LevelCacheStore<E, std::fs::File>;

pub type MerkleStore<T> = DiskStore<T>;

pub type DiskTree<H, U, V, W> = MerkleTreeWrapper<H, DiskStore<<H as Hasher>::Domain>, U, V, W>;
pub type LCTree<H, U, V, W> = MerkleTreeWrapper<H, LCStore<<H as Hasher>::Domain>, U, V, W>;

pub type MerkleTree<H, U> = DiskTree<H, U, U0, U0>;
pub type LCMerkleTree<H, U> = LCTree<H, U, U0, U0>;

pub type BinaryMerkleTree<H> = MerkleTree<H, U2>;
pub type BinaryLCMerkleTree<H> = LCMerkleTree<H, U2>;

pub type BinarySubMerkleTree<H> = DiskTree<H, U2, U2, U0>;

pub type QuadMerkleTree<H> = MerkleTree<H, U4>;
pub type QuadLCMerkleTree<H> = LCMerkleTree<H, U4>;

pub type OctMerkleTree<H> = DiskTree<H, U8, U0, U0>;
pub type OctSubMerkleTree<H> = DiskTree<H, U8, U2, U0>;
pub type OctTopMerkleTree<H> = DiskTree<H, U8, U8, U2>;

pub type OctLCMerkleTree<H> = LCTree<H, U8, U0, U0>;
pub type OctLCSubMerkleTree<H> = LCTree<H, U8, U2, U0>;
pub type OctLCTopMerkleTree<H> = LCTree<H, U8, U8, U2>;

'''
'''--- storage-proofs/core/src/merkle/proof.rs ---
#![allow(clippy::len_without_is_empty)]

use std::marker::PhantomData;

use anyhow::{ensure, Result};
use generic_array::typenum::{Unsigned, U0};
use merkletree::hash::Algorithm;
use merkletree::proof;
use paired::bls12_381::Fr;
use serde::{Deserialize, Serialize};

use crate::drgraph::graph_height;
use crate::hasher::{Hasher, PoseidonArity};

/// Trait to abstract over the concept of Merkle Proof.
pub trait MerkleProofTrait:
    Clone + Serialize + serde::de::DeserializeOwned + std::fmt::Debug + Sync + Send
{
    type Hasher: Hasher;
    type Arity: 'static + PoseidonArity;
    type SubTreeArity: 'static + PoseidonArity;
    type TopTreeArity: 'static + PoseidonArity;

    /// Try to convert a merkletree proof into this structure.
    fn try_from_proof(
        p: proof::Proof<<Self::Hasher as Hasher>::Domain, Self::Arity>,
    ) -> Result<Self>;

    fn as_options(&self) -> Vec<(Vec<Option<Fr>>, Option<usize>)> {
        self.path()
            .iter()
            .map(|v| {
                (
                    v.0.iter().copied().map(Into::into).map(Some).collect(),
                    Some(v.1),
                )
            })
            .collect::<Vec<_>>()
    }

    fn into_options_with_leaf(self) -> (Option<Fr>, Vec<(Vec<Option<Fr>>, Option<usize>)>) {
        let leaf = self.leaf();
        let path = self.path();
        (
            Some(leaf.into()),
            path.into_iter()
                .map(|(a, b)| {
                    (
                        a.iter().copied().map(Into::into).map(Some).collect(),
                        Some(b),
                    )
                })
                .collect::<Vec<_>>(),
        )
    }
    fn as_pairs(&self) -> Vec<(Vec<Fr>, usize)> {
        self.path()
            .iter()
            .map(|v| (v.0.iter().copied().map(Into::into).collect(), v.1))
            .collect::<Vec<_>>()
    }
    fn verify(&self) -> bool;

    /// Validates the MerkleProof and that it corresponds to the supplied node.
    ///
    /// TODO: audit performance and usage in case verification is
    /// unnecessary based on how it's used.
    fn validate(&self, node: usize) -> bool {
        if !self.verify() {
            return false;
        }

        node == self.path_index()
    }

    fn validate_data(&self, data: <Self::Hasher as Hasher>::Domain) -> bool {
        if !self.verify() {
            return false;
        }

        self.leaf() == data
    }

    fn leaf(&self) -> <Self::Hasher as Hasher>::Domain;
    fn root(&self) -> <Self::Hasher as Hasher>::Domain;
    fn len(&self) -> usize;
    fn path(&self) -> Vec<(Vec<<Self::Hasher as Hasher>::Domain>, usize)>;

    fn path_index(&self) -> usize {
        self.path()
            .iter()
            .rev()
            .fold(0, |acc, (_, index)| (acc * Self::Arity::to_usize()) + index)
    }

    fn proves_challenge(&self, challenge: usize) -> bool {
        self.path_index() == challenge
    }

    /// Calcluates the exected length of the full path, given the number of leaves in the base layer.
    fn expected_len(&self, leaves: usize) -> usize {
        compound_path_length::<Self::Arity, Self::SubTreeArity, Self::TopTreeArity>(leaves)
    }

    /// Test only method to break a valid proof.
    #[cfg(test)]
    fn break_me(&mut self, leaf: <Self::Hasher as Hasher>::Domain);
}

pub fn base_path_length<A: Unsigned, B: Unsigned, C: Unsigned>(leaves: usize) -> usize {
    let leaves = if C::to_usize() > 0 {
        leaves / C::to_usize() / B::to_usize()
    } else if B::to_usize() > 0 {
        leaves / B::to_usize()
    } else {
        leaves
    };

    graph_height::<A>(leaves) - 1
}

pub fn compound_path_length<A: Unsigned, B: Unsigned, C: Unsigned>(leaves: usize) -> usize {
    let mut len = base_path_length::<A, B, C>(leaves);
    if B::to_usize() > 0 {
        len += 1;
    }

    if C::to_usize() > 0 {
        len += 1;
    }

    len
}
pub fn compound_tree_height<A: Unsigned, B: Unsigned, C: Unsigned>(leaves: usize) -> usize {
    // base layer
    let a = graph_height::<A>(leaves) - 1;

    // sub tree layer
    let b = if B::to_usize() > 0 {
        B::to_usize() - 1
    } else {
        0
    };

    // top tree layer
    let c = if C::to_usize() > 0 {
        C::to_usize() - 1
    } else {
        0
    };

    a + b + c
}

macro_rules! forward_method {
    ($caller:expr, $name:ident) => {
        match $caller {
            ProofData::Single(ref proof) => proof.$name(),
            ProofData::Sub(ref proof) => proof.$name(),
            ProofData::Top(ref proof) => proof.$name(),
        }
    };
    ($caller:expr, $name:ident, $( $args:expr ),+) => {
        match $caller {
            ProofData::Single(ref proof) => proof.$name($($args),+),
            ProofData::Sub(ref proof) => proof.$name($($args),+),
            ProofData::Top(ref proof) => proof.$name($($args),+),
        }
    };
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct InclusionPath<H: Hasher, Arity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    path: Vec<PathElement<H, Arity>>,
}

impl<H: Hasher, Arity: PoseidonArity> From<Vec<PathElement<H, Arity>>> for InclusionPath<H, Arity> {
    fn from(path: Vec<PathElement<H, Arity>>) -> Self {
        Self { path }
    }
}

impl<H: Hasher, Arity: PoseidonArity> InclusionPath<H, Arity> {
    /// Calculate the root of this path, given the leaf as input.
    pub fn root(&self, leaf: H::Domain) -> H::Domain {
        let mut a = H::Function::default();
        (0..self.path.len()).fold(leaf, |h, height| {
            a.reset();

            let index = self.path[height].index;
            let mut nodes = self.path[height].hashes.clone();
            nodes.insert(index, h);

            a.multi_node(&nodes, height)
        })
    }

    pub fn len(&self) -> usize {
        self.path.len()
    }

    pub fn is_empty(&self) -> bool {
        self.path.is_empty()
    }

    pub fn iter(&self) -> std::slice::Iter<PathElement<H, Arity>> {
        self.path.iter()
    }

    pub fn path_index(&self) -> usize {
        self.path
            .iter()
            .rev()
            .fold(0, |acc, p| (acc * Arity::to_usize()) + p.index)
    }
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct PathElement<H: Hasher, Arity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    hashes: Vec<H::Domain>,
    index: usize,
    #[serde(skip)]
    _arity: PhantomData<Arity>,
}

/// Representation of a merkle proof.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MerkleProof<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity = U0,
    TopTreeArity: PoseidonArity = U0,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    data: ProofData<H, BaseArity, SubTreeArity, TopTreeArity>,
}

impl<
        H: Hasher,
        Arity: 'static + PoseidonArity,
        SubTreeArity: 'static + PoseidonArity,
        TopTreeArity: 'static + PoseidonArity,
    > MerkleProofTrait for MerkleProof<H, Arity, SubTreeArity, TopTreeArity>
{
    type Hasher = H;
    type Arity = Arity;
    type SubTreeArity = SubTreeArity;
    type TopTreeArity = TopTreeArity;

    fn try_from_proof(
        p: proof::Proof<<Self::Hasher as Hasher>::Domain, Self::Arity>,
    ) -> Result<Self> {
        if p.top_layer_nodes() > 0 {
            Ok(MerkleProof {
                data: ProofData::Top(TopProof::try_from_proof(p)?),
            })
        } else if p.sub_layer_nodes() > 0 {
            Ok(MerkleProof {
                data: ProofData::Sub(SubProof::try_from_proof(p)?),
            })
        } else {
            Ok(MerkleProof {
                data: ProofData::Single(SingleProof::try_from_proof(p)?),
            })
        }
    }

    fn verify(&self) -> bool {
        forward_method!(self.data, verify)
    }

    fn leaf(&self) -> H::Domain {
        forward_method!(self.data, leaf)
    }

    fn root(&self) -> H::Domain {
        forward_method!(self.data, root)
    }

    fn len(&self) -> usize {
        forward_method!(self.data, len)
    }

    fn path(&self) -> Vec<(Vec<H::Domain>, usize)> {
        forward_method!(self.data, path)
    }
    fn path_index(&self) -> usize {
        forward_method!(self.data, path_index)
    }

    /// Test only method to break a valid proof.
    #[cfg(test)]
    fn break_me(&mut self, leaf: H::Domain) {
        match self.data {
            ProofData::Single(ref mut proof) => {
                proof.leaf = leaf;
            }
            ProofData::Sub(ref mut proof) => {
                proof.leaf = leaf;
            }
            ProofData::Top(ref mut proof) => {
                proof.leaf = leaf;
            }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum ProofData<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity,
    TopTreeArity: PoseidonArity,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Single(SingleProof<H, BaseArity>),
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Sub(SubProof<H, BaseArity, SubTreeArity>),
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    Top(TopProof<H, BaseArity, SubTreeArity, TopTreeArity>),
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
struct SingleProof<H: Hasher, Arity: PoseidonArity> {
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
    /// The path from leaf to root.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    path: InclusionPath<H, Arity>,
}

impl<H: Hasher, Arity: PoseidonArity> SingleProof<H, Arity> {
    pub fn new(path: InclusionPath<H, Arity>, root: H::Domain, leaf: H::Domain) -> Self {
        SingleProof { root, leaf, path }
    }
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
struct SubProof<H: Hasher, BaseArity: PoseidonArity, SubTreeArity: PoseidonArity> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    base_proof: InclusionPath<H, BaseArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    sub_proof: InclusionPath<H, SubTreeArity>,
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
}

impl<H: Hasher, BaseArity: PoseidonArity, SubTreeArity: PoseidonArity>
    SubProof<H, BaseArity, SubTreeArity>
{
    pub fn new(
        base_proof: InclusionPath<H, BaseArity>,
        sub_proof: InclusionPath<H, SubTreeArity>,
        root: H::Domain,
        leaf: H::Domain,
    ) -> Self {
        Self {
            base_proof,
            sub_proof,
            root,
            leaf,
        }
    }
}

#[derive(Debug, Default, Clone, Serialize, Deserialize)]
struct TopProof<
    H: Hasher,
    BaseArity: PoseidonArity,
    SubTreeArity: PoseidonArity,
    TopTreeArity: PoseidonArity,
> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    base_proof: InclusionPath<H, BaseArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    sub_proof: InclusionPath<H, SubTreeArity>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    top_proof: InclusionPath<H, TopTreeArity>,
    /// Root of the merkle tree.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    root: H::Domain,
    /// The original leaf data for this prof.
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    leaf: H::Domain,
}

impl<
        H: Hasher,
        BaseArity: PoseidonArity,
        SubTreeArity: PoseidonArity,
        TopTreeArity: PoseidonArity,
    > TopProof<H, BaseArity, SubTreeArity, TopTreeArity>
{
    pub fn new(
        base_proof: InclusionPath<H, BaseArity>,
        sub_proof: InclusionPath<H, SubTreeArity>,
        top_proof: InclusionPath<H, TopTreeArity>,
        root: H::Domain,
        leaf: H::Domain,
    ) -> Self {
        Self {
            base_proof,
            sub_proof,
            top_proof,
            root,
            leaf,
        }
    }
}

impl<
        H: Hasher,
        BaseArity: PoseidonArity,
        SubTreeArity: PoseidonArity,
        TopTreeArity: PoseidonArity,
    > MerkleProof<H, BaseArity, SubTreeArity, TopTreeArity>
{
    pub fn new(n: usize) -> Self {
        let root = Default::default();
        let leaf = Default::default();
        let path_elem = PathElement {
            hashes: vec![Default::default(); BaseArity::to_usize()],
            index: 0,
            _arity: Default::default(),
        };
        let path = vec![path_elem; n];
        MerkleProof {
            data: ProofData::Single(SingleProof::new(path.into(), root, leaf)),
        }
    }
}

/// Converts a merkle_light proof to a SingleProof
fn proof_to_single<H: Hasher, Arity: PoseidonArity, TargetArity: PoseidonArity>(
    proof: &proof::Proof<H::Domain, Arity>,
    lemma_start_index: usize,
    sub_root: Option<H::Domain>,
) -> SingleProof<H, TargetArity> {
    let root = proof.root();
    let leaf = if let Some(sub_root) = sub_root {
        sub_root
    } else {
        proof.item()
    };
    let path = extract_path::<H, TargetArity>(proof.lemma(), proof.path(), lemma_start_index);

    SingleProof::new(path, root, leaf)
}

/// 'lemma_start_index' is required because sub/top proofs start at
/// index 0 and base proofs start at index 1 (skipping the leaf at the
/// front)
fn extract_path<H: Hasher, Arity: PoseidonArity>(
    lemma: &[H::Domain],
    path: &[usize],
    lemma_start_index: usize,
) -> InclusionPath<H, Arity> {
    let path = lemma[lemma_start_index..lemma.len() - 1]
        .chunks(Arity::to_usize() - 1)
        .zip(path.iter())
        .map(|(hashes, index)| PathElement {
            hashes: hashes.to_vec(),
            index: *index,
            _arity: Default::default(),
        })
        .collect::<Vec<_>>();

    path.into()
}

impl<H: Hasher, Arity: 'static + PoseidonArity> SingleProof<H, Arity> {
    fn try_from_proof(p: proof::Proof<<H as Hasher>::Domain, Arity>) -> Result<Self> {
        Ok(proof_to_single(&p, 1, None))
    }

    fn verify(&self) -> bool {
        let calculated_root = self.path.root(self.leaf);
        self.root == calculated_root
    }

    fn leaf(&self) -> H::Domain {
        self.leaf
    }

    fn root(&self) -> H::Domain {
        self.root
    }

    fn len(&self) -> usize {
        self.path.len() * (Arity::to_usize() - 1) + 2
    }

    fn path(&self) -> Vec<(Vec<H::Domain>, usize)> {
        self.path
            .iter()
            .map(|x| (x.hashes.clone(), x.index))
            .collect::<Vec<_>>()
    }

    fn path_index(&self) -> usize {
        self.path.path_index()
    }
}

impl<H: Hasher, Arity: 'static + PoseidonArity, SubTreeArity: 'static + PoseidonArity>
    SubProof<H, Arity, SubTreeArity>
{
    fn try_from_proof(p: proof::Proof<<H as Hasher>::Domain, Arity>) -> Result<Self> {
        ensure!(
            p.sub_layer_nodes() == SubTreeArity::to_usize(),
            "sub arity mismatch"
        );
        ensure!(
            p.sub_tree_proof.is_some(),
            "Cannot generate sub proof without a base-proof"
        );
        let base_p = p.sub_tree_proof.as_ref().unwrap();

        // Generate SubProof
        let root = p.root();
        let leaf = base_p.item();
        let base_proof = extract_path::<H, Arity>(base_p.lemma(), base_p.path(), 1);
        let sub_proof = extract_path::<H, SubTreeArity>(p.lemma(), p.path(), 0);

        Ok(SubProof::new(base_proof, sub_proof, root, leaf))
    }

    fn verify(&self) -> bool {
        let sub_leaf = self.base_proof.root(self.leaf);
        let calculated_root = self.sub_proof.root(sub_leaf);

        self.root == calculated_root
    }

    fn leaf(&self) -> H::Domain {
        self.leaf
    }

    fn root(&self) -> H::Domain {
        self.root
    }

    fn len(&self) -> usize {
        SubTreeArity::to_usize()
    }

    fn path(&self) -> Vec<(Vec<H::Domain>, usize)> {
        self.base_proof
            .iter()
            .map(|x| (x.hashes.clone(), x.index))
            .chain(self.sub_proof.iter().map(|x| (x.hashes.clone(), x.index)))
            .collect()
    }

    fn path_index(&self) -> usize {
        let mut base_proof_leaves = 1;
        for _i in 0..self.base_proof.len() {
            base_proof_leaves *= Arity::to_usize()
        }

        let sub_proof_index = self.sub_proof.path_index();

        (sub_proof_index * base_proof_leaves) + self.base_proof.path_index()
    }
}

impl<
        H: Hasher,
        Arity: 'static + PoseidonArity,
        SubTreeArity: 'static + PoseidonArity,
        TopTreeArity: 'static + PoseidonArity,
    > TopProof<H, Arity, SubTreeArity, TopTreeArity>
{
    fn try_from_proof(p: proof::Proof<<H as Hasher>::Domain, Arity>) -> Result<Self> {
        ensure!(
            p.top_layer_nodes() == TopTreeArity::to_usize(),
            "top arity mismatch"
        );
        ensure!(
            p.sub_layer_nodes() == SubTreeArity::to_usize(),
            "sub arity mismatch"
        );

        ensure!(
            p.sub_tree_proof.is_some(),
            "Cannot generate top proof without a sub-proof"
        );
        let sub_p = p.sub_tree_proof.as_ref().unwrap();

        ensure!(
            sub_p.sub_tree_proof.is_some(),
            "Cannot generate top proof without a base-proof"
        );
        let base_p = sub_p.sub_tree_proof.as_ref().unwrap();

        let root = p.root();
        let leaf = base_p.item();

        let base_proof = extract_path::<H, Arity>(base_p.lemma(), base_p.path(), 1);
        let sub_proof = extract_path::<H, SubTreeArity>(sub_p.lemma(), sub_p.path(), 0);
        let top_proof = extract_path::<H, TopTreeArity>(p.lemma(), p.path(), 0);

        Ok(TopProof::new(base_proof, sub_proof, top_proof, root, leaf))
    }

    fn verify(&self) -> bool {
        let sub_leaf = self.base_proof.root(self.leaf);
        let top_leaf = self.sub_proof.root(sub_leaf);
        let calculated_root = self.top_proof.root(top_leaf);

        self.root == calculated_root
    }

    fn leaf(&self) -> H::Domain {
        self.leaf
    }

    fn root(&self) -> H::Domain {
        self.root
    }

    fn len(&self) -> usize {
        TopTreeArity::to_usize()
    }

    fn path(&self) -> Vec<(Vec<H::Domain>, usize)> {
        self.base_proof
            .iter()
            .map(|x| (x.hashes.clone(), x.index))
            .chain(self.sub_proof.iter().map(|x| (x.hashes.clone(), x.index)))
            .chain(self.top_proof.iter().map(|x| (x.hashes.clone(), x.index)))
            .collect()
    }

    fn path_index(&self) -> usize {
        let mut base_proof_leaves = 1;
        for _i in 0..self.base_proof.len() {
            base_proof_leaves *= Arity::to_usize()
        }

        let sub_proof_leaves = base_proof_leaves * SubTreeArity::to_usize();

        let sub_proof_index = self.sub_proof.path_index();
        let top_proof_index = self.top_proof.path_index();

        (sub_proof_index * base_proof_leaves)
            + (top_proof_index * sub_proof_leaves)
            + self.base_proof.path_index()
    }
}

#[cfg(test)]
mod tests {
    use super::super::*;

    use generic_array::typenum;
    use rand;

    use crate::hasher::{Blake2sHasher, Domain, PedersenHasher, PoseidonHasher, Sha256Hasher};
    use crate::merkle::{generate_tree, MerkleProofTrait};

    fn merklepath<Tree: 'static + MerkleTreeTrait>() {
        let node_size = 32;
        let nodes = 64 * get_base_tree_count::<Tree>();

        let mut rng = rand::thread_rng();
        let (data, tree) = generate_tree::<Tree, _>(&mut rng, nodes, None);

        for i in 0..nodes {
            let proof = tree.gen_proof(i).unwrap();

            assert!(proof.verify(), "failed to validate");

            assert!(proof.validate(i), "failed to validate valid merkle path");
            let data_slice = &data[i * node_size..(i + 1) * node_size].to_vec();
            assert!(
                proof.validate_data(
                    <Tree::Hasher as Hasher>::Domain::try_from_bytes(data_slice).unwrap()
                ),
                "failed to validate valid data"
            );
        }
    }

    #[test]
    fn merklepath_pedersen_2() {
        merklepath::<
            MerkleTreeWrapper<
                PedersenHasher,
                DiskStore<<PedersenHasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_pedersen_4() {
        merklepath::<
            MerkleTreeWrapper<
                PedersenHasher,
                DiskStore<<PedersenHasher as Hasher>::Domain>,
                typenum::U4,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_pedersen_8() {
        merklepath::<
            MerkleTreeWrapper<
                PedersenHasher,
                DiskStore<<PedersenHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_pedersen_2_2() {
        merklepath::<
            MerkleTreeWrapper<
                PedersenHasher,
                DiskStore<<PedersenHasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U2,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_pedersen_2_2_2() {
        merklepath::<
            MerkleTreeWrapper<
                PedersenHasher,
                DiskStore<<PedersenHasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U2,
                typenum::U2,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_2() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_4() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U4,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_8() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_8_2() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U2,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_8_4() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U4,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_poseidon_8_4_2() {
        merklepath::<
            MerkleTreeWrapper<
                PoseidonHasher,
                DiskStore<<PoseidonHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U4,
                typenum::U2,
            >,
        >();
    }

    #[test]
    fn merklepath_sha256_2() {
        merklepath::<
            MerkleTreeWrapper<
                Sha256Hasher,
                DiskStore<<Sha256Hasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_sha256_4() {
        merklepath::<
            MerkleTreeWrapper<
                Sha256Hasher,
                DiskStore<<Sha256Hasher as Hasher>::Domain>,
                typenum::U4,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_sha256_2_4() {
        merklepath::<
            MerkleTreeWrapper<
                Sha256Hasher,
                DiskStore<<Sha256Hasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U4,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_sha256_top_2_4_2() {
        merklepath::<
            MerkleTreeWrapper<
                Sha256Hasher,
                DiskStore<<Sha256Hasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U4,
                typenum::U2,
            >,
        >();
    }

    #[test]
    fn merklepath_blake2s_2() {
        merklepath::<
            MerkleTreeWrapper<
                Blake2sHasher,
                DiskStore<<Blake2sHasher as Hasher>::Domain>,
                typenum::U2,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_blake2s_4() {
        merklepath::<
            MerkleTreeWrapper<
                Blake2sHasher,
                DiskStore<<Blake2sHasher as Hasher>::Domain>,
                typenum::U4,
                typenum::U0,
                typenum::U0,
            >,
        >();
    }

    #[test]
    fn merklepath_blake2s_8_4_2() {
        merklepath::<
            MerkleTreeWrapper<
                Blake2sHasher,
                DiskStore<<Blake2sHasher as Hasher>::Domain>,
                typenum::U8,
                typenum::U4,
                typenum::U2,
            >,
        >();
    }
}

'''
'''--- storage-proofs/core/src/merkle/tree.rs ---
#![allow(clippy::len_without_is_empty)]

use std::marker::PhantomData;

use anyhow::Result;
use generic_array::typenum::{self, U0};
use merkletree::hash::Hashable;
use merkletree::merkle;
use merkletree::merkle::FromIndexedParallelIterator;
use merkletree::store::{ReplicaConfig, StoreConfig};
use rayon::prelude::*;

use crate::hasher::{Hasher, PoseidonArity};

use super::*;

/// Trait used to abstract over the way Merkle Trees are constructed and stored.
pub trait MerkleTreeTrait: Send + Sync + std::fmt::Debug {
    type Arity: 'static + PoseidonArity;
    type SubTreeArity: 'static + PoseidonArity;
    type TopTreeArity: 'static + PoseidonArity;
    type Hasher: 'static + Hasher;
    type Store: Store<<Self::Hasher as Hasher>::Domain>;
    type Proof: MerkleProofTrait<
        Hasher = Self::Hasher,
        Arity = Self::Arity,
        SubTreeArity = Self::SubTreeArity,
        TopTreeArity = Self::TopTreeArity,
    >;

    /// Print a unique name for this configuration.
    fn display() -> String;
    /// Returns the root hash of the tree.
    fn root(&self) -> <Self::Hasher as Hasher>::Domain;
    /// Creates a merkle proof of the node at the given index.
    fn gen_proof(&self, index: usize) -> Result<Self::Proof>;
    fn gen_cached_proof(&self, i: usize, rows_to_discard: Option<usize>) -> Result<Self::Proof>;
    fn row_count(&self) -> usize;
    fn leaves(&self) -> usize;
    fn from_merkle(
        tree: merkle::MerkleTree<
            <Self::Hasher as Hasher>::Domain,
            <Self::Hasher as Hasher>::Function,
            Self::Store,
            Self::Arity,
            Self::SubTreeArity,
            Self::TopTreeArity,
        >,
    ) -> Self;
}

pub struct MerkleTreeWrapper<
    H: Hasher,
    S: Store<<H as Hasher>::Domain>,
    U: PoseidonArity,
    V: PoseidonArity = typenum::U0,
    W: PoseidonArity = typenum::U0,
> {
    pub inner: merkle::MerkleTree<<H as Hasher>::Domain, <H as Hasher>::Function, S, U, V, W>,
    pub h: PhantomData<H>,
}

impl<
        H: 'static + Hasher,
        S: Store<<H as Hasher>::Domain>,
        U: 'static + PoseidonArity,
        V: 'static + PoseidonArity,
        W: 'static + PoseidonArity,
    > MerkleTreeTrait for MerkleTreeWrapper<H, S, U, V, W>
{
    type Arity = U;
    type SubTreeArity = V;
    type TopTreeArity = W;
    type Hasher = H;
    type Store = S;
    type Proof = MerkleProof<Self::Hasher, Self::Arity, Self::SubTreeArity, Self::TopTreeArity>;

    fn display() -> String {
        format!(
            "merkletree-{}-{}-{}-{}",
            H::name(),
            U::to_usize(),
            V::to_usize(),
            W::to_usize()
        )
    }

    fn root(&self) -> <Self::Hasher as Hasher>::Domain {
        self.inner.root()
    }

    fn gen_proof(&self, i: usize) -> Result<Self::Proof> {
        let proof = self.inner.gen_proof(i)?;

        debug_assert!(proof.validate::<H::Function>().expect("validate failed"));

        MerkleProof::try_from_proof(proof)
    }

    fn gen_cached_proof(&self, i: usize, rows_to_discard: Option<usize>) -> Result<Self::Proof> {
        if rows_to_discard.is_some() && rows_to_discard.unwrap() == 0 {
            return self.gen_proof(i);
        }

        let proof = self.inner.gen_cached_proof(i, rows_to_discard)?;

        debug_assert!(proof.validate::<H::Function>().expect("validate failed"));

        MerkleProof::try_from_proof(proof)
    }

    fn row_count(&self) -> usize {
        self.inner.row_count()
    }

    fn leaves(&self) -> usize {
        self.inner.leafs()
    }

    fn from_merkle(
        tree: merkle::MerkleTree<
            <Self::Hasher as Hasher>::Domain,
            <Self::Hasher as Hasher>::Function,
            Self::Store,
            Self::Arity,
            Self::SubTreeArity,
            Self::TopTreeArity,
        >,
    ) -> Self {
        tree.into()
    }
}

impl<
        H: Hasher,
        S: Store<<H as Hasher>::Domain>,
        U: PoseidonArity,
        V: PoseidonArity,
        W: PoseidonArity,
    > From<merkle::MerkleTree<<H as Hasher>::Domain, <H as Hasher>::Function, S, U, V, W>>
    for MerkleTreeWrapper<H, S, U, V, W>
{
    fn from(
        tree: merkle::MerkleTree<<H as Hasher>::Domain, <H as Hasher>::Function, S, U, V, W>,
    ) -> Self {
        Self {
            inner: tree,
            h: Default::default(),
        }
    }
}

impl<
        H: Hasher,
        S: Store<<H as Hasher>::Domain>,
        U: PoseidonArity,
        V: PoseidonArity,
        W: PoseidonArity,
    > MerkleTreeWrapper<H, S, U, V, W>
{
    pub fn new<I: IntoIterator<Item = H::Domain>>(data: I) -> Result<Self> {
        let tree = merkle::MerkleTree::new(data)?;
        Ok(tree.into())
    }

    pub fn new_with_config<I: IntoIterator<Item = H::Domain>>(
        data: I,
        config: StoreConfig,
    ) -> Result<Self> {
        let tree = merkle::MerkleTree::new_with_config(data, config)?;
        Ok(tree.into())
    }

    pub fn from_data_with_config<O: Hashable<H::Function>, I: IntoIterator<Item = O>>(
        data: I,
        config: StoreConfig,
    ) -> Result<Self> {
        let tree = merkle::MerkleTree::from_data_with_config(data, config)?;
        Ok(tree.into())
    }

    pub fn from_data_store(data: S, leafs: usize) -> Result<Self> {
        let tree = merkle::MerkleTree::from_data_store(data, leafs)?;
        Ok(tree.into())
    }

    pub fn from_tree_slice(data: &[u8], leafs: usize) -> Result<Self> {
        let tree = merkle::MerkleTree::from_tree_slice(data, leafs)?;
        Ok(tree.into())
    }

    pub fn from_tree_slice_with_config(
        data: &[u8],
        leafs: usize,
        config: StoreConfig,
    ) -> Result<Self> {
        let tree = merkle::MerkleTree::from_tree_slice_with_config(data, leafs, config)?;
        Ok(tree.into())
    }

    pub fn from_trees(trees: Vec<MerkleTreeWrapper<H, S, U, U0, U0>>) -> Result<Self> {
        let trees = trees.into_iter().map(|t| t.inner).collect();
        let tree = merkle::MerkleTree::from_trees(trees)?;
        Ok(tree.into())
    }

    pub fn from_sub_trees(trees: Vec<MerkleTreeWrapper<H, S, U, V, U0>>) -> Result<Self> {
        let trees = trees.into_iter().map(|t| t.inner).collect();
        let tree = merkle::MerkleTree::from_sub_trees(trees)?;
        Ok(tree.into())
    }

    pub fn from_sub_trees_as_trees(trees: Vec<MerkleTreeWrapper<H, S, U, U0, U0>>) -> Result<Self> {
        let trees = trees.into_iter().map(|t| t.inner).collect();
        let tree = merkle::MerkleTree::from_sub_trees_as_trees(trees)?;
        Ok(tree.into())
    }

    pub fn from_slices(
        tree_data: &[&[u8]],
        leafs: usize,
    ) -> Result<MerkleTreeWrapper<H, S, U, V, U0>> {
        let tree = merkle::MerkleTree::<
                <H as Hasher>::Domain, <H as Hasher>::Function, S, U, V, U0
        >::from_slices(tree_data, leafs)?;
        Ok(tree.into())
    }

    pub fn from_slices_with_configs(
        tree_data: &[&[u8]],
        leafs: usize,
        configs: &[StoreConfig],
    ) -> Result<Self> {
        let tree = merkle::MerkleTree::from_slices_with_configs(tree_data, leafs, configs)?;
        Ok(tree.into())
    }

    pub fn from_stores(leafs: usize, stores: Vec<S>) -> Result<Self> {
        let tree = merkle::MerkleTree::from_stores(leafs, stores)?;
        Ok(tree.into())
    }

    pub fn from_store_configs(leafs: usize, configs: &[StoreConfig]) -> Result<Self> {
        let tree = merkle::MerkleTree::from_store_configs(leafs, configs)?;
        Ok(tree.into())
    }

    pub fn from_store_configs_and_replica(
        leafs: usize,
        configs: &[StoreConfig],
        replica_config: &ReplicaConfig,
    ) -> Result<LCTree<H, U, V, W>> {
        let tree =
            merkle::MerkleTree::from_store_configs_and_replica(leafs, configs, replica_config)?;
        Ok(tree.into())
    }

    pub fn from_sub_tree_store_configs(leafs: usize, configs: &[StoreConfig]) -> Result<Self> {
        let tree = merkle::MerkleTree::from_sub_tree_store_configs(leafs, configs)?;
        Ok(tree.into())
    }

    pub fn try_from_iter<I: IntoIterator<Item = Result<H::Domain>>>(into: I) -> Result<Self> {
        let tree = merkle::MerkleTree::try_from_iter(into)?;
        Ok(tree.into())
    }

    pub fn from_sub_tree_store_configs_and_replica(
        leafs: usize,
        configs: &[StoreConfig],
        replica_config: &ReplicaConfig,
    ) -> Result<LCTree<H, U, V, W>> {
        let tree = merkle::MerkleTree::from_sub_tree_store_configs_and_replica(
            leafs,
            configs,
            replica_config,
        )?;
        Ok(tree.into())
    }

    pub fn try_from_iter_with_config<I: IntoIterator<Item = Result<H::Domain>>>(
        into: I,
        config: StoreConfig,
    ) -> Result<Self> {
        let tree = merkle::MerkleTree::try_from_iter_with_config(into, config)?;
        Ok(tree.into())
    }

    pub fn from_par_iter<I>(par_iter: I) -> Result<Self>
    where
        I: IntoParallelIterator<Item = H::Domain>,
        I::Iter: IndexedParallelIterator,
    {
        let tree = merkle::MerkleTree::from_par_iter(par_iter)?;
        Ok(tree.into())
    }

    pub fn from_par_iter_with_config<I>(par_iter: I, config: StoreConfig) -> Result<Self>
    where
        I: IntoParallelIterator<Item = H::Domain>,
        I::Iter: IndexedParallelIterator,
    {
        let tree = merkle::MerkleTree::from_par_iter_with_config(par_iter, config)?;
        Ok(tree.into())
    }
}

impl<
        H: Hasher,
        S: Store<<H as Hasher>::Domain>,
        BaseArity: PoseidonArity,
        SubTreeArity: PoseidonArity,
        TopTreeArity: PoseidonArity,
    > std::fmt::Debug for MerkleTreeWrapper<H, S, BaseArity, SubTreeArity, TopTreeArity>
{
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("MerkleTreeWrapper")
            .field("inner", &self.inner)
            .field("Hasher", &H::name())
            .finish()
    }
}

impl<
        H: Hasher,
        S: Store<<H as Hasher>::Domain>,
        BaseArity: PoseidonArity,
        SubTreeArity: PoseidonArity,
        TopTreeArity: PoseidonArity,
    > std::ops::Deref for MerkleTreeWrapper<H, S, BaseArity, SubTreeArity, TopTreeArity>
{
    type Target =
        merkle::MerkleTree<H::Domain, H::Function, S, BaseArity, SubTreeArity, TopTreeArity>;

    fn deref(&self) -> &Self::Target {
        &self.inner
    }
}

impl<
        H: Hasher,
        S: Store<<H as Hasher>::Domain>,
        BaseArity: PoseidonArity,
        SubTreeArity: PoseidonArity,
        TopTreeArity: PoseidonArity,
    > std::ops::DerefMut for MerkleTreeWrapper<H, S, BaseArity, SubTreeArity, TopTreeArity>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.inner
    }
}

'''
'''--- storage-proofs/core/src/multi_proof.rs ---
use bellperson::groth16;

use crate::error::Result;
use anyhow::Context;
use paired::bls12_381::Bls12;
use std::io::{self, Read, Write};

pub struct MultiProof<'a> {
    pub circuit_proofs: Vec<groth16::Proof<Bls12>>,
    pub verifying_key: &'a groth16::VerifyingKey<Bls12>,
}

impl<'a> MultiProof<'a> {
    pub fn new(
        groth_proofs: Vec<groth16::Proof<Bls12>>,
        verifying_key: &'a groth16::VerifyingKey<Bls12>,
    ) -> Self {
        MultiProof {
            circuit_proofs: groth_proofs,
            verifying_key,
        }
    }

    pub fn new_from_reader<R: Read>(
        partitions: Option<usize>,
        mut reader: R,
        verifying_key: &'a groth16::VerifyingKey<Bls12>,
    ) -> Result<Self> {
        let num_proofs = match partitions {
            Some(n) => n,
            None => 1,
        };
        let proofs = (0..num_proofs)
            .map(|_| groth16::Proof::read(&mut reader))
            .collect::<io::Result<Vec<_>>>()?;

        Ok(Self::new(proofs, verifying_key))
    }

    pub fn write<W: Write>(&self, mut writer: W) -> Result<()> {
        for proof in &self.circuit_proofs {
            proof.write(&mut writer)?
        }
        Ok(())
    }

    pub fn to_vec(&self) -> Result<Vec<u8>> {
        let mut out = Vec::new();
        self.write(&mut out).context("known allocation target")?;
        Ok(out)
    }

    pub fn len(&self) -> usize {
        self.circuit_proofs.len()
    }

    pub fn is_empty(&self) -> bool {
        self.circuit_proofs.is_empty()
    }
}

'''
'''--- storage-proofs/core/src/parameter_cache.rs ---
use crate::error::*;
use anyhow::bail;
use bellperson::groth16::Parameters;
use bellperson::{groth16, Circuit};
use fs2::FileExt;
use itertools::Itertools;
use log::info;
use paired::bls12_381::Bls12;
use rand::RngCore;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

use std::env;
use std::fs::{self, create_dir_all, File};
use std::io::{self, SeekFrom};
use std::path::{Path, PathBuf};

/// Bump this when circuits change to invalidate the cache.
pub const VERSION: usize = 27;

pub const PARAMETER_CACHE_ENV_VAR: &str = "FIL_PROOFS_PARAMETER_CACHE";
pub const PARAMETER_CACHE_DIR: &str = "/var/tmp/filecoin-proof-parameters/";
pub const GROTH_PARAMETER_EXT: &str = "params";
pub const PARAMETER_METADATA_EXT: &str = "meta";
pub const VERIFYING_KEY_EXT: &str = "vk";

#[derive(Debug)]
struct LockedFile(File);

// TODO: use in memory lock as well, as file locks do not guarantee exclusive access across OSes.

impl LockedFile {
    pub fn open_exclusive_read<P: AsRef<Path>>(p: P) -> io::Result<Self> {
        let f = fs::OpenOptions::new().read(true).open(p)?;
        f.lock_exclusive()?;

        Ok(LockedFile(f))
    }

    pub fn open_exclusive<P: AsRef<Path>>(p: P) -> io::Result<Self> {
        let f = fs::OpenOptions::new()
            .read(true)
            .write(true)
            .create(true)
            .open(p)?;
        f.lock_exclusive()?;

        Ok(LockedFile(f))
    }
}

impl io::Write for LockedFile {
    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {
        self.0.write(buf)
    }

    fn flush(&mut self) -> io::Result<()> {
        self.0.flush()
    }
}

impl io::Read for LockedFile {
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        self.0.read(buf)
    }
}

impl io::Seek for LockedFile {
    fn seek(&mut self, pos: SeekFrom) -> io::Result<u64> {
        self.0.seek(pos)
    }
}

impl Drop for LockedFile {
    fn drop(&mut self) {
        self.0
            .unlock()
            .unwrap_or_else(|e| panic!("{}: failed to {:?} unlock file safely", e, &self.0));
    }
}

fn parameter_cache_dir_name() -> String {
    match env::var(PARAMETER_CACHE_ENV_VAR) {
        Ok(dir) => dir,
        Err(_) => String::from(PARAMETER_CACHE_DIR),
    }
}

pub fn parameter_cache_dir() -> PathBuf {
    Path::new(&parameter_cache_dir_name()).to_path_buf()
}

pub fn parameter_cache_params_path(parameter_set_identifier: &str) -> PathBuf {
    let dir = Path::new(&parameter_cache_dir_name()).to_path_buf();
    dir.join(format!(
        "v{}-{}.{}",
        VERSION, parameter_set_identifier, GROTH_PARAMETER_EXT
    ))
}

pub fn parameter_cache_metadata_path(parameter_set_identifier: &str) -> PathBuf {
    let dir = Path::new(&parameter_cache_dir_name()).to_path_buf();
    dir.join(format!(
        "v{}-{}.{}",
        VERSION, parameter_set_identifier, PARAMETER_METADATA_EXT
    ))
}

pub fn parameter_cache_verifying_key_path(parameter_set_identifier: &str) -> PathBuf {
    let dir = Path::new(&parameter_cache_dir_name()).to_path_buf();
    dir.join(format!(
        "v{}-{}.{}",
        VERSION, parameter_set_identifier, VERIFYING_KEY_EXT
    ))
}

fn ensure_ancestor_dirs_exist(cache_entry_path: PathBuf) -> Result<PathBuf> {
    info!(
        "ensuring that all ancestor directories for: {:?} exist",
        cache_entry_path
    );

    if let Some(parent_dir) = cache_entry_path.parent() {
        if let Err(err) = create_dir_all(&parent_dir) {
            match err.kind() {
                io::ErrorKind::AlreadyExists => {}
                _ => return Err(From::from(err)),
            }
        }
    } else {
        bail!("{:?} has no parent directory", cache_entry_path);
    }

    Ok(cache_entry_path)
}

pub trait ParameterSetMetadata: Clone {
    fn identifier(&self) -> String;
    fn sector_size(&self) -> u64;
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CacheEntryMetadata {
    pub sector_size: u64,
}

pub trait CacheableParameters<C, P>
where
    C: Circuit<Bls12>,
    P: ParameterSetMetadata,
{
    fn cache_prefix() -> String;

    fn cache_meta(pub_params: &P) -> CacheEntryMetadata {
        CacheEntryMetadata {
            sector_size: pub_params.sector_size(),
        }
    }

    fn cache_identifier(pub_params: &P) -> String {
        let param_identifier = pub_params.identifier();
        info!("parameter set identifier for cache: {}", param_identifier);
        let mut hasher = Sha256::default();
        hasher.input(&param_identifier.into_bytes());
        let circuit_hash = hasher.result();
        format!(
            "{}-{:02x}",
            Self::cache_prefix(),
            circuit_hash.iter().format("")
        )
    }

    fn get_param_metadata(_circuit: C, pub_params: &P) -> Result<CacheEntryMetadata> {
        let id = Self::cache_identifier(pub_params);

        // generate (or load) metadata
        let meta_path = ensure_ancestor_dirs_exist(parameter_cache_metadata_path(&id))?;
        read_cached_metadata(&meta_path)
            .or_else(|_| write_cached_metadata(&meta_path, Self::cache_meta(pub_params)))
    }

    /// If the rng option argument is set, parameters will be
    /// generated using it.  This is used for testing only, or where
    /// parameters are otherwise unavailable (e.g. benches).  If rng
    /// is not set, an error will result if parameters are not
    /// present.
    fn get_groth_params<R: RngCore>(
        rng: Option<&mut R>,
        circuit: C,
        pub_params: &P,
    ) -> Result<groth16::MappedParameters<Bls12>> {
        let id = Self::cache_identifier(pub_params);

        let generate = || -> Result<_> {
            if let Some(rng) = rng {
                use std::time::Instant;

                info!("Actually generating groth params. (id: {})", &id);
                let start = Instant::now();
                let parameters = groth16::generate_random_parameters::<Bls12, _, _>(circuit, rng)?;
                let generation_time = start.elapsed();
                info!(
                    "groth_parameter_generation_time: {:?} (id: {})",
                    generation_time, &id
                );
                Ok(parameters)
            } else {
                bail!("No cached parameters found for {}", id);
            }
        };

        // load or generate Groth parameter mappings
        let cache_path = ensure_ancestor_dirs_exist(parameter_cache_params_path(&id))?;
        match read_cached_params(&cache_path) {
            Ok(x) => Ok(x),
            Err(_) => {
                write_cached_params(&cache_path, generate()?).unwrap_or_else(|e| {
                    panic!("{}: failed to write generated parameters to cache", e)
                });
                Ok(read_cached_params(&cache_path)?)
            }
        }
    }

    /// If the rng option argument is set, parameters will be
    /// generated using it.  This is used for testing only, or where
    /// parameters are otherwise unavailable (e.g. benches).  If rng
    /// is not set, an error will result if parameters are not
    /// present.
    fn get_verifying_key<R: RngCore>(
        rng: Option<&mut R>,
        circuit: C,
        pub_params: &P,
    ) -> Result<groth16::VerifyingKey<Bls12>> {
        let id = Self::cache_identifier(pub_params);

        let generate = || -> Result<groth16::VerifyingKey<Bls12>> {
            let groth_params = Self::get_groth_params(rng, circuit, pub_params)?;
            info!("Getting verifying key. (id: {})", &id);
            Ok(groth_params.vk)
        };

        // generate (or load) verifying key
        let cache_path = ensure_ancestor_dirs_exist(parameter_cache_verifying_key_path(&id))?;
        read_cached_verifying_key(&cache_path)
            .or_else(|_| write_cached_verifying_key(&cache_path, generate()?))
    }
}

fn ensure_parent(path: &PathBuf) -> Result<()> {
    match path.parent() {
        Some(dir) => {
            create_dir_all(dir)?;
            Ok(())
        }
        None => Ok(()),
    }
}

// Reads parameter mappings using mmap so that they can be lazily
// loaded later.
fn read_cached_params(cache_entry_path: &PathBuf) -> Result<groth16::MappedParameters<Bls12>> {
    info!("checking cache_path: {:?} for parameters", cache_entry_path);
    with_exclusive_read_lock(cache_entry_path, |_| {
        let params = Parameters::build_mapped_parameters(cache_entry_path.to_path_buf(), false)?;
        info!("read parameters from cache {:?} ", cache_entry_path);

        Ok(params)
    })
}

fn read_cached_verifying_key(cache_entry_path: &PathBuf) -> Result<groth16::VerifyingKey<Bls12>> {
    info!(
        "checking cache_path: {:?} for verifying key",
        cache_entry_path
    );
    with_exclusive_read_lock(cache_entry_path, |mut file| {
        let key = groth16::VerifyingKey::read(&mut file)?;
        info!("read verifying key from cache {:?} ", cache_entry_path);

        Ok(key)
    })
}

fn read_cached_metadata(cache_entry_path: &PathBuf) -> Result<CacheEntryMetadata> {
    info!("checking cache_path: {:?} for metadata", cache_entry_path);
    with_exclusive_read_lock(cache_entry_path, |file| {
        let value = serde_json::from_reader(file)?;
        info!("read metadata from cache {:?} ", cache_entry_path);

        Ok(value)
    })
}

fn write_cached_metadata(
    cache_entry_path: &PathBuf,
    value: CacheEntryMetadata,
) -> Result<CacheEntryMetadata> {
    with_exclusive_lock(cache_entry_path, |file| {
        serde_json::to_writer(file, &value)?;
        info!("wrote metadata to cache {:?} ", cache_entry_path);

        Ok(value)
    })
}

fn write_cached_verifying_key(
    cache_entry_path: &PathBuf,
    value: groth16::VerifyingKey<Bls12>,
) -> Result<groth16::VerifyingKey<Bls12>> {
    with_exclusive_lock(cache_entry_path, |file| {
        value.write(file)?;
        info!("wrote verifying key to cache {:?} ", cache_entry_path);

        Ok(value)
    })
}

fn write_cached_params(
    cache_entry_path: &PathBuf,
    value: groth16::Parameters<Bls12>,
) -> Result<groth16::Parameters<Bls12>> {
    with_exclusive_lock(cache_entry_path, |file| {
        value.write(file)?;
        info!("wrote groth parameters to cache {:?} ", cache_entry_path);

        Ok(value)
    })
}

fn with_exclusive_lock<T>(
    file_path: &PathBuf,
    f: impl FnOnce(&mut LockedFile) -> Result<T>,
) -> Result<T> {
    with_open_file(file_path, LockedFile::open_exclusive, f)
}

fn with_exclusive_read_lock<T>(
    file_path: &PathBuf,
    f: impl FnOnce(&mut LockedFile) -> Result<T>,
) -> Result<T> {
    with_open_file(file_path, LockedFile::open_exclusive_read, f)
}

fn with_open_file<'a, T>(
    file_path: &'a PathBuf,
    open_file: impl FnOnce(&'a PathBuf) -> io::Result<LockedFile>,
    f: impl FnOnce(&mut LockedFile) -> Result<T>,
) -> Result<T> {
    ensure_parent(&file_path)?;
    f(&mut open_file(&file_path)?)
}

'''
'''--- storage-proofs/core/src/partitions.rs ---
pub type Partitions = Option<usize>;

pub fn partition_count(partitions: Partitions) -> usize {
    match partitions {
        None => 1,
        Some(0) => panic!("cannot specify zero partitions"),
        Some(k) => k,
    }
}

'''
'''--- storage-proofs/core/src/pieces.rs ---
use std::io::Read;

use anyhow::{ensure, Context};
use merkletree::merkle::next_pow2;

use crate::error::*;
use crate::fr32::Fr32Ary;
use crate::hasher::{Domain, Hasher};
use crate::merkle::BinaryMerkleTree;
use crate::util::NODE_SIZE;

/// `position`, `length` are in H::Domain units
#[derive(Clone, Debug)]
pub struct PieceSpec {
    pub comm_p: Fr32Ary,
    pub position: usize,
    pub number_of_leaves: usize,
}

impl PieceSpec {
    /// `compute_packing` returns a packing list and a proof size.
    /// A packing list is a pair of (start, length) pairs, relative to the beginning of the piece,
    /// in leaf units.
    /// Proof size is a number of elements (size same as one leaf) provided in the variable part of a PieceInclusionProof.
    pub fn compute_packing(&self, tree_len: usize) -> Result<(Vec<(usize, usize)>, usize)> {
        ensure!(self.is_aligned(tree_len)?, Error::UnalignedPiece);

        let packing_list = vec![(0, self.number_of_leaves)];
        Ok((packing_list, self.proof_length(tree_len)))
    }

    pub fn is_aligned(&self, tree_len: usize) -> Result<bool> {
        piece_is_aligned(self.position, self.number_of_leaves, tree_len)
    }

    fn height(&self) -> usize {
        height_for_length(self.number_of_leaves)
    }

    // `proof_length` is length of proof that comm_p is in the containing root, excluding comm_p and root, which aren't needed for the proof itself.
    fn proof_length(&self, tree_len: usize) -> usize {
        height_for_length(tree_len) - self.height()
    }
}

/// Generate `comm_p` from a source and return it as bytes.
pub fn generate_piece_commitment_bytes_from_source<H: Hasher>(
    source: &mut dyn Read,
    padded_piece_size: usize,
) -> Result<Fr32Ary> {
    ensure!(padded_piece_size > 32, "piece is too small");
    ensure!(padded_piece_size % 32 == 0, "piece is not valid size");

    let mut buf = [0; NODE_SIZE];

    let parts = (padded_piece_size as f64 / NODE_SIZE as f64).ceil() as usize;

    let tree = BinaryMerkleTree::<H>::try_from_iter((0..parts).map(|_| {
        source.read_exact(&mut buf)?;
        <H::Domain as Domain>::try_from_bytes(&buf).context("invalid Fr element")
    }))
    .context("failed to build tree")?;

    let mut comm_p_bytes = [0; NODE_SIZE];
    let comm_p = tree.root();
    comm_p.write_bytes(&mut comm_p_bytes)?;

    Ok(comm_p_bytes)
}

////////////////////////////////////////////////////////////////////////////////
// Utility

pub fn piece_is_aligned(position: usize, length: usize, tree_len: usize) -> Result<bool> {
    let capacity_at_pos = subtree_capacity(position, tree_len)?;

    Ok(capacity_at_pos.is_power_of_two() && capacity_at_pos >= length)
}

fn height_for_length(n: usize) -> usize {
    if n == 0 {
        0
    } else {
        (n as f64).log2().ceil() as usize
    }
}

fn subtree_capacity(pos: usize, total: usize) -> Result<usize> {
    ensure!(pos < total, "position must be less than tree capacity");

    let mut capacity = 1;
    // If tree is not 'full', then pos 0 will have subtree_capacity greater than size of tree.
    let mut cursor = pos + next_pow2(total);

    while cursor & 1 == 0 {
        capacity *= 2;
        cursor >>= 1;
    }
    Ok(capacity)
}
////////////////////////////////////////////////////////////////////////////////

#[cfg(test)]
mod tests {
    use super::*;
    use crate::hasher::PedersenHasher;

    #[test]
    fn test_subtree_capacity() {
        assert_eq!(subtree_capacity(0, 16).unwrap(), 16);
        assert_eq!(subtree_capacity(1, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(2, 16).unwrap(), 2);
        assert_eq!(subtree_capacity(3, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(4, 16).unwrap(), 4);
        assert_eq!(subtree_capacity(5, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(6, 16).unwrap(), 2);
        assert_eq!(subtree_capacity(7, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(8, 16).unwrap(), 8);
        assert_eq!(subtree_capacity(9, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(10, 16).unwrap(), 2);
        assert_eq!(subtree_capacity(11, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(12, 16).unwrap(), 4);
        assert_eq!(subtree_capacity(13, 16).unwrap(), 1);
        assert_eq!(subtree_capacity(14, 16).unwrap(), 2);
        assert_eq!(subtree_capacity(15, 16).unwrap(), 1);
    }

    #[test]
    fn test_generate_piece_commitment_bytes_from_source() -> Result<()> {
        let some_bytes: Vec<u8> = vec![0; 64];
        let mut some_bytes_slice: &[u8] = &some_bytes;
        generate_piece_commitment_bytes_from_source::<PedersenHasher>(&mut some_bytes_slice, 64)
            .expect("threshold for sufficient bytes is 32");

        let not_enough_bytes: Vec<u8> = vec![0; 7];
        let mut not_enough_bytes_slice: &[u8] = &not_enough_bytes;
        assert!(
            generate_piece_commitment_bytes_from_source::<PedersenHasher>(
                &mut not_enough_bytes_slice,
                7
            )
            .is_err(),
            "insufficient bytes should error out"
        );

        Ok(())
    }
}

'''
'''--- storage-proofs/core/src/por.rs ---
use anyhow::ensure;
use serde::{Deserialize, Serialize};
use std::marker::PhantomData;

use crate::error::*;
use crate::hasher::{Domain, Hasher};
use crate::merkle::{MerkleProofTrait, MerkleTreeTrait};
use crate::parameter_cache::ParameterSetMetadata;
use crate::proof::{NoRequirements, ProofScheme};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "<Proof::Hasher as Hasher>::Domain: Serialize",
        deserialize = "<Proof::Hasher as Hasher>::Domain: Deserialize<'de>"
    ))]
    pub proof: Proof,
    #[serde(bound(
        serialize = "<Proof::Hasher as Hasher>::Domain: Serialize",
        deserialize = "<Proof::Hasher as Hasher>::Domain: Deserialize<'de>"
    ))]
    pub data: <Proof::Hasher as Hasher>::Domain,
}

/// The parameters shared between the prover and verifier.
#[derive(Clone, Debug)]
pub struct PublicParams {
    /// How many leaves the underlying merkle tree has.
    pub leaves: usize,
    pub private: bool,
}

impl ParameterSetMetadata for PublicParams {
    fn identifier(&self) -> String {
        format!(
            "merklepor::PublicParams{{leaves: {}; private: {}}}",
            self.leaves, self.private
        )
    }

    fn sector_size(&self) -> u64 {
        unimplemented!("required for parameter metadata file generation")
    }
}

/// The inputs that are necessary for the verifier to verify the proof.
#[derive(Debug, Clone)]
pub struct PublicInputs<T: Domain> {
    /// The root hash of the underlying merkle tree.
    pub commitment: Option<T>,
    /// The challenge, which leaf to prove.
    pub challenge: usize,
}

/// The inputs that are only available to the prover.
#[derive(Debug)]
pub struct PrivateInputs<'a, Tree: 'a + MerkleTreeTrait> {
    /// The data of the leaf.
    pub leaf: <Tree::Hasher as Hasher>::Domain,
    /// The underlying merkle tree.
    pub tree: &'a Tree,
}

impl<'a, Tree: MerkleTreeTrait> PrivateInputs<'a, Tree> {
    pub fn new(leaf: <Tree::Hasher as Hasher>::Domain, tree: &'a Tree) -> Self {
        PrivateInputs { leaf, tree }
    }
}

#[derive(Clone, Debug)]
pub struct SetupParams {
    pub leaves: usize,
    pub private: bool,
}

/// Merkle tree based proof of retrievability.
#[derive(Debug, Default)]
pub struct PoR<Tree: MerkleTreeTrait> {
    _tree: PhantomData<Tree>,
}

impl<'a, Tree: 'a + MerkleTreeTrait> ProofScheme<'a> for PoR<Tree> {
    type PublicParams = PublicParams;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<<Tree::Hasher as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<'a, Tree>;
    type Proof = DataProof<Tree::Proof>;
    type Requirements = NoRequirements;

    fn setup(sp: &SetupParams) -> Result<PublicParams> {
        // atm only binary trees are implemented
        Ok(PublicParams {
            leaves: sp.leaves,
            private: sp.private,
        })
    }

    fn prove<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        let challenge = pub_inputs.challenge % pub_params.leaves;
        let tree = priv_inputs.tree;

        if let Some(ref commitment) = pub_inputs.commitment {
            ensure!(commitment == &tree.root(), Error::InvalidCommitment);
        }
        let proof = tree.gen_proof(challenge)?;
        Ok(Self::Proof {
            proof,
            data: priv_inputs.leaf,
        })
    }

    fn verify(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        proof: &Self::Proof,
    ) -> Result<bool> {
        {
            // This was verify_proof_meta.
            let commitments_match = match pub_inputs.commitment {
                Some(ref commitment) => commitment == &proof.proof.root(),
                None => true,
            };

            let expected_path_length = proof.proof.expected_len(pub_params.leaves);
            let path_length_match = expected_path_length == proof.proof.path().len();

            if !(commitments_match && path_length_match) {
                dbg!(
                    commitments_match,
                    path_length_match,
                    expected_path_length,
                    proof.proof.path().len()
                );
                return Ok(false);
            }
        }

        let data_valid = proof.proof.validate_data(proof.data);
        let path_valid = proof.proof.validate(pub_inputs.challenge);

        Ok(data_valid && path_valid)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use generic_array::typenum;
    use paired::bls12_381::Fr;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    use crate::drgraph::{new_seed, BucketGraph, Graph, BASE_DEGREE};
    use crate::fr32::fr_into_bytes;
    use crate::hasher::{Blake2sHasher, PedersenHasher, PoseidonHasher, Sha256Hasher};
    use crate::merkle::{create_base_merkle_tree, DiskStore, MerkleProofTrait, MerkleTreeWrapper};
    use crate::util::data_at_node;

    fn test_merklepor<Tree: MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 16;
        let pub_params = PublicParams {
            leaves,
            private: false,
        };

        let data: Vec<u8> = (0..leaves)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        let graph = BucketGraph::<Tree::Hasher>::new(leaves, BASE_DEGREE, 0, new_seed()).unwrap();
        let tree = create_base_merkle_tree::<Tree>(None, graph.size(), data.as_slice()).unwrap();

        let pub_inputs = PublicInputs {
            challenge: 3,
            commitment: Some(tree.root()),
        };

        let leaf = <Tree::Hasher as Hasher>::Domain::try_from_bytes(
            data_at_node(data.as_slice(), pub_inputs.challenge).unwrap(),
        )
        .unwrap();

        let priv_inputs = PrivateInputs::new(leaf, &tree);

        let proof =
            PoR::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs).expect("proving failed");

        let is_valid =
            PoR::<Tree>::verify(&pub_params, &pub_inputs, &proof).expect("verification failed");

        assert!(is_valid);
    }

    type TestTree<H, U> =
        MerkleTreeWrapper<H, DiskStore<<H as Hasher>::Domain>, U, typenum::U0, typenum::U0>;

    #[test]
    fn merklepor_pedersen_binary() {
        test_merklepor::<TestTree<PedersenHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_poseidon_binary() {
        test_merklepor::<TestTree<PoseidonHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_sha256_binary() {
        test_merklepor::<TestTree<Sha256Hasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_blake2s_binary() {
        test_merklepor::<TestTree<Blake2sHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_pedersen_quad() {
        test_merklepor::<TestTree<PedersenHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_poseidon_quad() {
        test_merklepor::<TestTree<PoseidonHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_sha256_quad() {
        test_merklepor::<TestTree<Sha256Hasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_blake2s_quad() {
        test_merklepor::<TestTree<Blake2sHasher, typenum::U4>>();
    }

    // Takes a valid proof and breaks it.
    fn make_bogus_proof<Proof: MerkleProofTrait>(
        rng: &mut XorShiftRng,
        mut proof: DataProof<Proof>,
    ) -> DataProof<Proof> {
        let bogus_leaf = <Proof::Hasher as Hasher>::Domain::random(rng);
        proof.proof.break_me(bogus_leaf);
        proof
    }

    fn test_merklepor_validates<Tree: MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64;
        let pub_params = PublicParams {
            leaves,
            private: false,
        };

        let data: Vec<u8> = (0..leaves)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        let graph = BucketGraph::<Tree::Hasher>::new(leaves, BASE_DEGREE, 0, new_seed()).unwrap();
        let tree = create_base_merkle_tree::<Tree>(None, graph.size(), data.as_slice()).unwrap();

        let pub_inputs = PublicInputs {
            challenge: 3,
            commitment: Some(tree.root()),
        };

        let leaf = <Tree::Hasher as Hasher>::Domain::try_from_bytes(
            data_at_node(data.as_slice(), pub_inputs.challenge).unwrap(),
        )
        .unwrap();

        let priv_inputs = PrivateInputs::<Tree>::new(leaf, &tree);

        let good_proof =
            PoR::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs).expect("proving failed");

        let verified = PoR::<Tree>::verify(&pub_params, &pub_inputs, &good_proof)
            .expect("verification failed");
        assert!(verified);

        let bad_proof = make_bogus_proof::<Tree::Proof>(rng, good_proof);

        let verified =
            PoR::<Tree>::verify(&pub_params, &pub_inputs, &bad_proof).expect("verification failed");

        // A bad proof should not be verified!
        assert!(!verified);
    }

    #[test]
    fn merklepor_actually_validates_sha256_binary() {
        test_merklepor_validates::<TestTree<Sha256Hasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_blake2s_binary() {
        test_merklepor_validates::<TestTree<Blake2sHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_pedersen_binary() {
        test_merklepor_validates::<TestTree<PedersenHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_poseidon_binary() {
        test_merklepor_validates::<TestTree<PoseidonHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_sha256_quad() {
        test_merklepor_validates::<TestTree<Sha256Hasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_blake2s_quad() {
        test_merklepor_validates::<TestTree<Blake2sHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_pedersen_quad() {
        test_merklepor_validates::<TestTree<PedersenHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_poseidon_quad() {
        test_merklepor_validates::<TestTree<PoseidonHasher, typenum::U4>>();
    }

    fn test_merklepor_validates_challenge_identity<Tree: MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64;

        let pub_params = PublicParams {
            leaves,
            private: false,
        };

        let data: Vec<u8> = (0..leaves)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        let graph = BucketGraph::<Tree::Hasher>::new(leaves, BASE_DEGREE, 0, new_seed()).unwrap();
        let tree = create_base_merkle_tree::<Tree>(None, graph.size(), data.as_slice()).unwrap();

        let pub_inputs = PublicInputs {
            challenge: 3,
            commitment: Some(tree.root()),
        };

        let leaf = <Tree::Hasher as Hasher>::Domain::try_from_bytes(
            data_at_node(data.as_slice(), pub_inputs.challenge).unwrap(),
        )
        .unwrap();

        let priv_inputs = PrivateInputs::<Tree>::new(leaf, &tree);

        let proof =
            PoR::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs).expect("proving failed");

        let different_pub_inputs = PublicInputs {
            challenge: 999,
            commitment: Some(tree.root()),
        };

        let verified = PoR::<Tree>::verify(&pub_params, &different_pub_inputs, &proof)
            .expect("verification failed");

        // A proof created with a the wrong challenge not be verified!
        assert!(!verified);
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_sha256_binary() {
        test_merklepor_validates_challenge_identity::<TestTree<Sha256Hasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_blake2s_binary() {
        test_merklepor_validates_challenge_identity::<TestTree<Blake2sHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_pedersen_binary() {
        test_merklepor_validates_challenge_identity::<TestTree<PedersenHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_poseidon_binary() {
        test_merklepor_validates_challenge_identity::<TestTree<PoseidonHasher, typenum::U2>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_sha256_quad() {
        test_merklepor_validates_challenge_identity::<TestTree<Sha256Hasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_blake2s_quad() {
        test_merklepor_validates_challenge_identity::<TestTree<Blake2sHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_pedersen_quad() {
        test_merklepor_validates_challenge_identity::<TestTree<PedersenHasher, typenum::U4>>();
    }

    #[test]
    fn merklepor_actually_validates_challenge_identity_poseidon_quad() {
        test_merklepor_validates_challenge_identity::<TestTree<PoseidonHasher, typenum::U4>>();
    }
}

'''
'''--- storage-proofs/core/src/proof.rs ---
use std::time::Instant;

use log::info;
use serde::de::DeserializeOwned;
use serde::ser::Serialize;

use crate::error::Result;

/// The ProofScheme trait provides the methods that any proof scheme needs to implement.
pub trait ProofScheme<'a> {
    type PublicParams: Clone;
    type SetupParams: Clone;
    type PublicInputs: Clone;
    type PrivateInputs;
    type Proof: Clone + Serialize + DeserializeOwned;
    type Requirements: Default;

    /// setup is used to generate public parameters from setup parameters in order to specialize
    /// a ProofScheme to the specific parameters required by a consumer.
    fn setup(_: &Self::SetupParams) -> Result<Self::PublicParams>;

    /// prove generates and returns a proof from public parameters, public inputs, and private inputs.
    fn prove(
        _: &Self::PublicParams,
        _: &Self::PublicInputs,
        _: &Self::PrivateInputs,
    ) -> Result<Self::Proof>;

    fn prove_all_partitions(
        pub_params: &Self::PublicParams,
        pub_in: &Self::PublicInputs,
        priv_in: &Self::PrivateInputs,
        partition_count: usize,
    ) -> Result<Vec<Self::Proof>> {
        info!("groth_proof_count: {}", partition_count);
        info!("generating {} groth proofs.", partition_count);
        let start = Instant::now();

        let result = (0..partition_count)
            .map(|k| {
                info!("generating groth proof {}.", k);
                let start = Instant::now();

                let partition_pub_in = Self::with_partition((*pub_in).clone(), Some(k));
                let proof = Self::prove(pub_params, &partition_pub_in, priv_in);

                let proof_time = start.elapsed();
                info!("groth_proof_time: {:?}", proof_time);

                proof
            })
            .collect::<Result<Vec<Self::Proof>>>();

        let total_proof_time = start.elapsed();
        info!("total_groth_proof_time: {:?}", total_proof_time);

        result
    }

    /// verify returns true if the supplied proof is valid for the given public parameter and public inputs.
    /// Note that verify does not have access to private inputs.
    /// Remember that proof is untrusted, and any data it provides MUST be validated as corresponding
    /// to the supplied public parameters and inputs.
    fn verify(
        _pub_params: &Self::PublicParams,
        _pub_inputs: &Self::PublicInputs,
        _proof: &Self::Proof,
    ) -> Result<bool> {
        unimplemented!();
    }

    fn verify_all_partitions(
        pub_params: &Self::PublicParams,
        pub_in: &Self::PublicInputs,
        proofs: &[Self::Proof],
    ) -> Result<bool> {
        for (k, proof) in proofs.iter().enumerate() {
            let partition_pub_in = Self::with_partition((*pub_in).clone(), Some(k)); //

            if !Self::verify(pub_params, &partition_pub_in, proof)? {
                return Ok(false);
            }
        }

        Ok(true)
    }

    // This method must be specialized by concrete ProofScheme implementations which use partitions.
    fn with_partition(pub_in: Self::PublicInputs, _k: Option<usize>) -> Self::PublicInputs {
        pub_in
    }

    fn satisfies_requirements(
        _pub_params: &Self::PublicParams,
        _requirements: &Self::Requirements,
        _partitions: usize,
    ) -> bool {
        true
    }
}

#[derive(Default)]
pub struct NoRequirements;

'''
'''--- storage-proofs/core/src/sector.rs ---
use std::collections::BTreeSet;
use std::fmt;

use byteorder::ByteOrder;
use ff::PrimeField;
use paired::bls12_381::{Fr, FrRepr};
use serde::{Deserialize, Serialize};

/// An ordered set of `SectorId`s.
pub type OrderedSectorSet = BTreeSet<SectorId>;

/// Identifier for a single sector.
#[derive(
    Default, Debug, Clone, Copy, PartialOrd, Ord, PartialEq, Eq, Hash, Serialize, Deserialize,
)]
pub struct SectorId(u64);

impl From<u64> for SectorId {
    fn from(n: u64) -> Self {
        SectorId(n)
    }
}

impl From<SectorId> for u64 {
    fn from(n: SectorId) -> Self {
        n.0
    }
}

impl From<SectorId> for Fr {
    fn from(n: SectorId) -> Self {
        Fr::from_repr(FrRepr::from(n.0)).unwrap()
    }
}

impl fmt::Display for SectorId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "SectorId({})", self.0)
    }
}

impl SectorId {
    pub fn as_fr_safe(self) -> [u8; 31] {
        let mut buf: [u8; 31] = [0; 31];
        byteorder::LittleEndian::write_u64(&mut buf[0..8], self.0);
        buf
    }
}

'''
'''--- storage-proofs/core/src/settings.rs ---
use std::sync::Mutex;

use config::{Config, ConfigError, Environment, File};
use lazy_static::lazy_static;
use serde::{Deserialize, Serialize};

lazy_static! {
    pub static ref SETTINGS: Mutex<Settings> =
        Mutex::new(Settings::new().expect("invalid configuration"));
}

const SETTINGS_PATH: &str = "./rust-fil-proofs.config.toml";

#[derive(Debug, Serialize, Deserialize)]
#[serde(default)]
pub struct Settings {
    pub maximize_caching: bool,
    pub pedersen_hash_exp_window_size: u32,
    pub use_gpu_column_builder: bool,
    pub max_gpu_column_batch_size: u32,
    pub max_gpu_tree_batch_size: u32,
    pub rows_to_discard: u32,
}

impl Default for Settings {
    fn default() -> Self {
        Settings {
            maximize_caching: false,
            pedersen_hash_exp_window_size: 16,
            use_gpu_column_builder: false,
            max_gpu_column_batch_size: 400_000,
            max_gpu_tree_batch_size: 700_000,
            rows_to_discard: 0,
        }
    }
}

impl Settings {
    fn new() -> Result<Settings, ConfigError> {
        let mut s = Config::new();

        s.merge(File::with_name(SETTINGS_PATH).required(false))?;
        s.merge(Environment::with_prefix("FIL_PROOFS"))?;

        s.try_into()
    }
}

'''
'''--- storage-proofs/core/src/test_helper.rs ---
use memmap::MmapMut;
use memmap::MmapOptions;
use std::fs::OpenOptions;
use std::io::Write;
use std::path::Path;

pub fn setup_replica(data: &[u8], replica_path: &Path) -> MmapMut {
    let mut f = OpenOptions::new()
        .read(true)
        .write(true)
        .create(true)
        .open(replica_path)
        .expect("Failed to create replica");
    f.write_all(data).expect("Failed to write data to replica");

    unsafe {
        MmapOptions::new()
            .map_mut(&f)
            .expect("Failed to back memory map with tempfile")
    }
}

#[macro_export]
macro_rules! table_tests {
    ($property_test_func:ident {
        $( $(#[$attr:meta])* $test_name:ident( $( $param:expr ),* ); )+
    }) => {
        $(
            $(#[$attr])*
                #[test]
            fn $test_name() {
                $property_test_func($( $param ),* )
            }
        )+
    }
}

'''
'''--- storage-proofs/core/src/util.rs ---
use crate::error;
use anyhow::ensure;
use bellperson::gadgets::boolean::{self, AllocatedBit, Boolean};
use bellperson::{ConstraintSystem, SynthesisError};
use paired::Engine;

pub const NODE_SIZE: usize = 32;

/// Returns the start position of the data, 0-indexed.
pub fn data_at_node_offset(v: usize) -> usize {
    v * NODE_SIZE
}

/// Returns the byte slice representing one node (of uniform size, NODE_SIZE) at position v in data.
pub fn data_at_node(data: &[u8], v: usize) -> error::Result<&[u8]> {
    let offset = data_at_node_offset(v);

    ensure!(
        offset + NODE_SIZE <= data.len(),
        error::Error::OutOfBounds(offset + NODE_SIZE, data.len())
    );

    Ok(&data[offset..offset + NODE_SIZE])
}

/// Converts bytes into their bit representation, in little endian format.
pub fn bytes_into_bits(bytes: &[u8]) -> Vec<bool> {
    bytes
        .iter()
        .flat_map(|&byte| (0..8).map(move |i| (byte >> i) & 1u8 == 1u8))
        .collect()
}

/// Converts bytes into their bit representation, in little endian format.
pub fn bytes_into_bits_opt(bytes: &[u8]) -> Vec<Option<bool>> {
    bytes
        .iter()
        .flat_map(|&byte| (0..8).map(move |i| Some((byte >> i) & 1u8 == 1u8)))
        .collect()
}

/// Converts bytes into their bit representation, in big endian format.
pub fn bytes_into_bits_be(bytes: &[u8]) -> Vec<bool> {
    bytes
        .iter()
        .flat_map(|&byte| (0..8).rev().map(move |i| (byte >> i) & 1u8 == 1u8))
        .collect()
}

/// Converts the bytes into a boolean vector, in little endian format.
pub fn bytes_into_boolean_vec<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    value: Option<&[u8]>,
    size: usize,
) -> Result<Vec<boolean::Boolean>, SynthesisError> {
    let values = match value {
        Some(value) => bytes_into_bits(value).into_iter().map(Some).collect(),
        None => vec![None; size],
    };

    let bits = values
        .into_iter()
        .enumerate()
        .map(|(i, b)| {
            Ok(Boolean::from(AllocatedBit::alloc(
                cs.namespace(|| format!("bit {}", i)),
                b,
            )?))
        })
        .collect::<Result<Vec<_>, SynthesisError>>()?;

    Ok(bits)
}

/// Converts the bytes into a boolean vector, in big endian format.
pub fn bytes_into_boolean_vec_be<E: Engine, CS: ConstraintSystem<E>>(
    mut cs: CS,
    value: Option<&[u8]>,
    size: usize,
) -> Result<Vec<boolean::Boolean>, SynthesisError> {
    let values = match value {
        Some(value) => bytes_into_bits_be(value).into_iter().map(Some).collect(),
        None => vec![None; size],
    };

    let bits = values
        .into_iter()
        .enumerate()
        .map(|(i, b)| {
            Ok(Boolean::from(AllocatedBit::alloc(
                cs.namespace(|| format!("bit {}", i)),
                b,
            )?))
        })
        .collect::<Result<Vec<_>, SynthesisError>>()?;

    Ok(bits)
}

#[allow(dead_code)]
#[inline]
fn bool_to_u8(bit: bool, offset: usize) -> u8 {
    if bit {
        1u8 << offset
    } else {
        0u8
    }
}

/// Converts a slice of bools into their byte representation, in little endian.
#[allow(dead_code)]
pub fn bits_to_bytes(bits: &[bool]) -> Vec<u8> {
    bits.chunks(8)
        .map(|bits| {
            bool_to_u8(bits[7], 7)
                | bool_to_u8(bits[6], 6)
                | bool_to_u8(bits[5], 5)
                | bool_to_u8(bits[4], 4)
                | bool_to_u8(bits[3], 3)
                | bool_to_u8(bits[2], 2)
                | bool_to_u8(bits[1], 1)
                | bool_to_u8(bits[0], 0)
        })
        .collect()
}

/// Reverse the order of bits within each byte (bit numbering), but without altering the order of bytes
/// within the array (endianness) — when bit array is viewed as a flattened sequence of octets.
/// Before intra-byte bit reversal begins, zero-bit padding is added so every byte is full.
pub fn reverse_bit_numbering(bits: Vec<boolean::Boolean>) -> Vec<boolean::Boolean> {
    let mut padded_bits = bits;
    // Pad partial bytes
    while padded_bits.len() % 8 != 0 {
        padded_bits.push(boolean::Boolean::Constant(false));
    }

    padded_bits
        .chunks(8)
        .map(|chunk| chunk.iter().rev())
        .flatten()
        .cloned()
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    use crate::fr32::fr_into_bytes;
    use crate::gadgets::TestConstraintSystem;
    use bellperson::gadgets::num;
    use ff::Field;
    use paired::bls12_381::*;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    #[test]
    fn test_bytes_into_boolean_vec() {
        let mut cs = TestConstraintSystem::<Bls12>::new();
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 0..100 {
            let data: Vec<u8> = (0..i + 10).map(|_| rng.gen()).collect();
            let bools = {
                let mut cs = cs.namespace(|| format!("round: {}", i));
                bytes_into_boolean_vec(&mut cs, Some(data.as_slice()), 8).unwrap()
            };

            let bytes_actual: Vec<u8> = bits_to_bytes(
                bools
                    .iter()
                    .map(|b| b.get_value().unwrap())
                    .collect::<Vec<bool>>()
                    .as_slice(),
            );

            assert_eq!(data, bytes_actual);
        }
    }

    #[test]
    fn test_bool_to_u8() {
        assert_eq!(bool_to_u8(false, 2), 0b0000_0000);
        assert_eq!(bool_to_u8(true, 0), 0b0000_0001);
        assert_eq!(bool_to_u8(true, 1), 0b0000_0010);
        assert_eq!(bool_to_u8(true, 7), 0b1000_0000);
    }

    #[test]
    fn test_bits_into_bytes() {
        assert_eq!(
            bits_to_bytes(&[true, false, false, false, false, false, false, false]),
            vec![1]
        );
        assert_eq!(
            bits_to_bytes(&[true, true, true, true, true, true, true, true]),
            vec![255]
        );
    }

    #[test]
    fn test_bytes_into_bits() {
        assert_eq!(
            bytes_into_bits(&[1u8]),
            vec![true, false, false, false, false, false, false, false]
        );

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for i in 10..100 {
            let bytes: Vec<u8> = (0..i).map(|_| rng.gen()).collect();

            let bits = bytes_into_bits(bytes.as_slice());
            assert_eq!(bits_to_bytes(bits.as_slice()), bytes);
        }
    }

    #[test]
    fn test_reverse_bit_numbering() {
        for _ in 0..100 {
            let mut cs = TestConstraintSystem::<Bls12>::new();
            let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

            let val_fr = Fr::random(rng);
            let val_vec = fr_into_bytes(&val_fr);

            let val_num =
                num::AllocatedNum::alloc(cs.namespace(|| "val_num"), || Ok(val_fr.into())).unwrap();
            let val_num_bits = val_num.to_bits_le(cs.namespace(|| "val_bits")).unwrap();

            let bits =
                bytes_into_boolean_vec_be(cs.namespace(|| "val_bits_2"), Some(&val_vec), 256)
                    .unwrap();

            let val_num_reversed_bit_numbering = reverse_bit_numbering(val_num_bits);

            let a_values: Vec<bool> = val_num_reversed_bit_numbering
                .iter()
                .map(|v| v.get_value().unwrap())
                .collect();

            let b_values: Vec<bool> = bits.iter().map(|v| v.get_value().unwrap()).collect();
            assert_eq!(&a_values[..], &b_values[..]);
        }
    }
}

'''
'''--- storage-proofs/porep/Cargo.toml ---
[package]
name = "storage-proofs-porep"
version = "2.0.0"
authors = ["dignifiedquire <me@dignifiedquire.com>"]
description = "Proofs of replication"
license = "MIT OR Apache-2.0"
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[dependencies]
storage-proofs-core = { path = "../core", version = "2.0.0" }
sha2raw = { path = "../../sha2raw", version = "1.0.0" }
rand = "0.7"
merkletree = "0.20.0"
memmap = "0.7"
num-bigint = "0.2"
num-traits = "0.2"
sha2 = { version = "0.8.3", package = "sha2ni" }
rayon = "1.0.0"
serde = { version = "1.0", features = ["derive"]}
ff = { version = "0.2.1", package = "fff" }
bellperson = "0.8.0"
paired = { version = "0.19.0", features = ["serde"] }
fil-sapling-crypto = "0.6.0"
log = "0.4.7"
pretty_assertions = "0.6.1"
generic-array = "0.13.2"
anyhow = "1.0.23"
once_cell = "1.3.1"
neptune = { version = "0.7.1", features = ["gpu"] }
num_cpus = "1.10.1"

[dev-dependencies]
tempdir = "0.3.7"
tempfile = "3"
rand_xorshift = "0.2.0"
criterion = "0.3.2"

[features]
default = []

[[bench]]
name = "encode"
harness = false

[[bench]]
name = "parents"
harness = false

'''
'''--- storage-proofs/porep/README.md ---
# Storage Proofs PoRep

## License

MIT or Apache 2.0

'''
'''--- storage-proofs/porep/benches/encode.rs ---
use criterion::{black_box, criterion_group, criterion_main, Criterion, Throughput};
use ff::Field;
use paired::bls12_381::Fr;
use rand::thread_rng;
use storage_proofs_core::drgraph::new_seed;
use storage_proofs_core::fr32::fr_into_bytes;
use storage_proofs_core::hasher::sha256::Sha256Hasher;
use storage_proofs_core::hasher::{Domain, Hasher};
use storage_proofs_porep::stacked::{create_label, create_label_exp, StackedBucketGraph};

struct Pregenerated<H: 'static + Hasher> {
    data: Vec<u8>,
    replica_id: H::Domain,
    graph: StackedBucketGraph<H>,
}

fn pregenerate_data<H: Hasher>(degree: usize) -> Pregenerated<H> {
    assert_eq!(degree, 6 + 8);
    let mut rng = thread_rng();
    let size = degree * 4 * 1024 * 1024;
    let data: Vec<u8> = (0..size)
        .flat_map(|_| fr_into_bytes(&Fr::random(&mut rng)))
        .collect();
    let replica_id: H::Domain = H::Domain::random(&mut rng);

    let graph = StackedBucketGraph::<H>::new_stacked(size, 6, 8, new_seed()).unwrap();

    Pregenerated {
        data,
        replica_id,
        graph,
    }
}

fn kdf_benchmark(c: &mut Criterion) {
    let degree = 14;
    let Pregenerated {
        data,
        replica_id,
        graph,
    } = pregenerate_data::<Sha256Hasher>(degree);

    let mut group = c.benchmark_group("kdf");
    group.sample_size(10);
    group.throughput(Throughput::Bytes(
        /* replica id + 37 parents + node id */ 39 * 32,
    ));

    group.bench_function("exp", |b| {
        let mut raw_data = data.clone();
        raw_data.extend_from_slice(&data);
        let (data, exp_data) = raw_data.split_at_mut(data.len());

        let graph = &graph;
        let replica_id = replica_id.clone();

        b.iter(|| black_box(create_label_exp(graph, &replica_id, &*exp_data, data, 1, 2)))
    });

    group.bench_function("non-exp", |b| {
        let mut data = data.clone();
        let graph = &graph;
        let replica_id = replica_id.clone();

        b.iter(|| black_box(create_label(graph, &replica_id, &mut data, 1, 2)))
    });

    group.finish();
}

criterion_group!(benches, kdf_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/porep/benches/parents.rs ---
use criterion::{black_box, criterion_group, criterion_main, Criterion, ParameterizedBenchmark};
use storage_proofs_core::{
    drgraph::{Graph, BASE_DEGREE},
    hasher::blake2s::Blake2sHasher,
    hasher::pedersen::PedersenHasher,
    hasher::sha256::Sha256Hasher,
    hasher::Hasher,
};
use storage_proofs_porep::stacked::{StackedBucketGraph, EXP_DEGREE};

#[cfg(feature = "cpu-profile")]
#[inline(always)]
fn start_profile(stage: &str) {
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .start(format!("./{}.profile", stage))
        .unwrap();
}

#[cfg(not(feature = "cpu-profile"))]
#[inline(always)]
fn start_profile(_stage: &str) {}

#[cfg(feature = "cpu-profile")]
#[inline(always)]
fn stop_profile() {
    gperftools::profiler::PROFILER
        .lock()
        .unwrap()
        .stop()
        .unwrap();
}

#[cfg(not(feature = "cpu-profile"))]
#[inline(always)]
fn stop_profile() {}

fn pregenerate_graph<H: Hasher>(size: usize) -> StackedBucketGraph<H> {
    let seed = [1u8; 28];
    StackedBucketGraph::<H>::new_stacked(size, BASE_DEGREE, EXP_DEGREE, seed).unwrap()
}

fn parents_loop<H: Hasher, G: Graph<H>>(graph: &G, parents: &mut [u32]) {
    (0..graph.size())
        .map(|node| graph.parents(node, parents).unwrap())
        .collect()
}

fn parents_loop_benchmark(cc: &mut Criterion) {
    let sizes = vec![10, 50, 1000];

    cc.bench(
        "parents in a loop",
        ParameterizedBenchmark::new(
            "Blake2s",
            |b, size| {
                let graph = pregenerate_graph::<Blake2sHasher>(*size);
                let mut parents = vec![0; graph.degree()];
                start_profile(&format!("parents-blake2s-{}", *size));
                b.iter(|| black_box(parents_loop::<Blake2sHasher, _>(&graph, &mut parents)));
                stop_profile();
            },
            sizes,
        )
        .with_function("Pedersen", |b, degree| {
            let graph = pregenerate_graph::<PedersenHasher>(*degree);
            let mut parents = vec![0; graph.degree()];
            b.iter(|| black_box(parents_loop::<PedersenHasher, _>(&graph, &mut parents)))
        })
        .with_function("Sha256", |b, degree| {
            let graph = pregenerate_graph::<Sha256Hasher>(*degree);
            let mut parents = vec![0; graph.degree()];
            b.iter(|| black_box(parents_loop::<Sha256Hasher, _>(&graph, &mut parents)))
        }),
    );
}

criterion_group!(benches, parents_loop_benchmark);
criterion_main!(benches);

'''
'''--- storage-proofs/porep/src/drg/circuit.rs ---
use std::marker::PhantomData;

use bellperson::gadgets::{
    boolean::Boolean,
    sha256::sha256 as sha256_circuit,
    {multipack, num},
};
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use ff::PrimeField;
use fil_sapling_crypto::jubjub::JubjubEngine;
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::CircuitComponent, error::Result, gadgets::constraint, gadgets::encode,
    gadgets::por::PoRCircuit, gadgets::uint64, gadgets::variables::Root, hasher::Hasher,
    merkle::BinaryMerkleTree, util::reverse_bit_numbering,
};

/// DRG based Proof of Replication.
///
/// # Fields
///
/// * `params` - parameters for the curve
///
/// ----> Private `replica_node` - The replica node being proven.
///
/// * `replica_node` - The replica node being proven.
/// * `replica_node_path` - The path of the replica node being proven.
/// * `replica_root` - The merkle root of the replica.
///
/// * `replica_parents` - A list of all parents in the replica, with their value.
/// * `replica_parents_paths` - A list of all parents paths in the replica.
///
/// ----> Private `data_node` - The data node being proven.
///
/// * `data_node_path` - The path of the data node being proven.
/// * `data_root` - The merkle root of the data.
/// * `replica_id` - The id of the replica.
///

pub struct DrgPoRepCircuit<'a, H: Hasher> {
    pub replica_nodes: Vec<Option<Fr>>,
    #[allow(clippy::type_complexity)]
    pub replica_nodes_paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
    pub replica_root: Root<Bls12>,
    pub replica_parents: Vec<Vec<Option<Fr>>>,
    #[allow(clippy::type_complexity)]
    pub replica_parents_paths: Vec<Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>>,
    pub data_nodes: Vec<Option<Fr>>,
    #[allow(clippy::type_complexity)]
    pub data_nodes_paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
    pub data_root: Root<Bls12>,
    pub replica_id: Option<Fr>,
    pub private: bool,
    pub _h: PhantomData<&'a H>,
}

impl<'a, H: 'static + Hasher> DrgPoRepCircuit<'a, H> {
    #[allow(clippy::type_complexity, clippy::too_many_arguments)]
    pub fn synthesize<CS>(
        mut cs: CS,
        replica_nodes: Vec<Option<Fr>>,
        replica_nodes_paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
        replica_root: Root<Bls12>,
        replica_parents: Vec<Vec<Option<Fr>>>,
        replica_parents_paths: Vec<Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>>,
        data_nodes: Vec<Option<Fr>>,
        data_nodes_paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
        data_root: Root<Bls12>,
        replica_id: Option<Fr>,
        private: bool,
    ) -> Result<(), SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        DrgPoRepCircuit::<H> {
            replica_nodes,
            replica_nodes_paths,
            replica_root,
            replica_parents,
            replica_parents_paths,
            data_nodes,
            data_nodes_paths,
            data_root,
            replica_id,
            private,
            _h: Default::default(),
        }
        .synthesize(&mut cs)
    }
}

#[derive(Default, Clone)]
pub struct ComponentPrivateInputs {
    pub comm_r: Option<Root<Bls12>>,
    pub comm_d: Option<Root<Bls12>>,
}

impl<'a, H: Hasher> CircuitComponent for DrgPoRepCircuit<'a, H> {
    type ComponentPrivateInputs = ComponentPrivateInputs;
}

///
/// # Public Inputs
///
/// * [0] replica_id/0
/// * [1] replica_id/1
/// * [2] replica auth_path_bits
/// * [3] replica commitment (root hash)
/// * for i in 0..replica_parents.len()
///   * [ ] replica parent auth_path_bits
///   * [ ] replica parent commitment (root hash) // Same for all.
/// * [r + 1] data auth_path_bits
/// * [r + 2] data commitment (root hash)
///
///  Total = 6 + (2 * replica_parents.len())
/// # Private Inputs
///
/// * [ ] replica value/0
/// * for i in 0..replica_parents.len()
///  * [ ] replica parent value/0
/// * [ ] data value/
///
/// Total = 2 + replica_parents.len()
///
impl<'a, H: 'static + Hasher> Circuit<Bls12> for DrgPoRepCircuit<'a, H> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let replica_id = self.replica_id;
        let replica_root = self.replica_root;
        let data_root = self.data_root;

        let nodes = self.data_nodes.len();

        assert_eq!(self.replica_nodes.len(), nodes);
        assert_eq!(self.replica_nodes_paths.len(), nodes);
        assert_eq!(self.replica_parents.len(), nodes);
        assert_eq!(self.replica_parents_paths.len(), nodes);
        assert_eq!(self.data_nodes_paths.len(), nodes);

        let replica_node_num = num::AllocatedNum::alloc(cs.namespace(|| "replica_id_num"), || {
            replica_id.ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        replica_node_num.inputize(cs.namespace(|| "replica_id"))?;

        // get the replica_id in bits
        let replica_id_bits =
            reverse_bit_numbering(replica_node_num.to_bits_le(cs.namespace(|| "replica_id_bits"))?);

        let replica_root_var = Root::Var(replica_root.allocated(cs.namespace(|| "replica_root"))?);
        let data_root_var = Root::Var(data_root.allocated(cs.namespace(|| "data_root"))?);

        for i in 0..self.data_nodes.len() {
            let mut cs = cs.namespace(|| format!("challenge_{}", i));
            // ensure that all inputs are well formed
            let replica_node_path = &self.replica_nodes_paths[i];
            let replica_parents_paths = &self.replica_parents_paths[i];
            let data_node_path = &self.data_nodes_paths[i];

            let replica_node = &self.replica_nodes[i];
            let replica_parents = &self.replica_parents[i];
            let data_node = &self.data_nodes[i];

            assert_eq!(replica_parents.len(), replica_parents_paths.len());
            assert_eq!(data_node_path.len(), replica_node_path.len());
            assert_eq!(replica_node.is_some(), data_node.is_some());

            // Inclusion checks
            {
                let mut cs = cs.namespace(|| "inclusion_checks");
                PoRCircuit::<BinaryMerkleTree<H>>::synthesize(
                    cs.namespace(|| "replica_inclusion"),
                    Root::Val(*replica_node),
                    replica_node_path.clone().into(),
                    replica_root_var.clone(),
                    self.private,
                )?;

                // validate each replica_parents merkle proof
                for j in 0..replica_parents.len() {
                    PoRCircuit::<BinaryMerkleTree<H>>::synthesize(
                        cs.namespace(|| format!("parents_inclusion_{}", j)),
                        Root::Val(replica_parents[j]),
                        replica_parents_paths[j].clone().into(),
                        replica_root_var.clone(),
                        self.private,
                    )?;
                }

                // validate data node commitment
                PoRCircuit::<BinaryMerkleTree<H>>::synthesize(
                    cs.namespace(|| "data_inclusion"),
                    Root::Val(*data_node),
                    data_node_path.clone().into(),
                    data_root_var.clone(),
                    self.private,
                )?;
            }

            // Encoding checks
            {
                let mut cs = cs.namespace(|| "encoding_checks");
                // get the parents into bits
                let parents_bits: Vec<Vec<Boolean>> = replica_parents
                    .iter()
                    .enumerate()
                    .map(|(i, val)| {
                        let num = num::AllocatedNum::alloc(
                            cs.namespace(|| format!("parents_{}_num", i)),
                            || {
                                val.map(Into::into)
                                    .ok_or_else(|| SynthesisError::AssignmentMissing)
                            },
                        )?;
                        Ok(reverse_bit_numbering(num.to_bits_le(
                            cs.namespace(|| format!("parents_{}_bits", i)),
                        )?))
                    })
                    .collect::<Result<Vec<Vec<Boolean>>, SynthesisError>>()?;

                // generate the encryption key
                let key = kdf(
                    cs.namespace(|| "kdf"),
                    &replica_id_bits,
                    parents_bits,
                    None,
                    None,
                )?;

                let replica_node_num =
                    num::AllocatedNum::alloc(cs.namespace(|| "replica_node"), || {
                        (*replica_node).ok_or_else(|| SynthesisError::AssignmentMissing)
                    })?;

                let decoded = encode::decode(cs.namespace(|| "decode"), &key, &replica_node_num)?;

                // TODO this should not be here, instead, this should be the leaf Fr in the data_auth_path
                // TODO also note that we need to change/makesurethat the leaves are the data, instead of hashes of the data
                let expected = num::AllocatedNum::alloc(cs.namespace(|| "data node"), || {
                    data_node.ok_or_else(|| SynthesisError::AssignmentMissing)
                })?;

                // ensure the encrypted data and data_node match
                constraint::equal(&mut cs, || "equality", &expected, &decoded);
            }
        }
        // profit!
        Ok(())
    }
}

/// Key derivation function.
fn kdf<E, CS>(
    mut cs: CS,
    id: &[Boolean],
    parents: Vec<Vec<Boolean>>,
    window_index: Option<uint64::UInt64>,
    node: Option<uint64::UInt64>,
) -> Result<num::AllocatedNum<E>, SynthesisError>
where
    E: JubjubEngine,
    CS: ConstraintSystem<E>,
{
    // ciphertexts will become a buffer of the layout
    // id | node | encodedParentNode1 | encodedParentNode1 | ...

    let mut ciphertexts = id.to_vec();

    if let Some(window_index) = window_index {
        ciphertexts.extend_from_slice(&window_index.to_bits_be());
    }

    if let Some(node) = node {
        ciphertexts.extend_from_slice(&node.to_bits_be());
    }

    for parent in parents.into_iter() {
        ciphertexts.extend_from_slice(&parent);
    }

    let alloc_bits = sha256_circuit(cs.namespace(|| "hash"), &ciphertexts[..])?;
    let fr = if alloc_bits[0].get_value().is_some() {
        let be_bits = alloc_bits
            .iter()
            .map(|v| v.get_value().ok_or(SynthesisError::AssignmentMissing))
            .collect::<Result<Vec<bool>, SynthesisError>>()?;

        let le_bits = be_bits
            .chunks(8)
            .flat_map(|chunk| chunk.iter().rev())
            .copied()
            .take(E::Fr::CAPACITY as usize)
            .collect::<Vec<bool>>();

        Ok(multipack::compute_multipacking::<E>(&le_bits)[0])
    } else {
        Err(SynthesisError::AssignmentMissing)
    };

    num::AllocatedNum::<E>::alloc(cs.namespace(|| "result_num"), || fr)
}

#[cfg(test)]
mod tests {

    use super::*;

    use ff::Field;
    use generic_array::typenum;
    use merkletree::store::StoreConfig;
    use pretty_assertions::assert_eq;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        cache_key::CacheKey,
        compound_proof,
        drgraph::{graph_height, new_seed, BucketGraph, BASE_DEGREE},
        fr32::{bytes_into_fr, fr_into_bytes},
        gadgets::TestConstraintSystem,
        hasher::PedersenHasher,
        merkle::MerkleProofTrait,
        proof::ProofScheme,
        test_helper::setup_replica,
        util::data_at_node,
    };

    use super::super::compound::DrgPoRepCompound;
    use crate::drg;
    use crate::stacked::BINARY_ARITY;
    use crate::PoRep;

    #[test]
    fn drgporep_input_circuit_with_bls12_381() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let nodes = 16;
        let degree = BASE_DEGREE;
        let challenge = 2;

        let replica_id: Fr = Fr::random(rng);

        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let data_node: Option<Fr> = Some(
            bytes_into_fr(
                data_at_node(&mmapped_data, challenge).expect("failed to read original data"),
            )
            .unwrap(),
        );

        let sp = drg::SetupParams {
            drg: drg::DrgParams {
                nodes,
                degree,
                expansion_degree: 0,
                seed: new_seed(),
            },
            private: false,
            challenges_count: 1,
        };

        let pp = drg::DrgPoRep::<PedersenHasher, BucketGraph<_>>::setup(&sp)
            .expect("failed to create drgporep setup");
        let (tau, aux) = drg::DrgPoRep::<PedersenHasher, _>::replicate(
            &pp,
            &replica_id.into(),
            (mmapped_data.as_mut()).into(),
            None,
            config,
            replica_path.clone(),
        )
        .expect("failed to replicate");

        let pub_inputs = drg::PublicInputs {
            replica_id: Some(replica_id.into()),
            challenges: vec![challenge],
            tau: Some(tau.into()),
        };

        let priv_inputs = drg::PrivateInputs::<PedersenHasher> {
            tree_d: &aux.tree_d,
            tree_r: &aux.tree_r,
            tree_r_config_rows_to_discard: StoreConfig::default_rows_to_discard(
                nodes,
                BINARY_ARITY,
            ),
        };

        let proof_nc = drg::DrgPoRep::<PedersenHasher, _>::prove(&pp, &pub_inputs, &priv_inputs)
            .expect("failed to prove");

        assert!(
            drg::DrgPoRep::<PedersenHasher, _>::verify(&pp, &pub_inputs, &proof_nc)
                .expect("failed to verify"),
            "failed to verify (non circuit)"
        );

        let replica_node: Option<Fr> = Some(proof_nc.replica_nodes[0].data.into());

        let replica_node_path = proof_nc.replica_nodes[0].proof.as_options();
        let replica_root = Root::Val(Some(proof_nc.replica_root.into()));
        let replica_parents = proof_nc
            .replica_parents
            .iter()
            .map(|v| {
                v.iter()
                    .map(|(_, parent)| Some(parent.data.into()))
                    .collect()
            })
            .collect();
        let replica_parents_paths: Vec<_> = proof_nc
            .replica_parents
            .iter()
            .map(|v| {
                v.iter()
                    .map(|(_, parent)| parent.proof.as_options())
                    .collect()
            })
            .collect();

        let data_node_path = proof_nc.nodes[0].proof.as_options();
        let data_root = Root::Val(Some(proof_nc.data_root.into()));
        let replica_id = Some(replica_id);

        assert!(
            proof_nc.nodes[0].proof.validate(challenge),
            "failed to verify data commitment"
        );
        assert!(
            proof_nc.nodes[0]
                .proof
                .validate_data(data_node.unwrap().into()),
            "failed to verify data commitment with data"
        );

        let mut cs = TestConstraintSystem::<Bls12>::new();
        DrgPoRepCircuit::<PedersenHasher>::synthesize(
            cs.namespace(|| "drgporep"),
            vec![replica_node],
            vec![replica_node_path],
            replica_root,
            replica_parents,
            replica_parents_paths,
            vec![data_node],
            vec![data_node_path],
            data_root,
            replica_id,
            false,
        )
        .expect("failed to synthesize circuit");

        if !cs.is_satisfied() {
            println!(
                "failed to satisfy: {:?}",
                cs.which_is_unsatisfied().unwrap()
            );
        }

        assert!(cs.is_satisfied(), "constraints not satisfied");
        assert_eq!(cs.num_inputs(), 18, "wrong number of inputs");
        assert_eq!(cs.num_constraints(), 149_580, "wrong number of constraints");

        assert_eq!(cs.get_input(0, "ONE"), Fr::one());

        assert_eq!(
            cs.get_input(1, "drgporep/replica_id/input variable"),
            replica_id.unwrap()
        );

        let generated_inputs =
                <DrgPoRepCompound<_, _> as compound_proof::CompoundProof<_, _>>::generate_public_inputs(
                    &pub_inputs,
                    &pp,
                    None,
                )
                .unwrap();
        let expected_inputs = cs.get_inputs();

        for ((input, label), generated_input) in
            expected_inputs.iter().skip(1).zip(generated_inputs.iter())
        {
            assert_eq!(input, generated_input, "{}", label);
        }

        assert_eq!(
            generated_inputs.len(),
            expected_inputs.len() - 1,
            "inputs are not the same length"
        );

        cache_dir.close().expect("Failed to remove cache dir");
    }

    #[test]
    fn drgporep_input_circuit_num_constraints() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        // 1 GB
        let n = (1 << 30) / 32;
        let m = BASE_DEGREE;
        let tree_depth = graph_height::<typenum::U2>(n);

        let mut cs = TestConstraintSystem::<Bls12>::new();
        DrgPoRepCircuit::<PedersenHasher>::synthesize(
            cs.namespace(|| "drgporep"),
            vec![Some(Fr::random(rng)); 1],
            vec![vec![(vec![Some(Fr::random(rng))], Some(0)); tree_depth]; 1],
            Root::Val(Some(Fr::random(rng))),
            vec![vec![Some(Fr::random(rng)); m]; 1],
            vec![vec![vec![(vec![Some(Fr::random(rng))], Some(0)); tree_depth]; m]; 1],
            vec![Some(Fr::random(rng)); 1],
            vec![vec![(vec![Some(Fr::random(rng))], Some(0)); tree_depth]; 1],
            Root::Val(Some(Fr::random(rng))),
            Some(Fr::random(rng)),
            false,
        )
        .expect("failed to synthesize circuit");

        assert_eq!(cs.num_inputs(), 18, "wrong number of inputs");
        assert_eq!(cs.num_constraints(), 391_404, "wrong number of constraints");
    }
}

'''
'''--- storage-proofs/porep/src/drg/compound.rs ---
use std::marker::PhantomData;

use anyhow::{ensure, Context};
use bellperson::Circuit;
use generic_array::typenum;
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::{CircuitComponent, CompoundProof},
    drgraph::Graph,
    error::Result,
    gadgets::por::PoRCompound,
    gadgets::variables::Root,
    hasher::Hasher,
    merkle::{BinaryMerkleTree, MerkleProofTrait},
    parameter_cache::{CacheableParameters, ParameterSetMetadata},
    por,
    proof::ProofScheme,
};

use super::circuit::DrgPoRepCircuit;
use super::DrgPoRep;

/// DRG based Proof of Replication.
///
/// # Fields
///
/// * `params` - parameters for the curve
///
/// ----> Private `replica_node` - The replica node being proven.
///
/// * `replica_node` - The replica node being proven.
/// * `replica_node_path` - The path of the replica node being proven.
/// * `replica_root` - The merkle root of the replica.
///
/// * `replica_parents` - A list of all parents in the replica, with their value.
/// * `replica_parents_paths` - A list of all parents paths in the replica.
///
/// ----> Private `data_node` - The data node being proven.
///
/// * `data_node_path` - The path of the data node being proven.
/// * `data_root` - The merkle root of the data.
/// * `replica_id` - The id of the replica.
///

pub struct DrgPoRepCompound<H, G>
where
    H: Hasher,
    G::Key: AsRef<H::Domain>,
    G: Graph<H>,
{
    // Sad phantom is sad
    _h: PhantomData<H>,
    _g: PhantomData<G>,
}

impl<C: Circuit<Bls12>, H: Hasher, G: Graph<H>, P: ParameterSetMetadata> CacheableParameters<C, P>
    for DrgPoRepCompound<H, G>
where
    G::Key: AsRef<H::Domain>,
{
    fn cache_prefix() -> String {
        format!("drg-proof-of-replication-{}", H::name())
    }
}

impl<'a, H, G> CompoundProof<'a, DrgPoRep<'a, H, G>, DrgPoRepCircuit<'a, H>>
    for DrgPoRepCompound<H, G>
where
    H: 'static + Hasher,
    G::Key: AsRef<<H as Hasher>::Domain>,
    G: 'a + Graph<H> + ParameterSetMetadata + Sync + Send,
{
    fn generate_public_inputs(
        pub_in: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::PublicInputs,
        pub_params: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::PublicParams,
        // We can ignore k because challenges are generated by caller and included
        // in PublicInputs.
        _k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let replica_id = pub_in.replica_id.context("missing replica id")?;
        let challenges = &pub_in.challenges;

        ensure!(
            pub_in.tau.is_none() == pub_params.private,
            "Public input parameter tau must be unset"
        );

        let (comm_r, comm_d) = match pub_in.tau {
            None => (None, None),
            Some(tau) => (Some(tau.comm_r), Some(tau.comm_d)),
        };

        let leaves = pub_params.graph.size();

        let por_pub_params = por::PublicParams {
            leaves,
            private: pub_params.private,
        };

        let mut input: Vec<Fr> = Vec::new();
        input.push(replica_id.into());

        let mut parents = vec![0; pub_params.graph.degree()];
        for challenge in challenges {
            let mut por_nodes = vec![*challenge as u32];
            pub_params.graph.parents(*challenge, &mut parents)?;
            por_nodes.extend_from_slice(&parents);

            for node in por_nodes {
                let por_pub_inputs = por::PublicInputs {
                    commitment: comm_r,
                    challenge: node as usize,
                };
                let por_inputs = PoRCompound::<BinaryMerkleTree<H>>::generate_public_inputs(
                    &por_pub_inputs,
                    &por_pub_params,
                    None,
                )?;

                input.extend(por_inputs);
            }

            let por_pub_inputs = por::PublicInputs {
                commitment: comm_d,
                challenge: *challenge,
            };

            let por_inputs = PoRCompound::<BinaryMerkleTree<H>>::generate_public_inputs(
                &por_pub_inputs,
                &por_pub_params,
                None,
            )?;
            input.extend(por_inputs);
        }
        Ok(input)
    }

    fn circuit(
        public_inputs: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::PublicInputs,
        component_private_inputs: <DrgPoRepCircuit<H> as CircuitComponent>::ComponentPrivateInputs,
        proof: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::Proof,
        public_params: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<DrgPoRepCircuit<'a, H>> {
        let challenges = public_params.challenges_count;
        let len = proof.nodes.len();

        ensure!(len <= challenges, "too many challenges");
        ensure!(
            proof.replica_parents.len() == len,
            "Number of replica parents must match"
        );
        ensure!(
            proof.replica_nodes.len() == len,
            "Number of replica nodes must match"
        );

        let replica_nodes: Vec<_> = proof
            .replica_nodes
            .iter()
            .map(|node| Some(node.data.into()))
            .collect();

        let replica_nodes_paths: Vec<_> = proof
            .replica_nodes
            .iter()
            .map(|node| node.proof.as_options())
            .collect();

        let is_private = public_params.private;

        let (data_root, replica_root) = if is_private {
            (
                component_private_inputs.comm_d.context("is_private")?,
                component_private_inputs.comm_r.context("is_private")?,
            )
        } else {
            (
                Root::Val(Some(proof.data_root.into())),
                Root::Val(Some(proof.replica_root.into())),
            )
        };

        let replica_id = public_inputs.replica_id;

        let replica_parents: Vec<_> = proof
            .replica_parents
            .iter()
            .map(|parents| {
                parents
                    .iter()
                    .map(|(_, parent)| Some(parent.data.into()))
                    .collect()
            })
            .collect();

        let replica_parents_paths: Vec<Vec<_>> = proof
            .replica_parents
            .iter()
            .map(|parents| {
                let p: Vec<_> = parents
                    .iter()
                    .map(|(_, parent)| parent.proof.as_options())
                    .collect();
                p
            })
            .collect();

        let data_nodes: Vec<_> = proof
            .nodes
            .iter()
            .map(|node| Some(node.data.into()))
            .collect();

        let data_nodes_paths: Vec<_> = proof
            .nodes
            .iter()
            .map(|node| node.proof.as_options())
            .collect();

        ensure!(
            public_inputs.tau.is_none() == public_params.private,
            "inconsistent private state"
        );

        Ok(DrgPoRepCircuit {
            replica_nodes,
            replica_nodes_paths,
            replica_root,
            replica_parents,
            replica_parents_paths,
            data_nodes,
            data_nodes_paths,
            data_root,
            replica_id: replica_id.map(Into::into),
            private: public_params.private,
            _h: Default::default(),
        })
    }

    fn blank_circuit(
        public_params: &<DrgPoRep<'a, H, G> as ProofScheme<'a>>::PublicParams,
    ) -> DrgPoRepCircuit<'a, H> {
        let depth = public_params.graph.merkle_tree_depth::<typenum::U2>() as usize;
        let degree = public_params.graph.degree();
        let arity = 2;

        let challenges_count = public_params.challenges_count;

        let replica_nodes = vec![None; challenges_count];
        let replica_nodes_paths =
            vec![vec![(vec![None; arity - 1], None); depth - 1]; challenges_count];

        let replica_root = Root::Val(None);
        let replica_parents = vec![vec![None; degree]; challenges_count];
        let replica_parents_paths =
            vec![vec![vec![(vec![None; arity - 1], None); depth - 1]; degree]; challenges_count];
        let data_nodes = vec![None; challenges_count];
        let data_nodes_paths =
            vec![vec![(vec![None; arity - 1], None); depth - 1]; challenges_count];
        let data_root = Root::Val(None);

        DrgPoRepCircuit {
            replica_nodes,
            replica_nodes_paths,
            replica_root,
            replica_parents,
            replica_parents_paths,
            data_nodes,
            data_nodes_paths,
            data_root,
            replica_id: None,
            private: public_params.private,
            _h: Default::default(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use merkletree::store::StoreConfig;
    use pretty_assertions::assert_eq;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        cache_key::CacheKey,
        compound_proof,
        drgraph::{new_seed, BucketGraph, BASE_DEGREE},
        fr32::fr_into_bytes,
        gadgets::{MetricCS, TestConstraintSystem},
        hasher::{Hasher, PedersenHasher, PoseidonHasher},
        merkle::{BinaryMerkleTree, MerkleTreeTrait},
        proof::NoRequirements,
        test_helper::setup_replica,
    };

    use crate::stacked::BINARY_ARITY;
    use crate::{drg, PoRep};

    #[test]
    #[ignore] // Slow test – run only when compiled for release.
    fn test_drgporep_compound_pedersen() {
        drgporep_test_compound::<BinaryMerkleTree<PedersenHasher>>();
    }

    #[test]
    #[ignore] // Slow test – run only when compiled for release.
    fn test_drgporep_compound_poseidon() {
        drgporep_test_compound::<BinaryMerkleTree<PoseidonHasher>>();
    }

    fn drgporep_test_compound<Tree: 'static + MerkleTreeTrait>() {
        // femme::pretty::Logger::new()
        //     .start(log::LevelFilter::Trace)
        //     .ok();

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let nodes = 8;
        let degree = BASE_DEGREE;
        let challenges = vec![1, 3];

        let replica_id: Fr = Fr::random(rng);
        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        // Only generate seed once. It would be bad if we used different seeds in the same test.
        let seed = new_seed();

        let setup_params = compound_proof::SetupParams {
            vanilla_params: drg::SetupParams {
                drg: drg::DrgParams {
                    nodes,
                    degree,
                    expansion_degree: 0,
                    seed,
                },
                private: false,
                challenges_count: 2,
            },
            partitions: None,
            priority: false,
        };

        let public_params =
            DrgPoRepCompound::<Tree::Hasher, BucketGraph<Tree::Hasher>>::setup(&setup_params)
                .expect("setup failed");

        let data_tree: Option<BinaryMerkleTree<Tree::Hasher>> = None;
        let (tau, aux) = drg::DrgPoRep::<Tree::Hasher, BucketGraph<_>>::replicate(
            &public_params.vanilla_params,
            &replica_id.into(),
            (mmapped_data.as_mut()).into(),
            data_tree,
            config,
            replica_path.clone(),
        )
        .expect("failed to replicate");

        let public_inputs = drg::PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
            replica_id: Some(replica_id.into()),
            challenges,
            tau: Some(tau),
        };
        let private_inputs = drg::PrivateInputs {
            tree_d: &aux.tree_d,
            tree_r: &aux.tree_r,
            tree_r_config_rows_to_discard: StoreConfig::default_rows_to_discard(
                nodes,
                BINARY_ARITY,
            ),
        };

        // This duplication is necessary so public_params don't outlive public_inputs and private_inputs.
        let setup_params = compound_proof::SetupParams {
            vanilla_params: drg::SetupParams {
                drg: drg::DrgParams {
                    nodes,
                    degree,
                    expansion_degree: 0,
                    seed,
                },
                private: false,
                challenges_count: 2,
            },
            partitions: None,
            priority: false,
        };

        let public_params =
            DrgPoRepCompound::<Tree::Hasher, BucketGraph<Tree::Hasher>>::setup(&setup_params)
                .expect("setup failed");

        {
            let (circuit, inputs) = DrgPoRepCompound::<Tree::Hasher, _>::circuit_for_test(
                &public_params,
                &public_inputs,
                &private_inputs,
            )
            .unwrap();

            let mut cs = TestConstraintSystem::new();

            circuit
                .synthesize(&mut cs)
                .expect("failed to synthesize test circuit");
            assert!(cs.is_satisfied());
            assert!(cs.verify(&inputs));

            let blank_circuit = <DrgPoRepCompound<_, _> as CompoundProof<_, _>>::blank_circuit(
                &public_params.vanilla_params,
            );

            let mut cs_blank = MetricCS::new();
            blank_circuit
                .synthesize(&mut cs_blank)
                .expect("failed to synthesize blank circuit");

            let a = cs_blank.pretty_print_list();
            let b = cs.pretty_print_list();

            for (i, (a, b)) in a.chunks(100).zip(b.chunks(100)).enumerate() {
                assert_eq!(a, b, "failed at chunk {}", i);
            }
        }

        {
            let gparams = DrgPoRepCompound::<Tree::Hasher, _>::groth_params(
                Some(rng),
                &public_params.vanilla_params,
            )
            .expect("failed to get groth params");

            let proof = DrgPoRepCompound::<Tree::Hasher, _>::prove(
                &public_params,
                &public_inputs,
                &private_inputs,
                &gparams,
            )
            .expect("failed while proving");

            let verified = DrgPoRepCompound::<Tree::Hasher, _>::verify(
                &public_params,
                &public_inputs,
                &proof,
                &NoRequirements,
            )
            .expect("failed while verifying");

            assert!(verified);
        }

        cache_dir.close().expect("Failed to remove cache dir");
    }
}

'''
'''--- storage-proofs/porep/src/drg/mod.rs ---
mod circuit;
mod compound;
mod vanilla;

pub use self::circuit::*;
pub use self::compound::*;
pub use self::vanilla::*;

'''
'''--- storage-proofs/porep/src/drg/vanilla.rs ---
use std::marker::PhantomData;
use std::path::PathBuf;

use anyhow::{ensure, Context};
use generic_array::typenum;
use merkletree::store::{ReplicaConfig, StoreConfig};
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

use storage_proofs_core::{
    drgraph::Graph,
    error::Result,
    fr32::bytes_into_fr_repr_safe,
    hasher::{Domain, HashFunction, Hasher, PoseidonArity},
    merkle::{
        create_base_lcmerkle_tree, create_base_merkle_tree, BinaryLCMerkleTree, BinaryMerkleTree,
        LCMerkleTree, MerkleProof, MerkleProofTrait, MerkleTreeTrait,
    },
    parameter_cache::ParameterSetMetadata,
    proof::{NoRequirements, ProofScheme},
    util::{data_at_node, data_at_node_offset, NODE_SIZE},
    Data,
};

use crate::{encode, PoRep};

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Tau<T> {
    pub comm_r: T,
    pub comm_d: T,
}

impl<T: Domain> Tau<T> {
    pub fn new(comm_d: T, comm_r: T) -> Self {
        Tau { comm_d, comm_r }
    }
}

#[derive(Debug)]
pub struct ProverAux<H: Hasher> {
    pub tree_d: BinaryMerkleTree<H>,
    pub tree_r: BinaryLCMerkleTree<H>,
}

impl<H: Hasher> ProverAux<H> {
    pub fn new(tree_d: BinaryMerkleTree<H>, tree_r: BinaryLCMerkleTree<H>) -> Self {
        ProverAux { tree_d, tree_r }
    }
}

#[derive(Debug, Clone)]
pub struct PublicInputs<T: Domain> {
    pub replica_id: Option<T>,
    pub challenges: Vec<usize>,
    pub tau: Option<Tau<T>>,
}

#[derive(Debug)]
pub struct PrivateInputs<'a, H: 'a + Hasher> {
    pub tree_d: &'a BinaryMerkleTree<H>,
    pub tree_r: &'a BinaryLCMerkleTree<H>,
    pub tree_r_config_rows_to_discard: usize,
}

#[derive(Clone, Debug)]
pub struct SetupParams {
    pub drg: DrgParams,
    pub private: bool,
    pub challenges_count: usize,
}

#[derive(Debug, Clone)]
pub struct DrgParams {
    // Number of nodes
    pub nodes: usize,

    // Base degree of DRG
    pub degree: usize,

    pub expansion_degree: usize,

    // Random seed
    pub seed: [u8; 28],
}

#[derive(Debug, Clone)]
pub struct PublicParams<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata,
{
    pub graph: G,
    pub private: bool,
    pub challenges_count: usize,

    _h: PhantomData<H>,
}

impl<H, G> PublicParams<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata,
{
    pub fn new(graph: G, private: bool, challenges_count: usize) -> Self {
        PublicParams {
            graph,
            private,
            challenges_count,
            _h: PhantomData,
        }
    }
}

impl<H, G> ParameterSetMetadata for PublicParams<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata,
{
    fn identifier(&self) -> String {
        format!(
            "drgporep::PublicParams{{graph: {}}}",
            self.graph.identifier(),
        )
    }

    fn sector_size(&self) -> u64 {
        self.graph.sector_size()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataProof<H: Hasher, U: PoseidonArity> {
    #[serde(bound(
        serialize = "MerkleProof<H, U>: Serialize",
        deserialize = "MerkleProof<H, U>: Deserialize<'de>"
    ))]
    pub proof: MerkleProof<H, U>,
    pub data: H::Domain,
}

impl<H: Hasher, U: 'static + PoseidonArity> DataProof<H, U> {
    pub fn new(n: usize) -> Self {
        DataProof {
            proof: MerkleProof::new(n),
            data: Default::default(),
        }
    }

    /// proves_challenge returns true if this self.proof corresponds to challenge.
    /// This is useful for verifying that a supplied proof is actually relevant to a given challenge.
    pub fn proves_challenge(&self, challenge: usize) -> bool {
        self.proof.proves_challenge(challenge)
    }
}

pub type ReplicaParents<H> = Vec<(u32, DataProof<H, typenum::U2>)>;

#[derive(Default, Debug, Clone, Serialize, Deserialize)]
pub struct Proof<H: Hasher> {
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    pub data_root: H::Domain,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    pub replica_root: H::Domain,
    #[serde(bound(
        serialize = "DataProof<H, typenum::U2>: Serialize",
        deserialize = "DataProof<H, typenum::U2>: Deserialize<'de>"
    ))]
    pub replica_nodes: Vec<DataProof<H, typenum::U2>>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    pub replica_parents: Vec<ReplicaParents<H>>,
    #[serde(bound(
        serialize = "H::Domain: Serialize",
        deserialize = "H::Domain: Deserialize<'de>"
    ))]
    pub nodes: Vec<DataProof<H, typenum::U2>>,
}

impl<H: Hasher> Proof<H> {
    pub fn new_empty(height: usize, degree: usize, challenges: usize) -> Proof<H> {
        Proof {
            data_root: Default::default(),
            replica_root: Default::default(),
            replica_nodes: vec![DataProof::new(height); challenges],
            replica_parents: vec![vec![(0, DataProof::new(height)); degree]; challenges],
            nodes: vec![DataProof::new(height); challenges],
        }
    }

    pub fn new(
        replica_nodes: Vec<DataProof<H, typenum::U2>>,
        replica_parents: Vec<ReplicaParents<H>>,
        nodes: Vec<DataProof<H, typenum::U2>>,
    ) -> Proof<H> {
        Proof {
            data_root: nodes[0].proof.root(),
            replica_root: replica_nodes[0].proof.root(),
            replica_nodes,
            replica_parents,
            nodes,
        }
    }
}

impl<'a, H: Hasher> From<&'a Proof<H>> for Proof<H> {
    fn from(p: &Proof<H>) -> Proof<H> {
        Proof {
            data_root: p.nodes[0].proof.root(),
            replica_root: p.replica_nodes[0].proof.root(),
            replica_nodes: p.replica_nodes.clone(),
            replica_parents: p.replica_parents.clone(),
            nodes: p.nodes.clone(),
        }
    }
}

#[derive(Default)]
pub struct DrgPoRep<'a, H, G>
where
    H: 'a + Hasher,
    G: 'a + Graph<H>,
{
    _h: PhantomData<&'a H>,
    _g: PhantomData<G>,
}

impl<'a, H, G> ProofScheme<'a> for DrgPoRep<'a, H, G>
where
    H: 'static + Hasher,
    G: 'a + Graph<H> + ParameterSetMetadata,
{
    type PublicParams = PublicParams<H, G>;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<<H as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<'a, H>;
    type Proof = Proof<H>;
    type Requirements = NoRequirements;

    fn setup(sp: &Self::SetupParams) -> Result<Self::PublicParams> {
        let graph = G::new(
            sp.drg.nodes,
            sp.drg.degree,
            sp.drg.expansion_degree,
            sp.drg.seed,
        )?;

        Ok(PublicParams::new(graph, sp.private, sp.challenges_count))
    }

    fn prove<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        let len = pub_inputs.challenges.len();
        ensure!(
            len <= pub_params.challenges_count,
            "too many challenges {} > {}",
            len,
            pub_params.challenges_count
        );

        let mut replica_nodes = Vec::with_capacity(len);
        let mut replica_parents = Vec::with_capacity(len);
        let mut data_nodes: Vec<DataProof<H, typenum::U2>> = Vec::with_capacity(len);

        for i in 0..len {
            let challenge = pub_inputs.challenges[i] % pub_params.graph.size();
            ensure!(challenge != 0, "cannot prove the first node");

            let tree_d = &priv_inputs.tree_d;
            let tree_r = &priv_inputs.tree_r;
            let tree_r_config_rows_to_discard = priv_inputs.tree_r_config_rows_to_discard;

            let data = tree_r.read_at(challenge)?;
            let tree_proof =
                tree_r.gen_cached_proof(challenge, Some(tree_r_config_rows_to_discard))?;
            replica_nodes.push(DataProof {
                proof: tree_proof,
                data,
            });

            let mut parents = vec![0; pub_params.graph.degree()];
            pub_params.graph.parents(challenge, &mut parents)?;
            let mut replica_parentsi = Vec::with_capacity(parents.len());

            for p in &parents {
                replica_parentsi.push((*p, {
                    let proof = tree_r
                        .gen_cached_proof(*p as usize, Some(tree_r_config_rows_to_discard))?;
                    DataProof {
                        proof,
                        data: tree_r.read_at(*p as usize)?,
                    }
                }));
            }

            replica_parents.push(replica_parentsi);

            let node_proof = tree_d.gen_proof(challenge)?;

            {
                // TODO: use this again, I can't make lifetimes work though atm and I do not know why
                // let extracted = Self::extract(
                //     pub_params,
                //     &pub_inputs.replica_id.into_bytes(),
                //     &replica,
                //     challenge,
                // )?;

                let extracted = decode_domain_block::<H>(
                    &pub_inputs.replica_id.context("missing replica_id")?,
                    tree_r,
                    challenge,
                    tree_r.read_at(challenge)?,
                    &parents,
                )?;
                data_nodes.push(DataProof {
                    data: extracted,
                    proof: node_proof,
                });
            }
        }

        let proof = Proof::new(replica_nodes, replica_parents, data_nodes);

        Ok(proof)
    }

    fn verify(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        proof: &Self::Proof,
    ) -> Result<bool> {
        let mut hasher = Sha256::new();

        for i in 0..pub_inputs.challenges.len() {
            {
                // This was verify_proof_meta.
                if pub_inputs.challenges[i] >= pub_params.graph.size() {
                    return Ok(false);
                }

                if !(proof.nodes[i].proves_challenge(pub_inputs.challenges[i])) {
                    return Ok(false);
                }

                if !(proof.replica_nodes[i].proves_challenge(pub_inputs.challenges[i])) {
                    return Ok(false);
                }

                let mut expected_parents = vec![0; pub_params.graph.degree()];
                pub_params
                    .graph
                    .parents(pub_inputs.challenges[i], &mut expected_parents)?;
                if proof.replica_parents[i].len() != expected_parents.len() {
                    println!(
                        "proof parents were not the same length as in public parameters: {} != {}",
                        proof.replica_parents[i].len(),
                        expected_parents.len()
                    );
                    return Ok(false);
                }

                let parents_as_expected = proof.replica_parents[i]
                    .iter()
                    .zip(&expected_parents)
                    .all(|(actual, expected)| actual.0 == *expected);

                if !parents_as_expected {
                    println!("proof parents were not those provided in public parameters");
                    return Ok(false);
                }
            }

            let challenge = pub_inputs.challenges[i] % pub_params.graph.size();
            ensure!(challenge != 0, "cannot prove the first node");

            if !proof.replica_nodes[i].proof.validate(challenge) {
                return Ok(false);
            }

            for (parent_node, p) in &proof.replica_parents[i] {
                if !p.proof.validate(*parent_node as usize) {
                    return Ok(false);
                }
            }

            let key = {
                let prover_bytes = pub_inputs.replica_id.context("missing replica_id")?;
                hasher.input(AsRef::<[u8]>::as_ref(&prover_bytes));

                for p in proof.replica_parents[i].iter() {
                    hasher.input(AsRef::<[u8]>::as_ref(&p.1.data));
                }

                let hash = hasher.result_reset();
                bytes_into_fr_repr_safe(hash.as_ref()).into()
            };

            let unsealed = encode::decode(key, proof.replica_nodes[i].data);

            if unsealed != proof.nodes[i].data {
                return Ok(false);
            }

            if !proof.nodes[i].proof.validate_data(unsealed) {
                println!("invalid data for merkle path {:?}", unsealed);
                return Ok(false);
            }
        }

        Ok(true)
    }
}

impl<'a, H, G> PoRep<'a, H, H> for DrgPoRep<'a, H, G>
where
    H: 'static + Hasher,
    G::Key: AsRef<<H as Hasher>::Domain>,
    G: 'a + Graph<H> + ParameterSetMetadata + Sync + Send,
{
    type Tau = Tau<<H as Hasher>::Domain>;
    type ProverAux = ProverAux<H>;

    fn replicate(
        pp: &Self::PublicParams,
        replica_id: &<H as Hasher>::Domain,
        mut data: Data<'a>,
        data_tree: Option<BinaryMerkleTree<H>>,
        config: StoreConfig,
        replica_path: PathBuf,
    ) -> Result<(Self::Tau, Self::ProverAux)> {
        use storage_proofs_core::cache_key::CacheKey;

        let tree_d = match data_tree {
            Some(tree) => tree,
            None => create_base_merkle_tree::<BinaryMerkleTree<H>>(
                Some(config.clone()),
                pp.graph.size(),
                data.as_ref(),
            )?,
        };

        let graph = &pp.graph;
        // encode(&pp.graph, replica_id, data, None)?;
        // Because a node always follows all of its parents in the data,
        // the nodes are by definition already topologically sorted.
        // Therefore, if we simply traverse the data in order, encoding each node in place,
        // we can always get each parent's encodings with a simple lookup --
        // since we will already have encoded the parent earlier in the traversal.

        let mut parents = vec![0; graph.degree()];
        for node in 0..graph.size() {
            graph.parents(node, &mut parents)?;
            let key = graph.create_key(replica_id, node, &parents, data.as_ref(), None)?;
            let start = data_at_node_offset(node);
            let end = start + NODE_SIZE;

            let node_data = <H as Hasher>::Domain::try_from_bytes(&data.as_ref()[start..end])?;
            let encoded = H::sloth_encode(key.as_ref(), &node_data)?;

            encoded.write_bytes(&mut data.as_mut()[start..end])?;
        }

        let replica_config = ReplicaConfig {
            path: replica_path,
            offsets: vec![0],
        };
        let tree_r_last_config =
            StoreConfig::from_config(&config, CacheKey::CommRLastTree.to_string(), None);
        let tree_r =
            create_base_lcmerkle_tree::<H, <BinaryLCMerkleTree<H> as MerkleTreeTrait>::Arity>(
                tree_r_last_config,
                pp.graph.size(),
                &data.as_ref(),
                &replica_config,
            )?;

        let comm_d = tree_d.root();
        let comm_r = tree_r.root();

        Ok((Tau::new(comm_d, comm_r), ProverAux::new(tree_d, tree_r)))
    }

    fn extract_all<'b>(
        pp: &'b Self::PublicParams,
        replica_id: &'b <H as Hasher>::Domain,
        data: &'b [u8],
        _config: Option<StoreConfig>,
    ) -> Result<Vec<u8>> {
        decode(&pp.graph, replica_id, data, None)
    }

    fn extract(
        pp: &Self::PublicParams,
        replica_id: &<H as Hasher>::Domain,
        data: &[u8],
        node: usize,
        _config: Option<StoreConfig>,
    ) -> Result<Vec<u8>> {
        Ok(decode_block(&pp.graph, replica_id, data, None, node)?.into_bytes())
    }
}

pub fn decode<'a, H, G>(
    graph: &'a G,
    replica_id: &'a <H as Hasher>::Domain,
    data: &'a [u8],
    exp_parents_data: Option<&'a [u8]>,
) -> Result<Vec<u8>>
where
    H: Hasher,
    G::Key: AsRef<H::Domain>,
    G: Graph<H> + Sync,
{
    // TODO: proper error handling
    let result = (0..graph.size())
        .into_par_iter()
        .flat_map(|i| {
            decode_block::<H, G>(graph, replica_id, data, exp_parents_data, i)
                .unwrap()
                .into_bytes()
        })
        .collect();

    Ok(result)
}

pub fn decode_block<'a, H, G>(
    graph: &'a G,
    replica_id: &'a <H as Hasher>::Domain,
    data: &'a [u8],
    exp_parents_data: Option<&'a [u8]>,
    v: usize,
) -> Result<<H as Hasher>::Domain>
where
    H: Hasher,
    G::Key: AsRef<H::Domain>,
    G: Graph<H>,
{
    let mut parents = vec![0; graph.degree()];
    graph.parents(v, &mut parents)?;
    let key = graph.create_key(replica_id, v, &parents, &data, exp_parents_data)?;
    let node_data = <H as Hasher>::Domain::try_from_bytes(&data_at_node(data, v)?)?;

    Ok(encode::decode(*key.as_ref(), node_data))
}

pub fn decode_domain_block<H: Hasher>(
    replica_id: &H::Domain,
    tree: &BinaryLCMerkleTree<H>,
    node: usize,
    node_data: H::Domain,
    parents: &[u32],
) -> Result<H::Domain>
where
    H: Hasher,
{
    let key = create_key_from_tree::<H, _>(replica_id, node, parents, tree)?;

    Ok(encode::decode(key, node_data))
}

/// Creates the encoding key from a `MerkleTree`.
/// The algorithm for that is `Blake2s(id | encodedParentNode1 | encodedParentNode1 | ...)`.
/// It is only public so that it can be used for benchmarking
pub fn create_key_from_tree<H: Hasher, U: 'static + PoseidonArity>(
    id: &H::Domain,
    node: usize,
    parents: &[u32],
    tree: &LCMerkleTree<H, U>,
) -> Result<H::Domain> {
    let mut hasher = Sha256::new();
    hasher.input(AsRef::<[u8]>::as_ref(&id));

    // The hash is about the parents, hence skip if a node doesn't have any parents
    if node != parents[0] as usize {
        let mut scratch: [u8; NODE_SIZE] = [0; NODE_SIZE];
        for parent in parents.iter() {
            tree.read_into(*parent as usize, &mut scratch)?;
            hasher.input(&scratch);
        }
    }

    let hash = hasher.result();
    Ok(bytes_into_fr_repr_safe(hash.as_ref()).into())
}

pub fn replica_id<H: Hasher>(prover_id: [u8; 32], sector_id: [u8; 32]) -> H::Domain {
    let mut to_hash = [0; 64];
    to_hash[..32].copy_from_slice(&prover_id);
    to_hash[32..].copy_from_slice(&sector_id);

    H::Function::hash_leaf(&to_hash)
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use paired::bls12_381::Fr;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        cache_key::CacheKey,
        drgraph::{new_seed, BucketGraph, BASE_DEGREE},
        fr32::fr_into_bytes,
        hasher::{Blake2sHasher, PedersenHasher, Sha256Hasher},
        merkle::{BinaryMerkleTree, MerkleTreeTrait},
        table_tests,
        test_helper::setup_replica,
        util::data_at_node,
    };
    use tempfile;

    use crate::stacked::BINARY_ARITY;

    fn test_extract_all<Tree: MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let replica_id: <Tree::Hasher as Hasher>::Domain =
            <Tree::Hasher as Hasher>::Domain::random(rng);
        let nodes = 4;
        let data = vec![2u8; 32 * nodes];

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let sp = SetupParams {
            drg: DrgParams {
                nodes,
                degree: BASE_DEGREE,
                expansion_degree: 0,
                seed: new_seed(),
            },
            private: false,
            challenges_count: 1,
        };

        let pp: PublicParams<Tree::Hasher, BucketGraph<Tree::Hasher>> =
            DrgPoRep::setup(&sp).expect("setup failed");

        DrgPoRep::replicate(
            &pp,
            &replica_id,
            (mmapped_data.as_mut()).into(),
            None,
            config.clone(),
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        let decoded_data = DrgPoRep::<Tree::Hasher, _>::extract_all(
            &pp,
            &replica_id,
            mmapped_data.as_mut(),
            Some(config.clone()),
        )
        .unwrap_or_else(|e| {
            panic!("Failed to extract data from `DrgPoRep`: {}", e);
        });

        assert_eq!(data, decoded_data.as_slice(), "failed to extract data");

        cache_dir.close().expect("Failed to remove cache dir");
    }

    #[test]
    fn extract_all_pedersen() {
        test_extract_all::<BinaryMerkleTree<PedersenHasher>>();
    }

    #[test]
    fn extract_all_sha256() {
        test_extract_all::<BinaryMerkleTree<Sha256Hasher>>();
    }

    #[test]
    fn extract_all_blake2s() {
        test_extract_all::<BinaryMerkleTree<Blake2sHasher>>();
    }

    fn test_extract<Tree: MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let replica_id: <Tree::Hasher as Hasher>::Domain =
            <Tree::Hasher as Hasher>::Domain::random(rng);
        let nodes = 4;
        let data = vec![2u8; 32 * nodes];

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let sp = SetupParams {
            drg: DrgParams {
                nodes: data.len() / 32,
                degree: BASE_DEGREE,
                expansion_degree: 0,
                seed: new_seed(),
            },
            private: false,
            challenges_count: 1,
        };

        let pp =
            DrgPoRep::<Tree::Hasher, BucketGraph<Tree::Hasher>>::setup(&sp).expect("setup failed");

        DrgPoRep::replicate(
            &pp,
            &replica_id,
            (mmapped_data.as_mut()).into(),
            None,
            config.clone(),
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        for i in 0..nodes {
            let decoded_data =
                DrgPoRep::extract(&pp, &replica_id, &mmapped_data, i, Some(config.clone()))
                    .expect("failed to extract node data from PoRep");

            let original_data = data_at_node(&data, i).unwrap();

            assert_eq!(
                original_data,
                decoded_data.as_slice(),
                "failed to extract data"
            );
        }
    }

    #[test]
    fn extract_pedersen() {
        test_extract::<BinaryMerkleTree<PedersenHasher>>();
    }

    #[test]
    fn extract_sha256() {
        test_extract::<BinaryMerkleTree<Sha256Hasher>>();
    }

    #[test]
    fn extract_blake2s() {
        test_extract::<BinaryMerkleTree<Blake2sHasher>>();
    }

    fn prove_verify_aux<Tree: MerkleTreeTrait>(
        nodes: usize,
        i: usize,
        use_wrong_challenge: bool,
        use_wrong_parents: bool,
    ) {
        assert!(i < nodes);

        // The loop is here in case we need to retry because of an edge case in the test design.
        loop {
            let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
            let degree = BASE_DEGREE;
            let expansion_degree = 0;
            let seed = new_seed();

            let replica_id: <Tree::Hasher as Hasher>::Domain =
                <Tree::Hasher as Hasher>::Domain::random(rng);
            let data: Vec<u8> = (0..nodes)
                .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
                .collect();

            // MT for original data is always named tree-d, and it will be
            // referenced later in the process as such.
            let cache_dir = tempfile::tempdir().unwrap();
            let config = StoreConfig::new(
                cache_dir.path(),
                CacheKey::CommDTree.to_string(),
                StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
            );

            // Generate a replica path.
            let replica_path = cache_dir.path().join("replica-path");
            let mut mmapped_data = setup_replica(&data, &replica_path);

            let challenge = i;

            let sp = SetupParams {
                drg: DrgParams {
                    nodes,
                    degree,
                    expansion_degree,
                    seed,
                },
                private: false,
                challenges_count: 2,
            };

            let pp = DrgPoRep::<Tree::Hasher, BucketGraph<_>>::setup(&sp).expect("setup failed");

            let (tau, aux) = DrgPoRep::<Tree::Hasher, _>::replicate(
                &pp,
                &replica_id,
                (mmapped_data.as_mut()).into(),
                None,
                config,
                replica_path.clone(),
            )
            .expect("replication failed");

            let mut copied = vec![0; data.len()];
            copied.copy_from_slice(&mmapped_data);
            assert_ne!(data, copied, "replication did not change data");

            let pub_inputs = PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
                replica_id: Some(replica_id),
                challenges: vec![challenge, challenge],
                tau: Some(tau.clone().into()),
            };

            let priv_inputs = PrivateInputs::<Tree::Hasher> {
                tree_d: &aux.tree_d,
                tree_r: &aux.tree_r,
                tree_r_config_rows_to_discard: StoreConfig::default_rows_to_discard(
                    nodes,
                    BINARY_ARITY,
                ),
            };

            let real_proof = DrgPoRep::<Tree::Hasher, _>::prove(&pp, &pub_inputs, &priv_inputs)
                .expect("proving failed");

            if use_wrong_parents {
                // Only one 'wrong' option will be tested at a time.
                assert!(!use_wrong_challenge);
                let real_parents = real_proof.replica_parents;

                // Parent vector claiming the wrong parents.
                let fake_parents = vec![real_parents[0]
                    .iter()
                    // Incrementing each parent node will give us a different parent set.
                    // It's fine to be out of range, since this only needs to fail.
                    .map(|(i, data_proof)| (i + 1, data_proof.clone()))
                    .collect::<Vec<_>>()];

                let proof = Proof::new(
                    real_proof.replica_nodes.clone(),
                    fake_parents,
                    real_proof.nodes.clone().into(),
                );

                let is_valid =
                    DrgPoRep::verify(&pp, &pub_inputs, &proof).expect("verification failed");

                assert!(!is_valid, "verified in error -- with wrong parents");

                let mut all_same = true;
                for (p, _) in &real_parents[0] {
                    if *p != real_parents[0][0].0 {
                        all_same = false;
                    }
                }

                if all_same {
                    println!("invalid test data can't scramble proofs with all same parents.");

                    // If for some reason, we hit this condition because of the data passed in,
                    // try again.
                    continue;
                }

                // Parent vector claiming the right parents but providing valid proofs for different
                // parents.
                let fake_proof_parents = vec![real_parents[0]
                    .iter()
                    .enumerate()
                    .map(|(i, (p, _))| {
                        // Rotate the real parent proofs.
                        let x = (i + 1) % real_parents[0].len();
                        let j = real_parents[0][x].0;
                        (*p, real_parents[0][j as usize].1.clone())
                    })
                    .collect::<Vec<_>>()];

                let proof2 = Proof::new(
                    real_proof.replica_nodes,
                    fake_proof_parents,
                    real_proof.nodes.into(),
                );

                assert!(
                    !DrgPoRep::<Tree::Hasher, _>::verify(&pp, &pub_inputs, &proof2).unwrap_or_else(
                        |e| {
                            panic!("Verification failed: {}", e);
                        }
                    ),
                    "verified in error -- with wrong parent proofs"
                );

                return ();
            }

            let proof = real_proof;

            if use_wrong_challenge {
                let pub_inputs_with_wrong_challenge_for_proof =
                    PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
                        replica_id: Some(replica_id),
                        challenges: vec![if challenge == 1 { 2 } else { 1 }],
                        tau: Some(tau.into()),
                    };
                let verified = DrgPoRep::<Tree::Hasher, _>::verify(
                    &pp,
                    &pub_inputs_with_wrong_challenge_for_proof,
                    &proof,
                )
                .expect("Verification failed");
                assert!(
                    !verified,
                    "wrongly verified proof which does not match challenge in public input"
                );
            } else {
                assert!(
                    DrgPoRep::<Tree::Hasher, _>::verify(&pp, &pub_inputs, &proof)
                        .expect("verification failed"),
                    "failed to verify"
                );
            }

            cache_dir.close().expect("Failed to remove cache dir");

            // Normally, just run once.
            break;
        }
    }

    fn prove_verify(n: usize, i: usize) {
        prove_verify_aux::<BinaryMerkleTree<PedersenHasher>>(n, i, false, false);
        prove_verify_aux::<BinaryMerkleTree<Sha256Hasher>>(n, i, false, false);
        prove_verify_aux::<BinaryMerkleTree<Blake2sHasher>>(n, i, false, false);
    }

    fn prove_verify_wrong_challenge(n: usize, i: usize) {
        prove_verify_aux::<BinaryMerkleTree<PedersenHasher>>(n, i, true, false);
        prove_verify_aux::<BinaryMerkleTree<Sha256Hasher>>(n, i, true, false);
        prove_verify_aux::<BinaryMerkleTree<Blake2sHasher>>(n, i, true, false);
    }

    fn prove_verify_wrong_parents(n: usize, i: usize) {
        prove_verify_aux::<BinaryMerkleTree<PedersenHasher>>(n, i, false, true);
        prove_verify_aux::<BinaryMerkleTree<Sha256Hasher>>(n, i, false, true);
        prove_verify_aux::<BinaryMerkleTree<Blake2sHasher>>(n, i, false, true);
    }

    table_tests! {
        prove_verify {
            prove_verify_32_16_1(16, 1);

            prove_verify_32_64_1(64, 1);
            prove_verify_32_64_2(64, 2);

            prove_verify_32_256_1(256, 1);
            prove_verify_32_256_2(256, 2);
            prove_verify_32_256_3(256, 3);
            prove_verify_32_256_4(256, 4);
            prove_verify_32_256_5(256, 5);
        }
    }

    #[test]
    fn test_drgporep_verifies_using_challenge() {
        prove_verify_wrong_challenge(8, 1);
    }

    #[test]
    fn test_drgporep_verifies_parents() {
        // Challenge a node (3) that doesn't have all the same parents.
        prove_verify_wrong_parents(8, 5);
    }
}

'''
'''--- storage-proofs/porep/src/encode.rs ---
use ff::Field;
use paired::bls12_381::Fr;
use storage_proofs_core::hasher::Domain;

pub fn encode<T: Domain>(key: T, value: T) -> T {
    let mut result: Fr = value.into();
    let key: Fr = key.into();

    result.add_assign(&key);
    result.into()
}

pub fn decode<T: Domain>(key: T, value: T) -> T {
    let mut result: Fr = value.into();
    let key: Fr = key.into();

    result.sub_assign(&key);
    result.into()
}

'''
'''--- storage-proofs/porep/src/lib.rs ---
pub mod drg;
pub mod stacked;

mod encode;

use std::path::PathBuf;

use merkletree::store::StoreConfig;
use storage_proofs_core::{
    error::Result, hasher::Hasher, merkle::BinaryMerkleTree, proof::ProofScheme, Data,
};

pub trait PoRep<'a, H: Hasher, G: Hasher>: ProofScheme<'a> {
    type Tau;
    type ProverAux;

    fn replicate(
        pub_params: &'a Self::PublicParams,
        replica_id: &H::Domain,
        data: Data<'a>,
        data_tree: Option<BinaryMerkleTree<G>>,
        config: StoreConfig,
        replica_path: PathBuf,
    ) -> Result<(Self::Tau, Self::ProverAux)>;

    fn extract_all(
        pub_params: &'a Self::PublicParams,
        replica_id: &H::Domain,
        replica: &[u8],
        config: Option<StoreConfig>,
    ) -> Result<Vec<u8>>;

    fn extract(
        pub_params: &'a Self::PublicParams,
        replica_id: &H::Domain,
        replica: &[u8],
        node: usize,
        config: Option<StoreConfig>,
    ) -> Result<Vec<u8>>;
}

#[cfg(test)]
pub(crate) const TEST_SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

'''
'''--- storage-proofs/porep/src/stacked/circuit/column.rs ---
use bellperson::gadgets::num;
use bellperson::{ConstraintSystem, SynthesisError};
use paired::bls12_381::{Bls12, Fr};
use storage_proofs_core::{hasher::Hasher, merkle::MerkleTreeTrait};

use super::hash::hash_single_column;
use crate::stacked::{Column as VanillaColumn, PublicParams};

#[derive(Debug, Clone)]
pub struct Column {
    rows: Vec<Option<Fr>>,
}

#[derive(Clone)]
pub struct AllocatedColumn {
    rows: Vec<num::AllocatedNum<Bls12>>,
}

impl<H: Hasher> From<VanillaColumn<H>> for Column {
    fn from(other: VanillaColumn<H>) -> Self {
        let VanillaColumn { rows, .. } = other;

        Column {
            rows: rows.into_iter().map(|r| Some(r.into())).collect(),
        }
    }
}

impl Column {
    /// Create an empty `Column`, used in `blank_circuit`s.
    pub fn empty<Tree: MerkleTreeTrait>(params: &PublicParams<Tree>) -> Self {
        Column {
            rows: vec![None; params.layer_challenges.layers()],
        }
    }

    /// Consume this column, and allocate its values in the circuit.
    pub fn alloc<CS: ConstraintSystem<Bls12>>(
        self,
        mut cs: CS,
    ) -> Result<AllocatedColumn, SynthesisError> {
        let Self { rows } = self;

        let rows = rows
            .into_iter()
            .enumerate()
            .map(|(i, val)| {
                num::AllocatedNum::alloc(cs.namespace(|| format!("column_num_row_{}", i)), || {
                    val.ok_or_else(|| SynthesisError::AssignmentMissing)
                })
            })
            .collect::<Result<Vec<_>, _>>()?;

        Ok(AllocatedColumn { rows })
    }
}

impl AllocatedColumn {
    /// Creates the column hash of this column.
    pub fn hash<CS: ConstraintSystem<Bls12>>(
        &self,
        cs: CS,
    ) -> Result<num::AllocatedNum<Bls12>, SynthesisError> {
        hash_single_column(cs, &self.rows)
    }

    pub fn get_value(&self, layer: usize) -> &num::AllocatedNum<Bls12> {
        assert!(layer > 0, "layers are 1 indexed");
        assert!(
            layer <= self.rows.len(),
            "layer {} out of range: 1..={}",
            layer,
            self.rows.len()
        );
        &self.rows[layer - 1]
    }
}

'''
'''--- storage-proofs/porep/src/stacked/circuit/column_proof.rs ---
use bellperson::{ConstraintSystem, SynthesisError};
use paired::bls12_381::Bls12;
use storage_proofs_core::{
    drgraph::Graph,
    gadgets::por::AuthPath,
    hasher::{Hasher, PoseidonArity},
    merkle::{MerkleProofTrait, MerkleTreeTrait, Store},
};

use super::column::{AllocatedColumn, Column};
use crate::stacked::{ColumnProof as VanillaColumnProof, PublicParams};

#[derive(Debug, Clone)]
pub struct ColumnProof<
    H: Hasher,
    U: 'static + PoseidonArity,
    V: 'static + PoseidonArity,
    W: 'static + PoseidonArity,
> {
    column: Column,
    inclusion_path: AuthPath<H, U, V, W>,
}

impl<
        H: 'static + Hasher,
        U: 'static + PoseidonArity,
        V: 'static + PoseidonArity,
        W: 'static + PoseidonArity,
    > ColumnProof<H, U, V, W>
{
    /// Create an empty `ColumnProof`, used in `blank_circuit`s.
    pub fn empty<
        S: Store<H::Domain>,
        Tree: MerkleTreeTrait<Hasher = H, Store = S, Arity = U, SubTreeArity = V, TopTreeArity = W>,
    >(
        params: &PublicParams<Tree>,
    ) -> Self {
        ColumnProof {
            column: Column::empty(params),
            inclusion_path: AuthPath::blank(params.graph.size()),
        }
    }

    /// Allocate the private inputs for this column proof, and return the inclusion path for verification.
    pub fn alloc<CS: ConstraintSystem<Bls12>>(
        self,
        mut cs: CS,
    ) -> Result<(AllocatedColumn, AuthPath<H, U, V, W>), SynthesisError> {
        let ColumnProof {
            inclusion_path,
            column,
        } = self;

        let column = column.alloc(cs.namespace(|| "column"))?;

        Ok((column, inclusion_path))
    }
}

impl<Proof: MerkleProofTrait> From<VanillaColumnProof<Proof>>
    for ColumnProof<Proof::Hasher, Proof::Arity, Proof::SubTreeArity, Proof::TopTreeArity>
{
    fn from(vanilla_proof: VanillaColumnProof<Proof>) -> Self {
        let VanillaColumnProof {
            column,
            inclusion_proof,
        } = vanilla_proof;

        ColumnProof {
            column: column.into(),
            inclusion_path: inclusion_proof.as_options().into(),
        }
    }
}

'''
'''--- storage-proofs/porep/src/stacked/circuit/create_label.rs ---
use bellperson::gadgets::{boolean::Boolean, num, sha256::sha256 as sha256_circuit, uint32};
use bellperson::{ConstraintSystem, SynthesisError};
use ff::PrimeField;
use fil_sapling_crypto::jubjub::JubjubEngine;
use storage_proofs_core::{gadgets::multipack, gadgets::uint64, util::reverse_bit_numbering};

use crate::stacked::vanilla::TOTAL_PARENTS;

/// Compute a single label.
pub fn create_label_circuit<E, CS>(
    mut cs: CS,
    replica_id: &[Boolean],
    parents: Vec<Vec<Boolean>>,
    layer_index: uint32::UInt32,
    node: uint64::UInt64,
) -> Result<num::AllocatedNum<E>, SynthesisError>
where
    E: JubjubEngine,
    CS: ConstraintSystem<E>,
{
    assert!(replica_id.len() <= 256, "replica id is too large");
    assert_eq!(parents.len(), TOTAL_PARENTS, "invalid sized parents");

    // ciphertexts will become a buffer of the layout
    // id | node | parent_node_0 | parent_node_1 | ...

    let mut ciphertexts = replica_id.to_vec();

    // pad to 32 bytes
    while ciphertexts.len() < 256 {
        ciphertexts.push(Boolean::constant(false));
    }

    ciphertexts.extend_from_slice(&layer_index.into_bits_be());
    ciphertexts.extend_from_slice(&node.to_bits_be());
    // pad to 64 bytes
    while ciphertexts.len() < 512 {
        ciphertexts.push(Boolean::constant(false));
    }

    for parent in parents.iter() {
        ciphertexts.extend_from_slice(parent);

        // pad such that each parents take 32 bytes
        while ciphertexts.len() % 256 != 0 {
            ciphertexts.push(Boolean::constant(false));
        }
    }

    // 32b replica id
    // 32b layer_index + node
    // 37 * 32b  = 1184b parents
    assert_eq!(ciphertexts.len(), (1 + 1 + TOTAL_PARENTS) * 32 * 8);

    // Compute Sha256
    let alloc_bits = sha256_circuit(cs.namespace(|| "hash"), &ciphertexts[..])?;

    // Convert the hash result into a single Fr.
    let bits = reverse_bit_numbering(alloc_bits);
    multipack::pack_bits(
        cs.namespace(|| "result_num"),
        &bits[0..(E::Fr::CAPACITY as usize)],
    )
}

#[cfg(test)]
mod tests {
    use super::*;

    use bellperson::gadgets::boolean::Boolean;
    use bellperson::ConstraintSystem;
    use ff::Field;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        drgraph::{new_seed, Graph, BASE_DEGREE},
        fr32::{bytes_into_fr, fr_into_bytes},
        gadgets::TestConstraintSystem,
        hasher::Sha256Hasher,
        util::bytes_into_boolean_vec_be,
        util::{data_at_node, NODE_SIZE},
    };

    use crate::stacked::vanilla::{
        create_label_exp, StackedBucketGraph, EXP_DEGREE, TOTAL_PARENTS,
    };

    #[test]
    fn test_create_label() {
        let mut cs = TestConstraintSystem::<Bls12>::new();
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let size = 64;

        let graph = StackedBucketGraph::<Sha256Hasher>::new_stacked(
            size,
            BASE_DEGREE,
            EXP_DEGREE,
            new_seed(),
        )
        .unwrap();

        let id_fr = Fr::random(rng);
        let id: Vec<u8> = fr_into_bytes(&id_fr);
        let layer = 3;
        let node = 22;

        let mut data: Vec<u8> = (0..2 * size)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        let mut parents = vec![0; BASE_DEGREE + EXP_DEGREE];
        graph.parents(node, &mut parents).unwrap();

        let raw_parents_bytes: Vec<Vec<u8>> = parents
            .iter()
            .enumerate()
            .map(|(i, p)| {
                if i < BASE_DEGREE {
                    // base
                    data_at_node(&data[..size * NODE_SIZE], *p as usize)
                        .unwrap()
                        .to_vec()
                } else {
                    // exp
                    data_at_node(&data[size * NODE_SIZE..], *p as usize)
                        .unwrap()
                        .to_vec()
                }
            })
            .collect();

        let mut parents_bytes = raw_parents_bytes.clone(); // 14
        parents_bytes.extend_from_slice(&raw_parents_bytes); // 28
        parents_bytes.extend_from_slice(&raw_parents_bytes[..9]); // 37

        assert_eq!(parents_bytes.len(), TOTAL_PARENTS);
        let parents_bits: Vec<Vec<Boolean>> = parents_bytes
            .iter()
            .enumerate()
            .map(|(i, p)| {
                let mut cs = cs.namespace(|| format!("parents {}", i));
                bytes_into_boolean_vec_be(&mut cs, Some(p), p.len()).unwrap()
            })
            .collect();

        let id_bits: Vec<Boolean> = {
            let mut cs = cs.namespace(|| "id");
            bytes_into_boolean_vec_be(&mut cs, Some(id.as_slice()), id.len()).unwrap()
        };

        let layer_alloc = uint32::UInt32::constant(layer as u32);
        let node_alloc = uint64::UInt64::constant(node as u64);

        let out = create_label_circuit(
            cs.namespace(|| "create_label"),
            &id_bits,
            parents_bits.clone(),
            layer_alloc,
            node_alloc,
        )
        .expect("key derivation function failed");

        assert!(cs.is_satisfied(), "constraints not satisfied");
        assert_eq!(cs.num_constraints(), 532_025);

        let (l1, l2) = data.split_at_mut(size * NODE_SIZE);
        create_label_exp(&graph, &id_fr.into(), &*l2, l1, layer, node).unwrap();
        let expected_raw = data_at_node(&l1, node).unwrap();
        let expected = bytes_into_fr(expected_raw).unwrap();

        assert_eq!(
            expected,
            out.get_value().unwrap(),
            "circuit and non circuit do not match"
        );
    }
}

'''
'''--- storage-proofs/porep/src/stacked/circuit/hash.rs ---
use bellperson::gadgets::num;
use bellperson::{ConstraintSystem, SynthesisError};
use generic_array::typenum;
use neptune::circuit::poseidon_hash;
use paired::bls12_381::Bls12;

/// Hash a list of bits.
pub fn hash_single_column<CS>(
    cs: CS,
    column: &[num::AllocatedNum<Bls12>],
) -> Result<num::AllocatedNum<Bls12>, SynthesisError>
where
    CS: ConstraintSystem<Bls12>,
{
    match column.len() {
        2 => poseidon_hash::<CS, Bls12, typenum::U2>(
            cs,
            column.to_vec(),
            &*storage_proofs_core::hasher::types::POSEIDON_CONSTANTS_2,
        ),
        11 => poseidon_hash::<CS, Bls12, typenum::U11>(
            cs,
            column.to_vec(),
            &*storage_proofs_core::hasher::types::POSEIDON_CONSTANTS_11,
        ),
        _ => panic!("unsupported column size: {}", column.len()),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use bellperson::ConstraintSystem;
    use ff::Field;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::gadgets::TestConstraintSystem;
    use storage_proofs_core::hasher::{HashFunction, Hasher, PedersenHasher};

    use crate::stacked::vanilla::hash::hash_single_column as vanilla_hash_single_column;

    #[test]
    fn test_hash2_circuit() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..10 {
            let mut cs = TestConstraintSystem::<Bls12>::new();

            let a = Fr::random(rng);
            let b = Fr::random(rng);

            let a_num = {
                let mut cs = cs.namespace(|| "a");
                num::AllocatedNum::alloc(&mut cs, || Ok(a)).unwrap()
            };

            let b_num = {
                let mut cs = cs.namespace(|| "b");
                num::AllocatedNum::alloc(&mut cs, || Ok(b)).unwrap()
            };

            let out = <PedersenHasher as Hasher>::Function::hash2_circuit(
                cs.namespace(|| "hash2"),
                &a_num,
                &b_num,
            )
            .expect("hash2 function failed");

            assert!(cs.is_satisfied(), "constraints not satisfied");
            assert_eq!(cs.num_constraints(), 1_371);

            let expected: Fr =
                <PedersenHasher as Hasher>::Function::hash2(&a.into(), &b.into()).into();

            assert_eq!(
                expected,
                out.get_value().unwrap(),
                "circuit and non circuit do not match"
            );
        }
    }

    #[test]
    fn test_hash_single_column_circuit() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        for _ in 0..1 {
            let mut cs = TestConstraintSystem::<Bls12>::new();

            let vals = vec![Fr::random(rng); 11];
            let vals_opt = vals
                .iter()
                .enumerate()
                .map(|(i, v)| {
                    num::AllocatedNum::alloc(cs.namespace(|| format!("num_{}", i)), || Ok(*v))
                        .unwrap()
                })
                .collect::<Vec<_>>();

            let out = hash_single_column(cs.namespace(|| "hash_single_column"), &vals_opt)
                .expect("hash_single_column function failed");

            assert!(cs.is_satisfied(), "constraints not satisfied");
            assert_eq!(cs.num_constraints(), 601);

            let expected: Fr = vanilla_hash_single_column(&vals).into();

            assert_eq!(
                expected,
                out.get_value().unwrap(),
                "circuit and non circuit do not match"
            );
        }
    }
}

'''
'''--- storage-proofs/porep/src/stacked/circuit/mod.rs ---
mod column;
mod column_proof;
mod create_label;
mod hash;
mod params;
mod proof;

pub use self::create_label::*;
pub use self::proof::{StackedCircuit, StackedCompound};

'''
'''--- storage-proofs/porep/src/stacked/circuit/params.rs ---
use std::marker::PhantomData;

use bellperson::gadgets::{boolean::Boolean, num, uint32};
use bellperson::{ConstraintSystem, SynthesisError};
use generic_array::typenum::{U0, U2};
use paired::bls12_381::{Bls12, Fr};
use storage_proofs_core::{
    drgraph::Graph,
    gadgets::por::{AuthPath, PoRCircuit},
    gadgets::{encode::encode, uint64, variables::Root},
    hasher::{Hasher, PoseidonArity},
    merkle::{DiskStore, MerkleProofTrait, MerkleTreeTrait, MerkleTreeWrapper},
    util::reverse_bit_numbering,
};

use super::{
    column_proof::ColumnProof, create_label_circuit as create_label, hash::hash_single_column,
};
use crate::stacked::{
    Proof as VanillaProof, PublicParams, ReplicaColumnProof as VanillaReplicaColumnProof,
};

type TreeAuthPath<T> = AuthPath<
    <T as MerkleTreeTrait>::Hasher,
    <T as MerkleTreeTrait>::Arity,
    <T as MerkleTreeTrait>::SubTreeArity,
    <T as MerkleTreeTrait>::TopTreeArity,
>;

type TreeColumnProof<T> = ColumnProof<
    <T as MerkleTreeTrait>::Hasher,
    <T as MerkleTreeTrait>::Arity,
    <T as MerkleTreeTrait>::SubTreeArity,
    <T as MerkleTreeTrait>::TopTreeArity,
>;

/// Proof for a single challenge.
#[derive(Debug)]
pub struct Proof<Tree: MerkleTreeTrait, G: Hasher> {
    /// Inclusion path for the challenged data node in tree D.
    pub comm_d_path: AuthPath<G, U2, U0, U0>,
    /// The value of the challenged data node.
    pub data_leaf: Option<Fr>,
    /// The index of the challenged node.
    pub challenge: Option<u64>,
    /// Inclusion path of the challenged replica node in tree R.
    pub comm_r_last_path: TreeAuthPath<Tree>,
    /// Inclusion path of the column hash of the challenged node  in tree C.
    pub comm_c_path: TreeAuthPath<Tree>,
    /// Column proofs for the drg parents.
    pub drg_parents_proofs: Vec<TreeColumnProof<Tree>>,
    /// Column proofs for the expander parents.
    pub exp_parents_proofs: Vec<TreeColumnProof<Tree>>,
    _t: PhantomData<Tree>,
}

impl<Tree: MerkleTreeTrait, G: 'static + Hasher> Proof<Tree, G> {
    /// Create an empty proof, used in `blank_circuit`s.
    pub fn empty(params: &PublicParams<Tree>) -> Self {
        Proof {
            comm_d_path: AuthPath::blank(params.graph.size()),
            data_leaf: None,
            challenge: None,
            comm_r_last_path: AuthPath::blank(params.graph.size()),
            comm_c_path: AuthPath::blank(params.graph.size()),
            drg_parents_proofs: vec![
                ColumnProof::empty(params);
                params.graph.base_graph().degree()
            ],
            exp_parents_proofs: vec![ColumnProof::empty(params); params.graph.expansion_degree()],
            _t: PhantomData,
        }
    }

    /// Circuit synthesis.
    #[allow(clippy::too_many_arguments)]
    pub fn synthesize<CS: ConstraintSystem<Bls12>>(
        self,
        mut cs: CS,
        layers: usize,
        comm_d: &num::AllocatedNum<Bls12>,
        comm_c: &num::AllocatedNum<Bls12>,
        comm_r_last: &num::AllocatedNum<Bls12>,
        replica_id: &[Boolean],
    ) -> Result<(), SynthesisError> {
        let Proof {
            comm_d_path,
            data_leaf,
            challenge,
            comm_r_last_path,
            comm_c_path,
            drg_parents_proofs,
            exp_parents_proofs,
            ..
        } = self;

        // -- verify initial data layer

        // PrivateInput: data_leaf
        let data_leaf_num = num::AllocatedNum::alloc(cs.namespace(|| "data_leaf"), || {
            data_leaf.ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // enforce inclusion of the data leaf in the tree D
        enforce_inclusion(
            cs.namespace(|| "comm_d_inclusion"),
            comm_d_path,
            comm_d,
            &data_leaf_num,
        )?;

        // -- verify replica column openings

        // Private Inputs for the DRG parent nodes.
        let mut drg_parents = Vec::new();

        for (i, parent) in drg_parents_proofs.into_iter().enumerate() {
            let (parent_col, inclusion_path) =
                parent.alloc(cs.namespace(|| format!("drg_parent_{}_num", i)))?;

            // calculate column hash
            let val = parent_col.hash(cs.namespace(|| format!("drg_parent_{}_constraint", i)))?;
            // enforce inclusion of the column hash in the tree C
            enforce_inclusion(
                cs.namespace(|| format!("drg_parent_{}_inclusion", i)),
                inclusion_path,
                comm_c,
                &val,
            )?;
            drg_parents.push(parent_col);
        }

        // Private Inputs for the Expander parent nodes.
        let mut exp_parents = Vec::new();

        for (i, parent) in exp_parents_proofs.into_iter().enumerate() {
            let (parent_col, inclusion_path) =
                parent.alloc(cs.namespace(|| format!("exp_parent_{}_num", i)))?;

            // calculate column hash
            let val = parent_col.hash(cs.namespace(|| format!("exp_parent_{}_constraint", i)))?;
            // enforce inclusion of the column hash in the tree C
            enforce_inclusion(
                cs.namespace(|| format!("exp_parent_{}_inclusion", i)),
                inclusion_path,
                comm_c,
                &val,
            )?;
            exp_parents.push(parent_col);
        }

        // -- Verify labeling and encoding

        // stores the labels of the challenged column
        let mut column_labels = Vec::new();

        // PublicInput: challenge index
        let challenge_num = uint64::UInt64::alloc(cs.namespace(|| "challenge"), challenge)?;
        challenge_num.pack_into_input(cs.namespace(|| "challenge input"))?;

        for layer in 1..=layers {
            let layer_num = uint32::UInt32::constant(layer as u32);

            let mut cs = cs.namespace(|| format!("labeling_{}", layer));

            // Collect the parents
            let mut parents = Vec::new();

            // all layers have drg parents
            for parent_col in &drg_parents {
                let parent_val_num = parent_col.get_value(layer);
                let parent_val_bits =
                    reverse_bit_numbering(parent_val_num.to_bits_le(
                        cs.namespace(|| format!("drg_parent_{}_bits", parents.len())),
                    )?);
                parents.push(parent_val_bits);
            }

            // the first layer does not contain expander parents
            if layer > 1 {
                for parent_col in &exp_parents {
                    // subtract 1 from the layer index, as the exp parents, are shifted by one, as they
                    // do not store a value for the first layer
                    let parent_val_num = parent_col.get_value(layer - 1);
                    let parent_val_bits = reverse_bit_numbering(parent_val_num.to_bits_le(
                        cs.namespace(|| format!("exp_parent_{}_bits", parents.len())),
                    )?);
                    parents.push(parent_val_bits);
                }
            }

            // Duplicate parents, according to the hashing algorithm.
            let mut expanded_parents = parents.clone();
            if layer > 1 {
                expanded_parents.extend_from_slice(&parents); // 28
                expanded_parents.extend_from_slice(&parents[..9]); // 37
            } else {
                // layer 1 only has drg parents
                expanded_parents.extend_from_slice(&parents); // 12
                expanded_parents.extend_from_slice(&parents); // 18
                expanded_parents.extend_from_slice(&parents); // 24
                expanded_parents.extend_from_slice(&parents); // 30
                expanded_parents.extend_from_slice(&parents); // 36
                expanded_parents.push(parents[0].clone()); // 37
            };

            // Reconstruct the label
            let label = create_label(
                cs.namespace(|| "create_label"),
                replica_id,
                expanded_parents,
                layer_num,
                challenge_num.clone(),
            )?;
            column_labels.push(label);
        }

        // -- encoding node
        {
            // encode the node

            // key is the last label
            let key = &column_labels[column_labels.len() - 1];
            let encoded_node = encode(cs.namespace(|| "encode_node"), key, &data_leaf_num)?;

            // verify inclusion of the encoded node
            enforce_inclusion(
                cs.namespace(|| "comm_r_last_data_inclusion"),
                comm_r_last_path,
                comm_r_last,
                &encoded_node,
            )?;
        }

        // -- ensure the column hash of the labels is included
        {
            // calculate column_hash
            let column_hash =
                hash_single_column(cs.namespace(|| "c_x_column_hash"), &column_labels)?;

            // enforce inclusion of the column hash in the tree C
            enforce_inclusion(
                cs.namespace(|| "c_x_inclusion"),
                comm_c_path,
                comm_c,
                &column_hash,
            )?;
        }

        Ok(())
    }
}

impl<Tree: MerkleTreeTrait, G: Hasher> From<VanillaProof<Tree, G>> for Proof<Tree, G>
where
    Tree::Hasher: 'static,
{
    fn from(vanilla_proof: VanillaProof<Tree, G>) -> Self {
        let VanillaProof {
            comm_d_proofs,
            comm_r_last_proof,
            replica_column_proofs,
            labeling_proofs,
            ..
        } = vanilla_proof;
        let VanillaReplicaColumnProof {
            c_x,
            drg_parents,
            exp_parents,
        } = replica_column_proofs;

        let data_leaf = Some(comm_d_proofs.leaf().into());

        Proof {
            comm_d_path: comm_d_proofs.as_options().into(),
            data_leaf,
            challenge: Some(labeling_proofs[0].node),
            comm_r_last_path: comm_r_last_proof.as_options().into(),
            comm_c_path: c_x.inclusion_proof.as_options().into(),
            drg_parents_proofs: drg_parents.into_iter().map(|p| p.into()).collect(),
            exp_parents_proofs: exp_parents.into_iter().map(|p| p.into()).collect(),
            _t: PhantomData,
        }
    }
}

/// Enforce the inclusion of the given path, to the given leaf and the root.
fn enforce_inclusion<H, U, V, W, CS: ConstraintSystem<Bls12>>(
    cs: CS,
    path: AuthPath<H, U, V, W>,
    root: &num::AllocatedNum<Bls12>,
    leaf: &num::AllocatedNum<Bls12>,
) -> Result<(), SynthesisError>
where
    H: 'static + Hasher,
    U: 'static + PoseidonArity,
    V: 'static + PoseidonArity,
    W: 'static + PoseidonArity,
{
    let root = Root::from_allocated::<CS>(root.clone());
    let leaf = Root::from_allocated::<CS>(leaf.clone());

    PoRCircuit::<MerkleTreeWrapper<H, DiskStore<H::Domain>, U, V, W>>::synthesize(
        cs, leaf, path, root, true,
    )?;

    Ok(())
}

'''
'''--- storage-proofs/porep/src/stacked/circuit/proof.rs ---
use std::marker::PhantomData;

use anyhow::ensure;
use bellperson::gadgets::num;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use paired::bls12_381::{Bls12, Fr};
use storage_proofs_core::{
    compound_proof::{CircuitComponent, CompoundProof},
    drgraph::Graph,
    error::Result,
    fr32::u64_into_fr,
    gadgets::constraint,
    gadgets::por::PoRCompound,
    hasher::{HashFunction, Hasher},
    merkle::{BinaryMerkleTree, MerkleTreeTrait},
    parameter_cache::{CacheableParameters, ParameterSetMetadata},
    por,
    proof::ProofScheme,
    util::reverse_bit_numbering,
};

use super::params::Proof;
use crate::stacked::StackedDrg;

/// Stacked DRG based Proof of Replication.
///
/// # Fields
///
/// * `params` - parameters for the curve
///
pub struct StackedCircuit<'a, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher> {
    public_params: <StackedDrg<'a, Tree, G> as ProofScheme<'a>>::PublicParams,
    replica_id: Option<<Tree::Hasher as Hasher>::Domain>,
    comm_d: Option<G::Domain>,
    comm_r: Option<<Tree::Hasher as Hasher>::Domain>,
    comm_r_last: Option<<Tree::Hasher as Hasher>::Domain>,
    comm_c: Option<<Tree::Hasher as Hasher>::Domain>,

    // one proof per challenge
    proofs: Vec<Proof<Tree, G>>,
}

impl<'a, Tree: MerkleTreeTrait, G: Hasher> CircuitComponent for StackedCircuit<'a, Tree, G> {
    type ComponentPrivateInputs = ();
}

impl<'a, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher> StackedCircuit<'a, Tree, G> {
    #[allow(clippy::too_many_arguments)]
    pub fn synthesize<CS>(
        mut cs: CS,
        public_params: <StackedDrg<'a, Tree, G> as ProofScheme<'a>>::PublicParams,
        replica_id: Option<<Tree::Hasher as Hasher>::Domain>,
        comm_d: Option<G::Domain>,
        comm_r: Option<<Tree::Hasher as Hasher>::Domain>,
        comm_r_last: Option<<Tree::Hasher as Hasher>::Domain>,
        comm_c: Option<<Tree::Hasher as Hasher>::Domain>,
        proofs: Vec<Proof<Tree, G>>,
    ) -> Result<(), SynthesisError>
    where
        CS: ConstraintSystem<Bls12>,
    {
        let circuit = StackedCircuit::<'a, Tree, G> {
            public_params,
            replica_id,
            comm_d,
            comm_r,
            comm_r_last,
            comm_c,
            proofs,
        };

        circuit.synthesize(&mut cs)
    }
}

impl<'a, Tree: MerkleTreeTrait, G: Hasher> Circuit<Bls12> for StackedCircuit<'a, Tree, G> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let StackedCircuit {
            public_params,
            proofs,
            replica_id,
            comm_r,
            comm_d,
            comm_r_last,
            comm_c,
            ..
        } = self;

        // Allocate replica_id
        let replica_id_num = num::AllocatedNum::alloc(cs.namespace(|| "replica_id"), || {
            replica_id
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // make replica_id a public input
        replica_id_num.inputize(cs.namespace(|| "replica_id_input"))?;

        let replica_id_bits =
            reverse_bit_numbering(replica_id_num.to_bits_le(cs.namespace(|| "replica_id_bits"))?);

        // Allocate comm_d as Fr
        let comm_d_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_d"), || {
            comm_d
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // make comm_d a public input
        comm_d_num.inputize(cs.namespace(|| "comm_d_input"))?;

        // Allocate comm_r as Fr
        let comm_r_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r"), || {
            comm_r
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // make comm_r a public input
        comm_r_num.inputize(cs.namespace(|| "comm_r_input"))?;

        // Allocate comm_r_last as Fr
        let comm_r_last_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r_last"), || {
            comm_r_last
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // Allocate comm_c as Fr
        let comm_c_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_c"), || {
            comm_c
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // Verify comm_r = H(comm_c || comm_r_last)
        {
            let hash_num = <Tree::Hasher as Hasher>::Function::hash2_circuit(
                cs.namespace(|| "H_comm_c_comm_r_last"),
                &comm_c_num,
                &comm_r_last_num,
            )?;

            // Check actual equality
            constraint::equal(
                cs,
                || "enforce comm_r = H(comm_c || comm_r_last)",
                &comm_r_num,
                &hash_num,
            );
        }

        for (i, proof) in proofs.into_iter().enumerate() {
            proof.synthesize(
                &mut cs.namespace(|| format!("challenge_{}", i)),
                public_params.layer_challenges.layers(),
                &comm_d_num,
                &comm_c_num,
                &comm_r_last_num,
                &replica_id_bits,
            )?;
        }

        Ok(())
    }
}

#[allow(dead_code)]
pub struct StackedCompound<Tree: MerkleTreeTrait, G: Hasher> {
    partitions: Option<usize>,
    _t: PhantomData<Tree>,
    _g: PhantomData<G>,
}

impl<C: Circuit<Bls12>, P: ParameterSetMetadata, Tree: MerkleTreeTrait, G: Hasher>
    CacheableParameters<C, P> for StackedCompound<Tree, G>
{
    fn cache_prefix() -> String {
        format!(
            "stacked-proof-of-replication-{}-{}",
            Tree::display(),
            G::name()
        )
    }
}

impl<'a, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher>
    CompoundProof<'a, StackedDrg<'a, Tree, G>, StackedCircuit<'a, Tree, G>>
    for StackedCompound<Tree, G>
{
    fn generate_public_inputs(
        pub_in: &<StackedDrg<Tree, G> as ProofScheme>::PublicInputs,
        pub_params: &<StackedDrg<Tree, G> as ProofScheme>::PublicParams,
        k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let graph = &pub_params.graph;

        let mut inputs = Vec::new();

        let replica_id = pub_in.replica_id;
        inputs.push(replica_id.into());

        let comm_d = pub_in.tau.as_ref().expect("missing tau").comm_d;
        inputs.push(comm_d.into());

        let comm_r = pub_in.tau.as_ref().expect("missing tau").comm_r;
        inputs.push(comm_r.into());

        let por_setup_params = por::SetupParams {
            leaves: graph.size(),
            private: true,
        };

        let por_params = por::PoR::<Tree>::setup(&por_setup_params)?;
        let por_params_d = por::PoR::<BinaryMerkleTree<G>>::setup(&por_setup_params)?;

        let all_challenges = pub_in.challenges(&pub_params.layer_challenges, graph.size(), k);

        for challenge in all_challenges.into_iter() {
            // comm_d inclusion proof for the data leaf
            inputs.extend(generate_inclusion_inputs::<BinaryMerkleTree<G>>(
                &por_params_d,
                challenge,
                k,
            )?);

            // drg parents
            let mut drg_parents = vec![0; graph.base_graph().degree()];
            graph.base_graph().parents(challenge, &mut drg_parents)?;

            // Inclusion Proofs: drg parent node in comm_c
            for parent in drg_parents.into_iter() {
                inputs.extend(generate_inclusion_inputs::<Tree>(
                    &por_params,
                    parent as usize,
                    k,
                )?);
            }

            // exp parents
            let mut exp_parents = vec![0; graph.expansion_degree()];
            graph.expanded_parents(challenge, &mut exp_parents);

            // Inclusion Proofs: expander parent node in comm_c
            for parent in exp_parents.into_iter() {
                inputs.extend(generate_inclusion_inputs::<Tree>(
                    &por_params,
                    parent as usize,
                    k,
                )?);
            }

            inputs.push(u64_into_fr(challenge as u64));

            // Inclusion Proof: encoded node in comm_r_last
            inputs.extend(generate_inclusion_inputs::<Tree>(
                &por_params,
                challenge,
                k,
            )?);

            // Inclusion Proof: column hash of the challenged node in comm_c
            inputs.extend(generate_inclusion_inputs::<Tree>(
                &por_params,
                challenge,
                k,
            )?);
        }

        Ok(inputs)
    }

    fn circuit<'b>(
        public_inputs: &'b <StackedDrg<Tree, G> as ProofScheme>::PublicInputs,
        _component_private_inputs: <StackedCircuit<'a, Tree, G> as CircuitComponent>::ComponentPrivateInputs,
        vanilla_proof: &'b <StackedDrg<Tree, G> as ProofScheme>::Proof,
        public_params: &'b <StackedDrg<Tree, G> as ProofScheme>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<StackedCircuit<'a, Tree, G>> {
        ensure!(
            !vanilla_proof.is_empty(),
            "Cannot create a circuit with no vanilla proofs"
        );

        let comm_r_last = vanilla_proof[0].comm_r_last();
        let comm_c = vanilla_proof[0].comm_c();

        // ensure consistency
        ensure!(
            vanilla_proof.iter().all(|p| p.comm_r_last() == comm_r_last),
            "inconsistent comm_r_lasts"
        );
        ensure!(
            vanilla_proof.iter().all(|p| p.comm_c() == comm_c),
            "inconsistent comm_cs"
        );

        Ok(StackedCircuit {
            public_params: public_params.clone(),
            replica_id: Some(public_inputs.replica_id),
            comm_d: public_inputs.tau.as_ref().map(|t| t.comm_d),
            comm_r: public_inputs.tau.as_ref().map(|t| t.comm_r),
            comm_r_last: Some(comm_r_last),
            comm_c: Some(comm_c),
            proofs: vanilla_proof.iter().cloned().map(|p| p.into()).collect(),
        })
    }

    fn blank_circuit(
        public_params: &<StackedDrg<Tree, G> as ProofScheme>::PublicParams,
    ) -> StackedCircuit<'a, Tree, G> {
        StackedCircuit {
            public_params: public_params.clone(),
            replica_id: None,
            comm_d: None,
            comm_r: None,
            comm_r_last: None,
            comm_c: None,
            proofs: (0..public_params.layer_challenges.challenges_count_all())
                .map(|_challenge_index| Proof::empty(public_params))
                .collect(),
        }
    }
}

/// Helper to generate public inputs for inclusion proofs.
fn generate_inclusion_inputs<Tree: 'static + MerkleTreeTrait>(
    por_params: &por::PublicParams,
    challenge: usize,
    k: Option<usize>,
) -> Result<Vec<Fr>> {
    let pub_inputs = por::PublicInputs::<<Tree::Hasher as Hasher>::Domain> {
        challenge,
        commitment: None,
    };

    PoRCompound::<Tree>::generate_public_inputs(&pub_inputs, por_params, k)
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use generic_array::typenum::{U0, U2, U4, U8};
    use merkletree::store::StoreConfig;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        cache_key::CacheKey,
        compound_proof,
        drgraph::{new_seed, BASE_DEGREE},
        fr32::fr_into_bytes,
        gadgets::{MetricCS, TestConstraintSystem},
        hasher::{Hasher, PedersenHasher, PoseidonHasher, Sha256Hasher},
        merkle::{get_base_tree_count, BinaryMerkleTree, DiskTree, MerkleTreeTrait},
        proof::ProofScheme,
        test_helper::setup_replica,
    };

    use crate::stacked::{
        ChallengeRequirements, LayerChallenges, PrivateInputs, PublicInputs, SetupParams,
        TemporaryAux, TemporaryAuxCache, BINARY_ARITY, EXP_DEGREE,
    };
    use crate::PoRep;

    #[test]
    fn stacked_input_circuit_pedersen_base_2() {
        stacked_input_circuit::<DiskTree<PedersenHasher, U2, U0, U0>>(22, 1_258_197);
    }

    #[test]
    fn stacked_input_circuit_poseidon_base_2() {
        stacked_input_circuit::<DiskTree<PoseidonHasher, U2, U0, U0>>(22, 1_206_404);
    }

    #[test]
    fn stacked_input_circuit_poseidon_base_8() {
        stacked_input_circuit::<DiskTree<PoseidonHasher, U8, U0, U0>>(22, 1_199_716);
    }

    #[test]
    fn stacked_input_circuit_poseidon_sub_8_4() {
        stacked_input_circuit::<DiskTree<PoseidonHasher, U8, U4, U0>>(22, 1_296_720);
    }

    #[test]
    fn stacked_input_circuit_poseidon_top_8_4_2() {
        stacked_input_circuit::<DiskTree<PoseidonHasher, U8, U4, U2>>(22, 1_347_174);
    }

    fn stacked_input_circuit<Tree: MerkleTreeTrait + 'static>(
        expected_inputs: usize,
        expected_constraints: usize,
    ) {
        let nodes = 8 * get_base_tree_count::<Tree>();
        let degree = BASE_DEGREE;
        let expansion_degree = EXP_DEGREE;
        let num_layers = 2;
        let layer_challenges = LayerChallenges::new(num_layers, 1);

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let replica_id: Fr = Fr::random(rng);
        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let sp = SetupParams {
            nodes,
            degree,
            expansion_degree,
            seed: new_seed(),
            layer_challenges: layer_challenges.clone(),
        };

        let pp = StackedDrg::<Tree, Sha256Hasher>::setup(&sp).expect("setup failed");
        let (tau, (p_aux, t_aux)) = StackedDrg::<Tree, Sha256Hasher>::replicate(
            &pp,
            &replica_id.into(),
            (mmapped_data.as_mut()).into(),
            None,
            config,
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        let seed = rng.gen();

        let pub_inputs =
            PublicInputs::<<Tree::Hasher as Hasher>::Domain, <Sha256Hasher as Hasher>::Domain> {
                replica_id: replica_id.into(),
                seed,
                tau: Some(tau.into()),
                k: None,
            };

        // Store copy of original t_aux for later resource deletion.
        let t_aux_orig = t_aux.clone();

        // Convert TemporaryAux to TemporaryAuxCache, which instantiates all
        // elements based on the configs stored in TemporaryAux.
        let t_aux = TemporaryAuxCache::<Tree, Sha256Hasher>::new(&t_aux, replica_path.clone())
            .expect("failed to restore contents of t_aux");

        let priv_inputs = PrivateInputs::<Tree, Sha256Hasher> {
            p_aux: p_aux.into(),
            t_aux: t_aux.into(),
        };

        let proofs = StackedDrg::<Tree, Sha256Hasher>::prove_all_partitions(
            &pp,
            &pub_inputs,
            &priv_inputs,
            1,
        )
        .expect("failed to generate partition proofs");

        let proofs_are_valid =
            StackedDrg::<Tree, Sha256Hasher>::verify_all_partitions(&pp, &pub_inputs, &proofs)
                .expect("failed while trying to verify partition proofs");

        assert!(proofs_are_valid);

        // Discard cached MTs that are no longer needed.
        TemporaryAux::<Tree, Sha256Hasher>::clear_temp(t_aux_orig).expect("t_aux delete failed");

        {
            // Verify that MetricCS returns the same metrics as TestConstraintSystem.
            let mut cs = MetricCS::<Bls12>::new();

            StackedCompound::<Tree, Sha256Hasher>::circuit(
                &pub_inputs,
                <StackedCircuit<Tree, Sha256Hasher> as CircuitComponent>::ComponentPrivateInputs::default(),
                &proofs[0],
                &pp,
                None,
            )
            .expect("circuit failed")
            .synthesize(&mut cs.namespace(|| "stacked drgporep"))
            .expect("failed to synthesize circuit");

            assert_eq!(cs.num_inputs(), expected_inputs, "wrong number of inputs");
            assert_eq!(
                cs.num_constraints(),
                expected_constraints,
                "wrong number of constraints"
            );
        }
        let mut cs = TestConstraintSystem::<Bls12>::new();

        StackedCompound::<Tree, Sha256Hasher>::circuit(
            &pub_inputs,
            <StackedCircuit<Tree, Sha256Hasher> as CircuitComponent>::ComponentPrivateInputs::default(),
            &proofs[0],
            &pp,
            None,
        )
        .expect("circuit failed")
        .synthesize(&mut cs.namespace(|| "stacked drgporep"))
        .expect("failed to synthesize circuit");

        assert!(cs.is_satisfied(), "constraints not satisfied");
        assert_eq!(cs.num_inputs(), expected_inputs, "wrong number of inputs");
        assert_eq!(
            cs.num_constraints(),
            expected_constraints,
            "wrong number of constraints"
        );

        assert_eq!(cs.get_input(0, "ONE"), Fr::one());

        let generated_inputs = <StackedCompound<Tree, Sha256Hasher> as CompoundProof<
            StackedDrg<Tree, Sha256Hasher>,
            _,
        >>::generate_public_inputs(&pub_inputs, &pp, None)
        .expect("failed to generate public inputs");
        let expected_inputs = cs.get_inputs();

        for ((input, label), generated_input) in
            expected_inputs.iter().skip(1).zip(generated_inputs.iter())
        {
            assert_eq!(input, generated_input, "{}", label);
        }

        assert_eq!(
            generated_inputs.len(),
            expected_inputs.len() - 1,
            "inputs are not the same length"
        );

        cache_dir.close().expect("Failed to remove cache dir");
    }

    #[test]
    #[ignore]
    fn test_stacked_compound_pedersen() {
        stacked_test_compound::<BinaryMerkleTree<PedersenHasher>>();
    }

    #[test]
    #[ignore]
    fn test_stacked_compound_poseidon_base_8() {
        stacked_test_compound::<DiskTree<PoseidonHasher, U8, U0, U0>>();
    }

    #[test]
    #[ignore]
    fn test_stacked_compound_poseidon_sub_8_4() {
        stacked_test_compound::<DiskTree<PoseidonHasher, U8, U4, U0>>();
    }

    #[test]
    #[ignore]
    fn test_stacked_compound_poseidon_top_8_4_2() {
        stacked_test_compound::<DiskTree<PoseidonHasher, U8, U4, U2>>();
    }

    fn stacked_test_compound<Tree: 'static + MerkleTreeTrait>() {
        let nodes = 8 * get_base_tree_count::<Tree>();

        let degree = BASE_DEGREE;
        let expansion_degree = EXP_DEGREE;
        let num_layers = 2;
        let layer_challenges = LayerChallenges::new(num_layers, 1);
        let partition_count = 1;

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let replica_id: Fr = Fr::random(rng);
        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        let setup_params = compound_proof::SetupParams {
            vanilla_params: SetupParams {
                nodes,
                degree,
                expansion_degree,
                seed: new_seed(),
                layer_challenges: layer_challenges.clone(),
            },
            partitions: Some(partition_count),
            priority: false,
        };

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");

        // create a copy, so we can compare roundtrips
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let public_params = StackedCompound::setup(&setup_params).expect("setup failed");
        let (tau, (p_aux, t_aux)) = StackedDrg::<Tree, _>::replicate(
            &public_params.vanilla_params,
            &replica_id.into(),
            (mmapped_data.as_mut()).into(),
            None,
            config,
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        let seed = rng.gen();

        let public_inputs =
            PublicInputs::<<Tree::Hasher as Hasher>::Domain, <Sha256Hasher as Hasher>::Domain> {
                replica_id: replica_id.into(),
                seed,
                tau: Some(tau),
                k: None,
            };

        // Store a copy of the t_aux for later resource deletion.
        let t_aux_orig = t_aux.clone();

        // Convert TemporaryAux to TemporaryAuxCache, which instantiates all
        // elements based on the configs stored in TemporaryAux.
        let t_aux = TemporaryAuxCache::<Tree, _>::new(&t_aux, replica_path.clone())
            .expect("failed to restore contents of t_aux");

        let private_inputs = PrivateInputs::<Tree, Sha256Hasher> { p_aux, t_aux };

        {
            let (circuit, inputs) =
                StackedCompound::circuit_for_test(&public_params, &public_inputs, &private_inputs)
                    .unwrap();

            let mut cs = TestConstraintSystem::new();

            circuit.synthesize(&mut cs).expect("failed to synthesize");

            if !cs.is_satisfied() {
                panic!(
                    "failed to satisfy: {:?}",
                    cs.which_is_unsatisfied().unwrap()
                );
            }
            assert!(
                cs.verify(&inputs),
                "verification failed with TestContraintSystem and generated inputs"
            );
        }

        // Use this to debug differences between blank and regular circuit generation.
        {
            let (circuit1, _inputs) =
                StackedCompound::circuit_for_test(&public_params, &public_inputs, &private_inputs)
                    .unwrap();
            let blank_circuit = <StackedCompound<Tree, Sha256Hasher> as CompoundProof<
                StackedDrg<Tree, Sha256Hasher>,
                _,
            >>::blank_circuit(&public_params.vanilla_params);

            let mut cs_blank = MetricCS::new();
            blank_circuit
                .synthesize(&mut cs_blank)
                .expect("failed to synthesize");

            let a = cs_blank.pretty_print_list();

            let mut cs1 = TestConstraintSystem::new();
            circuit1.synthesize(&mut cs1).expect("failed to synthesize");
            let b = cs1.pretty_print_list();

            for (i, (a, b)) in a.chunks(100).zip(b.chunks(100)).enumerate() {
                assert_eq!(a, b, "failed at chunk {}", i);
            }
        }

        let blank_groth_params = <StackedCompound<Tree, Sha256Hasher> as CompoundProof<
            StackedDrg<Tree, Sha256Hasher>,
            _,
        >>::groth_params(Some(rng), &public_params.vanilla_params)
        .expect("failed to generate groth params");

        // Discard cached MTs that are no longer needed.
        TemporaryAux::<Tree, Sha256Hasher>::clear_temp(t_aux_orig).expect("t_aux delete failed");

        let proof = StackedCompound::prove(
            &public_params,
            &public_inputs,
            &private_inputs,
            &blank_groth_params,
        )
        .expect("failed while proving");

        let verified = StackedCompound::verify(
            &public_params,
            &public_inputs,
            &proof,
            &ChallengeRequirements {
                minimum_challenges: 1,
            },
        )
        .expect("failed while verifying");

        assert!(verified);

        cache_dir.close().expect("Failed to remove cache dir");
    }
}

'''
'''--- storage-proofs/porep/src/stacked/mod.rs ---
mod circuit;
mod vanilla;

pub use self::circuit::*;
pub use self::vanilla::*;

'''
'''--- storage-proofs/porep/src/stacked/vanilla/challenges.rs ---
use num_bigint::BigUint;
use num_traits::cast::ToPrimitive;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

use storage_proofs_core::hasher::Domain;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LayerChallenges {
    /// How many layers we are generating challenges for.
    layers: usize,
    /// The maximum count of challenges
    max_count: usize,
}

impl LayerChallenges {
    pub const fn new(layers: usize, max_count: usize) -> Self {
        LayerChallenges { layers, max_count }
    }

    pub fn layers(&self) -> usize {
        self.layers
    }

    pub fn challenges_count_all(&self) -> usize {
        self.max_count
    }

    /// Derive all challenges.
    pub fn derive<D: Domain>(
        &self,
        leaves: usize,
        replica_id: &D,
        seed: &[u8; 32],
        k: u8,
    ) -> Vec<usize> {
        self.derive_internal(self.challenges_count_all(), leaves, replica_id, seed, k)
    }

    pub fn derive_internal<D: Domain>(
        &self,
        challenges_count: usize,
        leaves: usize,
        replica_id: &D,
        seed: &[u8; 32],
        k: u8,
    ) -> Vec<usize> {
        assert!(leaves > 2, "Too few leaves: {}", leaves);

        (0..challenges_count)
            .map(|i| {
                let j: u32 = ((challenges_count * k as usize) + i) as u32;

                let hash = Sha256::new()
                    .chain(replica_id.into_bytes())
                    .chain(seed)
                    .chain(&j.to_le_bytes())
                    .result();

                let big_challenge = BigUint::from_bytes_le(hash.as_ref());

                // We cannot try to prove the first node, so make sure the challenge
                // can never be 0.
                let big_mod_challenge = big_challenge % (leaves - 1);
                let big_mod_challenge = big_mod_challenge
                    .to_usize()
                    .expect("`big_mod_challenge` exceeds size of `usize`");
                big_mod_challenge + 1
            })
            .collect()
    }
}

#[derive(Debug, Default)]
pub struct ChallengeRequirements {
    pub minimum_challenges: usize,
}

#[cfg(test)]
mod test {
    use super::*;

    use rand::{thread_rng, Rng};
    use std::collections::HashMap;
    use storage_proofs_core::hasher::pedersen::PedersenDomain;

    #[test]
    fn challenge_derivation() {
        let n = 200;
        let layers = 100;

        let challenges = LayerChallenges::new(layers, n);
        let leaves = 1 << 30;
        let rng = &mut thread_rng();
        let replica_id: PedersenDomain = PedersenDomain::random(rng);
        let seed: [u8; 32] = rng.gen();
        let partitions = 5;
        let total_challenges = partitions * n;

        let mut layers_with_duplicates = 0;

        for _layer in 1..=layers {
            let mut histogram = HashMap::new();
            for k in 0..partitions {
                let challenges = challenges.derive(leaves, &replica_id, &seed, k as u8);

                for challenge in challenges {
                    let counter = histogram.entry(challenge).or_insert(0);
                    *counter += 1;
                }
            }
            let unique_challenges = histogram.len();
            if unique_challenges < total_challenges {
                layers_with_duplicates += 1;
            }
        }

        // If we generate 100 layers with 1,000 challenges in each, at most two layers can contain
        // any duplicates for this assertion to succeed.
        //
        // This test could randomly fail (anything's possible), but if it happens regularly something is wrong.
        assert!(layers_with_duplicates < 3);
    }

    #[test]
    // This test shows that partitioning (k = 0..partitions) generates the same challenges as
    // generating the same number of challenges with only one partition (k = 0).
    fn challenge_partition_equivalence() {
        let n = 40;
        let leaves = 1 << 30;
        let rng = &mut thread_rng();
        let replica_id: PedersenDomain = PedersenDomain::random(rng);
        let seed: [u8; 32] = rng.gen();
        let partitions = 5;
        let layers = 100;
        let total_challenges = n * partitions;

        for _layer in 1..=layers {
            let one_partition_challenges = LayerChallenges::new(layers, total_challenges).derive(
                leaves,
                &replica_id,
                &seed,
                0,
            );
            let many_partition_challenges = (0..partitions)
                .flat_map(|k| {
                    LayerChallenges::new(layers, n).derive(leaves, &replica_id, &seed, k as u8)
                })
                .collect::<Vec<_>>();

            assert_eq!(one_partition_challenges, many_partition_challenges);
        }
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/column.rs ---
use std::marker::PhantomData;

use paired::bls12_381::Fr;
use serde::{Deserialize, Serialize};
use storage_proofs_core::{
    error::Result,
    hasher::Hasher,
    merkle::{MerkleTreeTrait, Store},
};

use super::{column_proof::ColumnProof, hash::hash_single_column};

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
pub struct Column<H: Hasher> {
    pub(crate) index: u32,
    pub(crate) rows: Vec<H::Domain>,
    _h: PhantomData<H>,
}

impl<H: Hasher> Column<H> {
    pub fn new(index: u32, rows: Vec<H::Domain>) -> Result<Self> {
        Ok(Column {
            index,
            rows,
            _h: PhantomData,
        })
    }

    pub fn with_capacity(index: u32, capacity: usize) -> Result<Self> {
        Column::new(index, Vec::with_capacity(capacity))
    }

    pub fn rows(&self) -> &[H::Domain] {
        &self.rows
    }

    pub fn index(&self) -> u32 {
        self.index
    }

    /// Calculate the column hashes `C_i = H(E_i, O_i)` for the passed in column.
    pub fn hash(&self) -> Fr {
        hash_single_column(
            &self
                .rows
                .iter()
                .copied()
                .map(Into::into)
                .collect::<Vec<_>>(),
        )
    }

    pub fn get_node_at_layer(&self, layer: usize) -> Result<&H::Domain> {
        assert!(layer > 0, "layer must be greater than 0");
        let row_index = layer - 1;

        Ok(&self.rows[row_index])
    }

    /// Create a column proof for this column.
    pub fn into_proof<S: Store<H::Domain>, Tree: MerkleTreeTrait<Hasher = H, Store = S>>(
        self,
        tree_c: &Tree,
    ) -> Result<ColumnProof<Tree::Proof>> {
        let inclusion_proof = tree_c.gen_proof(self.index() as usize)?;
        ColumnProof::<Tree::Proof>::from_column(self, inclusion_proof)
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/column_proof.rs ---
use log::trace;
use paired::bls12_381::Fr;
use serde::{Deserialize, Serialize};
use storage_proofs_core::{error::Result, hasher::Hasher, merkle::MerkleProofTrait};

use super::column::Column;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ColumnProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "Column<Proof::Hasher>: Serialize",
        deserialize = "Column<Proof::Hasher>: Deserialize<'de>"
    ))]
    pub(crate) column: Column<Proof::Hasher>,
    #[serde(bound(
        serialize = "Proof: Serialize",
        deserialize = "Proof: serde::de::DeserializeOwned"
    ))]
    pub(crate) inclusion_proof: Proof,
}

impl<Proof: MerkleProofTrait> ColumnProof<Proof> {
    pub fn from_column(column: Column<Proof::Hasher>, inclusion_proof: Proof) -> Result<Self> {
        Ok(ColumnProof {
            column,
            inclusion_proof,
        })
    }

    pub fn root(&self) -> <Proof::Hasher as Hasher>::Domain {
        self.inclusion_proof.root()
    }

    fn column(&self) -> &Column<Proof::Hasher> {
        &self.column
    }

    pub fn get_node_at_layer(&self, layer: usize) -> Result<&<Proof::Hasher as Hasher>::Domain> {
        self.column().get_node_at_layer(layer)
    }

    pub fn column_hash(&self) -> Fr {
        self.column.hash()
    }

    pub fn verify(
        &self,
        challenge: u32,
        expected_root: &<Proof::Hasher as Hasher>::Domain,
    ) -> bool {
        let c_i = self.column_hash();

        check_eq!(&self.inclusion_proof.root(), expected_root);
        check!(self.inclusion_proof.validate_data(c_i.into()));
        check!(self.inclusion_proof.validate(challenge as usize));

        true
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/create_label.rs ---
#[cfg(target_arch = "x86")]
use std::arch::x86::*;
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

use sha2raw::Sha256;
use storage_proofs_core::{
    error::Result,
    hasher::Hasher,
    util::{data_at_node_offset, NODE_SIZE},
};

use super::graph::StackedBucketGraph;

pub fn create_label<H: Hasher>(
    graph: &StackedBucketGraph<H>,
    replica_id: &H::Domain,
    layer_labels: &mut [u8],
    layer_index: usize,
    node: usize,
) -> Result<()> {
    let mut hasher = Sha256::new();
    let mut buffer = [0u8; 32];

    buffer[..4].copy_from_slice(&(layer_index as u32).to_be_bytes());
    buffer[4..12].copy_from_slice(&(node as u64).to_be_bytes());
    hasher.input(&[AsRef::<[u8]>::as_ref(replica_id), &buffer[..]][..]);

    // hash parents for all non 0 nodes
    let hash = if node > 0 {
        // prefetch previous node, which is always a parent
        let prev = &layer_labels[(node - 1) * NODE_SIZE..node * NODE_SIZE];
        unsafe {
            _mm_prefetch(prev.as_ptr() as *const i8, _MM_HINT_T0);
        }

        graph.copy_parents_data(node as u32, &*layer_labels, hasher)
    } else {
        hasher.finish()
    };

    // store the newly generated key
    let start = data_at_node_offset(node);
    let end = start + NODE_SIZE;
    layer_labels[start..end].copy_from_slice(&hash[..]);

    // strip last two bits, to ensure result is in Fr.
    layer_labels[end - 1] &= 0b0011_1111;

    Ok(())
}

pub fn create_label_exp<H: Hasher>(
    graph: &StackedBucketGraph<H>,
    replica_id: &H::Domain,
    exp_parents_data: &[u8],
    layer_labels: &mut [u8],
    layer_index: usize,
    node: usize,
) -> Result<()> {
    let mut hasher = Sha256::new();
    let mut buffer = [0u8; 32];

    buffer[0..4].copy_from_slice(&(layer_index as u32).to_be_bytes());
    buffer[4..12].copy_from_slice(&(node as u64).to_be_bytes());
    hasher.input(&[AsRef::<[u8]>::as_ref(replica_id), &buffer[..]][..]);

    // hash parents for all non 0 nodes
    let hash = if node > 0 {
        // prefetch previous node, which is always a parent
        let prev = &layer_labels[(node - 1) * NODE_SIZE..node * NODE_SIZE];
        unsafe {
            _mm_prefetch(prev.as_ptr() as *const i8, _MM_HINT_T0);
        }

        graph.copy_parents_data_exp(node as u32, &*layer_labels, exp_parents_data, hasher)
    } else {
        hasher.finish()
    };

    // store the newly generated key
    let start = data_at_node_offset(node);
    let end = start + NODE_SIZE;
    layer_labels[start..end].copy_from_slice(&hash[..]);

    // strip last two bits, to ensure result is in Fr.
    layer_labels[end - 1] &= 0b0011_1111;

    Ok(())
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/encoding_proof.rs ---
use log::trace;
use std::marker::PhantomData;

use paired::bls12_381::Fr;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use storage_proofs_core::{fr32::bytes_into_fr_repr_safe, hasher::Hasher};

use crate::encode::encode;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EncodingProof<H: Hasher> {
    pub(crate) parents: Vec<H::Domain>,
    pub(crate) layer_index: u32,
    pub(crate) node: u64,
    #[serde(skip)]
    _h: PhantomData<H>,
}

impl<H: Hasher> EncodingProof<H> {
    pub fn new(layer_index: u32, node: u64, parents: Vec<H::Domain>) -> Self {
        EncodingProof {
            layer_index,
            node,
            parents,
            _h: PhantomData,
        }
    }

    fn create_key(&self, replica_id: &H::Domain) -> H::Domain {
        let mut hasher = Sha256::new();
        let mut buffer = [0u8; 64];

        // replica_id
        buffer[..32].copy_from_slice(AsRef::<[u8]>::as_ref(replica_id));

        // layer index
        buffer[32..36].copy_from_slice(&(self.layer_index as u32).to_be_bytes());
        // node id
        buffer[36..44].copy_from_slice(&(self.node as u64).to_be_bytes());

        hasher.input(&buffer[..]);

        // parents
        for parent in &self.parents {
            hasher.input(AsRef::<[u8]>::as_ref(parent));
        }

        bytes_into_fr_repr_safe(hasher.result().as_ref()).into()
    }

    pub fn verify<G: Hasher>(
        &self,
        replica_id: &H::Domain,
        exp_encoded_node: &H::Domain,
        decoded_node: &G::Domain,
    ) -> bool {
        let key = self.create_key(replica_id);

        let fr: Fr = (*decoded_node).into();
        let encoded_node = encode(key, fr.into());

        check_eq!(exp_encoded_node, &encoded_node);

        true
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/graph.rs ---
use std::marker::PhantomData;

#[cfg(target_arch = "x86")]
use std::arch::x86::*;
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

use anyhow::ensure;
use log::info;
use once_cell::sync::OnceCell;
use rayon::prelude::*;
use sha2raw::Sha256;
use storage_proofs_core::{
    crypto::feistel::{self, FeistelPrecomputed},
    drgraph::BASE_DEGREE,
    drgraph::{BucketGraph, Graph},
    error::Result,
    hasher::Hasher,
    parameter_cache::ParameterSetMetadata,
    settings,
    util::NODE_SIZE,
};

/// The expansion degree used for Stacked Graphs.
pub const EXP_DEGREE: usize = 8;
const FEISTEL_KEYS: [feistel::Index; 4] = [1, 2, 3, 4];

const DEGREE: usize = BASE_DEGREE + EXP_DEGREE;

/// Returns a reference to the parent cache, initializing it lazily the first time this is called.
fn parent_cache<H, G>(
    cache_entries: u32,
    graph: &StackedGraph<H, G>,
) -> Result<&'static ParentCache>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata + Send + Sync,
{
    static INSTANCE_32_GIB: OnceCell<ParentCache> = OnceCell::new();
    static INSTANCE_64_GIB: OnceCell<ParentCache> = OnceCell::new();

    const NODE_GIB: u32 = (1024 * 1024 * 1024) / NODE_SIZE as u32;
    ensure!(
        ((cache_entries == 32 * NODE_GIB) || (cache_entries == 64 * NODE_GIB)),
        "Cache is only available for 32GiB and 64GiB sectors"
    );
    info!("using parent_cache[{}]", cache_entries);
    if cache_entries == 32 * NODE_GIB {
        Ok(INSTANCE_32_GIB.get_or_init(|| {
            ParentCache::new(cache_entries, graph).expect("failed to fill 32GiB cache")
        }))
    } else {
        Ok(INSTANCE_64_GIB.get_or_init(|| {
            ParentCache::new(cache_entries, graph).expect("failed to fill 64GiB cache")
        }))
    }
}

// StackedGraph will hold two different (but related) `ParentCache`,
#[derive(Debug, Clone)]
struct ParentCache {
    /// This is a large list of fixed (parent) sized arrays.
    /// `Vec<Vec<u32>>` was showing quite a large memory overhead, so this is layed out as a fixed boxed slice of memory.
    cache: Box<[u32]>,
}

impl ParentCache {
    pub fn new<H, G>(cache_entries: u32, graph: &StackedGraph<H, G>) -> Result<Self>
    where
        H: Hasher,
        G: Graph<H> + ParameterSetMetadata + Send + Sync,
    {
        info!("filling parents cache");
        let mut cache = vec![0u32; DEGREE * cache_entries as usize];

        let base_degree = BASE_DEGREE;
        let exp_degree = EXP_DEGREE;

        cache
            .par_chunks_mut(DEGREE)
            .enumerate()
            .try_for_each(|(node, entry)| -> Result<()> {
                graph
                    .base_graph()
                    .parents(node, &mut entry[..base_degree])?;
                graph.generate_expanded_parents(
                    node,
                    &mut entry[base_degree..base_degree + exp_degree],
                );
                Ok(())
            })?;

        info!("cache filled");

        Ok(ParentCache {
            cache: cache.into_boxed_slice(),
        })
    }

    /// Read a single cache element at position `node`.
    #[inline]
    pub fn read(&self, node: u32) -> &[u32] {
        let start = node as usize * DEGREE;
        let end = start + DEGREE;
        &self.cache[start..end]
    }
}

#[derive(Clone)]
pub struct StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + 'static,
{
    expansion_degree: usize,
    base_graph: G,
    feistel_precomputed: FeistelPrecomputed,
    id: String,
    cache: Option<&'static ParentCache>,
    _h: PhantomData<H>,
}

impl<H, G> std::fmt::Debug for StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + 'static,
{
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("StackedGraph")
            .field("expansion_degree", &self.expansion_degree)
            .field("base_graph", &self.base_graph)
            .field("feistel_precomputed", &self.feistel_precomputed)
            .field("id", &self.id)
            .field("cache", &self.cache)
            .finish()
    }
}

pub type StackedBucketGraph<H> = StackedGraph<H, BucketGraph<H>>;

#[inline]
fn prefetch(parents: &[u32], data: &[u8]) {
    for parent in parents {
        let start = *parent as usize * NODE_SIZE;
        let end = start + NODE_SIZE;

        unsafe {
            _mm_prefetch(data[start..end].as_ptr() as *const i8, _MM_HINT_T0);
        }
    }
}

#[inline]
fn read_node<'a>(i: usize, parents: &[u32], data: &'a [u8]) -> &'a [u8] {
    let start = parents[i] as usize * NODE_SIZE;
    let end = start + NODE_SIZE;
    &data[start..end]
}

impl<H, G> StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata + Sync + Send,
{
    pub fn new(
        base_graph: Option<G>,
        nodes: usize,
        base_degree: usize,
        expansion_degree: usize,
        seed: [u8; 28],
    ) -> Result<Self> {
        assert_eq!(base_degree, BASE_DEGREE);
        assert_eq!(expansion_degree, EXP_DEGREE);
        ensure!(nodes <= std::u32::MAX as usize, "too many nodes");

        let use_cache = settings::SETTINGS.lock().unwrap().maximize_caching;

        let base_graph = match base_graph {
            Some(graph) => graph,
            None => G::new(nodes, base_degree, 0, seed)?,
        };
        let bg_id = base_graph.identifier();

        let mut res = StackedGraph {
            base_graph,
            id: format!(
                "stacked_graph::StackedGraph{{expansion_degree: {} base_graph: {} }}",
                expansion_degree, bg_id,
            ),
            expansion_degree,
            cache: None,
            feistel_precomputed: feistel::precompute((expansion_degree * nodes) as feistel::Index),
            _h: PhantomData,
        };

        if use_cache {
            info!("using parents cache of unlimited size");

            let cache = parent_cache(nodes as u32, &res)?;
            res.cache = Some(cache);
        }

        Ok(res)
    }

    pub fn copy_parents_data_exp(
        &self,
        node: u32,
        base_data: &[u8],
        exp_data: &[u8],
        hasher: Sha256,
    ) -> [u8; 32] {
        if let Some(cache) = self.cache {
            let cache_parents = cache.read(node as u32);
            self.copy_parents_data_inner_exp(&cache_parents, base_data, exp_data, hasher)
        } else {
            let mut cache_parents = [0u32; DEGREE];

            self.parents(node as usize, &mut cache_parents[..]).unwrap();
            self.copy_parents_data_inner_exp(&cache_parents, base_data, exp_data, hasher)
        }
    }

    pub fn copy_parents_data(&self, node: u32, base_data: &[u8], hasher: Sha256) -> [u8; 32] {
        if let Some(cache) = self.cache {
            let cache_parents = cache.read(node as u32);
            self.copy_parents_data_inner(&cache_parents, base_data, hasher)
        } else {
            let mut cache_parents = [0u32; DEGREE];

            self.parents(node as usize, &mut cache_parents[..]).unwrap();
            self.copy_parents_data_inner(&cache_parents, base_data, hasher)
        }
    }

    fn copy_parents_data_inner_exp(
        &self,
        cache_parents: &[u32],
        base_data: &[u8],
        exp_data: &[u8],
        mut hasher: Sha256,
    ) -> [u8; 32] {
        prefetch(&cache_parents[..BASE_DEGREE], base_data);
        prefetch(&cache_parents[BASE_DEGREE..], exp_data);

        // fill buffer
        let parents = [
            read_node(0, cache_parents, base_data),
            read_node(1, cache_parents, base_data),
            read_node(2, cache_parents, base_data),
            read_node(3, cache_parents, base_data),
            read_node(4, cache_parents, base_data),
            read_node(5, cache_parents, base_data),
            read_node(6, cache_parents, exp_data),
            read_node(7, cache_parents, exp_data),
            read_node(8, cache_parents, exp_data),
            read_node(9, cache_parents, exp_data),
            read_node(10, cache_parents, exp_data),
            read_node(11, cache_parents, exp_data),
            read_node(12, cache_parents, exp_data),
            read_node(13, cache_parents, exp_data),
        ];

        // round 1 (14)
        hasher.input(&parents);

        // round 2 (14)
        hasher.input(&parents);

        // round 3 (9)
        hasher.input(&parents[..8]);
        hasher.finish_with(&parents[8])
    }

    fn copy_parents_data_inner(
        &self,
        cache_parents: &[u32],
        base_data: &[u8],
        mut hasher: Sha256,
    ) -> [u8; 32] {
        prefetch(&cache_parents[..BASE_DEGREE], base_data);

        // fill buffer
        let parents = [
            read_node(0, cache_parents, base_data),
            read_node(1, cache_parents, base_data),
            read_node(2, cache_parents, base_data),
            read_node(3, cache_parents, base_data),
            read_node(4, cache_parents, base_data),
            read_node(5, cache_parents, base_data),
        ];

        // round 1 (0..6)
        hasher.input(&parents);

        // round 2 (6..12)
        hasher.input(&parents);

        // round 3 (12..18)
        hasher.input(&parents);

        // round 4 (18..24)
        hasher.input(&parents);

        // round 5 (24..30)
        hasher.input(&parents);

        // round 6 (30..36)
        hasher.input(&parents);

        // round 7 (37)
        hasher.finish_with(parents[0])
    }
}

impl<H, G> ParameterSetMetadata for StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata,
{
    fn identifier(&self) -> String {
        self.id.clone()
    }

    fn sector_size(&self) -> u64 {
        self.base_graph.sector_size()
    }
}

impl<H, G> Graph<H> for StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata + Sync + Send,
{
    type Key = Vec<u8>;

    fn size(&self) -> usize {
        self.base_graph().size()
    }

    fn degree(&self) -> usize {
        self.base_graph.degree() + self.expansion_degree
    }

    #[inline]
    fn parents(&self, node: usize, parents: &mut [u32]) -> Result<()> {
        if let Some(cache) = self.cache {
            // Read from the cache
            let cache_parents = cache.read(node as u32);
            parents.copy_from_slice(cache_parents);
        } else {
            self.base_parents(node, &mut parents[..self.base_graph().degree()])?;

            // expanded_parents takes raw_node
            self.expanded_parents(
                node,
                &mut parents[self.base_graph().degree()
                    ..self.base_graph().degree() + self.expansion_degree()],
            );
        }
        Ok(())
    }

    fn seed(&self) -> [u8; 28] {
        self.base_graph().seed()
    }

    fn new(
        nodes: usize,
        base_degree: usize,
        expansion_degree: usize,
        seed: [u8; 28],
    ) -> Result<Self> {
        Self::new_stacked(nodes, base_degree, expansion_degree, seed)
    }

    fn create_key(
        &self,
        _id: &H::Domain,
        _node: usize,
        _parents: &[u32],
        _base_parents_data: &[u8],
        _exp_parents_data: Option<&[u8]>,
    ) -> Result<Self::Key> {
        unimplemented!("not used");
    }
}

impl<'a, H, G> StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H> + ParameterSetMetadata + Sync + Send,
{
    /// Assign one parent to `node` using a Chung's construction with a reversible
    /// permutation function from a Feistel cipher (controlled by `invert_permutation`).
    fn correspondent(&self, node: usize, i: usize) -> u32 {
        // We can't just generate random values between `[0, size())`, we need to
        // expand the search space (domain) to accommodate every unique parent assignment
        // generated here. This can be visualized more clearly as a matrix where the each
        // new parent of each new node is assigned a unique `index`:
        //
        //
        //          | Parent 1 | Parent 2 | Parent 3 |
        //
        // | Node 1 |     0    |     1    |     2    |
        //
        // | Node 2 |     3    |     4    |     5    |
        //
        // | Node 3 |     6    |     7    |     8    |
        //
        // | Node 4 |     9    |     A    |     B    |
        //
        // This starting `index` will be shuffled to another position to generate a
        // parent-child relationship, e.g., if generating the parents for the second node,
        // `permute` would be called with values `[3; 4; 5]` that would be mapped to other
        // indexes in the search space of `[0, B]`, say, values `[A; 0; 4]`, that would
        // correspond to nodes numbered `[4; 1, 2]` which will become the parents of the
        // second node. In a later pass invalid parents like 2, self-referencing, and parents
        // with indexes bigger than 2 (if in the `forward` direction, smaller than 2 if the
        // inverse), will be removed.
        let a = (node * self.expansion_degree) as feistel::Index + i as feistel::Index;

        let transformed = feistel::permute(
            self.size() as feistel::Index * self.expansion_degree as feistel::Index,
            a,
            &FEISTEL_KEYS,
            self.feistel_precomputed,
        );
        transformed as u32 / self.expansion_degree as u32
        // Collapse the output in the matrix search space to the row of the corresponding
        // node (losing the column information, that will be regenerated later when calling
        // back this function in the `reversed` direction).
    }

    fn generate_expanded_parents(&self, node: usize, expanded_parents: &mut [u32]) {
        debug_assert_eq!(expanded_parents.len(), self.expansion_degree);
        for (i, el) in expanded_parents.iter_mut().enumerate() {
            *el = self.correspondent(node, i);
        }
    }

    pub fn new_stacked(
        nodes: usize,
        base_degree: usize,
        expansion_degree: usize,
        seed: [u8; 28],
    ) -> Result<Self> {
        Self::new(None, nodes, base_degree, expansion_degree, seed)
    }

    pub fn base_graph(&self) -> &G {
        &self.base_graph
    }

    pub fn expansion_degree(&self) -> usize {
        self.expansion_degree
    }

    pub fn base_parents(&self, node: usize, parents: &mut [u32]) -> Result<()> {
        if let Some(cache) = self.cache {
            // Read from the cache
            let cache_parents = cache.read(node as u32);
            parents.copy_from_slice(&cache_parents[..self.base_graph().degree()]);
            Ok(())
        } else {
            // No cache usage, generate on demand.
            self.base_graph().parents(node, parents)
        }
    }

    /// Assign `self.expansion_degree` parents to `node` using an invertible permutation
    /// that is applied one way for the forward layers and one way for the reversed
    /// ones.
    #[inline]
    pub fn expanded_parents(&self, node: usize, parents: &mut [u32]) {
        if let Some(cache) = self.cache {
            // Read from the cache
            let cache_parents = cache.read(node as u32);
            parents.copy_from_slice(&cache_parents[self.base_graph().degree()..]);
        } else {
            // No cache usage, generate on demand.
            self.generate_expanded_parents(node, parents);
        }
    }
}

impl<H, G> PartialEq for StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H>,
{
    fn eq(&self, other: &StackedGraph<H, G>) -> bool {
        self.base_graph == other.base_graph && self.expansion_degree == other.expansion_degree
    }
}

impl<H, G> Eq for StackedGraph<H, G>
where
    H: Hasher,
    G: Graph<H>,
{
}

#[cfg(test)]
mod tests {
    use super::*;

    use std::collections::HashSet;

    // Test that 3 (or more) rounds of the Feistel cipher can be used
    // as a pseudorandom permutation, that is, each input will be mapped
    // to a unique output (and though not test here, since the cipher
    // is symmetric, the decryption rounds also work as the inverse
    // permutation), for more details see:
    // https://en.wikipedia.org/wiki/Feistel_cipher#Theoretical_work.
    #[test]
    fn test_shuffle() {
        let n = 2_u64.pow(10);
        let d = EXP_DEGREE as u64;
        // Use a relatively small value of `n` as Feistel is expensive (but big
        // enough that `n >> d`).

        let mut shuffled: HashSet<u64> = HashSet::with_capacity((n * d) as usize);

        let feistel_keys = &[1, 2, 3, 4];
        let feistel_precomputed = feistel::precompute((n * d) as feistel::Index);

        for i in 0..n {
            for k in 0..d {
                let permuted =
                    feistel::permute(n * d, i * d + k, feistel_keys, feistel_precomputed);

                // Since the permutation implies a one-to-one correspondence,
                // traversing the entire input space should generate the entire
                // output space (in `shuffled`) without repetitions (since a duplicate
                // output would imply there is another output that wasn't generated
                // and the permutation would be incomplete).
                assert!(shuffled.insert(permuted));
            }
        }

        // Actually implied by the previous `assert!` this is left in place as an
        // extra safety check that indeed the permutation preserved all the output
        // space (of `n * d` nodes) without repetitions (which the `HashSet` would
        // have skipped as duplicates).
        assert_eq!(shuffled.len(), (n * d) as usize);
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/hash.rs ---
use neptune::poseidon::Poseidon;
use paired::bls12_381::Fr;
use storage_proofs_core::hasher::types::{POSEIDON_CONSTANTS_11, POSEIDON_CONSTANTS_2};

/// Hash all elements in the given column.
pub fn hash_single_column(column: &[Fr]) -> Fr {
    match column.len() {
        2 => {
            let mut hasher = Poseidon::new_with_preimage(column, &*POSEIDON_CONSTANTS_2);
            hasher.hash()
        }
        11 => {
            let mut hasher = Poseidon::new_with_preimage(column, &*POSEIDON_CONSTANTS_11);
            hasher.hash()
        }
        _ => panic!("unsupported column size: {}", column.len()),
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/labeling_proof.rs ---
use std::marker::PhantomData;

use log::trace;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use storage_proofs_core::{fr32::bytes_into_fr_repr_safe, hasher::Hasher};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LabelingProof<H: Hasher> {
    pub(crate) parents: Vec<H::Domain>,
    pub(crate) layer_index: u32,
    pub(crate) node: u64,
    #[serde(skip)]
    _h: PhantomData<H>,
}

impl<H: Hasher> LabelingProof<H> {
    pub fn new(layer_index: u32, node: u64, parents: Vec<H::Domain>) -> Self {
        LabelingProof {
            node,
            layer_index,
            parents,
            _h: PhantomData,
        }
    }

    fn create_label(&self, replica_id: &H::Domain) -> H::Domain {
        let mut hasher = Sha256::new();
        let mut buffer = [0u8; 64];

        // replica_id
        buffer[..32].copy_from_slice(AsRef::<[u8]>::as_ref(replica_id));

        // layer index
        buffer[32..36].copy_from_slice(&(self.layer_index as u32).to_be_bytes());

        // node id
        buffer[36..44].copy_from_slice(&(self.node as u64).to_be_bytes());

        hasher.input(&buffer[..]);

        // parents
        for parent in &self.parents {
            let data = AsRef::<[u8]>::as_ref(parent);
            hasher.input(data);
        }

        bytes_into_fr_repr_safe(hasher.result().as_ref()).into()
    }

    pub fn verify(&self, replica_id: &H::Domain, expected_label: &H::Domain) -> bool {
        let label = self.create_label(replica_id);
        check_eq!(expected_label, &label);

        true
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/macros.rs ---
/// Checks that the two passed values are equal. If they are not equal it prints a trace and returns `false`.
macro_rules! check_eq {
    ($left:expr , $right:expr,) => ({
        check_eq!($left, $right)
    });
    ($left:expr , $right:expr) => ({
        match (&($left), &($right)) {
            (left_val, right_val) => {
                if !(*left_val == *right_val) {
                    trace!("check failed: `(left == right)`\
                          \n\
                          \n{}\
                          \n",
                           pretty_assertions::Comparison::new(left_val, right_val));
                    return false;
                }
            }
        }
    });
    ($left:expr , $right:expr, $($arg:tt)*) => ({
        match (&($left), &($right)) {
            (left_val, right_val) => {
                if !(*left_val == *right_val) {
                    trace!("check failed: `(left == right)`: {}\
                          \n\
                          \n{}\
                          \n",
                           format_args!($($arg)*),
                           pretty_assertions::Comparison::new(left_val, right_val));
                    return false;
                }
            }
        }
    });
}

/// Checks that the passed in value is true. If they are not equal it prints a trace and returns `false`.
macro_rules! check {
    ($val:expr) => {
        if !$val {
            trace!("expected {:?} to be true", dbg!($val));
            return false;
        }
    };
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/mod.rs ---
#[macro_use]
mod macros;

mod challenges;
mod column;
mod column_proof;
mod create_label;
mod encoding_proof;
mod graph;
pub(crate) mod hash;
mod labeling_proof;
mod params;
mod porep;
mod proof;
mod proof_scheme;

pub use self::challenges::{ChallengeRequirements, LayerChallenges};
pub use self::column::Column;
pub use self::column_proof::ColumnProof;
pub use self::create_label::*;
pub use self::encoding_proof::EncodingProof;
pub use self::graph::{StackedBucketGraph, StackedGraph, EXP_DEGREE};
pub use self::labeling_proof::LabelingProof;
pub use self::params::*;
pub use self::proof::{StackedDrg, TOTAL_PARENTS};

'''
'''--- storage-proofs/porep/src/stacked/vanilla/params.rs ---
use std::marker::PhantomData;
use std::path::{Path, PathBuf};

use anyhow::Context;
use generic_array::typenum::{self, Unsigned};
use log::trace;
use merkletree::merkle::get_merkle_tree_leafs;
use merkletree::store::{DiskStore, Store, StoreConfig};
use serde::{Deserialize, Serialize};
use storage_proofs_core::{
    drgraph::Graph,
    error::Result,
    fr32::bytes_into_fr_repr_safe,
    hasher::{Domain, Hasher},
    merkle::*,
    parameter_cache::ParameterSetMetadata,
    util::data_at_node,
};

use super::{
    column::Column, column_proof::ColumnProof, graph::StackedBucketGraph, EncodingProof,
    LabelingProof, LayerChallenges,
};

pub const BINARY_ARITY: usize = 2;
pub const QUAD_ARITY: usize = 4;
pub const OCT_ARITY: usize = 8;

#[derive(Debug, Clone)]
pub struct SetupParams {
    // Number of nodes
    pub nodes: usize,

    // Base degree of DRG
    pub degree: usize,

    pub expansion_degree: usize,

    // Random seed
    pub seed: [u8; 28],

    pub layer_challenges: LayerChallenges,
}

#[derive(Debug)]
pub struct PublicParams<Tree>
where
    Tree: 'static + MerkleTreeTrait,
{
    pub graph: StackedBucketGraph<Tree::Hasher>,
    pub layer_challenges: LayerChallenges,
    _t: PhantomData<Tree>,
}

impl<Tree> Clone for PublicParams<Tree>
where
    Tree: MerkleTreeTrait,
{
    fn clone(&self) -> Self {
        Self {
            graph: self.graph.clone(),
            layer_challenges: self.layer_challenges.clone(),
            _t: Default::default(),
        }
    }
}

impl<Tree> PublicParams<Tree>
where
    Tree: MerkleTreeTrait,
{
    pub fn new(graph: StackedBucketGraph<Tree::Hasher>, layer_challenges: LayerChallenges) -> Self {
        PublicParams {
            graph,
            layer_challenges,
            _t: PhantomData,
        }
    }
}

impl<Tree> ParameterSetMetadata for PublicParams<Tree>
where
    Tree: MerkleTreeTrait,
{
    fn identifier(&self) -> String {
        format!(
            "layered_drgporep::PublicParams{{ graph: {}, challenges: {:?}, tree: {} }}",
            self.graph.identifier(),
            self.layer_challenges,
            Tree::display()
        )
    }

    fn sector_size(&self) -> u64 {
        self.graph.sector_size()
    }
}

impl<'a, Tree> From<&'a PublicParams<Tree>> for PublicParams<Tree>
where
    Tree: MerkleTreeTrait,
{
    fn from(other: &PublicParams<Tree>) -> PublicParams<Tree> {
        PublicParams::new(other.graph.clone(), other.layer_challenges.clone())
    }
}

#[derive(Debug, Clone)]
pub struct PublicInputs<T: Domain, S: Domain> {
    pub replica_id: T,
    pub seed: [u8; 32],
    pub tau: Option<Tau<T, S>>,
    /// Partition index
    pub k: Option<usize>,
}

impl<T: Domain, S: Domain> PublicInputs<T, S> {
    pub fn challenges(
        &self,
        layer_challenges: &LayerChallenges,
        leaves: usize,
        partition_k: Option<usize>,
    ) -> Vec<usize> {
        let k = partition_k.unwrap_or(0);

        layer_challenges.derive::<T>(leaves, &self.replica_id, &self.seed, k as u8)
    }
}

#[derive(Debug)]
pub struct PrivateInputs<Tree: MerkleTreeTrait, G: Hasher> {
    pub p_aux: PersistentAux<<Tree::Hasher as Hasher>::Domain>,
    pub t_aux: TemporaryAuxCache<Tree, G>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct Proof<Tree: MerkleTreeTrait, G: Hasher> {
    #[serde(bound(
        serialize = "MerkleProof<G, typenum::U2>: Serialize",
        deserialize = "MerkleProof<G, typenum::U2>: Deserialize<'de>"
    ))]
    pub comm_d_proofs: MerkleProof<G, typenum::U2>,
    #[serde(bound(
        serialize = "MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>: Serialize",
        deserialize = "MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>: Deserialize<'de>"
    ))]
    pub comm_r_last_proof:
        MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    #[serde(bound(
        serialize = "ReplicaColumnProof<MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,>: Serialize",
        deserialize = "ReplicaColumnProof<MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>: Deserialize<'de>"
    ))]
    pub replica_column_proofs: ReplicaColumnProof<
        MerkleProof<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    >,
    #[serde(bound(
        serialize = "LabelingProof<Tree::Hasher>: Serialize",
        deserialize = "LabelingProof<Tree::Hasher>: Deserialize<'de>"
    ))]
    /// Indexed by layer in 1..layers.
    pub labeling_proofs: Vec<LabelingProof<Tree::Hasher>>,
    #[serde(bound(
        serialize = "EncodingProof<Tree::Hasher>: Serialize",
        deserialize = "EncodingProof<Tree::Hasher>: Deserialize<'de>"
    ))]
    pub encoding_proof: EncodingProof<Tree::Hasher>,
}

impl<Tree: MerkleTreeTrait, G: Hasher> Clone for Proof<Tree, G> {
    fn clone(&self) -> Self {
        Self {
            comm_d_proofs: self.comm_d_proofs.clone(),
            comm_r_last_proof: self.comm_r_last_proof.clone(),
            replica_column_proofs: self.replica_column_proofs.clone(),
            labeling_proofs: self.labeling_proofs.clone(),
            encoding_proof: self.encoding_proof.clone(),
        }
    }
}

impl<Tree: MerkleTreeTrait, G: Hasher> Proof<Tree, G> {
    pub fn comm_r_last(&self) -> <Tree::Hasher as Hasher>::Domain {
        self.comm_r_last_proof.root()
    }

    pub fn comm_c(&self) -> <Tree::Hasher as Hasher>::Domain {
        self.replica_column_proofs.c_x.root()
    }

    /// Verify the full proof.
    pub fn verify(
        &self,
        pub_params: &PublicParams<Tree>,
        pub_inputs: &PublicInputs<<Tree::Hasher as Hasher>::Domain, <G as Hasher>::Domain>,
        challenge: usize,
        graph: &StackedBucketGraph<Tree::Hasher>,
    ) -> bool {
        let replica_id = &pub_inputs.replica_id;

        check!(challenge < graph.size());
        check!(pub_inputs.tau.is_some());

        // Verify initial data layer
        trace!("verify initial data layer");

        check!(self.comm_d_proofs.proves_challenge(challenge));

        if let Some(ref tau) = pub_inputs.tau {
            check_eq!(&self.comm_d_proofs.root(), &tau.comm_d);
        } else {
            return false;
        }

        // Verify replica column openings
        trace!("verify replica column openings");
        let mut parents = vec![0; graph.degree()];
        graph.parents(challenge, &mut parents).unwrap(); // FIXME: error handling
        check!(self.replica_column_proofs.verify(challenge, &parents));

        check!(self.verify_final_replica_layer(challenge));

        check!(self.verify_labels(replica_id, &pub_params.layer_challenges));

        trace!("verify encoding");

        check!(self.encoding_proof.verify::<G>(
            replica_id,
            &self.comm_r_last_proof.leaf(),
            &self.comm_d_proofs.leaf()
        ));

        true
    }

    /// Verify all labels.
    fn verify_labels(
        &self,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        layer_challenges: &LayerChallenges,
    ) -> bool {
        // Verify Labels Layer 1..layers
        for layer in 1..=layer_challenges.layers() {
            trace!("verify labeling (layer: {})", layer,);

            check!(self.labeling_proofs.get(layer - 1).is_some());
            let labeling_proof = &self.labeling_proofs.get(layer - 1).unwrap();
            let labeled_node = self
                .replica_column_proofs
                .c_x
                .get_node_at_layer(layer)
                .unwrap(); // FIXME: error handling
            check!(labeling_proof.verify(replica_id, labeled_node));
        }

        true
    }

    /// Verify final replica layer openings
    fn verify_final_replica_layer(&self, challenge: usize) -> bool {
        trace!("verify final replica layer openings");
        check!(self.comm_r_last_proof.proves_challenge(challenge));

        true
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReplicaColumnProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub c_x: ColumnProof<Proof>,
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub drg_parents: Vec<ColumnProof<Proof>>,
    #[serde(bound(
        serialize = "ColumnProof<Proof>: Serialize",
        deserialize = "ColumnProof<Proof>: Deserialize<'de>"
    ))]
    pub exp_parents: Vec<ColumnProof<Proof>>,
}

impl<Proof: MerkleProofTrait> ReplicaColumnProof<Proof> {
    pub fn verify(&self, challenge: usize, parents: &[u32]) -> bool {
        let expected_comm_c = self.c_x.root();

        trace!("  verify c_x");
        check!(self.c_x.verify(challenge as u32, &expected_comm_c));

        trace!("  verify drg_parents");
        for (proof, parent) in self.drg_parents.iter().zip(parents.iter()) {
            check!(proof.verify(*parent, &expected_comm_c));
        }

        trace!("  verify exp_parents");
        for (proof, parent) in self
            .exp_parents
            .iter()
            .zip(parents.iter().skip(self.drg_parents.len()))
        {
            check!(proof.verify(*parent, &expected_comm_c));
        }

        true
    }
}

pub type TransformedLayers<Tree, G> = (
    Tau<<<Tree as MerkleTreeTrait>::Hasher as Hasher>::Domain, <G as Hasher>::Domain>,
    PersistentAux<<<Tree as MerkleTreeTrait>::Hasher as Hasher>::Domain>,
    TemporaryAux<Tree, G>,
);

/// Tau for a single parition.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Tau<D: Domain, E: Domain> {
    pub comm_d: E,
    pub comm_r: D,
}

/// Stored along side the sector on disk.
#[derive(Default, Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct PersistentAux<D> {
    pub comm_c: D,
    pub comm_r_last: D,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TemporaryAux<Tree: MerkleTreeTrait, G: Hasher> {
    /// The encoded nodes for 1..layers.
    #[serde(bound(
        serialize = "StoreConfig: Serialize",
        deserialize = "StoreConfig: Deserialize<'de>"
    ))]
    pub labels: Labels<Tree>,
    pub tree_d_config: StoreConfig,
    pub tree_r_last_config: StoreConfig,
    pub tree_c_config: StoreConfig,
    pub _g: PhantomData<G>,
}

impl<Tree: MerkleTreeTrait, G: Hasher> Clone for TemporaryAux<Tree, G> {
    fn clone(&self) -> Self {
        Self {
            labels: self.labels.clone(),
            tree_d_config: self.tree_d_config.clone(),
            tree_r_last_config: self.tree_r_last_config.clone(),
            tree_c_config: self.tree_c_config.clone(),
            _g: Default::default(),
        }
    }
}

impl<Tree: MerkleTreeTrait, G: Hasher> TemporaryAux<Tree, G> {
    pub fn set_cache_path<P: AsRef<Path>>(&mut self, cache_path: P) {
        let cp = cache_path.as_ref().to_path_buf();
        for label in self.labels.labels.iter_mut() {
            label.path = cp.clone();
        }
        self.tree_d_config.path = cp.clone();
        self.tree_r_last_config.path = cp.clone();
        self.tree_c_config.path = cp;
    }

    pub fn labels_for_layer(
        &self,
        layer: usize,
    ) -> Result<DiskStore<<Tree::Hasher as Hasher>::Domain>> {
        self.labels.labels_for_layer(layer)
    }

    pub fn domain_node_at_layer(
        &self,
        layer: usize,
        node_index: u32,
    ) -> Result<<Tree::Hasher as Hasher>::Domain> {
        Ok(self.labels_for_layer(layer)?.read_at(node_index as usize)?)
    }

    pub fn column(&self, column_index: u32) -> Result<Column<Tree::Hasher>> {
        self.labels.column(column_index)
    }

    // 'clear_temp' will discard all persisted merkle and layer data
    // that is no longer required.
    pub fn clear_temp(t_aux: TemporaryAux<Tree, G>) -> Result<()> {
        let cached = |config: &StoreConfig| {
            Path::new(&StoreConfig::data_path(&config.path, &config.id)).exists()
        };

        if cached(&t_aux.tree_d_config) {
            let tree_d_size = t_aux
                .tree_d_config
                .size
                .context("tree_d config has no size")?;
            let tree_d_store: DiskStore<G::Domain> =
                DiskStore::new_from_disk(tree_d_size, BINARY_ARITY, &t_aux.tree_d_config)
                    .context("tree_d")?;
            // Note: from_data_store requires the base tree leaf count
            let tree_d = BinaryMerkleTree::<G>::from_data_store(
                tree_d_store,
                get_merkle_tree_leafs(tree_d_size, BINARY_ARITY)?,
            )
            .context("tree_d")?;

            tree_d.delete(t_aux.tree_d_config).context("tree_d")?;
            trace!("tree d deleted");
        }

        if cached(&t_aux.tree_c_config) {
            let tree_c_size = t_aux
                .tree_c_config
                .size
                .context("tree_c config has no size")?;

            let tree_count = get_base_tree_count::<Tree>();
            let configs = split_config(t_aux.tree_c_config.clone(), tree_count)?;
            for config in &configs {
                let tree_c_store = DiskStore::<<Tree::Hasher as Hasher>::Domain>::new_from_disk(
                    tree_c_size,
                    Tree::Arity::to_usize(),
                    &config,
                )
                .context("tree_c")?;
                // Note: from_data_store requires the base tree leaf count
                let tree_c = DiskTree::<
                    Tree::Hasher,
                    Tree::Arity,
                    Tree::SubTreeArity,
                    Tree::TopTreeArity,
                >::from_data_store(
                    tree_c_store,
                    get_merkle_tree_leafs(tree_c_size, Tree::Arity::to_usize())?,
                )
                .context("tree_c")?;
                tree_c.delete(config.clone()).context("tree_c")?;
            }
            trace!("tree c deleted");
        }

        for i in 0..t_aux.labels.labels.len() {
            let cur_config = t_aux.labels.labels[i].clone();
            if cached(&cur_config) {
                DiskStore::<<Tree::Hasher as Hasher>::Domain>::delete(cur_config)
                    .with_context(|| format!("labels {}", i))?;
                trace!("layer {} deleted", i);
            }
        }

        Ok(())
    }
}

#[derive(Debug)]
pub struct TemporaryAuxCache<Tree: MerkleTreeTrait, G: Hasher> {
    /// The encoded nodes for 1..layers.
    pub labels: LabelsCache<Tree>,
    pub tree_d: BinaryMerkleTree<G>,

    // Notably this is a LevelCacheTree instead of a full merkle.
    pub tree_r_last: LCTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,

    // Store the 'rows_to_discard' value from the tree_r_last
    // StoreConfig for later use (i.e. proof generation).
    pub tree_r_last_config_rows_to_discard: usize,

    pub tree_c: DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
    pub t_aux: TemporaryAux<Tree, G>,
    pub replica_path: PathBuf,
}

impl<Tree: MerkleTreeTrait, G: Hasher> TemporaryAuxCache<Tree, G> {
    pub fn new(t_aux: &TemporaryAux<Tree, G>, replica_path: PathBuf) -> Result<Self> {
        // tree_d_size stored in the config is the base tree size
        let tree_d_size = t_aux.tree_d_config.size.unwrap();
        let tree_d_leafs = get_merkle_tree_leafs(tree_d_size, BINARY_ARITY)?;
        trace!(
            "Instantiating tree d with size {} and leafs {}",
            tree_d_size,
            tree_d_leafs,
        );
        let tree_d_store: DiskStore<G::Domain> =
            DiskStore::new_from_disk(tree_d_size, BINARY_ARITY, &t_aux.tree_d_config)
                .context("tree_d_store")?;
        let tree_d =
            BinaryMerkleTree::<G>::from_data_store(tree_d_store, tree_d_leafs).context("tree_d")?;

        let tree_count = get_base_tree_count::<Tree>();
        let configs = split_config(t_aux.tree_c_config.clone(), tree_count)?;

        // tree_c_size stored in the config is the base tree size
        let tree_c_size = t_aux.tree_c_config.size.unwrap();
        trace!(
            "Instantiating tree c [count {}] with size {} and arity {}",
            tree_count,
            tree_c_size,
            Tree::Arity::to_usize(),
        );
        let tree_c = create_disk_tree::<
            DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
        >(tree_c_size, &configs)?;

        // tree_r_last_size stored in the config is the base tree size
        let tree_r_last_size = t_aux.tree_r_last_config.size.unwrap();
        let tree_r_last_config_rows_to_discard = t_aux.tree_r_last_config.rows_to_discard;
        let (configs, replica_config) = split_config_and_replica(
            t_aux.tree_r_last_config.clone(),
            replica_path.clone(),
            get_merkle_tree_leafs(tree_r_last_size, Tree::Arity::to_usize())?,
            tree_count,
        )?;

        trace!(
            "Instantiating tree r last [count {}] with size {} and arity {}, {}, {}",
            tree_count,
            tree_r_last_size,
            Tree::Arity::to_usize(),
            Tree::SubTreeArity::to_usize(),
            Tree::TopTreeArity::to_usize(),
        );
        let tree_r_last = create_lc_tree::<
            LCTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
        >(tree_r_last_size, &configs, &replica_config)?;

        Ok(TemporaryAuxCache {
            labels: LabelsCache::new(&t_aux.labels).context("labels_cache")?,
            tree_d,
            tree_r_last,
            tree_r_last_config_rows_to_discard,
            tree_c,
            replica_path,
            t_aux: t_aux.clone(),
        })
    }

    pub fn labels_for_layer(&self, layer: usize) -> &DiskStore<<Tree::Hasher as Hasher>::Domain> {
        self.labels.labels_for_layer(layer)
    }

    pub fn domain_node_at_layer(
        &self,
        layer: usize,
        node_index: u32,
    ) -> Result<<Tree::Hasher as Hasher>::Domain> {
        Ok(self.labels_for_layer(layer).read_at(node_index as usize)?)
    }

    pub fn column(&self, column_index: u32) -> Result<Column<Tree::Hasher>> {
        self.labels.column(column_index)
    }
}

type VerifyCallback = fn(&StoreConfig, usize, usize) -> Result<()>;

#[derive(Debug, Serialize, Deserialize)]
pub struct Labels<Tree: MerkleTreeTrait> {
    #[serde(bound(
        serialize = "StoreConfig: Serialize",
        deserialize = "StoreConfig: Deserialize<'de>"
    ))]
    pub labels: Vec<StoreConfig>,
    pub _h: PhantomData<Tree>,
}

impl<Tree: MerkleTreeTrait> Clone for Labels<Tree> {
    fn clone(&self) -> Self {
        Self {
            labels: self.labels.clone(),
            _h: Default::default(),
        }
    }
}

impl<Tree: MerkleTreeTrait> Labels<Tree> {
    pub fn new(labels: Vec<StoreConfig>) -> Self {
        Labels {
            labels,
            _h: PhantomData,
        }
    }

    pub fn len(&self) -> usize {
        self.labels.len()
    }

    pub fn is_empty(&self) -> bool {
        self.labels.is_empty()
    }

    pub fn verify_stores(&self, callback: VerifyCallback, cache_dir: &PathBuf) -> Result<()> {
        let updated_path_labels = self.labels.clone();
        let required_configs = get_base_tree_count::<Tree>();
        for mut label in updated_path_labels {
            label.path = cache_dir.to_path_buf();
            callback(&label, BINARY_ARITY, required_configs)?;
        }

        Ok(())
    }

    pub fn labels_for_layer(
        &self,
        layer: usize,
    ) -> Result<DiskStore<<Tree::Hasher as Hasher>::Domain>> {
        assert!(layer != 0, "Layer cannot be 0");
        assert!(
            layer <= self.layers(),
            "Layer {} is not available (only {} layers available)",
            layer,
            self.layers()
        );

        let row_index = layer - 1;
        let config = self.labels[row_index].clone();
        assert!(config.size.is_some());

        DiskStore::new_from_disk(config.size.unwrap(), Tree::Arity::to_usize(), &config)
    }

    /// Returns label for the last layer.
    pub fn labels_for_last_layer(&self) -> Result<DiskStore<<Tree::Hasher as Hasher>::Domain>> {
        self.labels_for_layer(self.labels.len() - 1)
    }

    /// How many layers are available.
    fn layers(&self) -> usize {
        self.labels.len()
    }

    /// Build the column for the given node.
    pub fn column(&self, node: u32) -> Result<Column<Tree::Hasher>> {
        let rows = self
            .labels
            .iter()
            .map(|label| {
                assert!(label.size.is_some());
                let store =
                    DiskStore::new_from_disk(label.size.unwrap(), Tree::Arity::to_usize(), &label)?;
                store.read_at(node as usize)
            })
            .collect::<Result<_>>()?;

        Column::new(node, rows)
    }

    /// Update all configs to the new passed in root cache path.
    pub fn update_root<P: AsRef<Path>>(&mut self, root: P) {
        for config in &mut self.labels {
            config.path = root.as_ref().into();
        }
    }
}

#[derive(Debug)]
pub struct LabelsCache<Tree: MerkleTreeTrait> {
    pub labels: Vec<DiskStore<<Tree::Hasher as Hasher>::Domain>>,
}

impl<Tree: MerkleTreeTrait> LabelsCache<Tree> {
    pub fn new(labels: &Labels<Tree>) -> Result<Self> {
        let mut disk_store_labels: Vec<DiskStore<<Tree::Hasher as Hasher>::Domain>> =
            Vec::with_capacity(labels.len());
        for i in 0..labels.len() {
            disk_store_labels.push(labels.labels_for_layer(i + 1)?);
        }

        Ok(LabelsCache {
            labels: disk_store_labels,
        })
    }

    pub fn len(&self) -> usize {
        self.labels.len()
    }

    pub fn is_empty(&self) -> bool {
        self.labels.is_empty()
    }

    pub fn labels_for_layer(&self, layer: usize) -> &DiskStore<<Tree::Hasher as Hasher>::Domain> {
        assert!(layer != 0, "Layer cannot be 0");
        assert!(
            layer <= self.layers(),
            "Layer {} is not available (only {} layers available)",
            layer,
            self.layers()
        );

        let row_index = layer - 1;
        &self.labels[row_index]
    }

    /// Returns the labels on the last layer.
    pub fn labels_for_last_layer(&self) -> Result<&DiskStore<<Tree::Hasher as Hasher>::Domain>> {
        Ok(&self.labels[self.labels.len() - 1])
    }

    /// How many layers are available.
    fn layers(&self) -> usize {
        self.labels.len()
    }

    /// Build the column for the given node.
    pub fn column(&self, node: u32) -> Result<Column<Tree::Hasher>> {
        let rows = self
            .labels
            .iter()
            .map(|labels| labels.read_at(node as usize))
            .collect::<Result<_>>()?;

        Column::new(node, rows)
    }
}

pub fn get_node<H: Hasher>(data: &[u8], index: usize) -> Result<H::Domain> {
    H::Domain::try_from_bytes(data_at_node(data, index).expect("invalid node math"))
}

/// Generate the replica id as expected for Stacked DRG.
pub fn generate_replica_id<H: Hasher, T: AsRef<[u8]>>(
    prover_id: &[u8; 32],
    sector_id: u64,
    ticket: &[u8; 32],
    comm_d: T,
) -> H::Domain {
    use sha2::{Digest, Sha256};

    let hash = Sha256::new()
        .chain(prover_id)
        .chain(&sector_id.to_be_bytes()[..])
        .chain(ticket)
        .chain(AsRef::<[u8]>::as_ref(&comm_d))
        .result();

    bytes_into_fr_repr_safe(hash.as_ref()).into()
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/porep.rs ---
use std::path::PathBuf;

use merkletree::store::StoreConfig;
use storage_proofs_core::{
    error::Result,
    hasher::Hasher,
    merkle::{BinaryMerkleTree, MerkleTreeTrait},
    Data,
};

use super::{
    params::{PersistentAux, PublicParams, Tau, TemporaryAux},
    proof::StackedDrg,
};
use crate::PoRep;

impl<'a, 'c, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher> PoRep<'a, Tree::Hasher, G>
    for StackedDrg<'a, Tree, G>
{
    type Tau = Tau<<Tree::Hasher as Hasher>::Domain, <G as Hasher>::Domain>;
    type ProverAux = (
        PersistentAux<<Tree::Hasher as Hasher>::Domain>,
        TemporaryAux<Tree, G>,
    );

    fn replicate(
        pp: &'a PublicParams<Tree>,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        data: Data<'a>,
        data_tree: Option<BinaryMerkleTree<G>>,
        config: StoreConfig,
        replica_path: PathBuf,
    ) -> Result<(Self::Tau, Self::ProverAux)> {
        let (tau, p_aux, t_aux) = Self::transform_and_replicate_layers(
            &pp.graph,
            &pp.layer_challenges,
            replica_id,
            data,
            data_tree,
            config,
            replica_path,
        )?;

        Ok((tau, (p_aux, t_aux)))
    }

    fn extract_all<'b>(
        pp: &'b PublicParams<Tree>,
        replica_id: &'b <Tree::Hasher as Hasher>::Domain,
        data: &'b [u8],
        config: Option<StoreConfig>,
    ) -> Result<Vec<u8>> {
        let mut data = data.to_vec();

        Self::extract_and_invert_transform_layers(
            &pp.graph,
            &pp.layer_challenges,
            replica_id,
            &mut data,
            config.expect("Missing store config"),
        )?;

        Ok(data)
    }

    fn extract(
        _pp: &PublicParams<Tree>,
        _replica_id: &<Tree::Hasher as Hasher>::Domain,
        _data: &[u8],
        _node: usize,
        _config: Option<StoreConfig>,
    ) -> Result<Vec<u8>> {
        unimplemented!();
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/proof.rs ---
use std::marker::PhantomData;
use std::path::PathBuf;

use generic_array::typenum::{self, Unsigned};
use log::{info, trace};
use merkletree::merkle::{get_merkle_tree_len, is_merkle_tree_size_valid};
use merkletree::store::{DiskStore, StoreConfig};
use paired::bls12_381::Fr;
use rayon::prelude::*;
use storage_proofs_core::{
    cache_key::CacheKey,
    data::Data,
    drgraph::Graph,
    error::Result,
    hasher::{Domain, HashFunction, Hasher, PoseidonArity},
    measurements::{
        measure_op,
        Operation::{CommD, EncodeWindowTimeAll, GenerateTreeC, GenerateTreeRLast},
    },
    merkle::*,
    settings,
    util::NODE_SIZE,
};
use typenum::{U11, U2, U8};

use super::{
    challenges::LayerChallenges,
    column::Column,
    create_label, create_label_exp,
    graph::StackedBucketGraph,
    hash::hash_single_column,
    params::{
        get_node, Labels, LabelsCache, PersistentAux, Proof, PublicInputs, PublicParams,
        ReplicaColumnProof, Tau, TemporaryAux, TemporaryAuxCache, TransformedLayers, BINARY_ARITY,
    },
    EncodingProof, LabelingProof,
};

use ff::Field;
use generic_array::{sequence::GenericSequence, GenericArray};
use neptune::batch_hasher::BatcherType;
use neptune::column_tree_builder::{ColumnTreeBuilder, ColumnTreeBuilderTrait};
use storage_proofs_core::fr32::fr_into_bytes;

use crate::encode::{decode, encode};
use crate::PoRep;

pub const TOTAL_PARENTS: usize = 37;

#[derive(Debug)]
pub struct StackedDrg<'a, Tree: 'a + MerkleTreeTrait, G: 'a + Hasher> {
    _a: PhantomData<&'a Tree>,
    _b: PhantomData<&'a G>,
}

impl<'a, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher> StackedDrg<'a, Tree, G> {
    #[allow(clippy::too_many_arguments)]
    pub(crate) fn prove_layers(
        graph: &StackedBucketGraph<Tree::Hasher>,
        pub_inputs: &PublicInputs<<Tree::Hasher as Hasher>::Domain, <G as Hasher>::Domain>,
        p_aux: &PersistentAux<<Tree::Hasher as Hasher>::Domain>,
        t_aux: &TemporaryAuxCache<Tree, G>,
        layer_challenges: &LayerChallenges,
        layers: usize,
        _total_layers: usize,
        partition_count: usize,
    ) -> Result<Vec<Vec<Proof<Tree, G>>>> {
        assert!(layers > 0);
        assert_eq!(t_aux.labels.len(), layers);

        let graph_size = graph.size();

        // Sanity checks on restored trees.
        assert!(pub_inputs.tau.is_some());
        assert_eq!(pub_inputs.tau.as_ref().unwrap().comm_d, t_aux.tree_d.root());

        let get_drg_parents_columns = |x: usize| -> Result<Vec<Column<Tree::Hasher>>> {
            let base_degree = graph.base_graph().degree();

            let mut columns = Vec::with_capacity(base_degree);

            let mut parents = vec![0; base_degree];
            graph.base_parents(x, &mut parents)?;

            for parent in &parents {
                columns.push(t_aux.column(*parent)?);
            }

            debug_assert!(columns.len() == base_degree);

            Ok(columns)
        };

        let get_exp_parents_columns = |x: usize| -> Result<Vec<Column<Tree::Hasher>>> {
            let mut parents = vec![0; graph.expansion_degree()];
            graph.expanded_parents(x, &mut parents);

            parents.iter().map(|parent| t_aux.column(*parent)).collect()
        };

        (0..partition_count)
            .map(|k| {
                trace!("proving partition {}/{}", k + 1, partition_count);

                // Derive the set of challenges we are proving over.
                let challenges = pub_inputs.challenges(layer_challenges, graph_size, Some(k));

                // Stacked commitment specifics
                challenges
                    .into_par_iter()
                    .enumerate()
                    .map(|(challenge_index, challenge)| {
                        trace!(" challenge {} ({})", challenge, challenge_index);
                        assert!(challenge < graph.size(), "Invalid challenge");
                        assert!(challenge > 0, "Invalid challenge");

                        // Initial data layer openings (c_X in Comm_D)
                        let comm_d_proof = t_aux.tree_d.gen_proof(challenge)?;
                        assert!(comm_d_proof.validate(challenge));

                        // Stacked replica column openings
                        let rcp = {
                            let (c_x, drg_parents, exp_parents) = {
                                assert_eq!(p_aux.comm_c, t_aux.tree_c.root());
                                let tree_c = &t_aux.tree_c;

                                // All labels in C_X
                                trace!("  c_x");
                                let c_x = t_aux.column(challenge as u32)?.into_proof(tree_c)?;

                                // All labels in the DRG parents.
                                trace!("  drg_parents");
                                let drg_parents = get_drg_parents_columns(challenge)?
                                    .into_iter()
                                    .map(|column| column.into_proof(tree_c))
                                    .collect::<Result<_>>()?;

                                // Labels for the expander parents
                                trace!("  exp_parents");
                                let exp_parents = get_exp_parents_columns(challenge)?
                                    .into_iter()
                                    .map(|column| column.into_proof(tree_c))
                                    .collect::<Result<_>>()?;

                                (c_x, drg_parents, exp_parents)
                            };

                            ReplicaColumnProof {
                                c_x,
                                drg_parents,
                                exp_parents,
                            }
                        };

                        // Final replica layer openings
                        trace!("final replica layer openings");
                        let comm_r_last_proof = t_aux.tree_r_last.gen_cached_proof(
                            challenge,
                            Some(t_aux.tree_r_last_config_rows_to_discard),
                        )?;

                        debug_assert!(comm_r_last_proof.validate(challenge));

                        // Labeling Proofs Layer 1..l
                        let mut labeling_proofs = Vec::with_capacity(layers);
                        let mut encoding_proof = None;

                        for layer in 1..=layers {
                            trace!("  encoding proof layer {}", layer,);
                            let parents_data: Vec<<Tree::Hasher as Hasher>::Domain> = if layer == 1
                            {
                                let mut parents = vec![0; graph.base_graph().degree()];
                                graph.base_parents(challenge, &mut parents)?;

                                parents
                                    .into_iter()
                                    .map(|parent| t_aux.domain_node_at_layer(layer, parent))
                                    .collect::<Result<_>>()?
                            } else {
                                let mut parents = vec![0; graph.degree()];
                                graph.parents(challenge, &mut parents)?;
                                let base_parents_count = graph.base_graph().degree();

                                parents
                                    .into_iter()
                                    .enumerate()
                                    .map(|(i, parent)| {
                                        if i < base_parents_count {
                                            // parents data for base parents is from the current layer
                                            t_aux.domain_node_at_layer(layer, parent)
                                        } else {
                                            // parents data for exp parents is from the previous layer
                                            t_aux.domain_node_at_layer(layer - 1, parent)
                                        }
                                    })
                                    .collect::<Result<_>>()?
                            };

                            // repeat parents
                            let mut parents_data_full = vec![Default::default(); TOTAL_PARENTS];
                            for chunk in parents_data_full.chunks_mut(parents_data.len()) {
                                chunk.copy_from_slice(&parents_data[..chunk.len()]);
                            }

                            let proof = LabelingProof::<Tree::Hasher>::new(
                                layer as u32,
                                challenge as u64,
                                parents_data_full.clone(),
                            );

                            {
                                let labeled_node = rcp.c_x.get_node_at_layer(layer)?;
                                assert!(
                                    proof.verify(&pub_inputs.replica_id, &labeled_node),
                                    format!("Invalid encoding proof generated at layer {}", layer)
                                );
                                trace!("Valid encoding proof generated at layer {}", layer);
                            }

                            labeling_proofs.push(proof);

                            if layer == layers {
                                encoding_proof = Some(EncodingProof::new(
                                    layer as u32,
                                    challenge as u64,
                                    parents_data_full,
                                ));
                            }
                        }

                        Ok(Proof {
                            comm_d_proofs: comm_d_proof,
                            replica_column_proofs: rcp,
                            comm_r_last_proof,
                            labeling_proofs,
                            encoding_proof: encoding_proof.expect("invalid tapering"),
                        })
                    })
                    .collect()
            })
            .collect()
    }

    pub(crate) fn extract_and_invert_transform_layers(
        graph: &StackedBucketGraph<Tree::Hasher>,
        layer_challenges: &LayerChallenges,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        data: &mut [u8],
        config: StoreConfig,
    ) -> Result<()> {
        trace!("extract_and_invert_transform_layers");

        let layers = layer_challenges.layers();
        assert!(layers > 0);

        // generate labels
        let (labels, _) = Self::generate_labels(graph, layer_challenges, replica_id, config)?;

        let last_layer_labels = labels.labels_for_last_layer()?;
        let size = merkletree::store::Store::len(last_layer_labels);

        for (key, encoded_node_bytes) in last_layer_labels
            .read_range(0..size)?
            .into_iter()
            .zip(data.chunks_mut(NODE_SIZE))
        {
            let encoded_node =
                <Tree::Hasher as Hasher>::Domain::try_from_bytes(encoded_node_bytes)?;
            let data_node = decode::<<Tree::Hasher as Hasher>::Domain>(key, encoded_node);

            // store result in the data
            encoded_node_bytes.copy_from_slice(AsRef::<[u8]>::as_ref(&data_node));
        }

        Ok(())
    }

    #[allow(clippy::type_complexity)]
    fn generate_labels(
        graph: &StackedBucketGraph<Tree::Hasher>,
        layer_challenges: &LayerChallenges,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        config: StoreConfig,
    ) -> Result<(LabelsCache<Tree>, Labels<Tree>)> {
        info!("generate labels");

        let layers = layer_challenges.layers();
        // For now, we require it due to changes in encodings structure.
        let mut labels: Vec<DiskStore<<Tree::Hasher as Hasher>::Domain>> =
            Vec::with_capacity(layers);
        let mut label_configs: Vec<StoreConfig> = Vec::with_capacity(layers);

        let layer_size = graph.size() * NODE_SIZE;
        // NOTE: this means we currently keep 2x sector size around, to improve speed.
        let mut labels_buffer = vec![0u8; 2 * layer_size];

        for layer in 1..=layers {
            info!("generating layer: {}", layer);

            if layer == 1 {
                let layer_labels = &mut labels_buffer[..layer_size];
                for node in 0..graph.size() {
                    create_label(graph, replica_id, layer_labels, layer, node)?;
                }
            } else {
                let (layer_labels, exp_labels) = labels_buffer.split_at_mut(layer_size);
                for node in 0..graph.size() {
                    create_label_exp(graph, replica_id, exp_labels, layer_labels, layer, node)?;
                }
            }

            info!("  setting exp parents");
            labels_buffer.copy_within(..layer_size, layer_size);

            // Write the result to disk to avoid keeping it in memory all the time.
            let layer_config =
                StoreConfig::from_config(&config, CacheKey::label_layer(layer), Some(graph.size()));

            info!("  storing labels on disk");
            // Construct and persist the layer data.
            let layer_store: DiskStore<<Tree::Hasher as Hasher>::Domain> =
                DiskStore::new_from_slice_with_config(
                    graph.size(),
                    Tree::Arity::to_usize(),
                    &labels_buffer[..layer_size],
                    layer_config.clone(),
                )?;
            info!(
                "  generated layer {} store with id {}",
                layer, layer_config.id
            );

            // Track the layer specific store and StoreConfig for later retrieval.
            labels.push(layer_store);
            label_configs.push(layer_config);
        }

        assert_eq!(
            labels.len(),
            layers,
            "Invalid amount of layers encoded expected"
        );

        Ok((
            LabelsCache::<Tree> { labels },
            Labels::<Tree> {
                labels: label_configs,
                _h: PhantomData,
            },
        ))
    }

    fn build_binary_tree<K: Hasher>(
        tree_data: &[u8],
        config: StoreConfig,
    ) -> Result<BinaryMerkleTree<K>> {
        trace!("building tree (size: {})", tree_data.len());

        let leafs = tree_data.len() / NODE_SIZE;
        assert_eq!(tree_data.len() % NODE_SIZE, 0);

        let tree = MerkleTree::from_par_iter_with_config(
            (0..leafs)
                .into_par_iter()
                // TODO: proper error handling instead of `unwrap()`
                .map(|i| get_node::<K>(tree_data, i).unwrap()),
            config,
        )?;
        Ok(tree)
    }

    fn generate_tree_c<ColumnArity, TreeArity>(
        layers: usize,
        nodes_count: usize,
        tree_count: usize,
        configs: Vec<StoreConfig>,
        labels: &LabelsCache<Tree>,
    ) -> Result<DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>
    where
        ColumnArity: PoseidonArity,
        TreeArity: PoseidonArity,
    {
        if settings::SETTINGS.lock().unwrap().use_gpu_column_builder {
            Self::generate_tree_c_gpu::<ColumnArity, TreeArity>(
                layers,
                nodes_count,
                tree_count,
                configs,
                labels,
            )
        } else {
            Self::generate_tree_c_cpu::<ColumnArity, TreeArity>(
                layers,
                nodes_count,
                tree_count,
                configs,
                labels,
            )
        }
    }

    fn generate_tree_c_gpu<ColumnArity, TreeArity>(
        layers: usize,
        nodes_count: usize,
        tree_count: usize,
        configs: Vec<StoreConfig>,
        labels: &LabelsCache<Tree>,
    ) -> Result<DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>
    where
        ColumnArity: PoseidonArity,
        TreeArity: PoseidonArity,
    {
        info!("generating tree c using the GPU");
        // Build the tree for CommC
        measure_op(GenerateTreeC, || {
            info!("Building column hashes");

            // NOTE: The max number of columns we recommend sending to
            // the GPU at once is 400000 for columns and 700000 for
            // trees (conservative soft-limits discussed).
            //
            // Override these values with care using environment
            // variables: FIL_PROOFS_MAX_COLUMN_BATCH_SIZE and
            // FIL_PROOFS_MAX_TREE_BATCH_SIZE, respectively.
            let max_gpu_column_batch_size =
                settings::SETTINGS.lock().unwrap().max_gpu_column_batch_size as usize;
            let max_gpu_tree_batch_size =
                settings::SETTINGS.lock().unwrap().max_gpu_tree_batch_size as usize;

            let mut column_tree_builder = ColumnTreeBuilder::<ColumnArity, TreeArity>::new(
                Some(BatcherType::GPU),
                nodes_count,
                max_gpu_column_batch_size,
                max_gpu_tree_batch_size,
            )?;

            for (i, config) in configs.iter().enumerate() {
                let mut node_index = 0;
                while node_index != nodes_count {
                    let chunked_nodes_count =
                        std::cmp::min(nodes_count - node_index, max_gpu_column_batch_size);
                    trace!(
                        "processing config {}/{} with column nodes {}",
                        i + 1,
                        tree_count,
                        chunked_nodes_count,
                    );
                    let mut columns: Vec<GenericArray<Fr, ColumnArity>> =
                        vec![
                            GenericArray::<Fr, ColumnArity>::generate(|_i: usize| Fr::zero());
                            chunked_nodes_count
                        ];

                    rayon::scope(|s| {
                        let n = num_cpus::get();

                        // only split if we have at least two elements per thread
                        let num_chunks = if n > chunked_nodes_count * 2 { 1 } else { n };

                        // chunk into n chunks
                        let chunk_size =
                            (chunked_nodes_count as f64 / num_chunks as f64).ceil() as usize;

                        // gather all n chunks in parallel
                        for (chunk, columns_chunk) in columns.chunks_mut(chunk_size).enumerate() {
                            let labels = &labels;

                            s.spawn(move |_| {
                                for (j, hash) in columns_chunk.iter_mut().enumerate() {
                                    for k in 1..=layers {
                                        let store = labels.labels_for_layer(k);
                                        let el: <Tree::Hasher as Hasher>::Domain = store
                                            .read_at(
                                                (i * nodes_count)
                                                    + node_index
                                                    + j
                                                    + chunk * chunk_size,
                                            )
                                            .unwrap();

                                        hash[k - 1] = el.into();
                                    }
                                }
                            });
                        }
                    });

                    node_index += chunked_nodes_count;
                    trace!(
                        "node index {}/{}/{}",
                        node_index,
                        chunked_nodes_count,
                        nodes_count,
                    );

                    if node_index != nodes_count {
                        column_tree_builder.add_columns(&columns)?;
                    } else {
                        assert_eq!(node_index, nodes_count);
                        let tree_data = column_tree_builder.add_final_columns(&columns)?;
                        let tree_data_len = tree_data.len();
                        info!(
                            "persisting base tree_c {}/{} of length {}",
                            i + 1,
                            tree_count,
                            tree_data_len
                        );
                        assert_eq!(tree_data_len, config.size.unwrap());

                        let flat_tree_data: Vec<_> = tree_data
                            .into_par_iter()
                            .flat_map(|el| fr_into_bytes(&el))
                            .collect();

                        // Persist the data to the store based on the current config.
                        DiskStore::<<Tree::Hasher as Hasher>::Domain>::new_from_slice_with_config(
                            tree_data_len,
                            Tree::Arity::to_usize(),
                            &flat_tree_data[..],
                            config.clone(),
                        )?;
                    }
                }
            }

            create_disk_tree::<
                DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
            >(configs[0].size.unwrap(), &configs)
        })
    }

    fn generate_tree_c_cpu<ColumnArity, TreeArity>(
        layers: usize,
        nodes_count: usize,
        tree_count: usize,
        configs: Vec<StoreConfig>,
        labels: &LabelsCache<Tree>,
    ) -> Result<DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>
    where
        ColumnArity: PoseidonArity,
        TreeArity: PoseidonArity,
    {
        info!("generating tree c using the CPU");
        measure_op(GenerateTreeC, || {
            info!("Building column hashes");

            let mut trees = Vec::with_capacity(tree_count);
            for (i, config) in configs.iter().enumerate() {
                let mut hashes: Vec<<Tree::Hasher as Hasher>::Domain> =
                    vec![<Tree::Hasher as Hasher>::Domain::default(); nodes_count];

                rayon::scope(|s| {
                    let n = num_cpus::get();

                    // only split if we have at least two elements per thread
                    let num_chunks = if n > nodes_count * 2 { 1 } else { n };

                    // chunk into n chunks
                    let chunk_size = (nodes_count as f64 / num_chunks as f64).ceil() as usize;

                    // calculate all n chunks in parallel
                    for (chunk, hashes_chunk) in hashes.chunks_mut(chunk_size).enumerate() {
                        let labels = &labels;

                        s.spawn(move |_| {
                            for (j, hash) in hashes_chunk.iter_mut().enumerate() {
                                let data: Vec<_> = (1..=layers)
                                    .map(|layer| {
                                        let store = labels.labels_for_layer(layer);
                                        let el: <Tree::Hasher as Hasher>::Domain = store
                                            .read_at((i * nodes_count) + j + chunk * chunk_size)
                                            .unwrap();
                                        el.into()
                                    })
                                    .collect();

                                *hash = hash_single_column(&data).into();
                            }
                        });
                    }
                });

                info!("building base tree_c {}/{}", i + 1, tree_count);
                trees.push(DiskTree::<
                    Tree::Hasher,
                    Tree::Arity,
                    typenum::U0,
                    typenum::U0,
                >::from_par_iter_with_config(
                    hashes.into_par_iter(), config.clone()
                ));
            }

            assert_eq!(tree_count, trees.len());
            create_disk_tree::<
                DiskTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
            >(configs[0].size.unwrap(), &configs)
        })
    }

    pub(crate) fn transform_and_replicate_layers(
        graph: &StackedBucketGraph<Tree::Hasher>,
        layer_challenges: &LayerChallenges,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        data: Data,
        data_tree: Option<BinaryMerkleTree<G>>,
        config: StoreConfig,
        replica_path: PathBuf,
    ) -> Result<TransformedLayers<Tree, G>> {
        // Generate key layers.
        let (_, labels) = measure_op(EncodeWindowTimeAll, || {
            Self::generate_labels(graph, layer_challenges, replica_id, config.clone())
        })?;

        Self::transform_and_replicate_layers_inner(
            graph,
            layer_challenges,
            data,
            data_tree,
            config,
            replica_path,
            labels,
        )
    }

    pub(crate) fn transform_and_replicate_layers_inner(
        graph: &StackedBucketGraph<Tree::Hasher>,
        layer_challenges: &LayerChallenges,
        mut data: Data,
        data_tree: Option<BinaryMerkleTree<G>>,
        config: StoreConfig,
        replica_path: PathBuf,
        label_configs: Labels<Tree>,
    ) -> Result<TransformedLayers<Tree, G>> {
        trace!("transform_and_replicate_layers");
        let nodes_count = graph.size();

        assert_eq!(data.len(), nodes_count * NODE_SIZE);
        trace!("nodes count {}, data len {}", nodes_count, data.len());

        let tree_count = get_base_tree_count::<Tree>();
        let nodes_count = graph.size() / tree_count;

        // Ensure that the node count will work for binary and oct arities.
        let binary_arity_valid = is_merkle_tree_size_valid(nodes_count, BINARY_ARITY);
        let other_arity_valid = is_merkle_tree_size_valid(nodes_count, Tree::Arity::to_usize());
        trace!(
            "is_merkle_tree_size_valid({}, BINARY_ARITY) = {}",
            nodes_count,
            binary_arity_valid
        );
        trace!(
            "is_merkle_tree_size_valid({}, {}) = {}",
            nodes_count,
            Tree::Arity::to_usize(),
            other_arity_valid
        );
        assert!(binary_arity_valid);
        assert!(other_arity_valid);

        let layers = layer_challenges.layers();
        assert!(layers > 0);

        // Generate all store configs that we need based on the
        // cache_path in the specified config.
        let mut tree_d_config = StoreConfig::from_config(
            &config,
            CacheKey::CommDTree.to_string(),
            Some(get_merkle_tree_len(nodes_count, BINARY_ARITY)?),
        );
        tree_d_config.rows_to_discard =
            StoreConfig::default_rows_to_discard(nodes_count, BINARY_ARITY);

        let mut tree_r_last_config = StoreConfig::from_config(
            &config,
            CacheKey::CommRLastTree.to_string(),
            Some(get_merkle_tree_len(nodes_count, Tree::Arity::to_usize())?),
        );

        // A default 'rows_to_discard' value will be chosen for
        // tree_r_last, unless the user overrides this value via the
        // environment setting (FIL_PROOFS_ROWS_TO_DISCARD).  If this
        // value is specified, no checking is done on it and it may
        // result in a broken configuration.  Use with caution.
        let env_rows_to_discard = settings::SETTINGS.lock().unwrap().rows_to_discard as usize;
        tree_r_last_config.rows_to_discard = if env_rows_to_discard != 0 {
            env_rows_to_discard
        } else {
            StoreConfig::default_rows_to_discard(nodes_count, Tree::Arity::to_usize())
        };

        let mut tree_c_config = StoreConfig::from_config(
            &config,
            CacheKey::CommCTree.to_string(),
            Some(get_merkle_tree_len(nodes_count, Tree::Arity::to_usize())?),
        );
        tree_c_config.rows_to_discard =
            StoreConfig::default_rows_to_discard(nodes_count, Tree::Arity::to_usize());

        let labels = LabelsCache::<Tree>::new(&label_configs)?;
        let configs = split_config(tree_c_config.clone(), tree_count)?;

        let tree_c_root = match layers {
            2 => {
                let tree_c = Self::generate_tree_c::<U2, Tree::Arity>(
                    layers,
                    nodes_count,
                    tree_count,
                    configs,
                    &labels,
                )?;
                tree_c.root()
            }
            8 => {
                let tree_c = Self::generate_tree_c::<U8, Tree::Arity>(
                    layers,
                    nodes_count,
                    tree_count,
                    configs,
                    &labels,
                )?;
                tree_c.root()
            }
            11 => {
                let tree_c = Self::generate_tree_c::<U11, Tree::Arity>(
                    layers,
                    nodes_count,
                    tree_count,
                    configs,
                    &labels,
                )?;
                tree_c.root()
            }
            _ => panic!("Unsupported column arity"),
        };
        info!("tree_c done");

        // Build the MerkleTree over the original data (if needed).
        let tree_d = match data_tree {
            Some(t) => {
                trace!("using existing original data merkle tree");
                assert_eq!(t.len(), 2 * (data.len() / NODE_SIZE) - 1);

                t
            }
            None => {
                trace!("building merkle tree for the original data");
                data.ensure_data()?;
                measure_op(CommD, || {
                    Self::build_binary_tree::<G>(data.as_ref(), tree_d_config.clone())
                })?
            }
        };
        tree_d_config.size = Some(tree_d.len());
        assert_eq!(tree_d_config.size.unwrap(), tree_d.len());
        let tree_d_root = tree_d.root();
        drop(tree_d);

        // Encode original data into the last layer.
        info!("building tree_r_last");
        let (configs, replica_config) = split_config_and_replica(
            tree_r_last_config.clone(),
            replica_path,
            nodes_count,
            tree_count,
        )?;

        let tree_r_last = measure_op(GenerateTreeRLast, || {
            data.ensure_data()?;

            let last_layer_labels = labels.labels_for_last_layer()?;
            let size = Store::len(last_layer_labels);

            let mut trees = Vec::with_capacity(tree_count);
            let mut start = 0;
            let mut end = size / tree_count;

            for (i, config) in configs.iter().enumerate() {
                let encoded_data = last_layer_labels
                    .read_range(start..end)?
                    .into_par_iter()
                    .zip(
                        data.as_mut()[(start * NODE_SIZE)..(end * NODE_SIZE)]
                            .par_chunks_mut(NODE_SIZE),
                    )
                    .map(|(key, data_node_bytes)| {
                        let data_node =
                            <Tree::Hasher as Hasher>::Domain::try_from_bytes(data_node_bytes)
                                .unwrap();
                        let encoded_node =
                            encode::<<Tree::Hasher as Hasher>::Domain>(key, data_node);
                        data_node_bytes.copy_from_slice(AsRef::<[u8]>::as_ref(&encoded_node));

                        encoded_node
                    });

                info!("building base tree_r_last {}/{}", i + 1, tree_count);
                trees.push(LCTree::<Tree::Hasher, Tree::Arity, typenum::U0, typenum::U0>::from_par_iter_with_config(encoded_data, config.clone())?);

                start = end;
                end += size / tree_count;
            }

            assert_eq!(tree_count, trees.len());

            create_lc_tree::<
                LCTree<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>,
            >(tree_r_last_config.size.unwrap(), &configs, &replica_config)
        })?;
        info!("tree_r_last done");

        let tree_r_last_root = tree_r_last.root();
        drop(tree_r_last);

        data.drop_data();

        // comm_r = H(comm_c || comm_r_last)
        let comm_r: <Tree::Hasher as Hasher>::Domain =
            <Tree::Hasher as Hasher>::Function::hash2(&tree_c_root, &tree_r_last_root);

        Ok((
            Tau {
                comm_d: tree_d_root,
                comm_r,
            },
            PersistentAux {
                comm_c: tree_c_root,
                comm_r_last: tree_r_last_root,
            },
            TemporaryAux {
                labels: label_configs,
                tree_d_config,
                tree_r_last_config,
                tree_c_config,
                _g: PhantomData,
            },
        ))
    }

    /// Phase1 of replication.
    pub fn replicate_phase1(
        pp: &'a PublicParams<Tree>,
        replica_id: &<Tree::Hasher as Hasher>::Domain,
        config: StoreConfig,
    ) -> Result<Labels<Tree>> {
        info!("replicate_phase1");

        let (_, labels) = measure_op(EncodeWindowTimeAll, || {
            Self::generate_labels(&pp.graph, &pp.layer_challenges, replica_id, config)
        })?;

        Ok(labels)
    }

    #[allow(clippy::type_complexity)]
    /// Phase2 of replication.
    #[allow(clippy::type_complexity)]
    pub fn replicate_phase2(
        pp: &'a PublicParams<Tree>,
        labels: Labels<Tree>,
        data: Data<'a>,
        data_tree: BinaryMerkleTree<G>,
        config: StoreConfig,
        replica_path: PathBuf,
    ) -> Result<(
        <Self as PoRep<'a, Tree::Hasher, G>>::Tau,
        <Self as PoRep<'a, Tree::Hasher, G>>::ProverAux,
    )> {
        info!("replicate_phase2");

        let (tau, paux, taux) = Self::transform_and_replicate_layers_inner(
            &pp.graph,
            &pp.layer_challenges,
            data,
            Some(data_tree),
            config,
            replica_path,
            labels,
        )?;

        Ok((tau, (paux, taux)))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use paired::bls12_381::Fr;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        drgraph::{new_seed, BASE_DEGREE},
        fr32::fr_into_bytes,
        hasher::{Blake2sHasher, PedersenHasher, PoseidonHasher, Sha256Hasher},
        merkle::MerkleTreeTrait,
        proof::ProofScheme,
        table_tests,
        test_helper::setup_replica,
    };

    use crate::stacked::{PrivateInputs, SetupParams, EXP_DEGREE};
    use crate::PoRep;

    const DEFAULT_STACKED_LAYERS: usize = 11;

    #[test]
    fn test_calculate_fixed_challenges() {
        let layer_challenges = LayerChallenges::new(10, 333);
        let expected = 333;

        let calculated_count = layer_challenges.challenges_count_all();
        assert_eq!(expected as usize, calculated_count);
    }

    #[test]
    fn extract_all_pedersen_8() {
        test_extract_all::<DiskTree<PedersenHasher, typenum::U8, typenum::U0, typenum::U0>>();
    }

    #[test]
    fn extract_all_pedersen_8_2() {
        test_extract_all::<DiskTree<PedersenHasher, typenum::U8, typenum::U2, typenum::U0>>();
    }

    #[test]
    fn extract_all_pedersen_8_8_2() {
        test_extract_all::<DiskTree<PedersenHasher, typenum::U8, typenum::U8, typenum::U2>>();
    }

    #[test]
    fn extract_all_sha256_8() {
        test_extract_all::<DiskTree<Sha256Hasher, typenum::U8, typenum::U0, typenum::U0>>();
    }

    #[test]
    fn extract_all_sha256_8_8() {
        test_extract_all::<DiskTree<Sha256Hasher, typenum::U8, typenum::U8, typenum::U0>>();
    }

    #[test]
    fn extract_all_sha256_8_8_2() {
        test_extract_all::<DiskTree<Sha256Hasher, typenum::U8, typenum::U8, typenum::U2>>();
    }

    #[test]
    fn extract_all_blake2s_8() {
        test_extract_all::<DiskTree<Blake2sHasher, typenum::U8, typenum::U0, typenum::U0>>();
    }

    #[test]
    fn extract_all_blake2s_8_8() {
        test_extract_all::<DiskTree<Blake2sHasher, typenum::U8, typenum::U8, typenum::U0>>();
    }

    #[test]
    fn extract_all_blake2s_8_8_2() {
        test_extract_all::<DiskTree<Blake2sHasher, typenum::U8, typenum::U8, typenum::U2>>();
    }

    #[test]
    fn extract_all_poseidon_8() {
        test_extract_all::<DiskTree<PoseidonHasher, typenum::U8, typenum::U0, typenum::U0>>();
    }

    #[test]
    fn extract_all_poseidon_8_2() {
        test_extract_all::<DiskTree<PoseidonHasher, typenum::U8, typenum::U2, typenum::U0>>();
    }

    #[test]
    fn extract_all_poseidon_8_8_2() {
        test_extract_all::<DiskTree<PoseidonHasher, typenum::U8, typenum::U8, typenum::U2>>();
    }

    fn test_extract_all<Tree: 'static + MerkleTreeTrait>() {
        // femme::pretty::Logger::new()
        //     .start(log::LevelFilter::Trace)
        //     .ok();

        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);
        let replica_id: <Tree::Hasher as Hasher>::Domain =
            <Tree::Hasher as Hasher>::Domain::random(rng);
        let nodes = 64 * get_base_tree_count::<Tree>();

        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| {
                let v: <Tree::Hasher as Hasher>::Domain =
                    <Tree::Hasher as Hasher>::Domain::random(rng);
                v.into_bytes()
            })
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let challenges = LayerChallenges::new(DEFAULT_STACKED_LAYERS, 5);

        let sp = SetupParams {
            nodes,
            degree: BASE_DEGREE,
            expansion_degree: EXP_DEGREE,
            seed: new_seed(),
            layer_challenges: challenges.clone(),
        };

        let pp = StackedDrg::<Tree, Blake2sHasher>::setup(&sp).expect("setup failed");

        StackedDrg::<Tree, Blake2sHasher>::replicate(
            &pp,
            &replica_id,
            (mmapped_data.as_mut()).into(),
            None,
            config.clone(),
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        let decoded_data = StackedDrg::<Tree, Blake2sHasher>::extract_all(
            &pp,
            &replica_id,
            mmapped_data.as_mut(),
            Some(config.clone()),
        )
        .expect("failed to extract data");

        assert_eq!(data, decoded_data);

        cache_dir.close().expect("Failed to remove cache dir");
    }

    fn prove_verify_fixed(n: usize) {
        let challenges = LayerChallenges::new(DEFAULT_STACKED_LAYERS, 5);

        test_prove_verify::<DiskTree<PedersenHasher, typenum::U4, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PedersenHasher, typenum::U4, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PedersenHasher, typenum::U4, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<PedersenHasher, typenum::U8, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PedersenHasher, typenum::U8, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PedersenHasher, typenum::U8, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U8, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U8, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U8, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U4, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U4, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Sha256Hasher, typenum::U4, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U4, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U4, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U4, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U8, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U8, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<Blake2sHasher, typenum::U8, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U4, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U4, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U4, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );

        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U8, typenum::U0, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U8, typenum::U2, typenum::U0>>(
            n,
            challenges.clone(),
        );
        test_prove_verify::<DiskTree<PoseidonHasher, typenum::U8, typenum::U8, typenum::U2>>(
            n,
            challenges.clone(),
        );
    }

    fn test_prove_verify<Tree: 'static + MerkleTreeTrait>(n: usize, challenges: LayerChallenges) {
        // This will be called multiple times, only the first one succeeds, and that is ok.
        // femme::pretty::Logger::new()
        //     .start(log::LevelFilter::Trace)
        //     .ok();

        let nodes = n * get_base_tree_count::<Tree>();
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let degree = BASE_DEGREE;
        let expansion_degree = EXP_DEGREE;
        let replica_id: <Tree::Hasher as Hasher>::Domain =
            <Tree::Hasher as Hasher>::Domain::random(rng);
        let data: Vec<u8> = (0..nodes)
            .flat_map(|_| fr_into_bytes(&Fr::random(rng)))
            .collect();

        // MT for original data is always named tree-d, and it will be
        // referenced later in the process as such.
        let cache_dir = tempfile::tempdir().unwrap();
        let config = StoreConfig::new(
            cache_dir.path(),
            CacheKey::CommDTree.to_string(),
            StoreConfig::default_rows_to_discard(nodes, BINARY_ARITY),
        );

        // Generate a replica path.
        let replica_path = cache_dir.path().join("replica-path");
        let mut mmapped_data = setup_replica(&data, &replica_path);

        let partitions = 2;

        let sp = SetupParams {
            nodes,
            degree,
            expansion_degree,
            seed: new_seed(),
            layer_challenges: challenges.clone(),
        };

        let pp = StackedDrg::<Tree, Blake2sHasher>::setup(&sp).expect("setup failed");
        let (tau, (p_aux, t_aux)) = StackedDrg::<Tree, Blake2sHasher>::replicate(
            &pp,
            &replica_id,
            (mmapped_data.as_mut()).into(),
            None,
            config,
            replica_path.clone(),
        )
        .expect("replication failed");

        let mut copied = vec![0; data.len()];
        copied.copy_from_slice(&mmapped_data);
        assert_ne!(data, copied, "replication did not change data");

        let seed = rng.gen();

        let pub_inputs =
            PublicInputs::<<Tree::Hasher as Hasher>::Domain, <Blake2sHasher as Hasher>::Domain> {
                replica_id,
                seed,
                tau: Some(tau),
                k: None,
            };

        // Store a copy of the t_aux for later resource deletion.
        let t_aux_orig = t_aux.clone();

        // Convert TemporaryAux to TemporaryAuxCache, which instantiates all
        // elements based on the configs stored in TemporaryAux.
        let t_aux = TemporaryAuxCache::<Tree, Blake2sHasher>::new(&t_aux, replica_path)
            .expect("failed to restore contents of t_aux");

        let priv_inputs = PrivateInputs { p_aux, t_aux };

        let all_partition_proofs = &StackedDrg::<Tree, Blake2sHasher>::prove_all_partitions(
            &pp,
            &pub_inputs,
            &priv_inputs,
            partitions,
        )
        .expect("failed to generate partition proofs");

        let proofs_are_valid = StackedDrg::<Tree, Blake2sHasher>::verify_all_partitions(
            &pp,
            &pub_inputs,
            all_partition_proofs,
        )
        .expect("failed to verify partition proofs");

        // Discard cached MTs that are no longer needed.
        TemporaryAux::<Tree, Blake2sHasher>::clear_temp(t_aux_orig).expect("t_aux delete failed");

        assert!(proofs_are_valid);

        cache_dir.close().expect("Failed to remove cache dir");
    }

    table_tests! {
        prove_verify_fixed {
           prove_verify_fixed_64_64(64);
        }
    }

    #[test]
    // We are seeing a bug, in which setup never terminates for some sector sizes.
    // This test is to debug that and should remain as a regression teset.
    fn setup_terminates() {
        let degree = BASE_DEGREE;
        let expansion_degree = EXP_DEGREE;
        let nodes = 1024 * 1024 * 32 * 8; // This corresponds to 8GiB sectors (32-byte nodes)
        let layer_challenges = LayerChallenges::new(10, 333);
        let sp = SetupParams {
            nodes,
            degree,
            expansion_degree,
            seed: new_seed(),
            layer_challenges: layer_challenges.clone(),
        };

        // When this fails, the call to setup should panic, but seems to actually hang (i.e. neither return nor panic) for some reason.
        // When working as designed, the call to setup returns without error.
        let _pp = StackedDrg::<
            DiskTree<PedersenHasher, typenum::U8, typenum::U0, typenum::U0>,
            Blake2sHasher,
        >::setup(&sp)
        .expect("setup failed");
    }
}

'''
'''--- storage-proofs/porep/src/stacked/vanilla/proof_scheme.rs ---
use anyhow::ensure;
use log::trace;
use rayon::prelude::*;
use storage_proofs_core::{
    drgraph::Graph,
    error::Result,
    hasher::{HashFunction, Hasher},
    merkle::MerkleTreeTrait,
    proof::ProofScheme,
};

use super::{
    challenges::ChallengeRequirements,
    graph::StackedBucketGraph,
    params::{PrivateInputs, Proof, PublicInputs, PublicParams, SetupParams},
    proof::StackedDrg,
};

impl<'a, 'c, Tree: 'static + MerkleTreeTrait, G: 'static + Hasher> ProofScheme<'a>
    for StackedDrg<'c, Tree, G>
{
    type PublicParams = PublicParams<Tree>;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<<Tree::Hasher as Hasher>::Domain, <G as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<Tree, G>;
    type Proof = Vec<Proof<Tree, G>>;
    type Requirements = ChallengeRequirements;

    fn setup(sp: &Self::SetupParams) -> Result<Self::PublicParams> {
        let graph = StackedBucketGraph::<Tree::Hasher>::new_stacked(
            sp.nodes,
            sp.degree,
            sp.expansion_degree,
            sp.seed,
        )?;

        Ok(PublicParams::new(graph, sp.layer_challenges.clone()))
    }

    fn prove<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        let proofs = Self::prove_all_partitions(pub_params, pub_inputs, priv_inputs, 1)?;
        let k = match pub_inputs.k {
            None => 0,
            Some(k) => k,
        };
        // Because partition proofs require a common setup, the general ProofScheme implementation,
        // which makes use of `ProofScheme::prove` cannot be used here. Instead, we need to prove all
        // partitions in one pass, as implemented by `prove_all_partitions` below.
        assert!(
            k < 1,
            "It is a programmer error to call StackedDrg::prove with more than one partition."
        );

        Ok(proofs[k].to_owned())
    }

    fn prove_all_partitions<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
        partition_count: usize,
    ) -> Result<Vec<Self::Proof>> {
        trace!("prove_all_partitions");
        ensure!(partition_count > 0, "partitions must not be 0");

        Self::prove_layers(
            &pub_params.graph,
            pub_inputs,
            &priv_inputs.p_aux,
            &priv_inputs.t_aux,
            &pub_params.layer_challenges,
            pub_params.layer_challenges.layers(),
            pub_params.layer_challenges.layers(),
            partition_count,
        )
    }

    fn verify_all_partitions(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        partition_proofs: &[Self::Proof],
    ) -> Result<bool> {
        trace!("verify_all_partitions");

        // generate graphs
        let graph = &pub_params.graph;

        let expected_comm_r = if let Some(ref tau) = pub_inputs.tau {
            &tau.comm_r
        } else {
            return Ok(false);
        };

        let res = partition_proofs.par_iter().enumerate().all(|(k, proofs)| {
            trace!(
                "verifying partition proof {}/{}",
                k + 1,
                partition_proofs.len()
            );

            trace!("verify comm_r");
            let actual_comm_r: <Tree::Hasher as Hasher>::Domain = {
                let comm_c = proofs[0].comm_c();
                let comm_r_last = proofs[0].comm_r_last();
                <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last)
            };

            if expected_comm_r != &actual_comm_r {
                return false;
            }

            let challenges =
                pub_inputs.challenges(&pub_params.layer_challenges, graph.size(), Some(k));

            proofs.par_iter().enumerate().all(|(i, proof)| {
                trace!("verify challenge {}/{}", i + 1, challenges.len());

                // Validate for this challenge
                let challenge = challenges[i];

                // make sure all proofs have the same comm_c
                if proof.comm_c() != proofs[0].comm_c() {
                    return false;
                }
                // make sure all proofs have the same comm_r_last
                if proof.comm_r_last() != proofs[0].comm_r_last() {
                    return false;
                }

                proof.verify(pub_params, pub_inputs, challenge, graph)
            })
        });

        Ok(res)
    }

    fn with_partition(pub_in: Self::PublicInputs, k: Option<usize>) -> Self::PublicInputs {
        self::PublicInputs {
            replica_id: pub_in.replica_id,
            seed: pub_in.seed,
            tau: pub_in.tau,
            k,
        }
    }

    fn satisfies_requirements(
        public_params: &PublicParams<Tree>,
        requirements: &ChallengeRequirements,
        partitions: usize,
    ) -> bool {
        let partition_challenges = public_params.layer_challenges.challenges_count_all();

        partition_challenges * partitions >= requirements.minimum_challenges
    }
}

'''
'''--- storage-proofs/post/Cargo.toml ---
[package]
name = "storage-proofs-post"
version = "2.0.0"
authors = ["dignifiedquire <me@dignifiedquire.com>"]
license = "MIT OR Apache-2.0"
description = "Proofs of Space Time"
edition = "2018"
repository = "https://github.com/filecoin-project/rust-fil-proofs"
readme = "README.md"

[dependencies]
storage-proofs-core = { path = "../core", version = "2.0.0" }
rand = "0.7"
merkletree = "0.20.0"
byteorder = "1"
sha2 = { version = "0.8.3", package = "sha2ni" }
rayon = "1.0.0"
serde = { version = "1.0", features = ["derive"]}
blake2b_simd = "0.5"
blake2s_simd = "0.5"
ff = { version = "0.2.1", package = "fff" }
bellperson = "0.8.0"
paired = { version = "0.19.0", features = ["serde"] }
fil-sapling-crypto = "0.6.0"
log = "0.4.7"
hex = "0.4.0"
generic-array = "0.13.2"
anyhow = "1.0.23"
neptune = { version = "0.7.1", features = ["gpu"] }

[dev-dependencies]
tempdir = "0.3.7"
tempfile = "3"
pretty_assertions = "0.6.1"
rand_xorshift = "0.2.0"

'''
'''--- storage-proofs/post/README.md ---
# Storage Proofs PoSt

## License

MIT or Apache 2.0

'''
'''--- storage-proofs/post/src/election/circuit.rs ---
use std::marker::PhantomData;

use bellperson::gadgets::num;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use ff::Field;
use generic_array::typenum;
use paired::bls12_381::{Bls12, Fr};
use typenum::marker_traits::Unsigned;

use storage_proofs_core::{
    compound_proof::CircuitComponent,
    gadgets::constraint,
    gadgets::por::PoRCircuit,
    gadgets::variables::Root,
    hasher::{HashFunction, Hasher, PoseidonFunction, PoseidonMDArity},
    merkle::MerkleTreeTrait,
};

/// This is the `ElectionPoSt` circuit.
pub struct ElectionPoStCircuit<Tree: MerkleTreeTrait> {
    pub comm_r: Option<Fr>,
    pub comm_c: Option<Fr>,
    pub comm_r_last: Option<Fr>,
    pub leafs: Vec<Option<Fr>>,
    #[allow(clippy::type_complexity)]
    pub paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
    pub partial_ticket: Option<Fr>,
    pub randomness: Option<Fr>,
    pub prover_id: Option<Fr>,
    pub sector_id: Option<Fr>,
    pub _t: PhantomData<Tree>,
}

#[derive(Clone, Default)]
pub struct ComponentPrivateInputs {}

impl<'a, Tree: MerkleTreeTrait> CircuitComponent for ElectionPoStCircuit<Tree> {
    type ComponentPrivateInputs = ComponentPrivateInputs;
}

impl<'a, Tree: 'static + MerkleTreeTrait> Circuit<Bls12> for ElectionPoStCircuit<Tree> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let comm_r = self.comm_r;
        let comm_c = self.comm_c;
        let comm_r_last = self.comm_r_last;
        let leafs = self.leafs;
        let paths = self.paths;
        let partial_ticket = self.partial_ticket;
        let randomness = self.randomness;
        let prover_id = self.prover_id;
        let sector_id = self.sector_id;

        assert_eq!(paths.len(), leafs.len());

        // 1. Verify comm_r

        let comm_r_last_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r_last"), || {
            comm_r_last
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        let comm_c_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_c"), || {
            comm_c
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        let comm_r_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r"), || {
            comm_r
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        comm_r_num.inputize(cs.namespace(|| "comm_r_input"))?;

        // Verify H(Comm_C || comm_r_last) == comm_r
        {
            let hash_num = <Tree::Hasher as Hasher>::Function::hash2_circuit(
                cs.namespace(|| "H_comm_c_comm_r_last"),
                &comm_c_num,
                &comm_r_last_num,
            )?;

            // Check actual equality
            constraint::equal(
                cs,
                || "enforce_comm_c_comm_r_last_hash_comm_r",
                &comm_r_num,
                &hash_num,
            );
        }

        // 2. Verify Inclusion Paths
        for (i, (leaf, path)) in leafs.iter().zip(paths.iter()).enumerate() {
            PoRCircuit::<Tree>::synthesize(
                cs.namespace(|| format!("challenge_inclusion{}", i)),
                Root::Val(*leaf),
                path.clone().into(),
                Root::from_allocated::<CS>(comm_r_last_num.clone()),
                true,
            )?;
        }

        // 3. Verify partial ticket

        // randomness
        let randomness_num = num::AllocatedNum::alloc(cs.namespace(|| "randomness"), || {
            randomness
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // prover_id
        let prover_id_num = num::AllocatedNum::alloc(cs.namespace(|| "prover_id"), || {
            prover_id
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        // sector_id
        let sector_id_num = num::AllocatedNum::alloc(cs.namespace(|| "sector_id"), || {
            sector_id
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        let mut partial_ticket_nums = vec![randomness_num, prover_id_num, sector_id_num];
        for (i, leaf) in leafs.iter().enumerate() {
            let leaf_num =
                num::AllocatedNum::alloc(cs.namespace(|| format!("leaf_{}", i)), || {
                    leaf.map(Into::into)
                        .ok_or_else(|| SynthesisError::AssignmentMissing)
                })?;
            partial_ticket_nums.push(leaf_num);
        }

        // pad to a multiple of md arity
        let arity = PoseidonMDArity::to_usize();
        while partial_ticket_nums.len() % arity != 0 {
            partial_ticket_nums.push(num::AllocatedNum::alloc(
                cs.namespace(|| format!("padding_{}", partial_ticket_nums.len())),
                || Ok(Fr::zero()),
            )?);
        }

        // hash it
        let partial_ticket_num = PoseidonFunction::hash_md_circuit::<_>(
            &mut cs.namespace(|| "partial_ticket_hash"),
            &partial_ticket_nums,
        )?;

        // allocate expected input
        let expected_partial_ticket_num =
            num::AllocatedNum::alloc(cs.namespace(|| "partial_ticket"), || {
                partial_ticket
                    .map(Into::into)
                    .ok_or_else(|| SynthesisError::AssignmentMissing)
            })?;

        expected_partial_ticket_num.inputize(cs.namespace(|| "partial_ticket_input"))?;

        // check equality
        constraint::equal(
            cs,
            || "enforce partial_ticket is correct",
            &partial_ticket_num,
            &expected_partial_ticket_num,
        );

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use std::collections::BTreeMap;

    use ff::Field;
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        compound_proof::CompoundProof,
        gadgets::TestConstraintSystem,
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait},
        proof::ProofScheme,
        sector::SectorId,
        util::NODE_SIZE,
    };
    use typenum::{U0, U8};

    use crate::election::{self, ElectionPoSt, ElectionPoStCompound};

    #[test]
    fn test_election_post_circuit_pedersen() {
        test_election_post_circuit::<LCTree<PedersenHasher, U8, U0, U0>>(388_523);
    }

    #[test]
    fn test_election_post_circuit_poseidon() {
        test_election_post_circuit::<LCTree<PoseidonHasher, U8, U0, U0>>(23_066);
    }

    fn test_election_post_circuit<Tree: 'static + MerkleTreeTrait>(expected_constraints: usize) {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves * NODE_SIZE;

        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);

        let pub_params = election::PublicParams {
            sector_size: sector_size as u64,
            challenge_count: 20,
            challenged_nodes: 1,
        };

        let mut sectors: Vec<SectorId> = Vec::new();
        let mut trees = BTreeMap::new();

        // Construct and store an MT using a named store.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        for i in 0..5 {
            sectors.push(i.into());
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.insert(i.into(), tree);
        }

        let candidates = election::generate_candidates::<Tree>(
            &pub_params,
            &sectors,
            &trees,
            prover_id,
            randomness,
        )
        .unwrap();

        let candidate = &candidates[0];
        let tree = trees.remove(&candidate.sector_id).unwrap();
        let comm_r_last = tree.root();
        let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
        let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);

        let pub_inputs = election::PublicInputs {
            randomness,
            sector_id: candidate.sector_id,
            prover_id,
            comm_r,
            partial_ticket: candidate.partial_ticket,
            sector_challenge_index: 0,
        };

        let priv_inputs = election::PrivateInputs::<Tree> {
            tree,
            comm_c,
            comm_r_last,
        };

        let proof = ElectionPoSt::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
            .expect("proving failed");

        let is_valid = ElectionPoSt::<Tree>::verify(&pub_params, &pub_inputs, &proof)
            .expect("verification failed");
        assert!(is_valid);

        // actual circuit test

        let paths = proof
            .paths()
            .iter()
            .map(|p| {
                p.iter()
                    .map(|v| {
                        (
                            v.0.iter().copied().map(Into::into).map(Some).collect(),
                            Some(v.1),
                        )
                    })
                    .collect::<Vec<_>>()
            })
            .collect();
        let leafs: Vec<_> = proof.leafs().iter().map(|l| Some((*l).into())).collect();

        let mut cs = TestConstraintSystem::<Bls12>::new();

        let instance = ElectionPoStCircuit::<Tree> {
            leafs,
            paths,
            comm_r: Some(comm_r.into()),
            comm_c: Some(comm_c.into()),
            comm_r_last: Some(comm_r_last.into()),
            partial_ticket: Some(candidate.partial_ticket.into()),
            randomness: Some(randomness.into()),
            prover_id: Some(prover_id.into()),
            sector_id: Some(candidate.sector_id.into()),
            _t: PhantomData,
        };

        instance
            .synthesize(&mut cs)
            .expect("failed to synthesize circuit");

        assert!(cs.is_satisfied(), "constraints not satisfied");

        assert_eq!(cs.num_inputs(), 23, "wrong number of inputs");
        assert_eq!(
            cs.num_constraints(),
            expected_constraints,
            "wrong number of constraints"
        );
        assert_eq!(cs.get_input(0, "ONE"), Fr::one());

        let generated_inputs =
            ElectionPoStCompound::<Tree>::generate_public_inputs(&pub_inputs, &pub_params, None)
                .unwrap();
        let expected_inputs = cs.get_inputs();

        for ((input, label), generated_input) in
            expected_inputs.iter().skip(1).zip(generated_inputs.iter())
        {
            assert_eq!(input, generated_input, "{}", label);
        }

        assert_eq!(
            generated_inputs.len(),
            expected_inputs.len() - 1,
            "inputs are not the same length"
        );
    }
}

'''
'''--- storage-proofs/post/src/election/compound.rs ---
use std::marker::PhantomData;

use bellperson::Circuit;
use generic_array::typenum;
use paired::bls12_381::{Bls12, Fr};
use typenum::marker_traits::Unsigned;

use storage_proofs_core::{
    compound_proof::{CircuitComponent, CompoundProof},
    drgraph,
    error::Result,
    gadgets::por::PoRCompound,
    merkle::MerkleTreeTrait,
    parameter_cache::{CacheableParameters, ParameterSetMetadata},
    por,
    proof::ProofScheme,
    util::NODE_SIZE,
};

use crate::election::{self, ElectionPoSt, ElectionPoStCircuit};

pub struct ElectionPoStCompound<Tree>
where
    Tree: MerkleTreeTrait,
{
    _t: PhantomData<Tree>,
}

impl<C: Circuit<Bls12>, P: ParameterSetMetadata, Tree: MerkleTreeTrait> CacheableParameters<C, P>
    for ElectionPoStCompound<Tree>
{
    fn cache_prefix() -> String {
        format!("proof-of-spacetime-election-{}", Tree::display())
    }
}

impl<'a, Tree> CompoundProof<'a, ElectionPoSt<'a, Tree>, ElectionPoStCircuit<Tree>>
    for ElectionPoStCompound<Tree>
where
    Tree: 'static + MerkleTreeTrait,
{
    fn generate_public_inputs(
        pub_inputs: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        pub_params: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let mut inputs = Vec::new();

        let por_pub_params = por::PublicParams {
            leaves: (pub_params.sector_size as usize / NODE_SIZE),
            private: true,
        };

        // 1. Inputs for verifying comm_r = H(comm_c || comm_r_last)

        inputs.push(pub_inputs.comm_r.into());

        // 2. Inputs for verifying inclusion paths

        for n in 0..pub_params.challenge_count {
            let challenged_leaf_start = election::generate_leaf_challenge(
                &pub_params,
                pub_inputs.randomness,
                pub_inputs.sector_challenge_index,
                n as u64,
            )?;
            for i in 0..pub_params.challenged_nodes {
                let por_pub_inputs = por::PublicInputs {
                    commitment: None,
                    challenge: challenged_leaf_start as usize + i,
                };
                let por_inputs = PoRCompound::<Tree>::generate_public_inputs(
                    &por_pub_inputs,
                    &por_pub_params,
                    None,
                )?;

                inputs.extend(por_inputs);
            }
        }

        // 3. Inputs for verifying partial_ticket generation
        inputs.push(pub_inputs.partial_ticket);

        Ok(inputs)
    }

    fn circuit(
        pub_in: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        _priv_in: <ElectionPoStCircuit<Tree> as CircuitComponent>::ComponentPrivateInputs,
        vanilla_proof: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::Proof,
        _pub_params: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<ElectionPoStCircuit<Tree>> {
        let comm_r = pub_in.comm_r.into();
        let comm_c = vanilla_proof.comm_c.into();
        let comm_r_last = vanilla_proof.comm_r_last().into();

        let leafs: Vec<_> = vanilla_proof
            .leafs()
            .iter()
            .map(|c| Some((*c).into()))
            .collect();

        let paths: Vec<Vec<_>> = vanilla_proof
            .paths()
            .iter()
            .map(|v| {
                v.iter()
                    .map(|p| {
                        (
                            (*p).0.iter().copied().map(Into::into).map(Some).collect(),
                            Some(p.1),
                        )
                    })
                    .collect()
            })
            .collect();

        Ok(ElectionPoStCircuit {
            leafs,
            comm_r: Some(comm_r),
            comm_c: Some(comm_c),
            comm_r_last: Some(comm_r_last),
            paths,
            partial_ticket: Some(pub_in.partial_ticket),
            randomness: Some(pub_in.randomness.into()),
            prover_id: Some(pub_in.prover_id.into()),
            sector_id: Some(pub_in.sector_id.into()),
            _t: PhantomData,
        })
    }

    fn blank_circuit(
        pub_params: &<ElectionPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
    ) -> ElectionPoStCircuit<Tree> {
        let challenges_count = pub_params.challenged_nodes * pub_params.challenge_count;
        let height =
            drgraph::graph_height::<Tree::Arity>(pub_params.sector_size as usize / NODE_SIZE);

        let leafs = vec![None; challenges_count];
        let paths = vec![
            vec![(vec![None; Tree::Arity::to_usize() - 1], None); height - 1];
            challenges_count
        ];

        ElectionPoStCircuit {
            comm_r: None,
            comm_c: None,
            comm_r_last: None,
            partial_ticket: None,
            leafs,
            paths,
            randomness: None,
            prover_id: None,
            sector_id: None,
            _t: PhantomData,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use std::collections::BTreeMap;

    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    use storage_proofs_core::{
        compound_proof,
        gadgets::{MetricCS, TestConstraintSystem},
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait},
        proof::NoRequirements,
        sector::SectorId,
    };
    use typenum::{U0, U8};

    use crate::election;

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn election_post_test_compound_pedersen() {
        election_post_test_compound::<LCTree<PedersenHasher, U8, U0, U0>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn election_post_test_compound_poseidon() {
        election_post_test_compound::<LCTree<PoseidonHasher, U8, U0, U0>>();
    }

    fn election_post_test_compound<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = (leaves * NODE_SIZE) as u64;
        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);

        let setup_params = compound_proof::SetupParams {
            vanilla_params: election::SetupParams {
                sector_size,
                challenge_count: 20,
                challenged_nodes: 1,
            },
            partitions: None,
            priority: true,
        };

        let mut sectors: Vec<SectorId> = Vec::new();
        let mut trees = BTreeMap::new();

        // Construct and store an MT using a named store.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        for i in 0..5 {
            sectors.push(i.into());
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.insert(i.into(), tree);
        }

        let pub_params = ElectionPoStCompound::<Tree>::setup(&setup_params).expect("setup failed");

        let candidates = election::generate_candidates::<Tree>(
            &pub_params.vanilla_params,
            &sectors,
            &trees,
            prover_id,
            randomness,
        )
        .unwrap();

        let candidate = &candidates[0];
        let tree = trees.remove(&candidate.sector_id).unwrap();
        let comm_r_last = tree.root();
        let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
        let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);

        let pub_inputs = election::PublicInputs {
            randomness,
            sector_id: candidate.sector_id,
            prover_id,
            comm_r,
            partial_ticket: candidate.partial_ticket,
            sector_challenge_index: 0,
        };

        let priv_inputs = election::PrivateInputs::<Tree> {
            tree,
            comm_c,
            comm_r_last,
        };

        {
            let (circuit, inputs) =
                ElectionPoStCompound::circuit_for_test(&pub_params, &pub_inputs, &priv_inputs)
                    .unwrap();

            let mut cs = TestConstraintSystem::new();

            circuit.synthesize(&mut cs).expect("failed to synthesize");

            if !cs.is_satisfied() {
                panic!(
                    "failed to satisfy: {:?}",
                    cs.which_is_unsatisfied().unwrap()
                );
            }
            assert!(
                cs.verify(&inputs),
                "verification failed with TestContraintSystem and generated inputs"
            );
        }

        // Use this to debug differences between blank and regular circuit generation.
        {
            let (circuit1, _inputs) =
                ElectionPoStCompound::circuit_for_test(&pub_params, &pub_inputs, &priv_inputs)
                    .unwrap();
            let blank_circuit =
                ElectionPoStCompound::<Tree>::blank_circuit(&pub_params.vanilla_params);

            let mut cs_blank = MetricCS::new();
            blank_circuit
                .synthesize(&mut cs_blank)
                .expect("failed to synthesize");

            let a = cs_blank.pretty_print_list();

            let mut cs1 = TestConstraintSystem::new();
            circuit1.synthesize(&mut cs1).expect("failed to synthesize");
            let b = cs1.pretty_print_list();

            for (i, (a, b)) in a.chunks(100).zip(b.chunks(100)).enumerate() {
                assert_eq!(a, b, "failed at chunk {}", i);
            }
        }
        let blank_groth_params =
            ElectionPoStCompound::<Tree>::groth_params(Some(rng), &pub_params.vanilla_params)
                .expect("failed to generate groth params");

        let proof = ElectionPoStCompound::prove(
            &pub_params,
            &pub_inputs,
            &priv_inputs,
            &blank_groth_params,
        )
        .expect("failed while proving");

        let verified =
            ElectionPoStCompound::verify(&pub_params, &pub_inputs, &proof, &NoRequirements)
                .expect("failed while verifying");

        assert!(verified);
    }
}

'''
'''--- storage-proofs/post/src/election/mod.rs ---
mod circuit;
mod compound;
mod vanilla;

pub use circuit::*;
pub use compound::*;
pub use vanilla::*;

'''
'''--- storage-proofs/post/src/election/vanilla.rs ---
use std::collections::BTreeMap;
use std::fmt;
use std::marker::PhantomData;

use anyhow::{bail, ensure, Context};
use byteorder::{ByteOrder, LittleEndian};
use generic_array::typenum;
use log::trace;
use paired::bls12_381::Fr;
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use typenum::Unsigned;

use storage_proofs_core::{
    error::{Error, Result},
    fr32::fr_into_bytes,
    hasher::{Domain, HashFunction, Hasher, PoseidonDomain, PoseidonFunction, PoseidonMDArity},
    measurements::{measure_op, Operation},
    merkle::{MerkleProof, MerkleProofTrait, MerkleTreeTrait, MerkleTreeWrapper},
    parameter_cache::ParameterSetMetadata,
    proof::{NoRequirements, ProofScheme},
    sector::*,
    util::NODE_SIZE,
};

#[derive(Debug, Clone)]
pub struct SetupParams {
    /// Size of the sector in bytes.
    pub sector_size: u64,
    pub challenge_count: usize,
    pub challenged_nodes: usize,
}

#[derive(Debug, Clone)]
pub struct PublicParams {
    /// Size of the sector in bytes.
    pub sector_size: u64,
    pub challenge_count: usize,
    pub challenged_nodes: usize,
}

impl ParameterSetMetadata for PublicParams {
    fn identifier(&self) -> String {
        format!(
            "ElectionPoSt::PublicParams{{sector_size: {}, count: {}, nodes: {}}}",
            self.sector_size(),
            self.challenge_count,
            self.challenged_nodes,
        )
    }

    fn sector_size(&self) -> u64 {
        self.sector_size
    }
}

#[derive(Debug, Clone)]
pub struct PublicInputs<T: Domain> {
    pub randomness: T,
    pub sector_id: SectorId,
    pub prover_id: T,
    pub comm_r: T,
    pub partial_ticket: Fr,
    pub sector_challenge_index: u64,
}

#[derive(Debug)]
pub struct PrivateInputs<Tree: MerkleTreeTrait> {
    pub tree: MerkleTreeWrapper<
        Tree::Hasher,
        Tree::Store,
        Tree::Arity,
        Tree::SubTreeArity,
        Tree::TopTreeArity,
    >,
    pub comm_c: <Tree::Hasher as Hasher>::Domain,
    pub comm_r_last: <Tree::Hasher as Hasher>::Domain,
}

/// The candidate data, that is needed for ticket generation.
#[derive(Clone, Serialize, Deserialize)]
pub struct Candidate {
    pub sector_id: SectorId,
    pub partial_ticket: Fr,
    pub ticket: [u8; 32],
    pub sector_challenge_index: u64,
}

impl fmt::Debug for Candidate {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("Candidate")
            .field("sector_id", &self.sector_id)
            .field("partial_ticket", &self.partial_ticket)
            .field("ticket", &hex::encode(&self.ticket))
            .field("sector_challenge_index", &self.sector_challenge_index)
            .finish()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Proof<P: MerkleProofTrait> {
    #[serde(bound(
        serialize = "MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>: Serialize",
        deserialize = "MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>: serde::de::DeserializeOwned"
    ))]
    inclusion_proofs: Vec<MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>>,
    pub ticket: [u8; 32],
    pub comm_c: <P::Hasher as Hasher>::Domain,
}

impl<P: MerkleProofTrait> Proof<P> {
    pub fn leafs(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::leaf)
            .collect()
    }

    pub fn comm_r_last(&self) -> <P::Hasher as Hasher>::Domain {
        self.inclusion_proofs[0].root()
    }

    pub fn commitments(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::root)
            .collect()
    }

    #[allow(clippy::type_complexity)]
    pub fn paths(&self) -> Vec<Vec<(Vec<<P::Hasher as Hasher>::Domain>, usize)>> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::path)
            .collect()
    }
}

#[derive(Debug, Clone)]
pub struct ElectionPoSt<'a, Tree>
where
    Tree: 'a + MerkleTreeTrait,
{
    _t: PhantomData<&'a Tree>,
}

#[allow(clippy::type_complexity)]
pub fn generate_candidates<Tree: MerkleTreeTrait>(
    pub_params: &PublicParams,
    challenged_sectors: &[SectorId],
    trees: &BTreeMap<
        SectorId,
        MerkleTreeWrapper<
            Tree::Hasher,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >,
    >,
    prover_id: <Tree::Hasher as Hasher>::Domain,
    randomness: <Tree::Hasher as Hasher>::Domain,
) -> Result<Vec<Candidate>> {
    challenged_sectors
        .par_iter()
        .enumerate()
        .map(|(sector_challenge_index, sector_id)| {
            let tree = match trees.get(sector_id) {
                Some(tree) => tree,
                None => bail!(Error::MissingPrivateInput("tree", (*sector_id).into())),
            };

            generate_candidate::<Tree>(
                pub_params,
                tree,
                prover_id,
                *sector_id,
                randomness,
                sector_challenge_index as u64,
            )
        })
        .collect()
}

fn generate_candidate<Tree: MerkleTreeTrait>(
    pub_params: &PublicParams,
    tree: &MerkleTreeWrapper<
        Tree::Hasher,
        Tree::Store,
        Tree::Arity,
        Tree::SubTreeArity,
        Tree::TopTreeArity,
    >,
    prover_id: <Tree::Hasher as Hasher>::Domain,
    sector_id: SectorId,
    randomness: <Tree::Hasher as Hasher>::Domain,
    sector_challenge_index: u64,
) -> Result<Candidate> {
    let randomness_fr: Fr = randomness.into();
    let prover_id_fr: Fr = prover_id.into();
    let mut data: Vec<PoseidonDomain> = vec![
        randomness_fr.into(),
        prover_id_fr.into(),
        Fr::from(sector_id).into(),
    ];

    for n in 0..pub_params.challenge_count {
        let challenge =
            generate_leaf_challenge(pub_params, randomness, sector_challenge_index, n as u64)?;

        let val: Fr = measure_op(Operation::PostReadChallengedRange, || {
            tree.read_at(challenge as usize)
        })?
        .into();
        data.push(val.into());
    }

    // pad for md
    let arity = PoseidonMDArity::to_usize();
    while data.len() % arity != 0 {
        data.push(PoseidonDomain::default());
    }

    let partial_ticket: Fr = measure_op(Operation::PostPartialTicketHash, || {
        PoseidonFunction::hash_md(&data)
    })
    .into();

    // ticket = sha256(partial_ticket)
    let ticket = finalize_ticket(&partial_ticket);

    Ok(Candidate {
        sector_challenge_index,
        sector_id,
        partial_ticket,
        ticket,
    })
}

pub fn finalize_ticket(partial_ticket: &Fr) -> [u8; 32] {
    let bytes = fr_into_bytes(partial_ticket);
    let ticket_hash = Sha256::digest(&bytes);
    let mut ticket = [0u8; 32];
    ticket.copy_from_slice(&ticket_hash[..]);
    ticket
}

pub fn is_valid_sector_challenge_index(challenge_count: u64, index: u64) -> bool {
    index < challenge_count
}

pub fn generate_sector_challenges<T: Domain>(
    randomness: T,
    challenge_count: u64,
    sectors: &OrderedSectorSet,
) -> Result<Vec<SectorId>> {
    (0..challenge_count)
        .into_par_iter()
        .map(|n| generate_sector_challenge(randomness, n as usize, sectors))
        .collect()
}

pub fn generate_sector_challenge<T: Domain>(
    randomness: T,
    n: usize,
    sectors: &OrderedSectorSet,
) -> Result<SectorId> {
    let mut hasher = Sha256::new();
    hasher.input(AsRef::<[u8]>::as_ref(&randomness));
    hasher.input(&n.to_le_bytes()[..]);
    let hash = hasher.result();

    let sector_challenge = LittleEndian::read_u64(&hash.as_ref()[..8]);
    let sector_index = (sector_challenge % sectors.len() as u64) as usize;
    let sector = *sectors
        .iter()
        .nth(sector_index)
        .context("invalid challenge generated")?;

    Ok(sector)
}

/// Generate all challenged leaf ranges for a single sector, such that the range fits into the sector.
pub fn generate_leaf_challenges<T: Domain>(
    pub_params: &PublicParams,
    randomness: T,
    sector_challenge_index: u64,
    challenge_count: usize,
) -> Result<Vec<u64>> {
    let mut challenges = Vec::with_capacity(challenge_count);

    for leaf_challenge_index in 0..challenge_count {
        let challenge = generate_leaf_challenge(
            pub_params,
            randomness,
            sector_challenge_index,
            leaf_challenge_index as u64,
        )?;
        challenges.push(challenge)
    }

    Ok(challenges)
}

/// Generates challenge, such that the range fits into the sector.
pub fn generate_leaf_challenge<T: Domain>(
    pub_params: &PublicParams,
    randomness: T,
    sector_challenge_index: u64,
    leaf_challenge_index: u64,
) -> Result<u64> {
    ensure!(
        pub_params.sector_size > pub_params.challenged_nodes as u64 * NODE_SIZE as u64,
        "sector size {} is too small",
        pub_params.sector_size
    );

    let mut hasher = Sha256::new();
    hasher.input(AsRef::<[u8]>::as_ref(&randomness));
    hasher.input(&sector_challenge_index.to_le_bytes()[..]);
    hasher.input(&leaf_challenge_index.to_le_bytes()[..]);
    let hash = hasher.result();

    let leaf_challenge = LittleEndian::read_u64(&hash.as_ref()[..8]);

    let challenged_range_index = leaf_challenge
        % (pub_params.sector_size / (pub_params.challenged_nodes * NODE_SIZE) as u64);

    Ok(challenged_range_index * pub_params.challenged_nodes as u64)
}

impl<'a, Tree: 'static + MerkleTreeTrait> ProofScheme<'a> for ElectionPoSt<'a, Tree> {
    type PublicParams = PublicParams;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<<Tree::Hasher as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<Tree>;
    type Proof = Proof<Tree::Proof>;
    type Requirements = NoRequirements;

    fn setup(sp: &Self::SetupParams) -> Result<Self::PublicParams> {
        Ok(PublicParams {
            sector_size: sp.sector_size,
            challenge_count: sp.challenge_count,
            challenged_nodes: sp.challenged_nodes,
        })
    }

    fn prove<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        // 1. Inclusions proofs of all challenged leafs in all challenged ranges
        let tree = &priv_inputs.tree;
        let tree_leafs = tree.leafs();

        trace!(
            "Generating proof for tree of len {} with leafs {}",
            tree.len(),
            tree_leafs,
        );

        let inclusion_proofs = measure_op(Operation::PostInclusionProofs, || {
            (0..pub_params.challenge_count)
                .into_par_iter()
                .flat_map(|n| {
                    // TODO: replace unwrap with proper error handling
                    let challenged_leaf_start = generate_leaf_challenge(
                        pub_params,
                        pub_inputs.randomness,
                        pub_inputs.sector_challenge_index,
                        n as u64,
                    )
                    .unwrap();
                    (0..pub_params.challenged_nodes)
                        .into_par_iter()
                        .map(move |i| {
                            tree.gen_cached_proof(challenged_leaf_start as usize + i, None)
                        })
                })
                .collect::<Result<Vec<_>>>()
        })?;

        // 2. correct generation of the ticket from the partial_ticket (add this to the candidate)
        let ticket = measure_op(Operation::PostFinalizeTicket, || {
            finalize_ticket(&pub_inputs.partial_ticket)
        });

        Ok(Proof {
            inclusion_proofs,
            ticket,
            comm_c: priv_inputs.comm_c,
        })
    }

    fn verify(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        proof: &Self::Proof,
    ) -> Result<bool> {
        // verify that H(Comm_c || Comm_r_last) == Comm_R
        // comm_r_last is the root of the proof
        let comm_r_last = proof.inclusion_proofs[0].root();
        let comm_c = proof.comm_c;
        let comm_r = &pub_inputs.comm_r;

        if AsRef::<[u8]>::as_ref(&<Tree::Hasher as Hasher>::Function::hash2(
            &comm_c,
            &comm_r_last,
        )) != AsRef::<[u8]>::as_ref(comm_r)
        {
            return Ok(false);
        }

        for n in 0..pub_params.challenge_count {
            let challenged_leaf_start = generate_leaf_challenge(
                pub_params,
                pub_inputs.randomness,
                pub_inputs.sector_challenge_index,
                n as u64,
            )?;
            for i in 0..pub_params.challenged_nodes {
                let merkle_proof = &proof.inclusion_proofs[n * pub_params.challenged_nodes + i];

                // validate all comm_r_lasts match
                if merkle_proof.root() != comm_r_last {
                    return Ok(false);
                }

                // validate the path length
                let expected_path_length =
                    merkle_proof.expected_len(pub_params.sector_size as usize / NODE_SIZE);

                if expected_path_length != merkle_proof.path().len() {
                    return Ok(false);
                }

                if !merkle_proof.validate(challenged_leaf_start as usize + i) {
                    return Ok(false);
                }
            }
        }

        Ok(true)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use typenum::{U0, U2, U8};

    use storage_proofs_core::{
        hasher::{PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree},
    };

    fn test_election_post<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves * NODE_SIZE;

        let pub_params = PublicParams {
            sector_size: sector_size as u64,
            challenge_count: 40,
            challenged_nodes: 1,
        };

        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);

        let mut sectors: Vec<SectorId> = Vec::new();
        let mut trees = BTreeMap::new();

        // Construct and store an MT using a named store.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        for i in 0..5 {
            sectors.push(i.into());
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.insert(i.into(), tree);
        }

        let candidates =
            generate_candidates::<Tree>(&pub_params, &sectors, &trees, prover_id, randomness)
                .unwrap();

        let candidate = &candidates[0];
        let tree = trees.remove(&candidate.sector_id).unwrap();
        let comm_r_last = tree.root();
        let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
        let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);

        let pub_inputs = PublicInputs {
            randomness,
            sector_id: candidate.sector_id,
            prover_id,
            comm_r,
            partial_ticket: candidate.partial_ticket,
            sector_challenge_index: 0,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            tree,
            comm_c,
            comm_r_last,
        };

        let proof = ElectionPoSt::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
            .expect("proving failed");

        let is_valid = ElectionPoSt::<Tree>::verify(&pub_params, &pub_inputs, &proof)
            .expect("verification failed");

        assert!(is_valid);
    }

    #[test]
    fn election_post_pedersen() {
        test_election_post::<LCTree<PedersenHasher, U8, U0, U0>>();
    }

    #[test]
    fn election_post_poseidon() {
        test_election_post::<LCTree<PoseidonHasher, U8, U0, U0>>();
    }

    #[test]
    fn election_post_poseidon_8_8() {
        test_election_post::<LCTree<PoseidonHasher, U8, U8, U0>>();
    }

    #[test]
    fn election_post_poseidon_8_8_2() {
        test_election_post::<LCTree<PoseidonHasher, U8, U8, U2>>();
    }
}

'''
'''--- storage-proofs/post/src/fallback/circuit.rs ---
use bellperson::gadgets::num;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::CircuitComponent,
    error::Result,
    gadgets::constraint,
    gadgets::por::{AuthPath, PoRCircuit},
    gadgets::variables::Root,
    hasher::{HashFunction, Hasher},
    merkle::MerkleTreeTrait,
    por,
    util::NODE_SIZE,
};

use super::vanilla::{PublicParams, PublicSector, SectorProof};

/// This is the `FallbackPoSt` circuit.
pub struct FallbackPoStCircuit<Tree: MerkleTreeTrait> {
    pub prover_id: Option<Fr>,
    pub sectors: Vec<Sector<Tree>>,
}

#[derive(Clone)]
pub struct Sector<Tree: MerkleTreeTrait> {
    pub comm_r: Option<Fr>,
    pub comm_c: Option<Fr>,
    pub comm_r_last: Option<Fr>,
    pub leafs: Vec<Option<Fr>>,
    pub paths: Vec<AuthPath<Tree::Hasher, Tree::Arity, Tree::SubTreeArity, Tree::TopTreeArity>>,
    pub id: Option<Fr>,
}

impl<Tree: 'static + MerkleTreeTrait> Sector<Tree> {
    pub fn circuit(
        sector: &PublicSector<<Tree::Hasher as Hasher>::Domain>,
        vanilla_proof: &SectorProof<Tree::Proof>,
    ) -> Result<Self> {
        let leafs = vanilla_proof
            .leafs()
            .iter()
            .map(|l| Some((*l).into()))
            .collect();

        let paths = vanilla_proof
            .as_options()
            .into_iter()
            .map(Into::into)
            .collect();

        Ok(Sector {
            leafs,
            id: Some(sector.id.into()),
            comm_r: Some(sector.comm_r.into()),
            comm_c: Some(vanilla_proof.comm_c.into()),
            comm_r_last: Some(vanilla_proof.comm_r_last.into()),
            paths,
        })
    }

    pub fn blank_circuit(pub_params: &PublicParams) -> Self {
        let challenges_count = pub_params.challenge_count;
        let leaves = pub_params.sector_size as usize / NODE_SIZE;

        let por_params = por::PublicParams {
            leaves,
            private: true,
        };
        let leafs = vec![None; challenges_count];
        let paths = vec![AuthPath::blank(por_params.leaves); challenges_count];

        Sector {
            id: None,
            comm_r: None,
            comm_c: None,
            comm_r_last: None,
            leafs,
            paths,
        }
    }
}

impl<Tree: 'static + MerkleTreeTrait> Circuit<Bls12> for &Sector<Tree> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let Sector {
            comm_r,
            comm_c,
            comm_r_last,
            leafs,
            paths,
            ..
        } = self;

        assert_eq!(paths.len(), leafs.len());

        // 1. Verify comm_r
        let comm_r_last_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r_last"), || {
            comm_r_last
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        let comm_c_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_c"), || {
            comm_c
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        let comm_r_num = num::AllocatedNum::alloc(cs.namespace(|| "comm_r"), || {
            comm_r
                .map(Into::into)
                .ok_or_else(|| SynthesisError::AssignmentMissing)
        })?;

        comm_r_num.inputize(cs.namespace(|| "comm_r_input"))?;

        // 1. Verify H(Comm_C || comm_r_last) == comm_r
        {
            let hash_num = <Tree::Hasher as Hasher>::Function::hash2_circuit(
                cs.namespace(|| "H_comm_c_comm_r_last"),
                &comm_c_num,
                &comm_r_last_num,
            )?;

            // Check actual equality
            constraint::equal(
                cs,
                || "enforce_comm_c_comm_r_last_hash_comm_r",
                &comm_r_num,
                &hash_num,
            );
        }

        // 2. Verify Inclusion Paths
        for (i, (leaf, path)) in leafs.iter().zip(paths.iter()).enumerate() {
            PoRCircuit::<Tree>::synthesize(
                cs.namespace(|| format!("challenge_inclusion_{}", i)),
                Root::Val(*leaf),
                path.clone(),
                Root::from_allocated::<CS>(comm_r_last_num.clone()),
                true,
            )?;
        }

        Ok(())
    }
}

#[derive(Clone, Default)]
pub struct ComponentPrivateInputs {}

impl<Tree: MerkleTreeTrait> CircuitComponent for FallbackPoStCircuit<Tree> {
    type ComponentPrivateInputs = ComponentPrivateInputs;
}

impl<Tree: 'static + MerkleTreeTrait> Circuit<Bls12> for FallbackPoStCircuit<Tree> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        for (i, sector) in self.sectors.iter().enumerate() {
            let cs = &mut cs.namespace(|| format!("sector_{}", i));

            sector.synthesize(cs)?;
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use ff::Field;
    use generic_array::typenum::{U0, U2, U4, U8};
    use paired::bls12_381::{Bls12, Fr};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        compound_proof::CompoundProof,
        gadgets::TestConstraintSystem,
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait, OctMerkleTree},
        proof::ProofScheme,
        util::NODE_SIZE,
    };

    use crate::fallback::{
        self, FallbackPoSt, FallbackPoStCompound, PrivateInputs, PrivateSector, PublicInputs,
        PublicSector,
    };

    #[test]
    fn fallback_post_pedersen_single_partition_matching_base_8() {
        fallback_post::<LCTree<PedersenHasher, U8, U0, U0>>(3, 3, 1, 19, 293_439);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(3, 3, 1, 19, 16_968);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_sub_8_4() {
        fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(3, 3, 1, 19, 22_818);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_top_8_4_2() {
        fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(3, 3, 1, 19, 27_573);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_smaller_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(2, 3, 1, 19, 16_968);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_matching_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(4, 2, 2, 13, 11_312);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(5, 3, 2, 19, 16_968);
    }

    #[test]
    #[ignore]
    fn metric_fallback_post_circuit_poseidon() {
        use storage_proofs_core::gadgets::BenchCS;

        let params = fallback::SetupParams {
            sector_size: 1024 * 1024 * 1024 * 32 as u64,
            challenge_count: 10,
            sector_count: 5,
        };

        let pp = FallbackPoSt::<OctMerkleTree<PoseidonHasher>>::setup(&params).unwrap();

        let mut cs = BenchCS::<Bls12>::new();
        FallbackPoStCompound::<OctMerkleTree<PoseidonHasher>>::blank_circuit(&pp)
            .synthesize(&mut cs)
            .unwrap();

        assert_eq!(cs.num_constraints(), 268_180);
    }

    fn fallback_post<Tree: 'static + MerkleTreeTrait>(
        total_sector_count: usize,
        sector_count: usize,
        partitions: usize,
        expected_num_inputs: usize,
        expected_constraints: usize,
    ) where
        Tree::Store: 'static,
    {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves * NODE_SIZE;
        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);

        let pub_params = fallback::PublicParams {
            sector_size: sector_size as u64,
            challenge_count: 5,
            sector_count,
        };

        // Construct and store an MT using a named DiskStore.
        let temp_dir = tempdir::TempDir::new("level_cache_tree_v1").unwrap();
        let temp_path = temp_dir.path();

        let mut pub_sectors = Vec::new();
        let mut priv_sectors = Vec::new();
        let mut trees = Vec::new();

        for _i in 0..total_sector_count {
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.push(tree);
        }

        for (i, tree) in trees.iter().enumerate() {
            let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
            let comm_r_last = tree.root();

            priv_sectors.push(PrivateSector {
                tree,
                comm_c,
                comm_r_last,
            });

            let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);
            pub_sectors.push(PublicSector {
                id: (i as u64).into(),
                comm_r,
            });
        }

        let pub_inputs = PublicInputs {
            randomness,
            prover_id,
            sectors: &pub_sectors,
            k: None,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            sectors: &priv_sectors,
        };

        let proofs = FallbackPoSt::<Tree>::prove_all_partitions(
            &pub_params,
            &pub_inputs,
            &priv_inputs,
            partitions,
        )
        .expect("proving failed");
        assert_eq!(proofs.len(), partitions);

        let is_valid =
            FallbackPoSt::<Tree>::verify_all_partitions(&pub_params, &pub_inputs, &proofs)
                .expect("verification failed");
        assert!(is_valid);

        // actual circuit test

        for (j, proof) in proofs.iter().enumerate() {
            // iterates over each partition
            let circuit_sectors = proof
                .sectors
                .iter()
                .enumerate()
                .map(|(i, proof)| {
                    // index into sectors by the correct offset
                    let i = j * sector_count + i;

                    if i < pub_sectors.len() {
                        Sector::circuit(&pub_sectors[i], proof)
                    } else {
                        // duplicated last one
                        let k = pub_sectors.len() - 1;
                        Sector::circuit(&pub_sectors[k], proof)
                    }
                })
                .collect::<Result<_>>()
                .unwrap();

            let mut cs = TestConstraintSystem::<Bls12>::new();

            let instance = FallbackPoStCircuit::<Tree> {
                sectors: circuit_sectors,
                prover_id: Some(prover_id.into()),
            };

            instance
                .synthesize(&mut cs)
                .expect("failed to synthesize circuit");

            assert!(cs.is_satisfied(), "constraints not satisfied");

            assert_eq!(
                cs.num_inputs(),
                expected_num_inputs,
                "wrong number of inputs"
            );
            assert_eq!(
                cs.num_constraints(),
                expected_constraints,
                "wrong number of constraints"
            );
            assert_eq!(cs.get_input(0, "ONE"), Fr::one());

            let generated_inputs = FallbackPoStCompound::<Tree>::generate_public_inputs(
                &pub_inputs,
                &pub_params,
                Some(j),
            )
            .unwrap();
            let expected_inputs = cs.get_inputs();

            for ((input, label), generated_input) in
                expected_inputs.iter().skip(1).zip(generated_inputs.iter())
            {
                assert_eq!(input, generated_input, "{}", label);
            }

            assert_eq!(
                generated_inputs.len(),
                expected_inputs.len() - 1,
                "inputs are not the same length"
            );

            assert!(
                cs.verify(&generated_inputs),
                "verification failed with TestContraintSystem and generated inputs"
            );
        }
    }
}

'''
'''--- storage-proofs/post/src/fallback/compound.rs ---
use std::marker::PhantomData;

use anyhow::{anyhow, ensure};
use bellperson::Circuit;
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::{CircuitComponent, CompoundProof},
    error::Result,
    gadgets::por::PoRCompound,
    merkle::MerkleTreeTrait,
    parameter_cache::{CacheableParameters, ParameterSetMetadata},
    por,
    proof::ProofScheme,
    util::NODE_SIZE,
};

use super::circuit::Sector;
use crate::fallback::{self, FallbackPoSt, FallbackPoStCircuit};

pub struct FallbackPoStCompound<Tree>
where
    Tree: MerkleTreeTrait,
{
    _t: PhantomData<Tree>,
}

impl<C: Circuit<Bls12>, P: ParameterSetMetadata, Tree: MerkleTreeTrait> CacheableParameters<C, P>
    for FallbackPoStCompound<Tree>
{
    fn cache_prefix() -> String {
        format!("proof-of-spacetime-fallback-{}", Tree::display())
    }
}

impl<'a, Tree: 'static + MerkleTreeTrait>
    CompoundProof<'a, FallbackPoSt<'a, Tree>, FallbackPoStCircuit<Tree>>
    for FallbackPoStCompound<Tree>
{
    fn generate_public_inputs(
        pub_inputs: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        pub_params: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        partition_k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let mut inputs = Vec::new();

        let por_pub_params = por::PublicParams {
            leaves: (pub_params.sector_size as usize / NODE_SIZE),
            private: true,
        };

        let num_sectors_per_chunk = pub_params.sector_count;

        let partition_index = partition_k.unwrap_or(0);

        let sectors = pub_inputs
            .sectors
            .chunks(num_sectors_per_chunk)
            .nth(partition_index)
            .ok_or_else(|| anyhow!("invalid number of sectors/partition index"))?;

        for (i, sector) in sectors.iter().enumerate() {
            // 1. Inputs for verifying comm_r = H(comm_c || comm_r_last)
            inputs.push(sector.comm_r.into());

            // 2. Inputs for verifying inclusion paths
            for n in 0..pub_params.challenge_count {
                let challenge_index = ((partition_index * pub_params.sector_count + i)
                    * pub_params.challenge_count
                    + n) as u64;
                let challenged_leaf_start = fallback::generate_leaf_challenge(
                    &pub_params,
                    pub_inputs.randomness,
                    sector.id.into(),
                    challenge_index,
                )?;

                let por_pub_inputs = por::PublicInputs {
                    commitment: None,
                    challenge: challenged_leaf_start as usize,
                };
                let por_inputs = PoRCompound::<Tree>::generate_public_inputs(
                    &por_pub_inputs,
                    &por_pub_params,
                    partition_k,
                )?;

                inputs.extend(por_inputs);
            }
        }
        let num_inputs_per_sector = inputs.len() / sectors.len();

        // duplicate last one if too little sectors available
        while inputs.len() / num_inputs_per_sector < num_sectors_per_chunk {
            let s = inputs[inputs.len() - num_inputs_per_sector..].to_vec();
            inputs.extend_from_slice(&s);
        }
        assert_eq!(inputs.len(), num_inputs_per_sector * num_sectors_per_chunk);

        Ok(inputs)
    }

    fn circuit(
        pub_in: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        _priv_in: <FallbackPoStCircuit<Tree> as CircuitComponent>::ComponentPrivateInputs,
        vanilla_proof: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::Proof,
        pub_params: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        partition_k: Option<usize>,
    ) -> Result<FallbackPoStCircuit<Tree>> {
        let num_sectors_per_chunk = pub_params.sector_count;
        ensure!(
            pub_params.sector_count == vanilla_proof.sectors.len(),
            "vanilla proofs must equal sector_count: {} != {}",
            num_sectors_per_chunk,
            vanilla_proof.sectors.len(),
        );

        let partition_index = partition_k.unwrap_or(0);
        let sectors = pub_in
            .sectors
            .chunks(num_sectors_per_chunk)
            .nth(partition_index)
            .ok_or_else(|| anyhow!("invalid number of sectors/partition index"))?;

        let mut res_sectors = Vec::with_capacity(vanilla_proof.sectors.len());

        for (i, vanilla_proof) in vanilla_proof.sectors.iter().enumerate() {
            let pub_sector = if i < sectors.len() {
                &sectors[i]
            } else {
                // Repeat the last sector, iff there are too little inputs to fill the circuit.
                &sectors[sectors.len() - 1]
            };

            res_sectors.push(Sector::circuit(pub_sector, vanilla_proof)?);
        }

        assert_eq!(res_sectors.len(), num_sectors_per_chunk);

        Ok(FallbackPoStCircuit {
            prover_id: Some(pub_in.prover_id.into()),
            sectors: res_sectors,
        })
    }

    fn blank_circuit(
        pub_params: &<FallbackPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
    ) -> FallbackPoStCircuit<Tree> {
        let sectors = (0..pub_params.sector_count)
            .map(|_| Sector::blank_circuit(pub_params))
            .collect();

        FallbackPoStCircuit {
            prover_id: None,
            sectors,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use generic_array::typenum::{U0, U2, U4, U8};
    use pretty_assertions::assert_eq;
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        compound_proof,
        gadgets::{MetricCS, TestConstraintSystem},
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait},
    };

    use crate::fallback::{
        self, ChallengeRequirements, PrivateInputs, PrivateSector, PublicInputs, PublicSector,
    };

    #[ignore]
    #[test]
    fn fallback_post_pedersen_single_partition_matching_base_8() {
        fallback_post::<LCTree<PedersenHasher, U8, U0, U0>>(3, 3, 1);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_single_partition_matching_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(3, 3, 1);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_single_partition_matching_sub_8_4() {
        fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(3, 3, 1);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_single_partition_matching_top_8_4_2() {
        fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(3, 3, 1);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_single_partition_smaller_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(2, 3, 1);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_two_partitions_matching_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(4, 2, 2);
    }

    #[ignore]
    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_base_8() {
        fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(5, 3, 2);
    }

    fn fallback_post<Tree: 'static + MerkleTreeTrait>(
        total_sector_count: usize,
        sector_count: usize,
        partitions: usize,
    ) where
        Tree::Store: 'static,
    {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = (leaves * NODE_SIZE) as u64;
        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);
        let challenge_count = 2;

        let setup_params = compound_proof::SetupParams {
            vanilla_params: fallback::SetupParams {
                sector_size: sector_size as u64,
                challenge_count,
                sector_count,
            },
            partitions: Some(partitions),
            priority: false,
        };

        // Construct and store an MT using a named DiskStore.
        let temp_dir = tempdir::TempDir::new("level_cache_tree_v1").unwrap();
        let temp_path = temp_dir.path();

        let mut pub_sectors = Vec::new();
        let mut priv_sectors = Vec::new();
        let mut trees = Vec::new();

        for _i in 0..total_sector_count {
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.push(tree);
        }
        for (i, tree) in trees.iter().enumerate() {
            let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
            let comm_r_last = tree.root();

            priv_sectors.push(PrivateSector {
                tree,
                comm_c,
                comm_r_last,
            });

            let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);
            pub_sectors.push(PublicSector {
                id: (i as u64).into(),
                comm_r,
            });
        }

        let pub_params = FallbackPoStCompound::<Tree>::setup(&setup_params).expect("setup failed");

        let pub_inputs = PublicInputs {
            randomness,
            prover_id,
            sectors: &pub_sectors,
            k: None,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            sectors: &priv_sectors,
        };

        // Use this to debug differences between blank and regular circuit generation.
        {
            let circuits =
                FallbackPoStCompound::circuit_for_test_all(&pub_params, &pub_inputs, &priv_inputs)
                    .unwrap();
            let blank_circuit =
                FallbackPoStCompound::<Tree>::blank_circuit(&pub_params.vanilla_params);

            let mut cs_blank = MetricCS::new();
            blank_circuit
                .synthesize(&mut cs_blank)
                .expect("failed to synthesize");

            let a = cs_blank.pretty_print_list();

            for (circuit1, _inputs) in circuits.into_iter() {
                let mut cs1 = TestConstraintSystem::new();
                circuit1.synthesize(&mut cs1).expect("failed to synthesize");
                let b = cs1.pretty_print_list();

                for (i, (a, b)) in a.chunks(100).zip(b.chunks(100)).enumerate() {
                    assert_eq!(a, b, "failed at chunk {}", i);
                }
            }
        }

        {
            let circuits =
                FallbackPoStCompound::circuit_for_test_all(&pub_params, &pub_inputs, &priv_inputs)
                    .unwrap();

            for (circuit, inputs) in circuits.into_iter() {
                let mut cs = TestConstraintSystem::new();

                circuit.synthesize(&mut cs).expect("failed to synthesize");

                if !cs.is_satisfied() {
                    panic!(
                        "failed to satisfy: {:?}",
                        cs.which_is_unsatisfied().unwrap()
                    );
                }
                assert!(
                    cs.verify(&inputs),
                    "verification failed with TestContraintSystem and generated inputs"
                );
            }
        }

        let blank_groth_params =
            FallbackPoStCompound::<Tree>::groth_params(Some(rng), &pub_params.vanilla_params)
                .expect("failed to generate groth params");

        let proof = FallbackPoStCompound::prove(
            &pub_params,
            &pub_inputs,
            &priv_inputs,
            &blank_groth_params,
        )
        .expect("failed while proving");

        let verified = FallbackPoStCompound::verify(
            &pub_params,
            &pub_inputs,
            &proof,
            &ChallengeRequirements {
                minimum_challenge_count: total_sector_count * challenge_count,
            },
        )
        .expect("failed while verifying");

        assert!(verified);
    }
}

'''
'''--- storage-proofs/post/src/fallback/mod.rs ---
mod circuit;
mod compound;
mod vanilla;

pub use circuit::*;
pub use compound::*;
pub use vanilla::*;

'''
'''--- storage-proofs/post/src/fallback/vanilla.rs ---
use std::marker::PhantomData;

use anyhow::ensure;
use byteorder::{ByteOrder, LittleEndian};
use generic_array::typenum::Unsigned;
use log::trace;
use paired::bls12_381::Fr;
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};

use storage_proofs_core::{
    error::Result,
    hasher::{Domain, HashFunction, Hasher},
    merkle::{MerkleProof, MerkleProofTrait, MerkleTreeTrait, MerkleTreeWrapper},
    parameter_cache::ParameterSetMetadata,
    proof::ProofScheme,
    sector::*,
    util::NODE_SIZE,
};

#[derive(Debug, Clone)]
pub struct SetupParams {
    /// Size of the sector in bytes.
    pub sector_size: u64,
    /// Number of challenges per sector.
    pub challenge_count: usize,
    /// Number of challenged sectors.
    pub sector_count: usize,
}

#[derive(Debug, Clone)]
pub struct PublicParams {
    /// Size of the sector in bytes.
    pub sector_size: u64,
    /// Number of challenges per sector.
    pub challenge_count: usize,
    /// Number of challenged sectors.
    pub sector_count: usize,
}

#[derive(Debug, Default)]
pub struct ChallengeRequirements {
    /// The sum of challenges across all challenged sectors. (even across partitions)
    pub minimum_challenge_count: usize,
}

impl ParameterSetMetadata for PublicParams {
    fn identifier(&self) -> String {
        format!(
            "FallbackPoSt::PublicParams{{sector_size: {}, challenge_count: {}, sector_count: {}}}",
            self.sector_size(),
            self.challenge_count,
            self.sector_count,
        )
    }

    fn sector_size(&self) -> u64 {
        self.sector_size
    }
}

#[derive(Debug, Clone)]
pub struct PublicInputs<'a, T: Domain> {
    pub randomness: T,
    pub prover_id: T,
    pub sectors: &'a [PublicSector<T>],
    /// Partition index
    pub k: Option<usize>,
}

#[derive(Debug, Clone)]
pub struct PublicSector<T: Domain> {
    pub id: SectorId,
    pub comm_r: T,
}

#[derive(Debug)]
pub struct PrivateSector<'a, Tree: MerkleTreeTrait> {
    pub tree: &'a MerkleTreeWrapper<
        Tree::Hasher,
        Tree::Store,
        Tree::Arity,
        Tree::SubTreeArity,
        Tree::TopTreeArity,
    >,
    pub comm_c: <Tree::Hasher as Hasher>::Domain,
    pub comm_r_last: <Tree::Hasher as Hasher>::Domain,
}

#[derive(Debug)]
pub struct PrivateInputs<'a, Tree: MerkleTreeTrait> {
    pub sectors: &'a [PrivateSector<'a, Tree>],
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Proof<P: MerkleProofTrait> {
    #[serde(bound(
        serialize = "SectorProof<P>: Serialize",
        deserialize = "SectorProof<P>: Deserialize<'de>"
    ))]
    pub sectors: Vec<SectorProof<P>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SectorProof<Proof: MerkleProofTrait> {
    #[serde(bound(
        serialize = "MerkleProof<Proof::Hasher, Proof::Arity, Proof::SubTreeArity, Proof::TopTreeArity>: Serialize",
        deserialize = "MerkleProof<Proof::Hasher, Proof::Arity, Proof::SubTreeArity, Proof::TopTreeArity>: serde::de::DeserializeOwned"
    ))]
    inclusion_proofs:
        Vec<MerkleProof<Proof::Hasher, Proof::Arity, Proof::SubTreeArity, Proof::TopTreeArity>>,
    pub comm_c: <Proof::Hasher as Hasher>::Domain,
    pub comm_r_last: <Proof::Hasher as Hasher>::Domain,
}

impl<P: MerkleProofTrait> SectorProof<P> {
    pub fn leafs(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProofTrait::leaf)
            .collect()
    }

    pub fn comm_r_last(&self) -> <P::Hasher as Hasher>::Domain {
        self.inclusion_proofs[0].root()
    }

    pub fn commitments(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProofTrait::root)
            .collect()
    }

    #[allow(clippy::type_complexity)]
    pub fn paths(&self) -> Vec<Vec<(Vec<<P::Hasher as Hasher>::Domain>, usize)>> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProofTrait::path)
            .collect()
    }

    pub fn as_options(&self) -> Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProofTrait::as_options)
            .collect()
    }
}

#[derive(Debug, Clone)]
pub struct FallbackPoSt<'a, Tree>
where
    Tree: 'a + MerkleTreeTrait,
{
    _t: PhantomData<&'a Tree>,
}

pub fn generate_sector_challenges<T: Domain>(
    randomness: T,
    challenge_count: usize,
    sector_set_len: u64,
    prover_id: T,
) -> Result<Vec<u64>> {
    (0..challenge_count)
        .map(|n| generate_sector_challenge(randomness, n, sector_set_len, prover_id))
        .collect()
}

/// Generate a single sector challenge.
pub fn generate_sector_challenge<T: Domain>(
    randomness: T,
    n: usize,
    sector_set_len: u64,
    prover_id: T,
) -> Result<u64> {
    let mut hasher = Sha256::new();
    hasher.input(AsRef::<[u8]>::as_ref(&prover_id));
    hasher.input(AsRef::<[u8]>::as_ref(&randomness));
    hasher.input(&n.to_le_bytes()[..]);

    let hash = hasher.result();

    let sector_challenge = LittleEndian::read_u64(&hash.as_ref()[..8]);
    let sector_index = sector_challenge % sector_set_len;

    Ok(sector_index)
}

/// Generate all challenged leaf ranges for a single sector, such that the range fits into the sector.
pub fn generate_leaf_challenges<T: Domain>(
    pub_params: &PublicParams,
    randomness: T,
    sector_id: u64,
    challenge_count: usize,
) -> Result<Vec<u64>> {
    let mut challenges = Vec::with_capacity(challenge_count);

    for leaf_challenge_index in 0..challenge_count {
        let challenge = generate_leaf_challenge(
            pub_params,
            randomness,
            sector_id,
            leaf_challenge_index as u64,
        )?;
        challenges.push(challenge)
    }

    Ok(challenges)
}

/// Generates challenge, such that the range fits into the sector.
pub fn generate_leaf_challenge<T: Domain>(
    pub_params: &PublicParams,
    randomness: T,
    sector_id: u64,
    leaf_challenge_index: u64,
) -> Result<u64> {
    let mut hasher = Sha256::new();
    hasher.input(AsRef::<[u8]>::as_ref(&randomness));
    hasher.input(&sector_id.to_le_bytes()[..]);
    hasher.input(&leaf_challenge_index.to_le_bytes()[..]);
    let hash = hasher.result();

    let leaf_challenge = LittleEndian::read_u64(&hash.as_ref()[..8]);

    let challenged_range_index = leaf_challenge % (pub_params.sector_size / NODE_SIZE as u64);

    Ok(challenged_range_index)
}

impl<'a, Tree: 'a + MerkleTreeTrait> ProofScheme<'a> for FallbackPoSt<'a, Tree> {
    type PublicParams = PublicParams;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<'a, <Tree::Hasher as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<'a, Tree>;
    type Proof = Proof<Tree::Proof>;
    type Requirements = ChallengeRequirements;

    fn setup(sp: &Self::SetupParams) -> Result<Self::PublicParams> {
        Ok(PublicParams {
            sector_size: sp.sector_size,
            challenge_count: sp.challenge_count,
            sector_count: sp.sector_count,
        })
    }

    fn prove<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        let proofs = Self::prove_all_partitions(pub_params, pub_inputs, priv_inputs, 1)?;
        let k = match pub_inputs.k {
            None => 0,
            Some(k) => k,
        };
        // Because partition proofs require a common setup, the general ProofScheme implementation,
        // which makes use of `ProofScheme::prove` cannot be used here. Instead, we need to prove all
        // partitions in one pass, as implemented by `prove_all_partitions` below.
        assert!(
            k < 1,
            "It is a programmer error to call StackedDrg::prove with more than one partition."
        );

        Ok(proofs[k].to_owned())
    }

    fn prove_all_partitions<'b>(
        pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
        partition_count: usize,
    ) -> Result<Vec<Self::Proof>> {
        ensure!(
            priv_inputs.sectors.len() == pub_inputs.sectors.len(),
            "inconsistent number of private and public sectors {} != {}",
            priv_inputs.sectors.len(),
            pub_inputs.sectors.len(),
        );

        let num_sectors_per_chunk = pub_params.sector_count;
        let num_sectors = pub_inputs.sectors.len();

        ensure!(
            num_sectors <= partition_count * num_sectors_per_chunk,
            "cannot prove the provided number of sectors: {} > {} * {}",
            num_sectors,
            partition_count,
            num_sectors_per_chunk,
        );

        let mut partition_proofs = Vec::new();

        for (j, (pub_sectors_chunk, priv_sectors_chunk)) in pub_inputs
            .sectors
            .chunks(num_sectors_per_chunk)
            .zip(priv_inputs.sectors.chunks(num_sectors_per_chunk))
            .enumerate()
        {
            trace!("proving partition {}", j);

            let mut proofs = Vec::with_capacity(num_sectors_per_chunk);

            for (i, (pub_sector, priv_sector)) in pub_sectors_chunk
                .iter()
                .zip(priv_sectors_chunk.iter())
                .enumerate()
            {
                let tree = priv_sector.tree;
                let sector_id = pub_sector.id;
                let tree_leafs = tree.leafs();

                trace!(
                    "Generating proof for tree leafs {} and arity {}",
                    tree_leafs,
                    Tree::Arity::to_usize(),
                );

                let inclusion_proofs = (0..pub_params.challenge_count)
                    .into_par_iter()
                    .map(|n| {
                        let challenge_index = ((j * num_sectors_per_chunk + i)
                            * pub_params.challenge_count
                            + n) as u64;
                        let challenged_leaf_start = generate_leaf_challenge(
                            pub_params,
                            pub_inputs.randomness,
                            sector_id.into(),
                            challenge_index,
                        )?;

                        tree.gen_cached_proof(challenged_leaf_start as usize, None)
                    })
                    .collect::<Result<Vec<_>>>()?;

                proofs.push(SectorProof {
                    inclusion_proofs,
                    comm_c: priv_sector.comm_c,
                    comm_r_last: priv_sector.comm_r_last,
                });
            }

            // If there were less than the required number of sectors provided, we duplicate the last one
            // to pad the proof out, such that it works in the circuit part.
            while proofs.len() < num_sectors_per_chunk {
                proofs.push(proofs[proofs.len() - 1].clone());
            }

            partition_proofs.push(Proof { sectors: proofs });
        }

        Ok(partition_proofs)
    }

    fn verify_all_partitions(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        partition_proofs: &[Self::Proof],
    ) -> Result<bool> {
        let challenge_count = pub_params.challenge_count;
        let num_sectors_per_chunk = pub_params.sector_count;
        let num_sectors = pub_inputs.sectors.len();

        ensure!(
            num_sectors <= num_sectors_per_chunk * partition_proofs.len(),
            "inconsistent number of sectors: {} > {} * {}",
            num_sectors,
            num_sectors_per_chunk,
            partition_proofs.len(),
        );

        for (j, (proof, pub_sectors_chunk)) in partition_proofs
            .iter()
            .zip(pub_inputs.sectors.chunks(num_sectors_per_chunk))
            .enumerate()
        {
            ensure!(
                pub_sectors_chunk.len() <= num_sectors_per_chunk,
                "inconsistent number of public sectors: {} > {}",
                pub_sectors_chunk.len(),
                num_sectors_per_chunk,
            );
            ensure!(
                proof.sectors.len() == num_sectors_per_chunk,
                "invalid number of sectors in the partition proof {}: {} != {}",
                j,
                proof.sectors.len(),
                num_sectors_per_chunk,
            );
            for (i, (pub_sector, sector_proof)) in pub_sectors_chunk
                .iter()
                .zip(proof.sectors.iter())
                .enumerate()
            {
                let sector_id = pub_sector.id;
                let comm_r = &pub_sector.comm_r;
                let comm_c = sector_proof.comm_c;
                let inclusion_proofs = &sector_proof.inclusion_proofs;

                // Verify that H(Comm_c || Comm_r_last) == Comm_R

                // comm_r_last is the root of the proof
                let comm_r_last = inclusion_proofs[0].root();

                if AsRef::<[u8]>::as_ref(&<Tree::Hasher as Hasher>::Function::hash2(
                    &comm_c,
                    &comm_r_last,
                )) != AsRef::<[u8]>::as_ref(comm_r)
                {
                    return Ok(false);
                }

                ensure!(
                    challenge_count == inclusion_proofs.len(),
                    "unexpected umber of inclusion proofs: {} != {}",
                    challenge_count,
                    inclusion_proofs.len()
                );

                for (n, inclusion_proof) in inclusion_proofs.iter().enumerate() {
                    let challenge_index =
                        ((j * num_sectors_per_chunk + i) * pub_params.challenge_count + n) as u64;
                    let challenged_leaf_start = generate_leaf_challenge(
                        pub_params,
                        pub_inputs.randomness,
                        sector_id.into(),
                        challenge_index,
                    )?;

                    // validate all comm_r_lasts match
                    if inclusion_proof.root() != comm_r_last {
                        return Ok(false);
                    }

                    // validate the path length
                    let expected_path_length =
                        inclusion_proof.expected_len(pub_params.sector_size as usize / NODE_SIZE);

                    if expected_path_length != inclusion_proof.path().len() {
                        return Ok(false);
                    }

                    if !inclusion_proof.validate(challenged_leaf_start as usize) {
                        return Ok(false);
                    }
                }
            }
        }

        Ok(true)
    }

    fn satisfies_requirements(
        public_params: &Self::PublicParams,
        requirements: &Self::Requirements,
        partitions: usize,
    ) -> bool {
        partitions * public_params.sector_count * public_params.challenge_count
            >= requirements.minimum_challenge_count
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use generic_array::typenum::{U0, U2, U4, U8};
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    use storage_proofs_core::{
        hasher::{PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait},
    };

    fn test_fallback_post<Tree: MerkleTreeTrait>(
        total_sector_count: usize,
        sector_count: usize,
        partitions: usize,
    ) where
        Tree::Store: 'static,
    {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves * NODE_SIZE;

        let pub_params = PublicParams {
            sector_size: sector_size as u64,
            challenge_count: 10,
            sector_count,
        };

        let randomness = <Tree::Hasher as Hasher>::Domain::random(rng);
        let prover_id = <Tree::Hasher as Hasher>::Domain::random(rng);

        // Construct and store an MT using a named DiskStore.
        let temp_dir = tempdir::TempDir::new("level_cache_tree").unwrap();
        let temp_path = temp_dir.path();

        let mut pub_sectors = Vec::new();
        let mut priv_sectors = Vec::new();
        let mut trees = Vec::new();

        for _i in 0..total_sector_count {
            let (_data, tree) =
                generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
            trees.push(tree);
        }
        for (i, tree) in trees.iter().enumerate() {
            let comm_c = <Tree::Hasher as Hasher>::Domain::random(rng);
            let comm_r_last = tree.root();

            priv_sectors.push(PrivateSector {
                tree,
                comm_c,
                comm_r_last,
            });

            let comm_r = <Tree::Hasher as Hasher>::Function::hash2(&comm_c, &comm_r_last);
            pub_sectors.push(PublicSector {
                id: (i as u64).into(),
                comm_r,
            });
        }

        let pub_inputs = PublicInputs {
            randomness,
            prover_id,
            sectors: &pub_sectors,
            k: None,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            sectors: &priv_sectors[..],
        };

        let proof = FallbackPoSt::<Tree>::prove_all_partitions(
            &pub_params,
            &pub_inputs,
            &priv_inputs,
            partitions,
        )
        .expect("proving failed");

        let is_valid =
            FallbackPoSt::<Tree>::verify_all_partitions(&pub_params, &pub_inputs, &proof)
                .expect("verification failed");

        assert!(is_valid);
    }

    #[test]
    fn fallback_post_pedersen_single_partition_matching_base_8() {
        test_fallback_post::<LCTree<PedersenHasher, U8, U0, U0>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_base_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_smaller_base_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(3, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_matching_base_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(4, 2, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_base_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U0, U0>>(5, 3, 2);
    }

    #[test]
    fn fallback_post_pedersen_single_partition_matching_sub_8_4() {
        test_fallback_post::<LCTree<PedersenHasher, U8, U4, U0>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_sub_8_4() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_smaller_sub_8_4() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(3, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_matching_sub_8_4() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(4, 2, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_matching_sub_8_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U8, U0>>(4, 2, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_sub_8_4() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U0>>(5, 3, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_sub_8_8() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U8, U0>>(5, 3, 2);
    }

    #[test]
    fn fallback_post_pedersen_single_partition_matching_top_8_4_2() {
        test_fallback_post::<LCTree<PedersenHasher, U8, U4, U2>>(5, 5, 1);
    }
    #[test]
    fn fallback_post_pedersen_single_partition_matching_top_8_8_2() {
        test_fallback_post::<LCTree<PedersenHasher, U8, U8, U2>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_top_8_4_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_matching_top_8_8_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U8, U2>>(5, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_single_partition_smaller_top_8_4_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(3, 5, 1);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_matching_top_8_4_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(4, 2, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_top_8_4_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U4, U2>>(5, 3, 2);
    }

    #[test]
    fn fallback_post_poseidon_two_partitions_smaller_top_8_8_2() {
        test_fallback_post::<LCTree<PoseidonHasher, U8, U8, U2>>(5, 3, 2);
    }
}

'''
'''--- storage-proofs/post/src/lib.rs ---
pub mod election;
pub mod fallback;
pub mod rational;

#[cfg(test)]
pub(crate) const TEST_SEED: [u8; 16] = [
    0x59, 0x62, 0xbe, 0x5d, 0x76, 0x3d, 0x31, 0x8d, 0x17, 0xdb, 0x37, 0x32, 0x54, 0x06, 0xbc, 0xe5,
];

'''
'''--- storage-proofs/post/src/rational/circuit.rs ---
use std::marker::PhantomData;

use bellperson::gadgets::num;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::CircuitComponent,
    error::Result,
    gadgets::constraint,
    gadgets::por::PoRCircuit,
    gadgets::variables::Root,
    hasher::{HashFunction, Hasher},
    merkle::MerkleTreeTrait,
};

/// This is the `RationalPoSt` circuit.
pub struct RationalPoStCircuit<Tree: MerkleTreeTrait> {
    /// Paramters for the engine.
    pub comm_rs: Vec<Option<Fr>>,
    pub comm_cs: Vec<Option<Fr>>,
    pub comm_r_lasts: Vec<Option<Fr>>,
    pub leafs: Vec<Option<Fr>>,
    #[allow(clippy::type_complexity)]
    pub paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
    pub _t: PhantomData<Tree>,
}

#[derive(Clone, Default)]
pub struct ComponentPrivateInputs {}

impl<'a, Tree: MerkleTreeTrait> CircuitComponent for RationalPoStCircuit<Tree> {
    type ComponentPrivateInputs = ComponentPrivateInputs;
}

impl<'a, Tree: 'static + MerkleTreeTrait> Circuit<Bls12> for RationalPoStCircuit<Tree> {
    fn synthesize<CS: ConstraintSystem<Bls12>>(self, cs: &mut CS) -> Result<(), SynthesisError> {
        let comm_rs = self.comm_rs;
        let comm_cs = self.comm_cs;
        let comm_r_lasts = self.comm_r_lasts;
        let leafs = self.leafs;
        let paths = self.paths;

        assert_eq!(paths.len(), leafs.len());
        assert_eq!(paths.len(), comm_rs.len());
        assert_eq!(paths.len(), comm_cs.len());
        assert_eq!(paths.len(), comm_r_lasts.len());

        for (((i, comm_r_last), comm_c), comm_r) in comm_r_lasts
            .iter()
            .enumerate()
            .zip(comm_cs.iter())
            .zip(comm_rs.iter())
        {
            let comm_r_last_num =
                num::AllocatedNum::alloc(cs.namespace(|| format!("comm_r_last_{}", i)), || {
                    comm_r_last
                        .map(Into::into)
                        .ok_or_else(|| SynthesisError::AssignmentMissing)
                })?;

            let comm_c_num =
                num::AllocatedNum::alloc(cs.namespace(|| format!("comm_c_{}", i)), || {
                    comm_c
                        .map(Into::into)
                        .ok_or_else(|| SynthesisError::AssignmentMissing)
                })?;

            let comm_r_num =
                num::AllocatedNum::alloc(cs.namespace(|| format!("comm_r_{}", i)), || {
                    comm_r
                        .map(Into::into)
                        .ok_or_else(|| SynthesisError::AssignmentMissing)
                })?;

            comm_r_num.inputize(cs.namespace(|| format!("comm_r_{}_input", i)))?;

            // Verify H(Comm_C || comm_r_last) == comm_r
            {
                let hash_num = <Tree::Hasher as Hasher>::Function::hash2_circuit(
                    cs.namespace(|| format!("H_comm_c_comm_r_last_{}", i)),
                    &comm_c_num,
                    &comm_r_last_num,
                )?;

                // Check actual equality
                constraint::equal(
                    cs,
                    || format!("enforce_comm_c_comm_r_last_hash_comm_r_{}", i),
                    &comm_r_num,
                    &hash_num,
                );
            }

            PoRCircuit::<Tree>::synthesize(
                cs.namespace(|| format!("challenge_inclusion{}", i)),
                Root::Val(leafs[i]),
                paths[i].clone().into(),
                Root::from_allocated::<CS>(comm_r_last_num),
                true,
            )?;
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use std::collections::BTreeMap;

    use ff::Field;
    use paired::bls12_381::{Bls12, Fr};
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;

    use storage_proofs_core::{
        compound_proof::CompoundProof,
        gadgets::TestConstraintSystem,
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, BinaryMerkleTree},
        proof::ProofScheme,
        sector::OrderedSectorSet,
        util::NODE_SIZE,
    };

    use crate::rational::{self, derive_challenges, RationalPoSt, RationalPoStCompound};

    #[test]
    fn test_rational_post_circuit_pedersen() {
        test_rational_post_circuit::<BinaryMerkleTree<PedersenHasher>>(16_490);
    }

    #[test]
    fn test_rational_post_circuit_poseidon() {
        test_rational_post_circuit::<BinaryMerkleTree<PoseidonHasher>>(3_806);
    }

    fn test_rational_post_circuit<Tree: 'static + MerkleTreeTrait>(expected_constraints: usize) {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 32 * get_base_tree_count::<Tree>();
        let sector_size = (leaves * NODE_SIZE) as u64;
        let challenges_count = 2;

        let pub_params = rational::PublicParams {
            sector_size,
            challenges_count,
        };

        // Construct and store an MT using a named DiskStore.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        let (_data1, tree1) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
        let (_data2, tree2) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));

        let faults = OrderedSectorSet::new();
        let mut sectors = OrderedSectorSet::new();
        sectors.insert(0.into());
        sectors.insert(1.into());

        let seed = (0..leaves).map(|_| rng.gen()).collect::<Vec<u8>>();
        let challenges =
            derive_challenges(challenges_count, sector_size, &sectors, &seed, &faults).unwrap();
        let comm_r_lasts_raw = vec![tree1.root(), tree2.root()];
        let comm_r_lasts: Vec<_> = challenges
            .iter()
            .map(|c| comm_r_lasts_raw[u64::from(c.sector) as usize])
            .collect();

        let comm_cs: Vec<<Tree::Hasher as Hasher>::Domain> = challenges
            .iter()
            .map(|_c| <Tree::Hasher as Hasher>::Domain::random(rng))
            .collect();

        let comm_rs: Vec<_> = comm_cs
            .iter()
            .zip(comm_r_lasts.iter())
            .map(|(comm_c, comm_r_last)| {
                <Tree::Hasher as Hasher>::Function::hash2(comm_c, comm_r_last)
            })
            .collect();

        let pub_inputs = rational::PublicInputs {
            challenges: &challenges,
            faults: &faults,
            comm_rs: &comm_rs,
        };

        let mut trees = BTreeMap::new();
        trees.insert(0.into(), &tree1);
        trees.insert(1.into(), &tree2);

        let priv_inputs = rational::PrivateInputs::<Tree> {
            trees: &trees,
            comm_cs: &comm_cs,
            comm_r_lasts: &comm_r_lasts,
        };

        let proof = RationalPoSt::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
            .expect("proving failed");

        let is_valid = RationalPoSt::<Tree>::verify(&pub_params, &pub_inputs, &proof)
            .expect("verification failed");
        assert!(is_valid);

        // actual circuit test

        let paths: Vec<_> = proof
            .paths()
            .iter()
            .map(|p| {
                p.iter()
                    .map(|v| {
                        (
                            v.0.iter().copied().map(Into::into).map(Some).collect(),
                            Some(v.1),
                        )
                    })
                    .collect::<Vec<_>>()
            })
            .collect();
        let leafs: Vec<_> = proof.leafs().iter().map(|l| Some((*l).into())).collect();

        let mut cs = TestConstraintSystem::<Bls12>::new();

        let instance = RationalPoStCircuit::<Tree> {
            leafs,
            paths,
            comm_rs: comm_rs.iter().copied().map(|c| Some(c.into())).collect(),
            comm_cs: comm_cs.into_iter().map(|c| Some(c.into())).collect(),
            comm_r_lasts: comm_r_lasts.into_iter().map(|c| Some(c.into())).collect(),
            _t: PhantomData,
        };

        instance
            .synthesize(&mut cs)
            .expect("failed to synthesize circuit");

        assert!(cs.is_satisfied(), "constraints not satisfied");

        assert_eq!(cs.num_inputs(), 5, "wrong number of inputs");
        assert_eq!(
            cs.num_constraints(),
            expected_constraints,
            "wrong number of constraints"
        );
        assert_eq!(cs.get_input(0, "ONE"), Fr::one());

        let generated_inputs =
            RationalPoStCompound::<Tree>::generate_public_inputs(&pub_inputs, &pub_params, None)
                .unwrap();
        let expected_inputs = cs.get_inputs();

        for ((input, label), generated_input) in
            expected_inputs.iter().skip(1).zip(generated_inputs.iter())
        {
            assert_eq!(input, generated_input, "{}", label);
        }

        assert_eq!(
            generated_inputs.len(),
            expected_inputs.len() - 1,
            "inputs are not the same length"
        );
    }
}

'''
'''--- storage-proofs/post/src/rational/compound.rs ---
use std::marker::PhantomData;

use anyhow::ensure;
use bellperson::{Circuit, ConstraintSystem, SynthesisError};
use generic_array::typenum;
use paired::bls12_381::{Bls12, Fr};

use storage_proofs_core::{
    compound_proof::{CircuitComponent, CompoundProof},
    drgraph,
    error::Result,
    gadgets::por::PoRCompound,
    merkle::MerkleTreeTrait,
    parameter_cache::{CacheableParameters, ParameterSetMetadata},
    por,
    proof::ProofScheme,
    util::NODE_SIZE,
};

use super::{RationalPoSt, RationalPoStCircuit};

pub struct RationalPoStCompound<Tree>
where
    Tree: MerkleTreeTrait,
{
    _t: PhantomData<Tree>,
}

impl<C: Circuit<Bls12>, P: ParameterSetMetadata, Tree: MerkleTreeTrait> CacheableParameters<C, P>
    for RationalPoStCompound<Tree>
{
    fn cache_prefix() -> String {
        format!("proof-of-spacetime-rational-{}", Tree::display())
    }
}

impl<'a, Tree: 'static + MerkleTreeTrait>
    CompoundProof<'a, RationalPoSt<'a, Tree>, RationalPoStCircuit<Tree>>
    for RationalPoStCompound<Tree>
where
    Tree: 'static + MerkleTreeTrait,
{
    fn generate_public_inputs(
        pub_in: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        pub_params: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<Vec<Fr>> {
        let mut inputs = Vec::new();

        let por_pub_params = por::PublicParams {
            leaves: (pub_params.sector_size as usize / NODE_SIZE),
            private: true,
        };

        ensure!(
            pub_in.challenges.len() == pub_in.comm_rs.len(),
            "Missmatch in challenges and comm_rs"
        );

        for (challenge, comm_r) in pub_in.challenges.iter().zip(pub_in.comm_rs.iter()) {
            inputs.push((*comm_r).into());

            let por_pub_inputs = por::PublicInputs {
                commitment: None,
                challenge: challenge.leaf as usize,
            };
            let por_inputs = PoRCompound::<Tree>::generate_public_inputs(
                &por_pub_inputs,
                &por_pub_params,
                None,
            )?;

            inputs.extend(por_inputs);
        }

        Ok(inputs)
    }

    fn circuit(
        pub_in: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::PublicInputs,
        _priv_in: <RationalPoStCircuit<Tree> as CircuitComponent>::ComponentPrivateInputs,
        vanilla_proof: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::Proof,
        _pub_params: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
        _partition_k: Option<usize>,
    ) -> Result<RationalPoStCircuit<Tree>> {
        let comm_rs: Vec<_> = pub_in.comm_rs.iter().map(|c| Some((*c).into())).collect();
        let comm_cs: Vec<_> = vanilla_proof
            .comm_cs
            .iter()
            .map(|c| Some((*c).into()))
            .collect();

        let comm_r_lasts: Vec<_> = vanilla_proof
            .commitments()
            .into_iter()
            .map(|c| Some(c.into()))
            .collect();

        let leafs: Vec<_> = vanilla_proof
            .leafs()
            .iter()
            .map(|c| Some((*c).into()))
            .collect();

        let paths: Vec<Vec<_>> = vanilla_proof
            .paths()
            .iter()
            .map(|v| {
                v.iter()
                    .map(|p| {
                        (
                            (*p).0.iter().copied().map(Into::into).map(Some).collect(),
                            Some(p.1),
                        )
                    })
                    .collect()
            })
            .collect();

        Ok(RationalPoStCircuit {
            leafs,
            comm_rs,
            comm_cs,
            comm_r_lasts,
            paths,
            _t: PhantomData,
        })
    }

    fn blank_circuit(
        pub_params: &<RationalPoSt<'a, Tree> as ProofScheme<'a>>::PublicParams,
    ) -> RationalPoStCircuit<Tree> {
        let challenges_count = pub_params.challenges_count;
        let height =
            drgraph::graph_height::<typenum::U2>(pub_params.sector_size as usize / NODE_SIZE);

        let comm_rs = vec![None; challenges_count];
        let comm_cs = vec![None; challenges_count];
        let comm_r_lasts = vec![None; challenges_count];
        let leafs = vec![None; challenges_count];
        let paths = vec![vec![(vec![None; 1], None); height - 1]; challenges_count];

        RationalPoStCircuit {
            comm_rs,
            comm_cs,
            comm_r_lasts,
            leafs,
            paths,
            _t: PhantomData,
        }
    }
}

impl<'a, Tree: 'static + MerkleTreeTrait> RationalPoStCircuit<Tree> {
    #[allow(clippy::type_complexity)]
    pub fn synthesize<CS: ConstraintSystem<Bls12>>(
        cs: &mut CS,
        leafs: Vec<Option<Fr>>,
        comm_rs: Vec<Option<Fr>>,
        comm_cs: Vec<Option<Fr>>,
        comm_r_lasts: Vec<Option<Fr>>,
        paths: Vec<Vec<(Vec<Option<Fr>>, Option<usize>)>>,
    ) -> Result<(), SynthesisError> {
        Self {
            leafs,
            comm_rs,
            comm_cs,
            comm_r_lasts,
            paths,
            _t: PhantomData,
        }
        .synthesize(cs)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use std::collections::BTreeMap;

    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use storage_proofs_core::{
        compound_proof,
        gadgets::TestConstraintSystem,
        hasher::{Domain, HashFunction, Hasher, PedersenHasher, PoseidonHasher},
        merkle::{generate_tree, get_base_tree_count, BinaryMerkleTree},
        proof::NoRequirements,
        sector::OrderedSectorSet,
    };

    use crate::rational::{self, derive_challenges};

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn rational_post_test_compound_pedersen() {
        rational_post_test_compound::<BinaryMerkleTree<PedersenHasher>>();
    }

    #[ignore] // Slow test – run only when compiled for release.
    #[test]
    fn rational_post_test_compound_poseidon() {
        rational_post_test_compound::<BinaryMerkleTree<PoseidonHasher>>();
    }

    fn rational_post_test_compound<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 32 * get_base_tree_count::<Tree>();
        let sector_size = (leaves * NODE_SIZE) as u64;
        let challenges_count = 2;

        let setup_params = compound_proof::SetupParams {
            vanilla_params: rational::SetupParams {
                sector_size,
                challenges_count,
            },
            partitions: None,
            priority: true,
        };

        let pub_params = RationalPoStCompound::<Tree>::setup(&setup_params).expect("setup failed");

        // Construct and store an MT using a named DiskStore.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        let (_data1, tree1) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
        let (_data2, tree2) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));

        let faults = OrderedSectorSet::new();
        let mut sectors = OrderedSectorSet::new();
        sectors.insert(0.into());
        sectors.insert(1.into());

        let seed = (0..leaves).map(|_| rng.gen()).collect::<Vec<u8>>();
        let challenges =
            derive_challenges(challenges_count, sector_size, &sectors, &seed, &faults).unwrap();

        let comm_r_lasts_raw = vec![tree1.root(), tree2.root()];
        let comm_r_lasts: Vec<_> = challenges
            .iter()
            .map(|c| comm_r_lasts_raw[u64::from(c.sector) as usize])
            .collect();

        let comm_cs: Vec<<Tree::Hasher as Hasher>::Domain> = challenges
            .iter()
            .map(|_c| <Tree::Hasher as Hasher>::Domain::random(rng))
            .collect();

        let comm_rs: Vec<_> = comm_cs
            .iter()
            .zip(comm_r_lasts.iter())
            .map(|(comm_c, comm_r_last)| {
                <Tree::Hasher as Hasher>::Function::hash2(comm_c, comm_r_last)
            })
            .collect();

        let pub_inputs = rational::PublicInputs {
            challenges: &challenges,
            faults: &faults,
            comm_rs: &comm_rs,
        };

        let mut trees = BTreeMap::new();
        trees.insert(0.into(), &tree1);
        trees.insert(1.into(), &tree2);

        let priv_inputs = rational::PrivateInputs::<Tree> {
            trees: &trees,
            comm_r_lasts: &comm_r_lasts,
            comm_cs: &comm_cs,
        };

        let gparams =
            RationalPoStCompound::<Tree>::groth_params(Some(rng), &pub_params.vanilla_params)
                .expect("failed to create groth params");

        let proof =
            RationalPoStCompound::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs, &gparams)
                .expect("proving failed");

        let (circuit, inputs) =
            RationalPoStCompound::<Tree>::circuit_for_test(&pub_params, &pub_inputs, &priv_inputs)
                .unwrap();

        {
            let mut cs = TestConstraintSystem::new();

            circuit.synthesize(&mut cs).expect("failed to synthesize");
            assert!(cs.is_satisfied());
            assert!(cs.verify(&inputs));
        }

        let verified =
            RationalPoStCompound::<Tree>::verify(&pub_params, &pub_inputs, &proof, &NoRequirements)
                .expect("failed while verifying");

        assert!(verified);
    }
}

'''
'''--- storage-proofs/post/src/rational/mod.rs ---
mod circuit;
mod compound;
mod vanilla;

pub use self::circuit::*;
pub use self::compound::*;
pub use self::vanilla::*;

'''
'''--- storage-proofs/post/src/rational/vanilla.rs ---
use std::collections::{BTreeMap, HashSet};
use std::marker::PhantomData;

use anyhow::{bail, ensure, Context};
use byteorder::{ByteOrder, LittleEndian};
use serde::{Deserialize, Serialize};

use storage_proofs_core::{
    error::{Error, Result},
    hasher::{Domain, HashFunction, Hasher},
    merkle::{MerkleProof, MerkleProofTrait, MerkleTreeTrait, MerkleTreeWrapper},
    parameter_cache::ParameterSetMetadata,
    proof::{NoRequirements, ProofScheme},
    sector::*,
    util::NODE_SIZE,
};

#[derive(Debug, Clone)]
pub struct SetupParams {
    /// The size of a sector.
    pub sector_size: u64,
    // TODO: can we drop this?
    /// How many challenges there are in total.
    pub challenges_count: usize,
}

#[derive(Debug, Clone)]
pub struct PublicParams {
    /// The size of a sector.
    pub sector_size: u64,
    /// How many challenges there are in total.
    pub challenges_count: usize,
}

impl ParameterSetMetadata for PublicParams {
    fn identifier(&self) -> String {
        format!(
            "RationalPoSt::PublicParams{{sector_size: {} challenges_count: {}}}",
            self.sector_size(),
            self.challenges_count,
        )
    }

    fn sector_size(&self) -> u64 {
        self.sector_size
    }
}

#[derive(Debug, Clone)]
pub struct PublicInputs<'a, T: 'a + Domain> {
    /// The challenges, which leafs to prove.
    pub challenges: &'a [Challenge],
    pub faults: &'a OrderedSectorSet,
    pub comm_rs: &'a [T],
}

#[derive(Debug, Clone)]
#[allow(clippy::type_complexity)]
pub struct PrivateInputs<'a, Tree: 'a + MerkleTreeTrait> {
    pub trees: &'a BTreeMap<
        SectorId,
        &'a MerkleTreeWrapper<
            Tree::Hasher,
            Tree::Store,
            Tree::Arity,
            Tree::SubTreeArity,
            Tree::TopTreeArity,
        >,
    >,
    pub comm_cs: &'a Vec<<Tree::Hasher as Hasher>::Domain>,
    pub comm_r_lasts: &'a Vec<<Tree::Hasher as Hasher>::Domain>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Proof<P: MerkleProofTrait> {
    #[serde(bound(
        serialize = "MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>: Serialize",
        deserialize = "MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>: serde::de::DeserializeOwned"
    ))]
    inclusion_proofs: Vec<MerkleProof<P::Hasher, P::Arity, P::SubTreeArity, P::TopTreeArity>>,
    pub comm_cs: Vec<<P::Hasher as Hasher>::Domain>,
}

impl<P: MerkleProofTrait> Proof<P> {
    pub fn leafs(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::leaf)
            .collect()
    }

    pub fn commitments(&self) -> Vec<<P::Hasher as Hasher>::Domain> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::root)
            .collect()
    }

    #[allow(clippy::type_complexity)]
    pub fn paths(&self) -> Vec<Vec<(Vec<<P::Hasher as Hasher>::Domain>, usize)>> {
        self.inclusion_proofs
            .iter()
            .map(MerkleProof::path)
            .collect()
    }
}

#[derive(Debug, Clone)]
pub struct RationalPoSt<'a, Tree>
where
    Tree: 'a + MerkleTreeTrait,
{
    _t: PhantomData<&'a Tree>,
}

impl<'a, Tree: 'a + MerkleTreeTrait> ProofScheme<'a> for RationalPoSt<'a, Tree> {
    type PublicParams = PublicParams;
    type SetupParams = SetupParams;
    type PublicInputs = PublicInputs<'a, <Tree::Hasher as Hasher>::Domain>;
    type PrivateInputs = PrivateInputs<'a, Tree>;
    type Proof = Proof<Tree::Proof>;
    type Requirements = NoRequirements;

    fn setup(sp: &Self::SetupParams) -> Result<Self::PublicParams> {
        Ok(PublicParams {
            sector_size: sp.sector_size,
            challenges_count: sp.challenges_count,
        })
    }

    fn prove<'b>(
        _pub_params: &'b Self::PublicParams,
        pub_inputs: &'b Self::PublicInputs,
        priv_inputs: &'b Self::PrivateInputs,
    ) -> Result<Self::Proof> {
        ensure!(
            pub_inputs.challenges.len() == pub_inputs.comm_rs.len(),
            "mismatched challenges and comm_rs"
        );
        ensure!(
            pub_inputs.challenges.len() == priv_inputs.comm_cs.len(),
            "mismatched challenges and comm_cs"
        );
        ensure!(
            pub_inputs.challenges.len() == priv_inputs.comm_r_lasts.len(),
            "mismatched challenges and comm_r_lasts"
        );
        let challenges = pub_inputs.challenges;

        let proofs = challenges
            .iter()
            .zip(priv_inputs.comm_r_lasts.iter())
            .map(|(challenge, comm_r_last)| {
                let challenged_leaf = challenge.leaf;

                if let Some(tree) = priv_inputs.trees.get(&challenge.sector) {
                    ensure!(comm_r_last == &tree.root(), Error::InvalidCommitment);

                    tree.gen_cached_proof(challenged_leaf as usize, None)
                } else {
                    bail!(Error::MalformedInput);
                }
            })
            .collect::<Result<Vec<_>>>()?;

        Ok(Proof {
            inclusion_proofs: proofs,
            comm_cs: priv_inputs.comm_cs.to_vec(),
        })
    }

    fn verify(
        pub_params: &Self::PublicParams,
        pub_inputs: &Self::PublicInputs,
        proof: &Self::Proof,
    ) -> Result<bool> {
        let challenges = pub_inputs.challenges;

        ensure!(
            challenges.len() == pub_inputs.comm_rs.len() as usize,
            Error::MalformedInput
        );

        ensure!(
            challenges.len() == proof.inclusion_proofs.len(),
            Error::MalformedInput
        );

        // validate each proof
        for (((merkle_proof, challenge), comm_r), comm_c) in proof
            .inclusion_proofs
            .iter()
            .zip(challenges.iter())
            .zip(pub_inputs.comm_rs.iter())
            .zip(proof.comm_cs.iter())
        {
            let challenged_leaf = challenge.leaf;

            // verify that H(Comm_c || Comm_r_last) == Comm_R
            // comm_r_last is the root of the proof
            let comm_r_last = merkle_proof.root();

            if AsRef::<[u8]>::as_ref(&<Tree::Hasher as Hasher>::Function::hash2(
                comm_c,
                &comm_r_last,
            )) != AsRef::<[u8]>::as_ref(&comm_r)
            {
                return Ok(false);
            }

            // validate the path length
            let expected_path_length =
                merkle_proof.expected_len(pub_params.sector_size as usize / NODE_SIZE);

            if expected_path_length != merkle_proof.path().len() {
                return Ok(false);
            }

            if !merkle_proof.validate(challenged_leaf as usize) {
                return Ok(false);
            }
        }

        Ok(true)
    }
}

/// A challenge specifying a sector and leaf.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Challenge {
    // The identifier of the challenged sector.
    pub sector: SectorId,
    // The leaf index this challenge points at.
    pub leaf: u64,
}

/// Rational PoSt specific challenge derivation.
pub fn derive_challenges(
    challenge_count: usize,
    sector_size: u64,
    sectors: &OrderedSectorSet,
    seed: &[u8],
    faults: &OrderedSectorSet,
) -> Result<Vec<Challenge>> {
    (0..challenge_count)
        .map(|n| {
            let mut attempt = 0;
            let mut attempted_sectors = HashSet::new();
            loop {
                let c = derive_challenge(seed, n as u64, attempt, sector_size, sectors)?;

                // check for faulty sector
                if !faults.contains(&c.sector) {
                    // valid challenge, not found
                    return Ok(c);
                } else {
                    attempt += 1;
                    attempted_sectors.insert(c.sector);

                    ensure!(
                        attempted_sectors.len() < sectors.len(),
                        "all sectors are faulty"
                    );
                }
            }
        })
        .collect()
}

fn derive_challenge(
    seed: &[u8],
    n: u64,
    attempt: u64,
    sector_size: u64,
    sectors: &OrderedSectorSet,
) -> Result<Challenge> {
    let mut data = seed.to_vec();
    data.extend_from_slice(&n.to_le_bytes()[..]);
    data.extend_from_slice(&attempt.to_le_bytes()[..]);

    let hash = blake2b_simd::blake2b(&data);
    let challenge_bytes = hash.as_bytes();
    let sector_challenge = LittleEndian::read_u64(&challenge_bytes[..8]);
    let leaf_challenge = LittleEndian::read_u64(&challenge_bytes[8..16]);

    let sector_index = (sector_challenge % sectors.len() as u64) as usize;
    let sector = *sectors
        .iter()
        .nth(sector_index)
        .context("invalid challenge generated")?;

    Ok(Challenge {
        sector,
        leaf: leaf_challenge % (sector_size / NODE_SIZE as u64),
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use generic_array::typenum;
    use rand::{Rng, SeedableRng};
    use rand_xorshift::XorShiftRng;
    use typenum::{U0, U2, U8};

    use storage_proofs_core::{
        hasher::{Blake2sHasher, Domain, Hasher, PedersenHasher, PoseidonHasher, Sha256Hasher},
        merkle::{generate_tree, get_base_tree_count, LCTree, MerkleTreeTrait},
    };

    fn test_rational_post<Tree: MerkleTreeTrait>()
    where
        Tree::Store: 'static,
    {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves as u64 * 32;
        let challenges_count = 8;

        let pub_params = PublicParams {
            sector_size,
            challenges_count,
        };

        // Construct and store an MT using a named store.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        let (_data1, tree1) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
        let (_data2, tree2) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));

        let seed = (0..leaves).map(|_| rng.gen()).collect::<Vec<u8>>();
        let mut faults = OrderedSectorSet::new();
        faults.insert(139.into());
        faults.insert(1.into());
        faults.insert(32.into());

        let mut sectors = OrderedSectorSet::new();
        sectors.insert(891.into());
        sectors.insert(139.into());
        sectors.insert(32.into());
        sectors.insert(1.into());

        let mut trees = BTreeMap::new();
        trees.insert(139.into(), &tree1); // faulty with tree
        trees.insert(891.into(), &tree2);
        // other two faults don't have a tree available

        let challenges =
            derive_challenges(challenges_count, sector_size, &sectors, &seed, &faults).unwrap();

        // the only valid sector to challenge is 891
        assert!(
            challenges.iter().all(|c| c.sector == 891.into()),
            "invalid challenge generated"
        );

        let comm_r_lasts = challenges
            .iter()
            .map(|c| trees.get(&c.sector).unwrap().root())
            .collect::<Vec<_>>();

        let comm_cs: Vec<<Tree::Hasher as Hasher>::Domain> = challenges
            .iter()
            .map(|_c| <Tree::Hasher as Hasher>::Domain::random(rng))
            .collect();

        let comm_rs: Vec<<Tree::Hasher as Hasher>::Domain> = comm_cs
            .iter()
            .zip(comm_r_lasts.iter())
            .map(|(comm_c, comm_r_last)| {
                <Tree::Hasher as Hasher>::Function::hash2(comm_c, comm_r_last)
            })
            .collect();

        let pub_inputs = PublicInputs {
            challenges: &challenges,
            comm_rs: &comm_rs,
            faults: &faults,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            trees: &trees,
            comm_cs: &comm_cs,
            comm_r_lasts: &comm_r_lasts,
        };

        let proof = RationalPoSt::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
            .expect("proving failed");

        let is_valid = RationalPoSt::<Tree>::verify(&pub_params, &pub_inputs, &proof)
            .expect("verification failed");

        assert!(is_valid);
    }

    #[test]
    fn rational_post_pedersen() {
        test_rational_post::<LCTree<PedersenHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_sha256() {
        test_rational_post::<LCTree<Sha256Hasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_blake2s() {
        test_rational_post::<LCTree<Blake2sHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_poseidon() {
        test_rational_post::<LCTree<PoseidonHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_poseidon_8_8() {
        test_rational_post::<LCTree<PoseidonHasher, U8, U8, U0>>();
    }

    #[test]
    fn rational_post_poseidon_8_8_2() {
        test_rational_post::<LCTree<PoseidonHasher, U8, U8, U2>>();
    }

    fn test_rational_post_validates_challenge_identity<Tree: 'static + MerkleTreeTrait>() {
        let rng = &mut XorShiftRng::from_seed(crate::TEST_SEED);

        let leaves = 64 * get_base_tree_count::<Tree>();
        let sector_size = leaves as u64 * 32;
        let challenges_count = 2;

        let pub_params = PublicParams {
            sector_size,
            challenges_count,
        };

        // Construct and store an MT using a named store.
        let temp_dir = tempdir::TempDir::new("tree").unwrap();
        let temp_path = temp_dir.path();

        let (_data, tree) = generate_tree::<Tree, _>(rng, leaves, Some(temp_path.to_path_buf()));
        let seed = (0..leaves).map(|_| rng.gen()).collect::<Vec<u8>>();
        let mut faults = OrderedSectorSet::new();
        faults.insert(1.into());
        let mut sectors = OrderedSectorSet::new();
        sectors.insert(0.into());
        sectors.insert(1.into());

        let mut trees = BTreeMap::new();
        trees.insert(0.into(), &tree);

        let challenges =
            derive_challenges(challenges_count, sector_size, &sectors, &seed, &faults).unwrap();
        let comm_r_lasts = challenges
            .iter()
            .map(|c| trees.get(&c.sector).unwrap().root())
            .collect::<Vec<_>>();

        let comm_cs: Vec<<Tree::Hasher as Hasher>::Domain> = challenges
            .iter()
            .map(|_c| <Tree::Hasher as Hasher>::Domain::random(rng))
            .collect();

        let comm_rs: Vec<<Tree::Hasher as Hasher>::Domain> = comm_cs
            .iter()
            .zip(comm_r_lasts.iter())
            .map(|(comm_c, comm_r_last)| {
                <Tree::Hasher as Hasher>::Function::hash2(comm_c, comm_r_last)
            })
            .collect();

        let pub_inputs = PublicInputs {
            challenges: &challenges,
            faults: &faults,
            comm_rs: &comm_rs,
        };

        let priv_inputs = PrivateInputs::<Tree> {
            trees: &trees,
            comm_cs: &comm_cs,
            comm_r_lasts: &comm_r_lasts,
        };

        let proof = RationalPoSt::<Tree>::prove(&pub_params, &pub_inputs, &priv_inputs)
            .expect("proving failed");

        let seed = (0..leaves).map(|_| rng.gen()).collect::<Vec<u8>>();
        let challenges =
            derive_challenges(challenges_count, sector_size, &sectors, &seed, &faults).unwrap();
        let comm_r_lasts = challenges.iter().map(|_c| tree.root()).collect::<Vec<_>>();

        let comm_cs: Vec<<Tree::Hasher as Hasher>::Domain> = challenges
            .iter()
            .map(|_c| <Tree::Hasher as Hasher>::Domain::random(rng))
            .collect();

        let comm_rs: Vec<<Tree::Hasher as Hasher>::Domain> = comm_cs
            .iter()
            .zip(comm_r_lasts.iter())
            .map(|(comm_c, comm_r_last)| {
                <Tree::Hasher as Hasher>::Function::hash2(comm_c, comm_r_last)
            })
            .collect();

        let different_pub_inputs = PublicInputs {
            challenges: &challenges,
            faults: &faults,
            comm_rs: &comm_rs,
        };

        let verified = RationalPoSt::<Tree>::verify(&pub_params, &different_pub_inputs, &proof)
            .expect("verification failed");

        // A proof created with a the wrong challenge not be verified!
        assert!(!verified);
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_sha256() {
        test_rational_post_validates_challenge_identity::<LCTree<Sha256Hasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_blake2s() {
        test_rational_post_validates_challenge_identity::<LCTree<Blake2sHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_pedersen() {
        test_rational_post_validates_challenge_identity::<LCTree<PedersenHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_poseidon() {
        test_rational_post_validates_challenge_identity::<LCTree<PoseidonHasher, U8, U0, U0>>();
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_poseidon_8_8() {
        test_rational_post_validates_challenge_identity::<LCTree<PoseidonHasher, U8, U8, U0>>();
    }

    #[test]
    fn rational_post_actually_validates_challenge_identity_poseidon_8_8_2() {
        test_rational_post_validates_challenge_identity::<LCTree<PoseidonHasher, U8, U8, U2>>();
    }

    #[test]
    fn test_derive_challenges_fails_on_all_faulty() {
        use std::collections::BTreeSet;

        let mut sectors = BTreeSet::new();
        sectors.insert(SectorId::from(1));
        sectors.insert(SectorId::from(2));

        let mut faults = BTreeSet::new();
        faults.insert(SectorId::from(1));
        faults.insert(SectorId::from(2));

        let seed = vec![0u8];

        assert!(derive_challenges(10, 1024, &sectors, &seed, &faults).is_err());
    }
}

'''
'''--- storage-proofs/src/lib.rs ---
pub use storage_proofs_core::*;
pub use storage_proofs_porep as porep;
pub use storage_proofs_post as post;

'''