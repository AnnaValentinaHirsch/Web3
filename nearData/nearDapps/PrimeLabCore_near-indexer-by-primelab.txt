*GitHub Repository "PrimeLabCore/near-indexer-by-primelab"*

'''--- .github/workflows/indexer_explorer.yml ---
name: "Indexer Explorer"
permissions:
  id-token: write
  contents: read
on:
  workflow_dispatch:
    inputs:
        version:
          description: 'Release Version'
          required: true
jobs:
  docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    environment: public
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1.6.1
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE_ARN }}
          aws-region: us-east-1
          role-skip-session-tagging: true
      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@master
      - name: Login to Public ECR
        run: |
          aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/r7z8c2r4
      - name: Cache Docker layers
        uses: actions/cache@v2
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
      - name: Build and push
        id: docker-build
        uses: docker/build-push-action@v2
        with:
          context: ./dockerfile/
          builder: ${{ steps.buildx.outputs.name }}
          push: true
          tags: public.ecr.aws/r7z8c2r4/near/indexer-explorer:${{ github.event.inputs.version }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache
        continue-on-error: true

'''
'''--- README.md ---
# Near Indexer for Explorer from PrimeLab!

### Quickly scale up Indexer Nodes with Explorer deployments via Docker

**GitHub:**  [Near-Indexer-for-Explorer](https://github.com/NearPrime/near-indexer-by-primelab)

**Contributors:**  
[PrimeLab Core Tools](https://primelab.io/)
[Near Indexer for Explorer Code Contributors](https://github.com/near/near-indexer-for-explorer)

PrimeLab is excited to release the first iteration of our Near Indexer for Explorer. Our goal for this project is to have a full End-to-End Deployment of the Near Indexer for Explorer.

**Why (is this needed)**

**Who (would this benefit)**

-   Any project in the NEAR Ecosystem. :)

**How (does this achieve a solution):**

**Tech:**

'''
'''--- dockerfile/CHANGELOG.md ---
# Changelog

## 0.10.14

* Fix the bug in logic of finding parent transaction for a receipt

## 0.10.13

* Upgrade `nearcore` to `1.25.0-rc.3`

## 0.10.12

* Upgrade `nearcore` to `1.25.0-rc.1`

## 0.10.11

* Upgrade `nearcore` to `1.24.0-rc.4`

## 0.10.10

* Upgrade `nearcore` to `1.24.0-rc.3`

## 0.10.9

* Add [FT events](https://nomicon.io/Standards/FungibleToken/Event.html) support: `assets__fungible_token_events` table stores the information about FT `mint`, `transfer`, `burn` events
* Add index on `action_receipt_actions` table. Applying migration could take some time
* Introduce `ReceiptsCache` to optimize the way we match `Receipts` with parent `Transactions`
* Upgrade nearcore to `1.24.0-rc.2`

## 0.10.8

* Upgrade nearcore to `1.24.0-rc.1`

## 0.10.7

* Upgrade `nearcore` to 1.23.1
* Optimized the latency of putting the data into database

## 0.10.6

* Upgrade `nearcore` to 1.23.1-rc.2

## 0.10.5

* Upgrade `nearcore` to 1.23.1-rc.1

## 0.10.4

* Upgrade `nearcore` to 1.23.0
* Handle transaction hash collisions (issue #84)

## 0.10.3

* Upgrade `nearcore` to 1.22.0
* Add [NFT events](https://nomicon.io/Standards/NonFungibleToken/Event.html) support: `assets__non_fungible_token_events` table stores the information about NFT `mint`, `transfer`, `burn` events

## 0.10.2

- Change the retry logic. Make indexer fail with error if is has retried for 5 min
- Upgrade `nearcore` to 1.22.0

## 0.10.1

* Upgrade `nearcore` to 1.21.1

## 0.10.0

* Drop `--allow-missing-relations-in-first-blocks` flag
* Introduce `--non-strict-mode` which does the same as `--allow-missing-relations-in-first-blocks` flag did but endlessly
* Add `--stop-after-number-of-blocks <count>` flag to plan Indexer for Explorer to stop once it indexed the provided `<count>` of blocks. May be useful for debug or maintenance purposes.

## Breaking changes

* The flag `--allow-missing-relations-in-first-blocks` is not available anymore in favor of `--non-strict-mode` flag

## 0.9.3

* Escape `args_json` on the fly to avoid null-byte issues
* Upgrade to NEAR Indexer Framework `0.10.0`
* Refactor the storing Accounts and AccessKeys from genesis to optimize memory usage
* Improve logging to better understand what Indexer for Explorer is doing on the start

## 0.9.2 (hotfix)

* Change `receiver_id` field type to `String` to be compatible with `nearcore` `AccessKeyPermissionView` struct (it caused problems during AccessKey serialization)

## 0.9.1

* Upgrade `nearcore` to 1.21.0 (rc1)

## 0.9.0 (nearcore dependency contains bug)

* Upgrade `nearcore` to 1.21.0

## Breaking changes

* `init` command has changed according to changes in `nearcore`:
  - `download` argument has been replaced with `download_config` and `download_genesis`
  - `boot_nodes` argument was added
  - `download_config_url` was added
* `AccountId` from `near-primitives` was replaced with separate crate `near-account-id` and it is no longer an alias for `String`
  - All the fields related to an account id have type `near_account_id::AccountId`

## 0.8.0

* Background calculation of circulating supply and storing it to DB
* Improvements on some tables (add indexes, simplify sorting etc.)

## 0.7.1

* Update nearcore version to 1.20.0-rc.2

## 0.7.0

* Handle null-bytes in `AddKey` actions
* Update nearcore version to 1.20.0

## Breaking change

`init_configs` function from nearcore has been extended with additional optional parameter `max_gas_burnt_view`. We've extended NEAR Indexer for Explorer `InitConfigArgs`

## 0.6.9

* Add `--concurrency` parameter to adjust the number of simultaneously running asynchronous adapters

## 0.6.8

* Update NEAR Indexer Framework version to 0.9.2 (with optimized delayed receipts tracking system)

## 0.6.7

* Remove duplicates from `account_changes` table by fixing unique index ([see issue #74](https://github.com/near/near-indexer-for-explorer/issues/74))

## 0.6.6 (hotfix)

* Upgrade `nearcore` to 1.19.1 (hotfix)

## 0.6.5

* Update NEAR Indexer Framework version to 0.9.1 (previous contained a bug with processing delayed local receipts)

## 0.6.4 (contains bug)

* Fix the overwriting of `created_by_receipt_id` for implicit accounts that may confuse users ([see issue #68 for ref](https://github.com/near/near-indexer-for-explorer/issues/68))

## 0.6.3

* Denormalize table `action_receipt_actions` in order to speed up some queries by avoid
  additional joins
* Extend `extract_action_type_and_value_from_action_view` function to try to parse base64 encoded args
  as a JSON object to put them decoded in the function call args `action_receipt_actions.args` additionally

## 0.6.2

* Upgrade `nearcore` dependency to exclude recent updates to runtime which caused a bug ([see for ref](https://github.com/near/nearcore/releases/tag/1.19.0-rc.2))

## 0.6.1

* Upgrade `nearcore` to support newer protocol version (45)

## 0.6.0

* Upgrade `nearcore` to get NEAR Indexer Framework 0.9.0
* Corresponding changes into adapters according to changes in `StreamerMessage` structure
* NEAR Indexer for Explorer now uses stable Rust (`rust-toolchain` has been updated accordingly) 

## 0.5.0

* Tweak `sync-from-interruption` mode to start syncing from N blocks earlier that actual interruption

## 0.4.0

* Update `nearcore` dependency
* Update underlying dependencies to correspond `nearcore`

**The way of starting `actix` runtime has changes**

## 0.3.0

* Migrate from `tokio-diesel` to `actix-diesel` (patched by @frol)

## 0.2.3

* Upgrade `nearcore` dependency
* Upgrade some external dependencies (`actix`, `tokio`)

## 0.2.2

* Fill `deleted_by_receipt_id` if `access_key` on owner account deletion

## 0.2.1

* Add `access_key` on transfer to implicit account action
* Upgrade `nearcore` dependency

'''
'''--- dockerfile/Cargo.toml ---
[package]
name = "indexer-explorer"
version = "0.10.14"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2021"

[dependencies]
actix = "=0.11.0-beta.2"
actix-rt = "=2.2.0"  # remove it once actix is upgraded to 0.11+
actix-web = "=4.0.0-beta.6"
actix-http = "=3.0.0-beta.6"
actix-tls = "=3.0.0-beta.5"
actix_derive = "=0.6.0-beta.1"
anyhow = "1.0.51"
base64 = "0.11"
bigdecimal = "=0.1.0"
borsh = "0.7.1"
cached = "0.23.0"
chrono = "0.4.19"
clap = { version = "3.0.0-beta.5", features = ["color", "derive", "env"] }
diesel = { version = "1.4.7", features = ["postgres", "numeric", "serde_json"] }
# Using hacky diesel-derive-enum https://github.com/adwhit/diesel-derive-enum/issues/52
diesel-derive-enum = { git = "https://github.com/khorolets/diesel-derive-enum.git", branch = "lookup-hack", features = ["postgres"] }
dotenv = "0.15.0"
futures = "0.3.5"
hex = "0.4"
itertools = "0.10.3"
# syn version conflict, replace with crates.io version once released
near-sdk = { git = "https://github.com/near/near-sdk-rs", rev="03487c184d37b0382dd9bd41c57466acad58fc1f" }
num-traits = "0.2.11"
openssl-probe = { version = "0.1.2" }
r2d2 = "0.8.8"
serde = { version = "1", features = ["derive"] }
serde_json = "1.0.55"
tokio = { version = "1.1", features = ["sync", "time"] }
tokio-stream = { version = "0.1" }
tracing = "0.1.13"
tracing-subscriber = "0.2.4"
uint = { version = "0.8.3", default-features = false }

actix-diesel = { git = "https://github.com/frol/actix-diesel", branch = "actix-0.11-beta.2" }
near-indexer = { git = "https://github.com/near/nearcore", rev = "4ac008b4a0194ed816f33c1c3a6da5159e25cac1" }
near-crypto = { git = "https://github.com/near/nearcore", rev = "4ac008b4a0194ed816f33c1c3a6da5159e25cac1" }
near-client = { git = "https://github.com/near/nearcore", rev = "4ac008b4a0194ed816f33c1c3a6da5159e25cac1" }

'''
'''--- dockerfile/diesel.toml ---
# For documentation on how to configure this file,
# see diesel.rs/guides/configuring-diesel-cli

[print_schema]
file = "src/schema.rs"
patch_file = "src/schema.patch"
import_types = ["diesel::sql_types::*", "crate::models::enums::*"]
# Exclicitly setting `only_tables` to avoid technical tables created by diesel to be included in schema
filter = { only_tables = [
    "blocks",
    "chunks",
    "receipts",
    "data_receipts",
    "action_receipts",
    "action_receipt_actions",
    "action_receipt_input_data",
    "action_receipt_output_data",
    "execution_outcomes",
    "execution_outcome_receipts",
    "transactions",
    "transaction_actions",
    "accounts",
    "access_keys",
    "account_changes",
    "aggregated__circulating_supply",
    "assets__non_fungible_token_events",
    "assets__fungible_token_events"
] }

'''
'''--- dockerfile/docker_entrypoint.sh ---
#!/usr/bin/env bash
set -euo pipefail   # Bash "strict mode"
script_dirpath="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# ==================================================================================================
#                                       Arg Parsing & Validation
# ==================================================================================================
show_helptext_and_exit() {
    echo "Usage: $(basename "${0}") diesel_binary_filepath database_url indexer_binary_filepath chain_id download_archive sync_command sync_delta [extra_indexer_param]..."
    echo ""
    echo "  diesel_binary_filepath  The filepath to the Diesel binary that will be used to run the database migration"
    echo "  database_url            The URL of the database against which the Diesel migration should be run, and the "
    echo "                          indexer should connect to (e.g. \"postgres://near:near@contract-helper-db:5432/indexer\")"
    echo "  indexer_binary_filepath The filepath to the binary that will run the indexer node"
    echo "  chain_id                The near blockchain you want to run (e.g. localnet, testnet, or mainnet). Defaults to mainnet."
    echo "  download_archive        Whither to download the backup archive or not (e.g. true, false). Defaults to true."
    echo "  sync_command            The command to start the indexer (e.g. sync-from-latest, sync-from-interruption --delta <sync_delta>,"
    echo "                          sync-from-block --height <block_height>). Defaults to sync-from-block --height <block_height>"
    echo "  sync_delta              The number of blocks to start sync from interruption (e.g. check 500 blocks before interuption, then sync)."
    echo "                          Defaults to 500."
    echo ""
    exit 1  # Exit with an error so that if this is accidentally called by CI, the script will fail
}

diesel_binary_filepath="${1:-}"
database_url="${2:-}"
indexer_binary_filepath="${3:-}"
chain_id="${4:-mainnet}"
download_archive="${5:-true}"
sync_command="${6:-}"
sync_delta="${7:-}"

shift 7   # Prep for consuming the extra indexer params below

# ==================================================================================================
#                                             Constants
# ==================================================================================================
# Config properties that will be set as part of startup
TRACKED_SHARD_CONFIG_PROPERTY="tracked_shards"
ARCHIVE_CONFIG_PROPERTY="archive"
# The path where the localnet NEAR config dir will be initialized
NEAR_DIRPATH="/root/.near/${chain_id}"
CONFIG_JSON_FILEPATH="${NEAR_DIRPATH}/config.json"

if [ -z "${diesel_binary_filepath}" ]; then
    echo "Error: no Diesel binary filepath provided" >&2
    show_helptext_and_exit
fi
if ! [ -f "${diesel_binary_filepath}" ]; then
    echo "Error: provided Diesel binary filepath '${some_filepath_arg}' isn't a valid file" >&2
    show_helptext_and_exit
fi
if [ -z "${database_url}" ]; then
    echo "Error: no database URL provided" >&2
    show_helptext_and_exit
fi
if [ -z "${indexer_binary_filepath}" ]; then
    echo "Error: no indexer binary filepath provided" >&2
    show_helptext_and_exit
fi
if ! [ -f "${indexer_binary_filepath}" ]; then
    echo "Error: provided indexer binary filepath '${some_filepath_arg}' isn't a valid file" >&2
    show_helptext_and_exit
fi

case $chain_id in

  mainnet)
    CHAIN_DATA_ARCHIVE_URL="https://near-protocol-public.s3-accelerate.amazonaws.com/backups/mainnet/archive/data.tar"
    if [ -z "$sync_delta" ]
    then
          COMPLETE_COMMAND="${sync_command:-sync-from-block --height 9820214}"
    else
          COMPLETE_COMMAND="${sync_command --delta $sync_delta:-sync-from-interruption --delta 500}"
    fi
    ;;

  testnet)
    CHAIN_DATA_ARCHIVE_URL="https://near-protocol-public.s3-accelerate.amazonaws.com/backups/testnet/archive/data.tar"
    if [ -z "$sync_delta" ]
    then
          COMPLETE_COMMAND="${sync_command:-sync-from-block --height 42376923}"
    else
          COMPLETE_COMMAND="${sync_command --delta $sync_delta:-sync-from-interruption --delta 500}"
    fi
    ;;

  localnet)
    unset CHAIN_DATA_ARCHIVE_URL
    unset sync_delta
    COMPLETE_COMMAND="${sync_command:-sync-from-latest}"
    ;;

  *)
    CHAIN_DATA_ARCHIVE_URL="https://near-protocol-public.s3-accelerate.amazonaws.com/backups/mainnet/archive/data.tar"
    if [ -z "$sync_delta" ]
    then
          COMPLETE_COMMAND="${sync_command:-sync-from-block --height 9820214}"
    else
          COMPLETE_COMMAND="${sync_command --delta $sync_delta:-sync-from-interruption --delta 500}"
    fi
    ;;
esac

# ==================================================================================================
#                                             Main Logic
# ==================================================================================================
# We add this check to see if the localnet directory already exists so that we can restart the
# indexer-for-explorer container: if the directory doesn't exist, the container is starting for the
# first time; if it already exists, the container is restarting so there's no need to do the migration
# or genesis setup
if ! [ -d "${NEAR_DIRPATH}" ]; then
    if ! DATABASE_URL="${database_url}" "${diesel_binary_filepath}" migration run; then
        echo "Error: The Diesel migration failed" >&2
        exit 1
    fi

    if ! DATABASE_URL="${database_url}" "${indexer_binary_filepath}" --home-dir "${NEAR_DIRPATH}" init ${BOOT_NODES:+--boot-nodes=${BOOT_NODES}} --chain-id ${chain_id}  --download-genesis --download-config; then
        echo "Error: An error occurred generating the genesis information" >&2
        exit 1
    fi

    # Required due to https://github.com/near/near-indexer-for-explorer#configure-near-indexer-for-explorer
    if ! num_tracked_shard_instances="$(grep -c "\"${TRACKED_SHARD_CONFIG_PROPERTY}\":" "${CONFIG_JSON_FILEPATH}" || true)"; then
        echo "Error: An error occurred getting the number of instances of the '${TRACKED_SHARD_CONFIG_PROPERTY}' config property to verify there's only one" >&2
        exit 1
    fi
    if [ "${num_tracked_shard_instances}" -ne 1 ]; then
        echo "Error: Expected exactly one line to match property '${TRACKED_SHARD_CONFIG_PROPERTY}' in config file '${CONFIG_JSON_FILEPATH}' but got ${num_tracked_shard_instances}" >&2
        exit 1
    fi
    if ! sed -i 's/"'${TRACKED_SHARD_CONFIG_PROPERTY}'": \[\]/"'${TRACKED_SHARD_CONFIG_PROPERTY}'": \[0\]/' "${CONFIG_JSON_FILEPATH}"; then
        echo "Error: An error occurred setting the tracked shards in the config" >&2
        exit 1
    fi

    # Required to keep more than 5 blocks in memory
    if ! num_archive_instances="$(grep -c "\"${ARCHIVE_CONFIG_PROPERTY}\":" "${CONFIG_JSON_FILEPATH}" || true)"; then
        echo "Error: An error occurred getting the number of instances of the '${ARCHIVE_CONFIG_PROPERTY}' config property to verify there's only one" >&2
        exit 1
    fi
    if [ "${num_archive_instances}" -ne 1 ]; then
        echo "Error: Expected exactly one line to match property '${ARCHIVE_CONFIG_PROPERTY}' in config file '${CONFIG_JSON_FILEPATH}' but got ${num_archive_instances}" >&2
        exit 1
    fi
    if ! sed -i 's/"'${ARCHIVE_CONFIG_PROPERTY}'": false/"'${ARCHIVE_CONFIG_PROPERTY}'": true/' "${CONFIG_JSON_FILEPATH}"; then
        echo "Error: An error occurred setting the archive mode to true" >&2
        exit 1
    fi

    if [ "$download_archive" = true ] ; then
      echo "Info: Starting Data Archive Download" >&2
      axel -n 200 --output=data.tar ${CHAIN_DATA_ARCHIVE_URL} > trace_log 2>&1
      echo "Info: Starting Data Archive Extraction" >&2
      tar xvf - -C ${NEAR_DIRPATH}/data
    fi
fi

# NOTE: The funky ${1+"${@}"} incantation is how you you feed arguments exactly as-is to a child script in Bash
#  ${*} loses quoting and ${@} trips set -e if no arguments are passed, so this incantation says, "if and only if
#  ${1} exists, evaluate ${@}"
DATABASE_URL="${database_url}" "${indexer_binary_filepath}" --home-dir "${NEAR_DIRPATH}" run --store-genesis --stream-while-syncing --non-strict-mode --concurrency 1 ${COMPLETE_COMMAND} ${1+"${@}"}

'''
'''--- dockerfile/migrations/00000000000000_diesel_initial_setup/down.sql ---
-- This file was automatically created by Diesel to setup helper functions
-- and other internal bookkeeping. This file is safe to edit, any future
-- changes will be added to existing projects as new migrations.

DROP FUNCTION IF EXISTS diesel_manage_updated_at(_tbl regclass);
DROP FUNCTION IF EXISTS diesel_set_updated_at();

'''
'''--- dockerfile/migrations/00000000000000_diesel_initial_setup/up.sql ---
-- This file was automatically created by Diesel to setup helper functions
-- and other internal bookkeeping. This file is safe to edit, any future
-- changes will be added to existing projects as new migrations.

-- Sets up a trigger for the given table to automatically set a column called
-- `updated_at` whenever the row is modified (unless `updated_at` was included
-- in the modified columns)
--
-- # Example
--
-- ```sql
-- CREATE TABLE users (id SERIAL PRIMARY KEY, updated_at TIMESTAMP NOT NULL DEFAULT NOW());
--
-- SELECT diesel_manage_updated_at('users');
-- ```
CREATE OR REPLACE FUNCTION diesel_manage_updated_at(_tbl regclass) RETURNS VOID AS $$
BEGIN
    EXECUTE format('CREATE TRIGGER set_updated_at BEFORE UPDATE ON %s
                    FOR EACH ROW EXECUTE PROCEDURE diesel_set_updated_at()', _tbl);
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION diesel_set_updated_at() RETURNS trigger AS $$
BEGIN
    IF (
        NEW IS DISTINCT FROM OLD AND
        NEW.updated_at IS NOT DISTINCT FROM OLD.updated_at
    ) THEN
        NEW.updated_at := current_timestamp;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

'''
'''--- dockerfile/migrations/2020-12-07-153402_initial_schema/down.sql ---
DROP TABLE public.access_keys;
DROP TABLE public.account_changes;
DROP TABLE public.accounts;
DROP TABLE public.execution_outcome_receipts;
DROP TABLE public.execution_outcomes;
DROP TABLE public.action_receipts;
DROP TABLE public.action_receipt_input_data;
DROP TABLE public.action_receipt_output_data;
DROP TABLE public.action_receipt_actions;
DROP TABLE public.data_receipts;
DROP TABLE public.receipts;
DROP TABLE public.transaction_actions;
DROP TABLE public.transactions;
DROP TABLE public.chunks;
DROP TABLE public.blocks;

DROP TYPE public.access_key_permission_kind;
DROP TYPE public.action_kind;
DROP TYPE public.execution_outcome_status;
DROP TYPE public.receipt_kind;
DROP TYPE public.state_change_reason_kind;

'''
'''--- dockerfile/migrations/2020-12-07-153402_initial_schema/up.sql ---
--
-- PostgreSQL database dump
--
--
-- Name: access_key_permission_kind; Type: TYPE; Schema: public; Owner: -
--

CREATE TYPE public.access_key_permission_kind AS ENUM (
    'FULL_ACCESS',
    'FUNCTION_CALL'
);

--
-- Name: action_kind; Type: TYPE; Schema: public; Owner: -
--

CREATE TYPE public.action_kind AS ENUM (
    'CREATE_ACCOUNT',
    'DEPLOY_CONTRACT',
    'FUNCTION_CALL',
    'TRANSFER',
    'STAKE',
    'ADD_KEY',
    'DELETE_KEY',
    'DELETE_ACCOUNT'
);

--
-- Name: execution_outcome_status; Type: TYPE; Schema: public; Owner: -
--

CREATE TYPE public.execution_outcome_status AS ENUM (
    'UNKNOWN',
    'FAILURE',
    'SUCCESS_VALUE',
    'SUCCESS_RECEIPT_ID'
);

--
-- Name: receipt_kind; Type: TYPE; Schema: public; Owner: -
--

CREATE TYPE public.receipt_kind AS ENUM (
    'ACTION',
    'DATA'
);

--
-- Name: state_change_reason_kind; Type: TYPE; Schema: public; Owner: -
--

CREATE TYPE public.state_change_reason_kind AS ENUM (
    'TRANSACTION_PROCESSING',
    'ACTION_RECEIPT_PROCESSING_STARTED',
    'ACTION_RECEIPT_GAS_REWARD',
    'RECEIPT_PROCESSING',
    'POSTPONED_RECEIPT',
    'UPDATED_DELAYED_RECEIPTS',
    'VALIDATOR_ACCOUNTS_UPDATE'
);

--
-- Name: access_keys; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.access_keys (
    public_key text NOT NULL,
    account_id text NOT NULL,
    created_by_receipt_id text,
    deleted_by_receipt_id text,
    permission_kind public.access_key_permission_kind NOT NULL,
    last_update_block_height numeric(20,0) NOT NULL
);

--
-- Name: account_changes; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.account_changes (
    id bigserial NOT NULL,
    affected_account_id text NOT NULL,
    changed_in_block_timestamp numeric(20,0) NOT NULL,
    changed_in_block_hash text NOT NULL,
    caused_by_transaction_hash text,
    caused_by_receipt_id text,
    update_reason public.state_change_reason_kind NOT NULL,
    affected_account_nonstaked_balance numeric(45,0) NOT NULL,
    affected_account_staked_balance numeric(45,0) NOT NULL,
    affected_account_storage_usage numeric(20,0) NOT NULL
);

--
-- Name: accounts; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.accounts (
    id bigserial NOT NULL,
    account_id text NOT NULL,
    created_by_receipt_id text,
    deleted_by_receipt_id text,
    last_update_block_height numeric(20,0) NOT NULL
);

--
-- Name: action_receipt_actions; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.action_receipt_actions (
    receipt_id text NOT NULL,
    index_in_action_receipt integer NOT NULL,
    action_kind public.action_kind NOT NULL,
    args jsonb NOT NULL
);

--
-- Name: action_receipt_input_data; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.action_receipt_input_data (
    input_data_id text NOT NULL,
    input_to_receipt_id text NOT NULL
);

--
-- Name: action_receipt_output_data; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.action_receipt_output_data (
    output_data_id text NOT NULL,
    output_from_receipt_id text NOT NULL,
    receiver_account_id text NOT NULL
);

--
-- Name: action_receipts; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.action_receipts (
    receipt_id text NOT NULL,
    signer_account_id text NOT NULL,
    signer_public_key text NOT NULL,
    gas_price numeric(45,0) NOT NULL
);

--
-- Name: blocks; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.blocks (
    block_height numeric(20,0) NOT NULL,
    block_hash text NOT NULL,
    prev_block_hash text NOT NULL,
    block_timestamp numeric(20,0) NOT NULL,
    total_supply numeric(45,0) NOT NULL,
    gas_price numeric(45,0) NOT NULL,
    author_account_id text NOT NULL
);

--
-- Name: chunks; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.chunks (
    included_in_block_hash text NOT NULL,
    chunk_hash text NOT NULL,
    shard_id numeric(20,0) NOT NULL,
    signature text NOT NULL,
    gas_limit numeric(20,0) NOT NULL,
    gas_used numeric(20,0) NOT NULL,
    author_account_id text NOT NULL
);

--
-- Name: data_receipts; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.data_receipts (
    data_id text NOT NULL,
    receipt_id text NOT NULL,
    data bytea
);

--
-- Name: execution_outcome_receipts; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.execution_outcome_receipts (
    executed_receipt_id text NOT NULL,
    index_in_execution_outcome integer NOT NULL,
    produced_receipt_id text NOT NULL
);

--
-- Name: execution_outcomes; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.execution_outcomes (
    receipt_id text NOT NULL,
    executed_in_block_hash text NOT NULL,
    executed_in_block_timestamp numeric(20,0) NOT NULL,
    executed_in_chunk_hash text NOT NULL,
    index_in_chunk integer NOT NULL,
    gas_burnt numeric(20,0) NOT NULL,
    tokens_burnt numeric(45,0) NOT NULL,
    executor_account_id text NOT NULL,
    status public.execution_outcome_status NOT NULL
);

--
-- Name: receipts; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.receipts (
    receipt_id text NOT NULL,
    included_in_block_hash text NOT NULL,
    included_in_chunk_hash text NOT NULL,
    index_in_chunk integer NOT NULL,
    included_in_block_timestamp numeric(20,0) NOT NULL,
    predecessor_account_id text NOT NULL,
    receiver_account_id text NOT NULL,
    receipt_kind public.receipt_kind NOT NULL,
    originated_from_transaction_hash text NOT NULL
);

--
-- Name: transaction_actions; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.transaction_actions (
    transaction_hash text NOT NULL,
    index_in_transaction integer NOT NULL,
    action_kind public.action_kind NOT NULL,
    args jsonb NOT NULL
);

--
-- Name: transactions; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.transactions (
    transaction_hash text NOT NULL,
    included_in_block_hash text NOT NULL,
    included_in_chunk_hash text NOT NULL,
    index_in_chunk integer NOT NULL,
    block_timestamp numeric(20,0) NOT NULL,
    signer_account_id text NOT NULL,
    signer_public_key text NOT NULL,
    nonce numeric(20,0) NOT NULL,
    receiver_account_id text NOT NULL,
    signature text NOT NULL,
    status public.execution_outcome_status NOT NULL,
    converted_into_receipt_id text NOT NULL,
    receipt_conversion_gas_burnt numeric(20,0),
    receipt_conversion_tokens_burnt numeric(45,0)
);

--
-- Name: access_keys access_keys_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.access_keys
    ADD CONSTRAINT access_keys_pk PRIMARY KEY (public_key, account_id);

--
-- Name: account_changes account_changes_affected_account_id_changed_in_block_hash_c_key; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT account_changes_affected_account_id_changed_in_block_hash_c_key UNIQUE (affected_account_id, changed_in_block_hash, caused_by_transaction_hash, caused_by_receipt_id);

--
-- Name: account_changes account_changes_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT account_changes_pkey PRIMARY KEY (id);

--
-- Name: accounts accounts_account_id_key; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT accounts_account_id_key UNIQUE (account_id);

--
-- Name: accounts accounts_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT accounts_pkey PRIMARY KEY (id);

--
-- Name: action_receipt_input_data action_input_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_input_data
    ADD CONSTRAINT action_input_pk PRIMARY KEY (input_data_id, input_to_receipt_id);

--
-- Name: action_receipt_output_data action_output_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_output_data
    ADD CONSTRAINT action_output_pk PRIMARY KEY (output_data_id, output_from_receipt_id);

--
-- Name: blocks blocks_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.blocks
    ADD CONSTRAINT blocks_pkey PRIMARY KEY (block_hash);

--
-- Name: chunks chunks_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.chunks
    ADD CONSTRAINT chunks_pkey PRIMARY KEY (chunk_hash);

--
-- Name: execution_outcome_receipts execution_outcome_receipt_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcome_receipts
    ADD CONSTRAINT execution_outcome_receipt_pk PRIMARY KEY (executed_receipt_id, index_in_execution_outcome, produced_receipt_id);

--
-- Name: execution_outcomes execution_outcomes_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcomes
    ADD CONSTRAINT execution_outcomes_pkey PRIMARY KEY (receipt_id);

--
-- Name: action_receipt_actions receipt_action_action_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_actions
    ADD CONSTRAINT receipt_action_action_pk PRIMARY KEY (receipt_id, index_in_action_receipt);

--
-- Name: action_receipts receipt_actions_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipts
    ADD CONSTRAINT receipt_actions_pkey PRIMARY KEY (receipt_id);

--
-- Name: data_receipts receipt_data_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.data_receipts
    ADD CONSTRAINT receipt_data_pkey PRIMARY KEY (data_id);

--
-- Name: receipts receipts_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.receipts
    ADD CONSTRAINT receipts_pkey PRIMARY KEY (receipt_id);

--
-- Name: transaction_actions transaction_action_pk; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.transaction_actions
    ADD CONSTRAINT transaction_action_pk PRIMARY KEY (transaction_hash, index_in_transaction);

--
-- Name: transactions transactions_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.transactions
    ADD CONSTRAINT transactions_pkey PRIMARY KEY (transaction_hash);

--
-- Name: access_keys_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX access_keys_account_id_idx ON public.access_keys USING btree (account_id);

--
-- Name: access_keys_last_update_block_height_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX access_keys_last_update_block_height_idx ON public.access_keys USING btree (last_update_block_height);

--
-- Name: access_keys_public_key_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX access_keys_public_key_idx ON public.access_keys USING btree (public_key);

--
-- Name: account_changes_affected_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX account_changes_affected_account_id_idx ON public.account_changes USING btree (affected_account_id);

--
-- Name: account_changes_changed_in_block_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX account_changes_changed_in_block_hash_idx ON public.account_changes USING btree (changed_in_block_hash);

--
-- Name: account_changes_changed_in_block_timestamp_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX account_changes_changed_in_block_timestamp_idx ON public.account_changes USING btree (changed_in_block_timestamp);

--
-- Name: account_changes_changed_in_caused_by_receipt_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX account_changes_changed_in_caused_by_receipt_id_idx ON public.account_changes USING btree (caused_by_receipt_id);

--
-- Name: account_changes_changed_in_caused_by_transaction_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX account_changes_changed_in_caused_by_transaction_hash_idx ON public.account_changes USING btree (caused_by_transaction_hash);

--
-- Name: accounts_last_update_block_height_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX accounts_last_update_block_height_idx ON public.accounts USING btree (last_update_block_height);

--
-- Name: action_receipt_input_data_input_data_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_input_data_input_data_id_idx ON public.action_receipt_input_data USING btree (input_data_id);

--
-- Name: action_receipt_input_data_input_to_receipt_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_input_data_input_to_receipt_id_idx ON public.action_receipt_input_data USING btree (input_to_receipt_id);

--
-- Name: action_receipt_output_data_output_data_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_output_data_output_data_id_idx ON public.action_receipt_output_data USING btree (output_data_id);

--
-- Name: action_receipt_output_data_output_from_receipt_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_output_data_output_from_receipt_id_idx ON public.action_receipt_output_data USING btree (output_from_receipt_id);

--
-- Name: action_receipt_output_data_receiver_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_output_data_receiver_account_id_idx ON public.action_receipt_output_data USING btree (receiver_account_id);

--
-- Name: action_receipt_signer_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX action_receipt_signer_account_id_idx ON public.action_receipts USING btree (signer_account_id);

--
-- Name: blocks_height_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX blocks_height_idx ON public.blocks USING btree (block_height);

--
-- Name: blocks_prev_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX blocks_prev_hash_idx ON public.blocks USING btree (prev_block_hash);

--
-- Name: blocks_timestamp_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX blocks_timestamp_idx ON public.blocks USING btree (block_timestamp);

--
-- Name: chunks_included_in_block_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX chunks_included_in_block_hash_idx ON public.chunks USING btree (included_in_block_hash);

--
-- Name: data_receipts_receipt_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX data_receipts_receipt_id_idx ON public.data_receipts USING btree (receipt_id);

--
-- Name: execution_outcome_executed_in_block_timestamp; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX execution_outcome_executed_in_block_timestamp ON public.execution_outcomes USING btree (executed_in_block_timestamp);

--
-- Name: execution_outcome_executed_in_chunk_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX execution_outcome_executed_in_chunk_hash_idx ON public.execution_outcomes USING btree (executed_in_chunk_hash);

--
-- Name: execution_outcome_receipts_produced_receipt_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX execution_outcome_receipts_produced_receipt_id ON public.execution_outcome_receipts USING btree (produced_receipt_id);

--
-- Name: execution_outcomes_block_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX execution_outcomes_block_hash_idx ON public.execution_outcomes USING btree (executed_in_block_hash);

--
-- Name: execution_outcomes_receipt_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX execution_outcomes_receipt_id_idx ON public.execution_outcomes USING btree (receipt_id);

--
-- Name: receipts_included_in_block_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX receipts_included_in_block_hash_idx ON public.receipts USING btree (included_in_block_hash);

--
-- Name: receipts_included_in_chunk_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX receipts_included_in_chunk_hash_idx ON public.receipts USING btree (included_in_chunk_hash);

--
-- Name: receipts_predecessor_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX receipts_predecessor_account_id_idx ON public.receipts USING btree (predecessor_account_id);

--
-- Name: receipts_receiver_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX receipts_receiver_account_id_idx ON public.receipts USING btree (receiver_account_id);

--
-- Name: receipts_timestamp_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX receipts_timestamp_idx ON public.receipts USING btree (included_in_block_timestamp);

--
-- Name: transactions_converted_into_receipt_id_dx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_converted_into_receipt_id_dx ON public.transactions USING btree (converted_into_receipt_id);

--
-- Name: transactions_included_in_block_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_included_in_block_hash_idx ON public.transactions USING btree (included_in_block_hash);

--
-- Name: transactions_included_in_block_timestamp_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_included_in_block_timestamp_idx ON public.transactions USING btree (block_timestamp);

--
-- Name: transactions_included_in_chunk_hash_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_included_in_chunk_hash_idx ON public.transactions USING btree (included_in_chunk_hash);

--
-- Name: transactions_signer_account_id_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_signer_account_id_idx ON public.transactions USING btree (signer_account_id);

--
-- Name: transactions_signer_public_key_idx; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX transactions_signer_public_key_idx ON public.transactions USING btree (signer_public_key);

--
-- Name: account_changes account_id_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT account_id_fk FOREIGN KEY (affected_account_id) REFERENCES public.accounts(account_id) ON DELETE CASCADE;

--
-- Name: action_receipt_actions action_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_actions
    ADD CONSTRAINT action_receipt_fk FOREIGN KEY (receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: execution_outcomes block_hash_execution_outcome_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcomes
    ADD CONSTRAINT block_hash_execution_outcome_fk FOREIGN KEY (executed_in_block_hash) REFERENCES public.blocks(block_hash) ON DELETE CASCADE;

--
-- Name: account_changes block_hash_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT block_hash_fk FOREIGN KEY (changed_in_block_hash) REFERENCES public.blocks(block_hash) ON DELETE CASCADE;

--
-- Name: receipts block_receipts_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.receipts
    ADD CONSTRAINT block_receipts_fk FOREIGN KEY (included_in_block_hash) REFERENCES public.blocks(block_hash) ON DELETE CASCADE;

--
-- Name: transactions block_tx_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.transactions
    ADD CONSTRAINT block_tx_fk FOREIGN KEY (included_in_block_hash) REFERENCES public.blocks(block_hash) ON DELETE CASCADE;

--
-- Name: execution_outcomes chunk_hash_outcome_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcomes
    ADD CONSTRAINT chunk_hash_outcome_fk FOREIGN KEY (executed_in_chunk_hash) REFERENCES public.chunks(chunk_hash) ON DELETE CASCADE;

--
-- Name: receipts chunk_receipts_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.receipts
    ADD CONSTRAINT chunk_receipts_fk FOREIGN KEY (included_in_chunk_hash) REFERENCES public.chunks(chunk_hash) ON DELETE CASCADE;

--
-- Name: transactions chunk_tx_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.transactions
    ADD CONSTRAINT chunk_tx_fk FOREIGN KEY (included_in_chunk_hash) REFERENCES public.chunks(chunk_hash) ON DELETE CASCADE;

--
-- Name: chunks chunks_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.chunks
    ADD CONSTRAINT chunks_fk FOREIGN KEY (included_in_block_hash) REFERENCES public.blocks(block_hash) ON DELETE CASCADE;

--
-- Name: access_keys created_by_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.access_keys
    ADD CONSTRAINT created_by_receipt_fk FOREIGN KEY (created_by_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: accounts created_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT created_receipt_fk FOREIGN KEY (created_by_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: access_keys deleted_by_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.access_keys
    ADD CONSTRAINT deleted_by_receipt_fk FOREIGN KEY (deleted_by_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: accounts deleted_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT deleted_receipt_fk FOREIGN KEY (deleted_by_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: execution_outcome_receipts execution_outcome_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcome_receipts
    ADD CONSTRAINT execution_outcome_fk FOREIGN KEY (executed_receipt_id) REFERENCES public.execution_outcomes(receipt_id) ON DELETE CASCADE;

--
-- Name: execution_outcomes receipt_execution_outcome_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcomes
    ADD CONSTRAINT receipt_execution_outcome_fk FOREIGN KEY (receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: data_receipts receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.data_receipts
    ADD CONSTRAINT receipt_fk FOREIGN KEY (receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: action_receipts receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipts
    ADD CONSTRAINT receipt_fk FOREIGN KEY (receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: action_receipt_output_data receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_output_data
    ADD CONSTRAINT receipt_fk FOREIGN KEY (output_from_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: action_receipt_input_data receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.action_receipt_input_data
    ADD CONSTRAINT receipt_fk FOREIGN KEY (input_to_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: account_changes receipt_id_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT receipt_id_fk FOREIGN KEY (caused_by_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: execution_outcome_receipts receipts_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.execution_outcome_receipts
    ADD CONSTRAINT receipts_fk FOREIGN KEY (executed_receipt_id) REFERENCES public.receipts(receipt_id) ON DELETE CASCADE;

--
-- Name: account_changes transaction_hash_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.account_changes
    ADD CONSTRAINT transaction_hash_fk FOREIGN KEY (caused_by_transaction_hash) REFERENCES public.transactions(transaction_hash) ON DELETE CASCADE;

--
-- Name: transaction_actions tx_action_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.transaction_actions
    ADD CONSTRAINT tx_action_fk FOREIGN KEY (transaction_hash) REFERENCES public.transactions(transaction_hash) ON DELETE CASCADE;

--
-- Name: receipts tx_receipt_fk; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.receipts
    ADD CONSTRAINT tx_receipt_fk FOREIGN KEY (originated_from_transaction_hash) REFERENCES public.transactions(transaction_hash) ON DELETE CASCADE;

--
-- PostgreSQL database dump complete
--

'''
'''--- dockerfile/migrations/2021-01-14-170424_index-receipt-originated-from-transaction-hash/down.sql ---
DROP INDEX receipts_originated_from_transaction_hash_idx;

'''
'''--- dockerfile/migrations/2021-01-14-170424_index-receipt-originated-from-transaction-hash/up.sql ---
CREATE INDEX receipts_originated_from_transaction_hash_idx ON receipts (originated_from_transaction_hash);

'''
'''--- dockerfile/migrations/2021-01-20-152056_index-transactions-receiver-account-id/down.sql ---
DROP INDEX transactions_receiver_account_id_idx;

'''
'''--- dockerfile/migrations/2021-01-20-152056_index-transactions-receiver-account-id/up.sql ---
CREATE INDEX transactions_receiver_account_id_idx ON transactions (receiver_account_id);

'''
'''--- dockerfile/migrations/2021-03-11-123839_index-action-kind-and-status/down.sql ---
DROP INDEX transactions_actions_action_kind_idx;
DROP INDEX action_receipt_actions_action_kind_idx;
DROP INDEX execution_outcomes_status_idx;

'''
'''--- dockerfile/migrations/2021-03-11-123839_index-action-kind-and-status/up.sql ---
CREATE INDEX transactions_actions_action_kind_idx ON transaction_actions (action_kind);
CREATE INDEX action_receipt_actions_action_kind_idx ON action_receipt_actions (action_kind);
CREATE INDEX execution_outcomes_status_idx ON execution_outcomes (status);

'''
'''--- dockerfile/migrations/2021-04-22-090505_execution_outcomes_replace_chunk_relation_with_shard_id/down.sql ---
-- Setting default value to empty string for further fill with data to avoid making the field nullable
ALTER TABLE execution_outcomes ADD COLUMN executed_in_chunk_hash text NOT NULL DEFAULT '';

UPDATE execution_outcomes SET executed_in_chunk_hash = chunks.chunk_hash
    FROM chunks
        WHERE execution_outcomes.executed_in_block_hash = chunks.included_in_block_hash
            AND execution_outcomes.shard_id = chunks.shard_id;

ALTER TABLE execution_outcomes ALTER COLUMN executed_in_chunk_hash DROP DEFAULT;
ALTER TABLE execution_outcomes DROP COLUMN shard_id;

'''
'''--- dockerfile/migrations/2021-04-22-090505_execution_outcomes_replace_chunk_relation_with_shard_id/up.sql ---
-- Setting default value 0 for further fill with data to avoid making the field nullable
ALTER TABLE execution_outcomes ADD COLUMN shard_id numeric(20,0) NOT NULL DEFAULT 0;

UPDATE execution_outcomes SET shard_id = chunks.shard_id FROM chunks WHERE execution_outcomes.executed_in_chunk_hash = chunks.chunk_hash;

ALTER TABLE execution_outcomes ALTER COLUMN shard_id DROP DEFAULT;
ALTER TABLE execution_outcomes DROP COLUMN executed_in_chunk_hash;

'''
'''--- dockerfile/migrations/2021-04-28-154439_denormalize_action_receipt_actions/down.sql ---
ALTER TABLE action_receipt_actions
    DROP COLUMN receipt_predecessor_account_id,
    DROP COLUMN receipt_receiver_account_id,
    DROP COLUMN receipt_included_in_block_timestamp;

'''
'''--- dockerfile/migrations/2021-04-28-154439_denormalize_action_receipt_actions/up.sql ---
ALTER TABLE action_receipt_actions
    ADD COLUMN receipt_predecessor_account_id text NOT NULL DEFAULT '',
    ADD COLUMN receipt_receiver_account_id text NOT NULL DEFAULT '',
    ADD COLUMN receipt_included_in_block_timestamp numeric(20, 0) NOT NULL DEFAULT 0;

UPDATE action_receipt_actions
SET receipt_predecessor_account_id = receipts.predecessor_account_id,
    receipt_receiver_account_id = receipts.receiver_account_id,
    receipt_included_in_block_timestamp = receipts.included_in_block_timestamp
    FROM receipts
WHERE action_receipt_actions.receipt_id = receipts.receipt_id;

ALTER TABLE action_receipt_actions
    ALTER COLUMN receipt_predecessor_account_id DROP DEFAULT,
    ALTER COLUMN receipt_receiver_account_id DROP DEFAULT,
    ALTER COLUMN receipt_included_in_block_timestamp DROP DEFAULT;

'''
'''--- dockerfile/migrations/2021-05-06-093622_additional_indexes_for_action_receipt_actions/down.sql ---
DROP INDEX action_receipt_actions_receipt_predecessor_account_id_idx;
DROP INDEX action_receipt_actions_receipt_receiver_account_id_idx;
DROP INDEX action_receipt_actions_receipt_included_in_block_timestamp_idx;

'''
'''--- dockerfile/migrations/2021-05-06-093622_additional_indexes_for_action_receipt_actions/up.sql ---
CREATE INDEX action_receipt_actions_receipt_predecessor_account_id_idx ON action_receipt_actions(receipt_predecessor_account_id);
CREATE INDEX action_receipt_actions_receipt_receiver_account_id_idx ON action_receipt_actions(receipt_receiver_account_id);
CREATE INDEX action_receipt_actions_receipt_included_in_block_timestamp_idx ON action_receipt_actions(receipt_included_in_block_timestamp);

'''
'''--- dockerfile/migrations/2021-05-07-115559_convert_args_base64_to_args_json/down.sql ---
-- There is no sense to migrate that data back

'''
'''--- dockerfile/migrations/2021-05-07-115559_convert_args_base64_to_args_json/up.sql ---
CREATE OR REPLACE FUNCTION decode_or_null(bytea) RETURNS jsonb
   LANGUAGE plpgsql AS
$$BEGIN
   RETURN convert_from($1, 'UTF8')::jsonb;
EXCEPTION
   WHEN others THEN
      RAISE WARNING '%', SQLERRM;
RETURN '{}'::jsonb;

END;$$;

UPDATE action_receipt_actions
SET args = jsonb_set(args, '{args_json}', decode_or_null(decode(args->>'args_base64', 'base64')), true)
WHERE action_kind = 'FUNCTION_CALL' AND receipt_receiver_account_id != 'client.bridge.near';

'''
'''--- dockerfile/migrations/2021-05-10-084700_indexer_on_args_field/down.sql ---
DROP INDEX action_receipt_actions_args_function_call_idx;
DROP INDEX action_receipt_actions_args_amount_idx;
DROP INDEX action_receipt_actions_args_receiver_id_idx;

'''
'''--- dockerfile/migrations/2021-05-10-084700_indexer_on_args_field/up.sql ---
CREATE INDEX action_receipt_actions_args_function_call_idx ON action_receipt_actions((args->>'method_name'))
    WHERE action_receipt_actions.action_kind = 'FUNCTION_CALL';

CREATE INDEX action_receipt_actions_args_amount_idx ON action_receipt_actions((args->'args_json'->>'amount'))
    WHERE action_receipt_actions.action_kind = 'FUNCTION_CALL' AND (action_receipt_actions.args->>'args_json') IS NOT NULL;

CREATE INDEX action_receipt_actions_args_receiver_id_idx ON action_receipt_actions((args->'args_json'->>'receiver_id'))
    WHERE action_receipt_actions.action_kind = 'FUNCTION_CALL' AND (action_receipt_actions.args->>'args_json') IS NOT NULL;

'''
'''--- dockerfile/migrations/2021-05-27-154211_account_changes_unique_idx/down.sql ---
-- See comment in corresponding up.sql
-- We decided to add it anyway for consistency
ALTER TABLE ONLY account_changes
    ADD CONSTRAINT account_changes_affected_account_id_changed_in_block_hash_c_key UNIQUE (
    affected_account_id,
    changed_in_block_hash,
    caused_by_transaction_hash,
    caused_by_receipt_id);

DROP INDEX IF EXISTS account_changes_transaction_uni_idx;
DROP INDEX IF EXISTS account_changes_receipt_uni_idx;
DROP INDEX IF EXISTS account_changes_null_uni_idx;

'''
'''--- dockerfile/migrations/2021-05-27-154211_account_changes_unique_idx/up.sql ---
-- This constraint is bad because of 2 reasons:
-- 1. It does not contain update_reason, so it can remove needed lines
-- 2. Fortunately, it does not work at all because we have 2 nullable columns, they could not be compared by equality
--    (all nulls are considered unique)
ALTER TABLE account_changes DROP CONSTRAINT IF EXISTS account_changes_affected_account_id_changed_in_block_hash_c_key;

CREATE UNIQUE INDEX account_changes_transaction_uni_idx
ON account_changes (
    affected_account_id,
    changed_in_block_hash,
    caused_by_transaction_hash,
    update_reason,
    affected_account_nonstaked_balance,
    affected_account_staked_balance,
    affected_account_storage_usage
)
WHERE caused_by_transaction_hash IS NOT NULL AND caused_by_receipt_id IS NULL;

CREATE UNIQUE INDEX account_changes_receipt_uni_idx
ON account_changes (
    affected_account_id,
    changed_in_block_hash,
    caused_by_receipt_id,
    update_reason,
    affected_account_nonstaked_balance,
    affected_account_staked_balance,
    affected_account_storage_usage
)
WHERE caused_by_transaction_hash IS NULL AND caused_by_receipt_id IS NOT NULL;

CREATE UNIQUE INDEX account_changes_null_uni_idx
ON account_changes (
    affected_account_id,
    changed_in_block_hash,
    update_reason,
    affected_account_nonstaked_balance,
    affected_account_staked_balance,
    affected_account_storage_usage
)
WHERE caused_by_transaction_hash IS NULL AND caused_by_receipt_id IS NULL;

'''
'''--- dockerfile/migrations/2021-06-02-173100_add_migration_state_change_reason_kind/down.sql ---
-- This file is empty since we can't remove items from enum in Postgres.
-- To be honest, it does not sound as a big problem. `IF_NOT_EXISTS` will prevent re-adding it.

'''
'''--- dockerfile/migrations/2021-06-02-173100_add_migration_state_change_reason_kind/up.sql ---
ALTER TYPE state_change_reason_kind ADD VALUE IF NOT EXISTS 'MIGRATION';

'''
'''--- dockerfile/migrations/2021-08-02-183200_transactions_sorting_idx/down.sql ---
DROP INDEX transactions_sorting_idx;

'''
'''--- dockerfile/migrations/2021-08-02-183200_transactions_sorting_idx/up.sql ---
CREATE INDEX transactions_sorting_idx ON transactions (block_timestamp, index_in_chunk);

'''
'''--- dockerfile/migrations/2021-08-04-151515_circulating_supply_table/down.sql ---
DROP TABLE aggregated__circulating_supply;
DROP VIEW aggregated__lockups;

'''
'''--- dockerfile/migrations/2021-08-04-151515_circulating_supply_table/up.sql ---
CREATE TABLE aggregated__circulating_supply
(
    computed_at_block_timestamp       numeric(20, 0) NOT NULL,
    computed_at_block_hash            text           NOT NULL,
    circulating_tokens_supply         numeric(45, 0) NOT NULL,
    total_tokens_supply               numeric(45, 0) NOT NULL,
    total_lockup_contracts_count      integer        NOT NULL,
    unfinished_lockup_contracts_count integer        NOT NULL,
    foundation_locked_tokens          numeric(45, 0) NOT NULL,
    lockups_locked_tokens             numeric(45, 0) NOT NULL
);

ALTER TABLE ONLY aggregated__circulating_supply
    ADD CONSTRAINT aggregated__circulating_supply_pkey PRIMARY KEY (computed_at_block_hash);

CREATE INDEX aggregated__circulating_supply_timestamp_idx ON aggregated__circulating_supply USING btree (computed_at_block_timestamp);

ALTER TABLE ONLY aggregated__circulating_supply
    ADD CONSTRAINT aggregated__circulating_supply_fk FOREIGN KEY (computed_at_block_hash) REFERENCES blocks (block_hash) ON DELETE CASCADE;

CREATE VIEW aggregated__lockups AS
(
SELECT accounts.account_id,
       blocks_start.block_height AS creation_block_height,
       blocks_end.block_height   AS deletion_block_height
FROM accounts
         LEFT JOIN receipts AS receipts_start ON accounts.created_by_receipt_id = receipts_start.receipt_id
         LEFT JOIN blocks AS blocks_start ON receipts_start.included_in_block_hash = blocks_start.block_hash
         LEFT JOIN receipts AS receipts_end ON accounts.deleted_by_receipt_id = receipts_end.receipt_id
         LEFT JOIN blocks AS blocks_end ON receipts_end.included_in_block_hash = blocks_end.block_hash
WHERE accounts.account_id like '%.lockup.near');

'''
'''--- dockerfile/migrations/2021-08-06-123500_account_changes_ordering_column/down.sql ---
ALTER TABLE account_changes DROP COLUMN index_in_block;

'''
'''--- dockerfile/migrations/2021-08-06-123500_account_changes_ordering_column/up.sql ---
-- Setting default value -1 for further fill with data to avoid making the field nullable
ALTER TABLE account_changes
    ADD COLUMN index_in_block integer NOT NULL DEFAULT -1;

-- This migration is heavy to apply. Consider using Python script to do that in background.
-- It applies the changes by tiny pieces.
-- You need to replace `END` and `connection_string` parameters

-- from sqlalchemy import create_engine
--
-- START = 1595370903490523743
-- STEP = 1000 * 1000 * 1000 * 1000  # 1000 secs -> ~17 minutes
-- END = 1628683241000000000
-- ESTIMATED_STEPS = (END - START) / STEP
-- connection_string = 'postgresql+psycopg2://user:pass@host/database'
--
--
-- def generate_sql(from_timestamp: int, to_timestamp: int) -> str:
--     """
--     Generates str for SQL query to convert args_base64 to args_json if possible
--     """
--     return f"""
--     BEGIN;
--     WITH indexes AS
--          (
--              SELECT id, row_number() OVER (PARTITION BY changed_in_block_timestamp ORDER BY id) - 1 as index_in_block
--              FROM account_changes
--              WHERE account_changes.changed_in_block_timestamp >= {from_timestamp}
--                 AND account_changes.changed_in_block_timestamp <= {to_timestamp}
--          )
--     UPDATE account_changes
--     SET index_in_block = indexes.index_in_block
--     FROM indexes
--     WHERE account_changes.id = indexes.id
--         AND account_changes.index_in_block = -1
--         AND account_changes.changed_in_block_timestamp >= {from_timestamp}
--         AND account_changes.changed_in_block_timestamp <= {to_timestamp};
--     COMMIT;
--     """
--
--
-- if __name__ == '__main__':
--     print("Establishing connection to %s..." % (connection_string.split('/')[-1],))
--     engine = create_engine(connection_string)
--     print(f"Estimated queries to execute: {ESTIMATED_STEPS}.")
--     from_timestamp = START-STEP
--     to_timestamp = START
--     counter = 1
--
--     with engine.connect() as con:
--         while True:
--             from_timestamp += STEP
--             to_timestamp += STEP
--             if (END - to_timestamp) < STEP:
--                 break
--             print(f"{counter}/{ESTIMATED_STEPS} (from {from_timestamp} to {to_timestamp})")
--
--             out = con.execute(generate_sql(from_timestamp, to_timestamp))
--             counter += 1
--
--     print("FINISHED")

ALTER TABLE account_changes
    ALTER COLUMN index_in_block DROP DEFAULT;

'''
'''--- dockerfile/migrations/2021-08-11-163800_account_changes_ordering_idx/down.sql ---
DROP INDEX account_changes_sorting_idx;

'''
'''--- dockerfile/migrations/2021-08-11-163800_account_changes_ordering_idx/up.sql ---
CREATE INDEX account_changes_sorting_idx ON account_changes (changed_in_block_timestamp, index_in_block);

'''
'''--- dockerfile/migrations/2021-10-04-100000_assets_nft/down.sql ---
DROP TABLE assets__non_fungible_token_events;

'''
'''--- dockerfile/migrations/2021-10-04-100000_assets_nft/up.sql ---
CREATE TYPE nft_event_kind AS ENUM (
    'MINT',
    'TRANSFER',
    'BURN'
    );

CREATE TABLE assets__non_fungible_token_events
(
    emitted_for_receipt_id                text           NOT NULL,

    -- Next three columns (emitted_at_block_timestamp, emitted_in_shard_id, emitted_index_of_event_entry_in_shard)
    -- should be used for sorting purposes, at the order that we just named.
    emitted_at_block_timestamp            numeric(20, 0) NOT NULL,
    emitted_in_shard_id                   numeric(20, 0) NOT NULL,
    -- `emitted_index_of_event_entry_in_shard` has non-trivial implementation. It combines the order from:
    -- 1. execution_outcomes::index_in_chunk
    -- 2. Index of current action_receipt
    -- 3. Index of event entry that we are currently working on. Note, one receipt can have multiple events
    --    (read: log with multiple statements), each of them can have multiple account_ids and token_ids.
    --    We use continuous numbering for all these items.
    emitted_index_of_event_entry_in_shard integer        NOT NULL,

    -- account_id of the contract itself. In a simple words, it's the owner/creator of NFT contract
    emitted_by_contract_account_id        text           NOT NULL,
    -- Unique ID of the token
    token_id                              text           NOT NULL,
    event_kind                            nft_event_kind NOT NULL,

    -- We use `NOT NULL DEFAULT ''` in all the lines below to simplify further issue with nulls + constraints
    -- Previous owner of the token. Empty if we have nft_event_kind 'MINT'.
    token_old_owner_account_id            text           NOT NULL DEFAULT '',
    -- New owner of the token. Empty if we have nft_event_kind 'BURN'.
    token_new_owner_account_id            text           NOT NULL DEFAULT '',
    -- The account that initialized the event.
    -- It differs from token_old_owner_account_id, but it is approved to manipulate with current token.
    -- More information here https://nomicon.io/Standards/NonFungibleToken/ApprovalManagement.html
    -- Optional field: filled only if the event is done NOT by token_old_owner_account_id.
    -- Empty if we have nft_event_kind 'MINT'.
    token_authorized_account_id           text           NOT NULL DEFAULT '',
    -- Optional message associated with token movement.
    event_memo                            text           NOT NULL DEFAULT ''
);

-- We have to add everything to PK because of some reasons:
-- 1. We need to ignore the same lines, they could come from different indexers, that is fully legal context.
-- 2. We need to catch the situation when we passed PK constraint, but failed UNIQUE constraint below.
ALTER TABLE ONLY assets__non_fungible_token_events
    ADD CONSTRAINT assets__non_fungible_token_events_pkey PRIMARY KEY (emitted_for_receipt_id,
                                                                       emitted_at_block_timestamp,
                                                                       emitted_in_shard_id,
                                                                       emitted_index_of_event_entry_in_shard,
                                                                       emitted_by_contract_account_id,
                                                                       token_id,
                                                                       event_kind,
                                                                       token_old_owner_account_id,
                                                                       token_new_owner_account_id,
                                                                       token_authorized_account_id,
                                                                       event_memo);

-- This set of columns is enough to identify the record
-- We use UNIQUE constraint here to catch the errors if the incoming data looks inconsistent
ALTER TABLE ONLY assets__non_fungible_token_events
    ADD CONSTRAINT assets__non_fungible_token_events_unique UNIQUE (emitted_for_receipt_id,
                                                                    emitted_index_of_event_entry_in_shard);

-- To sum up, let's consider all possible situations:
-- PK passed, UNIQUE passed: everything is OK, let's insert the line
-- PK passed, UNIQUE failed: we have UNIQUE constraint error, let's log it somewhere, there should be a bug somewhere.
-- PK failed, UNIQUE passed: unreachable
-- PK failed, UNIQUE failed: we have PK constraint error
--                           (we have both, but PK constraint is more severe and DB will complain only about it).
--                           It's the correct line from other indexer, simply ignore it

CREATE INDEX assets__non_fungible_token_events_sorting_idx ON assets__non_fungible_token_events
    USING btree (emitted_at_block_timestamp,
                 emitted_in_shard_id,
                 emitted_index_of_event_entry_in_shard);

CREATE INDEX assets__non_fungible_token_events_block_timestamp_idx ON assets__non_fungible_token_events
    USING btree (emitted_at_block_timestamp);

CREATE INDEX assets__non_fungible_token_events_old_owner_account_id_idx ON assets__non_fungible_token_events
    USING btree (token_old_owner_account_id);

CREATE INDEX assets__non_fungible_token_events_new_owner_account_id_idx ON assets__non_fungible_token_events
    USING btree (token_new_owner_account_id);

ALTER TABLE ONLY assets__non_fungible_token_events
    ADD CONSTRAINT assets__non_fungible_token_events_fk
        FOREIGN KEY (emitted_for_receipt_id) REFERENCES receipts (receipt_id) ON DELETE CASCADE;

'''
'''--- dockerfile/migrations/2021-10-14-180948_add_resharding_state_change_reason_kind/down.sql ---
-- This file should undo anything in `up.sql`

'''
'''--- dockerfile/migrations/2021-10-14-180948_add_resharding_state_change_reason_kind/up.sql ---
ALTER TYPE state_change_reason_kind ADD VALUE IF NOT EXISTS 'RESHARDING';

'''
'''--- dockerfile/migrations/2022-01-12-100000_assets_ft/down.sql ---
DROP TABLE assets__fungible_token_events;

'''
'''--- dockerfile/migrations/2022-01-12-100000_assets_ft/up.sql ---
CREATE TYPE ft_event_kind AS ENUM (
    'MINT',
    'TRANSFER',
    'BURN'
    );

CREATE TABLE assets__fungible_token_events
(
    emitted_for_receipt_id                text           NOT NULL,

    -- Next three columns (emitted_at_block_timestamp, emitted_in_shard_id, emitted_index_of_event_entry_in_shard)
    -- should be used for sorting purposes, at the order that we just named.
    emitted_at_block_timestamp            numeric(20, 0) NOT NULL,
    emitted_in_shard_id                   numeric(20, 0) NOT NULL,
    -- `emitted_index_of_event_entry_in_shard` has non-trivial implementation. It combines the order from:
    -- 1. execution_outcomes::index_in_chunk
    -- 2. Index of current action_receipt
    -- 3. Index of event entry that we are currently working on. Note, one receipt can have multiple events
    --    (read: log with multiple statements), each of them can have multiple account_ids and token_ids.
    --    We use continuous numbering for all these items.
    emitted_index_of_event_entry_in_shard integer        NOT NULL,

    -- account_id of the contract itself. In a simple words, it's the owner/creator of FT contract
    emitted_by_contract_account_id        text           NOT NULL,
    amount                                text           NOT NULL,
    event_kind                            ft_event_kind  NOT NULL,

    -- We use `NOT NULL DEFAULT ''` in all the lines below to simplify further issue with nulls + constraints
    -- Previous owner of the token. Empty if we have ft_event_kind 'MINT'.
    token_old_owner_account_id            text           NOT NULL DEFAULT '',
    -- New owner of the token. Empty if we have ft_event_kind 'BURN'.
    token_new_owner_account_id            text           NOT NULL DEFAULT '',
    -- Optional message associated with token movement.
    event_memo                            text           NOT NULL DEFAULT ''
);

-- We have to add everything to PK because of some reasons:
-- 1. We need to ignore the same lines, they could come from different indexers, that is fully legal context.
-- 2. We need to catch the situation when we passed PK constraint, but failed UNIQUE constraint below.
ALTER TABLE ONLY assets__fungible_token_events
    ADD CONSTRAINT assets__fungible_token_events_pkey PRIMARY KEY (emitted_for_receipt_id,
                                                                   emitted_at_block_timestamp,
                                                                   emitted_in_shard_id,
                                                                   emitted_index_of_event_entry_in_shard,
                                                                   emitted_by_contract_account_id,
                                                                   amount,
                                                                   event_kind,
                                                                   token_old_owner_account_id,
                                                                   token_new_owner_account_id,
                                                                   event_memo);

-- This set of columns is enough to identify the record
-- We use UNIQUE constraint here to catch the errors if the incoming data looks inconsistent
ALTER TABLE ONLY assets__fungible_token_events
    ADD CONSTRAINT assets__fungible_token_events_unique UNIQUE (emitted_for_receipt_id,
                                                                emitted_index_of_event_entry_in_shard);

-- To sum up, let's consider all possible situations:
-- PK passed, UNIQUE passed: everything is OK, let's insert the line
-- PK passed, UNIQUE failed: we have UNIQUE constraint error, let's log it somewhere, there should be a bug somewhere.
-- PK failed, UNIQUE passed: unreachable
-- PK failed, UNIQUE failed: we have PK constraint error
--                           (we have both, but PK constraint is more severe and DB will complain only about it).
--                           It's the correct line from other indexer, simply ignore it

CREATE INDEX assets__fungible_token_events_sorting_idx ON assets__fungible_token_events
    USING btree (emitted_at_block_timestamp,
                 emitted_in_shard_id,
                 emitted_index_of_event_entry_in_shard);

CREATE INDEX assets__fungible_token_events_block_timestamp_idx ON assets__fungible_token_events
    USING btree (emitted_at_block_timestamp);

CREATE INDEX assets__fungible_token_events_old_owner_account_id_idx ON assets__fungible_token_events
    USING btree (token_old_owner_account_id);

CREATE INDEX assets__fungible_token_events_new_owner_account_id_idx ON assets__fungible_token_events
    USING btree (token_new_owner_account_id);

ALTER TABLE ONLY assets__fungible_token_events
    ADD CONSTRAINT assets__fungible_token_events_fk
        FOREIGN KEY (emitted_for_receipt_id) REFERENCES receipts (receipt_id) ON DELETE CASCADE;

'''
'''--- dockerfile/migrations/2022-01-26-184200_drop_duplicated_index_execution_outcome/down.sql ---
-- I suggest to leave it blank because this index duplicates PK index created automatically
-- If we really need to re-create it, it should be done by:
-- CREATE INDEX execution_outcomes_receipt_id_idx ON execution_outcomes (receipt_id);

'''
'''--- dockerfile/migrations/2022-01-26-184200_drop_duplicated_index_execution_outcome/up.sql ---
DROP INDEX execution_outcomes_receipt_id_idx;

'''
'''--- dockerfile/migrations/2022-01-26-184201_index_action_receipt_actions/down.sql ---
DROP INDEX action_receipt_actions_receiver_and_timestamp_idx;

'''
'''--- dockerfile/migrations/2022-01-26-184201_index_action_receipt_actions/up.sql ---
CREATE INDEX action_receipt_actions_receiver_and_timestamp_idx
    ON action_receipt_actions (receipt_receiver_account_id, receipt_included_in_block_timestamp);

'''
'''--- dockerfile/src/aggregated/account_details.rs ---
use actix::Addr;
use anyhow::Context;

use near_client::{Query, ViewClientActor};
use near_indexer::near_primitives;

pub(crate) async fn get_account_balance(
    view_client: &Addr<ViewClientActor>,
    account_id: &near_primitives::types::AccountId,
    block_height: &near_primitives::types::BlockHeight,
) -> anyhow::Result<near_primitives::types::Balance> {
    get_account_view_for_block_height(view_client, account_id, block_height)
        .await
        .map(|account| account.amount)
        .with_context(|| format!("Unable to get account balance for {}", account_id))
}

pub(crate) async fn get_contract_code_hash(
    view_client: &Addr<ViewClientActor>,
    account_id: &near_primitives::types::AccountId,
    block_height: &near_primitives::types::BlockHeight,
) -> anyhow::Result<near_primitives::hash::CryptoHash> {
    get_account_view_for_block_height(view_client, account_id, block_height)
        .await
        .map(|account| account.code_hash)
        .with_context(|| format!("Unable to get contract code hash for {}", account_id))
}

async fn get_account_view_for_block_height(
    view_client: &Addr<ViewClientActor>,
    account_id: &near_primitives::types::AccountId,
    block_height: &near_primitives::types::BlockHeight,
) -> anyhow::Result<near_primitives::views::AccountView> {
    let block_reference = near_primitives::types::BlockReference::BlockId(
        near_primitives::types::BlockId::Height(*block_height),
    );
    let request = near_primitives::views::QueryRequest::ViewAccount {
        account_id: account_id.clone(),
    };
    let query = Query::new(block_reference, request);

    let account_response = view_client
        .send(query)
        .await
        .with_context(|| {
            format!(
                "Failed to deliver ViewAccount for account {}, block {}",
                account_id, block_height
            )
        })?
        .with_context(|| {
            format!(
                "Invalid ViewAccount query for account {}, block {}",
                account_id, block_height
            )
        })?;

    match account_response.kind {
        near_primitives::views::QueryResponseKind::ViewAccount(account) => Ok(account),
        _ => anyhow::bail!(
            "Failed to extract ViewAccount response for account {}, block {}",
            account_id,
            block_height
        ),
    }
}

'''
'''--- dockerfile/src/aggregated/circulating_supply/lockup.rs ---
use std::time::Duration;

use actix::Addr;
use anyhow::Context;

use near_client::{Query, ViewClientActor};
use near_indexer::near_primitives;
use near_sdk::borsh::BorshDeserialize;
use near_sdk::json_types::{U128, U64};

use super::lockup_types::{
    LockupContract, TransfersInformation, VestingInformation, VestingSchedule, WrappedBalance, U256,
};

// The timestamp (nanos) when transfers were enabled in the Mainnet after community voting
// Tuesday, 13 October 2020 18:38:58.293
pub(super) const TRANSFERS_ENABLED: Duration = Duration::from_nanos(1602614338293769340);

pub(super) async fn get_lockup_contract_state(
    view_client: &Addr<ViewClientActor>,
    account_id: &near_primitives::types::AccountId,
    block_height: &near_primitives::types::BlockHeight,
) -> anyhow::Result<LockupContract> {
    let block_reference = near_primitives::types::BlockReference::BlockId(
        near_primitives::types::BlockId::Height(*block_height),
    );
    let request = near_primitives::views::QueryRequest::ViewState {
        account_id: account_id.clone(),
        prefix: vec![].into(),
    };
    let query = Query::new(block_reference, request);

    let state_response = view_client
        .send(query)
        .await
        .with_context(|| {
            format!(
                "Failed to deliver ViewState for lockup contract {}, block_height {}",
                account_id, block_height
            )
        })?
        .with_context(|| {
            format!(
                "Invalid ViewState query for lockup contract {}, block_height {}",
                account_id, block_height
            )
        })?;

    let view_state_result = match state_response.kind {
        near_primitives::views::QueryResponseKind::ViewState(x) => x,
        _ => {
            anyhow::bail!(
                "Failed to extract ViewState response for lockup contract {}, block_height {}",
                account_id,
                block_height
            )
        }
    };
    let view_state = view_state_result.values.get(0).with_context(|| {
        format!(
            "Failed to find encoded lockup contract for {}, block_height {}",
            account_id, block_height
        )
    })?;

    let mut state = LockupContract::try_from_slice(
        base64::decode(&view_state.value)
            .with_context(|| {
                format!(
                    "Failed to decode `view_state` for lockup contract {}",
                    account_id
                )
            })?
            .as_slice(),
    )
    .with_context(|| format!("Failed to construct LockupContract for {}", account_id))?;

    // If owner of the lockup account didn't call the
    // `check_transfers_vote` contract method we won't be able to
    // get proper information based on timestamp, that's why we inject
    // the `transfer_timestamp` which is phase2 timestamp
    state.lockup_information.transfers_information = TransfersInformation::TransfersEnabled {
        transfers_timestamp: U64(TRANSFERS_ENABLED.as_nanos() as u64),
    };
    Ok(state)
}

// The lockup contract implementation had a bug that affected lockup start date.
// https://github.com/near/core-contracts/pull/136
// For each contract, we should choose the logic based on the binary version of the contract
pub(super) fn is_bug_inside_contract(
    code_hash: &near_primitives::hash::CryptoHash,
    account_id: &near_primitives::types::AccountId,
) -> anyhow::Result<bool> {
    match &*code_hash.to_string() {
        // The first implementation, with the bug
        "3kVY9qcVRoW3B5498SMX6R3rtSLiCdmBzKs7zcnzDJ7Q" => Ok(true),
        // We have 6 lockups created at 6th of April 2021, assume it's buggy
        "DiC9bKCqUHqoYqUXovAnqugiuntHWnM3cAc7KrgaHTu" => Ok(true),
        // Another 5 lockups created in May/June 2021, assume they are OK
        "Cw7bnyp4B6ypwvgZuMmJtY6rHsxP2D4PC8deqeJ3HP7D" => Ok(false),
        // The most fresh one
        "4Pfw2RU6e35dUsHQQoFYfwX8KFFvSRNwMSNLXuSFHXrC" => Ok(false),
        other => anyhow::bail!(
            "Unable to recognise the version of contract {}, code hash {}",
            account_id,
            other
        ),
    }
}

// This is almost a copy of https://github.com/near/core-contracts/blob/master/lockup/src/getters.rs#L64
impl LockupContract {
    /// Returns the amount of tokens that are locked in the account due to lockup or vesting.
    pub fn get_locked_amount(&self, timestamp: u64, has_bug: bool) -> WrappedBalance {
        let lockup_amount = self.lockup_information.lockup_amount;
        if let TransfersInformation::TransfersEnabled {
            transfers_timestamp,
        } = &self.lockup_information.transfers_information
        {
            let lockup_timestamp = std::cmp::max(
                transfers_timestamp
                    .0
                    .saturating_add(self.lockup_information.lockup_duration),
                self.lockup_information.lockup_timestamp.unwrap_or(0),
            );
            let block_timestamp = timestamp;
            if lockup_timestamp <= block_timestamp {
                let unreleased_amount =
                    if let Some(release_duration) = self.lockup_information.release_duration {
                        let start_lockup = if has_bug {
                            transfers_timestamp.0
                        } else {
                            lockup_timestamp
                        };
                        let end_timestamp = start_lockup.saturating_add(release_duration);
                        if block_timestamp >= end_timestamp {
                            // Everything is released
                            0
                        } else {
                            let time_left = U256::from(end_timestamp - block_timestamp);
                            let unreleased_amount = U256::from(lockup_amount) * time_left
                                / U256::from(release_duration);
                            // The unreleased amount can't be larger than lockup_amount because the
                            // time_left is smaller than total_time.
                            unreleased_amount.as_u128()
                        }
                    } else {
                        0
                    };

                let unvested_amount = match &self.vesting_information {
                    VestingInformation::VestingSchedule(vs) => {
                        self.get_unvested_amount(vs.clone(), block_timestamp)
                    }
                    VestingInformation::Terminating(terminating) => terminating.unvested_amount,
                    // Vesting is private, so we can assume the vesting started before lockup date.
                    _ => U128(0),
                };
                return std::cmp::max(
                    unreleased_amount
                        .saturating_sub(self.lockup_information.termination_withdrawn_tokens),
                    unvested_amount.0,
                )
                .into();
            }
        }
        // The entire balance is still locked before the lockup timestamp.
        (lockup_amount - self.lockup_information.termination_withdrawn_tokens).into()
    }

    /// Returns the amount of tokens that are locked in this account due to vesting schedule.
    /// Takes raw vesting schedule, in case the internal vesting schedule is private.
    pub fn get_unvested_amount(
        &self,
        vesting_schedule: VestingSchedule,
        block_timestamp: u64,
    ) -> WrappedBalance {
        let lockup_amount = self.lockup_information.lockup_amount;
        match &self.vesting_information {
            VestingInformation::Terminating(termination_information) => {
                termination_information.unvested_amount
            }
            VestingInformation::None => U128::from(0),
            _ => {
                if block_timestamp < vesting_schedule.cliff_timestamp.0 {
                    // Before the cliff, nothing is vested
                    lockup_amount.into()
                } else if block_timestamp >= vesting_schedule.end_timestamp.0 {
                    // After the end, everything is vested
                    0.into()
                } else {
                    // cannot overflow since block_timestamp < vesting_schedule.end_timestamp
                    let time_left = U256::from(vesting_schedule.end_timestamp.0 - block_timestamp);
                    // The total time is positive. Checked at the contract initialization.
                    let total_time = U256::from(
                        vesting_schedule.end_timestamp.0 - vesting_schedule.start_timestamp.0,
                    );
                    let unvested_amount = U256::from(lockup_amount) * time_left / total_time;
                    // The unvested amount can't be larger than lockup_amount because the
                    // time_left is smaller than total_time.
                    unvested_amount.as_u128().into()
                }
            }
        }
    }
}

'''
'''--- dockerfile/src/aggregated/circulating_supply/lockup_types.rs ---
#![allow(
    clippy::assign_op_pattern,
    clippy::manual_range_contains,
    clippy::ptr_offset_with_cast
)]
// Copied from lockup contract code
// https://github.com/near/core-contracts/blob/master/lockup/src/types.rs
// https://github.com/near/core-contracts/blob/master/lockup/src/lib.rs

use uint::construct_uint;

use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};
use near_sdk::json_types::{Base64VecU8, U128, U64};
use near_sdk::serde::{Deserialize, Serialize};
use near_sdk::{AccountId, Balance};

construct_uint! {
    /// 256-bit unsigned integer.
    pub struct U256(4);
}

/// Raw type for duration in nanoseconds
pub type Duration = u64;
/// Raw type for timestamp in nanoseconds
pub type Timestamp = u64;

/// Timestamp in nanosecond wrapped into a struct for JSON serialization as a string.
pub type WrappedTimestamp = U64;
/// Balance wrapped into a struct for JSON serialization as a string.
pub type WrappedBalance = U128;

#[derive(BorshDeserialize, BorshSerialize)]
pub struct LockupContract {
    /// The account ID of the owner.
    pub owner_account_id: AccountId,

    /// Information about lockup schedule and the amount.
    pub lockup_information: LockupInformation,

    /// Information about vesting including schedule or termination status.
    pub vesting_information: VestingInformation,

    /// Account ID of the staking pool whitelist contract.
    pub staking_pool_whitelist_account_id: AccountId,

    /// Information about staking and delegation.
    /// `Some` means the staking information is available and the staking pool contract is selected.
    /// `None` means there is no staking pool selected.
    pub staking_information: Option<StakingInformation>,

    /// The account ID that the NEAR Foundation, that has the ability to terminate vesting.
    pub foundation_account_id: Option<AccountId>,
}

/// Contains information about token lockups.
#[derive(BorshDeserialize, BorshSerialize)]
pub struct LockupInformation {
    /// The amount in yocto-NEAR tokens locked for this account.
    pub lockup_amount: Balance,
    /// The amount of tokens that were withdrawn by NEAR foundation due to early termination
    /// of vesting.
    /// This amount has to be accounted separately from the lockup_amount to make sure
    /// linear release is not being affected.
    pub termination_withdrawn_tokens: Balance,
    /// [deprecated] - the duration in nanoseconds of the lockup period from
    /// the moment the transfers are enabled. During this period tokens are locked and
    /// the release doesn't start. Instead of this, use `lockup_timestamp` and `release_duration`
    pub lockup_duration: Duration,
    /// If present, it is the duration when the full lockup amount will be available. The tokens
    /// are linearly released from the moment tokens are unlocked, defined by:
    /// `max(transfers_timestamp + lockup_duration, lockup_timestamp)`.
    /// If not present, the tokens are not locked (though, vesting logic could be used).
    pub release_duration: Option<Duration>,
    /// The optional absolute lockup timestamp in nanoseconds which locks the tokens until this
    /// timestamp passes. Until this moment the tokens are locked and the release doesn't start.
    /// If not present, `transfers_timestamp` will be used.
    pub lockup_timestamp: Option<Timestamp>,
    /// The information about the transfers. Either transfers are already enabled, then it contains
    /// the timestamp when they were enabled. Or the transfers are currently disabled and
    /// it contains the account ID of the transfer poll contract.
    pub transfers_information: TransfersInformation,
}

/// Contains information about the transfers. Whether transfers are enabled or disabled.
#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, Debug)]
#[serde(crate = "near_sdk::serde")]
pub enum TransfersInformation {
    /// The timestamp when the transfers were enabled.
    TransfersEnabled {
        transfers_timestamp: WrappedTimestamp,
    },
    /// The account ID of the transfers poll contract, to check if the transfers are enabled.
    /// The lockup period can start only after the transfer voted to be enabled.
    /// At the launch of the network transfers are disabled for all lockup contracts, once transfers
    /// are enabled, they can't be disabled and don't need to be checked again.
    TransfersDisabled { transfer_poll_account_id: AccountId },
}

/// Describes the status of transactions with the staking pool contract or terminated unvesting
/// amount withdrawal.
#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, PartialEq)]
#[serde(crate = "near_sdk::serde")]
pub enum TransactionStatus {
    /// There are no transactions in progress.
    Idle,
    /// There is a transaction in progress.
    Busy,
}

/// Contains information about current stake and delegation.
#[derive(BorshDeserialize, BorshSerialize)]
pub struct StakingInformation {
    /// The Account ID of the staking pool contract.
    pub staking_pool_account_id: AccountId,

    /// Contains status whether there is a transaction in progress.
    pub status: TransactionStatus,

    /// The amount of tokens that were deposited from this account to the staking pool.
    /// NOTE: The unstaked amount on the staking pool might be higher due to staking rewards.
    pub deposit_amount: WrappedBalance,
}

/// Contains information about vesting schedule.
#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, Clone, PartialEq, Debug)]
#[serde(crate = "near_sdk::serde")]
pub struct VestingSchedule {
    /// The timestamp in nanosecond when the vesting starts. E.g. the start date of employment.
    pub start_timestamp: WrappedTimestamp,
    /// The timestamp in nanosecond when the first part of lockup tokens becomes vested.
    /// The remaining tokens will vest continuously until they are fully vested.
    /// Example: a 1 year of employment at which moment the 1/4 of tokens become vested.
    pub cliff_timestamp: WrappedTimestamp,
    /// The timestamp in nanosecond when the vesting ends.
    pub end_timestamp: WrappedTimestamp,
}

/// Initialization argument type to define the vesting schedule
#[derive(Serialize, Deserialize, Debug)]
#[serde(crate = "near_sdk::serde")]
pub enum VestingScheduleOrHash {
    /// [deprecated] After transfers are enabled, only public schedule is used.
    /// The vesting schedule is private and this is a hash of (vesting_schedule, salt).
    /// In JSON, the hash has to be encoded with base64 to a string.
    VestingHash(Base64VecU8),
    /// The vesting schedule (public)
    VestingSchedule(VestingSchedule),
}

/// Contains information about vesting that contains vesting schedule and termination information.
#[derive(Serialize, BorshDeserialize, BorshSerialize, PartialEq, Clone, Debug)]
#[serde(crate = "near_sdk::serde")]
pub enum VestingInformation {
    None,
    /// [deprecated] After transfers are enabled, only public schedule is used.
    /// Vesting schedule is hashed for privacy and only will be revealed if the NEAR foundation
    /// has to terminate vesting.
    /// The contract assume the vesting schedule doesn't affect lockup release and duration, because
    /// the vesting started before transfers were enabled and the duration is shorter or the same.
    VestingHash(Base64VecU8),
    /// Explicit vesting schedule.
    VestingSchedule(VestingSchedule),
    /// The information about the early termination of the vesting schedule.
    /// It means the termination of the vesting is currently in progress.
    /// Once the unvested amount is transferred out, `VestingInformation` is removed.
    Terminating(TerminationInformation),
}

/// Describes the status of transactions with the staking pool contract or terminated unvesting
/// amount withdrawal.
#[derive(
    BorshDeserialize, BorshSerialize, Deserialize, Serialize, PartialEq, Copy, Clone, Debug,
)]
#[serde(crate = "near_sdk::serde")]
pub enum TerminationStatus {
    /// Initial stage of the termination in case there are deficit on the account.
    VestingTerminatedWithDeficit,
    /// A transaction to unstake everything is in progress.
    UnstakingInProgress,
    /// The transaction to unstake everything from the staking pool has completed.
    EverythingUnstaked,
    /// A transaction to withdraw everything from the staking pool is in progress.
    WithdrawingFromStakingPoolInProgress,
    /// Everything is withdrawn from the staking pool. Ready to withdraw out of the account.
    ReadyToWithdraw,
    /// A transaction to withdraw tokens from the account is in progress.
    WithdrawingFromAccountInProgress,
}

/// Contains information about early termination of the vesting schedule.
#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, PartialEq, Clone, Debug)]
#[serde(crate = "near_sdk::serde")]
pub struct TerminationInformation {
    /// The amount of tokens that are unvested and has to be transferred back to NEAR Foundation.
    /// These tokens are effectively locked and can't be transferred out and can't be restaked.
    pub unvested_amount: WrappedBalance,

    /// The status of the withdrawal. When the unvested amount is in progress of withdrawal the
    /// status will be marked as busy, to avoid withdrawing the funds twice.
    pub status: TerminationStatus,
}

/// Contains a vesting schedule with a salt.
#[derive(BorshSerialize, Deserialize, Serialize, Clone, Debug)]
#[serde(crate = "near_sdk::serde")]
pub struct VestingScheduleWithSalt {
    /// The vesting schedule
    pub vesting_schedule: VestingSchedule,
    /// Salt to make the hash unique
    pub salt: Base64VecU8,
}

'''
'''--- dockerfile/src/aggregated/circulating_supply/mod.rs ---
use std::ops::{Add, Sub};
use std::str::FromStr;
use std::time::{Duration, SystemTime};

use actix::Addr;
use actix_diesel::Database;
use anyhow::Context;
use bigdecimal::{BigDecimal, ToPrimitive};
use chrono::NaiveDateTime;
use diesel::PgConnection;
use tracing::{error, info, warn};

use near_indexer::near_primitives;

use crate::aggregated::{account_details, circulating_supply};
use crate::db_adapters::accounts;
use crate::db_adapters::aggregated::circulating_supply::{
    add_circulating_supply, get_precomputed_circulating_supply_for_timestamp,
};
use crate::db_adapters::blocks;
use crate::models;
use crate::models::aggregated::circulating_supply::CirculatingSupply;

mod lockup;
mod lockup_types;

const DAY: Duration = Duration::from_secs(60 * 60 * 24);
const RETRY_DURATION: Duration = Duration::from_secs(60 * 60 * 2);

// Compute circulating supply on a daily basis, starting from 13 Oct 2020
// (Transfers enabled moment on the Mainnet), and put it to the Indexer DB.
// Circulating supply is calculated by the formula:
// total_supply - sum(locked_tokens_on_each_lockup) - sum(locked_foundation_account)
// The value is always computed for the last block in a day (UTC).
pub(super) async fn run_circulating_supply_computation(
    view_client: Addr<near_client::ViewClientActor>,
    pool: Database<PgConnection>,
) {
    // We perform actual computations 00:10 UTC each day to be sure that the data is finalized
    let mut day_to_compute = lockup::TRANSFERS_ENABLED
        .sub(Duration::from_secs(
            lockup::TRANSFERS_ENABLED.as_secs() % DAY.as_secs(),
        ))
        .add(DAY)
        .add(Duration::from_secs(10 * 60));

    loop {
        let now = SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .expect("Time went backwards");

        if now < day_to_compute {
            tokio::time::sleep_until(tokio::time::Instant::now().add(day_to_compute.sub(now)))
                .await;
        }
        wait_for_loading_needed_blocks(&view_client, &day_to_compute).await;

        match check_and_collect_daily_circulating_supply(&view_client, &pool, &day_to_compute).await
        {
            Ok(_) => {
                day_to_compute = day_to_compute.add(DAY);
            }
            Err(err) => {
                error!(
                    target: crate::AGGREGATED,
                    "Failed to compute circulating supply for {}: {}. Retry in {} hours",
                    NaiveDateTime::from_timestamp(day_to_compute.as_secs() as i64, 0).date(),
                    err,
                    RETRY_DURATION.as_secs() / 60 / 60,
                );
                tokio::time::sleep(RETRY_DURATION).await;
            }
        };
    }
}

async fn check_and_collect_daily_circulating_supply(
    view_client: &Addr<near_client::ViewClientActor>,
    pool: &Database<PgConnection>,
    request_datetime: &Duration,
) -> anyhow::Result<Option<CirculatingSupply>> {
    let start_of_day = request_datetime.as_nanos()
        - request_datetime.as_nanos() % circulating_supply::DAY.as_nanos();
    let printable_date = NaiveDateTime::from_timestamp(request_datetime.as_secs() as i64, 0).date();
    let block = blocks::get_latest_block_before_timestamp(pool, start_of_day as u64).await?;
    let block_timestamp = block
        .block_timestamp
        .to_u64()
        .context("`block_timestamp` expected to be u64")?;

    match get_precomputed_circulating_supply_for_timestamp(pool, block_timestamp).await {
        Ok(None) => {
            info!(
                target: crate::AGGREGATED,
                "Computing circulating supply for {} (timestamp {})",
                printable_date,
                block_timestamp
            );
            let supply = compute_circulating_supply_for_block(pool, view_client, &block).await?;
            add_circulating_supply(pool, &supply).await;
            info!(
                target: crate::AGGREGATED,
                "Circulating supply for {} (timestamp {}) is {}",
                printable_date,
                block_timestamp,
                supply.circulating_tokens_supply
            );
            Ok(Some(supply))
        }
        Ok(Some(supply)) => {
            info!(
                target: crate::AGGREGATED,
                "Circulating supply for {} (timestamp {}) was already computed: {}",
                printable_date,
                block_timestamp,
                supply
            );
            Ok(None)
        }
        Err(err) => Err(err),
    }
}

async fn compute_circulating_supply_for_block(
    pool: &Database<PgConnection>,
    view_client: &Addr<near_client::ViewClientActor>,
    block: &models::Block,
) -> anyhow::Result<CirculatingSupply> {
    let block_timestamp = block
        .block_timestamp
        .to_u64()
        .context("`block_timestamp` expected to be u64")?;
    let block_height = block
        .block_height
        .to_u64()
        .context("`block_height` expected to be u64")?;
    let total_supply = block
        .total_supply
        .to_string()
        .parse::<u128>()
        .context("`total_supply` expected to be u128")?;

    let lockup_account_ids =
        accounts::get_lockup_account_ids_at_block_height(pool, &block_height).await?;

    let mut lockups_locked_tokens: u128 = 0;
    let mut unfinished_lockup_contracts_count: i32 = 0;

    for lockup_account_id in &lockup_account_ids {
        let state =
            lockup::get_lockup_contract_state(view_client, lockup_account_id, &block_height)
                .await
                .with_context(|| {
                    format!(
                        "Failed to get lockup contract details for {}",
                        lockup_account_id
                    )
                })?;
        let code_hash =
            account_details::get_contract_code_hash(view_client, lockup_account_id, &block_height)
                .await?;
        let is_lockup_with_bug = lockup::is_bug_inside_contract(&code_hash, lockup_account_id)?;
        let locked_amount = state
            .get_locked_amount(block_timestamp, is_lockup_with_bug)
            .0;
        lockups_locked_tokens += locked_amount;
        if locked_amount > 0 {
            unfinished_lockup_contracts_count += 1;
        }
    }

    // The list is taken from the conversation with Yessin
    let foundation_locked_account_ids: [near_primitives::types::AccountId; 2] = [
        near_primitives::types::AccountId::from_str("lockup.near")
            .expect("lockup.near expected to be a valid AccountId"),
        near_primitives::types::AccountId::from_str("contributors.near")
            .expect("contributors.near expected to be a valid AccountId"),
    ];
    let mut foundation_locked_tokens: u128 = 0;
    for account_id in &foundation_locked_account_ids {
        foundation_locked_tokens +=
            account_details::get_account_balance(view_client, account_id, &block_height).await?;
    }

    let circulating_supply: u128 = total_supply - foundation_locked_tokens - lockups_locked_tokens;

    Ok(CirculatingSupply {
        computed_at_block_timestamp: BigDecimal::from(block_timestamp),
        computed_at_block_hash: (&block.block_hash).to_string(),
        circulating_tokens_supply: BigDecimal::from_str(&circulating_supply.to_string())
            .context("`circulating_tokens_supply` expected to be u128")?,
        total_tokens_supply: BigDecimal::from_str(&total_supply.to_string())
            .context("`total_supply` expected to be u128")?,
        total_lockup_contracts_count: lockup_account_ids.len() as i32,
        unfinished_lockup_contracts_count,
        foundation_locked_tokens: BigDecimal::from_str(&foundation_locked_tokens.to_string())
            .context("`foundation_locked_supply` expected to be u128")?,
        lockups_locked_tokens: BigDecimal::from_str(&lockups_locked_tokens.to_string())
            .context("`lockups_locked_supply` expected to be u128")?,
    })
}

async fn wait_for_loading_needed_blocks(
    view_client: &Addr<near_client::ViewClientActor>,
    day_to_compute: &Duration,
) {
    loop {
        match get_final_block_timestamp(view_client).await {
            Ok(timestamp) => {
                if timestamp > *day_to_compute {
                    return;
                }
                warn!(
                        target: crate::AGGREGATED,
                        "Blocks are not loaded to calculate circulating supply for {}. Wait for {} hours",
                        NaiveDateTime::from_timestamp(day_to_compute.as_secs() as i64, 0).date(),
                        circulating_supply::RETRY_DURATION.as_secs() / 60 / 60,
                    );
            }
            Err(err) => {
                error!(
                    target: crate::AGGREGATED,
                    "Failed to get latest block timestamp: {}. Retry in {} hours",
                    err,
                    circulating_supply::RETRY_DURATION.as_secs() / 60 / 60,
                );
            }
        }
        tokio::time::sleep(circulating_supply::RETRY_DURATION).await;
    }
}

async fn get_final_block_timestamp(
    view_client: &Addr<near_client::ViewClientActor>,
) -> anyhow::Result<Duration> {
    let block_reference =
        near_primitives::types::BlockReference::Finality(near_primitives::types::Finality::Final);
    let query = near_client::GetBlock(block_reference);

    let block_response = view_client
        .send(query)
        .await
        .context("Failed to deliver response")?
        .context("Invalid request")?;

    Ok(Duration::from_nanos(block_response.header.timestamp))
}

'''
'''--- dockerfile/src/aggregated/mod.rs ---
use actix_diesel::Database;
use diesel::PgConnection;
use near_indexer::Indexer;

mod account_details;
mod circulating_supply;

pub(crate) fn spawn_aggregated_computations(pool: Database<PgConnection>, indexer: &Indexer) {
    let view_client = indexer.client_actors().0;
    if indexer.near_config().genesis.config.chain_id == "mainnet" {
        actix::spawn(circulating_supply::run_circulating_supply_computation(
            view_client,
            pool,
        ));
    }
}

'''
'''--- dockerfile/src/configs.rs ---
use std::convert::TryFrom;

use clap::Parser;

/// NEAR Indexer for Explorer
/// Watches for stream of blocks from the chain
#[derive(Parser, Debug)]
#[clap(
    version,
    author,
    about,
    setting(clap::AppSettings::DisableHelpSubcommand),
    setting(clap::AppSettings::PropagateVersion),
    setting(clap::AppSettings::NextLineHelp)
)]
pub(crate) struct Opts {
    /// Sets a custom config dir. Defaults to ~/.near/
    #[clap(short, long)]
    pub home_dir: Option<std::path::PathBuf>,
    /// Enabled Indexer for Explorer debug level of logs
    #[clap(long)]
    pub debug: bool,
    #[clap(subcommand)]
    pub subcmd: SubCommand,
}

#[derive(Parser, Debug)]
pub(crate) enum SubCommand {
    /// Run NEAR Indexer Example. Start observe the network
    Run(RunArgs),
    /// Initialize necessary configs
    Init(InitConfigArgs),
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct RunArgs {
    /// Store initial data from genesis like Accounts, AccessKeys
    #[clap(long)]
    pub store_genesis: bool,
    /// Force streaming while node is syncing
    #[clap(long)]
    pub stream_while_syncing: bool,
    /// Switches indexer to non-strict mode (skips Receipts without parent Transaction hash, stops storing AccountChanges and AccessKeys)
    #[clap(long)]
    pub non_strict_mode: bool,
    /// Stops indexer completely after indexing the provided number of blocks
    #[clap(long, short)]
    pub stop_after_number_of_blocks: Option<std::num::NonZeroUsize>,
    /// Sets the concurrency for indexing. Note: concurrency (set to 2+) may lead to warnings due to tight constraints between transactions and receipts (those will get resolved eventually, but unless it is the second pass of indexing, concurrency won't help at the moment).
    #[clap(long, default_value = "1")]
    pub concurrency: std::num::NonZeroU16,
    #[clap(subcommand)]
    pub sync_mode: SyncModeSubCommand,
}

#[allow(clippy::enum_variant_names)] // we want commands to be more explicit
#[derive(Parser, Debug, Clone)]
pub(crate) enum SyncModeSubCommand {
    /// continue from the block Indexer was interrupted
    SyncFromInterruption(InterruptionArgs),
    /// start from the newest block after node finishes syncing
    SyncFromLatest,
    /// start from specified block height
    SyncFromBlock(BlockArgs),
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct InterruptionArgs {
    /// start indexing this number of blocks earlier than the actual interruption happened
    #[clap(long, default_value = "0")]
    pub delta: u64,
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct BlockArgs {
    /// block height for block sync mode
    #[clap(long)]
    pub height: u64,
}

impl TryFrom<SyncModeSubCommand> for near_indexer::SyncModeEnum {
    type Error = &'static str;

    fn try_from(sync_mode: SyncModeSubCommand) -> Result<Self, Self::Error> {
        match sync_mode {
            SyncModeSubCommand::SyncFromInterruption(_) => Err("Unable to convert SyncFromInterruption variant because it has additional parameter which is not acceptable by near_indexer::SyncModeEnum::SyncFromInterruption"),
            SyncModeSubCommand::SyncFromLatest => Ok(Self::LatestSynced),
            SyncModeSubCommand::SyncFromBlock(args) => Ok(Self::BlockHeight(args.height)),
        }
    }
}

#[derive(Parser, Debug)]
pub(crate) struct InitConfigArgs {
    /// chain/network id (localnet, testnet, devnet, betanet)
    #[clap(short, long)]
    pub chain_id: Option<String>,
    /// Account ID for the validator key
    #[clap(long)]
    pub account_id: Option<String>,
    /// Specify private key generated from seed (TESTING ONLY)
    #[clap(long)]
    pub test_seed: Option<String>,
    /// Number of shards to initialize the chain with
    #[clap(short, long, default_value = "1")]
    pub num_shards: u64,
    /// Makes block production fast (TESTING ONLY)
    #[clap(short, long)]
    pub fast: bool,
    /// Genesis file to use when initialize testnet (including downloading)
    #[clap(short, long)]
    pub genesis: Option<String>,
    #[clap(short, long)]
    /// Download the verified NEAR config file automatically.
    #[clap(long)]
    pub download_config: bool,
    #[clap(long)]
    pub download_config_url: Option<String>,
    /// Download the verified NEAR genesis file automatically.
    #[clap(long)]
    pub download_genesis: bool,
    /// Specify a custom download URL for the genesis-file.
    #[clap(long)]
    pub download_genesis_url: Option<String>,
    /// Customize max_gas_burnt_view runtime limit.  If not specified, value
    /// from genesis configuration will be taken.
    #[clap(long)]
    pub max_gas_burnt_view: Option<u64>,
    /// Initialize boots nodes in <node_key>@<ip_addr> format seperated by commas
    /// to bootstrap the network and store them in config.json
    #[clap(long)]
    pub boot_nodes: Option<String>,
}

'''
'''--- dockerfile/src/db_adapters/access_keys.rs ---
use std::collections::HashMap;
use std::convert::TryFrom;

use actix_diesel::dsl::AsyncRunQueryDsl;
use actix_diesel::Database;
use bigdecimal::BigDecimal;
use diesel::{ExpressionMethods, PgConnection, QueryDsl};
use futures::try_join;
use tracing::info;

use near_indexer::near_primitives;

use crate::models;
use crate::schema;

pub(crate) async fn handle_access_keys(
    pool: &actix_diesel::Database<PgConnection>,
    outcomes: &[near_indexer::IndexerExecutionOutcomeWithReceipt],
    block_height: near_primitives::types::BlockHeight,
) -> anyhow::Result<()> {
    if outcomes.is_empty() {
        return Ok(());
    }
    let successful_receipts = outcomes
        .iter()
        .filter(|outcome_with_receipt| {
            matches!(
                outcome_with_receipt.execution_outcome.outcome.status,
                near_primitives::views::ExecutionStatusView::SuccessValue(_)
                    | near_primitives::views::ExecutionStatusView::SuccessReceiptId(_)
            )
        })
        .map(|outcome_with_receipt| &outcome_with_receipt.receipt);

    let mut access_keys = HashMap::<(String, String), models::access_keys::AccessKey>::new();
    let mut deleted_accounts = HashMap::<String, String>::new();

    for receipt in successful_receipts {
        if let near_primitives::views::ReceiptEnumView::Action { actions, .. } = &receipt.receipt {
            for action in actions {
                match action {
                    near_primitives::views::ActionView::DeleteAccount { .. } => {
                        deleted_accounts.insert(
                            receipt.receiver_id.to_string(),
                            receipt.receipt_id.to_string(),
                        );
                        access_keys
                            .iter_mut()
                            .filter(|((_, receiver_id), _)| {
                                receiver_id == receipt.receiver_id.as_ref()
                            })
                            .for_each(|(_, access_key)| {
                                access_key.deleted_by_receipt_id =
                                    Some(receipt.receipt_id.to_string());
                            });
                    }
                    near_primitives::views::ActionView::AddKey {
                        public_key,
                        access_key,
                    } => {
                        access_keys.insert(
                            (public_key.to_string(), receipt.receiver_id.to_string()),
                            models::access_keys::AccessKey::from_action_view(
                                public_key,
                                &receipt.receiver_id,
                                access_key,
                                &receipt.receipt_id,
                                block_height,
                            ),
                        );
                    }
                    near_primitives::views::ActionView::DeleteKey { public_key } => {
                        access_keys
                            .entry((public_key.to_string(), receipt.receiver_id.to_string()))
                            .and_modify(|existing_access_key| {
                                existing_access_key.deleted_by_receipt_id =
                                    Some(receipt.receipt_id.to_string());
                            })
                            .or_insert_with(|| models::access_keys::AccessKey {
                                public_key: public_key.to_string(),
                                account_id: receipt.receiver_id.to_string(),
                                created_by_receipt_id: None,
                                deleted_by_receipt_id: Some(receipt.receipt_id.to_string()),
                                // this is a workaround to avoid additional struct with optional field
                                // permission_kind is not supposed to change on delete action
                                permission_kind: models::enums::AccessKeyPermission::FullAccess,
                                last_update_block_height: block_height.into(),
                            });
                    }
                    near_indexer::near_primitives::views::ActionView::Transfer { .. } => {
                        if receipt.receiver_id.len() != 64usize {
                            continue;
                        }
                        if let Ok(public_key_bytes) = hex::decode(receipt.receiver_id.as_ref()) {
                            if let Ok(public_key) =
                                near_crypto::ED25519PublicKey::try_from(&public_key_bytes[..])
                            {
                                access_keys.insert(
                                    (near_crypto::PublicKey::from(public_key.clone()).to_string(), receipt.receiver_id.to_string()),
                                    models::access_keys::AccessKey::from_action_view(
                                        &near_crypto::PublicKey::from(public_key.clone()),
                                        &receipt.receiver_id,
                                        &near_primitives::views::AccessKeyView {
                                            nonce: 0,
                                            permission: near_primitives::views::AccessKeyPermissionView::FullAccess
                                        },
                                        &receipt.receipt_id,
                                        block_height,
                                    ),
                                );
                            }
                        }
                    }
                    _ => continue,
                }
            }
        }
    }

    let (access_keys_to_insert, access_keys_to_update): (
        Vec<models::access_keys::AccessKey>,
        Vec<models::access_keys::AccessKey>,
    ) = access_keys
        .values()
        .cloned()
        .partition(|model| model.created_by_receipt_id.is_some());

    let delete_access_keys_for_deleted_accounts = async {
        let last_update_block_height: BigDecimal = block_height.into();
        for (account_id, deleted_by_receipt_id) in deleted_accounts {
            let target = schema::access_keys::table
                .filter(schema::access_keys::dsl::deleted_by_receipt_id.is_null())
                .filter(
                    schema::access_keys::dsl::last_update_block_height
                        .lt(last_update_block_height.clone()),
                )
                .filter(schema::access_keys::dsl::account_id.eq(account_id));

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::access_keys::dsl::deleted_by_receipt_id
                            .eq(deleted_by_receipt_id.clone()),
                        schema::access_keys::dsl::last_update_block_height
                            .eq(last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "AccessKeys were deleting".to_string(),
                &deleted_by_receipt_id
            );
        }
        Ok(())
    };

    let update_access_keys_future = async {
        for value in access_keys_to_update {
            let target = schema::access_keys::table
                .filter(schema::access_keys::dsl::public_key.eq(value.public_key.clone()))
                .filter(
                    schema::access_keys::dsl::last_update_block_height
                        .lt(value.last_update_block_height.clone()),
                )
                .filter(schema::access_keys::dsl::account_id.eq(value.account_id));

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::access_keys::dsl::deleted_by_receipt_id
                            .eq(value.deleted_by_receipt_id.clone()),
                        schema::access_keys::dsl::last_update_block_height
                            .eq(value.last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "AccessKeys were updating".to_string(),
                &value.public_key
            );
        }
        Ok(())
    };

    let add_access_keys_future = async {
        crate::await_retry_or_panic!(
            diesel::insert_into(schema::access_keys::table)
                .values(access_keys_to_insert.clone())
                .on_conflict_do_nothing()
                .execute_async(pool),
            10,
            "AccessKeys were stored in database".to_string(),
            &access_keys_to_insert
        );

        for value in access_keys_to_insert {
            let target = schema::access_keys::table
                .filter(schema::access_keys::dsl::public_key.eq(value.public_key.clone()))
                .filter(
                    schema::access_keys::dsl::last_update_block_height
                        .lt(value.last_update_block_height.clone()),
                )
                .filter(schema::access_keys::dsl::account_id.eq(value.account_id));

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::access_keys::dsl::created_by_receipt_id
                            .eq(value.created_by_receipt_id.clone()),
                        schema::access_keys::dsl::deleted_by_receipt_id
                            .eq(value.deleted_by_receipt_id.clone()),
                        schema::access_keys::dsl::last_update_block_height
                            .eq(value.last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "AccessKeys were created".to_string(),
                &value.public_key
            );
        }
        Ok(())
    };

    try_join!(
        delete_access_keys_for_deleted_accounts,
        update_access_keys_future,
        add_access_keys_future
    )?;

    Ok(())
}

pub(crate) async fn store_access_keys_from_genesis(
    pool: Database<PgConnection>,
    access_keys_models: Vec<models::access_keys::AccessKey>,
) -> anyhow::Result<()> {
    info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Adding/updating access keys from genesis..."
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::access_keys::table)
            .values(access_keys_models.clone())
            .on_conflict_do_nothing()
            .execute_async(&pool),
        10,
        "AccessKeys were stored from genesis".to_string(),
        &access_keys_models
    );
    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/account_changes.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use diesel::PgConnection;

use crate::models;
use crate::schema;

/// Saves state change related to account to database
pub(crate) async fn store_account_changes(
    pool: &actix_diesel::Database<PgConnection>,
    state_changes: &[near_indexer::near_primitives::views::StateChangeWithCauseView],
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_timestamp: u64,
) -> anyhow::Result<()> {
    if state_changes.is_empty() {
        return Ok(());
    }

    let account_changes_models: Vec<models::account_changes::AccountChange> = state_changes
        .iter()
        .enumerate()
        .filter_map(|(index_in_block, state_change)| {
            models::account_changes::AccountChange::from_state_change_with_cause(
                state_change,
                block_hash,
                block_timestamp,
                index_in_block as i32,
            )
        })
        .collect();

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::account_changes::table)
            .values(account_changes_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "AccountChanges were stored in database".to_string(),
        &account_changes_models
    );
    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/accounts.rs ---
use std::collections::HashMap;
use std::convert::TryFrom;

use actix_diesel::dsl::AsyncRunQueryDsl;
use actix_diesel::Database;
use anyhow::Context;
use bigdecimal::BigDecimal;
use diesel::{BoolExpressionMethods, ExpressionMethods, PgConnection, QueryDsl};
use futures::try_join;

use tracing::info;

use near_indexer::near_primitives;

use crate::models;
use crate::schema;

/// Saves new Accounts to database or deletes the ones should be deleted
pub(crate) async fn handle_accounts(
    pool: &actix_diesel::Database<PgConnection>,
    outcomes: &[near_indexer::IndexerExecutionOutcomeWithReceipt],
    block_height: near_primitives::types::BlockHeight,
) -> anyhow::Result<()> {
    if outcomes.is_empty() {
        return Ok(());
    }
    let successful_receipts = outcomes
        .iter()
        .filter(|outcome_with_receipt| {
            matches!(
                outcome_with_receipt.execution_outcome.outcome.status,
                near_primitives::views::ExecutionStatusView::SuccessValue(_)
                    | near_primitives::views::ExecutionStatusView::SuccessReceiptId(_)
            )
        })
        .map(|outcome_with_receipt| &outcome_with_receipt.receipt);

    let mut accounts =
        HashMap::<near_primitives::types::AccountId, models::accounts::Account>::new();

    for receipt in successful_receipts {
        if let near_primitives::views::ReceiptEnumView::Action { actions, .. } = &receipt.receipt {
            for action in actions {
                match action {
                    near_primitives::views::ActionView::CreateAccount => {
                        accounts.insert(
                            receipt.receiver_id.clone(),
                            models::accounts::Account::new_from_receipt(
                                &receipt.receiver_id,
                                &receipt.receipt_id,
                                block_height,
                            ),
                        );
                    }
                    near_primitives::views::ActionView::Transfer { .. } => {
                        if receipt.receiver_id.len() == 64usize {
                            accounts.insert(
                                receipt.receiver_id.clone(),
                                models::accounts::Account::new_from_receipt(
                                    &receipt.receiver_id,
                                    &receipt.receipt_id,
                                    block_height,
                                ),
                            );
                        }
                    }
                    near_primitives::views::ActionView::DeleteAccount { .. } => {
                        accounts
                            .entry(receipt.receiver_id.clone())
                            .and_modify(|existing_account| {
                                existing_account.deleted_by_receipt_id =
                                    Some(receipt.receipt_id.to_string())
                            })
                            .or_insert_with(|| models::accounts::Account {
                                account_id: receipt.receiver_id.to_string(),
                                created_by_receipt_id: None,
                                deleted_by_receipt_id: Some(receipt.receipt_id.to_string()),
                                last_update_block_height: block_height.into(),
                            });
                    }
                    _ => {}
                }
            }
        }
    }

    let (accounts_to_create_or_update, accounts_to_delete): (
        Vec<models::accounts::Account>,
        Vec<models::accounts::Account>,
    ) = accounts
        .values()
        .cloned()
        .partition(|model| model.created_by_receipt_id.is_some());

    let delete_accounts_future = async {
        for value in accounts_to_delete {
            let target = schema::accounts::table
                .filter(schema::accounts::dsl::account_id.eq(value.account_id.clone()))
                .filter(
                    schema::accounts::dsl::last_update_block_height
                        .lt(value.last_update_block_height.clone()),
                );

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::accounts::dsl::deleted_by_receipt_id
                            .eq(value.deleted_by_receipt_id.clone()),
                        schema::accounts::dsl::last_update_block_height
                            .eq(value.last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "Accounts were deleted".to_string(),
                &value.account_id
            );
        }
        Ok(())
    };

    let create_or_update_accounts_future = async {
        crate::await_retry_or_panic!(
            diesel::insert_into(schema::accounts::table)
                .values(accounts_to_create_or_update.clone())
                .on_conflict_do_nothing()
                .execute_async(pool),
            10,
            "Accounts were created/updated".to_string(),
            &accounts_to_create_or_update
        );

        // [Implicit accounts](https://docs.near.org/docs/roles/integrator/implicit-accounts)
        // pretend to be created on each transfer to these accounts and cause some confusion
        // Resolving the issue https://github.com/near/near-indexer-for-explorer/issues/68 to avoid confusion
        // we block updating `created_by_receipt_id` for implicit accounts that were not deleted
        // (have `deleted_by_receipt_id` NOT NULL)
        // For this purpose we separate such accounts from others to handle them properly
        let (implicit_accounts_to_recreate, other_accounts_to_update): (
            Vec<models::accounts::Account>,
            Vec<models::accounts::Account>,
        ) = accounts_to_create_or_update.into_iter().partition(|model| {
            model.account_id.len() == 64 && model.deleted_by_receipt_id.is_none()
        });

        for value in implicit_accounts_to_recreate {
            let target = schema::accounts::table
                .filter(schema::accounts::dsl::account_id.eq(value.account_id.clone()))
                .filter(schema::accounts::dsl::deleted_by_receipt_id.is_not_null()) // this filter ensures we update only "deleted" accounts
                .filter(
                    schema::accounts::dsl::last_update_block_height
                        .lt(value.last_update_block_height.clone()),
                );

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::accounts::dsl::created_by_receipt_id
                            .eq(value.created_by_receipt_id.clone()),
                        schema::accounts::dsl::deleted_by_receipt_id
                            .eq(value.deleted_by_receipt_id.clone()),
                        schema::accounts::dsl::last_update_block_height
                            .eq(value.last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "Implicit Account were updated".to_string(),
                &value.account_id
            );
        }

        for value in other_accounts_to_update {
            let target = schema::accounts::table
                .filter(schema::accounts::dsl::account_id.eq(value.account_id.clone()))
                .filter(
                    schema::accounts::dsl::last_update_block_height
                        .lt(value.last_update_block_height.clone()),
                );

            crate::await_retry_or_panic!(
                diesel::update(target.clone())
                    .set((
                        schema::accounts::dsl::created_by_receipt_id
                            .eq(value.created_by_receipt_id.clone()),
                        schema::accounts::dsl::deleted_by_receipt_id
                            .eq(value.deleted_by_receipt_id.clone()),
                        schema::accounts::dsl::last_update_block_height
                            .eq(value.last_update_block_height.clone()),
                    ))
                    .execute_async(pool),
                10,
                "Account was updated".to_string(),
                &value.account_id
            );
        }
        Ok(())
    };

    // Joining it unless we can't execute it in the correct order
    // see https://github.com/nearprotocol/nearcore/issues/3467
    try_join!(delete_accounts_future, create_or_update_accounts_future)?;
    Ok(())
}

pub(crate) async fn store_accounts_from_genesis(
    pool: Database<PgConnection>,
    accounts_models: Vec<models::accounts::Account>,
) -> anyhow::Result<()> {
    info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Adding/updating accounts from genesis..."
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::accounts::table)
            .values(accounts_models.clone())
            .on_conflict_do_nothing()
            .execute_async(&pool),
        10,
        "Accounts were stored from genesis".to_string(),
        &accounts_models
    );

    Ok(())
}

pub(crate) async fn get_lockup_account_ids_at_block_height(
    pool: &actix_diesel::Database<PgConnection>,
    block_height: &near_primitives::types::BlockHeight,
) -> anyhow::Result<Vec<near_primitives::types::AccountId>> {
    // Diesel does not support named joins
    // https://github.com/diesel-rs/diesel/pull/2254
    // Raw SQL (diesel-1.4.7/src/query_builder/functions.rs:464) does not support async methods
    // So we decided to use view + simple SQL with `where` clause
    // Initial SQL statement:
    //   let raw_sql: String = format!("
    //   SELECT accounts.account_id, blocks_start.block_height, blocks_end.block_height
    //   FROM accounts
    //            LEFT JOIN receipts AS receipts_start ON accounts.created_by_receipt_id = receipts_start.receipt_id
    //            LEFT JOIN blocks AS blocks_start ON receipts_start.included_in_block_hash = blocks_start.block_hash
    //            LEFT JOIN receipts AS receipts_end ON accounts.deleted_by_receipt_id = receipts_end.receipt_id
    //            LEFT JOIN blocks AS blocks_end ON receipts_end.included_in_block_hash = blocks_end.block_hash
    //   WHERE accounts.account_id like '%.lockup.near'
    //     AND (blocks_start.block_height IS NULL OR blocks_start.block_height <= {0})
    //     AND (blocks_end.block_height IS NULL OR blocks_end.block_height >= {0});
    // ", block_height);

    schema::aggregated__lockups::table
        .select(schema::aggregated__lockups::dsl::account_id)
        .filter(
            schema::aggregated__lockups::dsl::creation_block_height
                .is_null()
                .or(schema::aggregated__lockups::dsl::creation_block_height
                    .le(BigDecimal::from(*block_height))),
        )
        .filter(
            schema::aggregated__lockups::dsl::deletion_block_height
                .is_null()
                .or(schema::aggregated__lockups::dsl::deletion_block_height
                    .ge(BigDecimal::from(*block_height))),
        )
        .get_results_async::<String>(pool)
        .await
        .with_context(|| format!(
                "DB error while collecting lockup account ids for block_height {}",
                block_height
            )
        )
        .map(|results| {
            results
                .into_iter()
                .map(|account_id_string|
                    near_primitives::types::AccountId::try_from(account_id_string)
                        .expect("Selecting lockup account ids bumped into the account_id which is not valid; that should never happen"))
                .collect()
        })
}

'''
'''--- dockerfile/src/db_adapters/aggregated/circulating_supply.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use bigdecimal::BigDecimal;
use diesel::{ExpressionMethods, PgConnection, QueryDsl};
use tracing::error;

use crate::models::aggregated::circulating_supply::CirculatingSupply;
use crate::schema;

pub(crate) async fn add_circulating_supply(
    pool: &actix_diesel::Database<PgConnection>,
    stats: &CirculatingSupply,
) {
    let mut interval = crate::INTERVAL;
    loop {
        match diesel::insert_into(schema::aggregated__circulating_supply::table)
            .values(stats.to_owned())
            .on_conflict_do_nothing()
            .execute_async(pool)
            .await
        {
            Ok(_) => {
                break;
            }
            Err(async_error) => {
                error!(
                    target: crate::AGGREGATED,
                    "Error occurred while Circulating Supply was adding to database. Retrying in {} milliseconds... \n {:#?}",
                    interval.as_millis(),
                    async_error
                );
                tokio::time::sleep(interval).await;
                if interval < crate::MAX_DELAY_TIME {
                    interval *= 2;
                }
            }
        }
    }
}

pub(crate) async fn get_precomputed_circulating_supply_for_timestamp(
    pool: &actix_diesel::Database<PgConnection>,
    timestamp: u64,
) -> anyhow::Result<Option<u128>> {
    let supply = schema::aggregated__circulating_supply::table
        .select(schema::aggregated__circulating_supply::dsl::circulating_tokens_supply)
        .filter(
            schema::aggregated__circulating_supply::dsl::computed_at_block_timestamp
                .eq(BigDecimal::from(timestamp)),
        )
        .get_optional_result_async::<bigdecimal::BigDecimal>(pool)
        .await;

    match supply {
        Ok(Some(value)) => match value.to_string().parse::<u128>() {
            Ok(res) => Ok(Some(res)),
            Err(_) => anyhow::bail!("`circulating_tokens_supply` expected to be u128"),
        },
        Ok(None) => Ok(None),
        Err(err) => anyhow::bail!("DB Error: {}", err),
    }
}

'''
'''--- dockerfile/src/db_adapters/aggregated/mod.rs ---
pub(crate) mod circulating_supply;

'''
'''--- dockerfile/src/db_adapters/assets/event_types.rs ---
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "standard")]
#[serde(rename_all = "snake_case")]
pub(crate) enum NearEvent {
    Nep141(Nep141Event),
    Nep171(Nep171Event),
}

// *** NEP-141 FT ***
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct Nep141Event {
    pub version: String,
    #[serde(flatten)]
    pub event_kind: Nep141EventKind,
}

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "event", content = "data")]
#[serde(rename_all = "snake_case")]
#[allow(clippy::enum_variant_names)]
pub(crate) enum Nep141EventKind {
    FtMint(Vec<FtMintData>),
    FtTransfer(Vec<FtTransferData>),
    FtBurn(Vec<FtBurnData>),
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct FtMintData {
    pub owner_id: String,
    pub amount: String,
    pub memo: Option<String>,
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct FtTransferData {
    pub old_owner_id: String,
    pub new_owner_id: String,
    pub amount: String,
    pub memo: Option<String>,
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct FtBurnData {
    pub owner_id: String,
    pub amount: String,
    pub memo: Option<String>,
}

// *** NEP-171 NFT ***
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct Nep171Event {
    pub version: String,
    #[serde(flatten)]
    pub event_kind: Nep171EventKind,
}

#[derive(Serialize, Deserialize, Debug)]
#[serde(tag = "event", content = "data")]
#[serde(rename_all = "snake_case")]
#[allow(clippy::enum_variant_names)]
pub(crate) enum Nep171EventKind {
    NftMint(Vec<NftMintData>),
    NftTransfer(Vec<NftTransferData>),
    NftBurn(Vec<NftBurnData>),
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct NftMintData {
    pub owner_id: String,
    pub token_ids: Vec<String>,
    pub memo: Option<String>,
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct NftTransferData {
    pub authorized_id: Option<String>,
    pub old_owner_id: String,
    pub new_owner_id: String,
    pub token_ids: Vec<String>,
    pub memo: Option<String>,
}

#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct NftBurnData {
    pub authorized_id: Option<String>,
    pub owner_id: String,
    pub token_ids: Vec<String>,
    pub memo: Option<String>,
}

'''
'''--- dockerfile/src/db_adapters/assets/events.rs ---
use actix_diesel::{AsyncError, Database};
use diesel::PgConnection;
use tracing::warn;

use crate::db_adapters::assets;

use super::event_types;

pub(crate) async fn store_events(
    pool: &Database<PgConnection>,
    streamer_message: &near_indexer::StreamerMessage,
) -> anyhow::Result<()> {
    let futures = streamer_message.shards.iter().map(|shard| {
        collect_and_store_events(pool, shard, streamer_message.block.header.timestamp)
    });

    futures::future::try_join_all(futures).await.map(|_| ())
}

pub(crate) async fn detect_db_error(
    async_error: &AsyncError<diesel::result::Error>,
    duplicate_constraint_name: &str,
    broken_data_constraint_name: &str,
) -> bool {
    if let actix_diesel::AsyncError::Execute(diesel::result::Error::DatabaseError(
        diesel::result::DatabaseErrorKind::UniqueViolation,
        ref error_info,
    )) = *async_error
    {
        let constraint_name = error_info.constraint_name().unwrap_or("");
        if constraint_name == duplicate_constraint_name {
            // Everything is fine, we have already written this to the DB
            return true;
        } else if constraint_name == broken_data_constraint_name {
            warn!(
                target: crate::INDEXER_FOR_EXPLORER,
                "assets::events: data inconsistency is found"
            );
        }
    }
    false
}

async fn collect_and_store_events(
    pool: &Database<PgConnection>,
    shard: &near_indexer::IndexerShard,
    block_timestamp: u64,
) -> anyhow::Result<()> {
    let mut ft_events_with_outcomes = Vec::new();
    let mut nft_events_with_outcomes = Vec::new();

    for outcome in &shard.receipt_execution_outcomes {
        let events = extract_events(outcome);
        for event in events {
            match event {
                assets::event_types::NearEvent::Nep141(ft_event) => {
                    ft_events_with_outcomes.push((ft_event, outcome));
                }
                assets::event_types::NearEvent::Nep171(nft_event) => {
                    nft_events_with_outcomes.push((nft_event, outcome));
                }
            }
        }
    }

    let ft_future = assets::fungible_token_events::store_ft_events(
        pool,
        shard,
        block_timestamp,
        &ft_events_with_outcomes,
    );
    let nft_future = assets::non_fungible_token_events::store_nft_events(
        pool,
        shard,
        block_timestamp,
        &nft_events_with_outcomes,
    );
    futures::try_join!(ft_future, nft_future)?;
    Ok(())
}

fn extract_events(
    outcome: &near_indexer::IndexerExecutionOutcomeWithReceipt,
) -> Vec<event_types::NearEvent> {
    let prefix = "EVENT_JSON:";
    outcome.execution_outcome.outcome.logs.iter().filter_map(|untrimmed_log| {
        let log = untrimmed_log.trim();
        if !log.starts_with(prefix) {
            return None;
        }

        match serde_json::from_str::<'_, event_types::NearEvent>(
            log[prefix.len()..].trim(),
        ) {
            Ok(result) => Some(result),
            Err(err) => {
                warn!(
                    target: crate::INDEXER_FOR_EXPLORER,
                    "Provided event log does not correspond to any of formats defined in NEP. Will ignore this event. \n {:#?} \n{:#?}",
                    err,
                    untrimmed_log,
                );
                None
            }
        }
    }).collect()
}

'''
'''--- dockerfile/src/db_adapters/assets/fungible_token_events.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use actix_diesel::{AsyncError, Database};
use bigdecimal::BigDecimal;
use diesel::PgConnection;

use crate::db_adapters::{assets, CHUNK_SIZE_FOR_BATCH_INSERT};
use crate::models;
use crate::schema;

use super::event_types;

pub(crate) async fn store_ft_events(
    pool: &Database<PgConnection>,
    shard: &near_indexer::IndexerShard,
    block_timestamp: u64,
    events_with_outcomes: &[(
        assets::event_types::Nep141Event,
        &near_indexer::IndexerExecutionOutcomeWithReceipt,
    )],
) -> anyhow::Result<()> {
    let ft_events = compose_ft_db_events(events_with_outcomes, block_timestamp, &shard.shard_id);

    for chunk in ft_events.chunks(CHUNK_SIZE_FOR_BATCH_INSERT) {
        let ft_events_chunk = chunk.to_owned();
        crate::await_retry_or_panic!(
            diesel::insert_into(schema::assets__fungible_token_events::table)
                .values(ft_events_chunk.clone())
                .execute_async(pool),
            10,
            "FungibleTokenEvent were adding to database".to_string(),
            &ft_events_chunk,
            &detect_ft_db_error
        );
    }

    Ok(())
}

async fn detect_ft_db_error(async_error: &AsyncError<diesel::result::Error>) -> bool {
    assets::events::detect_db_error(
        async_error,
        "assets__fungible_token_events_pkey",
        "assets__fungible_token_events_unique",
    )
    .await
}

fn compose_ft_db_events(
    events_with_outcomes: &[(
        assets::event_types::Nep141Event,
        &near_indexer::IndexerExecutionOutcomeWithReceipt,
    )],
    block_timestamp: u64,
    shard_id: &near_indexer::near_primitives::types::ShardId,
) -> Vec<models::assets::fungible_token_events::FungibleTokenEvent> {
    let mut ft_events = Vec::new();
    for (event, outcome) in events_with_outcomes {
        let contract_id = &outcome.receipt.receiver_id;
        match &event.event_kind {
            event_types::Nep141EventKind::FtMint(mint_events) => {
                for mint_event in mint_events {
                    ft_events.push(models::assets::fungible_token_events::FungibleTokenEvent {
                        emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                        emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                        emitted_in_shard_id: BigDecimal::from(*shard_id),
                        emitted_index_of_event_entry_in_shard: ft_events.len() as i32,
                        emitted_by_contract_account_id: contract_id.to_string(),
                        amount: mint_event.amount.to_string(),
                        event_kind: models::enums::FtEventKind::Mint,
                        token_old_owner_account_id: "".to_string(),
                        token_new_owner_account_id: mint_event
                            .owner_id
                            .escape_default()
                            .to_string(),
                        event_memo: mint_event
                            .memo
                            .clone()
                            .unwrap_or_else(|| "".to_string())
                            .escape_default()
                            .to_string(),
                    });
                }
            }
            event_types::Nep141EventKind::FtTransfer(transfer_events) => {
                for transfer_event in transfer_events {
                    ft_events.push(models::assets::fungible_token_events::FungibleTokenEvent {
                        emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                        emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                        emitted_in_shard_id: BigDecimal::from(*shard_id),
                        emitted_index_of_event_entry_in_shard: ft_events.len() as i32,
                        emitted_by_contract_account_id: contract_id.to_string(),
                        amount: transfer_event.amount.to_string(),
                        event_kind: models::enums::FtEventKind::Transfer,
                        token_old_owner_account_id: transfer_event
                            .old_owner_id
                            .escape_default()
                            .to_string(),
                        token_new_owner_account_id: transfer_event
                            .new_owner_id
                            .escape_default()
                            .to_string(),
                        event_memo: transfer_event
                            .memo
                            .clone()
                            .unwrap_or_else(|| "".to_string())
                            .escape_default()
                            .to_string(),
                    });
                }
            }
            event_types::Nep141EventKind::FtBurn(burn_events) => {
                for burn_event in burn_events {
                    ft_events.push(models::assets::fungible_token_events::FungibleTokenEvent {
                        emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                        emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                        emitted_in_shard_id: BigDecimal::from(*shard_id),
                        emitted_index_of_event_entry_in_shard: ft_events.len() as i32,
                        emitted_by_contract_account_id: contract_id.to_string(),
                        amount: burn_event.amount.to_string(),
                        event_kind: models::enums::FtEventKind::Burn,
                        token_old_owner_account_id: burn_event
                            .owner_id
                            .escape_default()
                            .to_string(),
                        token_new_owner_account_id: "".to_string(),
                        event_memo: burn_event
                            .memo
                            .clone()
                            .unwrap_or_else(|| "".to_string())
                            .escape_default()
                            .to_string(),
                    });
                }
            }
        }
    }
    ft_events
}

'''
'''--- dockerfile/src/db_adapters/assets/mod.rs ---
mod event_types;
pub(crate) mod events;
pub(crate) mod fungible_token_events;
pub(crate) mod non_fungible_token_events;

'''
'''--- dockerfile/src/db_adapters/assets/non_fungible_token_events.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use actix_diesel::{AsyncError, Database};
use bigdecimal::BigDecimal;
use diesel::PgConnection;

use crate::db_adapters::{assets, CHUNK_SIZE_FOR_BATCH_INSERT};
use crate::models;
use crate::schema;

use super::event_types;

pub(crate) async fn store_nft_events(
    pool: &Database<PgConnection>,
    shard: &near_indexer::IndexerShard,
    block_timestamp: u64,
    events_with_outcomes: &[(
        assets::event_types::Nep171Event,
        &near_indexer::IndexerExecutionOutcomeWithReceipt,
    )],
) -> anyhow::Result<()> {
    let nft_events = compose_nft_db_events(events_with_outcomes, block_timestamp, &shard.shard_id);

    for chunk in nft_events.chunks(CHUNK_SIZE_FOR_BATCH_INSERT) {
        let nft_events_chunk = chunk.to_owned();
        crate::await_retry_or_panic!(
            diesel::insert_into(schema::assets__non_fungible_token_events::table)
                .values(nft_events_chunk.clone())
                .execute_async(pool),
            10,
            "NonFungibleTokenEvent were adding to database".to_string(),
            &nft_events_chunk,
            &detect_nft_db_error
        );
    }

    Ok(())
}

async fn detect_nft_db_error(async_error: &AsyncError<diesel::result::Error>) -> bool {
    assets::events::detect_db_error(
        async_error,
        "assets__non_fungible_token_events_pkey",
        "assets__non_fungible_token_events_unique",
    )
    .await
}

fn compose_nft_db_events(
    events_with_outcomes: &[(
        assets::event_types::Nep171Event,
        &near_indexer::IndexerExecutionOutcomeWithReceipt,
    )],
    block_timestamp: u64,
    shard_id: &near_indexer::near_primitives::types::ShardId,
) -> Vec<models::assets::non_fungible_token_events::NonFungibleTokenEvent> {
    let mut nft_events = Vec::new();
    for (event, outcome) in events_with_outcomes {
        let contract_id = &outcome.receipt.receiver_id;
        match &event.event_kind {
            event_types::Nep171EventKind::NftMint(mint_events) => {
                for mint_event in mint_events {
                    let memo = mint_event.memo.clone().unwrap_or_else(|| "".to_string());
                    for token_id in &mint_event.token_ids {
                        nft_events.push(
                            models::assets::non_fungible_token_events::NonFungibleTokenEvent {
                                emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                                emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                                emitted_in_shard_id: BigDecimal::from(*shard_id),
                                emitted_index_of_event_entry_in_shard: nft_events.len() as i32,
                                emitted_by_contract_account_id: contract_id.to_string(),
                                token_id: token_id.escape_default().to_string(),
                                event_kind: models::enums::NftEventKind::Mint,
                                token_old_owner_account_id: "".to_string(),
                                token_new_owner_account_id: mint_event
                                    .owner_id
                                    .escape_default()
                                    .to_string(),
                                token_authorized_account_id: "".to_string(),
                                event_memo: memo.escape_default().to_string(),
                            },
                        );
                    }
                }
            }
            event_types::Nep171EventKind::NftTransfer(transfer_events) => {
                for transfer_event in transfer_events {
                    let authorized_id = transfer_event
                        .authorized_id
                        .clone()
                        .unwrap_or_else(|| "".to_string());
                    let memo = transfer_event
                        .memo
                        .clone()
                        .unwrap_or_else(|| "".to_string());
                    for token_id in &transfer_event.token_ids {
                        nft_events.push(
                            models::assets::non_fungible_token_events::NonFungibleTokenEvent {
                                emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                                emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                                emitted_in_shard_id: BigDecimal::from(*shard_id),
                                emitted_index_of_event_entry_in_shard: nft_events.len() as i32,
                                emitted_by_contract_account_id: contract_id.to_string(),
                                token_id: token_id.escape_default().to_string(),
                                event_kind: models::enums::NftEventKind::Transfer,
                                token_old_owner_account_id: transfer_event
                                    .old_owner_id
                                    .escape_default()
                                    .to_string(),
                                token_new_owner_account_id: transfer_event
                                    .new_owner_id
                                    .escape_default()
                                    .to_string(),
                                token_authorized_account_id: authorized_id
                                    .escape_default()
                                    .to_string(),
                                event_memo: memo.escape_default().to_string(),
                            },
                        );
                    }
                }
            }
            event_types::Nep171EventKind::NftBurn(burn_events) => {
                for burn_event in burn_events {
                    let authorized_id = &burn_event
                        .authorized_id
                        .clone()
                        .unwrap_or_else(|| "".to_string());
                    let memo = burn_event.memo.clone().unwrap_or_else(|| "".to_string());
                    for token_id in &burn_event.token_ids {
                        nft_events.push(
                            models::assets::non_fungible_token_events::NonFungibleTokenEvent {
                                emitted_for_receipt_id: outcome.receipt.receipt_id.to_string(),
                                emitted_at_block_timestamp: BigDecimal::from(block_timestamp),
                                emitted_in_shard_id: BigDecimal::from(*shard_id),
                                emitted_index_of_event_entry_in_shard: nft_events.len() as i32,
                                emitted_by_contract_account_id: contract_id.to_string(),
                                token_id: token_id.escape_default().to_string(),
                                event_kind: models::enums::NftEventKind::Burn,
                                token_old_owner_account_id: burn_event
                                    .owner_id
                                    .escape_default()
                                    .to_string(),
                                token_new_owner_account_id: "".to_string(),
                                token_authorized_account_id: authorized_id
                                    .escape_default()
                                    .to_string(),
                                event_memo: memo.escape_default().to_string(),
                            },
                        );
                    }
                }
            }
        }
    }
    nft_events
}

'''
'''--- dockerfile/src/db_adapters/blocks.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use anyhow::Context;
use bigdecimal::{BigDecimal, ToPrimitive};
use diesel::{ExpressionMethods, PgConnection, QueryDsl};

use near_indexer::near_primitives;

use crate::models;
use crate::schema;

/// Saves block to database
pub(crate) async fn store_block(
    pool: &actix_diesel::Database<PgConnection>,
    block: &near_primitives::views::BlockView,
) -> anyhow::Result<()> {
    let block_model = models::blocks::Block::from(block);

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::blocks::table)
            .values(block_model.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "Block was stored to database".to_string(),
        &block_model
    );
    Ok(())
}

/// Gets the latest block's height from database
pub(crate) async fn latest_block_height(
    pool: &actix_diesel::Database<PgConnection>,
) -> Result<Option<u64>, String> {
    tracing::debug!(target: crate::INDEXER_FOR_EXPLORER, "fetching latest");
    Ok(schema::blocks::table
        .select((schema::blocks::dsl::block_height,))
        .order(schema::blocks::dsl::block_height.desc())
        .limit(1)
        .get_optional_result_async::<(bigdecimal::BigDecimal,)>(pool)
        .await
        .map_err(|err| format!("DB Error: {}", err))?
        .and_then(|(block_height,)| block_height.to_u64()))
}

pub(crate) async fn get_latest_block_before_timestamp(
    pool: &actix_diesel::Database<PgConnection>,
    timestamp: u64,
) -> anyhow::Result<models::Block> {
    Ok(schema::blocks::table
        .filter(schema::blocks::dsl::block_timestamp.le(BigDecimal::from(timestamp)))
        .order(schema::blocks::dsl::block_timestamp.desc())
        .first_async::<models::Block>(pool)
        .await
        .context("DB Error")?)
}

'''
'''--- dockerfile/src/db_adapters/chunks.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use diesel::PgConnection;

use crate::models;
use crate::schema;

/// Saves chunks to database
pub(crate) async fn store_chunks(
    pool: &actix_diesel::Database<PgConnection>,
    shards: &[near_indexer::IndexerShard],
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
) -> anyhow::Result<()> {
    if shards.is_empty() {
        return Ok(());
    }
    let chunk_models: Vec<models::chunks::Chunk> = shards
        .iter()
        .filter_map(|shard| shard.chunk.as_ref())
        .map(|chunk| models::chunks::Chunk::from_chunk_view(chunk, block_hash))
        .collect();

    if chunk_models.is_empty() {
        return Ok(());
    }

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::chunks::table)
            .values(chunk_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "Chunks were stored to database".to_string(),
        &chunk_models
    );
    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/execution_outcomes.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use cached::Cached;
use diesel::PgConnection;
use futures::future::try_join_all;

use crate::models;
use crate::schema;

pub(crate) async fn store_execution_outcomes(
    pool: &actix_diesel::Database<PgConnection>,
    shards: &[near_indexer::IndexerShard],
    block_timestamp: u64,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let futures = shards.iter().map(|shard| {
        store_execution_outcomes_for_chunk(
            pool,
            &shard.receipt_execution_outcomes,
            shard.shard_id,
            block_timestamp,
            std::sync::Arc::clone(&receipts_cache),
        )
    });

    try_join_all(futures).await.map(|_| ())
}

/// Saves ExecutionOutcome to database and then saves ExecutionOutcomesReceipts
pub async fn store_execution_outcomes_for_chunk(
    pool: &actix_diesel::Database<PgConnection>,
    execution_outcomes: &[near_indexer::IndexerExecutionOutcomeWithReceipt],
    shard_id: near_indexer::near_primitives::types::ShardId,
    block_timestamp: u64,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let mut outcome_models: Vec<models::execution_outcomes::ExecutionOutcome> = vec![];
    let mut outcome_receipt_models: Vec<models::execution_outcomes::ExecutionOutcomeReceipt> =
        vec![];
    let mut receipts_cache_lock = receipts_cache.lock().await;
    for (index_in_chunk, outcome) in execution_outcomes.iter().enumerate() {
        // Trying to take the parent Transaction hash for the Receipt from ReceiptsCache
        // remove it from cache once found as it is not expected to observe the Receipt for
        // second time
        let parent_transaction_hash = receipts_cache_lock.cache_remove(
            &crate::ReceiptOrDataId::ReceiptId(outcome.execution_outcome.id),
        );

        let model = models::execution_outcomes::ExecutionOutcome::from_execution_outcome(
            &outcome.execution_outcome,
            index_in_chunk as i32,
            block_timestamp,
            shard_id,
        );
        outcome_models.push(model);

        outcome_receipt_models.extend(
            outcome
                .execution_outcome
                .outcome
                .receipt_ids
                .iter()
                .enumerate()
                .map(|(index, receipt_id)| {
                    // if we have `parent_transaction_hash` from cache, then we put all "produced" Receipt IDs
                    // as key and `parent_transaction_hash` as value, so the Receipts from one of the next blocks
                    // could find their parents in cache
                    if let Some(transaction_hash) = &parent_transaction_hash {
                        receipts_cache_lock.cache_set(
                            crate::ReceiptOrDataId::ReceiptId(*receipt_id),
                            transaction_hash.clone(),
                        );
                    }
                    models::execution_outcomes::ExecutionOutcomeReceipt {
                        executed_receipt_id: outcome.execution_outcome.id.to_string(),
                        index_in_execution_outcome: index as i32,
                        produced_receipt_id: receipt_id.to_string(),
                    }
                }),
        );
    }

    // releasing the lock
    drop(receipts_cache_lock);

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::execution_outcomes::table)
            .values(outcome_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ExecutionOutcomes were stored in database".to_string(),
        &outcome_models
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::execution_outcome_receipts::table)
            .values(outcome_receipt_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ExecutionOutcomeReceipts were stored in database".to_string(),
        &outcome_receipt_models
    );

    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/genesis.rs ---
use actix_diesel::Database;
use diesel::PgConnection;

use crate::db_adapters::access_keys::store_access_keys_from_genesis;
use crate::db_adapters::accounts::store_accounts_from_genesis;

/// This is an ugly hack that allows to execute an async body on a specified actix runtime.
/// You should only call it from a separate thread!
///
/// ```ignore
/// async fn some_async_function() {
///     let current_actix_system = actix::System::current();
///     tokio::tasks::spawn_blocking(move || {
///         let x = vec![0, 1, 2];
///         x.map(|i| {
///             block_on(current_actix_system, async move {
///                 reqwest::get(...).await.text().await
///             })
///         });
///     }
/// }
fn block_on<Fut, T>(
    actix_arbiter: &actix_rt::ArbiterHandle,
    f: Fut,
) -> Result<T, std::sync::mpsc::RecvError>
where
    T: Send + 'static,
    Fut: std::future::Future<Output = T> + Send + 'static,
{
    let (tx, rx) = std::sync::mpsc::channel();
    actix_arbiter.spawn(async move {
        let result = f.await;
        let _ = tx.send(result);
    });
    rx.recv()
}

/// Iterates over GenesisRecords and stores selected ones (Accounts, AccessKeys)
/// to database.
/// Separately stores records divided in portions by 5000 to optimize
/// memory usage and minimize database queries
pub(crate) async fn store_genesis_records(
    pool: Database<PgConnection>,
    near_config: near_indexer::NearConfig,
) -> anyhow::Result<()> {
    tracing::info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Storing genesis records to database...",
    );
    let genesis_height = near_config.genesis.config.genesis_height;

    // Remember the current actix runtime thread in order to be able to
    // schedule async function on it from the thread that processes genesis in
    // a blocking way.
    let actix_system = actix::System::current();
    // Spawn the blocking genesis processing on a separate thread
    tokio::task::spawn_blocking(move || {
        let actix_arbiter = actix_system.arbiter();

        let mut accounts_to_store: Vec<crate::models::accounts::Account> = vec![];
        let mut access_keys_to_store: Vec<crate::models::access_keys::AccessKey> = vec![];

        near_config.genesis.for_each_record(|record| {
            if accounts_to_store.len() == 5_000 {
                let mut accounts_to_store_chunk = vec![];
                std::mem::swap(&mut accounts_to_store, &mut accounts_to_store_chunk);
                let pool = pool.clone();
                block_on(
                    actix_arbiter,
                    store_accounts_from_genesis(pool, accounts_to_store_chunk),
                )
                .expect("storing accounts from genesis failed")
                .expect("storing accounts from genesis failed");
            }
            if access_keys_to_store.len() == 5_000 {
                let mut access_keys_to_store_chunk = vec![];
                std::mem::swap(&mut access_keys_to_store, &mut access_keys_to_store_chunk);
                let pool = pool.clone();
                block_on(
                    actix_arbiter,
                    store_access_keys_from_genesis(pool, access_keys_to_store_chunk),
                )
                .expect("storing access keys from genesis failed")
                .expect("storing access keys from genesis failed");
            }

            match record {
                near_indexer::near_primitives::state_record::StateRecord::Account {
                    account_id,
                    ..
                } => {
                    accounts_to_store.push(crate::models::accounts::Account::new_from_genesis(
                        account_id,
                        genesis_height,
                    ));
                }
                near_indexer::near_primitives::state_record::StateRecord::AccessKey {
                    account_id,
                    public_key,
                    access_key,
                } => {
                    access_keys_to_store.push(crate::models::access_keys::AccessKey::from_genesis(
                        public_key,
                        account_id,
                        access_key,
                        genesis_height,
                    ));
                }
                _ => {}
            };
        });

        let fut = || async move {
            store_accounts_from_genesis(pool.clone(), accounts_to_store).await?;
            store_access_keys_from_genesis(pool, access_keys_to_store).await?;
            anyhow::Result::<()>::Ok(())
        };
        block_on(actix_arbiter, fut())
            .expect("storing leftover accounts and access keys from genesis failed")
            .expect("storing leftover accounts and access keys from genesis failed");
    })
    .await?;

    tracing::info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Genesis records has been stored.",
    );
    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/mod.rs ---
pub(crate) mod access_keys;
pub(crate) mod account_changes;
pub(crate) mod accounts;
pub(crate) mod aggregated;
pub(crate) mod assets;
pub(crate) mod blocks;
pub(crate) mod chunks;
pub(crate) mod execution_outcomes;
pub(crate) mod genesis;
pub(crate) mod receipts;
pub(crate) mod transactions;

const CHUNK_SIZE_FOR_BATCH_INSERT: usize = 500;

'''
'''--- dockerfile/src/db_adapters/receipts.rs ---
use std::collections::HashMap;
use std::convert::TryFrom;
use std::str::FromStr;

use near_indexer::near_primitives;

use actix_diesel::dsl::AsyncRunQueryDsl;
use cached::Cached;
use diesel::pg::expression::array_comparison::any;
use diesel::{ExpressionMethods, JoinOnDsl, PgConnection, QueryDsl};
use futures::future::try_join_all;
use futures::try_join;
use num_traits::cast::FromPrimitive;
use tracing::{error, warn};

use crate::models;
use crate::schema;

/// Saves receipts to database
pub(crate) async fn store_receipts(
    pool: &actix_diesel::Database<PgConnection>,
    shards: &[near_indexer::IndexerShard],
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_timestamp: u64,
    strict_mode: bool,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let futures = shards
        .iter()
        .filter_map(|shard| shard.chunk.as_ref())
        .filter(|chunk| !chunk.receipts.is_empty())
        .map(|chunk| {
            store_chunk_receipts(
                pool,
                &chunk.receipts,
                block_hash,
                &chunk.header.chunk_hash,
                block_timestamp,
                strict_mode,
                receipts_cache.clone(),
            )
        });

    try_join_all(futures).await.map(|_| ())
}

async fn store_chunk_receipts(
    pool: &actix_diesel::Database<PgConnection>,
    receipts: &[near_indexer::near_primitives::views::ReceiptView],
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    chunk_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_timestamp: u64,
    strict_mode: bool,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let mut skipping_receipt_ids =
        std::collections::HashSet::<near_indexer::near_primitives::hash::CryptoHash>::new();

    let tx_hashes_for_receipts = find_tx_hashes_for_receipts(
        pool,
        receipts.to_vec(),
        strict_mode,
        block_hash,
        chunk_hash,
        std::sync::Arc::clone(&receipts_cache),
    )
    .await?;

    let receipt_models: Vec<models::receipts::Receipt> = receipts
        .iter()
        .enumerate()
        .filter_map(|(index, r)| {
            // We need to search for parent transaction hash in cache differently
            // depending on the Receipt kind
            // In case of Action Receipt we are looking for ReceiptId
            // In case of Data Receipt we are looking for DataId
            let receipt_or_data_id = match r.receipt {
                near_primitives::views::ReceiptEnumView::Action { .. } => {
                    crate::ReceiptOrDataId::ReceiptId(r.receipt_id)
                }
                near_primitives::views::ReceiptEnumView::Data { data_id, .. } => {
                    crate::ReceiptOrDataId::DataId(data_id)
                }
            };
            if let Some(transaction_hash) = tx_hashes_for_receipts.get(&receipt_or_data_id) {
                Some(models::Receipt::from_receipt_view(
                        r,
                        block_hash,
                        transaction_hash,
                        chunk_hash,
                        index as i32,
                        block_timestamp,
                    ))
            } else {
                warn!(
                    target: crate::INDEXER_FOR_EXPLORER,
                    "Skipping Receipt {} as we can't find parent Transaction for it. Happen in block hash {}, chunk hash {}",
                    r.receipt_id.to_string(),
                    block_hash,
                    chunk_hash,
                );
                skipping_receipt_ids.insert(r.receipt_id);
                None
            }
        })
        .collect();

    // At the moment we can observe output data in the Receipt it's impossible to know
    // the Receipt Id of that Data Receipt. That's why we insert the pair DataId<>ParentTransactionHash
    // to ReceiptsCache
    let mut receipts_cache_lock = receipts_cache.lock().await;
    for receipt in receipts {
        if let near_primitives::views::ReceiptEnumView::Action {
            output_data_receivers,
            ..
        } = &receipt.receipt
        {
            if !output_data_receivers.is_empty() {
                if let Some(transaction_hash) = tx_hashes_for_receipts
                    .get(&crate::ReceiptOrDataId::ReceiptId(receipt.receipt_id))
                {
                    for data_receiver in output_data_receivers {
                        receipts_cache_lock.cache_set(
                            crate::ReceiptOrDataId::DataId(data_receiver.data_id),
                            transaction_hash.clone(),
                        );
                    }
                }
            }
        }
    }
    // releasing the lock
    drop(receipts_cache_lock);

    save_receipts(pool, receipt_models).await?;

    let (action_receipts, data_receipts): (
        Vec<&near_indexer::near_primitives::views::ReceiptView>,
        Vec<&near_indexer::near_primitives::views::ReceiptView>,
    ) = receipts
        .iter()
        .filter(|r| !skipping_receipt_ids.contains(&r.receipt_id))
        .partition(|receipt| {
            matches!(
                receipt.receipt,
                near_indexer::near_primitives::views::ReceiptEnumView::Action { .. }
            )
        });

    let process_receipt_actions_future =
        store_receipt_actions(pool, action_receipts, block_timestamp);

    let process_receipt_data_future = store_receipt_data(pool, data_receipts);

    try_join!(process_receipt_actions_future, process_receipt_data_future)?;
    Ok(())
}

/// Looks for already created parent transaction hash for given receipts
async fn find_tx_hashes_for_receipts(
    pool: &actix_diesel::Database<PgConnection>,
    mut receipts: Vec<near_indexer::near_primitives::views::ReceiptView>,
    strict_mode: bool,
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    chunk_hash: &near_indexer::near_primitives::hash::CryptoHash,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<HashMap<crate::ReceiptOrDataId, crate::ParentTransactionHashString>> {
    let mut tx_hashes_for_receipts: HashMap<
        crate::ReceiptOrDataId,
        crate::ParentTransactionHashString,
    > = HashMap::new();

    let mut receipts_cache_lock = receipts_cache.lock().await;
    // add receipt-transaction pairs from the cache to the response
    tx_hashes_for_receipts.extend(receipts.iter().filter_map(|receipt| {
        match receipt.receipt {
            near_primitives::views::ReceiptEnumView::Action { .. } => receipts_cache_lock
                .cache_get(&crate::ReceiptOrDataId::ReceiptId(receipt.receipt_id))
                .map(|parent_transaction_hash| {
                    (
                        crate::ReceiptOrDataId::ReceiptId(receipt.receipt_id),
                        parent_transaction_hash.clone(),
                    )
                }),
            near_primitives::views::ReceiptEnumView::Data { data_id, .. } => {
                // Pair DataId:ParentTransactionHash won't be used after this moment
                // We want to clean it up to prevent our cache from growing
                receipts_cache_lock
                    .cache_remove(&crate::ReceiptOrDataId::DataId(data_id))
                    .map(|parent_transaction_hash| {
                        (
                            crate::ReceiptOrDataId::DataId(data_id),
                            parent_transaction_hash,
                        )
                    })
            }
        }
    }));
    // releasing the lock
    drop(receipts_cache_lock);

    // discard the Receipts already in cache from the attempts to search
    receipts.retain(|r| match r.receipt {
        near_primitives::views::ReceiptEnumView::Data { data_id, .. } => {
            !tx_hashes_for_receipts.contains_key(&crate::ReceiptOrDataId::DataId(data_id))
        }
        near_primitives::views::ReceiptEnumView::Action { .. } => {
            !tx_hashes_for_receipts.contains_key(&crate::ReceiptOrDataId::ReceiptId(r.receipt_id))
        }
    });
    if receipts.is_empty() {
        return Ok(tx_hashes_for_receipts);
    }

    warn!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Looking for parent transaction hash in database for {} receipts {:#?}",
        &receipts.len(),
        &receipts,
    );

    let mut retries_left: u8 = 4; // retry at least times even in no-strict mode to avoid data loss
    let mut find_tx_retry_interval = crate::INTERVAL;
    loop {
        let data_ids: Vec<String> = receipts
            .iter()
            .filter_map(|r| match r.receipt {
                near_indexer::near_primitives::views::ReceiptEnumView::Data { data_id, .. } => {
                    Some(data_id.to_string())
                }
                _ => None,
            })
            .collect();
        if !data_ids.is_empty() {
            let mut interval = crate::INTERVAL;
            let tx_hashes_for_data_id_via_data_output: Vec<(
                crate::ReceiptOrDataId,
                crate::ParentTransactionHashString,
            )> = loop {
                match schema::action_receipt_output_data::table
                    .inner_join(
                        schema::receipts::table.on(
                            schema::action_receipt_output_data::dsl::output_from_receipt_id
                                .eq(schema::receipts::dsl::receipt_id),
                        ),
                    )
                    .filter(
                        schema::action_receipt_output_data::dsl::output_data_id
                            .eq(any(data_ids.clone())),
                    )
                    .select((
                        schema::action_receipt_output_data::dsl::output_data_id,
                        schema::receipts::dsl::originated_from_transaction_hash,
                    ))
                    .load_async(pool)
                    .await
                {
                    Ok(res) => {
                        break res
                            .into_iter()
                            .map(
                                |(receipt_id_string, transaction_hash_string): (String, String)| {
                                    (
                                        crate::ReceiptOrDataId::DataId(
                                            near_primitives::hash::CryptoHash::from_str(
                                                &receipt_id_string,
                                            )
                                            .expect("Failed to convert String to CryptoHash"),
                                        ),
                                        transaction_hash_string,
                                    )
                                },
                            )
                            .collect();
                    }
                    Err(async_error) => {
                        error!(
                            target: crate::INDEXER_FOR_EXPLORER,
                            "Error occurred while fetching the parent receipt for Receipt. Retrying in {} milliseconds... \n {:#?}",
                            interval.as_millis(),
                            async_error,
                        );
                        tokio::time::sleep(interval).await;
                        if interval < crate::MAX_DELAY_TIME {
                            interval *= 2;
                        }
                    }
                }
            };

            let mut tx_hashes_for_data_id_via_data_output_hashmap =
                HashMap::<crate::ReceiptOrDataId, crate::ParentTransactionHashString>::new();
            tx_hashes_for_data_id_via_data_output_hashmap
                .extend(tx_hashes_for_data_id_via_data_output);
            let tx_hashes_for_receipts_via_data_output: Vec<(
                crate::ReceiptOrDataId,
                crate::ParentTransactionHashString,
            )> = receipts
                .iter()
                .filter_map(|r| match r.receipt {
                    near_indexer::near_primitives::views::ReceiptEnumView::Data {
                        data_id, ..
                    } => tx_hashes_for_data_id_via_data_output_hashmap
                        .get(&crate::ReceiptOrDataId::DataId(data_id))
                        .map(|tx_hash| {
                            (
                                crate::ReceiptOrDataId::ReceiptId(r.receipt_id),
                                tx_hash.to_string(),
                            )
                        }),
                    _ => None,
                })
                .collect();

            let found_hashes_len = tx_hashes_for_receipts_via_data_output.len();
            tx_hashes_for_receipts.extend(tx_hashes_for_receipts_via_data_output);

            if found_hashes_len == receipts.len() {
                break;
            }

            receipts.retain(|r| {
                !tx_hashes_for_receipts
                    .contains_key(&crate::ReceiptOrDataId::ReceiptId(r.receipt_id))
            });
        }

        let tx_hashes_for_receipts_via_outcomes: Vec<(String, crate::ParentTransactionHashString)> =
            crate::await_retry_or_panic!(
                schema::execution_outcome_receipts::table
                    .inner_join(
                        schema::receipts::table
                            .on(schema::execution_outcome_receipts::dsl::executed_receipt_id
                                .eq(schema::receipts::dsl::receipt_id)),
                    )
                    .filter(
                        schema::execution_outcome_receipts::dsl::produced_receipt_id.eq(any(
                            receipts
                                .clone()
                                .iter()
                                .filter(|r| {
                                    matches!(
                                r.receipt,
                                near_indexer::near_primitives::views::ReceiptEnumView::Action { .. }
                            )
                                })
                                .map(|r| r.receipt_id.to_string())
                                .collect::<Vec<String>>()
                        )),
                    )
                    .select((
                        schema::execution_outcome_receipts::dsl::produced_receipt_id,
                        schema::receipts::dsl::originated_from_transaction_hash,
                    ))
                    .load_async::<(String, crate::ParentTransactionHashString)>(pool),
                10,
                "Parent Transaction for Receipts were fetched".to_string(),
                &receipts
            )
            .unwrap_or_default();

        let found_hashes_len = tx_hashes_for_receipts_via_outcomes.len();
        tx_hashes_for_receipts.extend(tx_hashes_for_receipts_via_outcomes.into_iter().map(
            |(receipt_id_string, transaction_hash_string)| {
                (
                    crate::ReceiptOrDataId::ReceiptId(
                        near_primitives::hash::CryptoHash::from_str(&receipt_id_string)
                            .expect("Failed to convert String to CryptoHash"),
                    ),
                    transaction_hash_string,
                )
            },
        ));

        if found_hashes_len == receipts.len() {
            break;
        }

        receipts.retain(|r| {
            !tx_hashes_for_receipts.contains_key(&crate::ReceiptOrDataId::ReceiptId(r.receipt_id))
        });

        let tx_hashes_for_receipt_via_transactions: Vec<(
            String,
            crate::ParentTransactionHashString,
        )> = crate::await_retry_or_panic!(
            schema::transactions::table
                .filter(
                    schema::transactions::dsl::converted_into_receipt_id.eq(any(receipts
                        .clone()
                        .iter()
                        .filter(|r| {
                            matches!(
                                r.receipt,
                                near_indexer::near_primitives::views::ReceiptEnumView::Action { .. }
                            )
                        })
                        .map(|r| r.receipt_id.to_string())
                        .collect::<Vec<String>>())),
                )
                .select((
                    schema::transactions::dsl::converted_into_receipt_id,
                    schema::transactions::dsl::transaction_hash,
                ))
                .load_async::<(String, crate::ParentTransactionHashString)>(pool),
            10,
            "Parent Transaction for ExecutionOutcome were fetched".to_string(),
            &receipts
        )
        .unwrap_or_default();

        let found_hashes_len = tx_hashes_for_receipt_via_transactions.len();
        tx_hashes_for_receipts.extend(tx_hashes_for_receipt_via_transactions.into_iter().map(
            |(receipt_id_string, transaction_hash_string)| {
                (
                    crate::ReceiptOrDataId::ReceiptId(
                        near_primitives::hash::CryptoHash::from_str(&receipt_id_string)
                            .expect("Failed to convert String to CryptoHash"),
                    ),
                    transaction_hash_string,
                )
            },
        ));

        if found_hashes_len == receipts.len() {
            break;
        }

        receipts.retain(|r| {
            !tx_hashes_for_receipts.contains_key(&crate::ReceiptOrDataId::ReceiptId(r.receipt_id))
        });

        if !strict_mode {
            if retries_left > 0 {
                retries_left -= 1;
            } else {
                break;
            }
        }
        warn!(
            target: crate::INDEXER_FOR_EXPLORER,
            "Going to retry to find parent transactions for receipts in {} milliseconds... \n {:#?}\n block hash {} \nchunk hash {}",
            find_tx_retry_interval.as_millis(),
            &receipts,
            block_hash,
            chunk_hash
        );
        tokio::time::sleep(find_tx_retry_interval).await;
        if find_tx_retry_interval < crate::MAX_DELAY_TIME {
            find_tx_retry_interval *= 2;
        }
    }

    Ok(tx_hashes_for_receipts)
}

async fn save_receipts(
    pool: &actix_diesel::Database<PgConnection>,
    receipts: Vec<models::Receipt>,
) -> anyhow::Result<()> {
    crate::await_retry_or_panic!(
        diesel::insert_into(schema::receipts::table)
            .values(receipts.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "Receipts were stored in database".to_string(),
        &receipts
    );
    Ok(())
}

async fn store_receipt_actions(
    pool: &actix_diesel::Database<PgConnection>,
    receipts: Vec<&near_indexer::near_primitives::views::ReceiptView>,
    block_timestamp: u64,
) -> anyhow::Result<()> {
    let receipt_actions: Vec<models::ActionReceipt> = receipts
        .iter()
        .filter_map(|receipt| models::ActionReceipt::try_from(*receipt).ok())
        .collect();

    let receipt_action_actions: Vec<models::ActionReceiptAction> = receipts
        .iter()
        .filter_map(|receipt| {
            if let near_indexer::near_primitives::views::ReceiptEnumView::Action {
                actions, ..
            } = &receipt.receipt
            {
                Some(actions.iter().enumerate().map(move |(index, action)| {
                    models::ActionReceiptAction::from_action_view(
                        receipt.receipt_id.to_string(),
                        i32::from_usize(index).expect("We expect usize to not overflow i32 here"),
                        action,
                        receipt.predecessor_id.to_string(),
                        receipt.receiver_id.to_string(),
                        block_timestamp,
                    )
                }))
            } else {
                None
            }
        })
        .flatten()
        .collect();

    let receipt_action_input_data: Vec<models::ActionReceiptInputData> = receipts
        .iter()
        .filter_map(|receipt| {
            if let near_indexer::near_primitives::views::ReceiptEnumView::Action {
                input_data_ids,
                ..
            } = &receipt.receipt
            {
                Some(input_data_ids.iter().map(move |data_id| {
                    models::ActionReceiptInputData::from_data_id(
                        receipt.receipt_id.to_string(),
                        data_id.to_string(),
                    )
                }))
            } else {
                None
            }
        })
        .flatten()
        .collect();

    let receipt_action_output_data: Vec<models::ActionReceiptOutputData> = receipts
        .iter()
        .filter_map(|receipt| {
            if let near_indexer::near_primitives::views::ReceiptEnumView::Action {
                output_data_receivers,
                ..
            } = &receipt.receipt
            {
                Some(output_data_receivers.iter().map(move |receiver| {
                    models::ActionReceiptOutputData::from_data_receiver(
                        receipt.receipt_id.to_string(),
                        receiver,
                    )
                }))
            } else {
                None
            }
        })
        .flatten()
        .collect();

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::action_receipts::table)
            .values(receipt_actions.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ReceiptActions were stored in database".to_string(),
        &receipt_actions
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::action_receipt_actions::table)
            .values(receipt_action_actions.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ReceiptActionActions were stored in database".to_string(),
        &receipt_action_actions
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::action_receipt_output_data::table)
            .values(receipt_action_output_data.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ReceiptActionOutputData were stored in database".to_string(),
        &receipt_action_output_data
    );

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::action_receipt_input_data::table)
            .values(receipt_action_input_data.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ReceiptActionInputData were stored in database".to_string(),
        &receipt_action_input_data
    );

    Ok(())
}

async fn store_receipt_data(
    pool: &actix_diesel::Database<PgConnection>,
    receipts: Vec<&near_indexer::near_primitives::views::ReceiptView>,
) -> anyhow::Result<()> {
    let receipt_data_models: Vec<models::DataReceipt> = receipts
        .iter()
        .filter_map(|receipt| models::DataReceipt::try_from(*receipt).ok())
        .collect();

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::data_receipts::table)
            .values(receipt_data_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "ReceiptData were stored in database".to_string(),
        &receipt_data_models
    );

    Ok(())
}

'''
'''--- dockerfile/src/db_adapters/transactions.rs ---
use actix_diesel::dsl::AsyncRunQueryDsl;
use anyhow::Context;
use cached::Cached;
use diesel::{ExpressionMethods, PgConnection, QueryDsl};
use futures::future::try_join_all;

use near_indexer::near_primitives;

use crate::models;
use crate::schema;

/// Saves Transactions to database
pub(crate) async fn store_transactions(
    pool: &actix_diesel::Database<PgConnection>,
    shards: &[near_indexer::IndexerShard],
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_timestamp: u64,
    block_height: near_primitives::types::BlockHeight,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let mut tried_to_insert_transactions_count = 0;
    let tx_futures = shards
        .iter()
        .filter_map(|shard| shard.chunk.as_ref())
        .map(|chunk| {
            tried_to_insert_transactions_count += chunk.transactions.len();
            store_chunk_transactions(
                pool,
                chunk
                    .transactions
                    .iter()
                    .enumerate()
                    .collect::<Vec<(usize, &near_indexer::IndexerTransactionWithOutcome)>>(),
                &chunk.header.chunk_hash,
                block_hash,
                block_timestamp,
                "",
                receipts_cache.clone(),
            )
        });

    try_join_all(tx_futures).await?;

    let inserted_receipt_ids = collect_converted_to_receipt_ids(pool, block_hash).await?;
    // If the number is the same, I see no chance if there's something wrong, so we can return here
    if inserted_receipt_ids.len() == tried_to_insert_transactions_count {
        return Ok(());
    }

    // https://github.com/near/near-indexer-for-explorer/issues/84
    // TLDR: it's the hack to store transactions with collided hashes
    // It should not happen, but unfortunately it did,
    // we have ~10 such transactions in Mainnet for now
    let transaction_hash_suffix = "_issue84_".to_owned() + &block_height.to_string();

    let collided_tx_futures = shards
        .iter()
        .filter_map(|shard| shard.chunk.as_ref())
        .map(|chunk| {
            store_chunk_transactions(
                pool,
                chunk
                    .transactions
                    .iter()
                    .enumerate()
                    .filter(|(_, transaction)| {
                        let converted_into_receipt_id = &transaction
                            .outcome
                            .execution_outcome
                            .outcome
                            .receipt_ids
                            .first()
                            .expect("`receipt_ids` must contain one Receipt Id")
                            .to_string();
                        !inserted_receipt_ids.contains(converted_into_receipt_id)
                    })
                    .collect::<Vec<(usize, &near_indexer::IndexerTransactionWithOutcome)>>(),
                &chunk.header.chunk_hash,
                block_hash,
                block_timestamp,
                &transaction_hash_suffix,
                receipts_cache.clone(),
            )
        });

    try_join_all(collided_tx_futures).await.map(|_| ())
}

async fn collect_converted_to_receipt_ids(
    pool: &actix_diesel::Database<PgConnection>,
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
) -> anyhow::Result<Vec<String>> {
    Ok(schema::transactions::table
        .select(schema::transactions::dsl::converted_into_receipt_id)
        .filter(schema::transactions::dsl::included_in_block_hash.eq(block_hash.to_string()))
        .get_results_async::<String>(pool)
        .await
        .context("DB Error")?)
}

async fn store_chunk_transactions(
    pool: &actix_diesel::Database<PgConnection>,
    transactions: Vec<(usize, &near_indexer::IndexerTransactionWithOutcome)>,
    chunk_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    block_timestamp: u64,
    // hack for supporting duplicated transaction hashes. Empty for most of transactions
    transaction_hash_suffix: &str,
    receipts_cache: crate::ReceiptsCache,
) -> anyhow::Result<()> {
    let mut receipts_cache_lock = receipts_cache.lock().await;

    let transaction_models: Vec<models::transactions::Transaction> = transactions
        .iter()
        .map(|(index, tx)| {
            let transaction_hash = tx.transaction.hash.to_string() + transaction_hash_suffix;
            let converted_into_receipt_id = tx
                .outcome
                .execution_outcome
                .outcome
                .receipt_ids
                .first()
                .expect("`receipt_ids` must contain one Receipt Id");

            // Save this Transaction hash to ReceiptsCache
            // we use the Receipt ID to which this transaction was converted
            // and the Transaction hash as a value.
            // Later, while Receipt will be looking for a parent Transaction hash
            // it will be able to find it in the ReceiptsCache
            receipts_cache_lock.cache_set(
                crate::ReceiptOrDataId::ReceiptId(*converted_into_receipt_id),
                transaction_hash.clone(),
            );

            models::transactions::Transaction::from_indexer_transaction(
                tx,
                &transaction_hash,
                &converted_into_receipt_id.to_string(),
                block_hash,
                chunk_hash,
                block_timestamp,
                *index as i32,
            )
        })
        .collect();

    // releasing the lock
    drop(receipts_cache_lock);

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::transactions::table)
            .values(transaction_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "Transactions were stored in database".to_string(),
        &transaction_models
    );

    let transaction_action_models: Vec<models::TransactionAction> = transactions
        .into_iter()
        .flat_map(|(_, tx)| {
            tx.transaction
                .actions
                .iter()
                .enumerate()
                .map(move |(index, action)| {
                    models::transactions::TransactionAction::from_action_view(
                        tx.transaction.hash.to_string(),
                        index as i32,
                        action,
                    )
                })
        })
        .collect();

    crate::await_retry_or_panic!(
        diesel::insert_into(schema::transaction_actions::table)
            .values(transaction_action_models.clone())
            .on_conflict_do_nothing()
            .execute_async(pool),
        10,
        "TransactionActions were stored in database".to_string(),
        &transaction_action_models
    );

    Ok(())
}

'''
'''--- dockerfile/src/main.rs ---
use clap::Parser;
use std::convert::TryFrom;
#[macro_use]
extern crate diesel;

use actix_diesel::Database;
pub use cached::SizedCache;
use diesel::PgConnection;
use futures::future::try_join_all;
use futures::{try_join, StreamExt};
use tokio::sync::{mpsc, Mutex};
use tracing::{debug, info, warn};
use tracing_subscriber::EnvFilter;

use crate::configs::{Opts, SubCommand};

mod aggregated;
mod configs;
mod db_adapters;
mod models;
mod schema;
#[macro_use]
mod retriable;

// Categories for logging
const INDEXER_FOR_EXPLORER: &str = "indexer_for_explorer";
const AGGREGATED: &str = "aggregated";

const INTERVAL: std::time::Duration = std::time::Duration::from_millis(100);
const MAX_DELAY_TIME: std::time::Duration = std::time::Duration::from_secs(120);

#[derive(Clone, Hash, PartialEq, Eq, Debug)]
pub enum ReceiptOrDataId {
    ReceiptId(near_indexer::near_primitives::hash::CryptoHash),
    DataId(near_indexer::near_primitives::hash::CryptoHash),
}
// Creating type aliases to make HashMap types for cache more explicit
pub type ParentTransactionHashString = String;
// Introducing a simple cache for Receipts to find their parent Transactions without
// touching the database
// The key is ReceiptID
// The value is TransactionHash (the very parent of the Receipt)
pub type ReceiptsCache =
    std::sync::Arc<Mutex<SizedCache<ReceiptOrDataId, ParentTransactionHashString>>>;

async fn handle_message(
    pool: &actix_diesel::Database<PgConnection>,
    streamer_message: near_indexer::StreamerMessage,
    strict_mode: bool,
    receipts_cache: ReceiptsCache,
) -> anyhow::Result<()> {
    debug!(
        target: INDEXER_FOR_EXPLORER,
        "ReceiptsCache #{} \n {:#?}", streamer_message.block.header.height, &receipts_cache
    );
    db_adapters::blocks::store_block(pool, &streamer_message.block).await?;

    // Chunks
    db_adapters::chunks::store_chunks(
        pool,
        &streamer_message.shards,
        &streamer_message.block.header.hash,
    )
    .await?;

    // Transactions
    let transactions_future = db_adapters::transactions::store_transactions(
        pool,
        &streamer_message.shards,
        &streamer_message.block.header.hash,
        streamer_message.block.header.timestamp,
        streamer_message.block.header.height,
        std::sync::Arc::clone(&receipts_cache),
    );

    // Receipts
    let receipts_future = db_adapters::receipts::store_receipts(
        pool,
        &streamer_message.shards,
        &streamer_message.block.header.hash,
        streamer_message.block.header.timestamp,
        strict_mode,
        std::sync::Arc::clone(&receipts_cache),
    );

    // We can process transactions and receipts in parallel
    // because most of receipts depend on transactions from previous blocks,
    // so we can save up some time here.
    // In case of local receipts (they are stored in the same block with corresponding transaction),
    // we hope retry logic will cover it fine
    try_join!(transactions_future, receipts_future)?;

    // ExecutionOutcomes
    let execution_outcomes_future = db_adapters::execution_outcomes::store_execution_outcomes(
        pool,
        &streamer_message.shards,
        streamer_message.block.header.timestamp,
        std::sync::Arc::clone(&receipts_cache),
    );

    // Accounts
    let accounts_future = async {
        let futures = streamer_message.shards.iter().map(|shard| {
            db_adapters::accounts::handle_accounts(
                pool,
                &shard.receipt_execution_outcomes,
                streamer_message.block.header.height,
            )
        });

        try_join_all(futures).await.map(|_| ())
    };

    // Event-based entities (FT, NFT)
    let assets_events_future = db_adapters::assets::events::store_events(pool, &streamer_message);

    if strict_mode {
        // AccessKeys
        let access_keys_future = async {
            let futures = streamer_message.shards.iter().map(|shard| {
                db_adapters::access_keys::handle_access_keys(
                    pool,
                    &shard.receipt_execution_outcomes,
                    streamer_message.block.header.height,
                )
            });

            try_join_all(futures).await.map(|_| ())
        };

        // StateChange related to Account
        let account_changes_future = db_adapters::account_changes::store_account_changes(
            pool,
            &streamer_message.state_changes,
            &streamer_message.block.header.hash,
            streamer_message.block.header.timestamp,
        );

        try_join!(
            execution_outcomes_future,
            accounts_future,
            access_keys_future,
            assets_events_future,
            account_changes_future,
        )?;
    } else {
        try_join!(
            execution_outcomes_future,
            accounts_future,
            assets_events_future
        )?;
    }
    Ok(())
}

async fn listen_blocks(
    stream: mpsc::Receiver<near_indexer::StreamerMessage>,
    pool: Database<PgConnection>,
    concurrency: std::num::NonZeroU16,
    strict_mode: bool,
    stop_after_number_of_blocks: Option<std::num::NonZeroUsize>,
) {
    if let Some(stop_after_n_blocks) = stop_after_number_of_blocks {
        warn!(
            target: crate::INDEXER_FOR_EXPLORER,
            "Indexer will stop after indexing {} blocks", stop_after_n_blocks,
        );
    }
    if !strict_mode {
        warn!(
            target: crate::INDEXER_FOR_EXPLORER,
            "Indexer is starting in NON-STRICT mode",
        );
    }
    info!(target: crate::INDEXER_FOR_EXPLORER, "Stream has started");

    // We want to prevent unnecessary SELECT queries to the database to find
    // the Transaction hash for the Receipt.
    // Later we need to find the Receipt which is a parent to underlying Receipts.
    // Receipt ID will of the child will be stored as key and parent Transaction hash/Receipt ID
    // will be stored as a value
    let receipts_cache: ReceiptsCache =
        std::sync::Arc::new(Mutex::new(SizedCache::with_size(100_000)));

    let handle_messages =
        tokio_stream::wrappers::ReceiverStream::new(stream).map(|streamer_message| {
            info!(
                target: crate::INDEXER_FOR_EXPLORER,
                "Block height {}", &streamer_message.block.header.height
            );
            handle_message(
                &pool,
                streamer_message,
                strict_mode,
                std::sync::Arc::clone(&receipts_cache),
            )
        });
    let mut handle_messages = if let Some(stop_after_n_blocks) = stop_after_number_of_blocks {
        handle_messages
            .take(stop_after_n_blocks.get())
            .boxed_local()
    } else {
        handle_messages.boxed_local()
    }
    .buffer_unordered(usize::from(concurrency.get()));

    while let Some(_handled_message) = handle_messages.next().await {}
    // Graceful shutdown
    info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "Indexer will be shutdown gracefully in 7 seconds...",
    );
    drop(handle_messages);
    tokio::time::sleep(std::time::Duration::from_secs(7)).await;
}

/// Takes `home_dir` and `RunArgs` to build proper IndexerConfig and returns it
async fn construct_near_indexer_config(
    pool: &Database<PgConnection>,
    home_dir: std::path::PathBuf,
    args: configs::RunArgs,
) -> near_indexer::IndexerConfig {
    // Extract await mode to avoid duplication
    info!(
        target: crate::INDEXER_FOR_EXPLORER,
        "construct_near_indexer_config"
    );
    let sync_mode: near_indexer::SyncModeEnum = match args.sync_mode {
        configs::SyncModeSubCommand::SyncFromInterruption(interruption_args)
            if interruption_args.delta == 1 =>
        {
            info!(target: crate::INDEXER_FOR_EXPLORER, "got from interruption");
            // If delta is 0 we just return IndexerConfig with sync_mode FromInterruption
            // without any changes
            near_indexer::SyncModeEnum::FromInterruption
        }
        configs::SyncModeSubCommand::SyncFromInterruption(interruption_args) => {
            info!(target: crate::INDEXER_FOR_EXPLORER, "got from interruption");
            info!(
                target: crate::INDEXER_FOR_EXPLORER,
                "delta is non zero, calculating..."
            );

            db_adapters::blocks::latest_block_height(pool)
                .await
                .ok()
                .map(|latest_block_height| {
                    if let Some(height) = latest_block_height {
                        near_indexer::SyncModeEnum::BlockHeight(
                            height.saturating_sub(interruption_args.delta),
                        )
                    } else {
                        near_indexer::SyncModeEnum::FromInterruption
                    }
                })
                .unwrap_or_else(|| near_indexer::SyncModeEnum::FromInterruption)
        }
        configs::SyncModeSubCommand::SyncFromBlock(block_args) => {
            near_indexer::SyncModeEnum::BlockHeight(block_args.height)
        }
        configs::SyncModeSubCommand::SyncFromLatest => near_indexer::SyncModeEnum::LatestSynced,
    };

    near_indexer::IndexerConfig {
        home_dir,
        sync_mode,
        await_for_node_synced: if args.stream_while_syncing {
            near_indexer::AwaitForNodeSyncedEnum::StreamWhileSyncing
        } else {
            near_indexer::AwaitForNodeSyncedEnum::WaitForFullSync
        },
    }
}

fn main() {
    // We use it to automatically search the for root certificates to perform HTTPS calls
    // (sending telemetry and downloading genesis)
    openssl_probe::init_ssl_cert_env_vars();

    // We establish connection as early as possible as an additional sanity check.
    // Indexer should fail if .env file with credentials is missing/wrong
    let pool = models::establish_connection();

    let opts: Opts = Opts::parse();

    let mut env_filter = EnvFilter::new(
        "tokio_reactor=info,near=info,stats=info,telemetry=info,indexer=info,aggregated=info",
    );

    if opts.debug {
        env_filter = env_filter.add_directive(
            "indexer_for_explorer=debug"
                .parse()
                .expect("Failed to parse directive"),
        );
    } else {
        env_filter = env_filter.add_directive(
            "indexer_for_explorer=info"
                .parse()
                .expect("Failed to parse directive"),
        );
    };

    if let Ok(rust_log) = std::env::var("RUST_LOG") {
        if !rust_log.is_empty() {
            for directive in rust_log.split(',').filter_map(|s| match s.parse() {
                Ok(directive) => Some(directive),
                Err(err) => {
                    eprintln!("Ignoring directive `{}`: {}", s, err);
                    None
                }
            }) {
                env_filter = env_filter.add_directive(directive);
            }
        }
    }

    tracing_subscriber::fmt::Subscriber::builder()
        .with_env_filter(env_filter)
        .with_writer(std::io::stderr)
        .init();

    let home_dir = opts.home_dir.unwrap_or_else(near_indexer::get_default_home);

    match opts.subcmd {
        SubCommand::Run(args) => {
            tracing::info!(
                target: crate::INDEXER_FOR_EXPLORER,
                "NEAR Indexer for Explorer v{} starting...",
                env!("CARGO_PKG_VERSION")
            );

            let system = actix::System::new();
            system.block_on(async move {
                let indexer_config =
                    construct_near_indexer_config(&pool, home_dir, args.clone()).await;
                let indexer =
                    near_indexer::Indexer::new(indexer_config).expect("Failed to initiate Indexer");
                if args.store_genesis {
                    let near_config = indexer.near_config().clone();
                    db_adapters::genesis::store_genesis_records(pool.clone(), near_config.clone())
                        .await
                        .expect("Failed to store the records from the genesis");
                }

                // Regular indexer process starts here
                let stream = indexer.streamer();

                // Spawning the computation of aggregated data
                aggregated::spawn_aggregated_computations(pool.clone(), &indexer);

                listen_blocks(
                    stream,
                    pool,
                    args.concurrency,
                    !args.non_strict_mode,
                    args.stop_after_number_of_blocks,
                )
                .await;

                actix::System::current().stop();
            });
            system.run().unwrap();
        }
        SubCommand::Init(config) => near_indexer::init_configs(
            &home_dir,
            config.chain_id.as_ref().map(AsRef::as_ref),
            config.account_id.map(|account_id_string| {
                near_indexer::near_primitives::types::AccountId::try_from(account_id_string)
                    .expect("Received accound_id is not valid")
            }),
            config.test_seed.as_ref().map(AsRef::as_ref),
            config.num_shards,
            config.fast,
            config.genesis.as_ref().map(AsRef::as_ref),
            config.download_genesis,
            config.download_genesis_url.as_ref().map(AsRef::as_ref),
            config.download_config,
            config.download_config_url.as_ref().map(AsRef::as_ref),
            config.boot_nodes.as_ref().map(AsRef::as_ref),
            config.max_gas_burnt_view,
        )
        .expect("Failed to initiate config"),
    }
}

'''
'''--- dockerfile/src/models/access_keys.rs ---
use bigdecimal::BigDecimal;

use crate::models::enums::AccessKeyPermission;
use crate::schema;
use schema::access_keys;

#[derive(Insertable, Clone, Debug)]
pub struct AccessKey {
    pub public_key: String,
    pub account_id: String,
    pub created_by_receipt_id: Option<String>,
    pub deleted_by_receipt_id: Option<String>,
    pub permission_kind: AccessKeyPermission,
    pub last_update_block_height: BigDecimal,
}

impl AccessKey {
    pub fn from_action_view(
        public_key: &near_crypto::PublicKey,
        account_id: &near_indexer::near_primitives::types::AccountId,
        access_key: &near_indexer::near_primitives::views::AccessKeyView,
        create_by_receipt_id: &near_indexer::near_primitives::hash::CryptoHash,
        last_update_block_height: near_indexer::near_primitives::types::BlockHeight,
    ) -> Self {
        Self {
            public_key: public_key.to_string(),
            account_id: account_id.to_string(),
            created_by_receipt_id: Some(create_by_receipt_id.to_string()),
            deleted_by_receipt_id: None,
            permission_kind: (&access_key.permission).into(),
            last_update_block_height: last_update_block_height.into(),
        }
    }

    pub fn from_genesis(
        public_key: &near_crypto::PublicKey,
        account_id: &near_indexer::near_primitives::types::AccountId,
        access_key: &near_indexer::near_primitives::account::AccessKey,
        last_update_block_height: near_indexer::near_primitives::types::BlockHeight,
    ) -> Self {
        Self {
            public_key: public_key.to_string(),
            account_id: account_id.to_string(),
            created_by_receipt_id: None,
            deleted_by_receipt_id: None,
            permission_kind: (&access_key.permission).into(),
            last_update_block_height: last_update_block_height.into(),
        }
    }
}

'''
'''--- dockerfile/src/models/account_changes.rs ---
use std::str::FromStr;

use bigdecimal::BigDecimal;

use crate::models::enums::StateChangeReasonKind;
use crate::schema;
use schema::account_changes;

#[derive(Insertable, Clone, Debug)]
pub struct AccountChange {
    pub affected_account_id: String,
    pub changed_in_block_timestamp: BigDecimal,
    pub changed_in_block_hash: String,
    pub caused_by_transaction_hash: Option<String>,
    pub caused_by_receipt_id: Option<String>,
    pub update_reason: StateChangeReasonKind,
    pub affected_account_nonstaked_balance: BigDecimal,
    pub affected_account_staked_balance: BigDecimal,
    pub affected_account_storage_usage: BigDecimal,
    pub index_in_block: i32,
}

impl AccountChange {
    pub fn from_state_change_with_cause(
        state_change_with_cause: &near_indexer::near_primitives::views::StateChangeWithCauseView,
        changed_in_block_hash: &near_indexer::near_primitives::hash::CryptoHash,
        changed_in_block_timestamp: u64,
        index_in_block: i32,
    ) -> Option<Self> {
        let near_indexer::near_primitives::views::StateChangeWithCauseView { cause, value } =
            state_change_with_cause;

        let (account_id, account): (
            String,
            Option<&near_indexer::near_primitives::views::AccountView>,
        ) = match value {
            near_indexer::near_primitives::views::StateChangeValueView::AccountUpdate {
                account_id,
                account,
            } => (account_id.to_string(), Some(account)),
            near_indexer::near_primitives::views::StateChangeValueView::AccountDeletion {
                account_id,
            } => (account_id.to_string(), None),
            _ => return None,
        };

        Some(Self {
            affected_account_id: account_id,
            changed_in_block_timestamp: changed_in_block_timestamp.into(),
            changed_in_block_hash: changed_in_block_hash.to_string(),
            caused_by_transaction_hash: if let near_indexer::near_primitives::views::StateChangeCauseView::TransactionProcessing {tx_hash } = cause {
                Some(tx_hash.to_string())
            } else {
                None
            },
            caused_by_receipt_id: match cause {
                near_indexer::near_primitives::views::StateChangeCauseView::ActionReceiptProcessingStarted { receipt_hash} => Some(receipt_hash.to_string()),
                near_indexer::near_primitives::views::StateChangeCauseView::ActionReceiptGasReward { receipt_hash } => Some(receipt_hash.to_string()),
                near_indexer::near_primitives::views::StateChangeCauseView::ReceiptProcessing { receipt_hash } => Some(receipt_hash.to_string()),
                near_indexer::near_primitives::views::StateChangeCauseView::PostponedReceipt { receipt_hash } => Some(receipt_hash.to_string()),
                _ => None,
            },
            update_reason: cause.into(),
            affected_account_nonstaked_balance: if let Some(acc) = account {
                BigDecimal::from_str(acc.amount.to_string().as_str())
                    .expect("`amount` expected to be u128")
            } else {
                BigDecimal::from(0)
            },
            affected_account_staked_balance: if let Some(acc) = account {
                BigDecimal::from_str(acc.locked.to_string().as_str())
                    .expect("`locked` expected to be u128")
            } else {
                BigDecimal::from(0)
            },
            affected_account_storage_usage: if let Some(acc) = account {
                acc.storage_usage.into()
            } else {
                BigDecimal::from(0)
            },
            index_in_block
        })
    }
}

'''
'''--- dockerfile/src/models/accounts.rs ---
use bigdecimal::BigDecimal;

use crate::schema;
use schema::accounts;

#[derive(Insertable, Debug, Clone, QueryableByName)]
#[table_name = "accounts"]
pub struct Account {
    pub account_id: String,
    pub created_by_receipt_id: Option<String>,
    pub deleted_by_receipt_id: Option<String>,
    pub last_update_block_height: BigDecimal,
}

impl Account {
    pub fn new_from_receipt(
        account_id: &near_indexer::near_primitives::types::AccountId,
        created_by_receipt_id: &near_indexer::near_primitives::hash::CryptoHash,
        last_update_block_height: near_indexer::near_primitives::types::BlockHeight,
    ) -> Self {
        Self {
            account_id: account_id.to_string(),
            created_by_receipt_id: Some(created_by_receipt_id.to_string()),
            deleted_by_receipt_id: None,
            last_update_block_height: last_update_block_height.into(),
        }
    }

    pub fn new_from_genesis(
        account_id: &near_indexer::near_primitives::types::AccountId,
        last_update_block_height: near_indexer::near_primitives::types::BlockHeight,
    ) -> Self {
        Self {
            account_id: account_id.to_string(),
            created_by_receipt_id: None,
            deleted_by_receipt_id: None,
            last_update_block_height: last_update_block_height.into(),
        }
    }
}

'''
'''--- dockerfile/src/models/aggregated/circulating_supply.rs ---
use bigdecimal::BigDecimal;

use crate::schema;
use schema::aggregated__circulating_supply;

#[derive(Insertable, Queryable, Clone, Debug)]
#[table_name = "aggregated__circulating_supply"]
pub struct CirculatingSupply {
    pub computed_at_block_timestamp: BigDecimal,
    pub computed_at_block_hash: String,
    pub circulating_tokens_supply: BigDecimal,
    pub total_tokens_supply: BigDecimal,
    pub total_lockup_contracts_count: i32,
    pub unfinished_lockup_contracts_count: i32,
    pub foundation_locked_tokens: BigDecimal,
    pub lockups_locked_tokens: BigDecimal,
}

'''
'''--- dockerfile/src/models/aggregated/mod.rs ---
pub(crate) mod circulating_supply;

'''
'''--- dockerfile/src/models/assets/fungible_token_events.rs ---
use bigdecimal::BigDecimal;

use crate::models::enums::FtEventKind;
use crate::schema;
use schema::assets__fungible_token_events;

#[derive(Insertable, Queryable, Clone, Debug)]
#[table_name = "assets__fungible_token_events"]
pub struct FungibleTokenEvent {
    pub emitted_for_receipt_id: String,
    pub emitted_at_block_timestamp: BigDecimal,
    pub emitted_in_shard_id: BigDecimal,
    pub emitted_index_of_event_entry_in_shard: i32,
    pub emitted_by_contract_account_id: String,
    pub amount: String,
    pub event_kind: FtEventKind,
    pub token_old_owner_account_id: String,
    pub token_new_owner_account_id: String,
    pub event_memo: String,
}

'''
'''--- dockerfile/src/models/assets/mod.rs ---
pub(crate) mod fungible_token_events;
pub(crate) mod non_fungible_token_events;

'''
'''--- dockerfile/src/models/assets/non_fungible_token_events.rs ---
use bigdecimal::BigDecimal;

use crate::models::enums::NftEventKind;
use crate::schema;
use schema::assets__non_fungible_token_events;

#[derive(Insertable, Queryable, Clone, Debug)]
#[table_name = "assets__non_fungible_token_events"]
pub struct NonFungibleTokenEvent {
    pub emitted_for_receipt_id: String,
    pub emitted_at_block_timestamp: BigDecimal,
    pub emitted_in_shard_id: BigDecimal,
    pub emitted_index_of_event_entry_in_shard: i32,
    pub emitted_by_contract_account_id: String,
    pub token_id: String,
    pub event_kind: NftEventKind,
    pub token_old_owner_account_id: String,
    pub token_new_owner_account_id: String,
    pub token_authorized_account_id: String,
    pub event_memo: String,
}

'''
'''--- dockerfile/src/models/blocks.rs ---
use std::str::FromStr;

use bigdecimal::BigDecimal;

use near_indexer::near_primitives;

use crate::schema;
use schema::blocks;

#[derive(Insertable, Queryable, Clone, Debug)]
pub struct Block {
    pub block_height: BigDecimal,
    pub block_hash: String,
    pub prev_block_hash: String,
    pub block_timestamp: BigDecimal,
    pub total_supply: BigDecimal,
    pub gas_price: BigDecimal,
    pub author_account_id: String,
}

impl From<&near_primitives::views::BlockView> for Block {
    fn from(block_view: &near_primitives::views::BlockView) -> Self {
        Self {
            block_height: block_view.header.height.into(),
            block_hash: block_view.header.hash.to_string(),
            prev_block_hash: block_view.header.prev_hash.to_string(),
            block_timestamp: block_view.header.timestamp.into(),
            total_supply: BigDecimal::from_str(block_view.header.total_supply.to_string().as_str())
                .expect("`total_supply` expected to be u128"),
            gas_price: BigDecimal::from_str(block_view.header.gas_price.to_string().as_str())
                .expect("`gas_price` expected to be u128"),
            author_account_id: block_view.author.to_string(),
        }
    }
}

'''
'''--- dockerfile/src/models/chunks.rs ---
use bigdecimal::BigDecimal;

use crate::schema;
use schema::chunks;

#[derive(Insertable, Clone, Debug)]
pub struct Chunk {
    pub included_in_block_hash: String,
    pub chunk_hash: String,
    pub shard_id: BigDecimal,
    pub signature: String,
    pub gas_limit: BigDecimal,
    pub gas_used: BigDecimal,
    pub author_account_id: String,
}

impl Chunk {
    pub fn from_chunk_view(
        chunk_view: &near_indexer::IndexerChunkView,
        block_hash: &near_indexer::near_primitives::hash::CryptoHash,
    ) -> Self {
        Self {
            included_in_block_hash: block_hash.to_string(),
            chunk_hash: chunk_view.header.chunk_hash.to_string(),
            shard_id: chunk_view.header.shard_id.into(),
            signature: chunk_view.header.signature.to_string(),
            gas_limit: chunk_view.header.gas_limit.into(),
            gas_used: chunk_view.header.gas_used.into(),
            author_account_id: chunk_view.author.to_string(),
        }
    }
}

'''
'''--- dockerfile/src/models/enums.rs ---
use diesel_derive_enum::DbEnum;

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Receipt_kind"]
#[PgType = "receipt_kind"]
pub enum ReceiptKind {
    Action,
    Data,
}

impl From<&near_indexer::near_primitives::views::ReceiptEnumView> for ReceiptKind {
    fn from(receipt_enum_view: &near_indexer::near_primitives::views::ReceiptEnumView) -> Self {
        match receipt_enum_view {
            near_indexer::near_primitives::views::ReceiptEnumView::Action { .. } => Self::Action,
            near_indexer::near_primitives::views::ReceiptEnumView::Data { .. } => Self::Data,
        }
    }
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Action_kind"]
#[PgType = "action_kind"]
pub enum ActionKind {
    CreateAccount,
    DeployContract,
    FunctionCall,
    Transfer,
    Stake,
    AddKey,
    DeleteKey,
    DeleteAccount,
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Execution_outcome_status"]
#[PgType = "execution_outcome_status"]
pub enum ExecutionOutcomeStatus {
    Unknown,
    Failure,
    SuccessValue,
    SuccessReceiptId,
}

impl From<near_indexer::near_primitives::views::ExecutionStatusView> for ExecutionOutcomeStatus {
    fn from(status: near_indexer::near_primitives::views::ExecutionStatusView) -> Self {
        match status {
            near_indexer::near_primitives::views::ExecutionStatusView::Unknown => Self::Unknown,
            near_indexer::near_primitives::views::ExecutionStatusView::Failure(_) => Self::Failure,
            near_indexer::near_primitives::views::ExecutionStatusView::SuccessValue(_) => {
                Self::SuccessValue
            }
            near_indexer::near_primitives::views::ExecutionStatusView::SuccessReceiptId(_) => {
                Self::SuccessReceiptId
            }
        }
    }
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Access_key_permission_kind"]
#[PgType = "access_key_permission_kind"]
pub enum AccessKeyPermission {
    /// Used only with AccessKeyAction::Add
    FullAccess,
    /// Used only with AccessKeyAction::Add
    FunctionCall,
}

impl From<&near_indexer::near_primitives::views::AccessKeyPermissionView> for AccessKeyPermission {
    fn from(item: &near_indexer::near_primitives::views::AccessKeyPermissionView) -> Self {
        match item {
            near_indexer::near_primitives::views::AccessKeyPermissionView::FunctionCall {
                ..
            } => Self::FunctionCall,
            near_indexer::near_primitives::views::AccessKeyPermissionView::FullAccess => {
                Self::FullAccess
            }
        }
    }
}

impl From<&near_indexer::near_primitives::account::AccessKeyPermission> for AccessKeyPermission {
    fn from(item: &near_indexer::near_primitives::account::AccessKeyPermission) -> Self {
        match item {
            near_indexer::near_primitives::account::AccessKeyPermission::FunctionCall {
                ..
            } => Self::FunctionCall,
            near_indexer::near_primitives::account::AccessKeyPermission::FullAccess => {
                Self::FullAccess
            }
        }
    }
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "State_change_reason_kind"]
#[PgType = "state_change_reason_kind"]
pub enum StateChangeReasonKind {
    TransactionProcessing,
    ActionReceiptProcessingStarted,
    ActionReceiptGasReward,
    ReceiptProcessing,
    PostponedReceipt,
    UpdatedDelayedReceipts,
    ValidatorAccountsUpdate,
    Migration,
    Resharding,
}

impl From<&near_indexer::near_primitives::views::StateChangeCauseView> for StateChangeReasonKind {
    fn from(
        state_change_cause_view: &near_indexer::near_primitives::views::StateChangeCauseView,
    ) -> Self {
        match state_change_cause_view {
            near_indexer::near_primitives::views::StateChangeCauseView::TransactionProcessing { .. } => Self::TransactionProcessing,
            near_indexer::near_primitives::views::StateChangeCauseView::ActionReceiptProcessingStarted { .. } => Self::ActionReceiptProcessingStarted,
            near_indexer::near_primitives::views::StateChangeCauseView::ActionReceiptGasReward { .. } => Self::ActionReceiptGasReward,
            near_indexer::near_primitives::views::StateChangeCauseView::ReceiptProcessing { .. } => Self::ReceiptProcessing,
            near_indexer::near_primitives::views::StateChangeCauseView::PostponedReceipt { .. } => Self::PostponedReceipt,
            near_indexer::near_primitives::views::StateChangeCauseView::UpdatedDelayedReceipts { .. } => Self::UpdatedDelayedReceipts,
            near_indexer::near_primitives::views::StateChangeCauseView::ValidatorAccountsUpdate { .. } => Self::ValidatorAccountsUpdate,
            near_indexer::near_primitives::views::StateChangeCauseView::Migration { .. } => Self::Migration,
            near_indexer::near_primitives::views::StateChangeCauseView::Resharding { .. } => Self::Resharding,
            near_indexer::near_primitives::views::StateChangeCauseView::NotWritableToDisk | near_indexer::near_primitives::views::StateChangeCauseView::InitialState => panic!("Unexpected variant {:?} received", state_change_cause_view),
        }
    }
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Nft_event_kind"]
#[PgType = "nft_event_kind"]
pub enum NftEventKind {
    Mint,
    Transfer,
    Burn,
}

#[derive(Debug, DbEnum, Clone)]
#[DbValueStyle = "SCREAMING_SNAKE_CASE"]
#[DieselType = "Ft_event_kind"]
#[PgType = "ft_event_kind"]
pub enum FtEventKind {
    Mint,
    Transfer,
    Burn,
}

'''
'''--- dockerfile/src/models/execution_outcomes.rs ---
use std::str::FromStr;

use bigdecimal::BigDecimal;

use crate::models::enums::ExecutionOutcomeStatus;

use crate::schema;
use schema::{execution_outcome_receipts, execution_outcomes};

#[derive(Insertable, Clone, Debug)]
pub struct ExecutionOutcome {
    pub receipt_id: String,
    pub executed_in_block_hash: String,
    pub executed_in_block_timestamp: BigDecimal,
    pub index_in_chunk: i32,
    pub gas_burnt: BigDecimal,
    pub tokens_burnt: BigDecimal,
    pub executor_account_id: String,
    pub status: ExecutionOutcomeStatus,
    pub shard_id: BigDecimal,
}

impl ExecutionOutcome {
    pub fn from_execution_outcome(
        execution_outcome: &near_indexer::near_primitives::views::ExecutionOutcomeWithIdView,
        index_in_chunk: i32,
        executed_in_block_timestamp: u64,
        shard_id: u64,
    ) -> Self {
        Self {
            executed_in_block_hash: execution_outcome.block_hash.to_string(),
            executed_in_block_timestamp: executed_in_block_timestamp.into(),
            index_in_chunk,
            receipt_id: execution_outcome.id.to_string(),
            gas_burnt: execution_outcome.outcome.gas_burnt.into(),
            tokens_burnt: BigDecimal::from_str(
                execution_outcome.outcome.tokens_burnt.to_string().as_str(),
            )
            .expect("`tokens_burnt` expected to be u128"),
            executor_account_id: execution_outcome.outcome.executor_id.to_string(),
            status: execution_outcome.outcome.status.clone().into(),
            shard_id: shard_id.into(),
        }
    }
}

#[derive(Insertable, Queryable, Clone, Debug)]
pub struct ExecutionOutcomeReceipt {
    pub executed_receipt_id: String,
    pub index_in_execution_outcome: i32,
    pub produced_receipt_id: String,
}

'''
'''--- dockerfile/src/models/mod.rs ---
use std::env;

use diesel::PgConnection;
use dotenv::dotenv;

pub use access_keys::AccessKey;
pub use account_changes::AccountChange;
pub use accounts::Account;
pub use blocks::Block;
pub use chunks::Chunk;
pub use execution_outcomes::{ExecutionOutcome, ExecutionOutcomeReceipt};
pub use receipts::{
    ActionReceipt, ActionReceiptAction, ActionReceiptInputData, ActionReceiptOutputData,
    DataReceipt, Receipt,
};
pub use transactions::{Transaction, TransactionAction};

pub(crate) use serializers::extract_action_type_and_value_from_action_view;

pub mod access_keys;
pub mod account_changes;
pub mod accounts;
pub mod aggregated;
pub mod assets;
pub mod blocks;
pub mod chunks;
pub mod enums;
pub mod execution_outcomes;
pub mod receipts;
mod serializers;
pub mod transactions;

/// Get database credentials from `.env` or fail
pub(crate) fn get_database_credentials() -> String {
    dotenv().ok();

    env::var("DATABASE_URL").expect("DATABASE_URL must be set in .env file")
}

pub(crate) fn establish_connection() -> actix_diesel::Database<PgConnection> {
    let database_url = get_database_credentials();
    actix_diesel::Database::builder()
        .pool_max_size(30)
        .open(&database_url)
}

'''
'''--- dockerfile/src/models/receipts.rs ---
use std::convert::TryFrom;
use std::str::FromStr;

use bigdecimal::BigDecimal;

use near_indexer::near_primitives::views::DataReceiverView;

use crate::models::enums::{ActionKind, ReceiptKind};
use crate::schema;
use schema::{
    action_receipt_actions, action_receipt_input_data, action_receipt_output_data, action_receipts,
    data_receipts, receipts,
};

#[derive(Insertable, Queryable, Clone, Debug)]
pub struct Receipt {
    pub receipt_id: String,
    pub included_in_block_hash: String,
    pub included_in_chunk_hash: String,
    pub index_in_chunk: i32,
    pub included_in_block_timestamp: BigDecimal,
    pub predecessor_account_id: String,
    pub receiver_account_id: String,
    pub receipt_kind: ReceiptKind,
    pub originated_from_transaction_hash: String,
}

impl Receipt {
    pub fn from_receipt_view(
        receipt: &near_indexer::near_primitives::views::ReceiptView,
        block_hash: &near_indexer::near_primitives::hash::CryptoHash,
        transaction_hash: &str,
        chunk_hash: &near_indexer::near_primitives::hash::CryptoHash,
        index_in_chunk: i32,
        block_timestamp: u64,
    ) -> Self {
        Self {
            receipt_id: receipt.receipt_id.to_string(),
            included_in_block_hash: block_hash.to_string(),
            included_in_chunk_hash: chunk_hash.to_string(),
            predecessor_account_id: receipt.predecessor_id.to_string(),
            receiver_account_id: receipt.receiver_id.to_string(),
            receipt_kind: (&receipt.receipt).into(),
            originated_from_transaction_hash: transaction_hash.to_string(),
            index_in_chunk,
            included_in_block_timestamp: block_timestamp.into(),
        }
    }
}

#[derive(Insertable, Clone, Debug)]
#[table_name = "data_receipts"]
pub struct DataReceipt {
    pub data_id: String,
    pub receipt_id: String,
    pub data: Option<Vec<u8>>,
}

impl TryFrom<&near_indexer::near_primitives::views::ReceiptView> for DataReceipt {
    type Error = &'static str;

    fn try_from(
        receipt_view: &near_indexer::near_primitives::views::ReceiptView,
    ) -> Result<Self, Self::Error> {
        if let near_indexer::near_primitives::views::ReceiptEnumView::Data { data_id, data } =
            &receipt_view.receipt
        {
            Ok(Self {
                receipt_id: receipt_view.receipt_id.to_string(),
                data_id: data_id.to_string(),
                data: data.clone(),
            })
        } else {
            Err("Given ReceiptView is not of Data variant")
        }
    }
}

#[derive(Insertable, Clone, Debug)]
#[table_name = "action_receipts"]
pub struct ActionReceipt {
    pub receipt_id: String,
    pub signer_account_id: String,
    pub signer_public_key: String,
    pub gas_price: BigDecimal,
}

impl TryFrom<&near_indexer::near_primitives::views::ReceiptView> for ActionReceipt {
    type Error = &'static str;

    fn try_from(
        receipt_view: &near_indexer::near_primitives::views::ReceiptView,
    ) -> Result<Self, Self::Error> {
        if let near_indexer::near_primitives::views::ReceiptEnumView::Action {
            signer_id,
            signer_public_key,
            gas_price,
            ..
        } = &receipt_view.receipt
        {
            Ok(Self {
                receipt_id: receipt_view.receipt_id.to_string(),
                signer_account_id: signer_id.to_string(),
                signer_public_key: signer_public_key.to_string(),
                gas_price: BigDecimal::from_str(gas_price.to_string().as_str())
                    .expect("gas_price expected to be u128"),
            })
        } else {
            Err("Given ReceiptView is not of Action variant")
        }
    }
}

#[derive(Insertable, Clone, Debug)]
#[table_name = "action_receipt_actions"]
pub struct ActionReceiptAction {
    pub receipt_id: String,
    pub index_in_action_receipt: i32,
    pub action_kind: ActionKind,
    pub args: serde_json::Value,
    pub receipt_predecessor_account_id: String,
    pub receipt_receiver_account_id: String,
    pub receipt_included_in_block_timestamp: BigDecimal,
}

impl ActionReceiptAction {
    pub fn from_action_view(
        receipt_id: String,
        index: i32,
        action_view: &near_indexer::near_primitives::views::ActionView,
        predecessor_account_id: String,
        receiver_account_id: String,
        block_timestamp: u64,
    ) -> Self {
        let (action_kind, args) =
            crate::models::extract_action_type_and_value_from_action_view(action_view);

        Self {
            receipt_id,
            index_in_action_receipt: index,
            args,
            action_kind,
            receipt_predecessor_account_id: predecessor_account_id,
            receipt_receiver_account_id: receiver_account_id,
            receipt_included_in_block_timestamp: block_timestamp.into(),
        }
    }
}

#[derive(Insertable, Clone, Debug)]
#[table_name = "action_receipt_input_data"]
pub struct ActionReceiptInputData {
    pub input_to_receipt_id: String,
    pub input_data_id: String,
}

impl ActionReceiptInputData {
    pub fn from_data_id(receipt_id: String, data_id: String) -> Self {
        Self {
            input_to_receipt_id: receipt_id,
            input_data_id: data_id,
        }
    }
}

#[derive(Insertable, Clone, Debug)]
#[table_name = "action_receipt_output_data"]
pub struct ActionReceiptOutputData {
    pub output_from_receipt_id: String,
    pub output_data_id: String,
    pub receiver_account_id: String,
}

impl ActionReceiptOutputData {
    pub fn from_data_receiver(receipt_id: String, data_receiver: &DataReceiverView) -> Self {
        Self {
            output_from_receipt_id: receipt_id,
            output_data_id: data_receiver.data_id.to_string(),
            receiver_account_id: data_receiver.receiver_id.to_string(),
        }
    }
}

'''
'''--- dockerfile/src/models/serializers.rs ---
use serde::{Deserialize, Serialize};
use serde_json::json;

use near_indexer::near_primitives::serialize::option_u128_dec_format;
use near_indexer::near_primitives::views::ActionView;

use crate::models::enums::ActionKind;

/// We want to store permission field more explicitly so we are making copy of nearcore struct
/// to change serde parameters of serialization.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub(crate) struct AccessKeyView {
    pub nonce: near_indexer::near_primitives::types::Nonce,
    pub permission: AccessKeyPermissionView,
}

impl From<&near_indexer::near_primitives::views::AccessKeyView> for AccessKeyView {
    fn from(access_key_view: &near_indexer::near_primitives::views::AccessKeyView) -> Self {
        Self {
            nonce: access_key_view.nonce,
            permission: access_key_view.permission.clone().into(),
        }
    }
}

/// This is a enum we want to store more explicitly, so we copy it from nearcore and provide
/// different serde representation settings
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(
    tag = "permission_kind",
    content = "permission_details",
    rename_all = "SCREAMING_SNAKE_CASE"
)]
pub(crate) enum AccessKeyPermissionView {
    FunctionCall {
        #[serde(with = "option_u128_dec_format")]
        allowance: Option<near_indexer::near_primitives::types::Balance>,
        receiver_id: String,
        method_names: Vec<String>,
    },
    FullAccess,
}

impl From<near_indexer::near_primitives::views::AccessKeyPermissionView>
    for AccessKeyPermissionView
{
    fn from(permission: near_indexer::near_primitives::views::AccessKeyPermissionView) -> Self {
        match permission {
            near_indexer::near_primitives::views::AccessKeyPermissionView::FullAccess => {
                Self::FullAccess
            }
            near_indexer::near_primitives::views::AccessKeyPermissionView::FunctionCall {
                allowance,
                receiver_id,
                method_names,
            } => Self::FunctionCall {
                allowance,
                receiver_id: receiver_id.escape_default().to_string(),
                method_names: method_names
                    .into_iter()
                    .map(|method_name| method_name.escape_default().to_string())
                    .collect(),
            },
        }
    }
}

pub(crate) fn extract_action_type_and_value_from_action_view(
    action_view: &near_indexer::near_primitives::views::ActionView,
) -> (crate::models::enums::ActionKind, serde_json::Value) {
    match action_view {
        ActionView::CreateAccount => (ActionKind::CreateAccount, json!({})),
        ActionView::DeployContract { code } => (
            ActionKind::DeployContract,
            json!({
                "code_sha256":  hex::encode(
                    base64::decode(code).expect("code expected to be encoded to base64")
                )
            }),
        ),
        ActionView::FunctionCall {
            method_name,
            args,
            gas,
            deposit,
        } => {
            let mut arguments = json!({
                "method_name": method_name.escape_default().to_string(),
                "args_base64": args,
                "gas": gas,
                "deposit": deposit.to_string(),
            });

            // During denormalization of action_receipt_actions table we wanted to try to decode
            // args which is base64 encoded in case if it is a JSON object and put them near initial
            // args_base64
            // See for reference https://github.com/near/near-indexer-for-explorer/issues/87
            if let Ok(decoded_args) = base64::decode(args) {
                if let Ok(mut args_json) = serde_json::from_slice(&decoded_args) {
                    escape_json(&mut args_json);
                    arguments["args_json"] = args_json;
                }
            }

            (ActionKind::FunctionCall, arguments)
        }
        ActionView::Transfer { deposit } => (
            ActionKind::Transfer,
            json!({ "deposit": deposit.to_string() }),
        ),
        ActionView::Stake { stake, public_key } => (
            ActionKind::Stake,
            json!({
                "stake": stake.to_string(),
                "public_key": public_key,
            }),
        ),
        ActionView::AddKey {
            public_key,
            access_key,
        } => (
            ActionKind::AddKey,
            json!({
                "public_key": public_key,
                "access_key": crate::models::serializers::AccessKeyView::from(access_key),
            }),
        ),
        ActionView::DeleteKey { public_key } => (
            ActionKind::DeleteKey,
            json!({
                "public_key": public_key,
            }),
        ),
        ActionView::DeleteAccount { beneficiary_id } => (
            ActionKind::DeleteAccount,
            json!({
                "beneficiary_id": beneficiary_id,
            }),
        ),
    }
}

/// This function will modify the JSON escaping the values
/// We can not store data with null-bytes in TEXT or JSONB fields
/// of PostgreSQL
/// ref: https://www.commandprompt.com/blog/null-characters-workarounds-arent-good-enough/
fn escape_json(object: &mut serde_json::Value) {
    match object {
        serde_json::Value::Object(ref mut value) => {
            for (_key, val) in value {
                escape_json(val);
            }
        }
        serde_json::Value::Array(ref mut values) => {
            for element in values.iter_mut() {
                escape_json(element)
            }
        }
        serde_json::Value::String(ref mut value) => *value = value.escape_default().to_string(),
        _ => {}
    }
}

'''
'''--- dockerfile/src/models/transactions.rs ---
use std::str::FromStr;

use bigdecimal::BigDecimal;

use crate::models::enums::{ActionKind, ExecutionOutcomeStatus};
use crate::schema;
use schema::{transaction_actions, transactions};

#[derive(Insertable, Clone, Debug)]
pub struct Transaction {
    pub transaction_hash: String,
    pub included_in_block_hash: String,
    pub included_in_chunk_hash: String,
    pub index_in_chunk: i32,
    pub block_timestamp: BigDecimal,
    pub signer_account_id: String,
    pub signer_public_key: String,
    pub nonce: BigDecimal,
    pub receiver_account_id: String,
    pub signature: String,
    pub status: ExecutionOutcomeStatus,
    pub converted_into_receipt_id: String,
    pub receipt_conversion_gas_burnt: BigDecimal,
    pub receipt_conversion_tokens_burnt: BigDecimal,
}

impl Transaction {
    pub fn from_indexer_transaction(
        tx: &near_indexer::IndexerTransactionWithOutcome,
        // hack for supporting duplicated transaction hashes
        transaction_hash: &str,
        converted_into_receipt_id: &str,
        block_hash: &near_indexer::near_primitives::hash::CryptoHash,
        chunk_hash: &near_indexer::near_primitives::hash::CryptoHash,
        block_timestamp: u64,
        index_in_chunk: i32,
    ) -> Self {
        Self {
            transaction_hash: transaction_hash.to_string(),
            included_in_block_hash: block_hash.to_string(),
            block_timestamp: block_timestamp.into(),
            index_in_chunk,
            nonce: tx.transaction.nonce.into(),
            signer_account_id: tx.transaction.signer_id.to_string(),
            signer_public_key: tx.transaction.public_key.to_string(),
            signature: tx.transaction.signature.to_string(),
            receiver_account_id: tx.transaction.receiver_id.to_string(),
            converted_into_receipt_id: converted_into_receipt_id.to_string(),
            included_in_chunk_hash: chunk_hash.to_string(),
            status: tx.outcome.execution_outcome.outcome.status.clone().into(),
            receipt_conversion_gas_burnt: tx.outcome.execution_outcome.outcome.gas_burnt.into(),
            receipt_conversion_tokens_burnt: BigDecimal::from_str(
                tx.outcome
                    .execution_outcome
                    .outcome
                    .tokens_burnt
                    .to_string()
                    .as_str(),
            )
            .expect("`token_burnt` must be u128"),
        }
    }
}

#[derive(Insertable, Clone, Debug)]
pub struct TransactionAction {
    pub transaction_hash: String,
    pub index_in_transaction: i32,
    pub action_kind: ActionKind,
    pub args: serde_json::Value,
}

impl TransactionAction {
    pub fn from_action_view(
        transaction_hash: String,
        index: i32,
        action_view: &near_indexer::near_primitives::views::ActionView,
    ) -> Self {
        let (action_kind, args) =
            crate::models::extract_action_type_and_value_from_action_view(action_view);
        Self {
            transaction_hash,
            index_in_transaction: index,
            args,
            action_kind,
        }
    }
}

'''
'''--- dockerfile/src/retriable.rs ---
#[macro_export]
macro_rules! await_retry_or_panic {
    ($query: expr, $number_of_retries: expr, $error_message: expr, $debug_structs: expr $(, $is_error_handled:expr)? $(,)?) => {
        {
            let mut interval = crate::INTERVAL;
            let mut retry_attempt = 0usize;
            loop {
                if retry_attempt == $number_of_retries {
                    return Err(
                        anyhow::anyhow!(
                            "Failed to perform query to database after {} attempts. Stop trying.",
                            $number_of_retries
                        )
                    );
                }
                retry_attempt += 1;

                match $query.await {
                    Ok(res) => break Some(res),
                    Err(async_error) => {
                        $(if $is_error_handled(&async_error).await {
                            break None;
                        })?

                        tracing::error!(
                             target: crate::INDEXER_FOR_EXPLORER,
                             "Error occurred during {}: \n{:#?} \n{:#?} \n Retrying in {} milliseconds...",
                             async_error,
                             &$error_message,
                             &$debug_structs,
                             interval.as_millis(),
                         );
                        tokio::time::sleep(interval).await;
                        if interval < crate::MAX_DELAY_TIME {
                            interval *= 2;
                        }
                    }
                }
            }
        }
    };
}

'''
'''--- dockerfile/src/schema.rs ---
// This file is autogenerated.
// Do not edit it manually. Consider editing `diesel.toml`
// ref: https://diesel.rs/guides/configuring-diesel-cli.html
//
// Steps to create proper schema.patch file:
// - Add new migration file
// - Add new tables to diesel.toml if applicable
// - Comment patch line in diesel.toml
// - `diesel migration run`
// - (new tables/items appeared in DB, schema.rs is updated)
// - `git add src/schema.rs && git commit -m "bad schema"`
// - Fix schema.rs, it should look exactly like you want, it should not produce any warnings.
// - git diff -U6 src/schema.rs > src/schema.patch
// - Uncomment patch line

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    access_keys (public_key, account_id) {
        public_key -> Text,
        account_id -> Text,
        created_by_receipt_id -> Nullable<Text>,
        deleted_by_receipt_id -> Nullable<Text>,
        permission_kind -> Access_key_permission_kind,
        last_update_block_height -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    account_changes (id) {
        id -> Int8,
        affected_account_id -> Text,
        changed_in_block_timestamp -> Numeric,
        changed_in_block_hash -> Text,
        caused_by_transaction_hash -> Nullable<Text>,
        caused_by_receipt_id -> Nullable<Text>,
        update_reason -> State_change_reason_kind,
        affected_account_nonstaked_balance -> Numeric,
        affected_account_staked_balance -> Numeric,
        affected_account_storage_usage -> Numeric,
        index_in_block -> Int4,
    }
}

table! {
    use diesel::sql_types::*;

    accounts (id) {
        id -> Int8,
        account_id -> Text,
        created_by_receipt_id -> Nullable<Text>,
        deleted_by_receipt_id -> Nullable<Text>,
        last_update_block_height -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    action_receipt_actions (receipt_id, index_in_action_receipt) {
        receipt_id -> Text,
        index_in_action_receipt -> Int4,
        action_kind -> Action_kind,
        args -> Jsonb,
        receipt_predecessor_account_id -> Text,
        receipt_receiver_account_id -> Text,
        receipt_included_in_block_timestamp -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;

    action_receipt_input_data (input_data_id, input_to_receipt_id) {
        input_data_id -> Text,
        input_to_receipt_id -> Text,
    }
}

table! {
    use diesel::sql_types::*;

    action_receipt_output_data (output_data_id, output_from_receipt_id) {
        output_data_id -> Text,
        output_from_receipt_id -> Text,
        receiver_account_id -> Text,
    }
}

table! {
    use diesel::sql_types::*;

    action_receipts (receipt_id) {
        receipt_id -> Text,
        signer_account_id -> Text,
        signer_public_key -> Text,
        gas_price -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;

    #[allow(non_snake_case)]
    aggregated__circulating_supply (computed_at_block_hash) {
        computed_at_block_timestamp -> Numeric,
        computed_at_block_hash -> Text,
        circulating_tokens_supply -> Numeric,
        total_tokens_supply -> Numeric,
        total_lockup_contracts_count -> Int4,
        unfinished_lockup_contracts_count -> Int4,
        foundation_locked_tokens -> Numeric,
        lockups_locked_tokens -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    #[allow(non_snake_case)]
    assets__fungible_token_events (emitted_for_receipt_id, emitted_at_block_timestamp, emitted_in_shard_id, emitted_index_of_event_entry_in_shard, emitted_by_contract_account_id, amount, event_kind, token_old_owner_account_id, token_new_owner_account_id, event_memo) {
        emitted_for_receipt_id -> Text,
        emitted_at_block_timestamp -> Numeric,
        emitted_in_shard_id -> Numeric,
        emitted_index_of_event_entry_in_shard -> Int4,
        emitted_by_contract_account_id -> Text,
        amount -> Text,
        event_kind -> Ft_event_kind,
        token_old_owner_account_id -> Text,
        token_new_owner_account_id -> Text,
        event_memo -> Text,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    #[allow(non_snake_case)]
    assets__non_fungible_token_events (emitted_for_receipt_id, emitted_at_block_timestamp, emitted_in_shard_id, emitted_index_of_event_entry_in_shard, emitted_by_contract_account_id, token_id, event_kind, token_old_owner_account_id, token_new_owner_account_id, token_authorized_account_id, event_memo) {
        emitted_for_receipt_id -> Text,
        emitted_at_block_timestamp -> Numeric,
        emitted_in_shard_id -> Numeric,
        emitted_index_of_event_entry_in_shard -> Int4,
        emitted_by_contract_account_id -> Text,
        token_id -> Text,
        event_kind -> Nft_event_kind,
        token_old_owner_account_id -> Text,
        token_new_owner_account_id -> Text,
        token_authorized_account_id -> Text,
        event_memo -> Text,
    }
}

table! {
     use diesel::sql_types::*;
    #[allow(non_snake_case)]
    aggregated__lockups(account_id) {
        account_id -> Text,
        creation_block_height -> Nullable<Numeric>,
        deletion_block_height -> Nullable<Numeric>,
    }
}

table! {
    use diesel::sql_types::*;

    blocks (block_hash) {
        block_height -> Numeric,
        block_hash -> Text,
        prev_block_hash -> Text,
        block_timestamp -> Numeric,
        total_supply -> Numeric,
        gas_price -> Numeric,
        author_account_id -> Text,
    }
}

table! {
    use diesel::sql_types::*;

    chunks (chunk_hash) {
        included_in_block_hash -> Text,
        chunk_hash -> Text,
        shard_id -> Numeric,
        signature -> Text,
        gas_limit -> Numeric,
        gas_used -> Numeric,
        author_account_id -> Text,
    }
}

table! {
    use diesel::sql_types::*;

    data_receipts (data_id) {
        data_id -> Text,
        receipt_id -> Text,
        data -> Nullable<Bytea>,
    }
}

table! {
    use diesel::sql_types::*;

    execution_outcome_receipts (executed_receipt_id, index_in_execution_outcome, produced_receipt_id) {
        executed_receipt_id -> Text,
        index_in_execution_outcome -> Int4,
        produced_receipt_id -> Text,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    execution_outcomes (receipt_id) {
        receipt_id -> Text,
        executed_in_block_hash -> Text,
        executed_in_block_timestamp -> Numeric,
        index_in_chunk -> Int4,
        gas_burnt -> Numeric,
        tokens_burnt -> Numeric,
        executor_account_id -> Text,
        status -> Execution_outcome_status,
        shard_id -> Numeric,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    receipts (receipt_id) {
        receipt_id -> Text,
        included_in_block_hash -> Text,
        included_in_chunk_hash -> Text,
        index_in_chunk -> Int4,
        included_in_block_timestamp -> Numeric,
        predecessor_account_id -> Text,
        receiver_account_id -> Text,
        receipt_kind -> Receipt_kind,
        originated_from_transaction_hash -> Text,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    transaction_actions (transaction_hash, index_in_transaction) {
        transaction_hash -> Text,
        index_in_transaction -> Int4,
        action_kind -> Action_kind,
        args -> Jsonb,
    }
}

table! {
    use diesel::sql_types::*;
    use crate::models::enums::*;

    transactions (transaction_hash) {
        transaction_hash -> Text,
        included_in_block_hash -> Text,
        included_in_chunk_hash -> Text,
        index_in_chunk -> Int4,
        block_timestamp -> Numeric,
        signer_account_id -> Text,
        signer_public_key -> Text,
        nonce -> Numeric,
        receiver_account_id -> Text,
        signature -> Text,
        status -> Execution_outcome_status,
        converted_into_receipt_id -> Text,
        receipt_conversion_gas_burnt -> Nullable<Numeric>,
        receipt_conversion_tokens_burnt -> Nullable<Numeric>,
    }
}

joinable!(account_changes -> blocks (changed_in_block_hash));
joinable!(account_changes -> receipts (caused_by_receipt_id));
joinable!(account_changes -> transactions (caused_by_transaction_hash));
joinable!(action_receipt_actions -> receipts (receipt_id));
joinable!(aggregated__circulating_supply -> blocks (computed_at_block_hash));
joinable!(assets__fungible_token_events -> receipts (emitted_for_receipt_id));
joinable!(assets__non_fungible_token_events -> receipts (emitted_for_receipt_id));
joinable!(chunks -> blocks (included_in_block_hash));
joinable!(execution_outcome_receipts -> execution_outcomes (executed_receipt_id));
joinable!(execution_outcome_receipts -> receipts (executed_receipt_id));
joinable!(execution_outcomes -> blocks (executed_in_block_hash));
joinable!(execution_outcomes -> receipts (receipt_id));
joinable!(receipts -> blocks (included_in_block_hash));
joinable!(receipts -> chunks (included_in_chunk_hash));
joinable!(receipts -> transactions (originated_from_transaction_hash));
joinable!(transaction_actions -> transactions (transaction_hash));
joinable!(transactions -> blocks (included_in_block_hash));
joinable!(transactions -> chunks (included_in_chunk_hash));

allow_tables_to_appear_in_same_query!(
    access_keys,
    account_changes,
    accounts,
    action_receipt_actions,
    action_receipt_input_data,
    action_receipt_output_data,
    action_receipts,
    aggregated__circulating_supply,
    assets__fungible_token_events,
    assets__non_fungible_token_events,
    blocks,
    chunks,
    data_receipts,
    execution_outcome_receipts,
    execution_outcomes,
    receipts,
    transaction_actions,
    transactions,
);

'''