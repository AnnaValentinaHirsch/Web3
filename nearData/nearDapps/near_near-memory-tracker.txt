*GitHub Repository "near/near-memory-tracker"*

'''--- .github/ISSUE_TEMPLATE/BOUNTY.yml ---
name: "Simple Bounty"
description: "Use this template to create a HEROES Simple Bounty via Github bot"
title: "Bounty: "
labels: ["bounty"]
assignees: heroes-bot-test
body:
  - type: markdown
    attributes:
      value: |
        Hi! Let's set up your bounty! Please don't change the template - @heroes-bot-test won't be able to help you.

  - type: dropdown
    id: type
    attributes:
      label: What talent are you looking for?
      options:
        - Marketing
        - Development
        - Design
        - Other
        - Content
        - Research
        - Audit

  - type: textarea
    id: description
    attributes:
      label: What you need to be done?

  - type: dropdown
    id: tags
    attributes:
      label: Tags
      description: Add tags that match the topic of the work
      multiple: true
      options:
        - API
        - Blockchain
        - Community
        - CSS
        - DAO
        - dApp
        - DeFi
        - Design
        - Documentation
        - HTML
        - Javascript
        - NFT
        - React
        - Rust
        - Smart contract
        - Typescript
        - UI/UX
        - web3
        - Translation
        - Illustration
        - Branding
        - Copywriting
        - Blogging
        - Editing
        - Video Creation
        - Social Media
        - Graphic Design
        - Transcription
        - Product Design
        - Artificial Intelligence
        - Quality Assurance
        - Risk Assessment
        - Security Audit
        - Bug Bounty
        - Code Review
        - Blockchain Security
        - Smart Contract Testing
        - Penetration Testing
        - Vulnerability Assessment
        - BOS
        - News
        - Hackathon
        - NEARCON2023
        - NEARWEEK

  - type: input
    id: deadline
    attributes:
      label: Deadline
      description: "Set a deadline for your bounty. Please enter the date in format: DD.MM.YYYY"
      placeholder: "19.05.2027"

  - type: dropdown
    id: currencyType
    attributes:
      label: Currency
      description: What is the currency you want to pay?
      options:
        - USDC.e
        - USDT.e
        - DAI
        - wNEAR
        - USDt
        - XP
        - marmaj
        - NEKO
        - JUMP
        - USDC
        - NEARVIDIA
      default: 0
    validations:
      required: true

  - type: input
    id: currencyAmount
    attributes:
      label: Amount
      description: How much it will be cost?

  - type: markdown
    attributes:
      value: "## Advanced settings"

  - type: checkboxes
    id: kyc
    attributes:
      label: KYC
      description: "Use HEROES' KYC Verification, only applicants who passed HEROES' KYC can apply and work on this bounty!"
      options:
        - label: Use KYC Verification

  - type: markdown
    attributes:
      value: |
        ### This cannot be changed once the bounty is live!

'''
'''--- .github/workflows/rust.yml ---
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: '-D warnings'
  CARGO_INCREMENTAL: 0
  RUST_BACKTRACE: short

jobs:
  build-macos-11:
    runs-on: macos-11

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-build
    - name: Build
      run: cargo build --verbose -p near-rust-allocator-proxy

  build-windows-2022:
    runs-on: windows-2022

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-build
    - name: Build
      run: cargo build --verbose -p near-rust-allocator-proxy

  build-ubuntu-20-04:
    runs-on: ubuntu-20.04

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-build
    - name: Build
      run: cargo build --verbose --workspace

  tests:
    runs-on: ubuntu-20.04

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-tests
    - name: Run tests
      run: cargo test --verbose --workspace

  clippy:
    runs-on: ubuntu-20.04

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-clippy
    - name: Run clippy
      run: cargo clippy --all-targets -- -D clippy::all

  cargo-deny:
    runs-on: ubuntu-20.04

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      id: deny-cache
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-cargo-deny
    - name: Install cargo-deny
      if: steps.deny-cache.outputs.cache-hit != 'true'
      run: cargo install cargo-deny
    - name: Run cargo-deny
      run: cargo-deny --all-features --workspace check advisories bans sources

  cargo-fmt:
    runs-on: ubuntu-20.04

    steps:
    - uses: actions/checkout@v2
    - uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}-fmt
    - name: Run cargo fmt
      run: cargo fmt --all -- --check

'''
'''--- Cargo.toml ---
[workspace]
members = ["example-target", "rust-memory-analyzer", "near-rust-allocator-proxy"]

[profile.bench]
codegen-units = 1 # Use only 1 codegen-unit to enable full optimizations.
lto = true
overflow-checks = true

[profile.release]
codegen-units = 1 # Use only 1 codegen-unit to enable full optimizations.
lto = true # Enable full link-time optimization.
overflow-checks = true

'''
'''--- README.md ---
Utilities developed to measure memory usage in projects with mixed Rust/C++ code
while having minimizing performance/memory overhead.

# Goals
* Track memory usage/leaks in large Rust projects, where memory leak could
  potencially practially everywhere: for example: application itself, any of hundreds
  imported Rust libraries or even with liked C/C++ code.
* Low performance overhead - existing tools like Valdrid can slow down program
  by a factor of 25-50 times, using such approach would be impractical.
* Low memory overhead - Adds extra 32 bytes per each memory allocation on heap.
  While it's easy to add extra memory to a machine when needed, adding extra CPU cores will not help with applications limited by a single core performance.
  This can be optimized if needed by either reducing header size or by
  doing random sampling for small allocations.
* Ability to dump memory while process is running without affecting it.

# Requirements

* Linux operating system - `dump` script uses linux proc filesystem to read
  process information. This can be extended to other platform if needed in the
  future.

# Design

Rust allocator proxy:
Tracking Rust allocation is done by adding a proxy, which uses jemalloc and
add 32 bytes header to all allocations.
See https://doc.rust-lang.org/std/alloc/trait.GlobalAlloc.html

C allocator proxy:
Tracking C allocator is done in by overriding dynamic links to malloc/free/etc.
This can be overriden by providing an enviroment variable while running an
executable `LD_PRELOAD=./mtrace.so path'.

`dump` script:
* Reads process memory mapping from `/proc/<PID>/smaps`.
* It's able to identify which pages are present by reading from `/proc/<PID>/pagemap`.
* It reads memory using `/proc/<PID>/pagemap`
* Once memory is read, regions of memory allocated by Rust/C code can be
  identified by looking for `MAGIC` keyword, which is part of the header.

The core tool is in `dump.cpp` file. It dumps the program memory and it prints
memory statistics.

# Modules
* near-rust-allocator-proxy inside `near-rust-allocator-proxy` folder
* near-c-allocator-proxy `near-c-allocator-proxy.c` inside
  `near-dump-analyzer` folder.
* near-dump-analyzer `dump.cpp` inside `near-dump-analyzer` folder

'''
'''--- deny.toml ---
# This template contains all of the possible sections and their default values

# Note that all fields that take a lint level have these possible values:
# * deny - An error will be produced and the check will fail
# * warn - A warning will be produced, but the check will not fail
# * allow - No warning or error will be produced, though in some cases a note
# will be

# The values provided in this template are the default values that will be used
# when any section or field is not specified in your own configuration

# If 1 or more target triples (and optionally, target_features) are specified,
# only the specified targets will be checked when running `cargo deny check`.
# This means, if a particular package is only ever used as a target specific
# dependency, such as, for example, the `nix` crate only being used via the
# `target_family = "unix"` configuration, that only having windows targets in
# this list would mean the nix crate, as well as any of its exclusive
# dependencies not shared by any other crates, would be ignored, as the target
# list here is effectively saying which targets you are building for.
targets = [
    # The triple can be any string, but only the target triples built in to
    # rustc (as of 1.40) can be checked against actual config expressions
    #{ triple = "x86_64-unknown-linux-musl" },
    # You can also specify which target_features you promise are enabled for a
    # particular target. target_features are currently not validated against
    # the actual valid features supported by the target architecture.
    #{ triple = "wasm32-unknown-unknown", features = ["atomics"] },
]

# This section is considered when running `cargo deny check advisories`
# More documentation for the advisories section can be found here:
# https://embarkstudios.github.io/cargo-deny/checks/advisories/cfg.html
[advisories]
# The path where the advisory database is cloned/fetched into
db-path = "~/.cargo/advisory-db"
# The url(s) of the advisory databases to use
db-urls = ["https://github.com/rustsec/advisory-db"]
# The lint level for security vulnerabilities
vulnerability = "deny"
# The lint level for unmaintained crates
unmaintained = "warn"
# The lint level for crates that have been yanked from their source registry
yanked = "warn"
# The lint level for crates with security notices. Note that as of
# 2019-12-17 there are no security notice advisories in
# https://github.com/rustsec/advisory-db
notice = "warn"
# A list of advisory IDs to ignore. Note that ignored advisories will still
# output a note when they are encountered.
ignore = [
    "RUSTSEC-2021-0127",
    #"RUSTSEC-0000-0000",
]
# Threshold for security vulnerabilities, any vulnerability with a CVSS score
# lower than the range specified will be ignored. Note that ignored advisories
# will still output a note when they are encountered.
# * None - CVSS Score 0.0
# * Low - CVSS Score 0.1 - 3.9
# * Medium - CVSS Score 4.0 - 6.9
# * High - CVSS Score 7.0 - 8.9
# * Critical - CVSS Score 9.0 - 10.0
#severity-threshold =

# This section is considered when running `cargo deny check licenses`
# More documentation for the licenses section can be found here:
# https://embarkstudios.github.io/cargo-deny/checks/licenses/cfg.html
[licenses]
# The lint level for crates which do not have a detectable license
unlicensed = "deny"
# List of explicitly allowed licenses
# See https://spdx.org/licenses/ for list of possible licenses
# [possible values: any SPDX 3.11 short identifier (+ optional exception)].
allow = [
    #"MIT",
    #"Apache-2.0",
    #"Apache-2.0 WITH LLVM-exception",
]
# List of explicitly disallowed licenses
# See https://spdx.org/licenses/ for list of possible licenses
# [possible values: any SPDX 3.11 short identifier (+ optional exception)].
deny = [
    #"Nokia",
]
# Lint level for licenses considered copyleft
copyleft = "warn"
# Blanket approval or denial for OSI-approved or FSF Free/Libre licenses
# * both - The license will be approved if it is both OSI-approved *AND* FSF
# * either - The license will be approved if it is either OSI-approved *OR* FSF
# * osi-only - The license will be approved if is OSI-approved *AND NOT* FSF
# * fsf-only - The license will be approved if is FSF *AND NOT* OSI-approved
# * neither - This predicate is ignored and the default lint level is used
allow-osi-fsf-free = "neither"
# Lint level used when no other predicates are matched
# 1. License isn't in the allow or deny lists
# 2. License isn't copyleft
# 3. License isn't OSI/FSF, or allow-osi-fsf-free = "neither"
default = "deny"
# The confidence threshold for detecting a license from license text.
# The higher the value, the more closely the license text must be to the
# canonical license text of a valid SPDX license file.
# [possible values: any between 0.0 and 1.0].
confidence-threshold = 0.8
# Allow 1 or more licenses on a per-crate basis, so that particular licenses
# aren't accepted for every possible crate as with the normal allow list
exceptions = [
    # Each entry is the crate and version constraint, and its specific allow
    # list
    #{ allow = ["Zlib"], name = "adler32", version = "*" },
]

# Some crates don't have (easily) machine readable licensing information,
# adding a clarification entry for it allows you to manually specify the
# licensing information
#[[licenses.clarify]]
# The name of the crate the clarification applies to
#name = "ring"
# The optional version constraint for the crate
#version = "*"
# The SPDX expression for the license requirements of the crate
#expression = "MIT AND ISC AND OpenSSL"
# One or more files in the crate's source used as the "source of truth" for
# the license expression. If the contents match, the clarification will be used
# when running the license check, otherwise the clarification will be ignored
# and the crate will be checked normally, which may produce warnings or errors
# depending on the rest of your configuration
#license-files = [
    # Each entry is a crate relative path, and the (opaque) hash of its contents
    #{ path = "LICENSE", hash = 0xbd0eed23 }
#]

[licenses.private]
# If true, ignores workspace crates that aren't published, or are only
# published to private registries.
# To see how to mark a crate as unpublished (to the official registry),
# visit https://doc.rust-lang.org/cargo/reference/manifest.html#the-publish-field.
ignore = false
# One or more private registries that you might publish crates to, if a crate
# is only published to private registries, and ignore is true, the crate will
# not have its license(s) checked
registries = [
    #"https://sekretz.com/registry
]

# This section is considered when running `cargo deny check bans`.
# More documentation about the 'bans' section can be found here:
# https://embarkstudios.github.io/cargo-deny/checks/bans/cfg.html
[bans]
# Lint level for when multiple versions of the same crate are detected
multiple-versions = "deny"
# Lint level for when a crate version requirement is `*`
wildcards = "allow"
# The graph highlighting used when creating dotgraphs for crates
# with multiple versions
# * lowest-version - The path to the lowest versioned duplicate is highlighted
# * simplest-path - The path to the version with the fewest edges is highlighted
# * all - Both lowest-version and simplest-path are used
highlight = "all"
# List of crates that are allowed. Use with care!
allow = [
]
# List of crates to deny
deny = [
    # Each entry the name of a crate and a version range. If version is
    # not specified, all versions will be matched.
    #{ name = "ansi_term", version = "=0.11.0" },
    #
    # Wrapper crates can optionally be specified to allow the crate when it
    # is a direct dependency of the otherwise banned crate
    #{ name = "ansi_term", version = "=0.11.0", wrappers = [] },
]
# Certain crates/versions that will be skipped when doing duplicate detection.
skip = [
    { name = "near-rust-allocator-proxy", version = "=0.4.0" },
    { name = "itoa", version = "=0.4.8" },
]
# Similarly to `skip` allows you to skip certain crates during duplicate
# detection. Unlike skip, it also includes the entire tree of transitive
# dependencies starting at the specified crate, up to a certain depth, which is
# by default infinite
skip-tree = [
    { name = "clap", version = "=2.34.0", depth = 20 },
]

# This section is considered when running `cargo deny check sources`.
# More documentation about the 'sources' section can be found here:
# https://embarkstudios.github.io/cargo-deny/checks/sources/cfg.html
[sources]
# Lint level for what to happen when a crate from a crate registry that is not
# in the allow list is encountered
unknown-registry = "warn"
# Lint level for what to happen when a crate from a git repository that is not
# in the allow list is encountered
unknown-git = "warn"
# List of URLs for allowed crate registries. Defaults to the crates.io index
# if not specified. If it is specified but empty, no registries are allowed.
allow-registry = ["https://github.com/rust-lang/crates.io-index"]
# List of URLs for allowed Git repositories
allow-git = []

[sources.allow-org]
# 1 or more github.com organizations to allow git sources for
# github = [""]
# 1 or more gitlab.com organizations to allow git sources for
# gitlab = [""]
# 1 or more bitbucket.org organizations to allow git sources for
# bitbucket = [""]

'''
'''--- dump-analyzer/Cargo.toml ---
[package]
name = "dump_analyzer"
version = "0.1.0"
edition = "2021"

[dependencies]
anyhow = "1.0.51"
clap = "=3.0.0-rc.7"
clap_derive = "=3.0.0-rc.7"
tracing = "0.1.29"
tracing-subscriber = "0.3.3"

'''
'''--- example-target/Cargo.toml ---
[package]
name = "example-target"
version = "0.1.0"
edition = "2021"
publish = false

[dependencies]
tikv-jemallocator = "0.5"
tracing = "0.1.13"
tracing-subscriber = "0.3.3"

near-rust-allocator-proxy = { path = "../near-rust-allocator-proxy" }

'''
'''--- example-target/src/main.rs ---
use near_rust_allocator_proxy::ProxyAllocator;
use std::thread::sleep;
use std::time::Duration;
use tracing::info;
use tracing_subscriber::util::SubscriberInitExt;

const MB: usize = 1024 * 1024;

#[global_allocator]
static ALLOC: ProxyAllocator<tikv_jemallocator::Jemalloc> =
    ProxyAllocator::new(tikv_jemallocator::Jemalloc);

#[allow(unused)]
pub struct MyData {
    pub xx: usize,
}

#[inline(never)]
fn something() {
    let mut res = Vec::new();
    for x in 0..1_000_000_000 {
        res.push(MyData { xx: x });
    }
    loop {
        res.push(MyData { xx: 123 });
        std::thread::sleep(Duration::from_millis(10000));
        info!(res_len = ?res.len(), expected_size_mb = res.len() * 8/ MB);
    }
}

#[inline(never)]
fn main() {
    let format = tracing_subscriber::fmt::format()
        .with_level(true) // don't include levels in formatted output
        .with_target(true) // don't include targets
        .without_time();
    tracing_subscriber::fmt().event_format(format).with_writer(std::io::stderr).finish().init();
    info!("init");

    ALLOC.set_report_usage_interval(usize::MAX).enable_stack_trace(true).set_verbose(true);
    sleep(Duration::from_millis(50));

    println!("Hello, world!");
    loop {
        something();
    }
}

'''
'''--- install.sh ---
#!/usr/bin/env bash

SCRIPT_DIR=$(dirname $(readlink -e $0))
echo $SCRIPT_DIR
if [[ $1 == "" || $1 == "rust-memory-analyzer" ]]; then
    cargo install --path "${SCRIPT_DIR}/rust-memory-analyzer" || exit 1
fi
if [[ $1 == "" || $1 == "example-target" ]]; then
    cargo install --path "${SCRIPT_DIR}/example-target" --debug || exit 1
fi

'''
'''--- near-dump-analyzer/dump.sh ---
#!/usr/bin/env bash

if [[ $1 == "" ]]; then
    echo NEAR pid = $(pidof neard)
    echo "usage ./dump.sh <PID> [TID]"
    exit 1
fi
PID=$1
TID=$2

make bins/dump
mkdir -p /tmp/dump/logs;
mkdir -p /tmp/dump/logs || true;
mkdir -p /tmp/dump/symbols || true;
pushd $(dirname $(readlink /proc/${PID}/exe))
test -f /tmp/dump/symbols/${PID} || (echo maint print psymbols | sudo gdb -p "${PID}" >> "/tmp/dump/symbols/${PID}");
test -f /tmp/dump/symbols/${PID}.m || (echo maint print msymbols | sudo gdb -p "${PID}" >> "/tmp/dump/symbols/${PID}.m");
popd
sudo ${PWD}/bins/dump "${PID}" ${TID}

'''
'''--- near-dump-analyzer/dump_every_hour.sh ---
#!/usr/bin/env bash

mkdir -p hourly_dumps

for i in {000000..1000000}; do
	echo DUMP $i
	make dump | tee hourly_dumps/dump003.$i
	sleep 300
done

'''
'''--- near-dump-analyzer/near-c-allocator-proxy.c ---
#define COUNT_BYTES

#define _GNU_SOURCE

#include <stdatomic.h>
#include <stdint.h>
#include <dlfcn.h>
#include <stddef.h>
#include <stdio.h>
#include <stdlib.h>
#include <threads.h>
#include <unistd.h>
#include <execinfo.h>
#include <sys/types.h>

const int ALLOC_LIMIT = 100;

static atomic_size_t mem_allocated_total_bytes = 0;
#define MAX_TID (1024 * 1024)

static atomic_size_t mem_allocated_bytes[MAX_TID];
thread_local FILE * file = 0;
thread_local size_t tid = 0;
thread_local int getting_trace = 0;
thread_local int last_size = 0;

#define MAGIC 0x12345678991301

struct Header {
    uint64_t magic;
    uint64_t size;
    uint64_t tid;
    uint64_t func;
};

char tmpbuff[1024];
unsigned long tmppos = 0;
unsigned long tmpallocs = 0;

void *memset(void*,int,size_t);
void *memmove(void *to, const void *from, size_t size);

/*=========================================================
 * interception points
 */

extern void * __libc_calloc(size_t nmemb, size_t size);
extern void * __libc_malloc(size_t size);
extern void   __libc_free(void *ptr);
extern void * __libc_realloc(void *ptr, size_t size);
extern void * __libc_memalign(size_t blocksize, size_t bytes);

static void *(*myfn_mmap)(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
static int (*myfn_posix_memalign)(void **memptr, size_t alignment, size_t size);
static int (*myfn_munmap)(void *addr, size_t len);

static void thread_init() {
    if (file == NULL) {
	if (tid == 0) tid = gettid();
	char buf[1000];
	sprintf(buf, "/tmp/dump/logs/%ld", tid);
	file = fopen(buf, "w");
	fprintf(file, "initializing tid: %ld\n", tid);
    }
}

#define ALIGN sizeof(struct Header)

thread_local int printing_trace = 0;

/*
 * O: 0x7fc4baef3618
O: 0x7fc4baef38cc
O: 0x560023dba768
--
O: 0x5600244dacc9
O: 0x560023009788
O: 0x7fc4baaed0b3
*/
/*
void print_trace2(void) {
    if (printing_trace) return;
    printing_trace = 1;
    char **strings;
    size_t i, size;
    enum Constexpr { MAX_SIZE = 1024 };
    void *array[MAX_SIZE];
    fprintf(stderr, "S0\n");
    size = backtrace(array, MAX_SIZE);
    fprintf(stderr, "S1\n");
    strings = backtrace_symbols(array, size);
    puts("XXYY\n");
    for (i = 0; i < size; i++)
        fprintf(stderr, "O: %s\n", strings[i]);
    puts("YY\n");
    free(strings);
    printing_trace = 0;
}
*/

void * get_trace(int64_t alloc_size) {
    if (alloc_size < ALLOC_LIMIT && (rand() % 100 != 0 && last_size == alloc_size)) {
    // if (alloc_size != 128 && alloc_size < ALLOC_LIMIT && (rand() % 100 != 0)) {
        return (void *)1;
    }
    last_size = alloc_size;

    if (getting_trace) return 0;

    getting_trace = 1;
    enum Constexpr { MAX_SIZE = 10 };
    void *array[MAX_SIZE];
    size_t i, size;
    size = backtrace(array, MAX_SIZE);
    getting_trace = 0;
    void *res = 0;
    for (i = 0; i < size; i++) {
	    res = array[i];
	    if ((size_t)array[i] < (size_t)0x700000000000) return res;
    }
    return res;
}

void print_trace3(void) {
    if (printing_trace) return;
    printing_trace = 1;
    size_t i, size;
    enum Constexpr { MAX_SIZE = 1024 };
    void *array[MAX_SIZE];
    fprintf(stderr, "S0\n");
    size = backtrace(array, MAX_SIZE);
    for (i = 0; i < size; i++)
        fprintf(stderr, "O: %p\n", array[i]);
    printing_trace = 0;
}

void *malloc(size_t size)
{

#ifdef COUNT_BYTES
    if (tid == 0) tid = gettid();
    if (size == (~(size_t)0)) {
        // hack used to report memory usage bytes from all threads
        return (void *)mem_allocated_total_bytes;
    }
    if (size == (~(size_t)0) - 1) {
        // hack used to report memory usage bytes from current thread
        return (void *)mem_allocated_bytes[tid % MAX_TID];
    }

    void *ptr = __libc_malloc(size + ALIGN);
    if (ptr)  {
        struct Header header = { MAGIC, size, tid, (size_t)get_trace(size)};
        *(struct Header*)ptr = header;
	__atomic_add_fetch(&mem_allocated_bytes[tid % MAX_TID], size, __ATOMIC_SEQ_CST);
	__atomic_add_fetch(&mem_allocated_total_bytes, size, __ATOMIC_SEQ_CST);

        return ptr + ALIGN;
    }
    return ptr;
#else
    return __libc_malloc(size);
#endif
}

void free(void *ptr)
{
#ifdef COUNT_BYTES
	if (ptr) ptr -= ALIGN;
#endif
	if (ptr && (long long)ptr % 16 != 0) {
        	fprintf(stderr, "BUG %p\n", ptr);
	}
	if (ptr && ((struct Header*)ptr)->magic != MAGIC) {
        	fprintf(stderr, "BUG_FREE %p\n", ptr);
		print_trace3();
		ptr += ALIGN;
	} else {
            if (ptr) {
    		((struct Header*)ptr)->magic += 0x100;
                size_t size = ((struct Header*)ptr)->size;
                size_t cur_tid = ((struct Header*)ptr)->tid;
		__atomic_sub_fetch(&mem_allocated_bytes[cur_tid % MAX_TID], size, __ATOMIC_SEQ_CST);
		__atomic_sub_fetch(&mem_allocated_total_bytes, size, __ATOMIC_SEQ_CST);
	    }
	}
        __libc_free(ptr);
}

void *realloc(void *ptr, size_t size)
{
#ifdef COUNT_BYTES
    if (ptr) {ptr -= ALIGN; }
#endif

#ifdef COUNT_BYTES
    if (ptr && ((struct Header*)ptr)->magic != MAGIC) {
	ptr += ALIGN;
	fprintf(stderr, "BUG_REALLOC %p\n", ptr);
        print_trace3();
        return __libc_realloc(ptr, size);
    }
    if (ptr) {
        size_t size = ((struct Header*)ptr)->size;
        size_t cur_tid = ((struct Header*)ptr)->tid;
	__atomic_sub_fetch(&mem_allocated_bytes[cur_tid % MAX_TID], size, __ATOMIC_SEQ_CST);
	__atomic_sub_fetch(&mem_allocated_total_bytes, size, __ATOMIC_SEQ_CST);
    }

    if (tid == 0) tid = gettid();
    struct Header header;

    if (ptr) {
	    header = *((struct Header*)ptr);
	    ((struct Header*)ptr)->magic += 0x100;

    } else {
    	struct Header header2 = { MAGIC, size, tid, (size_t)get_trace(size)};
	header = header2;
    }

    void *nptr = __libc_realloc(ptr, size + ALIGN);
    if (nptr) {
    	   *(struct Header*)nptr = header;
           __atomic_add_fetch(&mem_allocated_bytes[tid % MAX_TID], size, __ATOMIC_SEQ_CST);
           __atomic_add_fetch(&mem_allocated_total_bytes, size, __ATOMIC_SEQ_CST);

	   return nptr + ALIGN;
    }
    return nptr;
#else
    return __libc_realloc(ptr, size);
#endif
}

void *calloc(size_t nmemb, size_t size)
{

#ifdef COUNT_BYTES
    void *ptr = __libc_calloc(1, nmemb*size + ALIGN);
    if (tid == 0) tid = gettid();
    struct Header header = { MAGIC, size, tid, (size_t)get_trace(size)};
    *(struct Header*)ptr = header;
    return ptr + ALIGN;
#else
    return __libc_calloc(nmemb, size);
#endif
}

void *memalign(size_t blocksize, size_t bytes)
{
#ifdef COUNT_BYTES
    return malloc(blocksize * bytes);
#else
    void *ptr = __libc_memalign(blocksize, bytes);
    return ptr;
#endif
}

int posix_memalign(void **memptr, size_t alignment, size_t size)
{
    if (myfn_posix_memalign == NULL) myfn_posix_memalign = dlsym(RTLD_NEXT, "posix_memalign");

    int res = myfn_posix_memalign(memptr, alignment, size + ALIGN);
    if (tid == 0) tid = gettid();

    struct Header header = { MAGIC, size, tid, (size_t)get_trace(size)};
    *(struct Header*)*memptr = header;
    __atomic_add_fetch(&mem_allocated_bytes[tid % MAX_TID], size, __ATOMIC_SEQ_CST);
    __atomic_add_fetch(&mem_allocated_total_bytes, size, __ATOMIC_SEQ_CST);

    *memptr += ALIGN;

    return res;
}

void *valloc(size_t size) {
	fprintf(stderr, "NOT IMPLEMENTED VALLOC");
	return NULL;
}

void *alligned_alloc(size_t alignment,size_t size) {
	fprintf(stderr, "NOT IMPLEMENTED alligned_alloc");
	return NULL;
}

void *pvalloc(size_t lignment,size_t size) {
	fprintf(stderr, "NOT IMPLEMENTED pvalloc");
	return NULL;
}

void *mmap(void *addr, size_t length, int prot, int flags,
	  int fd, off_t offset) {
    if (myfn_mmap == NULL) myfn_mmap = dlsym(RTLD_NEXT, "mmap");

    	void *ptr =  myfn_mmap(addr, length, prot, flags, fd, offset);
	thread_init();
	fprintf(file, "mmap %p %ld %p %x\n", ptr, length, (void *)get_trace(length), flags);
    	fflush(file);

	return ptr;
}

int munmap(void *addr, size_t length) {
    if (myfn_munmap == NULL) myfn_munmap = dlsym(RTLD_NEXT, "munmap");

    int res = myfn_munmap(addr, length);
    thread_init();
    fprintf(file, "munmap %p %ld\n", addr, length);
    fflush(file);
    return res;
}

'''
'''--- near-rust-allocator-proxy/Cargo.toml ---
[package]
name = "near-rust-allocator-proxy"
version = "0.5.0"
authors = [
    "Near Inc <hello@nearprotocol.com>",
    "Piotr Mikulski <piotr@near.org>",
]
edition = "2021"
description = "Rust allocator proxy with added header"
readme = "README.md"
repository = "https://github.com/near/near-memory-tracker"
license = "Apache-2.0"
keywords = ["allocation", "header", "memory", "tracker"]
categories = ["memory-management"]

[dependencies]
backtrace = "0.3"
nix = ">=0.15,<=0.23"
tracing = "0.1.13"

[dev-dependencies]
criterion = "0.3.5"
serial_test = "0.5.1"
tikv-jemallocator = "0.5"
tracing-subscriber = "0.3.3"

[[bench]]
name = "allocations"
harness = false

'''
'''--- near-rust-allocator-proxy/README.md ---
Track Rust memory usage by adding a 32 bytes header to all allocations.
See https://doc.rust-lang.org/std/alloc/trait.GlobalAlloc.html

# Usage
You can use code below to enable usage of this library:
```rust
use near_rust_allocator_proxy::allocator::MyAllocator;
use jemallocator::Jemalloc;

#[global_allocator]
static ALLOC: MyAllocator<Jemalloc> = MyAllocator::new(Jemalloc);
```

# Design
* header - For each memory allocation we add a 32 bytes header. This allows figuring out how memory was allocated by looking at memory dump of the process.
* per thread memory usage stats - `thread_memory_usage(tid)` method can be used to get amount of memory allocated by thread
* `PRINT_STACK_TRACE_ON_MEMORY_SPIKE` - if set to true a stack trace will be used on memory spike

# Constants
* `ENABLE_STACK_TRACE` - if enabled `backtrace` will get executed on each allocation and stack pointer will be added to the header
* `MIN_BLOCK_SIZE` - if allocation size of below `MIN_BLOCK_SIZE`, we will only run `backtrace` `SMALL_BLOCK_TRACE_PROBABILITY` percentage of time
* `SMALL_BLOCK_TRACE_PROBABILITY` - probability of running a stack trace for small allocations
* `REPORT_USAGE_INTERVAL` - if printing memory spikes is enabled print if memory usage exceeded this value in bytes
* `PRINT_STACK_TRACE_ON_MEMORY_SPIKE` - if true print stack trace when memory usage exceeds `REPORT_USAGE_INTERVAL` on given Rust thread

# Header representation

Allocation structure:
* magic - unique 8 bytes identifier, which is used to mark memory allocations
* size - size in bytes
* tid - thread id
* stack - stack trace during time of allocation

```rust
#[repr(C)]
struct AllocHeader {
    magic: u64,
    size: u64,
    tid: u64,
    stack: [*mut c_void; STACK_SIZE],
}
```

# TODO
* Add methods to set the configuration instead of having to change the constants.
* Add tests

'''
'''--- near-rust-allocator-proxy/benches/allocations.rs ---
use near_rust_allocator_proxy::ProxyAllocator;

#[global_allocator]
static ALLOC: ProxyAllocator<tikv_jemallocator::Jemalloc> =
    ProxyAllocator::new(tikv_jemallocator::Jemalloc);
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tracing_subscriber::util::SubscriberInitExt;

fn alloc_1024(c: &mut Criterion) {
    let format = tracing_subscriber::fmt::format()
        .with_level(true) // don't include levels in formatted output
        .with_target(true) // don't include trgets
        .without_time();
    tracing_subscriber::fmt().event_format(format).finish().try_init().ok();
    ALLOC.set_verbose(false).enable_stack_trace(true);
    c.bench_function("alloc_2048", |b| {
        b.iter(|| {
            black_box(Vec::<u8>::with_capacity(1024));
        })
    });
}

fn alloc_32(c: &mut Criterion) {
    let format = tracing_subscriber::fmt::format()
        .with_level(true) // don't include levels in formatted output
        .with_target(true) // don't include targets
        .without_time();
    tracing_subscriber::fmt().event_format(format).finish().try_init().ok();
    ALLOC.set_verbose(false).enable_stack_trace(true);
    c.bench_function("alloc_32", |b| {
        b.iter(|| {
            black_box(Vec::<u8>::with_capacity(32));
        })
    });
}

criterion_group!(benches, alloc_32, alloc_1024);
criterion_main!(benches);
/*
alloc_32                time:   [38.494 ns 38.525 ns 38.557 ns]
alloc_1024              time:   [2.0461 us 2.0477 us 2.0494 us]
 */

'''
'''--- near-rust-allocator-proxy/src/allocator.rs ---
use backtrace::Backtrace;
use std::alloc::{GlobalAlloc, Layout};
use std::cell::Cell;
use std::os::raw::c_void;
use std::ptr::null_mut;
use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
use tracing::info;

const MEBIBYTE: usize = 1 << 20;
/// Skip addresses that are above this value.
const SKIP_ADDR_ABOVE: *mut c_void = 0x7000_0000_0000 as *mut c_void;
/// Configure how often should we print stack trace, whenever new record is reached.
pub(crate) static REPORT_USAGE_INTERVAL: AtomicUsize = AtomicUsize::new(usize::MAX);
/// Should be a configurable option.
pub(crate) static ENABLE_STACK_TRACE: AtomicBool = AtomicBool::new(false);
pub(crate) static VERBOSE: AtomicBool = AtomicBool::new(false);

const COUNTERS_SIZE: usize = 16384;
static MEM_SIZE: [AtomicUsize; COUNTERS_SIZE] = unsafe {
    // SAFETY: Rust [guarantees](https://doc.rust-lang.org/stable/std/sync/atomic/struct.AtomicUsize.html)
    // that `usize` and `AtomicUsize` have the same representation.
    std::mem::transmute::<[usize; COUNTERS_SIZE], [AtomicUsize; COUNTERS_SIZE]>(
        [0_usize; COUNTERS_SIZE],
    )
};
static MEM_CNT: [AtomicUsize; COUNTERS_SIZE] = unsafe {
    std::mem::transmute::<[usize; COUNTERS_SIZE], [AtomicUsize; COUNTERS_SIZE]>(
        [0_usize; COUNTERS_SIZE],
    )
};

const CACHE_SIZE: usize = 1 << 20;
static mut SKIP_CACHE: [u8; CACHE_SIZE] = [0; CACHE_SIZE];
static mut CHECKED_CACHE: [u8; CACHE_SIZE] = [0; CACHE_SIZE];

// TODO: Make stack size configurable
const STACK_SIZE: usize = 1;

// TODO: Store stack size
// MAYBE: Make: tid: u16
// MAYBE: split magic into two u32
// MAYBE: make size u32
// MAYBE: make stack list of [u32] to save memory - maybe?
#[derive(Debug)]
#[repr(C)]
pub struct AllocHeader {
    // TODO (magic should be split in two parts, at front and back)
    magic: usize,
    size: usize,
    tid: usize,
    stack: [*mut c_void; STACK_SIZE],
}

impl AllocHeader {
    unsafe fn new(layout: Layout, tid: usize) -> Self {
        Self {
            magic: MAGIC_RUST + STACK_SIZE,
            size: layout.size(),
            tid,
            stack: [null_mut::<c_void>(); STACK_SIZE],
        }
    }

    #[must_use]
    pub fn size(&self) -> usize {
        self.size
    }

    #[must_use]
    pub fn tid(&self) -> usize {
        self.tid
    }

    #[must_use]
    pub fn stack(&self) -> &[*mut c_void; STACK_SIZE] {
        &self.stack
    }

    #[must_use]
    pub fn valid(&self) -> bool {
        self.is_allocated() || self.is_freed()
    }

    #[must_use]
    pub fn is_allocated(&self) -> bool {
        self.magic == (MAGIC_RUST + STACK_SIZE)
    }

    #[must_use]
    pub fn is_freed(&self) -> bool {
        self.magic == MAGIC_RUST + STACK_SIZE + FREED_MAGIC
    }

    pub fn mark_as_freed(&mut self) {
        self.magic = MAGIC_RUST + STACK_SIZE + FREED_MAGIC;
    }
}

const MAGIC_RUST: usize = 0x12_3456_7899_1100;
const FREED_MAGIC: usize = 0x100;

thread_local! {
    static TID: Cell<usize> = Cell::new(0);
    static MEMORY_USAGE_MAX: Cell<usize> = Cell::new(0);
    static MEMORY_USAGE_LAST_REPORT: Cell<usize> = Cell::new(0);
    static NUM_ALLOCATIONS: Cell<usize> = Cell::new(0);
    static IN_TRACE: Cell<usize> = Cell::new(0);
}

#[must_use]
pub fn get_tid() -> usize {
    TID.with(|f| {
        let mut v = f.get();
        if v == 0 {
            // thread::current().id().as_u64() is still unstable
            #[cfg(target_os = "linux")]
            {
                v = nix::unistd::gettid().as_raw() as usize;
            }
            #[cfg(not(target_os = "linux"))]
            {
                static NTHREADS: AtomicUsize = AtomicUsize::new(0);
                v = NTHREADS.fetch_add(1, Ordering::Relaxed) as usize;
            }
            f.set(v)
        }
        v
    })
}

fn murmur64(mut h: u64) -> u64 {
    h ^= h >> 33;
    h = h.overflowing_mul(0xff51_afd7_ed55_8ccd).0;
    h ^= h >> 33;
    h = h.overflowing_mul(0xc4ce_b9fe_1a85_ec53).0;
    h ^= h >> 33;
    h
}

/// TODO: Consider making this configurable
const IGNORE_START: &[&str] = &[
    "__rg_",
    "_ZN10tokio_util",
    "_ZN20reed_solomon_erasure",
    "_ZN3std",
    "_ZN4core",
    "_ZN5actix",
    "_ZN5alloc",
    "_ZN5bytes",
    "_ZN5tokio",
    "_ZN6base64",
    "_ZN6cached",
    "_ZN8smallvec",
    "_ZN9backtrace9backtrace",
    "_ZN9hashbrown",
];

/// TODO: Consider making this configurable
const IGNORE_INSIDE: &[&str] = &[
    "$LT$actix..",
    "$LT$alloc..",
    "$LT$base64..",
    "$LT$cached..",
    "$LT$core..",
    "$LT$hashbrown..",
    "$LT$reed_solomon_erasure..",
    "$LT$serde_json..",
    "$LT$std..",
    "$LT$tokio..",
    "$LT$tokio_util..",
    "$LT$tracing_subscriber..",
    "allocator",
];

fn skip_ptr(addr: *mut c_void) -> bool {
    let mut found = false;
    backtrace::resolve(addr, |symbol| {
        found = found
            || symbol
                .name()
                .and_then(|name| name.as_str())
                .map(|name| {
                    IGNORE_START.iter().filter(|s: &&&str| name.starts_with(**s)).any(|_| true)
                        || IGNORE_INSIDE.iter().filter(|s: &&&str| name.contains(**s)).any(|_| true)
                })
                .unwrap_or_default()
    });

    found
}

#[must_use]
pub fn total_memory_usage() -> usize {
    MEM_SIZE.iter().map(|v| v.load(Ordering::Relaxed)).sum()
}

pub fn current_thread_memory_usage() -> usize {
    let tid = get_tid();

    MEM_SIZE[tid % COUNTERS_SIZE].load(Ordering::Relaxed)
}

pub fn thread_memory_usage(tid: usize) -> usize {
    MEM_SIZE[tid % COUNTERS_SIZE].load(Ordering::Relaxed)
}

pub fn thread_memory_count(tid: usize) -> usize {
    MEM_CNT[tid % COUNTERS_SIZE].load(Ordering::Relaxed)
}

pub fn current_thread_peak_memory_usage() -> usize {
    MEMORY_USAGE_MAX.with(Cell::get)
}

pub fn reset_memory_usage_max() {
    let tid = get_tid();
    let memory_usage = MEM_SIZE[tid % COUNTERS_SIZE].load(Ordering::Relaxed);
    MEMORY_USAGE_MAX.with(|x| x.set(memory_usage));
}

pub struct ProxyAllocator<A> {
    inner: A,
}

impl<A> ProxyAllocator<A> {
    pub const fn new(inner: A) -> Self {
        Self { inner }
    }

    /// Enable calling `backtrace` to fill out data
    pub fn enable_stack_trace(&self, value: bool) -> &Self {
        ENABLE_STACK_TRACE.store(value, Ordering::Relaxed);
        self
    }

    pub fn set_report_usage_interval(&self, value: usize) -> &Self {
        REPORT_USAGE_INTERVAL.store(value, Ordering::Relaxed);
        self
    }

    pub fn set_verbose(&self, value: bool) -> &Self {
        VERBOSE.store(value, Ordering::Relaxed);
        self
    }
}

unsafe impl<A: GlobalAlloc> GlobalAlloc for ProxyAllocator<A> {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let verbose = VERBOSE.load(Ordering::Relaxed);
        let tid = get_tid();
        let memory_usage = MEM_SIZE[tid % COUNTERS_SIZE]
            .fetch_add(layout.size(), Ordering::Relaxed)
            + layout.size();

        MEM_CNT[tid % COUNTERS_SIZE].fetch_add(1, Ordering::Relaxed);

        MEMORY_USAGE_MAX.with(|val| {
            if val.get() < memory_usage {
                val.set(memory_usage);
            }
        });

        let mut header = AllocHeader::new(layout, tid);

        IN_TRACE.with(|in_trace| {
            if in_trace.replace(1) != 0 {
                // Allocation happening within alloc due to backtrace.
                header.stack[0] = usize::MAX as *mut c_void;
                return;
            }
            Self::print_stack_trace_on_memory_spike(layout, tid, memory_usage);
            if ENABLE_STACK_TRACE.load(Ordering::Relaxed) {
                Self::compute_stack_trace(layout, &mut header.stack, verbose);
            }
            if verbose {
                tracing::info!(?header);
            }
            in_trace.set(0);
        });

        let (new_layout, offset) = Layout::new::<AllocHeader>().extend(layout).unwrap();

        let res = self.inner.alloc(new_layout);
        *res.cast::<AllocHeader>() = header;

        res.add(offset)
    }

    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        let (new_layout, offset) = Layout::new::<AllocHeader>().extend(layout).unwrap();

        let ptr = ptr.sub(offset);

        let ah = &mut (*(ptr.cast::<AllocHeader>()));
        debug_assert!(ah.is_allocated());
        ah.mark_as_freed();
        let header_tid = ah.tid;

        MEM_SIZE[header_tid % COUNTERS_SIZE].fetch_sub(layout.size(), Ordering::Relaxed);
        MEM_CNT[header_tid % COUNTERS_SIZE].fetch_sub(1, Ordering::Relaxed);

        self.inner.dealloc(ptr, new_layout);
    }
}

impl<A: GlobalAlloc> ProxyAllocator<A> {
    unsafe fn print_stack_trace_on_memory_spike(layout: Layout, tid: usize, memory_usage: usize) {
        MEMORY_USAGE_LAST_REPORT.with(|memory_usage_last_report| {
            if memory_usage
                > REPORT_USAGE_INTERVAL
                    .load(Ordering::Relaxed)
                    .saturating_add(memory_usage_last_report.get())
            {
                memory_usage_last_report.set(memory_usage);
                tracing::warn!(
                    tid,
                    memory_usage_mb = memory_usage / MEBIBYTE,
                    added_mb = layout.size() / MEBIBYTE,
                    bt = ?Backtrace::new(),
                    "reached new record of memory usage",
                );
            }
        });
    }
}

impl<A: GlobalAlloc> ProxyAllocator<A> {
    #[inline]
    unsafe fn compute_stack_trace(
        layout: Layout,
        stack: &mut [*mut c_void; STACK_SIZE],
        verbose: bool,
    ) {
        if Self::should_compute_trace(layout) {
            const MISSING_TRACE: *mut c_void = 2 as *mut c_void;
            stack[0] = MISSING_TRACE;
            backtrace::trace(|frame| {
                let addr = frame.ip();
                stack[0] = addr.cast::<c_void>();
                if addr >= SKIP_ADDR_ABOVE.cast::<c_void>() {
                    true
                } else {
                    let hash = (murmur64(addr as u64) % (8 * CACHE_SIZE as u64)) as usize;
                    let i = hash / 8;
                    let cur_bit = 1 << (hash % 8);
                    if SKIP_CACHE[i] & cur_bit != 0 {
                        true
                    } else if CHECKED_CACHE[i] & cur_bit != 0 {
                        false
                    } else if skip_ptr(addr) {
                        SKIP_CACHE[i] |= cur_bit;
                        true
                    } else {
                        CHECKED_CACHE[i] |= cur_bit;
                        false
                    }
                }
            });
            if verbose {
                info!(?stack, "STARTED_TRACE");
            }
        } else if verbose {
            info!(?layout, "TRACING SKIPPED");
        }
    }

    unsafe fn should_compute_trace(layout: Layout) -> bool {
        match layout.size() {
            // 1% of the time
            0..=999 => {
                (murmur64(NUM_ALLOCATIONS.with(|key| {
                    // key.update() is still unstable
                    let val = key.get();
                    key.set(val + 1);
                    val
                }) as u64)
                    % 1024)
                    < 10
            }
            // 100%
            _ => true,
        }
    }
}

pub fn print_memory_stats() {
    tracing::info!(tid = get_tid(), "tid");
    let mut total_cnt: usize = 0;
    let mut total_size: usize = 0;
    for idx in 0..COUNTERS_SIZE {
        let val = MEM_SIZE[idx].load(Ordering::Relaxed);
        if val != 0 {
            let cnt = MEM_CNT[idx].load(Ordering::Relaxed);
            total_cnt += cnt;
            total_size += val;

            tracing::info!(idx, cnt, val, "COUNTERS");
        }
    }
    tracing::info!(total_cnt, total_size, "COUNTERS TOTAL");
}

#[cfg(test)]
mod test {
    use crate::allocator::{print_memory_stats, total_memory_usage, ProxyAllocator};
    use crate::AllocHeader;
    use std::alloc::{GlobalAlloc, Layout};
    use std::mem;
    use std::ptr::null_mut;
    use tracing_subscriber::util::SubscriberInitExt;

    #[test]
    fn test_print_counters_ary() {
        tracing_subscriber::fmt().with_writer(std::io::stderr).finish().init();
        print_memory_stats();
    }

    static ALLOC: ProxyAllocator<tikv_jemallocator::Jemalloc> =
        ProxyAllocator::new(tikv_jemallocator::Jemalloc);

    #[test]
    #[serial_test::serial]
    // Works only if run alone.
    fn test_allocator() {
        let layout = Layout::from_size_align(32, 1).unwrap();
        let ptr = unsafe { ALLOC.alloc(layout) };
        assert_ne!(ptr, null_mut());

        assert_eq!(total_memory_usage(), 32);

        unsafe { ALLOC.dealloc(ptr, layout) };
    }

    #[test]
    #[serial_test::serial]
    fn test_alignment() {
        for alloc in (0..16).map(|i| i << 1) {
            for alignment in (0..16).map(|i| 1 << i) {
                let layout = Layout::from_size_align(alloc, alignment).unwrap();
                let ptr = unsafe { ALLOC.alloc(layout) };
                assert_ne!(ptr, null_mut());

                assert_eq!(ptr as usize % alignment, 0);

                unsafe { ALLOC.dealloc(ptr, layout) };
            }
        }
    }

    #[test]
    #[serial_test::serial]
    fn test_alignment_with_offset() {
        let header_size = mem::size_of::<AllocHeader>();
        for alloc in (0..16).map(|i| i << 1).filter(|&alloc| alloc > header_size) {
            for alignment in (0..16).map(|i| 1 << i).filter(|&p| p >= header_size) {
                let layout = Layout::from_size_align(alloc - header_size, alignment).unwrap();
                let ptr = unsafe { ALLOC.alloc(layout) };
                assert_ne!(ptr, null_mut());

                assert_eq!(ptr as usize % alignment, 0);

                unsafe { ALLOC.dealloc(ptr, layout) };
            }
        }
    }
}

'''
'''--- near-rust-allocator-proxy/src/lib.rs ---
mod allocator;

pub use allocator::{
    current_thread_memory_usage, current_thread_peak_memory_usage, get_tid, print_memory_stats,
    reset_memory_usage_max, thread_memory_count, thread_memory_usage, total_memory_usage,
    AllocHeader, ProxyAllocator,
};

'''
'''--- run_example.sh ---
#!/usr/bin/env bash

set -ve

SCRIPT_DIR=$(dirname $(readlink -e $0))

# Install all binaries
${SCRIPT_DIR}/install.sh

# kill previous
pkill example-target || echo "nothing to kill"

# Start example, which uses 8gb of ram
example-target &
sleep 10

# Measure memory usage
sudo $(which rust-memory-analyzer) analyze --pid `pidof example-target`

'''
'''--- rust-memory-analyzer/Cargo.toml ---
[package]
name = "rust-memory-analyzer"
version = "0.1.0"
authors = [
    "Near Inc <hello@nearprotocol.com>",
    "Piotr Mikulski <piotr@near.org>",
]
edition = "2021"
description = "Rust memory analyzer"
readme = "README.md"
repository = "https://github.com/near/near-memory-tracker"
license = "Apache-2.0"
keywords = ["allocation", "header", "memory", "tracker"]
categories = ["memory-management"]

[dependencies]
anyhow = "1.0.51"
clap = "=3.0.0-rc.7"
clap_derive = "=3.0.0-rc.7"
itertools = { version = "0.10.3", features = ["use_alloc", "use_std"] }
near-rust-allocator-proxy = "0.4.0"
nix = "0.23.1"
rustc-demangle = "=0.1.21"
tracing = "0.1.29"
tracing-subscriber = "0.3.3"

'''
'''--- rust-memory-analyzer/README.md ---

'''
'''--- rust-memory-analyzer/src/analyze.rs ---
use crate::symbols::get_symbols;
use crate::utils::{compute_present_pages, get_page_size, read_smaps, Counter, Smap, MIB};
use anyhow::Context;
use itertools::Itertools;
use near_rust_allocator_proxy::AllocHeader;
use nix::sys::uio::{IoVec, RemoteIoVec};
use nix::unistd::Pid;
use std::collections::HashMap;
use std::ffi::c_void;
use std::fs;
use std::fs::File;
use std::ops::Not;
use std::path::PathBuf;
use std::time::Instant;
use tracing::{debug, error, info};

#[derive(clap_derive::Parser, Debug)]
pub(crate) struct AnalyzeCmd {
    #[clap(long)]
    pid: i32,
    #[clap(long)]
    print_raw_symbols: bool,
    #[clap(long, conflicts_with("print_raw_symbols"))]
    print_ptr: bool,
}

impl AnalyzeCmd {
    pub(crate) fn handle(&self) -> anyhow::Result<()> {
        info!(?self.pid);
        let smaps = read_smaps(self.pid).with_context(|| "read_smaps failed")?;

        let start = Instant::now();
        let page_map_file = PathBuf::from("/proc").join(self.pid.to_string()).join("pagemap");
        let mut file = File::open(page_map_file.clone())
            .with_context(|| format!("page_map_file not found file={:?}", page_map_file))?;

        let page_size = get_page_size()?;
        info!(?page_size);

        let proc_exe_path = PathBuf::from("/proc").join(self.pid.to_string()).join("exe");
        info!(?proc_exe_path);
        let exe_path = fs::read_link(proc_exe_path).with_context(|| "unable to read exe path")?;
        info!(?exe_path);

        let mmaped_exec = Self::get_mmaped_exe_regions(&smaps, exe_path.clone());
        info!(mapped_exec_len = ?mmaped_exec.len());
        // compute memory used in not mmaped files

        let mut ptr_2_memory: HashMap<*mut c_void, Counter> = HashMap::new();

        info!("Reading pages.");
        let mut buffer = vec![0u8; page_size + std::mem::size_of::<AllocHeader>()];

        let not_mmaped_pages: Vec<_> =
            compute_present_pages(&smaps, &mut file, page_size, false)?.to_vec();
        let total_present_pages: usize = not_mmaped_pages.iter().map(|x| (x.1.len())).sum();
        info!("Read pages.");
        for (smap, addresses) in not_mmaped_pages.iter() {
            debug!(?smap, len = addresses.len());
            assert_eq!((smap.to - smap.from) % page_size, 0, "pages not multiple of {}", page_size);

            for ad in addresses {
                let input = [IoVec::from_mut_slice(buffer.as_mut_slice())];
                let output = [RemoteIoVec { base: *ad, len: page_size }];

                nix::sys::uio::process_vm_readv(Pid::from_raw(self.pid), &input, &output)?;
                // TODO: Allocation headers, which are split between 2 consecutive pages are not counter correctly.
                for val in (0..page_size / 8).map(|v| v * 8) {
                    let ah = unsafe {
                        &mut *(buffer.as_mut_slice()[val..].as_ptr() as *mut AllocHeader)
                    };
                    if ah.is_allocated() {
                        let ptr = ah.stack()[0];
                        if ptr != usize::MAX as *mut c_void
                            && ptr.is_null().not()
                            && ah.size() < u32::MAX as usize
                        {
                            *ptr_2_memory.entry(ptr).or_default() += Counter::with_size(ah.size());
                        }
                    }
                }
            }
        }
        info!("Getting exe path");

        let str_exe_path = exe_path.to_str().unwrap();
        info!(?str_exe_path, "Getting symbols.");
        let symbols = get_symbols(str_exe_path)?;
        info!(symbols = symbols.len());

        let mut func_2_mem: HashMap<String, Counter> = HashMap::new();
        let present_allocated_with_proxy = ptr_2_memory.iter().map(|x| x.1.size).sum();
        for (ptr, val) in ptr_2_memory.iter() {
            let symbol_mappings = (mmaped_exec.iter())
                .filter(|x| ((x.from as *mut c_void) <= (*ptr)) && ((*ptr as usize) < x.to))
                .filter_map(|smap| {
                    let file_offset = (*ptr as usize) - smap.from + smap.offset;

                    if let Some(last_sym) =
                        symbols.iter().filter(|s| s.offset <= file_offset).last()
                    {
                        let key = if self.print_ptr {
                            format!("{:?}", ptr)
                        } else if self.print_raw_symbols {
                            last_sym.raw_symbol.clone()
                        } else {
                            last_sym.symbol.clone()
                        };
                        Some((key, val))
                    } else {
                        None
                    }
                })
                .collect_vec();
            if symbol_mappings.is_empty() {
                error!(?ptr, "couldn't resolve ptr");
                *func_2_mem.entry(format!("{:?}", ptr)).or_default() += *val;
            } else if symbol_mappings.len() > 1 {
                error!(?ptr, symbols = ?symbol_mappings.iter().take(10).collect_vec(), "multiple symbols mapped");
                *func_2_mem.entry(format!("{:?}", ptr)).or_default() += *val;
            }
            for (key, val) in symbol_mappings.into_iter().take(1) {
                *func_2_mem.entry(key).or_default() += *val;
            }
        }
        info!("Results");
        let mut func_2_mem: Vec<_> = func_2_mem.iter().collect();
        func_2_mem.sort_by(|x, y| x.1.size.partial_cmp(&y.1.size).unwrap());
        for (func, counter) in func_2_mem.iter().filter(|c| c.1.size >= MIB) {
            info!(?func, count = counter.cnt, size_mb = counter.size / MIB);
        }

        let mapped_file_pages: usize = compute_present_pages(&smaps, &mut file, page_size, true)
            .with_context(|| "compute_present_pages")?
            .iter()
            .map(|x| x.1.len())
            .sum();
        let mapped_files_mb = mapped_file_pages * (page_size as usize) / MIB;
        let resident_but_not_used_mb = ((total_present_pages * (page_size as usize))
            .saturating_sub(present_allocated_with_proxy))
            / MIB;
        let total_size_mb =
            resident_but_not_used_mb + present_allocated_with_proxy / MIB + mapped_files_mb;
        info!(took = ?start.elapsed(), total_size_mb);

        info!(took = ?start.elapsed(), resident_but_not_used_mb, allocated_with_proxy_mb = present_allocated_with_proxy / MIB, mapped_files_mb);
        Ok(())
    }

    fn get_mmaped_exe_regions(smaps: &[Smap], exe_path: PathBuf) -> Vec<Smap> {
        let mut mmaped_exec = Vec::new();
        for smap in smaps.iter().filter(|x| x.mapped_file.is_some()) {
            if let Some(x) = &smap.mapped_file {
                if x.as_str() == exe_path.to_str().unwrap() {
                    info!(?smap);
                    mmaped_exec.push(smap.clone());
                }
            }
        }
        mmaped_exec
    }
}

'''
'''--- rust-memory-analyzer/src/main.rs ---
mod analyze;
mod mem_used;
mod opts;
mod symbols;
mod utils;

use crate::opts::SubCommand;
use anyhow::Context;
use clap::Parser;
use tracing::info;
use tracing_subscriber::util::SubscriberInitExt;

fn main() -> anyhow::Result<()> {
    let format = tracing_subscriber::fmt::format()
        .with_level(true) // don't include levels in formatted output
        .with_target(true) // don't include targets
        .without_time();

    tracing_subscriber::fmt().event_format(format).with_writer(std::io::stderr).finish().init();
    info!("init");
    let opts = crate::opts::Opts::parse();

    info!(?opts.subcmd);
    match opts.subcmd {
        SubCommand::Analyze(cmd) => cmd.handle().with_context(|| "analyze_cmd failed")?,
        SubCommand::MemUsed(cmd) => cmd.handle().with_context(|| "query_cmd failed")?,
        SubCommand::Symbols(cmd) => cmd.handle().with_context(|| "symbols_cmd failed")?,
    };
    Ok(())
}

'''
'''--- rust-memory-analyzer/src/mem_used.rs ---
use crate::utils;
use anyhow::Context;
use std::fs::File;
use std::path::PathBuf;
use std::time::Instant;
use tracing::info;

#[derive(clap_derive::Parser, Debug)]
pub(crate) struct MemUsedCmd {
    #[clap(long)]
    pid: i32,
}

impl MemUsedCmd {
    pub(crate) fn handle(&self) -> anyhow::Result<()> {
        info!(?self.pid);
        let smaps = utils::read_smaps(self.pid).with_context(|| "read_smaps failed")?;

        let mut total_present_pages = 0;
        let start = Instant::now();
        let page_map_file = PathBuf::from("/proc").join(self.pid.to_string()).join("pagemap");
        let mut file = File::open(page_map_file.clone())
            .with_context(|| format!("page_map_file not found file={:?}", page_map_file))?;

        let page_size = utils::get_page_size()?;

        for (smap, addresses) in
            utils::compute_present_pages(&smaps, &mut file, page_size, false)?.iter()
        {
            info!(?smap, len = addresses.len());
            total_present_pages += addresses.len();
        }
        // compute memory used in not mmaped files
        info!(mem_used_mb = total_present_pages * page_size / crate::utils::MIB, total_present_pages, took = ?start.elapsed());
        Ok(())
    }
}

#[cfg(test)]
mod test {
    use crate::utils::get_page_size;
    use tracing_subscriber::util::SubscriberInitExt;

    #[cfg(target_arch = "x86_64")]
    #[test]
    fn test_get_size() {
        tracing_subscriber::fmt().with_writer(std::io::stderr).finish().init();
        assert_eq!(get_page_size().ok(), Some(4096));
    }
}

'''
'''--- rust-memory-analyzer/src/opts.rs ---
use crate::analyze::AnalyzeCmd;
use crate::mem_used::MemUsedCmd;
use crate::symbols::SymbolsCmd;
use clap::AppSettings;

#[derive(clap_derive::Parser, Debug)]
#[clap(version = "0.1")]
#[clap(setting = AppSettings::SubcommandRequiredElseHelp)]
pub(crate) struct Opts {
    #[clap(subcommand)]
    pub subcmd: SubCommand,
}

#[derive(clap_derive::Parser, Debug)]
pub(super) enum SubCommand {
    MemUsed(MemUsedCmd),
    Analyze(AnalyzeCmd),
    Symbols(SymbolsCmd),
}

'''
'''--- rust-memory-analyzer/src/symbols.rs ---
use rustc_demangle::demangle;
use std::process::{Command, Stdio};
use std::usize;
use tracing::info;

#[derive(clap_derive::Parser, Debug)]
pub(crate) struct SymbolsCmd {
    #[clap(long)]
    binary_path: String,
}

#[allow(unused)]
#[derive(Debug)]
pub struct Symbol {
    pub offset: usize,
    pub unk: String,
    pub raw_symbol: String,
    pub symbol: String,
}

impl SymbolsCmd {
    pub(crate) fn handle(&self) -> anyhow::Result<()> {
        for symbol in get_symbols(&self.binary_path)? {
            info!(symbol = ?symbol);
        }
        Ok(())
    }
}

pub fn get_symbols(binary_path: &str) -> anyhow::Result<Vec<Symbol>> {
    let output = (Command::new("nm").arg("-an").arg(binary_path))
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .output()?;
    Ok(String::from_utf8_lossy(output.stdout.as_slice())
        .split('\n')
        .map(|line| line.split(' ').collect::<Vec<_>>())
        .filter(|s| s.len() >= 3)
        .map(|split| Symbol {
            offset: usize::from_str_radix(split[0], 16).unwrap_or_default(),
            unk: split[1].to_string(),
            raw_symbol: split[2].to_string(),
            symbol: demangle(split[2]).to_string(),
        })
        .collect())
}

'''
'''--- rust-memory-analyzer/src/utils.rs ---
use anyhow::Context;
use std::fs::File;
use std::io::{BufRead, Read, Seek, SeekFrom};
use std::ops::AddAssign;
use std::path::{Path, PathBuf};
use std::{io, usize};
use tracing::{debug, info};

pub const MIB: usize = 1 << 20;

pub fn read_lines(file_name: impl AsRef<Path>) -> anyhow::Result<impl Iterator<Item = String>> {
    let file = File::open(file_name)?;
    Ok(io::BufReader::new(file).lines().map_while(|x| x.ok()))
}

pub fn read_smaps(pid: i32) -> anyhow::Result<Vec<Smap>> {
    let path = PathBuf::from("/proc").join(pid.to_string()).join("smaps");
    info!(?path);
    Ok(read_lines(path.clone())
        .with_context(|| format!("cant open path={:?}", &path))?
        .map(|l| (l.split(' ').map(|s| s.to_string()).collect::<Vec<_>>(), l))
        .filter(|(s, _)| s.len() >= 3 && s[0].contains('-'))
        .map(|(sp, line)| {
            let (addresses, _flags, offset) = (&sp[0], &sp[1], &sp[2]);

            let split = addresses.split_once('-').unwrap();
            Smap {
                from: usize::from_str_radix(split.0, 16).unwrap_or_default(),
                to: usize::from_str_radix(split.1, 16).unwrap_or_default(),
                mapped_file: if line.len() > 73 { Some(line[73..].to_string()) } else { None },
                is_stack: false,
                offset: usize::from_str_radix(offset, 16).unwrap_or_default(),
            }
        })
        .collect())
}

/// 4096 on `x86_64` linux
pub fn get_page_size() -> anyhow::Result<usize> {
    let res = std::process::Command::new("getconf")
        .arg("PAGESIZE")
        .output()
        .expect("failed to execute process");

    Ok(String::from_utf8(res.stdout)?.trim_end().parse()?)
}

#[derive(Debug, Default, Copy, Clone)]
pub struct Counter {
    pub cnt: usize,
    pub size: usize,
}

impl Counter {
    pub fn with_size(size: usize) -> Self {
        Self { cnt: 1, size }
    }
}

impl AddAssign for Counter {
    fn add_assign(&mut self, other: Self) {
        *self = Self { cnt: self.cnt + other.cnt, size: self.size + other.size };
    }
}

#[derive(Debug, Clone)]
pub struct Smap {
    pub from: usize,
    pub to: usize,
    pub mapped_file: Option<String>,
    #[allow(unused)]
    is_stack: bool,
    pub offset: usize,
}

pub fn compute_present_pages(
    smaps: &[Smap],
    file: &mut File,
    page_size: usize,
    mapped: bool,
) -> anyhow::Result<Vec<(Smap, Vec<usize>)>> {
    let mut res = Vec::new();
    for smap in smaps.iter().filter(|s| s.mapped_file.is_some() == mapped) {
        // Verify that all memory regions are divided into pages.
        file.seek(SeekFrom::Start((smap.from / page_size * PAGE_MAP_ENTRY_SIZE) as u64))?;
        let entries = (smap.to - smap.from) / page_size;
        let mut x: Vec<u8> = Vec::new();
        x.resize(entries * PAGE_MAP_ENTRY_SIZE, 0);

        let read = file.read(x.as_mut_slice()).with_context(|| "read_exact")?;
        if read != entries {
            debug!(read, entries, "didn't ready the buffer completely");
        }
        let present_count: Vec<usize> = (0..entries)
            .filter(|i| x[8 * i + 7] & (1 << 7) != 0)
            .map(|i| smap.from + i * page_size)
            .collect();
        res.push((smap.clone(), present_count));
    }
    Ok(res)
}

// https://www.kernel.org/doc/Documentation/vm/pagemap.txt
const PAGE_MAP_ENTRY_SIZE: usize = std::mem::size_of::<u64>();

'''
'''--- rust-toolchain.toml ---
[toolchain]
channel = "1.72.0"
components = [ "rustfmt", "clippy" ]

'''
'''--- rustfmt.toml ---
use_small_heuristics = "Max"
reorder_imports = true
edition = "2021"
# This option will merge imports, however it's only available in +nightly.
# imports_granularity = "Module"
# fn_args_density = "Compressed"
# overflow_delimited_expr = "true"

'''