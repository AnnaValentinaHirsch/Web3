*GitHub Repository "puzzle-com/filesys-rust"*

'''--- ATTRIBUTIONS.md ---
# NEAR Client Attributions

We have taken inspiration and few pieces of code from:
 * [Parity Ethereum](https://github.com/paritytech/parity-ethereum)
 * [Parity Substrate](https://github.com/paritytech/substrate)
 * [Parity Trie](https://github.com/paritytech/trie)

## Licenses

### Parity {Ethereum, Substrate}

                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    {one line to give the program's name and a brief idea of what it does.}
    Copyright (C) {year}  {name of author}

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    {project}  Copyright (C) {year}  {fullname}
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<http://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<http://www.gnu.org/philosophy/why-not-lgpl.html>.

### Parity Trie

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

'''
'''--- Cargo.toml ---
cargo-features = ["profile-overrides"]

[package]
name = "nearcore"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[workspace]
members = [
    "async-utils/",
    "protos/builder",
    "core/primitives",
    "core/store",
    "runtime/runtime",
    "runtime/wasm",
    "runtime/wasm/runtest",
    "chain/chain",
    "chain/pool",
    "chain/client",
    "chain/network",
    "chain/jsonrpc",
    "test-utils/keystore",
    "test-utils/testlib",
    "test-utils/loadtester",
    "test-utils/state-viewer",
    "near/",
]
exclude = [
    "runtime/wasm/runtest/generate-wasm/to-wasm",
]

[dev-dependencies]
actix = "0.8.2"
lazy_static = "1.2.0"
log = "0.4.6"
rand = "0.6"
serde_json = "1.0.0"
reqwest = "0.9"
futures = "0.1.25"

near-protos = { path = "./core/protos" }
near-primitives = { path = "./core/primitives" }
near-store = { path = "./core/store" }

node-runtime = { path = "./runtime/runtime" }
wasm = { path = "./runtime/wasm" }

near-jsonrpc = { path = "./chain/jsonrpc" }
near-network = { path = "./chain/network" }

near = { path = "./near"}

testlib = { path = "./test-utils/testlib" }
keystore = { path = "./test-utils/keystore" }

[profile.release]
lto = true        # Enable full link-time optimization.
codegen-units = 1 # Use only 1 codegen-unit to enable full optimizations.

[profile.bench]
lto = true
codegen-units = 1 # Use only 1 codegen-unit to enable full optimizations.

[profile.dev.overrides.pairing]
opt-level = 3 # pairing library is too slow to use in debug

[profile.dev.overrides.bs58]
opt-level = 3 # bs58 library is too slow to use in debug

[features]
expensive_tests = []
regression_tests = []
old_tests = []

'''
'''--- README.md ---
<img src="" width="200px" align="right" />

## FileSys - scalable and usable blockchain,Official Rust implementation of the FileSys protocol

'''
'''--- async-utils/Cargo.toml ---
[package]
name = "async-utils"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
futures03 = { package = "futures-preview", version = "0.3.0-alpha.16", features = ["compat", "async-await", "nightly"] }
tokio = "0.1.15"

'''
'''--- async-utils/src/lib.rs ---
#![feature(await_macro, async_await)]

use std::time::{Duration, Instant};

use futures03::{compat::Future01CompatExt as _, FutureExt as _};

/// This macro is extracted from
/// https://github.com/rust-lang-nursery/futures-rs/blob/c30adf513b9eea35ab385c0797210c77986fc82f/futures/src/lib.rs#L503-L510
///
/// It is useful when the `futures-preview` is imported as `futures03`.
macro_rules! select { // replace `::futures_util` with `::futures03` as the crate path
    ($($tokens:tt)*) => {
        futures03::inner_select::select! {
            futures_crate_path ( ::futures03 )
            $( $tokens )*
        }
    }
}

/// An async/await helper to delay the execution:
///
/// ```ignore
/// let _ = delay(std::time::Duration::from_secs(1)).await;
/// ```
pub async fn delay(duration: Duration) -> Result<(), tokio::timer::Error> {
    tokio::timer::Delay::new(Instant::now() + duration).compat().await
}

pub struct TimeoutError;

/// An async/await helper to timeout a given async context:
///
/// ```ignore
/// timeout(
///     std::time::Duration::from_secs(1),
///     async {
///         let _ = delay(std::time::Duration::from_secs(2)).await;
///     }
/// ).await
/// ```
pub async fn timeout<T, Fut>(timeout: Duration, f: Fut) -> Result<T, TimeoutError>
where
    Fut: futures03::Future<Output = T> + Send,
{
    select! {
        result = f.boxed().fuse() => Ok(result),
        _ = delay(timeout).boxed().fuse() => Err(TimeoutError {})
    }
}

'''
'''--- chain/chain/Cargo.toml ---
[package]
name = "near-chain"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
chrono = { version = "0.4.4", features = ["serde"] }
log = "0.4"
failure = "0.1"
failure_derive = "0.1"
kvdb = "0.1"
protobuf = "2.4"
serde = "1.0"
serde_derive = "1.0"
cached = { git = "https://github.com/nearprotocol/cached", rev = "7e472eddef68607e344d5a106a0e6705d92e55be" }

near-primitives = { path = "../../core/primitives" }
near-protos = { path = "../../core/protos" }
near-store = { path = "../../core/store" }
# Not great, but used in test-utils
node-runtime = { path = "../../runtime/runtime" }
'''
'''--- chain/chain/src/chain.rs ---
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::{Duration as TimeDuration, Instant};

use chrono::prelude::{DateTime, Utc};
use chrono::Duration;
use log::{debug, info};

use near_primitives::hash::CryptoHash;
use near_primitives::transaction::{ReceiptTransaction, TransactionResult};
use near_primitives::types::{BlockIndex, MerkleHash};
use near_store::Store;

use crate::error::{Error, ErrorKind};
use crate::store::{ChainStore, ChainStoreAccess, ChainStoreUpdate};
use crate::types::{Block, BlockHeader, BlockStatus, Provenance, RuntimeAdapter, Tip};

/// Maximum number of orphans chain can store.
pub const MAX_ORPHAN_SIZE: usize = 1024;

/// Maximum age of orhpan to store in the chain.
const MAX_ORPHAN_AGE_SECS: u64 = 300;

/// Refuse blocks more than this many block intervals in the future (as in bitcoin).
const ACCEPTABLE_TIME_DIFFERENCE: i64 = 12 * 10;

pub struct Orphan {
    block: Block,
    provenance: Provenance,
    added: Instant,
}

pub struct OrphanBlockPool {
    orphans: HashMap<CryptoHash, Orphan>,
    height_idx: HashMap<u64, Vec<CryptoHash>>,
    evicted: usize,
}

impl OrphanBlockPool {
    fn new() -> OrphanBlockPool {
        OrphanBlockPool { orphans: HashMap::default(), height_idx: HashMap::default(), evicted: 0 }
    }

    fn len(&self) -> usize {
        self.orphans.len()
    }

    fn len_evicted(&self) -> usize {
        self.evicted
    }

    fn add(&mut self, orphan: Orphan) {
        let height_hashes = self.height_idx.entry(orphan.block.header.height).or_insert(vec![]);
        height_hashes.push(orphan.block.hash());
        self.orphans.insert(orphan.block.hash(), orphan);

        if self.orphans.len() > MAX_ORPHAN_SIZE {
            let old_len = self.orphans.len();

            self.orphans.retain(|_, ref mut x| {
                x.added.elapsed() < TimeDuration::from_secs(MAX_ORPHAN_AGE_SECS)
            });
            let mut heights = self.height_idx.keys().cloned().collect::<Vec<u64>>();
            heights.sort_unstable();
            let mut removed_hashes: HashSet<CryptoHash> = HashSet::default();
            for h in heights.iter().rev() {
                if let Some(hash) = self.height_idx.remove(h) {
                    for h in hash {
                        let _ = self.orphans.remove(&h);
                        removed_hashes.insert(h);
                    }
                }
                if self.orphans.len() < MAX_ORPHAN_SIZE {
                    break;
                }
            }
            self.height_idx.retain(|_, ref mut xs| xs.iter().any(|x| !removed_hashes.contains(&x)));

            self.evicted += old_len - self.orphans.len();
        }
    }

    pub fn contains(&self, hash: &CryptoHash) -> bool {
        self.orphans.contains_key(hash)
    }

    pub fn remove_by_height(&mut self, height: BlockIndex) -> Option<Vec<Orphan>> {
        self.height_idx
            .remove(&height)
            .map(|hs| hs.iter().filter_map(|h| self.orphans.remove(h)).collect())
    }
}

/// Facade to the blockchain block processing and storage.
/// Provides current view on the state according to the chain state.
pub struct Chain {
    store: ChainStore,
    runtime_adapter: Arc<dyn RuntimeAdapter>,
    orphans: OrphanBlockPool,
    genesis: BlockHeader,
}

impl Chain {
    pub fn new(
        store: Arc<Store>,
        runtime_adapter: Arc<dyn RuntimeAdapter>,
        genesis_time: DateTime<Utc>,
    ) -> Result<Chain, Error> {
        let mut store = ChainStore::new(store);

        // Get runtime initial state and create genesis block out of it.
        let (state_store_update, state_root) = runtime_adapter.genesis_state(0);
        let genesis = Block::genesis(state_root, genesis_time);

        // Check if we have a head in the store, otherwise pick genesis block.
        let mut store_update = store.store_update();
        let head_res = store_update.head();
        let head: Tip;
        match head_res {
            Ok(h) => {
                head = h;

                // Check that genesis in the store is the same as genesis given in the config.
                let genesis_hash = store_update.get_block_hash_by_height(0)?;
                if genesis_hash != genesis.hash() {
                    return Err(ErrorKind::Other(format!(
                        "Genesis mismatch between storage and config: {:?} vs {:?}",
                        genesis_hash,
                        genesis.hash()
                    ))
                    .into());
                }

                // Check we have the header corresponding to the header_head.
                let header_head = store_update.header_head()?;
                if store_update.get_block_header(&header_head.last_block_hash).is_err() {
                    // Reset header head and "sync" head to be consistent with current block head.
                    store_update.save_header_head(&head)?;
                    store_update.save_sync_head(&head);
                } else {
                    // Reset sync head to be consistent with current header head.
                    store_update.save_sync_head(&header_head);
                }
                // TODO: perform validation that latest state in runtime matches the stored chain.
            }
            Err(err) => match err.kind() {
                ErrorKind::DBNotFoundErr(_) => {
                    store_update
                        .save_post_state_root(&genesis.hash(), &genesis.header.prev_state_root);
                    store_update.save_block_header(genesis.header.clone());
                    store_update.save_block(genesis.clone());
                    store_update.save_receipt(&genesis.header.hash(), vec![]);

                    head = Tip::from_header(&genesis.header);
                    store_update.save_head(&head)?;
                    store_update.save_sync_head(&head);

                    store_update.merge(state_store_update);

                    info!(target: "chain", "Init: saved genesis: {:?} / {:?}", genesis.hash(), state_root);
                }
                e => return Err(e.into()),
            },
        }
        store_update.commit()?;

        info!(target: "chain", "Init: head: {} @ {} [{}]", head.total_weight.to_num(), head.height, head.last_block_hash);

        Ok(Chain {
            store,
            runtime_adapter,
            orphans: OrphanBlockPool::new(),
            genesis: genesis.header,
        })
    }

    /// Reset "sync" head to current header head.
    /// Do this when first transition to header syncing.
    pub fn reset_sync_head(&mut self) -> Result<Tip, Error> {
        let mut chain_store_update = self.store.store_update();
        let header_head = chain_store_update.header_head()?;
        chain_store_update.save_sync_head(&header_head);
        chain_store_update.commit()?;
        Ok(header_head)
    }

    /// Process a block header received during "header first" propagation.
    pub fn process_block_header(&mut self, header: &BlockHeader) -> Result<(), Error> {
        // We create new chain update, but it's not going to be committed so it's read only.
        let mut chain_update =
            ChainUpdate::new(&mut self.store, self.runtime_adapter.clone(), &self.orphans);
        chain_update.process_block_header(header)?;
        Ok(())
    }

    /// Process a received or produced block, and unroll any orphans that may depend on it.
    /// Changes current state, and calls `block_accepted` callback in case block was successfully applied.
    pub fn process_block<F>(
        &mut self,
        block: Block,
        provenance: Provenance,
        block_accepted: F,
    ) -> Result<Option<Tip>, Error>
    where
        F: Copy + FnMut(&Block, BlockStatus, Provenance) -> (),
    {
        let height = block.header.height;
        let res = self.process_block_single(block, provenance, block_accepted);
        if res.is_ok() {
            if let Some(new_res) = self.check_orphans(height + 1, block_accepted) {
                return Ok(Some(new_res));
            }
        }
        res
    }

    /// Processes headers and adds them to store for syncing.
    pub fn sync_block_headers(&mut self, headers: Vec<BlockHeader>) -> Result<(), Error> {
        let mut chain_update =
            ChainUpdate::new(&mut self.store, self.runtime_adapter.clone(), &self.orphans);
        chain_update.sync_block_headers(headers)?;
        chain_update.commit()
    }

    /// Check if state download is required, otherwise return hashes of blocks to fetch.
    pub fn check_state_needed(&mut self) -> Result<(bool, Vec<CryptoHash>), Error> {
        let block_head = self.head()?;
        let header_head = self.header_head()?;
        let mut hashes = vec![];

        if block_head.total_weight >= header_head.total_weight {
            return Ok((false, hashes));
        }

        // Find common block between header chain and block chain.
        let mut _oldest_height = 0;
        let mut current = self.get_block_header(&header_head.last_block_hash).map(|h| h.clone());
        while let Ok(header) = current {
            if header.height <= block_head.height {
                if self.is_on_current_chain(&header).is_ok() {
                    break;
                }
            }

            _oldest_height = header.height;
            hashes.push(header.hash());
            current = self.get_previous_header(&header).map(|h| h.clone());
        }

        // TODO: calcaulate if the oldest height is too far from header_head.height
        // let sync_head = self.sync_head()?;
        // and return Ok(true) to download state instead.
        Ok((false, hashes))
    }

    /// Returns if given block header on the current chain.
    fn is_on_current_chain(&mut self, header: &BlockHeader) -> Result<(), Error> {
        let chain_header = self.get_header_by_height(header.height)?;
        if chain_header.hash() == header.hash() {
            Ok(())
        } else {
            Err(ErrorKind::Other(format!("{} not on current chain", header.hash())).into())
        }
    }

    /// Finds first of the given hashes that is known on the main chain.
    pub fn find_common_header(&mut self, hashes: &Vec<CryptoHash>) -> Option<BlockHeader> {
        for hash in hashes {
            if let Ok(header) = self.get_block_header(&hash).map(|h| h.clone()) {
                if let Ok(header_at_height) = self.get_header_by_height(header.height) {
                    if header.hash() == header_at_height.hash() {
                        return Some(header);
                    }
                }
            }
        }
        None
    }

    fn determine_status(&self, head: Option<Tip>, prev_head: Tip) -> BlockStatus {
        let has_head = head.is_some();
        let mut is_next_block = false;

        if let Some(head) = head {
            if head.prev_block_hash == prev_head.last_block_hash {
                is_next_block = true;
            }
        }

        match (has_head, is_next_block) {
            (true, true) => BlockStatus::Next,
            (true, false) => BlockStatus::Reorg,
            (false, _) => BlockStatus::Fork,
        }
    }

    fn process_block_single<F>(
        &mut self,
        block: Block,
        provenance: Provenance,
        mut block_accepted: F,
    ) -> Result<Option<Tip>, Error>
    where
        F: FnMut(&Block, BlockStatus, Provenance) -> (),
    {
        let prev_head = self.store.head()?;
        let mut chain_update =
            ChainUpdate::new(&mut self.store, self.runtime_adapter.clone(), &self.orphans);
        let maybe_new_head = chain_update.process_block(&block, &provenance);

        if let Ok(_) = maybe_new_head {
            chain_update.commit()?;
        }

        match maybe_new_head {
            Ok(head) => {
                let status = self.determine_status(head.clone(), prev_head);

                // Notify other parts of the system of the update.
                block_accepted(&block, status, provenance);

                Ok(head)
            }
            Err(e) => match e.kind() {
                ErrorKind::Orphan => {
                    let block_hash = block.hash();
                    let orphan = Orphan { block, provenance, added: Instant::now() };

                    self.orphans.add(orphan);

                    debug!(
                        target: "chain",
                        "Process block: orphan: {:?}, # orphans {}{}",
                        block_hash,
                        self.orphans.len(),
                        if self.orphans.len_evicted() > 0 {
                            format!(", # evicted {}", self.orphans.len_evicted())
                        } else {
                            String::new()
                        },
                    );
                    Err(ErrorKind::Orphan.into())
                }
                ErrorKind::Unfit(ref msg) => {
                    debug!(
                        target: "chain",
                        "Block {} at {} is unfit at this time: {}",
                        block.hash(),
                        block.header.height,
                        msg
                    );
                    Err(ErrorKind::Unfit(msg.clone()).into())
                }
                _ => Err(ErrorKind::Other(format!("{:?}", e)).into()),
            },
        }
    }

    /// Check for orphans, once a block is successfully added.
    fn check_orphans<F>(&mut self, mut height: BlockIndex, block_accepted: F) -> Option<Tip>
    where
        F: Copy + FnMut(&Block, BlockStatus, Provenance) -> (),
    {
        let initial_height = height;

        let mut orphan_accepted = false;
        let mut maybe_new_head = None;

        // Check if there are orphans we can process.
        debug!(target: "chain", "Check orphans: at {}, # orphans {}", height, self.orphans.len());
        loop {
            if let Some(orphans) = self.orphans.remove_by_height(height) {
                debug!(target: "chain", "Check orphans: found {} orphans", orphans.len());
                for orphan in orphans.into_iter() {
                    let res =
                        self.process_block_single(orphan.block, orphan.provenance, block_accepted);
                    match res {
                        Ok(maybe_tip) => {
                            maybe_new_head = maybe_tip;
                            orphan_accepted = true;
                        }
                        Err(err) => {
                            debug!(target: "chain", "Orphan declined: {}", err);
                        }
                    }
                }

                if orphan_accepted {
                    // Accepted a block, so should check if there are now new orphans unlocked.
                    height += 1;
                    continue;
                }
            }
            break;
        }

        if initial_height != height {
            debug!(
                target: "chain",
                "Check orphans: {} blocks accepted since height {}, remaining # orphans {}",
                height - initial_height,
                initial_height,
                self.orphans.len(),
            );
        }

        maybe_new_head
    }
}

/// Various chain getters.
impl Chain {
    /// Gets chain head.
    #[inline]
    pub fn head(&self) -> Result<Tip, Error> {
        self.store.head()
    }

    /// Gets chain header head.
    #[inline]
    pub fn header_head(&self) -> Result<Tip, Error> {
        self.store.header_head()
    }

    /// Gets "sync" head. This may be significantly different to current header chain.
    #[inline]
    pub fn sync_head(&self) -> Result<Tip, Error> {
        self.store.sync_head()
    }

    /// Header of the block at the head of the block chain (not the same thing as header_head).
    #[inline]
    pub fn head_header(&mut self) -> Result<&BlockHeader, Error> {
        self.store.head_header()
    }

    /// Gets a block by hash.
    #[inline]
    pub fn get_block(&mut self, hash: &CryptoHash) -> Result<&Block, Error> {
        self.store.get_block(hash)
    }

    /// Gets a block from the current chain by height.
    #[inline]
    pub fn get_block_by_height(&mut self, height: BlockIndex) -> Result<&Block, Error> {
        let hash = self.store.get_block_hash_by_height(height)?.clone();
        self.store.get_block(&hash)
    }

    /// Gets a block header by hash.
    #[inline]
    pub fn get_block_header(&mut self, hash: &CryptoHash) -> Result<&BlockHeader, Error> {
        self.store.get_block_header(hash)
    }

    /// Returns block header from the current chain for given height if present.
    #[inline]
    pub fn get_header_by_height(&mut self, height: BlockIndex) -> Result<&BlockHeader, Error> {
        let hash = self.store.get_block_hash_by_height(height)?.clone();
        self.store.get_block_header(&hash)
    }

    /// Get previous block header.
    #[inline]
    pub fn get_previous_header(&mut self, header: &BlockHeader) -> Result<&BlockHeader, Error> {
        self.store.get_previous_header(header)
    }

    /// Check if block exists.
    #[inline]
    pub fn block_exists(&self, hash: &CryptoHash) -> Result<bool, Error> {
        self.store.block_exists(hash)
    }

    /// Get state root hash after applying header with given hash.
    #[inline]
    pub fn get_post_state_root(&mut self, hash: &CryptoHash) -> Result<&MerkleHash, Error> {
        self.store.get_post_state_root(hash)
    }

    /// Get receipts stored for the given hash.
    #[inline]
    pub fn get_receipts(&mut self, hash: &CryptoHash) -> Result<&Vec<ReceiptTransaction>, Error> {
        self.store.get_receipts(hash)
    }

    /// Get transaction result for given hash of transaction.
    #[inline]
    pub fn get_transaction_result(
        &mut self,
        hash: &CryptoHash,
    ) -> Result<&TransactionResult, Error> {
        self.store.get_transaction_result(hash)
    }

    /// Returns underlying ChainStore.
    #[inline]
    pub fn store(&self) -> &ChainStore {
        &self.store
    }

    /// Returns genesis block header.
    #[inline]
    pub fn genesis(&self) -> &BlockHeader {
        &self.genesis
    }

    /// Returns number of orphans currently in the orphan pool.
    #[inline]
    pub fn orphans_len(&self) -> usize {
        self.orphans.len()
    }

    /// Returns number of evicted orphans.
    #[inline]
    pub fn orphans_evicted_len(&self) -> usize {
        self.orphans.len_evicted()
    }

    /// Check if hash is for a known orphan.
    #[inline]
    pub fn is_orphan(&self, hash: &CryptoHash) -> bool {
        self.orphans.contains(hash)
    }
}

/// Chain update helper, contains information that is needed to process block
/// and decide to accept it or reject it.
/// If rejected nothing will be updated in underlying storage.
/// Safe to stop process mid way (Ctrl+C or crash).
struct ChainUpdate<'a> {
    runtime_adapter: Arc<dyn RuntimeAdapter>,
    chain_store_update: ChainStoreUpdate<'a, ChainStore>,
    orphans: &'a OrphanBlockPool,
}

impl<'a> ChainUpdate<'a> {
    pub fn new(
        store: &'a mut ChainStore,
        runtime_adapter: Arc<dyn RuntimeAdapter>,
        orphans: &'a OrphanBlockPool,
    ) -> Self {
        let chain_store_update = store.store_update();
        ChainUpdate { runtime_adapter, chain_store_update, orphans }
    }

    /// Commit changes to the chain into the database.
    pub fn commit(self) -> Result<(), Error> {
        self.chain_store_update.commit()
    }

    /// Process block header as part of "header first" block propagation.
    /// We validate the header but we do not store it or update header head
    /// based on this. We will update these once we get the block back after
    /// requesting it.
    pub fn process_block_header(&mut self, header: &BlockHeader) -> Result<(), Error> {
        debug!(target: "chain", "Process block header: {} at {}", header.hash(), header.height);

        self.check_header_known(header)?;
        self.validate_header(header, &Provenance::NONE)?;
        Ok(())
    }

    /// Find previous header or return Orphan error if not found.
    pub fn get_previous_header(&mut self, header: &BlockHeader) -> Result<&BlockHeader, Error> {
        self.chain_store_update.get_previous_header(header).map_err(|e| match e.kind() {
            ErrorKind::DBNotFoundErr(_) => ErrorKind::Orphan.into(),
            other => other.into(),
        })
    }

    /// Runs the block processing, including validation and finding a place for the new block in the chain.
    /// Returns new head if chain head updated.
    fn process_block(
        &mut self,
        block: &Block,
        provenance: &Provenance,
    ) -> Result<Option<Tip>, Error> {
        debug!(target: "chain", "Process block {} at {}, approvals: {}, tx: {}", block.hash(), block.header.height, block.header.approval_sigs.len(), block.transactions.len());

        // Check if we have already processed this block previously.
        self.check_known(&block)?;

        // Delay hitting the db for current chain head until we know this block is not already known.
        let head = self.chain_store_update.head()?;
        let is_next = block.header.prev_hash == head.last_block_hash;

        // First real I/O expense.
        let prev = self.get_previous_header(&block.header)?;
        let prev_hash = prev.hash();

        // Block is an orphan if we do not know about the previous full block.
        if !is_next && !self.chain_store_update.block_exists(&prev_hash)? {
            return Err(ErrorKind::Orphan.into());
        }

        // This is a fork in the context of both header and block processing
        // if this block does not immediately follow the chain head.
        // let is_fork = !is_next;

        // Check the header is valid before we proceed with the full block.
        self.process_header_for_block(&block.header, provenance)?;

        // Check that state root we computed from previous block matches recorded in this block.
        let state_root = self.chain_store_update.get_post_state_root(&prev_hash)?;
        if &block.header.prev_state_root != state_root {
            return Err(ErrorKind::InvalidStateRoot.into());
        }

        // Retrieve receipts from the previous block.
        let receipts = self.chain_store_update.get_receipts(&prev_hash)?;
        let receipt_hashes = receipts.iter().map(|r| r.get_hash()).collect::<Vec<_>>();

        // Apply block to runtime.
        let (trie_changes, state_root, mut tx_results, new_receipts) = self
            .runtime_adapter
            .apply_transactions(
                0,
                &block.header.prev_state_root,
                block.header.height,
                &block.header.prev_hash,
                &vec![receipts.clone()], // TODO: currently only taking into account one shard.
                &block.transactions,
            )
            .map_err(|e| ErrorKind::Other(e.to_string()))?;
        self.chain_store_update.save_trie_changes(trie_changes);
        // Save state root after applying transactions.
        self.chain_store_update.save_post_state_root(&block.hash(), &state_root);
        // Save resulting receipts.
        // TODO: currently only taking into account one shard.
        self.chain_store_update
            .save_receipt(&block.hash(), new_receipts.get(&0).unwrap_or(&vec![]).to_vec());
        // Save receipt and transaction results.
        for (i, tx_result) in tx_results.drain(..).enumerate() {
            if i < receipt_hashes.len() {
                self.chain_store_update.save_transaction_result(&receipt_hashes[i], tx_result);
            } else {
                self.chain_store_update.save_transaction_result(
                    &block.transactions[i - receipt_hashes.len()].get_hash(),
                    tx_result,
                );
            }
        }

        // Add validated block to the db, even if it's not the selected fork.
        self.chain_store_update.save_block(block.clone());

        // Update the chain head if total weight has increased.
        let res = self.update_head(block)?;
        Ok(res)
    }

    /// Process a block header as part of processing a full block.
    /// We want to be sure the header is valid before processing the full block.
    fn process_header_for_block(
        &mut self,
        header: &BlockHeader,
        provenance: &Provenance,
    ) -> Result<(), Error> {
        self.validate_header(header, provenance)?;
        self.chain_store_update.save_block_header(header.clone());
        self.update_header_head(header)?;
        Ok(())
    }

    /// Process incoming block headers for syncing.
    fn sync_block_headers(&mut self, headers: Vec<BlockHeader>) -> Result<Option<Tip>, Error> {
        let _first_header = if let Some(header) = headers.first() {
            debug!(target: "chain", "Sync block headers: {} headers from {} at {}", headers.len(), header.hash(), header.height);
            header
        } else {
            return Ok(None);
        };

        let all_known = if let Some(last_header) = headers.last() {
            self.chain_store_update.get_block_header(&last_header.hash()).is_ok()
        } else {
            false
        };

        if !all_known {
            // First add all headers to the chain.
            for header in headers.iter() {
                self.chain_store_update.save_block_header(header.clone());
            }
            // Then validate all headers (splitting into two, makes sure if they are out of order).
            // If validation fails, the saved block headers will not be committed to database as we revert store update.
            for header in headers.iter() {
                self.validate_header(header, &Provenance::SYNC)?;
            }
        }

        if let Some(header) = headers.last() {
            // Update sync_head regardless of the total weight.
            self.update_sync_head(header)?;
            // Update header_head if total weight changed.
            self.update_header_head(header)
        } else {
            Ok(None)
        }
    }

    fn validate_header(
        &mut self,
        header: &BlockHeader,
        provenance: &Provenance,
    ) -> Result<(), Error> {
        // Refuse blocks from the too distant future.
        if header.timestamp > Utc::now() + Duration::seconds(ACCEPTABLE_TIME_DIFFERENCE) {
            return Err(ErrorKind::InvalidBlockFutureTime(header.timestamp).into());
        }

        // First I/O cost, delayed as late as possible.
        let prev_header = self.get_previous_header(header)?;

        // Prevent time warp attacks and some timestamp manipulations by forcing strict
        // time progression.
        if header.timestamp <= prev_header.timestamp {
            return Err(
                ErrorKind::InvalidBlockPastTime(prev_header.timestamp, header.timestamp).into()
            );
        }

        // If this is not the block we produced (hence trust in it) - validates block
        // producer, confirmation signatures and returns new total weight.
        if *provenance != Provenance::PRODUCED {
            let prev_header = self.get_previous_header(header)?.clone();
            let weight = self.runtime_adapter.compute_block_weight(&prev_header, header)?;
            if weight != header.total_weight {
                return Err(ErrorKind::InvalidBlockWeight.into());
            }
        }

        Ok(())
    }

    /// Update the header head if this header has most work.
    fn update_header_head(&mut self, header: &BlockHeader) -> Result<Option<Tip>, Error> {
        let header_head = self.chain_store_update.header_head()?;
        if header.total_weight > header_head.total_weight {
            let tip = Tip::from_header(header);
            self.chain_store_update.save_header_head(&tip)?;
            debug!(target: "chain", "Header head updated to {} at {}", tip.last_block_hash, tip.height);

            Ok(Some(tip))
        } else {
            Ok(None)
        }
    }

    /// Directly updates the head if we've just appended a new block to it or handle
    /// the situation where we've just added enough weight to have a fork with more
    /// work than the head.
    fn update_head(&mut self, block: &Block) -> Result<Option<Tip>, Error> {
        // if we made a fork with more work than the head (which should also be true
        // when extending the head), update it
        let head = self.chain_store_update.head()?;
        if block.header.total_weight > head.total_weight {
            let tip = Tip::from_header(&block.header);

            self.chain_store_update.save_body_head(&tip);
            debug!(target: "chain", "Head updated to {} at {}", tip.last_block_hash, tip.height);
            Ok(Some(tip))
        } else {
            Ok(None)
        }
    }

    /// Updates "sync" head with given block header.
    fn update_sync_head(&mut self, header: &BlockHeader) -> Result<(), Error> {
        let tip = Tip::from_header(header);
        self.chain_store_update.save_sync_head(&tip);
        debug!(target: "chain", "Sync head {} @ {}", tip.last_block_hash, tip.height);
        Ok(())
    }

    /// Quick in-memory check to fast-reject any block header we've already handled
    /// recently. Keeps duplicates from the network in check.
    /// ctx here is specific to the header_head (tip of the header chain)
    fn check_header_known(&mut self, header: &BlockHeader) -> Result<(), Error> {
        let header_head = self.chain_store_update.header_head()?;
        if header.hash() == header_head.last_block_hash
            || header.hash() == header_head.prev_block_hash
        {
            return Err(ErrorKind::Unfit("header already known".to_string()).into());
        }
        Ok(())
    }

    /// Quick in-memory check for fast-reject any block handled recently.
    fn check_known_head(&self, header: &BlockHeader) -> Result<(), Error> {
        let head = self.chain_store_update.head()?;
        let bh = header.hash();
        if bh == head.last_block_hash || bh == head.prev_block_hash {
            return Err(ErrorKind::Unfit("already known in head".to_string()).into());
        }
        Ok(())
    }

    /// Check if this block is in the set of known orphans.
    fn check_known_orphans(&self, header: &BlockHeader) -> Result<(), Error> {
        if self.orphans.contains(&header.hash()) {
            return Err(ErrorKind::Unfit("already known in orphans".to_string()).into());
        }
        Ok(())
    }

    /// Check if this block is ini the store already.
    fn check_known_store(&self, header: &BlockHeader) -> Result<(), Error> {
        match self.chain_store_update.block_exists(&header.hash()) {
            Ok(true) => {
                let head = self.chain_store_update.head()?;
                if header.height > 50 && header.height < head.height - 50 {
                    // We flag this as an "abusive peer" but only in the case
                    // where we have the full block in our store.
                    // So this is not a particularly exhaustive check.
                    Err(ErrorKind::OldBlock.into())
                } else {
                    Err(ErrorKind::Unfit("already known in store".to_string()).into())
                }
            }
            Ok(false) => {
                // Not yet processed this block, we can proceed.
                Ok(())
            }
            Err(e) => Err(e),
        }
    }

    /// Check if header is known: head, orphan or in store.
    #[allow(dead_code)]
    fn is_header_known(&self, header: &BlockHeader) -> Result<bool, Error> {
        let check = || {
            self.check_known_head(header)?;
            self.check_known_orphans(header)?;
            self.check_known_store(header)
        };
        match check() {
            Ok(()) => Ok(false),
            Err(err) => match err.kind() {
                ErrorKind::Unfit(_) => Ok(true),
                kind => Err(kind.into()),
            },
        }
    }

    /// Check if block is known: head, orphan or in store.
    fn check_known(&self, block: &Block) -> Result<(), Error> {
        self.check_known_head(&block.header)?;
        self.check_known_orphans(&block.header)?;
        self.check_known_store(&block.header)?;
        Ok(())
    }
}

'''
'''--- chain/chain/src/error.rs ---
use std::fmt::{self, Display};
use std::io;

use chrono::{DateTime, Utc};
use failure::{Backtrace, Context, Fail};

#[derive(Debug)]
pub struct Error {
    inner: Context<ErrorKind>,
}

#[derive(Clone, Eq, PartialEq, Debug, Fail)]
pub enum ErrorKind {
    /// The block doesn't fit anywhere in our chain.
    #[fail(display = "Block is unfit: {}", _0)]
    Unfit(String),
    /// Orphan block.
    #[fail(display = "Orphan")]
    Orphan,
    /// Peer abusively sending us an old block we already have
    #[fail(display = "Old Block")]
    OldBlock,
    /// Block time is before parent block time.
    #[fail(display = "Invalid Block Time: block time {} before previous {}", _1, _0)]
    InvalidBlockPastTime(DateTime<Utc>, DateTime<Utc>),
    /// Block time is from too much in the future.
    #[fail(display = "Invalid Block Time: Too far in the future: {}", _0)]
    InvalidBlockFutureTime(DateTime<Utc>),
    /// Block height is invalid (not previous + 1).
    #[fail(display = "Invalid Block Height")]
    InvalidBlockHeight,
    /// Invalid block proposed signature.
    #[fail(display = "Invalid Block Proposer Signature")]
    InvalidBlockProposer,
    /// Invalid block confirmation signature.
    #[fail(display = "Invalid Block Confirmation Signature")]
    InvalidBlockConfirmation,
    /// Invalid block weight.
    #[fail(display = "Invalid Block Weight")]
    InvalidBlockWeight,
    /// Invalid state root hash.
    #[fail(display = "Invalid State Root Hash")]
    InvalidStateRoot,
    /// IO Error.
    #[fail(display = "IO Error: {}", _0)]
    IOErr(String),
    /// Not found record in the DB.
    #[fail(display = "DB Not Found Error: {}", _0)]
    DBNotFoundErr(String),
    /// Anything else
    #[fail(display = "Other Error: {}", _0)]
    Other(String),
}

impl Display for Error {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let cause = match self.cause() {
            Some(c) => format!("{}", c),
            None => String::from("Unknown"),
        };
        let backtrace = match self.backtrace() {
            Some(b) => format!("{}", b),
            None => String::from("Unknown"),
        };
        let output = format!("{} \n Cause: {} \n Backtrace: {}", self.inner, cause, backtrace);
        Display::fmt(&output, f)
    }
}

impl Error {
    pub fn kind(&self) -> ErrorKind {
        self.inner.get_context().clone()
    }

    pub fn cause(&self) -> Option<&dyn Fail> {
        self.inner.cause()
    }

    pub fn backtrace(&self) -> Option<&Backtrace> {
        self.inner.backtrace()
    }

    pub fn is_bad_data(&self) -> bool {
        match self.kind() {
            ErrorKind::Unfit(_)
            | ErrorKind::Orphan
            | ErrorKind::IOErr(_)
            | ErrorKind::Other(_)
            | ErrorKind::DBNotFoundErr(_) => false,
            ErrorKind::InvalidBlockPastTime(_, _)
            | ErrorKind::InvalidBlockFutureTime(_)
            | ErrorKind::InvalidBlockHeight
            | ErrorKind::OldBlock
            | ErrorKind::InvalidBlockProposer
            | ErrorKind::InvalidBlockConfirmation
            | ErrorKind::InvalidBlockWeight
            | ErrorKind::InvalidStateRoot => true,
        }
    }

    pub fn is_error(&self) -> bool {
        match self.kind() {
            ErrorKind::IOErr(_) | ErrorKind::Other(_) | ErrorKind::DBNotFoundErr(_) => true,
            _ => false,
        }
    }
}

impl From<ErrorKind> for Error {
    fn from(kind: ErrorKind) -> Error {
        Error { inner: Context::new(kind) }
    }
}

impl From<io::Error> for Error {
    fn from(error: io::Error) -> Error {
        Error { inner: Context::new(ErrorKind::IOErr(error.to_string())) }
    }
}

impl From<String> for Error {
    fn from(error: String) -> Error {
        Error { inner: Context::new(ErrorKind::Other(error)) }
    }
}

impl std::error::Error for Error {}

unsafe impl Send for Error {}
unsafe impl Sync for Error {}

'''
'''--- chain/chain/src/lib.rs ---
#[macro_use]
extern crate serde_derive;

pub use chain::{Chain, MAX_ORPHAN_SIZE};
pub use error::{Error, ErrorKind};
pub use store::{ChainStore, ChainStoreAccess};
pub use types::{
    Block, BlockApproval, BlockHeader, BlockStatus, Provenance, ReceiptResult, RuntimeAdapter, Tip,
    ValidTransaction, Weight,
};

mod chain;
mod error;
mod store;
pub mod test_utils;
mod types;

'''
'''--- chain/chain/src/store.rs ---
use std::collections::{HashMap, HashSet};
use std::io;
use std::sync::Arc;

use cached::SizedCache;
use log::debug;

use near_primitives::hash::CryptoHash;
use near_primitives::transaction::{ReceiptTransaction, TransactionResult};
use near_primitives::types::{BlockIndex, MerkleHash};
use near_primitives::utils::index_to_bytes;
use near_store::{
    read_with_cache, Store, StoreUpdate, WrappedTrieChanges, COL_BLOCK, COL_BLOCK_HEADER,
    COL_BLOCK_INDEX, COL_BLOCK_MISC, COL_RECEIPTS, COL_STATE_REF, COL_TRANSACTION_RESULT,
};

use crate::error::{Error, ErrorKind};
use crate::types::{Block, BlockHeader, Tip};

const HEAD_KEY: &[u8; 4] = b"HEAD";
const TAIL_KEY: &[u8; 4] = b"TAIL";
const SYNC_HEAD_KEY: &[u8; 9] = b"SYNC_HEAD";
const HEADER_HEAD_KEY: &[u8; 11] = b"HEADER_HEAD";

/// lru cache size
const CACHE_SIZE: usize = 20;

/// Accesses the chain store. Used to create atomic editable views that can be reverted.
pub trait ChainStoreAccess {
    /// Returns underlaying store.
    fn store(&self) -> &Store;
    /// The chain head.
    fn head(&self) -> Result<Tip, Error>;
    /// The chain tail (as far as chain goes).
    fn tail(&self) -> Result<Tip, Error>;
    /// Head of the header chain (not the same thing as head_header).
    fn header_head(&self) -> Result<Tip, Error>;
    /// The "sync" head: last header we received from syncing.
    fn sync_head(&self) -> Result<Tip, Error>;
    /// Header of the block at the head of the block chain (not the same thing as header_head).
    fn head_header(&mut self) -> Result<&BlockHeader, Error>;
    /// Get full block.
    fn get_block(&mut self, h: &CryptoHash) -> Result<&Block, Error>;
    /// Does this full block exist?
    fn block_exists(&self, h: &CryptoHash) -> Result<bool, Error>;
    /// Get previous header.
    fn get_previous_header(&mut self, header: &BlockHeader) -> Result<&BlockHeader, Error>;
    /// Get state root hash after applying header with given hash.
    fn get_post_state_root(&mut self, h: &CryptoHash) -> Result<&MerkleHash, Error>;
    /// Get block header.
    fn get_block_header(&mut self, h: &CryptoHash) -> Result<&BlockHeader, Error>;
    /// Returns hash of the block on the main chain for given height.
    fn get_block_hash_by_height(&mut self, height: BlockIndex) -> Result<CryptoHash, Error>;
    /// Returns resulting receipt for given block.
    fn get_receipts(&mut self, hash: &CryptoHash) -> Result<&Vec<ReceiptTransaction>, Error>;
    /// Returns transaction result for given tx hash.
    fn get_transaction_result(&mut self, hash: &CryptoHash) -> Result<&TransactionResult, Error>;
}

/// All chain-related database operations.
pub struct ChainStore {
    store: Arc<Store>,
    /// Cache with headers.
    headers: SizedCache<Vec<u8>, BlockHeader>,
    /// Cache with blocks.
    blocks: SizedCache<Vec<u8>, Block>,
    /// Cache with state roots.
    post_state_roots: SizedCache<Vec<u8>, MerkleHash>,
    // Cache with index to hash on the main chain.
    // block_index: SizedCache<Vec<u8>, CryptoHash>,
    /// Cache with receipts.
    receipts: SizedCache<Vec<u8>, Vec<ReceiptTransaction>>,
    /// Cache transaction statuses.
    transaction_results: SizedCache<Vec<u8>, TransactionResult>,
}

pub fn option_to_not_found<T>(res: io::Result<Option<T>>, field_name: &str) -> Result<T, Error> {
    match res {
        Ok(Some(o)) => Ok(o),
        Ok(None) => Err(ErrorKind::DBNotFoundErr(field_name.to_owned()).into()),
        Err(e) => Err(e.into()),
    }
}

impl ChainStore {
    pub fn new(store: Arc<Store>) -> ChainStore {
        ChainStore {
            store,
            blocks: SizedCache::with_size(CACHE_SIZE),
            headers: SizedCache::with_size(CACHE_SIZE),
            post_state_roots: SizedCache::with_size(CACHE_SIZE),
            // block_index: SizedCache::with_size(CACHE_SIZE),
            receipts: SizedCache::with_size(CACHE_SIZE),
            transaction_results: SizedCache::with_size(CACHE_SIZE),
        }
    }

    pub fn store_update(&mut self) -> ChainStoreUpdate<Self> {
        ChainStoreUpdate::new(self)
    }
}

impl ChainStoreAccess for ChainStore {
    fn store(&self) -> &Store {
        &*self.store
    }
    /// The chain head.
    fn head(&self) -> Result<Tip, Error> {
        option_to_not_found(self.store.get_ser(COL_BLOCK_MISC, HEAD_KEY), "HEAD")
    }

    /// The chain tail (as far as chain goes).
    fn tail(&self) -> Result<Tip, Error> {
        option_to_not_found(self.store.get_ser(COL_BLOCK_MISC, TAIL_KEY), "TAIL")
    }

    /// The "sync" head: last header we received from syncing.
    fn sync_head(&self) -> Result<Tip, Error> {
        option_to_not_found(self.store.get_ser(COL_BLOCK_MISC, SYNC_HEAD_KEY), "SYNC_HEAD")
    }

    /// Header of the block at the head of the block chain (not the same thing as header_head).
    fn head_header(&mut self) -> Result<&BlockHeader, Error> {
        self.get_block_header(&self.head()?.last_block_hash)
    }

    /// Head of the header chain (not the same thing as head_header).
    fn header_head(&self) -> Result<Tip, Error> {
        option_to_not_found(self.store.get_ser(COL_BLOCK_MISC, HEADER_HEAD_KEY), "HEADER_HEAD")
    }

    /// Get full block.
    fn get_block(&mut self, h: &CryptoHash) -> Result<&Block, Error> {
        option_to_not_found(
            read_with_cache(&*self.store, COL_BLOCK, &mut self.blocks, h.as_ref()),
            &format!("BLOCK: {}", h),
        )
    }

    /// Does this full block exist?
    fn block_exists(&self, h: &CryptoHash) -> Result<bool, Error> {
        self.store.exists(COL_BLOCK, h.as_ref()).map_err(|e| e.into())
    }

    /// Get previous header.
    fn get_previous_header(&mut self, header: &BlockHeader) -> Result<&BlockHeader, Error> {
        self.get_block_header(&header.prev_hash)
    }

    /// Get state root hash after applying header with given hash.
    fn get_post_state_root(&mut self, h: &CryptoHash) -> Result<&MerkleHash, Error> {
        option_to_not_found(
            read_with_cache(&*self.store, COL_STATE_REF, &mut self.post_state_roots, h.as_ref()),
            &format!("STATE ROOT: {}", h),
        )
    }

    /// Get block header.
    fn get_block_header(&mut self, h: &CryptoHash) -> Result<&BlockHeader, Error> {
        option_to_not_found(
            read_with_cache(&*self.store, COL_BLOCK_HEADER, &mut self.headers, h.as_ref()),
            &format!("BLOCK HEADER: {}", h),
        )
    }

    /// Returns hash of the block on the main chain for given height.
    fn get_block_hash_by_height(&mut self, height: BlockIndex) -> Result<CryptoHash, Error> {
        option_to_not_found(
            self.store.get_ser(COL_BLOCK_INDEX, &index_to_bytes(height)),
            &format!("BLOCK INDEX: {}", height),
        )
        // TODO: cache needs to be deleted when things get updated.
        //        option_to_not_found(
        //            read_with_cache(
        //                &*self.store,
        //                COL_BLOCK_INDEX,
        //                &mut self.block_index,
        //                &index_to_bytes(height),
        //            ),
        //            &format!("BLOCK INDEX: {}", height),
        //        )
    }

    fn get_receipts(&mut self, hash: &CryptoHash) -> Result<&Vec<ReceiptTransaction>, Error> {
        option_to_not_found(
            read_with_cache(&*self.store, COL_RECEIPTS, &mut self.receipts, hash.as_ref()),
            &format!("RECEIPT: {}", hash),
        )
    }

    fn get_transaction_result(&mut self, hash: &CryptoHash) -> Result<&TransactionResult, Error> {
        option_to_not_found(
            read_with_cache(
                &*self.store,
                COL_TRANSACTION_RESULT,
                &mut self.transaction_results,
                hash.as_ref(),
            ),
            &format!("TRANSACTION: {}", hash),
        )
    }
}

/// Provides layer to update chain without touching underlaying database.
/// This serves few purposes, main one is that even if executable exists/fails during update the database is in consistent state.
pub struct ChainStoreUpdate<'a, T> {
    chain_store: &'a mut T,
    store_updates: Vec<StoreUpdate>,
    /// Blocks added during this update. Takes ownership (unclear how to not do it because of failure exists).
    blocks: HashMap<CryptoHash, Block>,
    deleted_blocks: HashSet<CryptoHash>,
    headers: HashMap<CryptoHash, BlockHeader>,
    post_state_roots: HashMap<CryptoHash, MerkleHash>,
    block_index: HashMap<BlockIndex, Option<CryptoHash>>,
    receipts: HashMap<CryptoHash, Vec<ReceiptTransaction>>,
    transaction_results: HashMap<CryptoHash, TransactionResult>,
    head: Option<Tip>,
    tail: Option<Tip>,
    header_head: Option<Tip>,
    sync_head: Option<Tip>,
    trie_changes: Option<WrappedTrieChanges>,
}

impl<'a, T: ChainStoreAccess> ChainStoreUpdate<'a, T> {
    pub fn new(chain_store: &'a mut T) -> Self {
        ChainStoreUpdate {
            chain_store,
            store_updates: vec![],
            blocks: HashMap::default(),
            deleted_blocks: HashSet::default(),
            headers: HashMap::default(),
            block_index: HashMap::default(),
            post_state_roots: HashMap::default(),
            receipts: HashMap::default(),
            transaction_results: HashMap::default(),
            head: None,
            tail: None,
            header_head: None,
            sync_head: None,
            trie_changes: None,
        }
    }
}

impl<'a, T: ChainStoreAccess> ChainStoreAccess for ChainStoreUpdate<'a, T> {
    fn store(&self) -> &Store {
        self.chain_store.store()
    }
    /// The chain head.
    fn head(&self) -> Result<Tip, Error> {
        if let Some(head) = &self.head {
            Ok(head.clone())
        } else {
            self.chain_store.head()
        }
    }

    /// The chain tail (as far as chain goes).
    fn tail(&self) -> Result<Tip, Error> {
        if let Some(tail) = &self.tail {
            Ok(tail.clone())
        } else {
            self.chain_store.tail()
        }
    }

    /// The "sync" head: last header we received from syncing.
    fn sync_head(&self) -> Result<Tip, Error> {
        if let Some(sync_head) = &self.sync_head {
            Ok(sync_head.clone())
        } else {
            self.chain_store.sync_head()
        }
    }

    /// Head of the header chain (not the same thing as head_header).
    fn header_head(&self) -> Result<Tip, Error> {
        if let Some(header_head) = &self.header_head {
            Ok(header_head.clone())
        } else {
            self.chain_store.header_head()
        }
    }

    /// Header of the block at the head of the block chain (not the same thing as header_head).
    fn head_header(&mut self) -> Result<&BlockHeader, Error> {
        self.get_block_header(&(self.head()?.last_block_hash))
    }

    /// Get full block.
    fn get_block(&mut self, h: &CryptoHash) -> Result<&Block, Error> {
        if let Some(block) = self.blocks.get(h) {
            Ok(block)
        } else {
            self.chain_store.get_block(h)
        }
    }

    /// Does this full block exist?
    fn block_exists(&self, h: &CryptoHash) -> Result<bool, Error> {
        Ok(self.blocks.contains_key(h) || self.chain_store.block_exists(h)?)
    }

    /// Get previous header.
    fn get_previous_header(&mut self, header: &BlockHeader) -> Result<&BlockHeader, Error> {
        self.get_block_header(&header.prev_hash)
    }

    /// Get state root hash after applying header with given hash.
    fn get_post_state_root(&mut self, hash: &CryptoHash) -> Result<&MerkleHash, Error> {
        if let Some(post_state_root) = self.post_state_roots.get(hash) {
            Ok(post_state_root)
        } else {
            self.chain_store.get_post_state_root(hash)
        }
    }

    /// Get block header.
    fn get_block_header(&mut self, hash: &CryptoHash) -> Result<&BlockHeader, Error> {
        if let Some(header) = self.headers.get(hash) {
            Ok(header)
        } else {
            self.chain_store.get_block_header(hash)
        }
    }

    /// Get block header from the current chain by height.
    fn get_block_hash_by_height(&mut self, height: BlockIndex) -> Result<CryptoHash, Error> {
        self.chain_store.get_block_hash_by_height(height)
    }

    /// Get receipts produced for block with givien hash.
    fn get_receipts(&mut self, hash: &CryptoHash) -> Result<&Vec<ReceiptTransaction>, Error> {
        if let Some(receipts) = self.receipts.get(hash) {
            Ok(receipts)
        } else {
            self.chain_store.get_receipts(hash)
        }
    }

    fn get_transaction_result(&mut self, hash: &CryptoHash) -> Result<&TransactionResult, Error> {
        self.chain_store.get_transaction_result(hash)
    }
}

impl<'a, T: ChainStoreAccess> ChainStoreUpdate<'a, T> {
    /// Update both header and block body head.
    pub fn save_head(&mut self, t: &Tip) -> Result<(), Error> {
        self.save_body_head(t);
        self.save_header_head(t)
    }

    /// Update block body head.
    pub fn save_body_head(&mut self, t: &Tip) {
        self.head = Some(t.clone());
    }

    /// Update block body tail.
    pub fn save_body_tail(&mut self, t: &Tip) {
        self.tail = Some(t.clone());
    }

    fn update_block_index(&mut self, height: BlockIndex, hash: CryptoHash) -> Result<(), Error> {
        let mut prev_hash = hash;
        let mut prev_height = height;
        loop {
            let header = self.get_block_header(&prev_hash)?;
            let (header_height, header_hash, header_prev_hash) =
                (header.height, header.hash(), header.prev_hash);
            // Clean up block indicies between blocks.
            for height in (header_height + 1)..prev_height {
                self.block_index.insert(height, None);
            }
            match self.get_block_hash_by_height(header_height).map(|h| h.clone()) {
                Ok(cur_hash) if cur_hash == header_hash => {
                    // Found common ancestor.
                    return Ok(());
                }
                _ => {
                    self.block_index.insert(header_height, Some(header_hash));
                    prev_hash = header_prev_hash;
                    prev_height = header_height;
                }
            };
        }
    }

    /// Update header head and height to hash index for this branch.
    pub fn save_header_head(&mut self, t: &Tip) -> Result<(), Error> {
        if t.height > 0 {
            self.update_block_index(t.height, t.prev_block_hash)?;
        }
        self.block_index.insert(t.height, Some(t.last_block_hash));
        self.header_head = Some(t.clone());
        Ok(())
    }

    /// Save "sync" head.
    pub fn save_sync_head(&mut self, t: &Tip) {
        self.sync_head = Some(t.clone());
    }

    /// Save block.
    pub fn save_block(&mut self, block: Block) {
        self.blocks.insert(block.hash(), block);
    }

    /// Save post applying block state root.
    pub fn save_post_state_root(&mut self, hash: &CryptoHash, state_root: &CryptoHash) {
        self.post_state_roots.insert(*hash, *state_root);
    }

    pub fn delete_block(&mut self, hash: &CryptoHash) {
        self.deleted_blocks.insert(*hash);
    }

    pub fn save_block_header(&mut self, header: BlockHeader) {
        self.headers.insert(header.hash(), header);
    }

    pub fn save_receipt(&mut self, hash: &CryptoHash, receipt: Vec<ReceiptTransaction>) {
        self.receipts.insert(*hash, receipt);
    }

    pub fn save_transaction_result(&mut self, hash: &CryptoHash, result: TransactionResult) {
        self.transaction_results.insert(*hash, result);
    }

    /// Starts a sub-ChainUpdate with atomic commit/rollback of all operations done
    /// within this scope.
    /// If the closure returns and error, all changes are canceled.
    #[allow(dead_code)]
    pub fn extending<F>(&mut self, f: F) -> Result<bool, Error>
    where
        F: FnOnce(&mut ChainStoreUpdate<'_, ChainStoreUpdate<'a, T>>) -> Result<bool, Error>,
    {
        let mut child_store_update = ChainStoreUpdate::new(self);
        let res = f(&mut child_store_update);
        match res {
            // Committing changes.
            Ok(true) => {
                let store_update = child_store_update.finalize()?;
                self.store_updates.push(store_update);
                Ok(true)
            }
            // Rolling back changes.
            Ok(false) => Ok(false),
            Err(err) => {
                debug!(target: "chain", "Error returned, discarding extension");
                Err(err)
            }
        }
    }

    pub fn save_trie_changes(&mut self, trie_changes: WrappedTrieChanges) {
        self.trie_changes = Some(trie_changes);
    }

    /// Merge another StoreUpdate into this one
    pub fn merge(&mut self, store_update: StoreUpdate) {
        self.store_updates.push(store_update);
    }

    pub fn finalize(mut self) -> Result<StoreUpdate, Error> {
        let mut store_update = self.store().store_update();
        if let Some(t) = self.head {
            store_update.set_ser(COL_BLOCK_MISC, HEAD_KEY, &t).map_err::<Error, _>(|e| e.into())?;
        }
        if let Some(t) = self.tail {
            store_update.set_ser(COL_BLOCK_MISC, TAIL_KEY, &t).map_err::<Error, _>(|e| e.into())?;
        }
        if let Some(t) = self.header_head {
            store_update
                .set_ser(COL_BLOCK_MISC, HEADER_HEAD_KEY, &t)
                .map_err::<Error, _>(|e| e.into())?;
        }
        if let Some(t) = self.sync_head {
            store_update
                .set_ser(COL_BLOCK_MISC, SYNC_HEAD_KEY, &t)
                .map_err::<Error, _>(|e| e.into())?;
        }
        for (hash, block) in self.blocks.drain() {
            store_update
                .set_ser(COL_BLOCK, hash.as_ref(), &block)
                .map_err::<Error, _>(|e| e.into())?;
        }
        for hash in self.deleted_blocks.drain() {
            store_update.delete(COL_BLOCK, hash.as_ref());
        }
        for (hash, header) in self.headers.drain() {
            store_update
                .set_ser(COL_BLOCK_HEADER, hash.as_ref(), &header)
                .map_err::<Error, _>(|e| e.into())?;
        }
        for (hash, state_root) in self.post_state_roots.drain() {
            store_update
                .set_ser(COL_STATE_REF, hash.as_ref(), &state_root)
                .map_err::<Error, _>(|e| e.into())?;
        }
        for (height, hash) in self.block_index.drain() {
            if let Some(hash) = hash {
                store_update
                    .set_ser(COL_BLOCK_INDEX, &index_to_bytes(height), &hash)
                    .map_err::<Error, _>(|e| e.into())?;
            } else {
                store_update.delete(COL_BLOCK_INDEX, &index_to_bytes(height));
            }
        }
        for (hash, receipt) in self.receipts.drain() {
            store_update.set_ser(COL_RECEIPTS, hash.as_ref(), &receipt)?;
        }
        for (hash, tx_result) in self.transaction_results.drain() {
            store_update.set_ser(COL_TRANSACTION_RESULT, hash.as_ref(), &tx_result)?;
        }
        if let Some(trie_changes) = self.trie_changes {
            trie_changes
                .insertions_into(&mut store_update)
                .map_err(|err| ErrorKind::Other(err.to_string()))?;
            // TODO: save deletions separately for garbage collection.
        }
        for other in self.store_updates {
            store_update.merge(other);
        }
        Ok(store_update)
    }

    pub fn commit(self) -> Result<(), Error> {
        let store_update = self.finalize()?;
        store_update.commit().map_err(|e| e.into())
    }
}

'''
'''--- chain/chain/src/test_utils.rs ---
use std::collections::HashMap;
use std::sync::Arc;

use chrono::Utc;

use near_primitives::crypto::signature::{PublicKey, Signature};
use near_primitives::crypto::signer::{EDSigner, InMemorySigner};
use near_primitives::hash::CryptoHash;
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::test_utils::get_public_key_from_seed;
use near_primitives::transaction::{
    ReceiptTransaction, SignedTransaction, TransactionResult, TransactionStatus,
};
use near_primitives::types::{AccountId, BlockIndex, MerkleHash, ShardId};
use near_store::test_utils::create_test_store;
use near_store::{Store, StoreUpdate, Trie, TrieChanges, WrappedTrieChanges};
use node_runtime::state_viewer::AccountViewCallResult;

use crate::error::{Error, ErrorKind};
use crate::types::{BlockHeader, ReceiptResult, RuntimeAdapter, Weight};
use crate::{Block, Chain, ValidTransaction};

impl Block {
    pub fn empty(prev: &BlockHeader, signer: Arc<dyn EDSigner>) -> Self {
        Block::produce(
            prev,
            prev.height + 1,
            prev.prev_state_root,
            vec![],
            HashMap::default(),
            vec![],
            signer,
        )
    }
}

/// Simple key value runtime for tests.
pub struct KeyValueRuntime {
    store: Arc<Store>,
    trie: Arc<Trie>,
    root: MerkleHash,
    validators: Vec<(AccountId, PublicKey)>,
}

impl KeyValueRuntime {
    pub fn new(store: Arc<Store>) -> Self {
        Self::new_with_validators(store, vec!["test".to_string()])
    }

    pub fn new_with_validators(store: Arc<Store>, validators: Vec<AccountId>) -> Self {
        let trie = Arc::new(Trie::new(store.clone()));
        KeyValueRuntime {
            store,
            trie,
            root: MerkleHash::default(),
            validators: validators
                .iter()
                .map(|account_id| (account_id.clone(), get_public_key_from_seed(account_id)))
                .collect(),
        }
    }

    pub fn get_root(&self) -> MerkleHash {
        self.root
    }
}

impl RuntimeAdapter for KeyValueRuntime {
    fn genesis_state(&self, _shard_id: ShardId) -> (StoreUpdate, MerkleHash) {
        (self.store.store_update(), MerkleHash::default())
    }

    fn compute_block_weight(
        &self,
        prev_header: &BlockHeader,
        header: &BlockHeader,
    ) -> Result<Weight, Error> {
        let (_account_id, public_key) =
            &self.validators[(header.height as usize) % self.validators.len()];
        if !header.verify_block_producer(public_key) {
            return Err(ErrorKind::InvalidBlockProposer.into());
        }
        Ok(prev_header.total_weight.next(header.approval_sigs.len() as u64))
    }

    fn get_epoch_block_proposers(
        &self,
        _height: BlockIndex,
    ) -> Result<Vec<(AccountId, u64)>, Box<dyn std::error::Error>> {
        Ok(self.validators.iter().map(|x| (x.0.clone(), 1)).collect())
    }

    fn get_block_proposer(
        &self,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>> {
        Ok(self.validators[(height as usize) % self.validators.len()].0.clone())
    }

    fn get_chunk_proposer(
        &self,
        _shard_id: ShardId,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>> {
        Ok(self.validators[(height as usize) % self.validators.len()].0.clone())
    }

    fn check_validator_signature(&self, _account_id: &AccountId, _signature: &Signature) -> bool {
        true
    }

    fn num_shards(&self) -> ShardId {
        1
    }

    fn account_id_to_shard_id(&self, _account_id: &AccountId) -> ShardId {
        0
    }

    fn validate_tx(
        &self,
        _shard_id: ShardId,
        _state_root: MerkleHash,
        transaction: SignedTransaction,
    ) -> Result<ValidTransaction, String> {
        Ok(ValidTransaction { transaction })
    }

    fn apply_transactions(
        &self,
        _shard_id: ShardId,
        state_root: &MerkleHash,
        _block_index: BlockIndex,
        _prev_block_hash: &CryptoHash,
        _receipts: &Vec<Vec<ReceiptTransaction>>,
        transactions: &Vec<SignedTransaction>,
    ) -> Result<
        (WrappedTrieChanges, MerkleHash, Vec<TransactionResult>, ReceiptResult),
        Box<dyn std::error::Error>,
    > {
        let mut tx_results = vec![];
        for _ in transactions {
            tx_results.push(TransactionResult {
                status: TransactionStatus::Completed,
                logs: vec![],
                receipts: vec![],
                result: None,
            });
        }
        Ok((
            WrappedTrieChanges::new(self.trie.clone(), TrieChanges::empty(state_root.clone())),
            *state_root,
            tx_results,
            HashMap::default(),
        ))
    }

    fn query(
        &self,
        _state_root: MerkleHash,
        _height: BlockIndex,
        path: &str,
        _data: &[u8],
    ) -> Result<ABCIQueryResponse, Box<dyn std::error::Error>> {
        let path = path.split("/").collect::<Vec<_>>();
        Ok(ABCIQueryResponse::account(
            path[1],
            AccountViewCallResult {
                account_id: path[1].to_string(),
                nonce: 0,
                amount: 1000,
                stake: 0,
                public_keys: vec![],
                code_hash: CryptoHash::default(),
            },
        ))
    }
}

pub fn setup() -> (Chain, Arc<KeyValueRuntime>, Arc<InMemorySigner>) {
    let store = create_test_store();
    let runtime = Arc::new(KeyValueRuntime::new(store.clone()));
    let chain = Chain::new(store, runtime.clone(), Utc::now()).unwrap();
    let signer = Arc::new(InMemorySigner::from_seed("test", "test"));
    (chain, runtime, signer)
}

'''
'''--- chain/chain/src/types.rs ---
use std::collections::HashMap;
use std::convert::{TryFrom, TryInto};
use std::fmt;
use std::iter::FromIterator;
use std::sync::Arc;

use chrono::prelude::{DateTime, NaiveDateTime, Utc};
use chrono::serde::ts_nanoseconds;
use protobuf::{Message as ProtoMessage, RepeatedField, SingularPtrField};

use near_primitives::crypto::signature::{verify, PublicKey, Signature, DEFAULT_SIGNATURE};
use near_primitives::crypto::signer::EDSigner;
use near_primitives::hash::{hash, CryptoHash};
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::transaction::{ReceiptTransaction, SignedTransaction, TransactionResult};
use near_primitives::types::{AccountId, BlockIndex, MerkleHash, ShardId, ValidatorStake};
use near_primitives::utils::proto_to_type;
use near_protos::chain as chain_proto;
use near_store::{StoreUpdate, WrappedTrieChanges};

use crate::error::Error;

/// Number of nano seconds in one second.
const NS_IN_SECOND: u64 = 1_000_000_000;

#[derive(Serialize, Deserialize, Debug, Clone, Eq, PartialEq)]
pub struct BlockHeader {
    /// Height of this block since the genesis block (height 0).
    pub height: BlockIndex,
    /// Hash of the block previous to this in the chain.
    pub prev_hash: CryptoHash,
    /// Root hash of the state at the previous block.
    pub prev_state_root: MerkleHash,
    /// Root hash of the transactions in the given block.
    pub tx_root: MerkleHash,
    /// Timestamp at which the block was built.
    #[serde(with = "ts_nanoseconds")]
    pub timestamp: DateTime<Utc>,
    /// Approval mask, given current block producers.
    pub approval_mask: Vec<bool>,
    /// Approval signatures.
    pub approval_sigs: Vec<Signature>,
    /// Total weight.
    pub total_weight: Weight,
    /// Validator proposals.
    pub validator_proposal: Vec<ValidatorStake>,

    /// Signature of the block producer.
    pub signature: Signature,

    /// Cached value of hash for this block.
    hash: CryptoHash,
}

impl BlockHeader {
    fn header_body(
        height: BlockIndex,
        prev_hash: CryptoHash,
        prev_state_root: MerkleHash,
        tx_root: MerkleHash,
        timestamp: DateTime<Utc>,
        approval_mask: Vec<bool>,
        approval_sigs: Vec<Signature>,
        total_weight: Weight,
        mut validator_proposal: Vec<ValidatorStake>,
    ) -> chain_proto::BlockHeaderBody {
        chain_proto::BlockHeaderBody {
            height,
            prev_hash: prev_hash.into(),
            prev_state_root: prev_state_root.into(),
            tx_root: tx_root.into(),
            timestamp: timestamp.timestamp_nanos() as u64,
            approval_mask,
            approval_sigs: RepeatedField::from_iter(
                approval_sigs.iter().map(std::convert::Into::into),
            ),
            total_weight: total_weight.to_num(),
            validator_proposal: RepeatedField::from_iter(
                validator_proposal.drain(..).map(std::convert::Into::into),
            ),
            ..Default::default()
        }
    }

    pub fn new(
        height: BlockIndex,
        prev_hash: CryptoHash,
        prev_state_root: MerkleHash,
        tx_root: MerkleHash,
        timestamp: DateTime<Utc>,
        approval_mask: Vec<bool>,
        approval_sigs: Vec<Signature>,
        total_weight: Weight,
        validator_proposal: Vec<ValidatorStake>,
        signer: Arc<dyn EDSigner>,
    ) -> Self {
        let hb = Self::header_body(
            height,
            prev_hash,
            prev_state_root,
            tx_root,
            timestamp,
            approval_mask,
            approval_sigs,
            total_weight,
            validator_proposal,
        );
        let bytes = hb.write_to_bytes().expect("Failed to serialize");
        let hash = hash(&bytes);
        let h = chain_proto::BlockHeader {
            body: SingularPtrField::some(hb),
            signature: signer.sign(hash.as_ref()).into(),
            ..Default::default()
        };
        h.try_into().expect("Failed to parse just created header")
    }

    pub fn genesis(state_root: MerkleHash, timestamp: DateTime<Utc>) -> Self {
        chain_proto::BlockHeader {
            body: SingularPtrField::some(Self::header_body(
                0,
                CryptoHash::default(),
                state_root,
                MerkleHash::default(),
                timestamp,
                vec![],
                vec![],
                0.into(),
                vec![],
            )),
            signature: DEFAULT_SIGNATURE.into(),
            ..Default::default()
        }
        .try_into()
        .expect("Failed to parse just created header")
    }

    pub fn hash(&self) -> CryptoHash {
        self.hash
    }

    /// Verifies that given public key produced the block.
    pub fn verify_block_producer(&self, public_key: &PublicKey) -> bool {
        verify(self.hash.as_ref(), &self.signature, public_key)
    }
}

impl TryFrom<chain_proto::BlockHeader> for BlockHeader {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: chain_proto::BlockHeader) -> Result<Self, Self::Error> {
        let body = proto.body.into_option().ok_or("Missing Header body")?;
        let bytes = body.write_to_bytes().map_err(|err| err.to_string())?;
        let hash = hash(&bytes);
        let height = body.height;
        let prev_hash = body.prev_hash.try_into()?;
        let prev_state_root = body.prev_state_root.try_into()?;
        let tx_root = body.tx_root.try_into()?;
        let timestamp = DateTime::from_utc(
            NaiveDateTime::from_timestamp(
                (body.timestamp / NS_IN_SECOND) as i64,
                (body.timestamp % NS_IN_SECOND) as u32,
            ),
            Utc,
        );
        let approval_mask = body.approval_mask;
        let approval_sigs =
            body.approval_sigs.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let total_weight = body.total_weight.into();
        let signature = proto.signature.try_into()?;
        let validator_proposal = body
            .validator_proposal
            .into_iter()
            .map(TryInto::try_into)
            .collect::<Result<Vec<_>, _>>()?;
        Ok(BlockHeader {
            height,
            prev_hash,
            prev_state_root,
            tx_root,
            timestamp,
            approval_mask,
            approval_sigs,
            total_weight,
            validator_proposal,
            signature,
            hash,
        })
    }
}

impl From<BlockHeader> for chain_proto::BlockHeader {
    fn from(mut header: BlockHeader) -> Self {
        chain_proto::BlockHeader {
            body: SingularPtrField::some(chain_proto::BlockHeaderBody {
                height: header.height,
                prev_hash: header.prev_hash.into(),
                prev_state_root: header.prev_state_root.into(),
                tx_root: header.tx_root.into(),
                timestamp: header.timestamp.timestamp_nanos() as u64,
                approval_mask: header.approval_mask,
                approval_sigs: RepeatedField::from_iter(
                    header.approval_sigs.iter().map(std::convert::Into::into),
                ),
                total_weight: header.total_weight.to_num(),
                validator_proposal: RepeatedField::from_iter(
                    header.validator_proposal.drain(..).map(std::convert::Into::into),
                ),
                ..Default::default()
            }),
            signature: header.signature.into(),
            ..Default::default()
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct Bytes(Vec<u8>);

#[derive(Serialize, Deserialize, Debug, Clone, Eq, PartialEq)]
pub struct Block {
    pub header: BlockHeader,
    pub transactions: Vec<SignedTransaction>,
}

impl Block {
    /// Returns genesis block for given genesis date and state root.
    pub fn genesis(state_root: MerkleHash, timestamp: DateTime<Utc>) -> Self {
        Block { header: BlockHeader::genesis(state_root, timestamp), transactions: vec![] }
    }

    /// Produces new block from header of previous block, current state root and set of transactions.
    pub fn produce(
        prev: &BlockHeader,
        height: BlockIndex,
        state_root: MerkleHash,
        transactions: Vec<SignedTransaction>,
        mut approvals: HashMap<usize, Signature>,
        validator_proposal: Vec<ValidatorStake>,
        signer: Arc<dyn EDSigner>,
    ) -> Self {
        // TODO: merkelize transactions.
        let tx_root = CryptoHash::default();
        let (approval_mask, approval_sigs) = if let Some(max_approver) = approvals.keys().max() {
            (
                (0..=*max_approver).map(|i| approvals.contains_key(&i)).collect(),
                (0..=*max_approver).filter_map(|i| approvals.remove(&i)).collect(),
            )
        } else {
            (vec![], vec![])
        };
        let total_weight = (prev.total_weight.to_num() + (approval_sigs.len() as u64) + 1).into();
        Block {
            header: BlockHeader::new(
                height,
                prev.hash(),
                state_root,
                tx_root,
                Utc::now(),
                approval_mask,
                approval_sigs,
                total_weight,
                validator_proposal,
                signer,
            ),
            transactions,
        }
    }

    pub fn hash(&self) -> CryptoHash {
        self.header.hash()
    }
}

impl TryFrom<chain_proto::Block> for Block {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: chain_proto::Block) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(Block { header: proto_to_type(proto.header)?, transactions })
    }
}

impl From<Block> for chain_proto::Block {
    fn from(block: Block) -> Self {
        chain_proto::Block {
            header: SingularPtrField::some(block.header.into()),
            transactions: block.transactions.into_iter().map(std::convert::Into::into).collect(),
            ..Default::default()
        }
    }
}

#[derive(Eq, PartialEq, Debug)]
pub enum BlockStatus {
    /// Block is the "next" block, updating the chain head.
    Next,
    /// Block does not update the chain head and is a fork.
    Fork,
    /// Block updates the chain head via a (potentially disruptive) "reorg".
    /// Previous block was not our previous chain head.
    Reorg,
}

/// Options for block origin.
#[derive(Eq, PartialEq)]
pub enum Provenance {
    /// No provenance.
    NONE,
    /// Adds block while in syncing mode.
    SYNC,
    /// Block we produced ourselves.
    PRODUCED,
}

/// Information about valid transaction that was processed by chain + runtime.
pub struct ValidTransaction {
    pub transaction: SignedTransaction,
}

/// Map of shard to list of receipts to send to it.
pub type ReceiptResult = HashMap<ShardId, Vec<ReceiptTransaction>>;

/// Bridge between the chain and the runtime.
/// Main function is to update state given transactions.
/// Additionally handles validators and block weight computation.
pub trait RuntimeAdapter: Send + Sync {
    /// Initialize state to genesis state and returns StoreUpdate and state root.
    /// StoreUpdate can be discarded if the chain past the genesis.
    fn genesis_state(&self, shard_id: ShardId) -> (StoreUpdate, MerkleHash);

    /// Verify block producer validity and return weight of given block for fork choice rule.
    fn compute_block_weight(
        &self,
        prev_header: &BlockHeader,
        header: &BlockHeader,
    ) -> Result<Weight, Error>;

    /// Epoch block proposers with number of seats they have for given shard.
    /// Returns error if height is outside of known boundaries.
    fn get_epoch_block_proposers(
        &self,
        height: BlockIndex,
    ) -> Result<Vec<(AccountId, u64)>, Box<dyn std::error::Error>>;

    /// Block proposer for given height for the main block. Return error if outside of known boundaries.
    fn get_block_proposer(
        &self,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>>;

    /// Chunk proposer for given height for given shard. Return error if outside of known boundaries.
    fn get_chunk_proposer(
        &self,
        shard_id: ShardId,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>>;

    /// Check validator's signature.
    fn check_validator_signature(&self, account_id: &AccountId, signature: &Signature) -> bool;

    /// Get current number of shards.
    fn num_shards(&self) -> ShardId;

    /// Account Id to Shard Id mapping, given current number of shards.
    fn account_id_to_shard_id(&self, account_id: &AccountId) -> ShardId;

    /// Validate transaction and return transaction information relevant to ordering it in the mempool.
    fn validate_tx(
        &self,
        shard_id: ShardId,
        state_root: MerkleHash,
        transaction: SignedTransaction,
    ) -> Result<ValidTransaction, String>;

    /// Apply transactions to given state root and return store update and new state root.
    /// Also returns transaction result for each transaction and new receipts.
    fn apply_transactions(
        &self,
        shard_id: ShardId,
        merkle_hash: &MerkleHash,
        block_index: BlockIndex,
        prev_block_hash: &CryptoHash,
        receipts: &Vec<Vec<ReceiptTransaction>>,
        transactions: &Vec<SignedTransaction>,
    ) -> Result<
        (WrappedTrieChanges, MerkleHash, Vec<TransactionResult>, ReceiptResult),
        Box<dyn std::error::Error>,
    >;

    /// Query runtime with given `path` and `data`.
    fn query(
        &self,
        state_root: MerkleHash,
        height: BlockIndex,
        path: &str,
        data: &[u8],
    ) -> Result<ABCIQueryResponse, Box<dyn std::error::Error>>;
}

/// The weight is defined as the number of unique validators approving this fork.
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord, Serialize, Deserialize)]
pub struct Weight {
    num: u64,
}

impl Weight {
    pub fn to_num(&self) -> u64 {
        self.num
    }

    pub fn next(&self, num: u64) -> Self {
        Weight { num: self.num + num + 1 }
    }
}

impl From<u64> for Weight {
    fn from(num: u64) -> Self {
        Weight { num }
    }
}

impl fmt::Display for Weight {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", self.num)
    }
}

/// The tip of a fork. A handle to the fork ancestry from its leaf in the
/// blockchain tree. References the max height and the latest and previous
/// blocks for convenience and the total weight.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct Tip {
    /// Height of the tip (max height of the fork)
    pub height: u64,
    /// Last block pushed to the fork
    pub last_block_hash: CryptoHash,
    /// Previous block
    pub prev_block_hash: CryptoHash,
    /// Total weight on that fork
    pub total_weight: Weight,
}

impl Tip {
    /// Creates a new tip based on provided header.
    pub fn from_header(header: &BlockHeader) -> Tip {
        Tip {
            height: header.height,
            last_block_hash: header.hash(),
            prev_block_hash: header.prev_hash,
            total_weight: header.total_weight,
        }
    }
}

/// Block approval by other block producers.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct BlockApproval {
    pub hash: CryptoHash,
    pub signature: Signature,
    pub target: AccountId,
}

impl BlockApproval {
    pub fn new(hash: CryptoHash, signer: &dyn EDSigner, target: AccountId) -> Self {
        let signature = signer.sign(hash.as_ref());
        BlockApproval { hash, signature, target }
    }
}

#[cfg(test)]
mod tests {
    use near_primitives::crypto::signer::InMemorySigner;

    use super::*;

    #[test]
    fn test_block_produce() {
        let genesis = Block::genesis(MerkleHash::default(), Utc::now());
        let signer = Arc::new(InMemorySigner::from_seed("other", "other"));
        let b1 = Block::produce(
            &genesis.header,
            1,
            MerkleHash::default(),
            vec![],
            HashMap::default(),
            vec![],
            signer.clone(),
        );
        assert!(signer.verify(b1.hash().as_ref(), &b1.header.signature));
        assert_eq!(b1.header.total_weight.to_num(), 1);
        let other_signer = Arc::new(InMemorySigner::from_seed("other2", "other2"));
        let approvals: HashMap<usize, Signature> =
            vec![(1, other_signer.sign(b1.hash().as_ref()))].into_iter().collect();
        let b2 = Block::produce(
            &b1.header,
            2,
            MerkleHash::default(),
            vec![],
            approvals,
            vec![],
            signer.clone(),
        );
        assert!(signer.verify(b2.hash().as_ref(), &b2.header.signature));
        assert_eq!(b2.header.total_weight.to_num(), 3);
    }
}

'''
'''--- chain/chain/tests/simple_chain.rs ---
use std::collections::HashMap;

use near_chain::test_utils::setup;
use near_chain::{Block, ErrorKind, Provenance};
use near_primitives::test_utils::init_test_logger;
use near_primitives::types::MerkleHash;

#[test]
fn empty_chain() {
    init_test_logger();
    let (chain, _, _) = setup();
    assert_eq!(chain.head().unwrap().height, 0);
}

#[test]
fn build_chain() {
    init_test_logger();
    let (mut chain, _, signer) = setup();
    for i in 0..4 {
        let prev = chain.head_header().unwrap();
        let block = Block::empty(&prev, signer.clone());
        let tip = chain.process_block(block, Provenance::PRODUCED, |_, _, _| {}).unwrap();
        assert_eq!(tip.unwrap().height, i + 1);
    }
    assert_eq!(chain.head().unwrap().height, 4);
}

#[test]
fn build_chain_with_orhpans() {
    init_test_logger();
    let (mut chain, _, signer) = setup();
    let mut blocks = vec![chain.get_block(&chain.genesis().hash()).unwrap().clone()];
    for i in 1..4 {
        let block = Block::empty(&blocks[i - 1].header, signer.clone());
        blocks.push(block);
    }
    assert_eq!(
        chain
            .process_block(blocks.pop().unwrap(), Provenance::PRODUCED, |_, _, _| {})
            .unwrap_err()
            .kind(),
        ErrorKind::Orphan
    );
    assert_eq!(
        chain
            .process_block(blocks.pop().unwrap(), Provenance::PRODUCED, |_, _, _| {})
            .unwrap_err()
            .kind(),
        ErrorKind::Orphan
    );
    let res = chain.process_block(blocks.pop().unwrap(), Provenance::PRODUCED, |_, _, _| {});
    assert_eq!(res.unwrap().unwrap().height, 3);
    assert_eq!(
        chain
            .process_block(blocks.pop().unwrap(), Provenance::PRODUCED, |_, _, _| {})
            .unwrap_err()
            .kind(),
        ErrorKind::Unfit("already known in store".to_string())
    );
}

#[test]
fn build_chain_with_skips_and_forks() {
    init_test_logger();
    let (mut chain, _, signer) = setup();
    let b1 = Block::empty(chain.genesis(), signer.clone());
    let b2 = Block::produce(
        chain.genesis(),
        2,
        MerkleHash::default(),
        vec![],
        HashMap::default(),
        vec![],
        signer.clone(),
    );
    let b3 = Block::empty(&b1.header, signer.clone());
    let b4 = Block::produce(
        &b2.header,
        4,
        MerkleHash::default(),
        vec![],
        HashMap::default(),
        vec![],
        signer.clone(),
    );
    let b5 = Block::empty(&b4.header, signer);
    assert!(chain.process_block(b1, Provenance::PRODUCED, |_, _, _| {}).is_ok());
    assert!(chain.process_block(b2, Provenance::PRODUCED, |_, _, _| {}).is_ok());
    assert!(chain.process_block(b3, Provenance::PRODUCED, |_, _, _| {}).is_ok());
    assert!(chain.process_block(b4, Provenance::PRODUCED, |_, _, _| {}).is_ok());
    assert!(chain.process_block(b5, Provenance::PRODUCED, |_, _, _| {}).is_ok());
    assert!(chain.get_header_by_height(1).is_err());
    assert_eq!(chain.get_header_by_height(5).unwrap().height, 5);
}

'''
'''--- chain/chain/tests/sync_chain.rs ---
use near_chain::test_utils::setup;
use near_chain::Block;
use near_primitives::test_utils::init_test_logger;

#[test]
fn chain_sync_headers() {
    init_test_logger();
    let (mut chain, _, signer) = setup();
    assert_eq!(chain.sync_head().unwrap().height, 0);
    let mut headers = vec![chain.genesis().clone()];
    for i in 0..4 {
        headers.push(Block::empty(&headers[i], signer.clone()).header);
    }
    chain.sync_block_headers(headers.drain(1..).collect()).unwrap();
    assert_eq!(chain.sync_head().unwrap().height, 4);
}

'''
'''--- chain/client/Cargo.toml ---
[package]
name = "near-client"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
ansi_term = "0.11.0"
actix = "0.8.1"
futures = "0.1"
chrono = { version = "0.4.4", features = ["serde"] }
kvdb = "0.1"
log = "0.4"
rand = "0.6.5"
serde_derive = "1.0"
serde = { version = "1.0", features = ["derive"] }

near-primitives = { path = "../../core/primitives" }
near-store = { path = "../../core/store" }
near-chain = { path = "../chain" }
near-network = { path = "../network" }
near-pool = { path = "../pool" }

'''
'''--- chain/client/src/client.rs ---
//! Client is responsible for tracking the chain and related pieces of infrastructure.
//! Block production is done in done in this actor as well (at the moment).

use std::collections::HashMap;
use std::error::Error as StdError;
use std::ops::Sub;
use std::sync::{Arc, RwLock};
use std::time::Instant;

use actix::{
    Actor, ActorFuture, AsyncContext, Context, ContextFutureSpawner, Handler, Recipient, WrapFuture,
};
use ansi_term::Color::{Cyan, Green, White, Yellow};
use chrono::{DateTime, Utc};
use log::{debug, error, info, warn};

use near_chain::{
    Block, BlockApproval, BlockHeader, BlockStatus, Chain, Provenance, RuntimeAdapter,
    ValidTransaction,
};
use near_network::types::{PeerId, ReasonForBan};
use near_network::{
    NetworkClientMessages, NetworkClientResponses, NetworkRequests, NetworkResponses,
};
use near_pool::TransactionPool;
use near_primitives::crypto::signature::Signature;
use near_primitives::hash::CryptoHash;
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::{AccountId, BlockIndex};
use near_store::Store;

use crate::sync::{most_weight_peer, BlockSync, HeaderSync};
use crate::types::{
    BlockProducer, ClientConfig, Error, NetworkInfo, Status, StatusSyncInfo, SyncStatus,
};
use crate::{sync, StatusResponse};

/// Macro to either return value if the result is Ok, or exit function logging error.
macro_rules! unwrap_or_return(($obj: expr) => (match $obj {
    Ok(value) => value,
    Err(err) => {
        error!(target: "client", "Error: {:?}", err);
        return
    }
}));

pub struct ClientActor {
    config: ClientConfig,
    sync_status: SyncStatus,
    chain: Chain,
    runtime_adapter: Arc<dyn RuntimeAdapter>,
    tx_pool: TransactionPool,
    network_actor: Recipient<NetworkRequests>,
    block_producer: Option<BlockProducer>,
    network_info: NetworkInfo,
    /// Set of approvals for the next block.
    approvals: HashMap<usize, Signature>,
    /// Timestamp when last block was received / processed. Used to timeout block production.
    last_block_processed: Instant,
    /// Keeps track of syncing headers.
    header_sync: HeaderSync,
    block_sync: BlockSync,
    /// Timestamp when client was started.
    started: Instant,
    /// Total number of blocks processed.
    num_blocks_processed: u64,
    /// Total number of transactions processed.
    num_tx_processed: u64,
}

impl ClientActor {
    pub fn new(
        config: ClientConfig,
        store: Arc<Store>,
        genesis_time: DateTime<Utc>,
        runtime_adapter: Arc<dyn RuntimeAdapter>,
        network_actor: Recipient<NetworkRequests>,
        block_producer: Option<BlockProducer>,
    ) -> Result<Self, Error> {
        // TODO: Wait until genesis.
        let chain = Chain::new(store, runtime_adapter.clone(), genesis_time)?;
        let tx_pool = TransactionPool::new();
        let sync_status = SyncStatus::AwaitingPeers;
        let header_sync = HeaderSync::new(network_actor.clone());
        let block_sync = BlockSync::new(network_actor.clone());
        if let Some(bp) = &block_producer {
            info!(target: "client", "Starting validator node: {}", bp.account_id);
        }
        Ok(ClientActor {
            config,
            sync_status,
            chain,
            runtime_adapter,
            tx_pool,
            network_actor,
            block_producer,
            network_info: NetworkInfo {
                num_active_peers: 0,
                peer_max_count: 0,
                most_weight_peers: vec![],
            },
            approvals: HashMap::default(),
            last_block_processed: Instant::now(),
            header_sync,
            block_sync,
            started: Instant::now(),
            num_blocks_processed: 0,
            num_tx_processed: 0,
        })
    }
}

impl Actor for ClientActor {
    type Context = Context<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        // Start syncing job.
        self.start_sync(ctx);

        // Start fetching information from network.
        self.fetch_network_info(ctx);

        // Start periodic logging of current state of the client.
        self.log_summary(ctx);
    }
}

impl Handler<NetworkClientMessages> for ClientActor {
    type Result = NetworkClientResponses;

    fn handle(&mut self, msg: NetworkClientMessages, ctx: &mut Context<Self>) -> Self::Result {
        match msg {
            NetworkClientMessages::Transaction(tx) => match self.validate_tx(tx) {
                Ok(valid_transaction) => {
                    self.tx_pool.insert_transaction(valid_transaction);
                    NetworkClientResponses::ValidTx
                }
                Err(err) => NetworkClientResponses::InvalidTx(err),
            },
            NetworkClientMessages::BlockHeader(header, peer_id) => {
                self.receive_header(header, peer_id)
            }
            NetworkClientMessages::Block(block, peer_id, was_requested) => {
                self.receive_block(ctx, block, peer_id, was_requested)
            }
            NetworkClientMessages::BlockRequest(hash) => {
                if let Ok(block) = self.chain.get_block(&hash) {
                    NetworkClientResponses::Block(block.clone())
                } else {
                    NetworkClientResponses::NoResponse
                }
            }
            NetworkClientMessages::BlockHeadersRequest(hashes) => {
                if let Ok(headers) = self.retrieve_headers(hashes) {
                    NetworkClientResponses::BlockHeaders(headers)
                } else {
                    NetworkClientResponses::NoResponse
                }
            }
            NetworkClientMessages::GetChainInfo => match self.chain.head() {
                Ok(head) => NetworkClientResponses::ChainInfo {
                    height: head.height,
                    total_weight: head.total_weight,
                },
                Err(err) => {
                    error!(target: "client", "{}", err);
                    NetworkClientResponses::NoResponse
                }
            },
            NetworkClientMessages::BlockHeaders(headers, peer_id) => {
                if self.receive_headers(headers, peer_id) {
                    NetworkClientResponses::NoResponse
                } else {
                    warn!(target: "client", "Banning node for sending invalid block headers");
                    NetworkClientResponses::Ban { ban_reason: ReasonForBan::BadBlockHeader }
                }
            }
            NetworkClientMessages::BlockApproval(account_id, hash, signature) => {
                if self.collect_block_approval(&account_id, &hash, &signature) {
                    NetworkClientResponses::NoResponse
                } else {
                    warn!(target: "client", "Banning node for sending invalid block approval: {} {} {}", account_id, hash, signature);
                    NetworkClientResponses::Ban { ban_reason: ReasonForBan::BadBlockApproval }
                }
            }
        }
    }
}

impl Handler<Status> for ClientActor {
    type Result = Result<StatusResponse, String>;

    fn handle(&mut self, _: Status, _: &mut Context<Self>) -> Self::Result {
        let head = self.chain.head().map_err(|err| err.to_string())?;
        let last_header =
            self.chain.get_block_header(&head.last_block_hash).map_err(|err| err.to_string())?;
        let latest_block_time = last_header.timestamp.clone();
        let state_root =
            self.chain.get_post_state_root(&head.last_block_hash).map_err(|err| err.to_string())?;
        let validators = self
            .runtime_adapter
            .get_epoch_block_proposers(head.height)
            .map_err(|err| err.to_string())?
            .drain(..)
            .map(|(account_id, _)| account_id)
            .collect();
        Ok(StatusResponse {
            chain_id: self.config.chain_id.clone(),
            rpc_addr: self.config.rpc_addr.clone(),
            validators,
            sync_info: StatusSyncInfo {
                latest_block_hash: head.last_block_hash,
                latest_block_height: head.height,
                latest_state_root: state_root.clone(),
                latest_block_time,
                syncing: self.sync_status.is_syncing(),
            },
        })
    }
}

impl ClientActor {
    /// Gets called when block got accepted.
    /// Send updates over network, update tx pool and notify ourselves if it's time to produce next block.
    fn on_block_accepted(
        &mut self,
        ctx: &mut Context<ClientActor>,
        block_hash: CryptoHash,
        status: BlockStatus,
        provenance: Provenance,
    ) {
        let block = match self.chain.get_block(&block_hash) {
            Ok(block) => block.clone(),
            Err(err) => {
                error!(target: "client", "Failed to find block {} that was just accepted: {}", block_hash, err);
                return;
            }
        };

        // Update when last block was processed.
        self.last_block_processed = Instant::now();

        if provenance != Provenance::SYNC {
            self.num_blocks_processed += 1;
            self.num_tx_processed += block.transactions.len() as u64;

            // If we produced the block, then we want to broadcast it.
            // If received the block from another node then broadcast "header first" to minimise network traffic.
            if provenance == Provenance::PRODUCED {
                let _ = self.network_actor.do_send(NetworkRequests::Block { block: block.clone() });
            } else {
                let approval = self.get_block_approval(&block);
                let _ = self.network_actor.do_send(NetworkRequests::BlockHeaderAnnounce {
                    header: block.header.clone(),
                    approval,
                });
            }

            // If this is block producing node and next block is produced by us, schedule to produce a block after a delay.
            self.handle_scheduling_block_production(ctx, block.header.height, block.header.height);
        }

        // Reconcile the txpool against the new block *after* we have broadcast it too our peers.
        // This may be slow and we do not want to delay block propagation.
        // We only want to reconcile the txpool against the new block *if* total weight has increased.
        if status == BlockStatus::Next || status == BlockStatus::Reorg {
            self.tx_pool.reconcile_block(&block);
        }
    }

    /// Create approval for given block or return none if not a block producer.
    fn get_block_approval(&mut self, block: &Block) -> Option<BlockApproval> {
        let next_block_producer_account =
            self.runtime_adapter.get_block_proposer(block.header.height + 1);
        if let (Some(block_producer), Ok(next_block_producer_account)) =
            (&self.block_producer, &next_block_producer_account)
        {
            if &block_producer.account_id != next_block_producer_account {
                if let Ok(validators) = self
                    .runtime_adapter
                    .get_epoch_block_proposers(block.header.height)
                    .map(|mut x| x.drain(..).map(|v| v.0).collect::<Vec<_>>())
                {
                    if validators.contains(&block_producer.account_id) {
                        return Some(BlockApproval::new(
                            block.hash(),
                            &*block_producer.signer,
                            next_block_producer_account.clone(),
                        ));
                    }
                }
            }
        }
        None
    }

    /// Checks if we are block producer and if we are next block producer schedules calling `produce_block`.
    /// If we are not next block producer, schedule to check timeout.
    fn handle_scheduling_block_production(
        &mut self,
        ctx: &mut Context<ClientActor>,
        last_height: BlockIndex,
        check_height: BlockIndex,
    ) {
        // TODO: check this block producer is at all involved in this epoch. If not, check back after some time.
        let next_block_producer_account =
            unwrap_or_return!(self.runtime_adapter.get_block_proposer(check_height + 1));
        if let Some(block_producer) = &self.block_producer {
            if block_producer.account_id.clone() == next_block_producer_account {
                ctx.run_later(self.config.min_block_production_delay, move |act, ctx| {
                    act.produce_block(ctx, last_height, check_height + 1);
                });
            } else {
                // Otherwise, schedule timeout to check if the next block was produced.
                ctx.run_later(self.config.max_block_production_delay, move |act, ctx| {
                    act.check_block_timeout(ctx, last_height, check_height);
                });
            }
        }
    }

    /// Checks if next block was produced within timeout, if not check if we should produce next block.
    /// `last_height` is the height of the `head` at the point of scheduling,
    /// `check_height` is the height at which to call `handle_scheduling_block_production` to skip non received blocks.
    /// TODO: should we send approvals for `last_height` block to next block producer?
    fn check_block_timeout(
        &mut self,
        ctx: &mut Context<ClientActor>,
        last_height: BlockIndex,
        check_height: BlockIndex,
    ) {
        let head = unwrap_or_return!(self.chain.head());
        // If height changed since we scheduled this, exit.
        if head.height != last_height {
            return;
        }
        debug!(target: "client", "Timeout for {}, current head {}, suggesting to skip", last_height, head.height);
        // Update how long ago last block arrived to reset block production timer.
        self.last_block_processed = Instant::now();
        self.handle_scheduling_block_production(ctx, last_height, check_height + 1);
    }

    /// Produce block if we are block producer for given block. If error happens, retry.
    fn produce_block(
        &mut self,
        ctx: &mut Context<ClientActor>,
        last_height: BlockIndex,
        next_height: BlockIndex,
    ) {
        if let Err(err) = self.produce_block_err(ctx, last_height, next_height) {
            error!(target: "client", "Block production failed: {:?}", err);
            self.handle_scheduling_block_production(ctx, last_height, next_height - 1);
        }
    }

    /// Produce block if we are block producer for given `next_height` index.
    /// Can return error, should be called with `produce_block` to handle errors and reschedule.
    fn produce_block_err(
        &mut self,
        ctx: &mut Context<ClientActor>,
        last_height: BlockIndex,
        next_height: BlockIndex,
    ) -> Result<(), Error> {
        let block_producer = self.block_producer.as_ref().ok_or_else(|| {
            Error::BlockProducer("Called without block producer info.".to_string())
        })?;
        let head = self.chain.head()?;
        // If last height changed, this process should stop as we spun up another one.
        if head.height != last_height {
            return Ok(());
        }
        // Check that we are were called at the block that we are producer for.
        let next_block_proposer = self
            .runtime_adapter
            .get_block_proposer(next_height)
            .map_err(|err| Error::Other(err.to_string()))?;
        if block_producer.account_id != next_block_proposer {
            info!(target: "client", "Produce block: chain at {}, not block producer for next block.", next_height);
            return Ok(());
        }
        let state_root = self.chain.get_post_state_root(&head.last_block_hash)?.clone();
        let has_receipts =
            self.chain.get_receipts(&head.last_block_hash).map(|r| r.len() > 0).unwrap_or(false);
        let prev = self.chain.get_block_header(&head.last_block_hash)?;

        // Wait until we have all approvals or timeouts per max block production delay.
        let validators = self
            .runtime_adapter
            .get_epoch_block_proposers(next_height)
            .map_err(|err| Error::Other(err.to_string()))?;
        let total_validators = validators.len();
        let prev_same_bp = self
            .runtime_adapter
            .get_block_proposer(next_height - 1)
            .map_err(|err| Error::Other(err.to_string()))?
            == block_producer.account_id.clone();
        let total_approvals = total_validators - if prev_same_bp { 1 } else { 2 };
        if self.approvals.len() < total_approvals
            && self.last_block_processed.elapsed() < self.config.max_block_production_delay
        {
            // Schedule itself for (max BP delay - how much time passed).
            ctx.run_later(
                self.config.max_block_production_delay.sub(self.last_block_processed.elapsed()),
                move |act, ctx| {
                    act.produce_block(ctx, last_height, next_height);
                },
            );
            return Ok(());
        }

        // If we are not producing empty blocks, skip this and call handle scheduling for the next block.
        if !self.config.produce_empty_blocks && self.tx_pool.len() == 0 && !has_receipts {
            self.handle_scheduling_block_production(ctx, head.height, next_height);
            return Ok(());
        }

        // Take transactions from the pool.
        let transactions = self.tx_pool.prepare_transactions(self.config.block_expected_weight)?;
        let block = Block::produce(
            &prev,
            next_height,
            state_root,
            transactions,
            self.approvals.drain().collect(),
            vec![],
            block_producer.signer.clone(),
        );

        self.process_block(ctx, block, Provenance::PRODUCED).map(|_| ()).map_err(|err| err.into())
    }

    /// Process block and execute callbacks.
    fn process_block(
        &mut self,
        ctx: &mut Context<ClientActor>,
        block: Block,
        provenance: Provenance,
    ) -> Result<Option<near_chain::Tip>, near_chain::Error> {
        // XXX: this is bad, there is no multithreading here, what is the better way to handle this callback?
        // TODO: replace to channels or cross beams here?
        let accepted_blocks = Arc::new(RwLock::new(vec![]));
        let result = {
            self.chain.process_block(block, provenance, |block, status, provenance| {
                accepted_blocks.write().unwrap().push((block.hash(), status, provenance));
            })
        };
        // Process all blocks that were accepted.
        for (hash, status, provenance) in accepted_blocks.write().unwrap().drain(..) {
            self.on_block_accepted(ctx, hash, status, provenance);
        }
        result
    }

    /// Processes received block, returns boolean if block was reasonable or malicious.
    fn receive_block(
        &mut self,
        ctx: &mut Context<ClientActor>,
        block: Block,
        peer_id: PeerId,
        was_requested: bool,
    ) -> NetworkClientResponses {
        let hash = block.hash();
        debug!(target: "client", "Received block {} at {} from {}", hash, block.header.height, peer_id);
        let previous = self.chain.get_previous_header(&block.header).map(Clone::clone);
        let provenance =
            if was_requested { near_chain::Provenance::SYNC } else { near_chain::Provenance::NONE };
        match self.process_block(ctx, block, provenance) {
            Ok(_) => NetworkClientResponses::NoResponse,
            Err(ref e) if e.is_bad_data() => {
                NetworkClientResponses::Ban { ban_reason: ReasonForBan::BadBlock }
            }
            Err(ref e) if e.is_error() => {
                error!(target: "client", "Error on receival of block: {}", e.description());
                NetworkClientResponses::NoResponse
            }
            Err(e) => match e.kind() {
                near_chain::ErrorKind::Orphan => {
                    if let Ok(previous) = previous {
                        if !self.chain.is_orphan(&previous.hash()) {
                            debug!(
                                "Process block: received an orphan block, checking the parent: {}",
                                previous.hash()
                            );
                            self.request_block_by_hash(previous.hash(), peer_id)
                        }
                    }
                    NetworkClientResponses::NoResponse
                }
                _ => {
                    debug!("Process block: block {} refused by chain: {}", hash, e.kind());
                    NetworkClientResponses::NoResponse
                }
            },
        }
    }

    fn receive_header(&mut self, header: BlockHeader, peer_info: PeerId) -> NetworkClientResponses {
        let hash = header.hash();
        debug!(target: "client", "Received block header {} at {} from {}", hash, header.height, peer_info);

        // Process block by chain, if it's valid header ask for the block.
        let result = self.chain.process_block_header(&header);

        match result {
            Err(ref e) if e.is_bad_data() => {
                return NetworkClientResponses::Ban { ban_reason: ReasonForBan::BadBlockHeader }
            }
            // Some error that worth surfacing.
            Err(ref e) if e.is_error() => {
                error!(target: "client", "Error on receival of header: {}", e);
                return NetworkClientResponses::NoResponse;
            }
            // Got an error when trying to process the block header, but it's not due to
            // invalid data or underlying error. Surface as fine.
            Err(_) => return NetworkClientResponses::NoResponse,
            _ => {}
        }

        // Succesfully processed a block header and can request the full block.
        self.request_block_by_hash(header.hash(), peer_info);
        NetworkClientResponses::NoResponse
    }

    fn receive_headers(&mut self, headers: Vec<BlockHeader>, peer_id: PeerId) -> bool {
        info!(target: "client", "Received {} block headers from {}", headers.len(), peer_id);
        if headers.len() == 0 {
            return true;
        }
        match self.chain.sync_block_headers(headers) {
            Ok(_) => true,
            Err(err) => {
                if err.is_bad_data() {
                    error!(target: "client", "Error processing sync blocks: {}", err);
                    false
                } else {
                    debug!(target: "client", "Block headers refused by chain: {}", err);
                    true
                }
            }
        }
    }

    fn request_block_by_hash(&mut self, hash: CryptoHash, peer_id: PeerId) {
        match self.chain.block_exists(&hash) {
            Ok(false) => {
                // TODO: ?? should we add a wait for response here?
                let _ = self.network_actor.do_send(NetworkRequests::BlockRequest { hash, peer_id });
            }
            Ok(true) => {
                debug!(target: "client", "send_block_request_to_peer: block {} already known", hash)
            }
            Err(e) => {
                error!(target: "client", "send_block_request_to_peer: failed to check block exists: {:?}", e)
            }
        }
    }

    fn retrieve_headers(
        &mut self,
        hashes: Vec<CryptoHash>,
    ) -> Result<Vec<BlockHeader>, near_chain::Error> {
        let header = match self.chain.find_common_header(&hashes) {
            Some(header) => header,
            None => return Ok(vec![]),
        };

        let mut headers = vec![];
        let max_height = self.chain.header_head()?.height;
        // TODO: this may be inefficient if there are a lot of skipped blocks.
        for h in header.height + 1..=max_height {
            if let Ok(header) = self.chain.get_header_by_height(h) {
                headers.push(header.clone());
                if headers.len() >= sync::MAX_BLOCK_HEADERS as usize {
                    break;
                }
            }
        }
        Ok(headers)
    }

    /// Validate transaction and return transaction information relevant to ordering it in the mempool.
    fn validate_tx(&mut self, tx: SignedTransaction) -> Result<ValidTransaction, String> {
        let head = self.chain.head().map_err(|err| err.to_string())?;
        let state_root = self
            .chain
            .get_post_state_root(&head.last_block_hash)
            .map_err(|err| err.to_string())?
            .clone();
        self.runtime_adapter.validate_tx(0, state_root, tx)
    }

    /// Check whether need to (continue) sync.
    fn needs_syncing(&self) -> Result<(bool, u64), near_chain::Error> {
        let head = self.chain.head()?;
        let mut is_syncing = self.sync_status.is_syncing();

        let full_peer_info =
            if let Some(full_peer_info) = most_weight_peer(&self.network_info.most_weight_peers) {
                full_peer_info
            } else {
                if !self.config.skip_sync_wait {
                    warn!(target: "client", "Sync: no peers available, disabling sync");
                }
                return Ok((false, 0));
            };

        if is_syncing {
            if full_peer_info.chain_info.total_weight <= head.total_weight {
                info!(target: "client", "Sync: synced at {} @ {} [{}]", head.total_weight.to_num(), head.height, head.last_block_hash);
                is_syncing = false;
            }
        } else {
            if full_peer_info.chain_info.total_weight.to_num()
                > head.total_weight.to_num() + self.config.sync_weight_threshold
                && full_peer_info.chain_info.height
                    > head.height + self.config.sync_height_threshold
            {
                info!(
                    target: "client",
                    "Sync: height/weight: {}/{}, peer height/weight: {}/{}, enabling sync",
                    head.height,
                    head.total_weight,
                    full_peer_info.chain_info.height,
                    full_peer_info.chain_info.total_weight
                );
                is_syncing = true;
            }
        }
        Ok((is_syncing, full_peer_info.chain_info.height))
    }

    /// Starts syncing and then switches to either syncing or regular mode.
    fn start_sync(&mut self, ctx: &mut Context<ClientActor>) {
        // Wait for connections reach at least minimum peers unless skipping sync.
        if self.network_info.num_active_peers < self.config.min_num_peers
            && !self.config.skip_sync_wait
        {
            ctx.run_later(self.config.sync_step_period, move |act, ctx| {
                act.start_sync(ctx);
            });
            return;
        }
        // Start main sync loop.
        self.sync(ctx);
    }

    /// Main syncing job responsible for syncing client with other peers.
    fn sync(&mut self, ctx: &mut Context<ClientActor>) {
        // Macro to schedule to call this function later if error occurred.
        macro_rules! unwrap_or_run_later(($obj: expr) => (match $obj {
            Ok(v) => v,
            Err(err) => {
                error!(target: "sync", "Sync: Unexpected error: {}", err);
                ctx.run_later(self.config.sync_step_period, move |act, ctx| {
                    act.sync(ctx);
                });
                return;
            }
        }));

        let mut wait_period = self.config.sync_step_period;

        let currently_syncing = self.sync_status.is_syncing();
        let (needs_syncing, highest_height) = unwrap_or_run_later!(self.needs_syncing());

        if !needs_syncing {
            if currently_syncing {
                self.started = Instant::now();
                self.last_block_processed = Instant::now();
                self.sync_status = SyncStatus::NoSync;

                // Initial transition out of "syncing" state.
                // Start by handling scheduling block production if needed.
                let head = unwrap_or_run_later!(self.chain.head());
                self.handle_scheduling_block_production(ctx, head.height, head.height);
            }
            wait_period = self.config.sync_check_period;
        } else {
            // Run each step of syncing separately.
            unwrap_or_run_later!(self.header_sync.run(
                &mut self.sync_status,
                &mut self.chain,
                highest_height,
                &self.network_info.most_weight_peers
            ));
            unwrap_or_run_later!(self.block_sync.run(
                &mut self.sync_status,
                &mut self.chain,
                highest_height,
                &self.network_info.most_weight_peers
            ));
        }

        ctx.run_later(wait_period, move |act, ctx| {
            act.sync(ctx);
        });
    }

    /// Periodically fetch network info.
    fn fetch_network_info(&mut self, ctx: &mut Context<Self>) {
        // TODO: replace with push from network?
        self.network_actor
            .send(NetworkRequests::FetchInfo)
            .into_actor(self)
            .then(move |res, act, _ctx| match res {
                Ok(NetworkResponses::Info {
                    num_active_peers,
                    peer_max_count,
                    most_weight_peers,
                }) => {
                    act.network_info.num_active_peers = num_active_peers;
                    act.network_info.peer_max_count = peer_max_count;
                    act.network_info.most_weight_peers = most_weight_peers;
                    actix::fut::ok(())
                }
                _ => {
                    error!(target: "client", "Sync: recieved error or incorrect result.");
                    actix::fut::err(())
                }
            })
            .wait(ctx);

        ctx.run_later(self.config.fetch_info_period, move |act, ctx| {
            act.fetch_network_info(ctx);
        });
    }

    /// Periodically log summary.
    fn log_summary(&self, ctx: &mut Context<Self>) {
        ctx.run_later(self.config.log_summary_period, move |act, ctx| {
            // TODO: collect traffic, tx, blocks.
            let head = unwrap_or_return!(act.chain.head());
            let validators = unwrap_or_return!(act.runtime_adapter.get_epoch_block_proposers(head.height)).drain(..).map(|(account_id, _)| account_id).collect::<Vec<_>>();
            let num_validators = validators.len();
            let is_validator = if let Some(block_producer) = &act.block_producer {
                validators.contains(&block_producer.account_id)
            } else {
                false
            };
            // Block#, Block Hash, is validator/# validators, active/max peers.
            let avg_bls = (act.num_blocks_processed as f64) / (act.started.elapsed().as_secs() as f64);
            let avg_tps = (act.num_tx_processed as f64) / (act.started.elapsed().as_secs() as f64);
            info!(target: "info", "{} {} {} {}",
                match act.sync_status {
                    SyncStatus::NoSync => Yellow.bold().paint(format!("#{:>8} {}", head.height, head.last_block_hash)),
                    _ => {
                        if let Some(full_peer_info) = most_weight_peer(&act.network_info.most_weight_peers) {
                            Yellow.bold().paint(format!("Syncing {}..{}", head.height, full_peer_info.chain_info.height))
                        } else {
                            Yellow.bold().paint(format!("Syncing {}..???", head.height))
                        }
                    }
                },
                  White.bold().paint(format!("{}/{}", if is_validator { "V" } else { "-" }, num_validators)),
                  Cyan.bold().paint(format!("{:2}/{:2} peers", act.network_info.num_active_peers, act.network_info.peer_max_count)),
                  Green.bold().paint(format!("{:.2} bls {:.2} tps", avg_bls, avg_tps))
            );
            act.started = Instant::now();
            act.num_blocks_processed = 0;
            act.num_tx_processed = 0;

            act.log_summary(ctx);
        });
    }

    /// Collects block approvals. Returns false if block approval is invalid.
    fn collect_block_approval(
        &mut self,
        account_id: &AccountId,
        hash: &CryptoHash,
        signature: &Signature,
    ) -> bool {
        // TODO: figure out how to validate better before hitting the disk? For example validator and account cache to validate signature first.
        let header = match self.chain.get_block_header(&hash) {
            Ok(header) => header,
            Err(_) => {
                // TODO: This header is missing, should collect for later? should have better way to verify then.
                return true;
            }
        };
        // If given account is not current block proposer.
        let position = match self.runtime_adapter.get_epoch_block_proposers(header.height) {
            Ok(validators) => validators.iter().position(|x| &(x.0) == account_id),
            Err(err) => {
                error!(target: "client", "Error: {}", err);
                return false;
            }
        };
        if position.is_none() {
            return false;
        }
        // Check signature is correct for given validator.
        if !self.runtime_adapter.check_validator_signature(account_id, signature) {
            return false;
        }
        debug!(target: "client", "Received approval for {} from {}", hash, account_id);
        self.approvals.insert(position.unwrap(), signature.clone());
        true
    }
}

'''
'''--- chain/client/src/lib.rs ---
pub use crate::client::ClientActor;
pub use crate::types::{
    BlockProducer, ClientConfig, Error, GetBlock, NetworkInfo, Query, Status, StatusResponse,
    SyncStatus, TxStatus, TxDetails
};
pub use crate::view_client::ViewClientActor;

mod client;
mod sync;
pub mod test_utils;
mod types;
mod view_client;

'''
'''--- chain/client/src/sync.rs ---
use std::cmp;

use actix::Recipient;
use chrono::{DateTime, Duration, Utc};
use log::{debug, error, info};
use rand::{thread_rng, Rng};

use near_chain::{Chain, Tip};
use near_network::types::ReasonForBan;
use near_network::{FullPeerInfo, NetworkRequests};
use near_primitives::hash::CryptoHash;
use near_primitives::types::BlockIndex;

use crate::types::SyncStatus;

/// Maximum number of block headers send over the network.
pub const MAX_BLOCK_HEADERS: u64 = 512;

const BLOCK_HEADER_PROGRESS_TIMEOUT: i64 = 2;

/// Maximum number of block header hashes to send as part of a locator.
pub const MAX_BLOCK_HEADER_HASHES: usize = 20;

/// Maximum number of blocks to request in one step.
const MAX_BLOCK_REQUEST: usize = 100;

/// Maximum number of blocks to ask from single peer.
const MAX_PEER_BLOCK_REQUEST: usize = 10;

const BLOCK_REQUEST_TIMEOUT: i64 = 6;
const BLOCK_SOME_RECEIVED_TIMEOUT: i64 = 1;
const BLOCK_REQUEST_BROADCAST_OFFSET: u64 = 2;

/// Get random peer from the most weighted peers.
pub fn most_weight_peer(most_weight_peers: &Vec<FullPeerInfo>) -> Option<FullPeerInfo> {
    if most_weight_peers.len() == 0 {
        return None;
    }
    let index = thread_rng().gen_range(0, most_weight_peers.len());
    Some(most_weight_peers[index].clone())
}

/// Helper to keep track of sync headers.
/// Handles major re-orgs by finding closest header that matches and re-downloading headers from that point.
pub struct HeaderSync {
    network_recipient: Recipient<NetworkRequests>,
    history_locator: Vec<(BlockIndex, CryptoHash)>,
    prev_header_sync: (DateTime<Utc>, BlockIndex, BlockIndex),
    syncing_peer: Option<FullPeerInfo>,
    stalling_ts: Option<DateTime<Utc>>,
}

impl HeaderSync {
    pub fn new(network_recipient: Recipient<NetworkRequests>) -> Self {
        HeaderSync {
            network_recipient,
            history_locator: vec![],
            prev_header_sync: (Utc::now(), 0, 0),
            syncing_peer: None,
            stalling_ts: None,
        }
    }

    pub fn run(
        &mut self,
        sync_status: &mut SyncStatus,
        chain: &mut Chain,
        highest_height: BlockIndex,
        most_weight_peers: &Vec<FullPeerInfo>,
    ) -> Result<(), near_chain::Error> {
        let header_head = chain.header_head()?;
        if !self.header_sync_due(sync_status, &header_head) {
            return Ok(());
        }

        let enable_header_sync = match sync_status {
            SyncStatus::HeaderSync { .. } | SyncStatus::BodySync { .. } | SyncStatus::StateDone => {
                true
            }
            SyncStatus::NoSync | SyncStatus::AwaitingPeers => {
                let sync_head = chain.sync_head()?;
                debug!(target: "sync", "Sync: initial transition to Header sync. Sync head: {} at {}, resetting to {} at {}",
                    sync_head.last_block_hash, sync_head.height,
                    header_head.last_block_hash, header_head.height,
                );
                // Reset sync_head to header_head on initial transition to HeaderSync.
                chain.reset_sync_head()?;
                self.history_locator.retain(|&x| x.0 == 0);
                true
            }
            _ => false,
        };

        if enable_header_sync {
            *sync_status =
                SyncStatus::HeaderSync { current_height: header_head.height, highest_height };
            let header_head = chain.header_head()?;
            self.syncing_peer = None;
            if let Some(peer) = most_weight_peer(&most_weight_peers) {
                if peer.chain_info.total_weight > header_head.total_weight {
                    self.syncing_peer = self.request_headers(chain, peer);
                }
            }
        }
        Ok(())
    }

    fn header_sync_due(&mut self, sync_status: &SyncStatus, header_head: &Tip) -> bool {
        let now = Utc::now();
        let (timeout, latest_height, prev_height) = self.prev_header_sync;

        // Received all necessary header, can request more.
        let all_headers_received = header_head.height >= prev_height + MAX_BLOCK_HEADERS - 4;
        // No headers processed and it's past timeout, request more.
        let stalling = header_head.height <= latest_height && now > timeout;

        // Always enable header sync on initial state transition from NoSync / AwaitingPeers.
        let force_sync = match sync_status {
            SyncStatus::NoSync | SyncStatus::AwaitingPeers => true,
            _ => false,
        };

        if force_sync || all_headers_received || stalling {
            self.prev_header_sync =
                (now + Duration::seconds(10), header_head.height, header_head.height);

            if stalling {
                if self.stalling_ts.is_none() {
                    self.stalling_ts = Some(now);
                } else {
                    self.stalling_ts = None;
                }
            }

            if all_headers_received {
                self.stalling_ts = None;
            } else {
                if let Some(ref stalling_ts) = self.stalling_ts {
                    if let Some(ref peer) = self.syncing_peer {
                        match sync_status {
                            SyncStatus::HeaderSync { highest_height, .. } => {
                                if now > *stalling_ts + Duration::seconds(120)
                                    && *highest_height == peer.chain_info.height
                                {
                                    info!(target: "sync", "Sync: ban a fraudulent peer: {}, claimed height: {}, total weight: {}",
                                        peer.peer_info, peer.chain_info.height, peer.chain_info.total_weight);
                                    let _ =
                                        self.network_recipient.do_send(NetworkRequests::BanPeer {
                                            peer_id: peer.peer_info.id.clone(),
                                            ban_reason: ReasonForBan::HeightFraud,
                                        });
                                }
                            }
                            _ => (),
                        }
                    }
                }
            }
            self.syncing_peer = None;
            true
        } else {
            // Resetting the timeout as long as we make progress.
            if header_head.height > latest_height {
                self.prev_header_sync = (
                    now + Duration::seconds(BLOCK_HEADER_PROGRESS_TIMEOUT),
                    header_head.height,
                    prev_height,
                );
            }
            false
        }
    }

    /// Request headers from a given peer to advance the chain.
    fn request_headers(&mut self, chain: &Chain, peer: FullPeerInfo) -> Option<FullPeerInfo> {
        if let Ok(locator) = self.get_locator(chain) {
            debug!(target: "sync", "Sync: request headers: asking {} for headers, {:?}", peer.peer_info.id, locator);
            // TODO: actix::spawn?
            let _ = self.network_recipient.do_send(NetworkRequests::BlockHeadersRequest {
                hashes: locator,
                peer_id: peer.peer_info.id.clone(),
            });
            return Some(peer);
        }
        None
    }

    fn get_locator(&mut self, chain: &Chain) -> Result<Vec<CryptoHash>, near_chain::Error> {
        let tip = chain.sync_head()?;
        let heights = get_locator_heights(tip.height);

        // Clear history_locator in any case of header chain rollback.
        if self.history_locator.len() > 0
            && tip.last_block_hash != chain.header_head()?.last_block_hash
        {
            self.history_locator.retain(|&x| x.0 == 0);
        }

        // For each height we need, we either check if something is close enough from last locator, or go to the db.
        let mut locator: Vec<(u64, CryptoHash)> = vec![(tip.height, tip.last_block_hash)];
        for h in heights {
            if let Some(x) = close_enough(&self.history_locator, h) {
                locator.push(x);
            }
        }
        locator.dedup_by(|a, b| a.0 == b.0);
        debug!(target: "sync", "Sync: locator: {:?}", locator);
        self.history_locator = locator.clone();
        Ok(locator.iter().map(|x| x.1).collect())
    }
}

/// Check if there is a close enough value to provided height in the locator.
fn close_enough(locator: &Vec<(u64, CryptoHash)>, height: u64) -> Option<(u64, CryptoHash)> {
    if locator.len() == 0 {
        return None;
    }
    // Check boundaries, if lower than the last.
    if locator.last().unwrap().0 >= height {
        return locator.last().map(|x| x.clone());
    }
    // Higher than first and first is within acceptable gap.
    if locator[0].0 < height && height.saturating_sub(127) < locator[0].0 {
        return Some(locator[0]);
    }
    for h in locator.windows(2) {
        if height <= h[0].0 && height > h[1].0 {
            if h[0].0 - height < height - h[1].0 {
                return Some(h[0].clone());
            } else {
                return Some(h[1].clone());
            }
        }
    }
    None
}

/// Given height stepping back to 0 in powers of 2 steps.
fn get_locator_heights(height: u64) -> Vec<u64> {
    let mut current = height;
    let mut heights = vec![];
    while current > 0 {
        heights.push(current);
        if heights.len() >= MAX_BLOCK_HEADER_HASHES as usize - 1 {
            break;
        }
        let next = 2u64.pow(heights.len() as u32);
        current = if current > next { current - next } else { 0 };
    }
    heights.push(0);
    heights
}

/// Helper to track block syncing.
pub struct BlockSync {
    network_recipient: Recipient<NetworkRequests>,
    blocks_requested: BlockIndex,
    receive_timeout: DateTime<Utc>,
    prev_blocks_recevied: BlockIndex,
}

impl BlockSync {
    pub fn new(network_recipient: Recipient<NetworkRequests>) -> Self {
        BlockSync {
            network_recipient,
            blocks_requested: 0,
            receive_timeout: Utc::now(),
            prev_blocks_recevied: 0,
        }
    }

    pub fn run(
        &mut self,
        sync_status: &mut SyncStatus,
        chain: &mut Chain,
        highest_height: BlockIndex,
        most_weight_peers: &[FullPeerInfo],
    ) -> Result<(), near_chain::Error> {
        if self.block_sync_due(chain)? {
            if self.block_sync(chain, most_weight_peers)? {
                return Ok(());
            }

            let head = chain.head()?;
            *sync_status = SyncStatus::BodySync { current_height: head.height, highest_height };
        }
        Ok(())
    }

    /// Returns true if state download is required (last known block is too far).
    /// Otherwise request recent blocks from peers round robin.
    pub fn block_sync(
        &mut self,
        chain: &mut Chain,
        most_weight_peers: &[FullPeerInfo],
    ) -> Result<bool, near_chain::Error> {
        let (state_needed, mut hashes) = chain.check_state_needed()?;
        if state_needed {
            return Ok(true);
        }
        hashes.reverse();
        // Ask for `num_peers * MAX_PEER_BLOCK_REQUEST` blocks up to 100, throttle if there is too many orphans in the chain.
        let block_count = cmp::min(
            cmp::min(MAX_BLOCK_REQUEST, MAX_PEER_BLOCK_REQUEST * most_weight_peers.len()),
            near_chain::MAX_ORPHAN_SIZE.saturating_sub(chain.orphans_len()) + 1,
        );

        let mut hashes_to_request = hashes
            .iter()
            .filter(|x| !chain.get_block(x).is_ok() && !chain.is_orphan(x))
            .take(block_count)
            .collect::<Vec<_>>();
        if hashes_to_request.len() > 0 {
            let head = chain.head()?;
            let header_head = chain.header_head()?;

            debug!(target: "sync", "Block sync: {}/{} requesting blocks {:?} from {} peers", head.height, header_head.height, hashes_to_request, most_weight_peers.len());

            self.blocks_requested = 0;
            self.receive_timeout = Utc::now() + Duration::seconds(BLOCK_REQUEST_TIMEOUT);

            let mut peers_iter = most_weight_peers.iter().cycle();
            for hash in hashes_to_request.drain(..) {
                if let Some(peer) = peers_iter.next() {
                    if self
                        .network_recipient
                        .do_send(NetworkRequests::BlockRequest {
                            hash: hash.clone(),
                            peer_id: peer.peer_info.id.clone(),
                        })
                        .is_ok()
                    {
                        self.blocks_requested += 1;
                    } else {
                        error!(target: "sync", "Failed to send message to network agent");
                    }
                }
            }
        }
        Ok(false)
    }

    /// Check if we should run block body sync and ask for more full blocks.
    fn block_sync_due(&mut self, chain: &Chain) -> Result<bool, near_chain::Error> {
        let blocks_received = self.blocks_received(chain)?;

        // Some blocks have been requested.
        if self.blocks_requested > 0 {
            let timeout = Utc::now() > self.receive_timeout;
            if timeout && blocks_received <= self.prev_blocks_recevied {
                debug!(target: "sync", "Block sync: expecting {} more blocks and none received for a while", self.blocks_requested);
                return Ok(true);
            }
        }

        if blocks_received > self.prev_blocks_recevied {
            // Some blocks received, update for next check.
            self.receive_timeout = Utc::now() + Duration::seconds(BLOCK_SOME_RECEIVED_TIMEOUT);
            self.blocks_requested =
                self.blocks_requested.saturating_sub(blocks_received - self.prev_blocks_recevied);
            self.prev_blocks_recevied = blocks_received;
        }

        // Account for broadcast adding few blocks to orphans during.
        if self.blocks_requested < BLOCK_REQUEST_BROADCAST_OFFSET {
            // debug!(target: "sync", "Block sync: No pending block requests, requesting more.");
            return Ok(true);
        }

        Ok(false)
    }

    /// Total number of received blocks by the chain.
    fn blocks_received(&self, chain: &Chain) -> Result<u64, near_chain::Error> {
        Ok((chain.head()?).height + chain.orphans_len() as u64 + chain.orphans_evicted_len() as u64)
    }
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn test_get_locator_heights() {
        assert_eq!(get_locator_heights(0), vec![0]);
        assert_eq!(get_locator_heights(1), vec![1, 0]);
        assert_eq!(get_locator_heights(2), vec![2, 0]);
        assert_eq!(get_locator_heights(3), vec![3, 1, 0]);
        assert_eq!(get_locator_heights(10), vec![10, 8, 4, 0]);
        assert_eq!(get_locator_heights(100), vec![100, 98, 94, 86, 70, 38, 0]);
        assert_eq!(
            get_locator_heights(1000),
            vec![1000, 998, 994, 986, 970, 938, 874, 746, 490, 0]
        );
        // Locator is still reasonable size even given large height.
        assert_eq!(
            get_locator_heights(10000),
            vec![10000, 9998, 9994, 9986, 9970, 9938, 9874, 9746, 9490, 8978, 7954, 5906, 1810, 0,]
        );
    }
}

'''
'''--- chain/client/src/test_utils.rs ---
use std::sync::{Arc, RwLock};

use actix::actors::mocker::Mocker;
use actix::{Actor, Addr, AsyncContext, Context, Recipient};
use chrono::Utc;

use near_chain::test_utils::KeyValueRuntime;
use near_network::{NetworkRequests, NetworkResponses, PeerManagerActor};
use near_primitives::crypto::signer::InMemorySigner;
use near_store::test_utils::create_test_store;

use crate::{BlockProducer, ClientActor, ClientConfig, ViewClientActor};

pub type NetworkMock = Mocker<PeerManagerActor>;

/// Sets up ClientActor and ViewClientActor viewing the same store/runtime.
pub fn setup(
    validators: Vec<&str>,
    account_id: &str,
    skip_sync_wait: bool,
    recipient: Recipient<NetworkRequests>,
) -> (ClientActor, ViewClientActor) {
    let store = create_test_store();
    let runtime = Arc::new(KeyValueRuntime::new_with_validators(
        store.clone(),
        validators.into_iter().map(Into::into).collect(),
    ));
    let signer = Arc::new(InMemorySigner::from_seed(account_id, account_id));
    let genesis_time = Utc::now();
    let view_client =
        ViewClientActor::new(store.clone(), genesis_time.clone(), runtime.clone()).unwrap();
    let client = ClientActor::new(
        ClientConfig::test(skip_sync_wait),
        store,
        genesis_time,
        runtime,
        recipient,
        Some(signer.into()),
    )
    .unwrap();
    (client, view_client)
}

/// Sets up ClientActor and ViewClientActor with mock PeerManager.
pub fn setup_mock(
    validators: Vec<&'static str>,
    account_id: &'static str,
    skip_sync_wait: bool,
    mut network_mock: Box<
        dyn FnMut(
            &NetworkRequests,
            &mut Context<NetworkMock>,
            Addr<ClientActor>,
        ) -> NetworkResponses,
    >,
) -> (Addr<ClientActor>, Addr<ViewClientActor>) {
    let view_client_addr = Arc::new(RwLock::new(None));
    let view_client_addr1 = view_client_addr.clone();
    let client_addr = ClientActor::create(move |ctx| {
        let client_addr = ctx.address();
        let pm = NetworkMock::mock(Box::new(move |msg, ctx| {
            let msg = msg.downcast_ref::<NetworkRequests>().unwrap();
            let resp = network_mock(msg, ctx, client_addr.clone());
            Box::new(Some(resp))
        }))
        .start();
        let (client, view_client) = setup(validators, account_id, skip_sync_wait, pm.recipient());
        *view_client_addr1.write().unwrap() = Some(view_client.start());
        client
    });
    (client_addr, view_client_addr.clone().read().unwrap().clone().unwrap())
}

/// Sets up ClientActor and ViewClientActor without network.
pub fn setup_no_network(
    validators: Vec<&'static str>,
    account_id: &'static str,
    skip_sync_wait: bool,
) -> (Addr<ClientActor>, Addr<ViewClientActor>) {
    setup_mock(
        validators,
        account_id,
        skip_sync_wait,
        Box::new(|_, _, _| NetworkResponses::NoResponse),
    )
}

impl BlockProducer {
    pub fn test(seed: &str) -> Self {
        Arc::new(InMemorySigner::from_seed(seed, seed)).into()
    }
}

'''
'''--- chain/client/src/types.rs ---
use std::sync::Arc;
use std::time::Duration;

use actix::Message;
use chrono::{DateTime, Utc};
use serde_derive::{Deserialize, Serialize};

use near_chain::Block;
use near_network::types::FullPeerInfo;
use near_primitives::crypto::signer::{AccountSigner, EDSigner, InMemorySigner};
use near_primitives::hash::CryptoHash;
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::serialize::base_format;
use near_primitives::transaction::{FinalTransactionResult, TransactionResult};
use near_primitives::types::{AccountId, BlockIndex, MerkleHash};

/// Combines errors coming from chain, tx pool and block producer.
#[derive(Debug)]
pub enum Error {
    Chain(near_chain::Error),
    Pool(near_pool::Error),
    BlockProducer(String),
    Other(String),
}

impl std::fmt::Display for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Error::Chain(err) => write!(f, "Chain: {}", err),
            Error::Pool(err) => write!(f, "Pool: {}", err),
            Error::BlockProducer(err) => write!(f, "Block Producer: {}", err),
            Error::Other(err) => write!(f, "Other: {}", err),
        }
    }
}

impl std::error::Error for Error {}

impl From<near_chain::Error> for Error {
    fn from(e: near_chain::Error) -> Self {
        Error::Chain(e)
    }
}

impl From<near_chain::ErrorKind> for Error {
    fn from(e: near_chain::ErrorKind) -> Self {
        let error: near_chain::Error = e.into();
        Error::Chain(error)
    }
}

impl From<near_pool::Error> for Error {
    fn from(e: near_pool::Error) -> Self {
        Error::Pool(e)
    }
}

impl From<String> for Error {
    fn from(e: String) -> Self {
        Error::Other(e)
    }
}

#[derive(Clone)]
pub struct ClientConfig {
    /// Chain id for status.
    pub chain_id: String,
    /// Listening rpc port for status.
    pub rpc_addr: String,
    /// Minimum duration before producing block.
    pub min_block_production_delay: Duration,
    /// Maximum duration before producing block or skipping height.
    pub max_block_production_delay: Duration,
    /// Expected block weight (num of tx, gas, etc).
    pub block_expected_weight: u32,
    /// Skip waiting for sync (for testing or single node testnet).
    pub skip_sync_wait: bool,
    /// How often to check that we are not out of sync.
    pub sync_check_period: Duration,
    /// While syncing, how long to check for each step.
    pub sync_step_period: Duration,
    /// Sync weight threshold: below this difference in weight don't start syncing.
    pub sync_weight_threshold: u64,
    /// Sync height threshold: below this difference in height don't start syncing.
    pub sync_height_threshold: u64,
    /// Minimum number of peers to start syncing.
    pub min_num_peers: usize,
    /// Period between fetching data from other parts of the system.
    pub fetch_info_period: Duration,
    /// Period between logging summary information.
    pub log_summary_period: Duration,
    /// Produce empty blocks, use `false` for testing.
    pub produce_empty_blocks: bool,
}

impl ClientConfig {
    pub fn test(skip_sync_wait: bool) -> Self {
        ClientConfig {
            chain_id: "unittest".to_string(),
            rpc_addr: "0.0.0.0:3030".to_string(),
            min_block_production_delay: Duration::from_millis(100),
            max_block_production_delay: Duration::from_millis(300),
            block_expected_weight: 1000,
            skip_sync_wait,
            sync_check_period: Duration::from_millis(100),
            sync_step_period: Duration::from_millis(10),
            sync_weight_threshold: 0,
            sync_height_threshold: 1,
            min_num_peers: 1,
            fetch_info_period: Duration::from_millis(100),
            log_summary_period: Duration::from_secs(10),
            produce_empty_blocks: true,
        }
    }
}

impl ClientConfig {
    pub fn new() -> Self {
        ClientConfig {
            chain_id: "test".to_string(),
            rpc_addr: "0.0.0.0:3030".to_string(),
            min_block_production_delay: Duration::from_millis(100),
            max_block_production_delay: Duration::from_millis(2000),
            block_expected_weight: 1000,
            skip_sync_wait: false,
            sync_check_period: Duration::from_secs(10),
            sync_step_period: Duration::from_millis(10),
            sync_weight_threshold: 0,
            sync_height_threshold: 1,
            min_num_peers: 1,
            fetch_info_period: Duration::from_millis(100),
            log_summary_period: Duration::from_secs(10),
            produce_empty_blocks: true,
        }
    }
}

/// Required information to produce blocks.
#[derive(Clone)]
pub struct BlockProducer {
    pub account_id: AccountId,
    pub signer: Arc<dyn EDSigner>,
}

impl From<InMemorySigner> for BlockProducer {
    fn from(signer: InMemorySigner) -> Self {
        BlockProducer { account_id: signer.account_id(), signer: Arc::new(signer) }
    }
}

impl From<Arc<InMemorySigner>> for BlockProducer {
    fn from(signer: Arc<InMemorySigner>) -> Self {
        BlockProducer { account_id: signer.account_id(), signer }
    }
}

/// Various status sync can be in, whether it's fast sync or archival.
#[derive(Clone, Debug, Eq, PartialEq)]
pub enum SyncStatus {
    /// Initial state. Not enough peers to do anything yet. If boolean is false, skip this step.
    AwaitingPeers,
    /// Not syncing / Done syncing.
    NoSync,
    /// Downloading block headers for fast sync.
    HeaderSync { current_height: BlockIndex, highest_height: BlockIndex },
    /// Downloading state for fast sync.
    StateDownload,
    /// Validating the full state.
    StateValidation,
    /// Finalizing state sync.
    StateDone,
    /// Catch up on blocks.
    BodySync { current_height: BlockIndex, highest_height: BlockIndex },
}

impl SyncStatus {
    /// True if currently engaged in syncing the chain.
    pub fn is_syncing(&self) -> bool {
        self != &SyncStatus::NoSync
    }
}

pub struct NetworkInfo {
    pub num_active_peers: usize,
    pub peer_max_count: u32,
    pub most_weight_peers: Vec<FullPeerInfo>,
}

/// Actor message requesting block by id or hash.
pub enum GetBlock {
    Best,
    Height(BlockIndex),
    Hash(CryptoHash),
}

impl Message for GetBlock {
    type Result = Result<Block, String>;
}

/// Queries client for given path / data.
pub struct Query {
    pub path: String,
    pub data: Vec<u8>,
}

impl Message for Query {
    type Result = Result<ABCIQueryResponse, String>;
}

#[derive(Serialize, Deserialize, Debug)]
pub struct StatusSyncInfo {
    #[serde(with = "base_format")]
    pub latest_block_hash: CryptoHash,
    pub latest_block_height: BlockIndex,
    #[serde(with = "base_format")]
    pub latest_state_root: MerkleHash,
    pub latest_block_time: DateTime<Utc>,
    pub syncing: bool,
}

// TODO: add more information to status.
#[derive(Serialize, Deserialize, Debug)]
pub struct StatusResponse {
    /// Unique chain id.
    pub chain_id: String,
    /// Address for RPC server.
    pub rpc_addr: String,
    /// Current epoch validators.
    pub validators: Vec<AccountId>,
    /// Sync status of the node.
    pub sync_info: StatusSyncInfo,
}

pub struct Status {}

impl Message for Status {
    type Result = Result<StatusResponse, String>;
}

/// Status of given transaction including all the subsequent receipts.
pub struct TxStatus {
    pub tx_hash: CryptoHash,
}

impl Message for TxStatus {
    type Result = Result<FinalTransactionResult, String>;
}

/// Details about given transaction.
pub struct TxDetails {
    pub tx_hash: CryptoHash,
}

impl Message for TxDetails {
    type Result = Result<TransactionResult, String>;
}

'''
'''--- chain/client/src/view_client.rs ---
//! Readonly view of the chain and state of the database.
//! Useful for querying from RPC.

use std::sync::Arc;

use actix::{Actor, Context, Handler};
use chrono::{DateTime, Utc};

use near_chain::{Block, Chain, ErrorKind, RuntimeAdapter};
use near_primitives::hash::CryptoHash;
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::transaction::{
    FinalTransactionResult, FinalTransactionStatus, TransactionLogs, TransactionResult,
    TransactionStatus,
};
use near_store::Store;

use crate::types::{Error, GetBlock, Query, TxStatus};
use crate::TxDetails;

/// View client provides currently committed (to the storage) view of the current chain and state.
pub struct ViewClientActor {
    chain: Chain,
    runtime_adapter: Arc<dyn RuntimeAdapter>,
}

impl ViewClientActor {
    pub fn new(
        store: Arc<Store>,
        genesis_time: DateTime<Utc>,
        runtime_adapter: Arc<dyn RuntimeAdapter>,
    ) -> Result<Self, Error> {
        // TODO: should we create shared ChainStore that is passed to both Client and ViewClient?
        let chain = Chain::new(store, runtime_adapter.clone(), genesis_time)?;
        Ok(ViewClientActor { chain, runtime_adapter })
    }

    pub fn get_transaction_result(
        &mut self,
        hash: &CryptoHash,
    ) -> Result<TransactionResult, String> {
        match self.chain.get_transaction_result(hash) {
            Ok(result) => Ok(result.clone()),
            Err(err) => match err.kind() {
                ErrorKind::DBNotFoundErr(_) => Ok(TransactionResult::default()),
                _ => Err(err.to_string()),
            },
        }
    }

    fn collect_transaction_final_result(
        &mut self,
        transaction_result: &TransactionResult,
        logs: &mut Vec<TransactionLogs>,
    ) -> Result<FinalTransactionStatus, String> {
        match transaction_result.status {
            TransactionStatus::Unknown => Ok(FinalTransactionStatus::Unknown),
            TransactionStatus::Failed => Ok(FinalTransactionStatus::Failed),
            TransactionStatus::Completed => {
                for r in transaction_result.receipts.iter() {
                    let receipt_result = self.get_transaction_result(&r)?;
                    logs.push(TransactionLogs {
                        hash: *r,
                        lines: receipt_result.logs.clone(),
                        receipts: receipt_result.receipts.clone(),
                        result: receipt_result.result.clone(),
                    });
                    match self.collect_transaction_final_result(&receipt_result, logs)? {
                        FinalTransactionStatus::Failed => {
                            return Ok(FinalTransactionStatus::Failed)
                        }
                        FinalTransactionStatus::Completed => {}
                        _ => return Ok(FinalTransactionStatus::Started),
                    };
                }
                Ok(FinalTransactionStatus::Completed)
            }
        }
    }
}

impl Actor for ViewClientActor {
    type Context = Context<Self>;
}

/// Handles runtime query.
impl Handler<Query> for ViewClientActor {
    type Result = Result<ABCIQueryResponse, String>;

    fn handle(&mut self, msg: Query, _: &mut Context<Self>) -> Self::Result {
        let head = self.chain.head().map_err(|err| err.to_string())?;
        let state_root =
            self.chain.get_post_state_root(&head.last_block_hash).map_err(|err| err.to_string())?;
        self.runtime_adapter
            .query(*state_root, head.height, &msg.path, &msg.data)
            .map_err(|err| err.to_string())
    }
}

/// Handles retrieving block from the chain.
impl Handler<GetBlock> for ViewClientActor {
    type Result = Result<Block, String>;

    fn handle(&mut self, msg: GetBlock, _: &mut Context<Self>) -> Self::Result {
        match msg {
            GetBlock::Best => match self.chain.head() {
                Ok(head) => self.chain.get_block(&head.last_block_hash).map(Clone::clone),
                Err(err) => Err(err),
            },
            GetBlock::Height(height) => self.chain.get_block_by_height(height).map(Clone::clone),
            GetBlock::Hash(hash) => self.chain.get_block(&hash).map(Clone::clone),
        }
        .map_err(|err| err.to_string())
    }
}

impl Handler<TxStatus> for ViewClientActor {
    type Result = Result<FinalTransactionResult, String>;

    fn handle(&mut self, msg: TxStatus, _: &mut Context<Self>) -> Self::Result {
        let transaction_result = self.get_transaction_result(&msg.tx_hash)?;
        let mut result = FinalTransactionResult {
            status: FinalTransactionStatus::Unknown,
            logs: vec![TransactionLogs {
                hash: msg.tx_hash,
                lines: transaction_result.logs.clone(),
                receipts: transaction_result.receipts.clone(),
                result: transaction_result.result.clone(),
            }],
        };
        result.status =
            self.collect_transaction_final_result(&transaction_result, &mut result.logs)?;
        Ok(result)
    }
}

impl Handler<TxDetails> for ViewClientActor {
    type Result = Result<TransactionResult, String>;

    fn handle(&mut self, msg: TxDetails, _: &mut Context<Self>) -> Self::Result {
        self.get_transaction_result(&msg.tx_hash)
    }
}

'''
'''--- chain/client/tests/process_blocks.rs ---
use std::collections::HashMap;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::{Arc, RwLock};

use actix::System;
use futures::{future, Future};

use near_chain::{Block, BlockApproval};
use near_client::test_utils::setup_mock;
use near_client::GetBlock;
use near_network::test_utils::wait_or_panic;
use near_network::types::{FullPeerInfo, PeerChainInfo};
use near_network::{NetworkClientMessages, NetworkRequests, NetworkResponses, PeerInfo};
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::hash::hash;
use near_primitives::test_utils::init_test_logger;
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::MerkleHash;

/// Runs block producing client and stops after network mock received two blocks.
#[test]
fn produce_two_blocks() {
    init_test_logger();
    System::run(|| {
        let count = Arc::new(AtomicUsize::new(0));
        setup_mock(
            vec!["test"],
            "test",
            true,
            Box::new(move |msg, _ctx, _| {
                if let NetworkRequests::Block { .. } = msg {
                    count.fetch_add(1, Ordering::Relaxed);
                    if count.load(Ordering::Relaxed) >= 2 {
                        System::current().stop();
                    }
                }
                NetworkResponses::NoResponse
            }),
        );
    })
    .unwrap();
}

/// Runs block producing client and sends it a transaction.
#[test]
fn produce_blocks_with_tx() {
    let count = Arc::new(AtomicUsize::new(0));
    init_test_logger();
    System::run(|| {
        let (client, _) = setup_mock(
            vec!["test"],
            "test",
            true,
            Box::new(move |msg, _ctx, _| {
                if let NetworkRequests::Block { block } = msg {
                    count.fetch_add(block.transactions.len(), Ordering::Relaxed);
                    if count.load(Ordering::Relaxed) >= 1 {
                        System::current().stop();
                    }
                }
                NetworkResponses::NoResponse
            }),
        );
        client.do_send(NetworkClientMessages::Transaction(SignedTransaction::empty()));
    })
    .unwrap();
}

/// Runs client that receives a block from network and announces header to the network with approval.
/// Need 3 block producers, to receive approval.
#[test]
fn receive_network_block() {
    init_test_logger();
    System::run(|| {
        let (client, view_client) = setup_mock(
            vec!["test2", "test1", "test3"],
            "test2",
            true,
            Box::new(move |msg, _ctx, _| {
                if let NetworkRequests::BlockHeaderAnnounce { approval, .. } = msg {
                    assert!(approval.is_some());
                    System::current().stop();
                }
                NetworkResponses::NoResponse
            }),
        );
        actix::spawn(view_client.send(GetBlock::Best).then(move |res| {
            let last_block = res.unwrap().unwrap();
            let signer = Arc::new(InMemorySigner::from_seed("test1", "test1"));
            let block = Block::produce(
                &last_block.header,
                last_block.header.height + 1,
                MerkleHash::default(),
                vec![],
                HashMap::default(),
                vec![],
                signer,
            );
            client.do_send(NetworkClientMessages::Block(block, PeerInfo::random().id, false));
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Runs client that receives a block from network and announces header to the network.
#[test]
fn receive_network_block_header() {
    let block_holder: Arc<RwLock<Option<Block>>> = Arc::new(RwLock::new(None));
    init_test_logger();
    System::run(|| {
        let block_holder1 = block_holder.clone();
        let (client, view_client) = setup_mock(
            vec!["test"],
            "other",
            true,
            Box::new(move |msg, _ctx, client_addr| match msg {
                NetworkRequests::BlockRequest { hash, peer_id } => {
                    let block = block_holder1.read().unwrap().clone().unwrap();
                    assert_eq!(hash.clone(), block.hash());
                    actix::spawn(
                        client_addr
                            .send(NetworkClientMessages::Block(block, peer_id.clone(), false))
                            .then(|_| futures::future::ok(())),
                    );
                    NetworkResponses::NoResponse
                }
                NetworkRequests::BlockHeaderAnnounce { .. } => {
                    System::current().stop();
                    NetworkResponses::NoResponse
                }
                _ => NetworkResponses::NoResponse,
            }),
        );
        actix::spawn(view_client.send(GetBlock::Best).then(move |res| {
            let last_block = res.unwrap().unwrap();
            let signer = Arc::new(InMemorySigner::from_seed("test", "test"));
            let block = Block::produce(
                &last_block.header,
                last_block.header.height + 1,
                MerkleHash::default(),
                vec![],
                HashMap::default(),
                vec![],
                signer,
            );
            client.do_send(NetworkClientMessages::BlockHeader(
                block.header.clone(),
                PeerInfo::random().id,
            ));
            *block_holder.write().unwrap() = Some(block);
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Include approvals to the next block in newly produced block.
#[test]
fn produce_block_with_approvals() {
    init_test_logger();
    System::run(|| {
        let (client, view_client) = setup_mock(
            vec!["test3", "test1", "test2"],
            "test2",
            true,
            Box::new(move |msg, _ctx, _| {
                if let NetworkRequests::Block { block } = msg {
                    assert!(block.header.approval_sigs.len() > 0);
                    System::current().stop();
                }
                NetworkResponses::NoResponse
            }),
        );
        actix::spawn(view_client.send(GetBlock::Best).then(move |res| {
            let last_block = res.unwrap().unwrap();
            let signer1 = Arc::new(InMemorySigner::from_seed("test1", "test1"));
            let signer3 = Arc::new(InMemorySigner::from_seed("test3", "test3"));
            let block = Block::produce(
                &last_block.header,
                last_block.header.height + 1,
                MerkleHash::default(),
                vec![],
                HashMap::default(),
                vec![],
                signer1,
            );
            let block_approval = BlockApproval::new(block.hash(), &*signer3, "test2".to_string());
            client.do_send(NetworkClientMessages::Block(block, PeerInfo::random().id, false));
            client.do_send(NetworkClientMessages::BlockApproval(
                "test3".to_string(),
                block_approval.hash,
                block_approval.signature,
            ));
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Sends 2 invalid blocks followed by valid block, and checks that client announces only valid block.
#[test]
fn invalid_blocks() {
    init_test_logger();
    System::run(|| {
        let (client, view_client) = setup_mock(
            vec!["test"],
            "other",
            false,
            Box::new(move |msg, _ctx, _client_actor| {
                match msg {
                    NetworkRequests::BlockHeaderAnnounce { header, approval } => {
                        assert_eq!(header.height, 1);
                        assert_eq!(header.prev_state_root, MerkleHash::default());
                        assert_eq!(*approval, None);
                        System::current().stop();
                    }
                    _ => {}
                };
                NetworkResponses::NoResponse
            }),
        );
        actix::spawn(view_client.send(GetBlock::Best).then(move |res| {
            let last_block = res.unwrap().unwrap();
            let signer = Arc::new(InMemorySigner::from_seed("test", "test"));
            // Send invalid state root.
            let block = Block::produce(
                &last_block.header,
                last_block.header.height + 1,
                hash(&[0]),
                vec![],
                HashMap::default(),
                vec![],
                signer.clone(),
            );
            client.do_send(NetworkClientMessages::Block(
                block.clone(),
                PeerInfo::random().id,
                false,
            ));
            // Send block that builds on invalid one.
            let block2 = Block::produce(
                &block.header,
                block.header.height + 1,
                hash(&[1]),
                vec![],
                HashMap::default(),
                vec![],
                signer.clone(),
            );
            client.do_send(NetworkClientMessages::Block(block2, PeerInfo::random().id, false));
            // Send proper block.
            let block3 = Block::produce(
                &last_block.header,
                last_block.header.height + 1,
                MerkleHash::default(),
                vec![],
                HashMap::default(),
                vec![],
                signer,
            );
            client.do_send(NetworkClientMessages::Block(block3, PeerInfo::random().id, false));
            future::result(Ok(()))
        }));
        near_network::test_utils::wait_or_panic(5000);
    })
    .unwrap();
}

/// Runs two validators runtime with only one validator online.
/// Present validator produces blocks on it's height after deadline.
#[test]
fn skip_block_production() {
    init_test_logger();
    System::run(|| {
        setup_mock(
            vec!["test1", "test2"],
            "test2",
            true,
            Box::new(move |msg, _ctx, _client_actor| {
                match msg {
                    NetworkRequests::Block { block } => {
                        if block.header.height > 3 {
                            System::current().stop();
                        }
                    }
                    _ => {}
                };
                NetworkResponses::NoResponse
            }),
        );
        wait_or_panic(10000);
    })
    .unwrap();
}

/// Runs client that syncs with peers.
#[test]
fn client_sync() {
    init_test_logger();
    System::run(|| {
        let peer_info1 = PeerInfo::random();
        let _ = setup_mock(
            vec!["test"],
            "other",
            false,
            Box::new(move |msg, _ctx, _client_actor| match msg {
                NetworkRequests::FetchInfo => NetworkResponses::Info {
                    num_active_peers: 1,
                    peer_max_count: 1,
                    most_weight_peers: vec![FullPeerInfo {
                        peer_info: peer_info1.clone(),
                        chain_info: PeerChainInfo { height: 5, total_weight: 100.into() },
                    }],
                },
                NetworkRequests::BlockHeadersRequest { hashes, peer_id } => {
                    assert_eq!(*peer_id, peer_info1.id);
                    assert_eq!(hashes.len(), 1);
                    // TODO: check it requests correct hashes.
                    System::current().stop();
                    NetworkResponses::NoResponse
                }
                _ => NetworkResponses::NoResponse,
            }),
        );
        wait_or_panic(1000);
    })
    .unwrap();
}

'''
'''--- chain/client/tests/query_client.rs ---
use actix::System;
use futures::future;
use futures::future::Future;

use near_client::test_utils::setup_no_network;
use near_client::Query;
use near_primitives::test_utils::init_test_logger;

/// Query account from view client
#[test]
fn query_client() {
    init_test_logger();
    System::run(|| {
        let (_, view_client) = setup_no_network(vec!["test"], "other", true);
        actix::spawn(
            view_client.send(Query { path: "account/test".to_string(), data: vec![] }).then(
                |res| {
                    assert_eq!(res.unwrap().unwrap().log, "exists");
                    System::current().stop();
                    future::result(Ok(()))
                },
            ),
        );
    })
    .unwrap();
}

'''
'''--- chain/jsonrpc/Cargo.toml ---
[package]
name = "near-jsonrpc"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
ansi_term = "0.11.0"
actix = "0.8.1"
actix-web = "1.0.0-rc"
base64 = "0.10.0"
bytes = "0.4.11"
futures = "0.1"
futures03 = { package = "futures-preview", version = "0.3.0-alpha.16", features = ["compat", "async-await", "nightly"] }
chrono = { version = "0.4.4", features = ["serde"] }
log = "0.4"
serde_derive = "1.0"
serde_json = "1.0"
serde = { version = "1.0", features = ["derive"] }
tokio = "0.1.15"
uuid = { version = "~0.6", features = ["v4"] }
protobuf = "2.4"

async-utils = { path = "../../async-utils" }
near-primitives = { path = "../../core/primitives" }
near-protos = { path = "../../core/protos" }
near-store = { path = "../../core/store" }
near-chain = { path = "../chain" }
near-client = { path = "../client" }
near-network = { path = "../network" }
near-pool = { path = "../pool" }

'''
'''--- chain/jsonrpc/src/client.rs ---
use std::time::Duration;

use actix_web::client::Client;
use futures::Future;
use serde::Serialize;

use near_chain::Block;
use near_client::StatusResponse;
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::transaction::{FinalTransactionResult, TransactionResult};
use near_primitives::types::BlockIndex;

use crate::message::{from_slice, Message};

/// Timeout for establishing connection.
const CONNECT_TIMEOUT: Duration = Duration::from_secs(10);

type HttpRequest<T> = Box<dyn Future<Item = T, Error = String>>;
type RpcRequest<T> = Box<dyn Future<Item = T, Error = String>>;

/// Prepare a `RPCRequest` with a given client, server address, method and parameters.
fn call_method<P, R>(client: &Client, server_addr: &str, method: &str, params: P) -> RpcRequest<R>
where
    P: Serialize,
    R: serde::de::DeserializeOwned + 'static,
{
    let request =
        Message::request(method.to_string(), Some(serde_json::to_value(&params).unwrap()));
    // TODO: simplify this.
    Box::new(
        client
            .post(server_addr)
            .header("Content-Type", "application/json")
            .send_json(&request)
            .map_err(|err| err.to_string())
            .and_then(|mut response| {
                response.body().then(|body| match body {
                    Ok(bytes) => {
                        from_slice(&bytes).map_err(|err| format!("Error {:?} in {:?}", err, bytes))
                    }
                    Err(_) => Err("Payload error: {:?}".to_string()),
                })
            })
            .and_then(|message| match message {
                Message::Response(resp) => resp
                    .result
                    .map_err(|x| format!("{:?}", x))
                    .and_then(|x| serde_json::from_value(x).map_err(|x| x.to_string())),
                _ => Err("Invalid message type".to_string()),
            }),
    )
}

/// Prepare a `HttpRequest` with a given client, server address and parameters.
fn call_http_get<R, P>(
    client: &Client,
    server_addr: &str,
    method: &str,
    _params: P,
) -> HttpRequest<R>
where
    P: Serialize,
    R: serde::de::DeserializeOwned + 'static,
{
    // TODO: url encode params.
    let response = client
        .get(format!("{}/{}", server_addr, method))
        .send()
        .map_err(|err| err.to_string())
        .and_then(|mut response| {
            response.body().then(|body| match body {
                Ok(bytes) => String::from_utf8(bytes.to_vec())
                    .map_err(|err| format!("Error {:?} in {:?}", err, bytes))
                    .and_then(|s| serde_json::from_str(&s).map_err(|err| err.to_string())),
                Err(_) => Err("Payload error: {:?}".to_string()),
            })
        });
    Box::new(response)
}

/// Expands a variable list of parameters into its serializable form. Is needed to make the params
/// of a nullary method equal to `[]` instead of `()` and thus make sure it serializes to `[]`
/// instead of `null`.
#[doc(hidden)]
macro_rules! expand_params {
    () => ([] as [(); 0]);
    ($($arg_name:ident,)+) => (($($arg_name,)+))
}

/// Generates a simple HTTP client with automatic serialization and deserialization.
/// Method calls get correct types automatically.
macro_rules! http_client {
    (
        $(#[$struct_attr:meta])*
        pub struct $struct_name:ident {$(
            $(#[$attr:meta])*
            pub fn $method:ident(&mut $selff:ident $(, $arg_name:ident: $arg_ty:ty)*)
                -> HttpRequest<$return_ty:ty>;
        )*}
    ) => (
        $(#[$struct_attr])*
        pub struct $struct_name {
            server_addr: String,
            client: Client,
        }

        impl $struct_name {
            /// Creates a new HTTP client backed by the given transport implementation.
            pub fn new(server_addr: &str, client: Client) -> Self {
                $struct_name { server_addr: server_addr.to_string(), client }
            }

            $(
                $(#[$attr])*
                pub fn $method(&mut $selff $(, $arg_name: $arg_ty)*)
                    -> HttpRequest<$return_ty>
                {
                    let method = String::from(stringify!($method));
                    let params = expand_params!($($arg_name,)*);
                    call_http_get(&mut $selff.client, &$selff.server_addr, &method, params)
                }
            )*
        }
    )
}

/// Generates JSON-RPC 2.0 client structs with automatic serialization
/// and deserialization. Method calls get correct types automatically.
macro_rules! jsonrpc_client {
    (
        $(#[$struct_attr:meta])*
        pub struct $struct_name:ident {$(
            $(#[$attr:meta])*
            pub fn $method:ident(&mut $selff:ident $(, $arg_name:ident: $arg_ty:ty)*)
                -> RpcRequest<$return_ty:ty>;
        )*}
    ) => (
        $(#[$struct_attr])*
        pub struct $struct_name {
            server_addr: String,
            client: Client,
        }

        impl $struct_name {
            /// Creates a new RPC client backed by the given transport implementation.
            pub fn new(server_addr: &str, client: Client) -> Self {
                $struct_name { server_addr: server_addr.to_string(), client }
            }

            $(
                $(#[$attr])*
                pub fn $method(&mut $selff $(, $arg_name: $arg_ty)*)
                    -> RpcRequest<$return_ty>
                {
                    let method = String::from(stringify!($method));
                    let params = expand_params!($($arg_name,)*);
                    call_method(&mut $selff.client, &$selff.server_addr, &method, params)
                }
            )*
        }
    )
}

jsonrpc_client!(pub struct JsonRpcClient {
    pub fn broadcast_tx_async(&mut self, tx: String) -> RpcRequest<String>;
    pub fn broadcast_tx_commit(&mut self, tx: String) -> RpcRequest<FinalTransactionResult>;
    pub fn query(&mut self, path: String, data: String) -> RpcRequest<ABCIQueryResponse>;
    pub fn status(&mut self) -> RpcRequest<StatusResponse>;
    pub fn health(&mut self) -> RpcRequest<()>;
    pub fn tx(&mut self, hash: String) -> RpcRequest<FinalTransactionResult>;
    pub fn tx_details(&mut self, hash: String) -> RpcRequest<TransactionResult>;
    pub fn block(&mut self, height: BlockIndex) -> RpcRequest<Block>;
});

/// Create new JSON RPC client that connects to the given address.
pub fn new_client(server_addr: &str) -> JsonRpcClient {
    let client = Client::build().timeout(CONNECT_TIMEOUT).finish();
    JsonRpcClient::new(server_addr, client)
}

http_client!(pub struct HttpClient {
    pub fn status(&mut self) -> HttpRequest<StatusResponse>;
});

/// Create new HTTP client that connects to the given address.
pub fn new_http_client(server_addr: &str) -> HttpClient {
    let client = Client::build().timeout(CONNECT_TIMEOUT).finish();
    HttpClient::new(server_addr, client)
}

'''
'''--- chain/jsonrpc/src/lib.rs ---
#![feature(await_macro, async_await)]

use std::convert::TryFrom;
use std::convert::TryInto;
use std::time::Duration;

use actix::{Addr, MailboxError};
use actix_web::{App, Error as HttpError, HttpResponse, HttpServer, middleware, web};
use futures03::{compat::Future01CompatExt as _, FutureExt as _, TryFutureExt as _};
use futures::future::Future;
use protobuf::parse_from_bytes;
use serde::de::DeserializeOwned;
use serde_derive::{Deserialize, Serialize};
use serde_json::Value;

use async_utils::{delay, timeout};
use message::Message;
use near_client::{ClientActor, GetBlock, Query, Status, TxDetails, TxStatus, ViewClientActor};
use near_network::{NetworkClientMessages, NetworkClientResponses};
use near_primitives::hash::CryptoHash;
use near_primitives::serialize::{BaseEncode, from_base};
use near_primitives::transaction::{FinalTransactionStatus, SignedTransaction};
use near_primitives::types::BlockIndex;
use near_protos::signed_transaction as transaction_proto;

use crate::message::{Request, RpcError};

pub mod client;
mod message;
pub mod test_utils;

/// Maximum byte size of the json payload.
const JSON_PAYLOAD_MAX_SIZE: usize = 2 * 1024 * 1024;

#[derive(Serialize, Deserialize, Clone, Copy, Debug)]
pub struct RpcPollingConfig {
    pub polling_interval: Duration,
    pub polling_timeout: Duration,
}

impl Default for RpcPollingConfig {
    fn default() -> Self {
        Self {
            polling_interval: Duration::from_millis(100),
            polling_timeout: Duration::from_secs(5),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct RpcConfig {
    pub addr: String,
    pub cors_allowed_origins: Vec<String>,
    pub polling_config: RpcPollingConfig,
}

impl Default for RpcConfig {
    fn default() -> Self {
        RpcConfig {
            addr: "0.0.0.0:3030".to_owned(),
            cors_allowed_origins: vec!["*".to_owned()],
            polling_config: Default::default(),
        }
    }
}

impl RpcConfig {
    pub fn new(addr: &str) -> Self {
        RpcConfig { addr: addr.to_owned(), ..Default::default() }
    }
}

fn from_base_or_parse_err(encoded: String) -> Result<Vec<u8>, RpcError> {
    from_base(&encoded).map_err(|err| RpcError::parse_error(err.to_string()))
}

fn parse_params<T: DeserializeOwned>(value: Option<Value>) -> Result<T, RpcError> {
    if let Some(value) = value {
        serde_json::from_value(value)
            .map_err(|err| RpcError::invalid_params(Some(format!("Failed parsing args: {}", err))))
    } else {
        Err(RpcError::invalid_params(Some("Require at least one parameter".to_owned())))
    }
}

fn jsonify<T: serde::Serialize>(
    response: Result<Result<T, String>, MailboxError>,
) -> Result<Value, RpcError> {
    response
        .map_err(|err| err.to_string())
        .and_then(|value| {
            value.and_then(|value| serde_json::to_value(value).map_err(|err| err.to_string()))
        })
        .map_err(|err| RpcError::server_error(Some(err)))
}

fn parse_tx(params: Option<Value>) -> Result<SignedTransaction, RpcError> {
    let (encoded,) = parse_params::<(String,)>(params)?;
    let bytes = from_base_or_parse_err(encoded)?;
    let tx: transaction_proto::SignedTransaction = parse_from_bytes(&bytes).map_err(|e| {
        RpcError::invalid_params(Some(format!("Failed to decode transaction proto: {}", e)))
    })?;
    Ok(tx.try_into().map_err(|e| {
        RpcError::invalid_params(Some(format!("Failed to decode transaction: {}", e)))
    })?)
}

fn parse_hash(params: Option<Value>) -> Result<CryptoHash, RpcError> {
    let (encoded,) = parse_params::<(String,)>(params)?;
    from_base_or_parse_err(encoded).and_then(|bytes| {
        CryptoHash::try_from(bytes).map_err(|err| RpcError::parse_error(err.to_string()))
    })
}

struct JsonRpcHandler {
    client_addr: Addr<ClientActor>,
    view_client_addr: Addr<ViewClientActor>,
    polling_config: RpcPollingConfig,
}

impl JsonRpcHandler {
    pub async fn process(&self, message: Message) -> Result<Message, HttpError> {
        let id = message.id();
        match message {
            Message::Request(request) => {
                Ok(Message::response(id, self.process_request(request).await))
            }
            _ => Ok(Message::error(RpcError::invalid_request())),
        }
    }

    async fn process_request(&self, request: Request) -> Result<Value, RpcError> {
        match request.method.as_ref() {
            "broadcast_tx_async" => self.send_tx_async(request.params).await,
            "broadcast_tx_commit" => self.send_tx_commit(request.params).await,
            "query" => self.query(request.params).await,
            "health" => self.health().await,
            "status" => self.status().await,
            "tx" => self.tx_status(request.params).await,
            "tx_details" => self.tx_details(request.params).await,
            "block" => self.block(request.params).await,
            _ => Err(RpcError::method_not_found(request.method)),
        }
    }

    async fn send_tx_async(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let tx = parse_tx(params)?;
        let hash = (&tx.get_hash()).to_base();
        actix::spawn(
            self.client_addr
                .send(NetworkClientMessages::Transaction(tx))
                .map(|_| ())
                .map_err(|_| ()),
        );
        Ok(Value::String(hash))
    }

    async fn send_tx_commit(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let tx = parse_tx(params)?;
        let tx_hash = tx.get_hash();
        let result = self.client_addr
            .send(NetworkClientMessages::Transaction(tx))
            .map_err(|err| RpcError::server_error(Some(err.to_string())))
            .compat()
            .await?;
        match result {
            NetworkClientResponses::ValidTx => {
                timeout(self.polling_config.polling_timeout, async {
                    loop {
                        let final_tx = self.view_client_addr.send(TxStatus { tx_hash }).compat().await;
                        if let Ok(Ok(ref tx)) = final_tx {
                            match tx.status {
                                FinalTransactionStatus::Started | FinalTransactionStatus::Unknown => {}
                                _ => {
                                    break jsonify(final_tx);
                                }
                            }
                        }
                        let _ = delay(self.polling_config.polling_interval).await;
                    }
                })
                    .await
                    .map_err(|_| RpcError::server_error(Some("send_tx_commit has timed out.".to_owned())))?
            },
            NetworkClientResponses::InvalidTx(err) => {
                Err(RpcError::server_error(Some(err)))
            }
            _ => unreachable!(),
        }
    }

    async fn health(&self) -> Result<Value, RpcError> {
        Ok(Value::Null)
    }

    pub async fn status(&self) -> Result<Value, RpcError> {
        jsonify(self.client_addr.send(Status {}).compat().await)
    }

    async fn query(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let (path, data) = parse_params::<(String, String)>(params)?;
        let data = from_base_or_parse_err(data)?;
        jsonify(self.view_client_addr.send(Query { path, data }).compat().await)
    }

    async fn tx_status(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let tx_hash = parse_hash(params)?;
        jsonify(self.view_client_addr.send(TxStatus { tx_hash }).compat().await)
    }

    async fn tx_details(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let tx_hash = parse_hash(params)?;
        jsonify(self.view_client_addr.send(TxDetails { tx_hash }).compat().await)
    }

    async fn block(&self, params: Option<Value>) -> Result<Value, RpcError> {
        let (height,) = parse_params::<(BlockIndex,)>(params)?;
        jsonify(self.view_client_addr.send(GetBlock::Height(height)).compat().await)
    }
}

fn rpc_handler(
    message: web::Json<Message>,
    handler: web::Data<JsonRpcHandler>,
) -> impl Future<Item = HttpResponse, Error = HttpError> {
    let response = async move {
        let message = handler.process(message.0).await?;
        Ok(HttpResponse::Ok().json(message))
    };
    response.boxed().compat()
}

fn status_handler(handler: web::Data<JsonRpcHandler>) -> impl Future<Item = HttpResponse, Error = HttpError> {
    let response = async move {
        match handler.status().await {
            Ok(value) => Ok(HttpResponse::Ok().json(value)),
            Err(_) => Ok(HttpResponse::ServiceUnavailable().finish()),
        }
    };
    response.boxed().compat()
}

pub fn start_http(
    config: RpcConfig,
    client_addr: Addr<ClientActor>,
    view_client_addr: Addr<ViewClientActor>,
) {
    let RpcConfig { addr, polling_config, .. } = config;
    HttpServer::new(move || {
        App::new()
            .data(JsonRpcHandler {
                client_addr: client_addr.clone(),
                view_client_addr: view_client_addr.clone(),
                polling_config,
            })
            .data(web::JsonConfig::default().limit(JSON_PAYLOAD_MAX_SIZE))
            .wrap(middleware::Logger::default())
            .service(web::resource("/").route(web::post().to_async(rpc_handler)))
            .service(web::resource("/status").route(web::get().to_async(status_handler)))
    })
    .bind(addr)
    .unwrap()
    .workers(4)
    .shutdown_timeout(5)
    .start();
}

'''
'''--- chain/jsonrpc/src/message.rs ---
// Copyright 2017 tokio-jsonrpc Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.

//! JSON-RPC 2.0 messages.
//!
//! The main entrypoint here is the [Message](enum.Message.html). The others are just building
//! blocks and you should generally work with `Message` instead.

#![allow(unused)]

use std::fmt::{Formatter, Result as FmtResult};

use serde::de::{Deserialize, Deserializer, Error, Unexpected, Visitor};
use serde::ser::{Serialize, SerializeStruct, Serializer};
use serde_derive::{Deserialize, Serialize};
use serde_json::{to_value, Result as JsonResult, Value};
use uuid::Uuid;

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
struct Version;

impl Serialize for Version {
    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {
        serializer.serialize_str("2.0")
    }
}

impl<'de> Deserialize<'de> for Version {
    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {
        struct VersionVisitor;
        impl<'de> Visitor<'de> for VersionVisitor {
            type Value = Version;

            fn expecting(&self, formatter: &mut Formatter) -> FmtResult {
                formatter.write_str("a version string")
            }

            fn visit_str<E: Error>(self, value: &str) -> Result<Version, E> {
                match value {
                    "2.0" => Ok(Version),
                    _ => Err(E::invalid_value(Unexpected::Str(value), &"value 2.0")),
                }
            }
        }
        deserializer.deserialize_str(VersionVisitor)
    }
}

/// An RPC request.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(deny_unknown_fields)]
pub struct Request {
    jsonrpc: Version,
    pub method: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub params: Option<Value>,
    pub id: Value,
}

impl Request {
    /// Answer the request with a (positive) reply.
    ///
    /// The ID is taken from the request.
    pub fn reply(&self, reply: Value) -> Message {
        Message::Response(Response { jsonrpc: Version, result: Ok(reply), id: self.id.clone() })
    }
    /// Answer the request with an error.
    pub fn error(&self, error: RpcError) -> Message {
        Message::Response(Response { jsonrpc: Version, result: Err(error), id: self.id.clone() })
    }
}

/// An error code.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(deny_unknown_fields)]
pub struct RpcError {
    pub code: i64,
    pub message: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub data: Option<Value>,
}

impl RpcError {
    /// A generic constructor.
    ///
    /// Mostly for completeness, doesn't do anything but filling in the corresponding fields.
    pub fn new(code: i64, message: String, data: Option<Value>) -> Self {
        RpcError { code, message, data }
    }
    /// Create an Invalid Param error.
    pub fn invalid_params(msg: Option<String>) -> Self {
        RpcError::new(-32_602, "Invalid params".to_owned(), msg.map(Value::String))
    }
    /// Create a server error.
    pub fn server_error<E: Serialize>(e: Option<E>) -> Self {
        RpcError::new(
            -32_000,
            "Server error".to_owned(),
            e.map(|v| to_value(v).expect("Must be representable in JSON")),
        )
    }
    /// Create an invalid request error.
    pub fn invalid_request() -> Self {
        RpcError::new(-32_600, "Invalid request".to_owned(), None)
    }
    /// Create a parse error.
    pub fn parse_error(e: String) -> Self {
        RpcError::new(-32_700, "Parse error".to_owned(), Some(Value::String(e)))
    }
    /// Create a method not found error.
    pub fn method_not_found(method: String) -> Self {
        RpcError::new(-32_601, "Method not found".to_owned(), Some(Value::String(method)))
    }
}

/// A response to an RPC.
///
/// It is created by the methods on [Request](struct.Request.html).
#[derive(Debug, Clone, PartialEq)]
pub struct Response {
    jsonrpc: Version,
    pub result: Result<Value, RpcError>,
    pub id: Value,
}

impl Serialize for Response {
    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {
        let mut sub = serializer.serialize_struct("Response", 3)?;
        sub.serialize_field("jsonrpc", &self.jsonrpc)?;
        match self.result {
            Ok(ref value) => sub.serialize_field("result", value),
            Err(ref err) => sub.serialize_field("error", err),
        }?;
        sub.serialize_field("id", &self.id)?;
        sub.end()
    }
}

/// Deserializer for `Option<Value>` that produces `Some(Value::Null)`.
///
/// The usual one produces None in that case. But we need to know the difference between
/// `{x: null}` and `{}`.
fn some_value<'de, D: Deserializer<'de>>(deserializer: D) -> Result<Option<Value>, D::Error> {
    Deserialize::deserialize(deserializer).map(Some)
}

/// A helper trick for deserialization.
#[derive(Deserialize)]
#[serde(deny_unknown_fields)]
struct WireResponse {
    // It is actually used to eat and sanity check the deserialized text
    #[allow(dead_code)]
    jsonrpc: Version,
    // Make sure we accept null as Some(Value::Null), instead of going to None
    #[serde(default, deserialize_with = "some_value")]
    result: Option<Value>,
    error: Option<RpcError>,
    id: Value,
}

// Implementing deserialize is hard. We sidestep the difficulty by deserializing a similar
// structure that directly corresponds to whatever is on the wire and then convert it to our more
// convenient representation.
impl<'de> Deserialize<'de> for Response {
    #[allow(unreachable_code)] // For that unreachable below
    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {
        let wr: WireResponse = Deserialize::deserialize(deserializer)?;
        let result = match (wr.result, wr.error) {
            (Some(res), None) => Ok(res),
            (None, Some(err)) => Err(err),
            _ => {
                let err = D::Error::custom("Either 'error' or 'result' is expected, but not both");
                return Err(err);
            }
        };
        Ok(Response { jsonrpc: Version, result, id: wr.id })
    }
}

/// A notification (doesn't expect an answer).
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(deny_unknown_fields)]
pub struct Notification {
    jsonrpc: Version,
    pub method: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub params: Option<Value>,
}

/// One message of the JSON RPC protocol.
///
/// One message, directly mapped from the structures of the protocol. See the
/// [specification](http://www.jsonrpc.org/specification) for more details.
///
/// Since the protocol allows one endpoint to be both client and server at the same time, the
/// message can decode and encode both directions of the protocol.
///
/// The `Batch` variant is supposed to be created directly, without a constructor.
///
/// The `UnmatchedSub` variant is used when a request is an array and some of the subrequests
/// aren't recognized as valid json rpc 2.0 messages. This is never returned as a top-level
/// element, it is returned as `Err(Broken::Unmatched)`.
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(untagged)]
pub enum Message {
    /// An RPC request.
    Request(Request),
    /// A response to a Request.
    Response(Response),
    /// A notification.
    Notification(Notification),
    /// A batch of more requests or responses.
    ///
    /// The protocol allows bundling multiple requests, notifications or responses to a single
    /// message.
    ///
    /// This variant has no direct constructor and is expected to be constructed manually.
    Batch(Vec<Message>),
    /// An unmatched sub entry in a `Batch`.
    ///
    /// When there's a `Batch` and an element doesn't comform to the JSONRPC 2.0 format, that one
    /// is represented by this. This is never produced as a top-level value when parsing, the
    /// `Err(Broken::Unmatched)` is used instead. It is not possible to serialize.
    #[serde(skip_serializing)]
    UnmatchedSub(Value),
}

impl Message {
    /// A constructor for a request.
    ///
    /// The ID is auto-generated.
    pub fn request(method: String, params: Option<Value>) -> Self {
        Message::Request(Request {
            jsonrpc: Version,
            method,
            params,
            id: Value::String(Uuid::new_v4().hyphenated().to_string()),
        })
    }
    /// Create a top-level error (without an ID).
    pub fn error(error: RpcError) -> Self {
        Message::Response(Response { jsonrpc: Version, result: Err(error), id: Value::Null })
    }
    /// A constructor for a notification.
    pub fn notification(method: String, params: Option<Value>) -> Self {
        Message::Notification(Notification { jsonrpc: Version, method, params })
    }
    /// A constructor for a response.
    pub fn response(id: Value, result: Result<Value, RpcError>) -> Self {
        Message::Response(Response { jsonrpc: Version, result, id })
    }
    /// Returns id or Null if there is no id.
    pub fn id(&self) -> Value {
        match self {
            Message::Request(req) => req.id.clone(),
            _ => Value::Null,
        }
    }
}

/// A broken message.
///
/// Protocol-level errors.
#[derive(Debug, Clone, PartialEq, Deserialize)]
#[serde(untagged)]
pub enum Broken {
    /// It was valid JSON, but doesn't match the form of a JSONRPC 2.0 message.
    Unmatched(Value),
    /// Invalid JSON.
    #[serde(skip_deserializing)]
    SyntaxError(String),
}

impl Broken {
    /// Generate an appropriate error message.
    ///
    /// The error message for these things are specified in the RFC, so this just creates an error
    /// with the right values.
    pub fn reply(&self) -> Message {
        match *self {
            Broken::Unmatched(_) => Message::error(RpcError::invalid_request()),
            Broken::SyntaxError(ref e) => Message::error(RpcError::parse_error(e.clone())),
        }
    }
}

/// A trick to easily deserialize and detect valid JSON, but invalid Message.
#[derive(Deserialize)]
#[serde(untagged)]
pub(crate) enum WireMessage {
    Message(Message),
    Broken(Broken),
}

pub(crate) fn decoded_to_parsed(res: JsonResult<WireMessage>) -> Parsed {
    match res {
        Ok(WireMessage::Message(Message::UnmatchedSub(value))) => Err(Broken::Unmatched(value)),
        Ok(WireMessage::Message(m)) => Ok(m),
        Ok(WireMessage::Broken(b)) => Err(b),
        Err(e) => Err(Broken::SyntaxError(format!("{}", e))),
    }
}

pub type Parsed = Result<Message, Broken>;

/// Read a [Message](enum.Message.html) from a slice.
///
/// Invalid JSON or JSONRPC messages are reported as [Broken](enum.Broken.html).
pub fn from_slice(s: &[u8]) -> Parsed {
    decoded_to_parsed(::serde_json::de::from_slice(s))
}

/// Read a [Message](enum.Message.html) from a string.
///
/// Invalid JSON or JSONRPC messages are reported as [Broken](enum.Broken.html).
pub fn from_str(s: &str) -> Parsed {
    from_slice(s.as_bytes())
}

impl Into<String> for Message {
    fn into(self) -> String {
        ::serde_json::ser::to_string(&self).unwrap()
    }
}

impl Into<Vec<u8>> for Message {
    fn into(self) -> Vec<u8> {
        ::serde_json::ser::to_vec(&self).unwrap()
    }
}

#[cfg(test)]
mod tests {
    use serde_json::de::from_slice;
    use serde_json::json;
    use serde_json::ser::to_vec;
    use serde_json::Value;

    use super::*;

    /// Test serialization and deserialization of the Message
    ///
    /// We first deserialize it from a string. That way we check deserialization works.
    /// But since serialization doesn't have to produce the exact same result (order, spaces, …),
    /// we then serialize and deserialize the thing again and check it matches.
    #[test]
    fn message_serde() {
        // A helper for running one message test
        fn one(input: &str, expected: &Message) {
            let parsed: Message = from_str(input).unwrap();
            assert_eq!(*expected, parsed);
            let serialized = to_vec(&parsed).unwrap();
            let deserialized: Message = from_slice(&serialized).unwrap();
            assert_eq!(parsed, deserialized);
        }

        // A request without parameters
        one(
            r#"{"jsonrpc": "2.0", "method": "call", "id": 1}"#,
            &Message::Request(Request {
                jsonrpc: Version,
                method: "call".to_owned(),
                params: None,
                id: json!(1),
            }),
        );
        // A request with parameters
        one(
            r#"{"jsonrpc": "2.0", "method": "call", "params": [1, 2, 3], "id": 2}"#,
            &Message::Request(Request {
                jsonrpc: Version,
                method: "call".to_owned(),
                params: Some(json!([1, 2, 3])),
                id: json!(2),
            }),
        );
        // A notification (with parameters)
        one(
            r#"{"jsonrpc": "2.0", "method": "notif", "params": {"x": "y"}}"#,
            &Message::Notification(Notification {
                jsonrpc: Version,
                method: "notif".to_owned(),
                params: Some(json!({"x": "y"})),
            }),
        );
        // A successful response
        one(
            r#"{"jsonrpc": "2.0", "result": 42, "id": 3}"#,
            &Message::Response(Response { jsonrpc: Version, result: Ok(json!(42)), id: json!(3) }),
        );
        // A successful response
        one(
            r#"{"jsonrpc": "2.0", "result": null, "id": 3}"#,
            &Message::Response(Response {
                jsonrpc: Version,
                result: Ok(Value::Null),
                id: json!(3),
            }),
        );
        // An error
        one(
            r#"{"jsonrpc": "2.0", "error": {"code": 42, "message": "Wrong!"}, "id": null}"#,
            &Message::Response(Response {
                jsonrpc: Version,
                result: Err(RpcError::new(42, "Wrong!".to_owned(), None)),
                id: Value::Null,
            }),
        );
        // A batch
        one(
            r#"[
                {"jsonrpc": "2.0", "method": "notif"},
                {"jsonrpc": "2.0", "method": "call", "id": 42}
            ]"#,
            &Message::Batch(vec![
                Message::Notification(Notification {
                    jsonrpc: Version,
                    method: "notif".to_owned(),
                    params: None,
                }),
                Message::Request(Request {
                    jsonrpc: Version,
                    method: "call".to_owned(),
                    params: None,
                    id: json!(42),
                }),
            ]),
        );
        // Some handling of broken messages inside a batch
        let parsed = from_str(
            r#"[
                {"jsonrpc": "2.0", "method": "notif"},
                {"jsonrpc": "2.0", "method": "call", "id": 42},
                true
            ]"#,
        )
        .unwrap();
        assert_eq!(
            Message::Batch(vec![
                Message::Notification(Notification {
                    jsonrpc: Version,
                    method: "notif".to_owned(),
                    params: None,
                }),
                Message::Request(Request {
                    jsonrpc: Version,
                    method: "call".to_owned(),
                    params: None,
                    id: json!(42),
                }),
                Message::UnmatchedSub(Value::Bool(true)),
            ]),
            parsed
        );
        to_vec(&Message::UnmatchedSub(Value::Null)).unwrap_err();
    }

    /// A helper for the `broken` test.
    ///
    /// Check that the given JSON string parses, but is not recognized as a valid RPC message.

    /// Test things that are almost but not entirely JSONRPC are rejected
    ///
    /// The reject is done by returning it as Unmatched.
    #[test]
    fn broken() {
        // A helper with one test
        fn one(input: &str) {
            let msg = from_str(input);
            match msg {
                Err(Broken::Unmatched(_)) => (),
                _ => panic!("{} recognized as an RPC message: {:?}!", input, msg),
            }
        }

        // Missing the version
        one(r#"{"method": "notif"}"#);
        // Wrong version
        one(r#"{"jsonrpc": 2.0, "method": "notif"}"#);
        // A response with both result and error
        one(r#"{"jsonrpc": "2.0", "result": 42, "error": {"code": 42, "message": "!"}, "id": 1}"#);
        // A response without an id
        one(r#"{"jsonrpc": "2.0", "result": 42}"#);
        // An extra field
        one(r#"{"jsonrpc": "2.0", "method": "weird", "params": 42, "others": 43, "id": 2}"#);
        // Something completely different
        one(r#"{"x": [1, 2, 3]}"#);

        match from_str(r#"{]"#) {
            Err(Broken::SyntaxError(_)) => (),
            other => panic!("Something unexpected: {:?}", other),
        };
    }

    /// Test some non-trivial aspects of the constructors
    ///
    /// This doesn't have a full coverage, because there's not much to actually test there.
    /// Most of it is related to the ids.
    #[test]
    fn constructors() {
        let msg1 = Message::request("call".to_owned(), Some(json!([1, 2, 3])));
        let msg2 = Message::request("call".to_owned(), Some(json!([1, 2, 3])));
        // They differ, even when created with the same parameters
        assert_ne!(msg1, msg2);
        // And, specifically, they differ in the ID's
        let (req1, req2) = if let (Message::Request(req1), Message::Request(req2)) = (msg1, msg2) {
            assert_ne!(req1.id, req2.id);
            assert!(req1.id.is_string());
            assert!(req2.id.is_string());
            (req1, req2)
        } else {
            panic!("Non-request received");
        };
        let id1 = req1.id.clone();
        // When we answer a message, we get the same ID
        if let Message::Response(ref resp) = req1.reply(json!([1, 2, 3])) {
            assert_eq!(*resp, Response { jsonrpc: Version, result: Ok(json!([1, 2, 3])), id: id1 });
        } else {
            panic!("Not a response");
        }
        let id2 = req2.id.clone();
        // The same with an error
        if let Message::Response(ref resp) =
            req2.error(RpcError::new(42, "Wrong!".to_owned(), None))
        {
            assert_eq!(
                *resp,
                Response {
                    jsonrpc: Version,
                    result: Err(RpcError::new(42, "Wrong!".to_owned(), None)),
                    id: id2,
                }
            );
        } else {
            panic!("Not a response");
        }
        // When we have unmatched, we generate a top-level error with Null id.
        if let Message::Response(ref resp) =
            Message::error(RpcError::new(43, "Also wrong!".to_owned(), None))
        {
            assert_eq!(
                *resp,
                Response {
                    jsonrpc: Version,
                    result: Err(RpcError::new(43, "Also wrong!".to_owned(), None)),
                    id: Value::Null,
                }
            );
        } else {
            panic!("Not a response");
        }
    }
}

'''
'''--- chain/jsonrpc/src/test_utils.rs ---
use actix::Addr;

use near_client::test_utils::setup_no_network;
use near_client::ViewClientActor;
use near_network::test_utils::open_port;

use crate::{start_http, RpcConfig};

pub fn start_all(validator: bool) -> (Addr<ViewClientActor>, String) {
    let (client_addr, view_client_addr) =
        setup_no_network(vec!["test1", "test2"], if validator { "test1" } else { "other" }, true);

    let addr = format!("127.0.0.1:{}", open_port());
    start_http(RpcConfig::new(&addr), client_addr.clone(), view_client_addr.clone());
    (view_client_addr, addr)
}

'''
'''--- chain/jsonrpc/tests/http_query.rs ---
use actix::System;
use futures::future;
use futures::future::Future;

use near_jsonrpc::client::new_http_client;
use near_jsonrpc::test_utils::start_all;
use near_primitives::test_utils::init_test_logger;

/// Retrieve client status via HTTP GET.
#[test]
fn test_status() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(false);

        let mut client = new_http_client(&format!("http://{}", addr));
        actix::spawn(client.status().then(|res| {
            let res = res.unwrap();
            assert_eq!(res.chain_id, "unittest");
            assert_eq!(res.sync_info.latest_block_height, 0);
            assert_eq!(res.sync_info.syncing, false);
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

'''
'''--- chain/jsonrpc/tests/rpc_query.rs ---
use actix::System;
use futures::future;
use futures::future::Future;

use near_jsonrpc::client::new_client;
use near_jsonrpc::test_utils::start_all;
use near_primitives::test_utils::init_test_logger;

/// Retrieve blocks via json rpc
#[test]
fn test_block() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(false);

        let mut client = new_client(&format!("http://{}", addr));
        actix::spawn(client.block(0).then(|res| {
            assert_eq!(res.unwrap().header.height, 0);
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Connect to json rpc and query the client.
#[test]
fn test_query() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(false);

        let mut client = new_client(&format!("http://{}", addr));
        actix::spawn(client.query("account/test".to_string(), "".to_string()).then(|res| {
            assert!(res.is_ok());
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Retrieve client status via JSON RPC.
#[test]
fn test_status() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(false);

        let mut client = new_client(&format!("http://{}", addr));
        actix::spawn(client.status().then(|res| {
            let res = res.unwrap();
            assert_eq!(res.chain_id, "unittest");
            assert_eq!(res.sync_info.latest_block_height, 0);
            assert_eq!(res.sync_info.syncing, false);
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Check health fails when node is absent.
#[test]
fn test_health_fail() {
    init_test_logger();

    System::run(|| {
        let mut client = new_client(&"http://127.0.0.1:12322/health");
        actix::spawn(client.health().then(|res| {
            assert!(res.is_err());
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

/// Retrieve client health.
#[test]
fn test_health_ok() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(false);

        let mut client = new_client(&format!("http://{}", addr));
        actix::spawn(client.health().then(|res| {
            assert!(res.is_ok());
            System::current().stop();
            future::result(Ok(()))
        }));
    })
    .unwrap();
}

'''
'''--- chain/jsonrpc/tests/rpc_transactions.rs ---
use actix::{Actor, System};
use futures::future::Future;
use protobuf::Message;

use near_jsonrpc::client::new_client;
use near_jsonrpc::test_utils::start_all;
use near_network::test_utils::{wait_or_panic, WaitOrTimeout};
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::serialize::to_base;
use near_primitives::test_utils::init_test_logger;
use near_primitives::transaction::{FinalTransactionStatus, TransactionBody};
use near_protos::signed_transaction as transaction_proto;

/// Test sending transaction via json rpc without waiting.
#[test]
fn test_send_tx_async() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(true);

        let mut client = new_client(&format!("http://{}", addr));
        let signer = InMemorySigner::from_seed("test1", "test1");
        let tx = TransactionBody::send_money(1, "test1", "test2", 100).sign(&signer);
        let tx_hash: String = (&tx.get_hash()).into();
        let tx_hash2 = tx_hash.clone();
        let proto: transaction_proto::SignedTransaction = tx.into();
        actix::spawn(
            client
                .broadcast_tx_async(to_base(&proto.write_to_bytes().unwrap()))
                .map_err(|_| ())
                .map(move |result| assert_eq!(tx_hash, result)),
        );
        WaitOrTimeout::new(
            Box::new(move |_| {
                actix::spawn(
                    client.tx(tx_hash2.clone()).map_err(|err| println!("Error: {:?}", err)).map(
                        |result| {
                            if result.status == FinalTransactionStatus::Completed {
                                System::current().stop();
                            }
                        },
                    ),
                )
            }),
            100,
            1000,
        )
        .start();
    })
    .unwrap();
}

/// Test sending transaction and waiting for it to be committed to a block.
#[test]
fn test_send_tx_commit() {
    init_test_logger();

    System::run(|| {
        let (_view_client_addr, addr) = start_all(true);

        let mut client = new_client(&format!("http://{}", addr));
        let signer = InMemorySigner::from_seed("test1", "test1");
        let tx = TransactionBody::send_money(1, "test1", "test2", 100).sign(&signer);
        let proto: transaction_proto::SignedTransaction = tx.into();
        actix::spawn(
            client
                .broadcast_tx_commit(to_base(&proto.write_to_bytes().unwrap()))
                .map_err(|why| {
                    System::current().stop();
                    panic!(why);
                })
                .map(move |result| {
                    assert_eq!(result.status, FinalTransactionStatus::Completed);
                    System::current().stop();
                }),
        );
        wait_or_panic(10000);
    })
    .unwrap();
}

'''
'''--- chain/network/Cargo.toml ---
[package]
name = "near-network"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
bytes = "0.4"
actix = "0.8.1"
log = "0.4"
tokio = "0.1"
protobuf = "2.4"
futures = "0.1"
chrono = { version = "0.4.4", features = ["serde"] }
serde = "1.0"
serde_derive = "1.0"
rand = "0.6.5"

near-primitives = { path = "../../core/primitives" }
near-protos = { path = "../../core/protos" }
near-store = { path = "../../core/store" }
near-chain = { path = "../chain" }

[dev-dependencies]
near-client = { path = "../client" }
'''
'''--- chain/network/src/codec.rs ---
use std::convert::TryInto;
use std::io::{Error, ErrorKind};

use bytes::{BufMut, BytesMut};
use protobuf::{parse_from_bytes, Message, ProtobufError};
use tokio::codec::{Decoder, Encoder};

use near_protos::network::PeerMessage as ProtoMessage;

use crate::types::PeerMessage;

// we could write our custom error type. For now we just
// use io::Error
fn convert_protobuf_error(err: ProtobufError) -> Error {
    match err {
        ProtobufError::IoError(e) => e,
        ProtobufError::MessageNotInitialized { message } => {
            Error::new(ErrorKind::InvalidInput, format!("protobuf not initialized: {}", message))
        }
        ProtobufError::Utf8(e) => Error::new(ErrorKind::InvalidInput, format!("Utf8 error: {}", e)),
        ProtobufError::WireError(e) => {
            Error::new(ErrorKind::InvalidInput, format!("WireError: {:?}", e))
        }
    }
}

pub struct Codec {
    max_length: u32,
}

impl Codec {
    pub fn new() -> Self {
        Codec { max_length: std::u32::MAX }
    }
}

impl Encoder for Codec {
    type Item = PeerMessage;
    type Error = Error;

    fn encode(&mut self, item: PeerMessage, buf: &mut BytesMut) -> Result<(), Error> {
        let proto: ProtoMessage = item.into();
        let bytes = proto.write_to_bytes().map_err(convert_protobuf_error)?;
        // first four bytes is the length of the buffer
        buf.reserve(bytes.len() + 4);
        if bytes.len() > self.max_length as usize {
            Err(Error::new(ErrorKind::InvalidInput, "Input is too long"))
        } else {
            buf.put_u32_le(bytes.len() as u32);
            buf.put(bytes);
            Ok(())
        }
    }
}

impl Decoder for Codec {
    type Item = PeerMessage;
    type Error = Error;

    fn decode(&mut self, buf: &mut BytesMut) -> Result<Option<PeerMessage>, Error> {
        if buf.len() < 4 {
            // not enough bytes to start decoding
            return Ok(None);
        }
        let mut len_bytes: [u8; 4] = [0; 4];
        len_bytes.copy_from_slice(&buf[0..4]);
        let len = unsafe { std::mem::transmute::<[u8; 4], u32>(len_bytes) }.to_le();
        if buf.len() < 4 + len as usize {
            // not enough bytes, keep waiting
            Ok(None)
        } else {
            let res: ProtoMessage =
                parse_from_bytes(&buf[4..4 + len as usize]).map_err(convert_protobuf_error)?;
            buf.advance(4 + len as usize);
            res.try_into()
                .map_err(|e: Box<dyn std::error::Error>| {
                    Error::new(ErrorKind::InvalidData, e.to_string())
                })
                .map(Some)
        }
    }
}

#[cfg(test)]
mod test {
    use crate::types::{Handshake, PeerChainInfo, PeerInfo};

    use super::*;

    fn test_codec(msg: PeerMessage) {
        let mut codec = Codec::new();
        let mut buffer = BytesMut::new();
        codec.encode(msg.clone(), &mut buffer).unwrap();
        let decoded = codec.decode(&mut buffer).unwrap().unwrap();
        assert_eq!(decoded, msg);
    }

    #[test]
    fn test_peer_message_handshake() {
        let peer_info = PeerInfo::random();
        let fake_handshake = Handshake {
            version: 1,
            peer_id: peer_info.id,
            account_id: Some("alice.near".to_string()),
            listen_port: None,
            chain_info: PeerChainInfo { height: 0, total_weight: 0.into() },
        };
        let msg = PeerMessage::Handshake(fake_handshake);
        test_codec(msg);
    }

    #[test]
    fn test_peer_message_info_gossip() {
        let peer_info1 = PeerInfo::random();
        let peer_info2 = PeerInfo::random();
        let msg = PeerMessage::PeersResponse(vec![peer_info1, peer_info2]);
        test_codec(msg);
    }
}

'''
'''--- chain/network/src/lib.rs ---
pub use peer_manager::PeerManagerActor;
pub use types::{
    FullPeerInfo, NetworkClientMessages, NetworkClientResponses, NetworkConfig, NetworkRequests,
    NetworkResponses, PeerInfo,
};

mod codec;
mod peer;
mod peer_manager;
mod peer_store;
pub mod types;

pub mod test_utils;

'''
'''--- chain/network/src/peer.rs ---
use std::io;
use std::net::SocketAddr;
use std::time::Duration;

use actix::io::{FramedWrite, WriteHandler};
use actix::{
    Actor, ActorContext, ActorFuture, Addr, AsyncContext, Context, ContextFutureSpawner, Handler,
    Recipient, Running, StreamHandler, WrapFuture,
};
use log::{debug, error, info, warn};
use tokio::io::WriteHalf;
use tokio::net::TcpStream;

use near_primitives::utils::DisplayOption;

use crate::codec::Codec;
use crate::types::{
    Ban, Consolidate, Handshake, NetworkClientMessages, PeerChainInfo, PeerInfo, PeerMessage,
    PeerStatus, PeerType, PeersRequest, PeersResponse, SendMessage, Unregister,
};
use crate::{NetworkClientResponses, PeerManagerActor};

pub struct Peer {
    /// This node's id and address (either listening or socket address).
    pub node_info: PeerInfo,
    /// Peer address from connection.
    pub peer_addr: SocketAddr,
    /// Peer id and info. Present if outbound or ready.
    pub peer_info: DisplayOption<PeerInfo>,
    /// Peer type.
    pub peer_type: PeerType,
    /// Peer status.
    pub peer_status: PeerStatus,
    /// Framed wrapper to send messages through the TCP connection.
    framed: FramedWrite<WriteHalf<TcpStream>, Codec>,
    /// Handshake timeout.
    handshake_timeout: Duration,
    /// Peer manager recipient to break the dependency loop.
    peer_manager_addr: Addr<PeerManagerActor>,
    client_addr: Recipient<NetworkClientMessages>,
}

impl Peer {
    pub fn new(
        node_info: PeerInfo,
        peer_addr: SocketAddr,
        peer_info: Option<PeerInfo>,
        peer_type: PeerType,
        framed: FramedWrite<WriteHalf<TcpStream>, Codec>,
        handshake_timeout: Duration,
        peer_manager_addr: Addr<PeerManagerActor>,
        client_addr: Recipient<NetworkClientMessages>,
    ) -> Self {
        Peer {
            node_info,
            peer_addr,
            peer_info: peer_info.into(),
            peer_type,
            peer_status: PeerStatus::Connecting,
            framed,
            handshake_timeout,
            peer_manager_addr,
            client_addr,
        }
    }

    fn send_message(&mut self, msg: PeerMessage) {
        debug!(target: "network", "Sending {:?} message to peer {}", msg, self.peer_info);
        self.framed.write(msg.into());
    }

    fn send_handshake(&mut self, ctx: &mut Context<Peer>) {
        self.client_addr
            .send(NetworkClientMessages::GetChainInfo)
            .into_actor(self)
            .then(move |res, act, _ctx| match res {
                Ok(NetworkClientResponses::ChainInfo { height, total_weight }) => {
                    let handshake = Handshake::new(
                        act.node_info.id,
                        act.node_info.account_id.clone(),
                        act.node_info.addr_port(),
                        PeerChainInfo { height, total_weight },
                    );
                    act.send_message(PeerMessage::Handshake(handshake));
                    actix::fut::ok(())
                }
                Err(err) => {
                    error!(target: "network", "Failed sending GetChain to client: {}", err);
                    actix::fut::err(())
                }
                _ => actix::fut::err(()),
            })
            .spawn(ctx);
    }

    /// Process non handshake/peer related messages.
    fn receive_client_message(&mut self, ctx: &mut Context<Peer>, msg: PeerMessage) {
        debug!(target: "network", "Received {:?} message from {}", msg, self.peer_info);
        let peer_id = match self.peer_info.as_ref() {
            Some(peer_info) => peer_info.id.clone(),
            None => {
                return;
            }
        };

        // Wrap peer message into what client expects.
        let network_client_msg = match msg {
            PeerMessage::Block(block) => {
                // TODO: add tracking of requests here.
                NetworkClientMessages::Block(block, peer_id, false)
            }
            PeerMessage::BlockHeaderAnnounce(header) => {
                NetworkClientMessages::BlockHeader(header, peer_id)
            }
            PeerMessage::Transaction(transaction) => {
                NetworkClientMessages::Transaction(transaction)
            }
            PeerMessage::BlockApproval(account_id, hash, signature) => {
                NetworkClientMessages::BlockApproval(account_id, hash, signature)
            }
            PeerMessage::BlockRequest(hash) => NetworkClientMessages::BlockRequest(hash),
            PeerMessage::BlockHeadersRequest(hashes) => {
                NetworkClientMessages::BlockHeadersRequest(hashes)
            }
            PeerMessage::BlockHeaders(headers) => {
                NetworkClientMessages::BlockHeaders(headers, peer_id)
            }
            _ => unreachable!(),
        };
        self.client_addr
            .send(network_client_msg)
            .into_actor(self)
            .then(|res, act, ctx| {
                // Ban peer if client thinks received data is bad.
                match res {
                    Ok(NetworkClientResponses::InvalidTx(err)) => {
                        warn!(target: "network", "Received invalid tx from peer {}: {}", act.peer_info, err);
                        // TODO: count as malicious behaviour?
                    }
                    Ok(NetworkClientResponses::Ban { ban_reason }) => {
                        act.peer_status = PeerStatus::Banned(ban_reason);
                        ctx.stop();
                    }
                    Ok(NetworkClientResponses::Block(block)) => {
                        act.send_message(PeerMessage::Block(block))
                    }
                    Ok(NetworkClientResponses::BlockHeaders(headers)) => {
                        act.send_message(PeerMessage::BlockHeaders(headers))
                    }
                    Err(err) => {
                        error!(
                            target: "network",
                            "Received error sending message to client: {} for {}",
                            err, act.peer_info
                        );
                        return actix::fut::err(());
                    }
                    _ => {}
                };
                actix::fut::ok(())
            })
            .spawn(ctx);
    }
}

impl Actor for Peer {
    type Context = Context<Peer>;

    fn started(&mut self, ctx: &mut Self::Context) {
        debug!(target: "network", "Peer {:?} {:?} started", self.peer_addr, self.peer_type);
        // Set Handshake timeout for stopping actor if peer is not ready after given period of time.
        ctx.run_later(self.handshake_timeout, move |act, ctx| {
            if act.peer_status != PeerStatus::Ready {
                info!(target: "network", "Handshake timeout expired for {}", act.peer_info);
                ctx.stop();
            }
        });

        // If outbound peer, initiate handshake.
        if self.peer_type == PeerType::Outbound {
            self.send_handshake(ctx);
        }
    }

    fn stopping(&mut self, _: &mut Self::Context) -> Running {
        debug!(target: "network", "Peer {} disconnected.", self.peer_info);
        if let Some(peer_info) = self.peer_info.as_ref() {
            if self.peer_status == PeerStatus::Ready {
                self.peer_manager_addr.do_send(Unregister { peer_id: peer_info.id })
            } else if let PeerStatus::Banned(ban_reason) = self.peer_status {
                self.peer_manager_addr.do_send(Ban { peer_id: peer_info.id, ban_reason });
            }
        }
        Running::Stop
    }
}

impl WriteHandler<io::Error> for Peer {}

impl StreamHandler<PeerMessage, io::Error> for Peer {
    fn handle(&mut self, msg: PeerMessage, ctx: &mut Self::Context) {
        match (self.peer_type, self.peer_status, msg) {
            (_, PeerStatus::Connecting, PeerMessage::Handshake(handshake)) => {
                debug!(target: "network", "{:?} received handshake {:?}", self.node_info.id, handshake);
                if handshake.peer_id == self.node_info.id {
                    warn!(target: "network", "Received info about itself. Disconnecting this peer.");
                    ctx.stop();
                }
                let peer_info = PeerInfo {
                    id: handshake.peer_id,
                    addr: handshake
                        .listen_port
                        .map(|port| SocketAddr::new(self.peer_addr.ip(), port)),
                    account_id: handshake.account_id.clone(),
                };
                self.peer_manager_addr
                    .send(Consolidate {
                        actor: ctx.address(),
                        peer_info: peer_info.clone(),
                        peer_type: self.peer_type,
                        chain_info: handshake.chain_info,
                    })
                    .into_actor(self)
                    .then(move |res, act, ctx| {
                        match res {
                            Ok(true) => {
                                debug!(target: "network", "Peer {:?} successfully consolidated", act.peer_addr);
                                act.peer_info = Some(peer_info).into();
                                act.peer_status = PeerStatus::Ready;
                                // Respond to handshake if it's inbound and connection was consolidated.
                                if act.peer_type == PeerType::Inbound {
                                    act.send_handshake(ctx);
                                }
                                actix::fut::ok(())
                            },
                            _ => {
                                info!(target: "network", "Peer with handshake {:?} wasn't consolidated, disconnecting.", handshake);
                                ctx.stop();
                                actix::fut::err(())
                            }
                        }
                    })
                    .wait(ctx);
            }
            (_, PeerStatus::Ready, PeerMessage::PeersRequest) => {
                self.peer_manager_addr.send(PeersRequest {}).into_actor(self).then(|res, act, _ctx| {
                    if let Ok(peers) = res {
                        debug!(target: "network", "Peers request from {}: sending {} peers.", act.peer_info, peers.peers.len());
                        act.send_message(PeerMessage::PeersResponse(peers.peers));
                    }
                    actix::fut::ok(())
                }).spawn(ctx);
            }
            (_, PeerStatus::Ready, PeerMessage::PeersResponse(peers)) => {
                debug!(target: "network", "Received peers from {}: {} peers.", self.peer_info, peers.len());
                self.peer_manager_addr.do_send(PeersResponse { peers });
            }
            (_, PeerStatus::Ready, msg) => {
                self.receive_client_message(ctx, msg);
            }
            (_, _, msg) => {
                warn!(target: "network", "Received {} while {:?} from {:?} connection.", msg, self.peer_status, self.peer_type);
            }
        }
    }
}

impl Handler<SendMessage> for Peer {
    type Result = ();

    fn handle(&mut self, msg: SendMessage, _: &mut Self::Context) {
        self.send_message(msg.message);
    }
}

'''
'''--- chain/network/src/peer_manager.rs ---
use std::cmp;
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::Duration;

use actix::actors::resolver::{ConnectAddr, Resolver};
use actix::io::FramedWrite;
use actix::prelude::Stream;
use actix::{
    Actor, ActorFuture, Addr, AsyncContext, Context, ContextFutureSpawner, Handler, Recipient,
    StreamHandler, SystemService, WrapFuture,
};
use chrono::Utc;
use futures::future;
use log::{debug, error, info, warn};
use rand::{thread_rng, Rng};
use tokio::codec::FramedRead;
use tokio::io::AsyncRead;
use tokio::net::{TcpListener, TcpStream};

use near_primitives::types::AccountId;
use near_store::Store;

use crate::codec::Codec;
use crate::peer::Peer;
use crate::peer_store::PeerStore;
use crate::types::{
    Ban, Consolidate, FullPeerInfo, InboundTcpConnect, KnownPeerStatus, OutboundTcpConnect, PeerId,
    PeerList, PeerMessage, PeerType, PeersRequest, PeersResponse, ReasonForBan, SendMessage,
    Unregister,
};
use crate::types::{
    NetworkClientMessages, NetworkConfig, NetworkRequests, NetworkResponses, PeerInfo,
};

macro_rules! unwrap_or_error(($obj: expr, $error: expr) => (match $obj {
    Ok(result) => result,
    Err(err) => {
        error!(target: "network", "{}: {}", $error, err);
        return;
    }
}));

/// Actor that manages peers connections.
pub struct PeerManagerActor {
    /// Networking configuration.
    config: NetworkConfig,
    /// Peer information for this node.
    peer_id: PeerId,
    /// Address of the client actor.
    client_addr: Recipient<NetworkClientMessages>,
    /// Peer store that provides read/write access to peers.
    peer_store: PeerStore,
    /// Set of outbound connections that were not consolidated yet.
    outgoing_peers: HashSet<PeerId>,
    /// Active peers (inbound and outbound) with their full peer information.
    active_peers: HashMap<PeerId, (Addr<Peer>, FullPeerInfo)>,
    /// Peers with known account ids.
    account_peers: HashMap<AccountId, PeerId>,
    /// Monitor peers attempts, used for fast checking in the beginning with exponential backoff.
    monitor_peers_attempts: u64,
}

impl PeerManagerActor {
    pub fn new(
        store: Arc<Store>,
        config: NetworkConfig,
        client_addr: Recipient<NetworkClientMessages>,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let peer_store = PeerStore::new(store, &config.boot_nodes)?;
        debug!(target: "network", "Found known peers: {} (boot nodes={})", peer_store.len(), config.boot_nodes.len());
        Ok(PeerManagerActor {
            peer_id: config.public_key.into(),
            config,
            client_addr,
            peer_store,
            active_peers: HashMap::default(),
            outgoing_peers: HashSet::default(),
            account_peers: HashMap::default(),
            monitor_peers_attempts: 0,
        })
    }

    fn num_active_peers(&self) -> usize {
        self.active_peers.len()
    }

    fn register_peer(&mut self, peer_info: FullPeerInfo, addr: Addr<Peer>) {
        if self.outgoing_peers.contains(&peer_info.peer_info.id) {
            self.outgoing_peers.remove(&peer_info.peer_info.id);
        }
        unwrap_or_error!(self.peer_store.peer_connected(&peer_info), "Failed to save peer data");
        if let Some(account_id) = &peer_info.peer_info.account_id {
            self.account_peers.insert(account_id.clone(), peer_info.peer_info.id);
        }
        self.active_peers.insert(peer_info.peer_info.id, (addr, peer_info));
    }

    fn unregister_peer(&mut self, peer_id: PeerId) {
        // If this is an unconsolidated peer because failed / connected inbound, just delete it.
        if self.outgoing_peers.contains(&peer_id) {
            self.outgoing_peers.remove(&peer_id);
            return;
        }
        if let Some((_, peer_info)) = self.active_peers.get(&peer_id) {
            if let Some(account_id) = &peer_info.peer_info.account_id {
                self.account_peers.remove(account_id);
            }
            self.active_peers.remove(&peer_id);
        }
        unwrap_or_error!(self.peer_store.peer_disconnected(&peer_id), "Failed to save peer data");
    }

    fn ban_peer(&mut self, peer_id: &PeerId, ban_reason: ReasonForBan) {
        info!(target: "network", "Banning peer {:?}", peer_id);
        self.active_peers.remove(&peer_id);
        unwrap_or_error!(self.peer_store.peer_ban(peer_id, ban_reason), "Failed to save peer data");
    }

    /// Connects peer with given TcpStream and optional information if it's outbound.
    fn connect_peer(
        &mut self,
        recipient: Addr<Self>,
        stream: TcpStream,
        peer_type: PeerType,
        peer_info: Option<PeerInfo>,
    ) {
        let peer_id = self.peer_id;
        let account_id = self.config.account_id.clone();
        let server_addr = self.config.addr;
        let handshake_timeout = self.config.handshake_timeout;
        let client_addr = self.client_addr.clone();
        Peer::create(move |ctx| {
            let server_addr = server_addr.unwrap_or_else(|| stream.local_addr().unwrap());
            let remote_addr = stream.peer_addr().unwrap();
            let (read, write) = stream.split();

            // TODO: check if peer is banned or known based on IP address and port.

            Peer::add_stream(FramedRead::new(read, Codec::new()), ctx);
            Peer::new(
                PeerInfo { id: peer_id, addr: Some(server_addr), account_id },
                remote_addr,
                peer_info,
                peer_type,
                FramedWrite::new(write, Codec::new(), ctx),
                handshake_timeout,
                recipient,
                client_addr,
            )
        });
    }

    fn is_outbound_bootstrap_needed(&self) -> bool {
        (self.active_peers.len() + self.outgoing_peers.len())
            < (self.config.peer_max_count as usize)
    }

    /// Returns single random peer with the most weight.
    fn most_weight_peers(&self) -> Vec<FullPeerInfo> {
        let max_weight =
            match self.active_peers.values().map(|(_, x)| x.chain_info.total_weight).max() {
                Some(w) => w,
                None => return vec![],
            };
        self.active_peers
            .values()
            .filter_map(|(_, x)| {
                if x.chain_info.total_weight == max_weight {
                    Some(x.clone())
                } else {
                    None
                }
            })
            .collect::<Vec<_>>()
    }

    /// Get a random peer we are not connected to from the known list.
    fn sample_random_peer(&self) -> Option<PeerInfo> {
        let unconnected_peers = self.peer_store.unconnected_peers();
        let index = thread_rng().gen_range(0, std::cmp::max(unconnected_peers.len(), 1));

        unconnected_peers
            .iter()
            .enumerate()
            .filter_map(|(i, v)| if i == index { Some(v.clone()) } else { None })
            .next()
    }

    /// Periodically monitor list of peers and:
    ///  - request new peers from connected peers,
    ///  - bootstrap outbound connections from known peers,
    ///  - unban peers that have been banned for awhile,
    ///  - remove expired peers,
    fn monitor_peers(&mut self, ctx: &mut Context<Self>) {
        let mut to_unban = vec![];
        for (peer_id, peer_state) in self.peer_store.iter() {
            match peer_state.status {
                KnownPeerStatus::Banned(_, last_banned) => {
                    let interval = unwrap_or_error!(
                        (Utc::now() - last_banned).to_std(),
                        "Failed to convert time"
                    );
                    if interval > self.config.ban_window {
                        info!(target: "network", "Monitor peers: unbanned {} after {:?}.", peer_id, interval);
                        to_unban.push(peer_id.clone());
                    }
                }
                _ => {}
            }
        }
        for peer_id in to_unban {
            unwrap_or_error!(self.peer_store.peer_unban(&peer_id), "Failed to unban a peer");
        }

        if self.is_outbound_bootstrap_needed() {
            if let Some(peer_info) = self.sample_random_peer() {
                ctx.notify(OutboundTcpConnect { peer_info });
            } else {
                // Query current peers for more peers.
                self.broadcast_message(ctx, SendMessage { message: PeerMessage::PeersRequest });
            }
        }

        unwrap_or_error!(
            self.peer_store.remove_expired(&self.config),
            "Failed to remove expired peers"
        );

        // Reschedule the bootstrap peer task, starting of as quick as possible with exponential backoff.
        let wait = Duration::from_millis(cmp::min(
            self.config.bootstrap_peers_period.as_millis() as u64,
            10 << self.monitor_peers_attempts,
        ));
        self.monitor_peers_attempts = cmp::min(13, self.monitor_peers_attempts + 1);
        ctx.run_later(wait, move |act, ctx| {
            act.monitor_peers(ctx);
        });
    }

    /// Broadcast message to all active peers.
    fn broadcast_message(&self, ctx: &mut Context<Self>, msg: SendMessage) {
        let requests: Vec<_> =
            self.active_peers.values().map(|peer| peer.0.send(msg.clone())).collect();
        future::join_all(requests)
            .into_actor(self)
            .map_err(|e, _, _| error!("Failed sending broadcast message: {}", e))
            .and_then(|_, _, _| actix::fut::ok(()))
            .spawn(ctx);
    }

    /// Send message to specific account.
    /// TODO: currently sends in direct message, need to support indirect routing.
    fn send_message_to_account(
        &self,
        ctx: &mut Context<Self>,
        account_id: AccountId,
        msg: SendMessage,
    ) {
        if let Some(peer_id) = self.account_peers.get(&account_id) {
            if let Some((addr, _)) = self.active_peers.get(peer_id) {
                addr.send(msg)
                    .into_actor(self)
                    .map_err(|e, _, _| error!("Failed sending message: {}", e))
                    .and_then(|_, _, _| actix::fut::ok(()))
                    .spawn(ctx);
            } else {
                error!(target: "network", "Missing peer {:?} that is related to account {}", peer_id, account_id);
            }
        } else {
            warn!(target: "network", "Unknown account {} in peers, not supported indirect routing", account_id);
        }
    }
}

impl Actor for PeerManagerActor {
    type Context = Context<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        // Start server if address provided.
        if let Some(server_addr) = self.config.addr {
            // TODO: for now crashes if server didn't start.
            let listener = TcpListener::bind(&server_addr).unwrap();
            info!(target: "network", "Server listening at {}@{}", self.peer_id, server_addr);
            ctx.add_message_stream(listener.incoming().map_err(|_| ()).map(InboundTcpConnect::new));
        }

        // Start peer monitoring.
        self.monitor_peers(ctx);
    }
}

impl Handler<NetworkRequests> for PeerManagerActor {
    type Result = NetworkResponses;

    fn handle(&mut self, msg: NetworkRequests, ctx: &mut Context<Self>) -> Self::Result {
        match msg {
            NetworkRequests::FetchInfo => NetworkResponses::Info {
                num_active_peers: self.num_active_peers(),
                peer_max_count: self.config.peer_max_count,
                most_weight_peers: self.most_weight_peers(),
            },
            NetworkRequests::Block { block } => {
                self.broadcast_message(ctx, SendMessage { message: PeerMessage::Block(block) });
                NetworkResponses::NoResponse
            }
            NetworkRequests::BlockHeaderAnnounce { header, approval } => {
                if let Some(approval) = approval {
                    if let Some(account_id) = &self.config.account_id {
                        self.send_message_to_account(
                            ctx,
                            approval.target,
                            SendMessage {
                                message: PeerMessage::BlockApproval(
                                    account_id.clone(),
                                    approval.hash,
                                    approval.signature,
                                ),
                            },
                        );
                    }
                }
                self.broadcast_message(
                    ctx,
                    SendMessage { message: PeerMessage::BlockHeaderAnnounce(header) },
                );
                NetworkResponses::NoResponse
            }
            NetworkRequests::BlockRequest { hash, peer_id } => {
                if let Some((addr, _)) = self.active_peers.get(&peer_id) {
                    addr.do_send(SendMessage { message: PeerMessage::BlockRequest(hash) });
                }
                NetworkResponses::NoResponse
            }
            NetworkRequests::BlockHeadersRequest { hashes, peer_id } => {
                if let Some((addr, _)) = self.active_peers.get(&peer_id) {
                    addr.do_send(SendMessage { message: PeerMessage::BlockHeadersRequest(hashes) });
                }
                NetworkResponses::NoResponse
            }
            NetworkRequests::StateRequest { shard_id: _, state_root: _ } => {
                // TODO: implement state sync.
                NetworkResponses::NoResponse
            }
            NetworkRequests::BanPeer { peer_id, ban_reason } => {
                if let Some((_addr, _full_info)) = self.active_peers.get(&peer_id) {
                    // TODO: send stop signal to the addr.
                }
                self.ban_peer(&peer_id, ban_reason);
                NetworkResponses::NoResponse
            }
        }
    }
}

impl Handler<InboundTcpConnect> for PeerManagerActor {
    type Result = ();

    fn handle(&mut self, msg: InboundTcpConnect, ctx: &mut Self::Context) {
        self.connect_peer(ctx.address(), msg.stream, PeerType::Inbound, None);
    }
}

impl Handler<OutboundTcpConnect> for PeerManagerActor {
    type Result = ();

    fn handle(&mut self, msg: OutboundTcpConnect, ctx: &mut Self::Context) {
        if let Some(addr) = msg.peer_info.addr {
            Resolver::from_registry()
                .send(ConnectAddr(addr))
                .into_actor(self)
                .then(move |res, act, ctx| match res {
                    Ok(res) => match res {
                        Ok(stream) => {
                            debug!(target: "network", "Connected to {}", msg.peer_info);
                            act.outgoing_peers.insert(msg.peer_info.id);
                            act.connect_peer(
                                ctx.address(),
                                stream,
                                PeerType::Outbound,
                                Some(msg.peer_info),
                            );
                            actix::fut::ok(())
                        }
                        Err(err) => {
                            error!(target: "network", "Error connecting to {}: {}", addr, err);
                            actix::fut::err(())
                        }
                    },
                    Err(err) => {
                        error!(target: "network", "Error connecting to {}: {}", addr, err);
                        actix::fut::err(())
                    }
                })
                .wait(ctx);
        } else {
            warn!(target: "network", "Trying to connect to peer with no public address: {:?}", msg.peer_info);
        }
    }
}

impl Handler<Consolidate> for PeerManagerActor {
    type Result = bool;

    fn handle(&mut self, msg: Consolidate, _ctx: &mut Self::Context) -> Self::Result {
        // We already connected to this peer.
        if self.active_peers.contains_key(&msg.peer_info.id) {
            return false;
        }
        // This is incoming connection but we have this peer already in outgoing.
        // This only happens when both of us connect at the same time, break tie using higher peer id.
        if msg.peer_type == PeerType::Inbound && self.outgoing_peers.contains(&msg.peer_info.id) {
            // We pick connection that has lower id.
            if msg.peer_info.id > self.peer_id {
                return false;
            }
        }
        // TODO: double check that address is connectable and add account id.
        self.register_peer(
            FullPeerInfo { peer_info: msg.peer_info, chain_info: msg.chain_info },
            msg.actor,
        );
        true
    }
}

impl Handler<Unregister> for PeerManagerActor {
    type Result = ();

    fn handle(&mut self, msg: Unregister, _ctx: &mut Self::Context) {
        self.unregister_peer(msg.peer_id);
    }
}

impl Handler<Ban> for PeerManagerActor {
    type Result = ();

    fn handle(&mut self, msg: Ban, _ctx: &mut Self::Context) {
        self.ban_peer(&msg.peer_id, msg.ban_reason);
    }
}

impl Handler<PeersRequest> for PeerManagerActor {
    type Result = PeerList;

    fn handle(&mut self, _msg: PeersRequest, _ctx: &mut Self::Context) -> Self::Result {
        PeerList { peers: self.peer_store.healthy_peers(self.config.max_send_peers) }
    }
}

impl Handler<PeersResponse> for PeerManagerActor {
    type Result = ();

    fn handle(&mut self, mut msg: PeersResponse, _ctx: &mut Self::Context) {
        self.peer_store.add_peers(
            msg.peers.drain(..).filter(|peer_info| peer_info.id != self.peer_id).collect(),
        );
    }
}

'''
'''--- chain/network/src/peer_store.rs ---
use std::collections::{hash_map::Iter, HashMap};
use std::convert::TryInto;
use std::sync::Arc;

use chrono::Utc;
use log::debug;
use rand::seq::SliceRandom;
use rand::thread_rng;

use near_store::{Store, COL_PEERS};

use crate::types::{
    FullPeerInfo, KnownPeerState, KnownPeerStatus, NetworkConfig, PeerId, PeerInfo, ReasonForBan,
};

/// Known peers store, maintaining cache of known peers and connection to storage to save/load them.
pub struct PeerStore {
    store: Arc<Store>,
    peer_states: HashMap<PeerId, KnownPeerState>,
}

impl PeerStore {
    pub fn new(
        store: Arc<Store>,
        boot_nodes: &[PeerInfo],
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let mut peer_states = HashMap::default();
        for (key, value) in store.iter(COL_PEERS) {
            let key: Vec<u8> = key.into();
            let value: Vec<u8> = value.into();
            let peer_id: PeerId = key.try_into()?;
            let mut peer_state: KnownPeerState = value.try_into()?;
            peer_state.status = KnownPeerStatus::NotConnected;
            peer_states.insert(peer_id, peer_state);
        }
        for peer_info in boot_nodes.iter() {
            if !peer_states.contains_key(&peer_info.id) {
                peer_states.insert(peer_info.id, KnownPeerState::new(peer_info.clone()));
            }
        }
        Ok(PeerStore { store, peer_states })
    }

    pub fn len(&self) -> usize {
        self.peer_states.len()
    }

    pub fn peer_connected(
        &mut self,
        peer_info: &FullPeerInfo,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let entry = self
            .peer_states
            .entry(peer_info.peer_info.id)
            .or_insert(KnownPeerState::new(peer_info.peer_info.clone()));
        entry.last_seen = Utc::now();
        entry.status = KnownPeerStatus::Connected;
        let mut store_update = self.store.store_update();
        store_update.set_ser(COL_PEERS, peer_info.peer_info.id.as_ref(), entry)?;
        store_update.commit().map_err(|err| err.into())
    }

    pub fn peer_disconnected(
        &mut self,
        peer_id: &PeerId,
    ) -> Result<(), Box<dyn std::error::Error>> {
        if let Some(peer_state) = self.peer_states.get_mut(peer_id) {
            peer_state.last_seen = Utc::now();
            peer_state.status = KnownPeerStatus::NotConnected;
            let mut store_update = self.store.store_update();
            store_update.set_ser(COL_PEERS, peer_id.as_ref(), peer_state)?;
            store_update.commit().map_err(|err| err.into())
        } else {
            Err(format!("Peer {} is missing in the peer store", peer_id).into())
        }
    }

    pub fn peer_ban(
        &mut self,
        peer_id: &PeerId,
        ban_reason: ReasonForBan,
    ) -> Result<(), Box<dyn std::error::Error>> {
        if let Some(peer_state) = self.peer_states.get_mut(peer_id) {
            peer_state.last_seen = Utc::now();
            peer_state.status = KnownPeerStatus::Banned(ban_reason, Utc::now());
            let mut store_update = self.store.store_update();
            store_update.set_ser(COL_PEERS, peer_id.as_ref(), peer_state)?;
            store_update.commit().map_err(|err| err.into())
        } else {
            Err(format!("Peer {} is missing in the peer store", peer_id).into())
        }
    }

    pub fn peer_unban(&mut self, peer_id: &PeerId) -> Result<(), Box<dyn std::error::Error>> {
        if let Some(peer_state) = self.peer_states.get_mut(peer_id) {
            peer_state.status = KnownPeerStatus::NotConnected;
            let mut store_update = self.store.store_update();
            store_update.set_ser(COL_PEERS, peer_id.as_ref(), peer_state)?;
            store_update.commit().map_err(|err| err.into())
        } else {
            Err(format!("Peer {} is missing in the peer store", peer_id).into())
        }
    }

    fn find_peers<F>(&self, mut filter: F, count: u32) -> Vec<PeerInfo>
    where
        F: FnMut(&KnownPeerState) -> bool,
    {
        let mut peers = self
            .peer_states
            .values()
            .filter_map(|p| if filter(p) { Some(p.peer_info.clone()) } else { None })
            .collect::<Vec<_>>();
        if count == 0 {
            return peers;
        }
        peers.shuffle(&mut thread_rng());
        peers.iter().take(count as usize).cloned().collect::<Vec<_>>()
    }

    /// Return unconnected or peers with unknown status that we can try to connect to.
    pub fn unconnected_peers(&self) -> Vec<PeerInfo> {
        self.find_peers(
            |p| p.status == KnownPeerStatus::NotConnected || p.status == KnownPeerStatus::Unknown,
            0,
        )
    }

    /// Return healthy known peers up to given amount.
    pub fn healthy_peers(&self, max_count: u32) -> Vec<PeerInfo> {
        // TODO: better healthy peer definition here.
        self.find_peers(
            |p| match p.status {
                KnownPeerStatus::Banned(_, _) => false,
                _ => true,
            },
            max_count,
        )
    }

    /// Return iterator over all known peers.
    pub fn iter(&self) -> Iter<PeerId, KnownPeerState> {
        self.peer_states.iter()
    }

    /// Removes peers that are not responding for expiration period.
    pub fn remove_expired(
        &mut self,
        config: &NetworkConfig,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let now = Utc::now();
        let mut to_remove = vec![];
        for (peer_id, peer_status) in self.peer_states.iter() {
            let diff = (now - peer_status.last_seen).to_std()?;
            if peer_status.status != KnownPeerStatus::Connected
                && diff > config.peer_expiration_duration
            {
                debug!(target: "network", "Removing peer: last seen {:?}", diff);
                to_remove.push(peer_id.clone());
            }
        }
        let mut store_update = self.store.store_update();
        for peer_id in to_remove {
            self.peer_states.remove(&peer_id);
            store_update.delete(COL_PEERS, peer_id.as_ref());
        }
        store_update.commit().map_err(|err| err.into())
    }

    pub fn add_peers(&mut self, mut peers: Vec<PeerInfo>) {
        for peer_info in peers.drain(..) {
            if !self.peer_states.contains_key(&peer_info.id) {
                self.peer_states.insert(peer_info.id, KnownPeerState::new(peer_info));
            }
        }
    }
}

'''
'''--- chain/network/src/test_utils.rs ---
use std::net::TcpListener;
use std::time::{Duration, Instant};

use actix::{Actor, AsyncContext, Context, System};
use futures::future::Future;
use tokio::timer::Delay;

use near_primitives::crypto::signature::get_key_pair;
use near_primitives::test_utils::get_key_pair_from_seed;

use crate::types::{NetworkConfig, PeerInfo};
use futures::future;

/// Returns available port.
pub fn open_port() -> u16 {
    // use port 0 to allow the OS to assign an open port
    // TcpListener's Drop impl will unbind the port as soon as
    // listener goes out of scope
    let listener = TcpListener::bind("127.0.0.1:0").unwrap();
    listener.local_addr().unwrap().port()
}

impl NetworkConfig {
    /// Returns network config with given seed used for peer id.
    pub fn from_seed(seed: &str, port: u16) -> Self {
        let (public_key, secret_key) = get_key_pair_from_seed(seed);
        NetworkConfig {
            public_key,
            secret_key,
            account_id: Some(seed.to_string()),
            addr: Some(format!("0.0.0.0:{}", port).parse().unwrap()),
            boot_nodes: vec![],
            handshake_timeout: Duration::from_secs(60),
            reconnect_delay: Duration::from_secs(60),
            bootstrap_peers_period: Duration::from_millis(100),
            peer_max_count: 10,
            ban_window: Duration::from_secs(1),
            peer_expiration_duration: Duration::from_secs(60 * 60),
            max_send_peers: 512,
        }
    }
}

pub fn convert_boot_nodes(boot_nodes: Vec<(&str, u16)>) -> Vec<PeerInfo> {
    let mut result = vec![];
    for (peer_seed, port) in boot_nodes {
        let (id, _) = get_key_pair_from_seed(peer_seed);
        result.push(PeerInfo::new(id.into(), format!("127.0.0.1:{}", port).parse().unwrap()))
    }
    result
}

impl PeerInfo {
    /// Creates random peer info.
    pub fn random() -> Self {
        let (id, _) = get_key_pair();
        PeerInfo { id: id.into(), addr: None, account_id: None }
    }
}

/// Timeouts by stopping system without any condition and raises panic.
/// Useful in tests to prevent them from running forever.
#[allow(unreachable_code)]
pub fn wait_or_panic(max_wait_ms: u64) {
    actix::spawn(Delay::new(Instant::now() + Duration::from_millis(max_wait_ms)).then(|_| {
        System::current().stop();
        panic!("Timeout exceeded.");
        future::result(Ok(()))
    }));
}

/// Waits until condition or timeouts with panic.
/// Use in tests to check for a condition and stop or fail otherwise.
///
/// # Example
///
/// ```
/// use actix::{System, Actor};
/// use near_network::test_utils::WaitOrTimeout;
/// use std::time::{Instant, Duration};
///
/// System::run(|| {
///     let start = Instant::now();
///     WaitOrTimeout::new(Box::new(move |ctx| {
///             if start.elapsed() > Duration::from_millis(10) {
///                 System::current().stop()
///             }
///         }),
///         1000,
///         60000,
///     ).start();
/// }).unwrap();
/// ```
pub struct WaitOrTimeout {
    f: Box<dyn FnMut(&mut Context<WaitOrTimeout>)>,
    check_interval_ms: u64,
    max_wait_ms: u64,
    ms_slept: u64,
}

impl WaitOrTimeout {
    pub fn new(
        f: Box<dyn FnMut(&mut Context<WaitOrTimeout>)>,
        check_interval_ms: u64,
        max_wait_ms: u64,
    ) -> Self {
        WaitOrTimeout { f, check_interval_ms, max_wait_ms, ms_slept: 0 }
    }

    fn wait_or_timeout(&mut self, ctx: &mut Context<Self>) {
        (self.f)(ctx);
        ctx.run_later(Duration::from_millis(self.check_interval_ms), move |act, ctx| {
            act.ms_slept += act.check_interval_ms;
            if act.ms_slept > act.max_wait_ms {
                println!("BBBB Slept {}; max_wait_ms {}", act.ms_slept, act.max_wait_ms);
                panic!("Timed out waiting for the condition");
            }
            act.wait_or_timeout(ctx);
        });
    }
}

impl Actor for WaitOrTimeout {
    type Context = Context<Self>;

    fn started(&mut self, ctx: &mut Context<Self>) {
        self.wait_or_timeout(ctx);
    }
}

'''
'''--- chain/network/src/types.rs ---
use std::convert::From;
use std::convert::{Into, TryFrom, TryInto};
use std::fmt;
use std::hash::{Hash, Hasher};
use std::iter::FromIterator;
use std::net::SocketAddr;
use std::time::Duration;

use actix::dev::{MessageResponse, ResponseChannel};
use actix::{Actor, Addr, Message};
use chrono::{DateTime, Utc};
use protobuf::well_known_types::UInt32Value;
use protobuf::{RepeatedField, SingularPtrField};
use serde_derive::{Deserialize, Serialize};
use tokio::net::TcpStream;

use near_chain::{Block, BlockApproval, BlockHeader, Weight};
use near_primitives::crypto::signature::{PublicKey, SecretKey, Signature};
use near_primitives::hash::CryptoHash;
use near_primitives::logging::pretty_str;
use near_primitives::serialize::{BaseEncode, Decode};
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::{AccountId, BlockIndex, MerkleHash, ShardId};
use near_primitives::utils::{proto_to_type, to_string_value};
use near_protos::network as network_proto;

use crate::peer::Peer;

/// Current latest version of the protocol
pub const PROTOCOL_VERSION: u32 = 1;

/// Peer id is the public key.
#[derive(Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]
pub struct PeerId(PublicKey);

impl From<PeerId> for Vec<u8> {
    fn from(peer_id: PeerId) -> Vec<u8> {
        (&peer_id.0).into()
    }
}

impl From<PublicKey> for PeerId {
    fn from(public_key: PublicKey) -> PeerId {
        PeerId(public_key)
    }
}

impl TryFrom<Vec<u8>> for PeerId {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: Vec<u8>) -> Result<PeerId, Self::Error> {
        Ok(PeerId(bytes.try_into()?))
    }
}

impl std::convert::AsRef<[u8]> for PeerId {
    fn as_ref(&self) -> &[u8] {
        &(self.0).0[..]
    }
}

impl Hash for PeerId {
    fn hash<H: Hasher>(&self, state: &mut H) {
        state.write(self.0.as_ref());
    }
}

impl fmt::Display for PeerId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl fmt::Debug for PeerId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_str(&self.0.to_base(), 4))
    }
}

/// Peer information.
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub struct PeerInfo {
    pub id: PeerId,
    pub addr: Option<SocketAddr>,
    pub account_id: Option<AccountId>,
}

impl PeerInfo {
    pub fn addr_port(&self) -> Option<u16> {
        self.addr.map(|addr| addr.port())
    }
}

impl PeerInfo {
    pub fn new(id: PeerId, addr: SocketAddr) -> Self {
        PeerInfo { id, addr: Some(addr), account_id: None }
    }
}

impl fmt::Display for PeerInfo {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if let Some(acc) = self.account_id.as_ref() {
            write!(f, "({}, {:?}, {})", self.id, self.addr, acc)
        } else {
            write!(f, "({}, {:?})", self.id, self.addr)
        }
    }
}

impl TryFrom<&str> for PeerInfo {
    type Error = Box<dyn std::error::Error>;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let chunks: Vec<_> = s.split("@").collect();
        if chunks.len() != 2 {
            return Err(format!("Invalid peer info format, got {}, must be id@ip_addr", s).into());
        }
        Ok(PeerInfo {
            id: PublicKey::try_from(chunks[0])?.into(),
            addr: Some(
                chunks[1].parse().map_err(|err| {
                    format!("Invalid ip address format for {}: {}", chunks[1], err)
                })?,
            ),
            account_id: None,
        })
    }
}

impl TryFrom<network_proto::PeerInfo> for PeerInfo {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: network_proto::PeerInfo) -> Result<Self, Self::Error> {
        let addr = proto.addr.into_option().and_then(|s| s.value.parse::<SocketAddr>().ok());
        let account_id = proto.account_id.into_option().map(|s| s.value);
        Ok(PeerInfo { id: PublicKey::try_from(proto.id)?.into(), addr, account_id })
    }
}

impl From<PeerInfo> for network_proto::PeerInfo {
    fn from(peer_info: PeerInfo) -> network_proto::PeerInfo {
        let id = peer_info.id;
        let addr = SingularPtrField::from_option(
            peer_info.addr.map(|s| to_string_value(format!("{}", s))),
        );
        let account_id = SingularPtrField::from_option(peer_info.account_id.map(to_string_value));
        network_proto::PeerInfo { id: (&id.0).into(), addr, account_id, ..Default::default() }
    }
}

/// Peer chain information.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub struct PeerChainInfo {
    /// Last known chain height of the peer.
    pub height: BlockIndex,
    /// Last known chain weight of the peer.
    pub total_weight: Weight,
}

impl TryFrom<network_proto::PeerChainInfo> for PeerChainInfo {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: network_proto::PeerChainInfo) -> Result<Self, Self::Error> {
        Ok(PeerChainInfo { height: proto.height, total_weight: proto.total_weight.into() })
    }
}

impl From<PeerChainInfo> for network_proto::PeerChainInfo {
    fn from(chain_peer_info: PeerChainInfo) -> network_proto::PeerChainInfo {
        network_proto::PeerChainInfo {
            height: chain_peer_info.height,
            total_weight: chain_peer_info.total_weight.to_num(),
            ..Default::default()
        }
    }
}

/// Peer type.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub enum PeerType {
    /// Inbound session
    Inbound,
    /// Outbound session
    Outbound,
}

/// Peer status.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub enum PeerStatus {
    /// Waiting for handshake.
    Connecting,
    /// Ready to go.
    Ready,
    /// Banned, should shutdown this peer.
    Banned(ReasonForBan),
}

#[derive(PartialEq, Eq, Clone, Debug)]
pub struct Handshake {
    /// Protocol version.
    pub version: u32,
    /// Sender's peer id.
    pub peer_id: PeerId,
    /// Sender's account id, if present.
    pub account_id: Option<AccountId>,
    /// Sender's listening addr.
    pub listen_port: Option<u16>,
    /// Peer's chain information.
    pub chain_info: PeerChainInfo,
}

impl Handshake {
    pub fn new(
        peer_id: PeerId,
        account_id: Option<AccountId>,
        listen_port: Option<u16>,
        chain_info: PeerChainInfo,
    ) -> Self {
        Handshake { version: PROTOCOL_VERSION, peer_id, account_id, listen_port, chain_info }
    }
}

impl TryFrom<network_proto::Handshake> for Handshake {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: network_proto::Handshake) -> Result<Self, Self::Error> {
        let account_id = proto.account_id.into_option().map(|s| s.value);
        let listen_port = proto.listen_port.into_option().map(|v| v.value as u16);
        let peer_id: PublicKey = proto.peer_id.try_into().map_err(|e| format!("{}", e))?;
        let chain_info = proto_to_type(proto.chain_info)?;
        Ok(Handshake {
            version: proto.version,
            peer_id: peer_id.into(),
            account_id,
            listen_port,
            chain_info,
        })
    }
}

impl From<Handshake> for network_proto::Handshake {
    fn from(handshake: Handshake) -> network_proto::Handshake {
        let account_id = SingularPtrField::from_option(handshake.account_id.map(to_string_value));
        let listen_port = SingularPtrField::from_option(handshake.listen_port.map(|v| {
            let mut res = UInt32Value::new();
            res.set_value(u32::from(v));
            res
        }));
        network_proto::Handshake {
            version: handshake.version,
            peer_id: handshake.peer_id.into(),
            account_id,
            listen_port,
            chain_info: SingularPtrField::some(handshake.chain_info.into()),
            ..Default::default()
        }
    }
}

#[derive(PartialEq, Eq, Clone, Debug)]
pub enum PeerMessage {
    Handshake(Handshake),

    PeersRequest,
    PeersResponse(Vec<PeerInfo>),

    BlockHeadersRequest(Vec<CryptoHash>),
    BlockHeaders(Vec<BlockHeader>),
    BlockHeaderAnnounce(BlockHeader),

    BlockRequest(CryptoHash),
    Block(Block),
    BlockApproval(AccountId, CryptoHash, Signature),

    Transaction(SignedTransaction),
}

impl fmt::Display for PeerMessage {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            PeerMessage::Handshake(_) => f.write_str("Handshake"),
            PeerMessage::PeersRequest => f.write_str("PeersRequest"),
            PeerMessage::PeersResponse(_) => f.write_str("PeersResponse"),
            PeerMessage::BlockHeadersRequest(_) => f.write_str("BlockHeaderRequest"),
            PeerMessage::BlockHeaders(_) => f.write_str("BlockHeaders"),
            PeerMessage::BlockHeaderAnnounce(_) => f.write_str("BlockHeaderAnnounce"),
            PeerMessage::BlockRequest(_) => f.write_str("BlockRequest"),
            PeerMessage::Block(_) => f.write_str("Block"),
            PeerMessage::BlockApproval(_, _, _) => f.write_str("BlockApproval"),
            PeerMessage::Transaction(_) => f.write_str("Transaction"),
        }
    }
}

impl TryFrom<network_proto::PeerMessage> for PeerMessage {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: network_proto::PeerMessage) -> Result<Self, Self::Error> {
        match proto.message_type {
            Some(network_proto::PeerMessage_oneof_message_type::hand_shake(hand_shake)) => {
                hand_shake.try_into().map(PeerMessage::Handshake)
            }
            Some(network_proto::PeerMessage_oneof_message_type::peers_request(_)) => {
                Ok(PeerMessage::PeersRequest)
            }
            Some(network_proto::PeerMessage_oneof_message_type::peers_response(peers_response)) => {
                let peers_response = peers_response
                    .peers
                    .into_iter()
                    .map(TryInto::try_into)
                    .collect::<Result<Vec<_>, _>>()?;
                Ok(PeerMessage::PeersResponse(peers_response))
            }
            Some(network_proto::PeerMessage_oneof_message_type::block(block)) => {
                Ok(PeerMessage::Block(block.try_into()?))
            }
            Some(network_proto::PeerMessage_oneof_message_type::block_header_announce(header)) => {
                Ok(PeerMessage::BlockHeaderAnnounce(header.try_into()?))
            }
            Some(network_proto::PeerMessage_oneof_message_type::transaction(transaction)) => {
                Ok(PeerMessage::Transaction(transaction.try_into()?))
            }
            Some(network_proto::PeerMessage_oneof_message_type::block_approval(block_approval)) => {
                Ok(PeerMessage::BlockApproval(
                    block_approval.account_id,
                    block_approval.hash.try_into()?,
                    block_approval.signature.try_into()?,
                ))
            }
            Some(network_proto::PeerMessage_oneof_message_type::block_request(block_request)) => {
                Ok(PeerMessage::BlockRequest(block_request.try_into()?))
            }
            Some(network_proto::PeerMessage_oneof_message_type::block_headers_request(
                block_headers_request,
            )) => Ok(PeerMessage::BlockHeadersRequest(
                block_headers_request
                    .hashes
                    .into_iter()
                    .map(TryInto::try_into)
                    .collect::<Result<Vec<_>, _>>()?,
            )),
            Some(network_proto::PeerMessage_oneof_message_type::block_headers(block_headers)) => {
                Ok(PeerMessage::BlockHeaders(
                    block_headers
                        .headers
                        .into_iter()
                        .map(TryInto::try_into)
                        .collect::<Result<Vec<_>, _>>()?,
                ))
            }
            None => unreachable!(),
        }
    }
}

impl From<PeerMessage> for network_proto::PeerMessage {
    fn from(message: PeerMessage) -> network_proto::PeerMessage {
        let message_type = match message {
            PeerMessage::Handshake(hand_shake) => {
                Some(network_proto::PeerMessage_oneof_message_type::hand_shake(hand_shake.into()))
            }
            PeerMessage::PeersRequest => {
                Some(network_proto::PeerMessage_oneof_message_type::peers_request(true))
            }
            PeerMessage::PeersResponse(peers_response) => {
                let peers_response = network_proto::PeersResponse {
                    peers: RepeatedField::from_iter(
                        peers_response.into_iter().map(std::convert::Into::into),
                    ),
                    ..Default::default()
                };
                Some(network_proto::PeerMessage_oneof_message_type::peers_response(peers_response))
            }
            PeerMessage::Block(block) => {
                Some(network_proto::PeerMessage_oneof_message_type::block(block.into()))
            }
            PeerMessage::BlockHeaderAnnounce(header) => Some(
                network_proto::PeerMessage_oneof_message_type::block_header_announce(header.into()),
            ),
            PeerMessage::Transaction(transaction) => {
                Some(network_proto::PeerMessage_oneof_message_type::transaction(transaction.into()))
            }
            PeerMessage::BlockApproval(account_id, hash, signature) => {
                let block_approval = network_proto::BlockApproval {
                    account_id,
                    hash: hash.into(),
                    signature: signature.into(),
                    ..Default::default()
                };
                Some(network_proto::PeerMessage_oneof_message_type::block_approval(block_approval))
            }
            PeerMessage::BlockRequest(hash) => {
                Some(network_proto::PeerMessage_oneof_message_type::block_request(hash.into()))
            }
            PeerMessage::BlockHeadersRequest(hashes) => {
                let request = network_proto::BlockHeaderRequest {
                    hashes: RepeatedField::from_iter(
                        hashes.into_iter().map(std::convert::Into::into),
                    ),
                    ..Default::default()
                };
                Some(network_proto::PeerMessage_oneof_message_type::block_headers_request(request))
            }
            PeerMessage::BlockHeaders(headers) => {
                let block_headers = network_proto::BlockHeaders {
                    headers: RepeatedField::from_iter(
                        headers.into_iter().map(std::convert::Into::into),
                    ),
                    ..Default::default()
                };
                Some(network_proto::PeerMessage_oneof_message_type::block_headers(block_headers))
            }
        };
        network_proto::PeerMessage { message_type, ..Default::default() }
    }
}

/// Configuration for the peer-to-peer manager.
#[derive(Clone)]
pub struct NetworkConfig {
    pub public_key: PublicKey,
    pub secret_key: SecretKey,
    pub account_id: Option<AccountId>,
    pub addr: Option<SocketAddr>,
    pub boot_nodes: Vec<PeerInfo>,
    pub handshake_timeout: Duration,
    pub reconnect_delay: Duration,
    pub bootstrap_peers_period: Duration,
    pub peer_max_count: u32,
    /// Duration of the ban for misbehaving peers.
    pub ban_window: Duration,
    /// Remove expired peers.
    pub peer_expiration_duration: Duration,
    /// Maximum number of peer addresses we should ever send.
    pub max_send_peers: u32,
}

/// Status of the known peers.
#[derive(Serialize, Deserialize, Eq, PartialEq, Debug)]
pub enum KnownPeerStatus {
    Unknown,
    NotConnected,
    Connected,
    Banned(ReasonForBan, DateTime<Utc>),
}

/// Information node stores about known peers.
#[derive(Serialize, Deserialize, Debug)]
pub struct KnownPeerState {
    pub peer_info: PeerInfo,
    pub status: KnownPeerStatus,
    pub first_seen: DateTime<Utc>,
    pub last_seen: DateTime<Utc>,
}

impl KnownPeerState {
    pub fn new(peer_info: PeerInfo) -> Self {
        KnownPeerState {
            peer_info,
            status: KnownPeerStatus::Unknown,
            first_seen: Utc::now(),
            last_seen: Utc::now(),
        }
    }
}

impl TryFrom<Vec<u8>> for KnownPeerState {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: Vec<u8>) -> Result<KnownPeerState, Self::Error> {
        Decode::decode(&bytes).map_err(|err| err.into())
    }
}

/// Actor message that holds the TCP stream from an inbound TCP connection
#[derive(Message)]
pub struct InboundTcpConnect {
    /// Tcp stream of the inbound connections
    pub stream: TcpStream,
}

impl InboundTcpConnect {
    /// Method to create a new InboundTcpConnect message from a TCP stream
    pub fn new(stream: TcpStream) -> InboundTcpConnect {
        InboundTcpConnect { stream }
    }
}

/// Actor message to request the creation of an outbound TCP connection to a peer.
#[derive(Message)]
pub struct OutboundTcpConnect {
    /// Peer information of the outbound connection
    pub peer_info: PeerInfo,
}

#[derive(Message, Clone, Debug)]
pub struct SendMessage {
    pub message: PeerMessage,
}

/// Actor message to consolidate potential new peer.
/// Returns if connection should be kept or dropped.
pub struct Consolidate {
    pub actor: Addr<Peer>,
    pub peer_info: PeerInfo,
    pub peer_type: PeerType,
    pub chain_info: PeerChainInfo,
}

impl Message for Consolidate {
    type Result = bool;
}

/// Unregister message from Peer to PeerManager.
#[derive(Message)]
pub struct Unregister {
    pub peer_id: PeerId,
}

pub struct PeerList {
    pub peers: Vec<PeerInfo>,
}

/// Requesting peers from peer manager to communicate to a peer.
pub struct PeersRequest {}

impl Message for PeersRequest {
    type Result = PeerList;
}

/// Received new peers from another peer.
#[derive(Message)]
pub struct PeersResponse {
    pub peers: Vec<PeerInfo>,
}

impl<A, M> MessageResponse<A, M> for PeerList
where
    A: Actor,
    M: Message<Result = PeerList>,
{
    fn handle<R: ResponseChannel<M>>(self, _: &mut A::Context, tx: Option<R>) {
        if let Some(tx) = tx {
            tx.send(self)
        }
    }
}

/// Ban reason.
#[derive(Debug, Clone, PartialEq, Eq, Copy, Serialize, Deserialize)]
pub enum ReasonForBan {
    None = 0,
    BadBlock = 1,
    BadBlockHeader = 2,
    HeightFraud = 3,
    BadHandshake = 4,
    BadBlockApproval = 5,
}

#[derive(Message)]
pub struct Ban {
    pub peer_id: PeerId,
    pub ban_reason: ReasonForBan,
}

#[derive(Debug)]
pub enum NetworkRequests {
    FetchInfo,
    /// Sends block, either when block was just produced or when requested.
    Block {
        block: Block,
    },
    /// Sends block header announcement, with possibly attaching approval for this block if
    /// participating in this epoch.
    BlockHeaderAnnounce {
        header: BlockHeader,
        approval: Option<BlockApproval>,
    },
    /// Request block with given hash from given peer.
    BlockRequest {
        hash: CryptoHash,
        peer_id: PeerId,
    },
    /// Request given block headers.
    BlockHeadersRequest {
        hashes: Vec<CryptoHash>,
        peer_id: PeerId,
    },
    /// Request state for given shard at given state root.
    StateRequest {
        shard_id: ShardId,
        state_root: MerkleHash,
    },
    /// Ban given peer.
    BanPeer {
        peer_id: PeerId,
        ban_reason: ReasonForBan,
    },
}

/// Combines peer address info and chain information.
#[derive(Debug, Clone)]
pub struct FullPeerInfo {
    pub peer_info: PeerInfo,
    pub chain_info: PeerChainInfo,
}

pub enum NetworkResponses {
    NoResponse,
    Info { num_active_peers: usize, peer_max_count: u32, most_weight_peers: Vec<FullPeerInfo> },
}

impl<A, M> MessageResponse<A, M> for NetworkResponses
where
    A: Actor,
    M: Message<Result = NetworkResponses>,
{
    fn handle<R: ResponseChannel<M>>(self, _: &mut A::Context, tx: Option<R>) {
        if let Some(tx) = tx {
            tx.send(self)
        }
    }
}

impl Message for NetworkRequests {
    type Result = NetworkResponses;
}

#[derive(Debug)]
pub enum NetworkClientMessages {
    /// Received transaction.
    Transaction(SignedTransaction),
    /// Received block header.
    BlockHeader(BlockHeader, PeerId),
    /// Received block, possibly requested.
    Block(Block, PeerId, bool),
    /// Received list of headers for syncing.
    BlockHeaders(Vec<BlockHeader>, PeerId),
    /// Get Chain information from Client.
    GetChainInfo,
    /// Block approval.
    BlockApproval(AccountId, CryptoHash, Signature),
    /// Request headers.
    BlockHeadersRequest(Vec<CryptoHash>),
    /// Request a block.
    BlockRequest(CryptoHash),
}

pub enum NetworkClientResponses {
    /// No response.
    NoResponse,
    /// Valid transaction inserted into mempool as response to Transaction.
    ValidTx,
    /// Invalid transaction inserted into mempool as response to Transaction.
    InvalidTx(String),
    /// Ban peer for malicious behaviour.
    Ban { ban_reason: ReasonForBan },
    /// Chain information.
    ChainInfo { height: BlockIndex, total_weight: Weight },
    /// Block response.
    Block(Block),
    /// Headers response.
    BlockHeaders(Vec<BlockHeader>),
}

impl<A, M> MessageResponse<A, M> for NetworkClientResponses
where
    A: Actor,
    M: Message<Result = NetworkClientResponses>,
{
    fn handle<R: ResponseChannel<M>>(self, _: &mut A::Context, tx: Option<R>) {
        if let Some(tx) = tx {
            tx.send(self)
        }
    }
}

impl Message for NetworkClientMessages {
    type Result = NetworkClientResponses;
}

'''
'''--- chain/network/tests/peer_handshake.rs ---
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;

use actix::actors::mocker::Mocker;
use actix::Actor;
use actix::System;
use futures::future;
use futures::future::Future;

use near_client::ClientActor;
use near_network::test_utils::{convert_boot_nodes, open_port, WaitOrTimeout};
use near_network::{
    NetworkClientMessages, NetworkClientResponses, NetworkConfig, NetworkRequests,
    NetworkResponses, PeerManagerActor,
};
use near_primitives::test_utils::init_test_logger;
use near_store::test_utils::create_test_store;

type ClientMock = Mocker<ClientActor>;

fn make_peer_manager(seed: &str, port: u16, boot_nodes: Vec<(&str, u16)>) -> PeerManagerActor {
    let store = create_test_store();
    let mut config = NetworkConfig::from_seed(seed, port);
    config.boot_nodes = convert_boot_nodes(boot_nodes);
    let client_addr = ClientMock::mock(Box::new(move |msg, _ctx| {
        let msg = msg.downcast_ref::<NetworkClientMessages>().unwrap();
        match msg {
            NetworkClientMessages::GetChainInfo => {
                Box::new(Some(NetworkClientResponses::ChainInfo {
                    height: 1,
                    total_weight: 1.into(),
                }))
            }
            _ => Box::new(Some(NetworkClientResponses::NoResponse)),
        }
    }))
    .start();
    PeerManagerActor::new(store, config, client_addr.recipient()).unwrap()
}

#[test]
fn peer_handshake() {
    init_test_logger();

    System::run(|| {
        let (port1, port2) = (open_port(), open_port());
        let pm1 = make_peer_manager("test1", port1, vec![("test2", port2)]).start();
        let _pm2 = make_peer_manager("test2", port2, vec![("test1", port1)]).start();
        WaitOrTimeout::new(
            Box::new(move |_| {
                actix::spawn(pm1.send(NetworkRequests::FetchInfo).then(move |res| {
                    if let NetworkResponses::Info { num_active_peers, .. } = res.unwrap() {
                        if num_active_peers == 1 {
                            System::current().stop();
                        }
                    }
                    future::result(Ok(()))
                }));
            }),
            100,
            2000,
        )
        .start();
    })
    .unwrap();
}

#[test]
fn peers_connect_all() {
    init_test_logger();

    System::run(|| {
        let port = open_port();
        let _pm = make_peer_manager("test", port, vec![]).start();
        let mut peers = vec![];
        for i in 0..5 {
            peers.push(
                make_peer_manager(&format!("test{}", i), open_port(), vec![("test", port)]).start(),
            );
        }
        let flags = Arc::new(AtomicUsize::new(0));
        WaitOrTimeout::new(
            Box::new(move |_| {
                for i in 0..5 {
                    let flags1 = flags.clone();
                    actix::spawn(peers[i].send(NetworkRequests::FetchInfo).then(move |res| {
                        if let NetworkResponses::Info { num_active_peers, .. } = res.unwrap() {
                            if num_active_peers > 4 && (flags1.load(Ordering::Relaxed) >> i) % 2 == 0 {
                                println!("Peer {}: {}", i, num_active_peers);
                                flags1.fetch_add(1 << i, Ordering::Relaxed);
                            }
                        }
                        future::result(Ok(()))
                    }));
                }
                // Stop if all connected to all after exchanging peers.
                println!("Flags: {}", flags.load(Ordering::Relaxed));
                if flags.load(Ordering::Relaxed) == 0b11111 {
                    System::current().stop();
                }
            }),
            100,
            1000,
        )
        .start();
    })
    .unwrap()
}

'''
'''--- chain/pool/Cargo.toml ---
[package]
name = "near-pool"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
log = "0.4"
chrono = "0.4.4"
failure = "0.1"
failure_derive = "0.1"

near-primitives = { path = "../../core/primitives" }
near-chain = { path = "../chain" }

[dev-dependencies]
rand = "0.6"

'''
'''--- chain/pool/src/lib.rs ---
use std::collections::btree_map::BTreeMap;
use std::collections::HashMap;

use near_chain::{Block, ValidTransaction};
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::{AccountId, Nonce};

pub use crate::types::Error;

pub mod types;

/// Transaction pool: keeps track of transactions that were not yet accepted into the block chain.
pub struct TransactionPool {
    num_transactions: usize,
    /// Transactions grouped by account and ordered by nonce.
    pub transactions: HashMap<AccountId, BTreeMap<Nonce, SignedTransaction>>,
}

impl TransactionPool {
    pub fn new() -> Self {
        TransactionPool { num_transactions: 0, transactions: HashMap::default() }
    }

    /// Insert a valid transaction into the pool that passed validation.
    pub fn insert_transaction(&mut self, valid_transaction: ValidTransaction) {
        let account = valid_transaction.transaction.body.get_originator();
        let nonce = valid_transaction.transaction.body.get_nonce();
        self.num_transactions += 1;
        self.transactions
            .entry(account)
            .or_insert_with(BTreeMap::new)
            .insert(nonce, valid_transaction.transaction);
    }

    /// Take transactions from the pool, in the appropriate order to be put in a new block.
    /// Ensure that on average they will fit into expected weight.
    pub fn prepare_transactions(
        &mut self,
        expected_weight: u32,
    ) -> Result<Vec<SignedTransaction>, Error> {
        // TODO: pack transactions better.
        let result = self
            .transactions
            .values()
            .flat_map(BTreeMap::values)
            .take(expected_weight as usize)
            .cloned()
            .collect();
        Ok(result)
    }

    /// Quick reconciliation step - evict all transactions that already in the block
    /// or became invalid after it.
    pub fn reconcile_block(&mut self, block: &Block) {
        for transaction in block.transactions.iter() {
            let account = transaction.body.get_originator();
            let nonce = transaction.body.get_nonce();
            let mut remove_map = false;
            if let Some(map) = self.transactions.get_mut(&account) {
                map.remove(&nonce);
                remove_map = map.is_empty();
            }
            if remove_map {
                self.num_transactions -= 1;
                self.transactions.remove(&account);
            }
        }
    }

    pub fn len(&self) -> usize {
        self.num_transactions
    }
}

#[cfg(test)]
mod tests {
    use rand::seq::SliceRandom;
    use rand::thread_rng;

    use near_chain::ValidTransaction;
    use near_primitives::crypto::signer::InMemorySigner;
    use near_primitives::transaction::TransactionBody;

    use crate::TransactionPool;
    use near_primitives::types::Balance;

    /// Add transactions of nonce from 1..10 in random order. Check that mempool
    /// orders them correctly.
    #[test]
    fn test_order_nonce() {
        let signer = InMemorySigner::from_seed("alice.near", "alice.near");
        let mut transactions: Vec<_> = (1..10)
            .map(|i| TransactionBody::send_money(i, "alice.near", "bob.near", i as Balance).sign(&signer))
            .collect();
        let mut pool = TransactionPool::new();
        let mut rng = thread_rng();
        transactions.shuffle(&mut rng);
        for tx in transactions {
            pool.insert_transaction(ValidTransaction { transaction: tx });
        }
        let transactions = pool.prepare_transactions(10).unwrap();
        let nonces: Vec<u64> = transactions.iter().map(|tx| tx.body.get_nonce()).collect();
        assert_eq!(nonces, (1..10).collect::<Vec<u64>>())
    }

}

'''
'''--- chain/pool/src/types.rs ---
use failure::Fail;

use near_chain::ValidTransaction;

/// Possible errors whe interacting with transaction pool.
#[derive(Debug, Fail)]
pub enum Error {
    /// An invalid pool entry caused by underlying tx validation error
    #[fail(display = "Invalid Tx {}", _0)]
    InvalidTx(String),
    /// Other kinds of error (not yet pulled out into meaningful errors).
    #[fail(display = "General pool error {}", _0)]
    Other(String),
}

pub type ValidateTxCallback = fn(&[u8]) -> Result<ValidTransaction, Error>;

// Interface that the transaction pool requires from a blockchain implementation.
//pub trait ChainAdapter {
//    /// Verify transaction validity.
//    // TODO: possible return values: deserialized transaction, it's expected "weight", nonce and account id for grouping.
//    fn validate_tx(&self, tx: &[u8]) -> Result<ValidTransaction, Error>;
//}

'''
'''--- core/primitives/Cargo.toml ---
[package]
name = "near-primitives"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
regex = "1"
bincode = { version = "1.0", features = ["i128"] }
bs58 = { git = "https://github.com/ilblackdragon/bs58-rs", rev = "46a818c93cd2ba19c2d5d9aefa8e3062ffb98d9b" }
byteorder = "1.2"
exonum_sodiumoxide = "0.0.20"
futures = "0.1"
heapsize = "0.4"
lazy_static = "1.3"
serde = "1.0"
serde_derive = "1.0"
sha2 = "0.8.0"
serde_json = "1.0"
pairing = { git = "https://github.com/nearprotocol/pairing.git", rev = "f009a9f54c1c1149cea4ee3e6e58ed71d72bb2e9" }
rand = "0.6"
rand_xorshift = "0.1"
protobuf = "2.4"
env_logger = "0.6.0"
log = "0.4"
reed-solomon-erasure = "3.1.1"
jemallocator = "0.3.0"

near-protos = { path = "../protos" }

[dev-dependencies]
bencher = "0.1.5"
serde_json = "1.0"

[[bench]]
name = "bls"
harness = false

'''
'''--- core/primitives/benches/bls.rs ---
#[macro_use]
extern crate bencher;

use bencher::Bencher;

use near_primitives::crypto::aggregate_signature::{BlsAggregatePublicKey, BlsAggregateSignature, BlsSecretKey};

fn bls_sign(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";

    bench.iter(|| {
        key.sign(message.as_bytes());
    });
}

fn bls_verify(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let public = key.get_public_key();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());

    bench.iter(|| {
        public.verify(message.as_bytes(), &signature);
    });
}

fn bls_aggregate_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let mut agg_sig = BlsAggregateSignature::new();

    bench.iter(|| {
        agg_sig.aggregate(&signature);
    });
}

fn bls_aggregate_pubkey(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let public = key.get_public_key();
    let mut agg_key = BlsAggregatePublicKey::new();

    bench.iter(|| {
        agg_key.aggregate(&public);
    });
}

/// Aggregate signatures, but keep them in affine coordinates at each step
fn bls_aggregate_signature_slow(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let mut signature = key.sign(message.as_bytes());

    bench.iter(|| {
        let mut agg_sig = BlsAggregateSignature::new();
        agg_sig.aggregate(&signature);
        agg_sig.aggregate(&signature);
        signature = agg_sig.get_signature();
    });
}

/// Aggregate pubkeys, but keep them in affine coordinates at each step
fn bls_aggregate_pubkey_slow(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let mut public = key.get_public_key();

    bench.iter(|| {
        let mut agg_key = BlsAggregatePublicKey::new();
        agg_key.aggregate(&public);
        agg_key.aggregate(&public);
        public = agg_key.get_key();
    });
}

fn bls_decompress_pubkey(bench: &mut Bencher) {
    let public = BlsSecretKey::generate().get_public_key();
    let compressed = public.compress();

    bench.iter(|| {
        compressed.decompress().unwrap();
    });
}

fn bls_decompress_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let compressed = signature.compress();

    bench.iter(|| {
        compressed.decode().unwrap();
    });
}

fn bls_decompress_pubkey_unchecked(bench: &mut Bencher) {
    let public = BlsSecretKey::generate().get_public_key();
    let compressed = public.compress();

    bench.iter(|| {
        compressed.decompress_unchecked();
    });
}

fn bls_decode_uncompressed_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let encoded = signature.encode_uncompressed();

    bench.iter(|| {
        encoded.decode().ok();
    })
}

benchmark_group!(
    benches,
    bls_sign,
    bls_verify,
    bls_aggregate_signature,
    bls_aggregate_pubkey,
    bls_aggregate_signature_slow,
    bls_aggregate_pubkey_slow,
    bls_decompress_signature,
    bls_decompress_pubkey,
    bls_decompress_pubkey_unchecked,
    bls_decode_uncompressed_signature,
);
benchmark_main!(benches);

'''
'''--- core/primitives/src/account.rs ---
use std::convert::{TryFrom, TryInto};
use std::fmt;

use protobuf::well_known_types::BytesValue;
use protobuf::well_known_types::StringValue;
use protobuf::SingularPtrField;

use near_protos::access_key as access_key_proto;

use crate::crypto::signature::PublicKey;
use crate::hash::CryptoHash;
use crate::logging;
use crate::types::{AccountId, Balance, BlockIndex, Nonce, StorageUsage};

/// Per account information stored in the state.
#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
pub struct Account {
    pub public_keys: Vec<PublicKey>,
    pub nonce: Nonce,
    // amount + staked is the total value of the account
    pub amount: Balance,
    pub staked: Balance,
    pub code_hash: CryptoHash,
    /// Storage used by the given account.
    pub storage_usage: StorageUsage,
    /// Last block index at which the storage was paid for.
    pub storage_paid_at: BlockIndex,
}

impl Account {
    pub fn new(public_keys: Vec<PublicKey>, amount: Balance, code_hash: CryptoHash) -> Self {
        Account {
            public_keys,
            nonce: 0,
            amount,
            staked: 0,
            code_hash,
            storage_usage: 0,
            storage_paid_at: 0,
        }
    }

    /// Try debiting the balance by the given amount.
    pub fn checked_sub(&mut self, amount: Balance) -> Result<(), String> {
        self.amount = self
            .amount
            .checked_sub(amount)
            .ok_or_else(|| {
                format!(
                    "Sender does not have enough balance {} for operation costing {}",
                    self.amount, amount
                )
            })?
            .into();
        Ok(())
    }
}

/// Limited Access key to use owner's account with the fixed public_key.
/// Access Key is stored under the key of owner's `account_id` and the `public_key`.
#[derive(Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct AccessKey {
    /// Balance amount on this Access Key. Can be used to pay for the transactions.
    pub amount: Balance,
    /// Owner of the balance of this Access Key. None means the account owner.
    pub balance_owner: Option<AccountId>,
    /// Contract ID that can be called with this Access Key. None means the account owner.
    /// Access key only allows to call given contract_id.
    pub contract_id: Option<AccountId>,
    /// The only method name that can be called with this Access Key. None means any method name.
    pub method_name: Option<Vec<u8>>,
}

impl fmt::Debug for AccessKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AccessKey")
            .field("amount", &self.amount)
            .field("balance_owner", &self.balance_owner)
            .field("contract_id", &self.contract_id)
            .field("method_name", &self.method_name.as_ref().map(|v| logging::pretty_utf8(&v)))
            .finish()
    }
}

impl TryFrom<access_key_proto::AccessKey> for AccessKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(access_key: access_key_proto::AccessKey) -> Result<Self, Self::Error> {
        Ok(AccessKey {
            amount: access_key.amount.unwrap_or_default().try_into()?,
            balance_owner: access_key.balance_owner.into_option().map(|s| s.value),
            contract_id: access_key.contract_id.into_option().map(|s| s.value),
            method_name: access_key.method_name.into_option().map(|s| s.value),
        })
    }
}

impl From<AccessKey> for access_key_proto::AccessKey {
    fn from(access_key: AccessKey) -> access_key_proto::AccessKey {
        access_key_proto::AccessKey {
            amount: SingularPtrField::some(access_key.amount.into()),
            balance_owner: SingularPtrField::from_option(access_key.balance_owner.map(|v| {
                let mut res = StringValue::new();
                res.set_value(v);
                res
            })),
            contract_id: SingularPtrField::from_option(access_key.contract_id.map(|v| {
                let mut res = StringValue::new();
                res.set_value(v);
                res
            })),
            method_name: SingularPtrField::from_option(access_key.method_name.map(|v| {
                let mut res = BytesValue::new();
                res.set_value(v);
                res
            })),
            ..Default::default()
        }
    }
}

'''
'''--- core/primitives/src/crypto/aggregate_signature.rs ---
use std::convert::TryFrom;
use std::error::Error;
use std::fmt;
use std::io::Cursor;

use pairing::bls12_381::Bls12;
use pairing::{
    CurveAffine, CurveProjective, EncodedPoint, Engine, Field, GroupDecodingError, PrimeField,
    PrimeFieldRepr, Rand,
};
use rand::rngs::OsRng;
use rand::Rng;

use crate::serialize::{to_base, BaseDecode};
use crate::types::ReadableBlsPublicKey;

const DOMAIN_SIGNATURE: &[u8] = b"_s";
const DOMAIN_PROOF_OF_POSSESSION: &[u8] = b"_p";

pub fn get_bls_key_pair() -> (BlsPublicKey, BlsSecretKey) {
    let secret_key = BlsSecretKey::generate();
    let public_key = secret_key.get_public_key();
    (public_key, secret_key)
}

#[derive(Clone, Debug)]
pub struct SecretKey<E: Engine> {
    scalar: E::Fr,
}

#[derive(Clone)]
pub struct PublicKey<E: Engine> {
    // G1 is the small-and-fast group.  G2 is the big-and-slow group.  Either one can be used for
    // public keys, and the other for signatures.  Since signature aggregation only needs to be
    // performed by provers, but pubkey aggregation needs to be done by verifiers, we choose the
    // small-and-fast group for public keys.
    point: E::G1Affine,
}

#[derive(Clone, Debug)]
pub struct Signature<E: Engine> {
    // A point on the G2 curve, but not necessarily in the correct G2 subgroup.
    point: E::G2Affine,
}

// TODO: it will usually be desirable to store pubkeys and signatures in compressed form, even in
// memory.  The compressed representations are half the size.
#[derive(Clone)]
pub struct CompressedPublicKey<E: Engine>(<E::G1Affine as CurveAffine>::Compressed);

#[derive(Clone)]
pub struct CompressedSignature<E: Engine>(<E::G2Affine as CurveAffine>::Compressed);

// For those times when time is more important than space, UncompressedSignature is 192 bytes, twice
// as large as CompressedSignature but much faster (about 250x) to decode.
#[derive(Clone)]
pub struct UncompressedSignature<E: Engine>(<E::G2Affine as CurveAffine>::Uncompressed);

impl<E: Engine> SecretKey<E> {
    /// Generate a new secret key from the OS rng.  Panics if OS is unable to provide randomness
    pub fn generate() -> Self {
        let mut rng = OsRng::new().expect("Unable to generate random numbers");
        Self::generate_from_rng(&mut rng)
    }

    pub fn generate_from_rng<R: Rng>(csprng: &mut R) -> Self {
        SecretKey { scalar: E::Fr::rand(csprng) }
    }

    pub fn empty() -> Self {
        SecretKey { scalar: E::Fr::zero() }
    }

    pub fn get_public_key(&self) -> PublicKey<E> {
        PublicKey { point: E::G1Affine::one().mul(self.scalar).into_affine() }
    }

    pub fn sign(&self, message: &[u8]) -> Signature<E> {
        self.sign_domain(message, DOMAIN_SIGNATURE)
    }

    pub fn get_proof_of_possession(&self) -> Signature<E> {
        let message = self.get_public_key().compress();
        self.sign_domain(message.as_ref(), DOMAIN_PROOF_OF_POSSESSION)
    }

    fn sign_domain(&self, message: &[u8], domain: &[u8]) -> Signature<E> {
        // TODO: it would be really nice if CurveProjective::hash took a pair of arguments instead
        // of just one.  The copy here is silly and avoidable.  It's here because we require domain
        // separation for the proof-of-possession.  Simply signing your own public key is not
        // sufficient.  See https://rist.tech.cornell.edu/papers/pkreg.pdf
        let padded_message = [message, domain].concat();
        self.sign_internal(padded_message.as_ref())
    }

    fn sign_internal(&self, message: &[u8]) -> Signature<E> {
        let h = E::G2::hash(message).into_affine();
        Signature { point: h.mul(self.scalar).into_affine() }
    }
}

impl<E: Engine> PublicKey<E> {
    pub fn empty() -> Self {
        PublicKey { point: E::G1Affine::zero() }
    }

    pub fn is_empty(&self) -> bool {
        self.point == E::G1Affine::zero()
    }

    pub fn compress(&self) -> CompressedPublicKey<E> {
        CompressedPublicKey(self.point.into_compressed())
    }

    pub fn to_readable(&self) -> ReadableBlsPublicKey {
        ReadableBlsPublicKey(self.to_string())
    }

    pub fn verify(&self, message: &[u8], signature: &Signature<E>) -> bool {
        self.verify_domain(message, DOMAIN_SIGNATURE, signature)
    }

    pub fn verify_proof_of_possession(&self, signature: &Signature<E>) -> bool {
        let message = self.compress();
        self.verify_domain(message.as_ref(), DOMAIN_PROOF_OF_POSSESSION, signature)
    }

    fn verify_domain(&self, message: &[u8], domain: &[u8], signature: &Signature<E>) -> bool {
        let padded_message = [message, domain].concat();
        self.verify_internal(padded_message.as_ref(), signature)
    }

    fn verify_internal(&self, message: &[u8], signature: &Signature<E>) -> bool {
        if !signature.point.is_in_correct_subgroup_assuming_on_curve() {
            return false;
        }
        let h = E::G2::hash(message).into_affine();
        let lhs = E::pairing(E::G1Affine::one(), signature.point);
        let rhs = E::pairing(self.point, h);
        lhs == rhs
    }
}

impl<E: Engine> fmt::Debug for PublicKey<E> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", to_base(self.compress().as_ref()))
    }
}

impl<E: Engine> fmt::Display for PublicKey<E> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", to_base(self.compress().as_ref()))
    }
}

// Note: deriving PartialEq and Eq doesn't work
impl<E: Engine> PartialEq for PublicKey<E> {
    fn eq(&self, other: &PublicKey<E>) -> bool {
        self.point == other.point
    }
}

impl<E: Engine> Eq for PublicKey<E> {}

impl<E: Engine> std::hash::Hash for PublicKey<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        let bytes: Vec<u8> = self.into();
        state.write(&bytes);
    }
}

impl<E: Engine> Signature<E> {
    pub fn compress(&self) -> CompressedSignature<E> {
        CompressedSignature(self.point.into_compressed())
    }

    pub fn encode_uncompressed(&self) -> UncompressedSignature<E> {
        UncompressedSignature(self.point.into_uncompressed())
    }

    pub fn empty() -> Self {
        Signature { point: E::G2Affine::zero() }
    }
}

// Note: deriving PartialEq and Eq doesn't work
impl<E: Engine> PartialEq for Signature<E> {
    fn eq(&self, other: &Signature<E>) -> bool {
        self.point == other.point
    }
}

impl<E: Engine> Eq for Signature<E> {}

impl<E: Engine> std::hash::Hash for Signature<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        self.compress().as_ref().hash(state);
    }
}

impl<E: Engine> Default for Signature<E> {
    fn default() -> Self {
        Self::empty()
    }
}

impl<E: Engine> From<SecretKey<E>> for Vec<u8> {
    fn from(secret_key: SecretKey<E>) -> Vec<u8> {
        let repr = secret_key.scalar.into_repr();
        let mut res = Vec::new();
        res.resize(repr.num_bits() as usize / 8, 0);
        let buf = Cursor::new(&mut res);
        repr.write_be(buf).unwrap();
        res
    }
}

impl<E: Engine> TryFrom<&[u8]> for SecretKey<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let mut repr: <E::Fr as PrimeField>::Repr = Default::default();
        let buf = Cursor::new(v);
        repr.read_be(buf).map_err(|err| err.to_string())?;
        let scalar = <E::Fr as PrimeField>::from_repr(repr).map_err(|err| err.to_string())?;
        Ok(Self { scalar })
    }
}

impl<E: Engine> TryFrom<Vec<u8>> for SecretKey<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: Vec<u8>) -> Result<Self, Self::Error> {
        Self::try_from(v.as_ref())
    }
}

// `Eq`, `PartialEq`, and `Hash` traits allow us to use `SecretKey<E>` in standard std containers
// and macros.
impl<E: Engine> Eq for SecretKey<E> {}

impl<E: Engine> PartialEq for SecretKey<E> {
    fn eq(&self, other: &Self) -> bool {
        self.scalar == other.scalar
    }
}

impl<E: Engine> std::hash::Hash for SecretKey<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        let bytes: Vec<u8> = self.clone().into();
        state.write(&bytes);
    }
}

impl<E: Engine> From<&PublicKey<E>> for Vec<u8> {
    fn from(public_key: &PublicKey<E>) -> Vec<u8> {
        public_key.compress().as_ref().to_vec()
    }
}

#[derive(Debug)]
pub struct LengthError(usize, usize);

impl Error for LengthError {
    fn description(&self) -> &str {
        "encoding has incorrect length"
    }
}

impl fmt::Display for LengthError {
    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {
        write!(f, "{}, expected {}, got {}", self.description(), self.0, self.1)
    }
}

impl<E: Engine> TryFrom<&[u8]> for PublicKey<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        Ok(CompressedPublicKey::try_from(v)?.decompress().map_err(|err| err.to_string())?)
    }
}

impl<E: Engine> From<&Signature<E>> for Vec<u8> {
    fn from(signature: &Signature<E>) -> Vec<u8> {
        signature.compress().into()
    }
}

impl<E: Engine> TryFrom<&[u8]> for Signature<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        Ok(CompressedSignature::try_from(v)?.decode().map_err(|err| err.to_string())?)
    }
}

impl<E: Engine> TryFrom<Vec<u8>> for Signature<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: Vec<u8>) -> Result<Self, Self::Error> {
        Self::try_from(v.as_ref())
    }
}

impl<E: Engine> CompressedPublicKey<E> {
    pub fn decompress(&self) -> Result<PublicKey<E>, GroupDecodingError> {
        Ok(PublicKey { point: self.0.into_affine()? })
    }

    /// Decompress a pubkey, without verifying that the resulting point is actually on the curve.
    /// Verifying is very slow, so if we know we've already done it (for example, if we're reading
    /// from disk a previously validated block), we can skip point verification.  Use with caution.
    pub fn decompress_unchecked(&self) -> PublicKey<E> {
        PublicKey { point: self.0.into_affine_unchecked().unwrap() }
    }
}

impl<E: Engine> From<&CompressedPublicKey<E>> for Vec<u8> {
    fn from(public_key: &CompressedPublicKey<E>) -> Vec<u8> {
        public_key.as_ref().to_vec()
    }
}

impl<E: Engine> AsRef<[u8]> for CompressedPublicKey<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for CompressedPublicKey<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> From<CompressedPublicKey<E>> for Vec<u8> {
    fn from(public_key: CompressedPublicKey<E>) -> Vec<u8> {
        public_key.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for CompressedPublicKey<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G1Affine as CurveAffine>::Compressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(LengthError(expected, v.len()).into());
        }
        let mut encoded = <E::G1Affine as CurveAffine>::Compressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

impl<E: Engine> CompressedSignature<E> {
    pub fn decode(&self) -> Result<Signature<E>, GroupDecodingError> {
        // Subgroup check is postponed until signature verification
        Ok(Signature { point: self.0.into_affine_semi_checked()? })
    }
}

impl<E: Engine> From<&CompressedSignature<E>> for Vec<u8> {
    fn from(signature: &CompressedSignature<E>) -> Vec<u8> {
        signature.as_ref().to_vec()
    }
}

impl<E: Engine> AsRef<[u8]> for CompressedSignature<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for CompressedSignature<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> From<CompressedSignature<E>> for Vec<u8> {
    fn from(signature: CompressedSignature<E>) -> Vec<u8> {
        signature.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for CompressedSignature<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G2Affine as CurveAffine>::Compressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(LengthError(expected, v.len()).into());
        }
        let mut encoded = <E::G2Affine as CurveAffine>::Compressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

impl<E: Engine> UncompressedSignature<E> {
    pub fn decode(&self) -> Result<Signature<E>, GroupDecodingError> {
        // Subgroup check is postponed until signature verification
        Ok(Signature { point: self.0.into_affine_semi_checked()? })
    }
}

impl<E: Engine> From<&UncompressedSignature<E>> for Vec<u8> {
    fn from(signature: &UncompressedSignature<E>) -> Vec<u8> {
        signature.as_ref().to_vec()
    }
}

impl<E: Engine> AsRef<[u8]> for UncompressedSignature<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for UncompressedSignature<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> From<UncompressedSignature<E>> for Vec<u8> {
    fn from(signature: UncompressedSignature<E>) -> Vec<u8> {
        signature.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for UncompressedSignature<E> {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G2Affine as CurveAffine>::Uncompressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(LengthError(expected, v.len()).into());
        }
        let mut encoded = <E::G2Affine as CurveAffine>::Uncompressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

#[derive(Debug, Clone)]
pub struct AggregatePublicKey<E: Engine> {
    // This is the same as a public key, but stored in projective coordinates instead of affine.
    point: E::G1,
}

#[derive(Debug, Clone)]
pub struct AggregateSignature<E: Engine> {
    // This is the same as a signature, but stored in projective coordinates instead of affine.
    point: E::G2,
}

impl<E: Engine> AggregatePublicKey<E> {
    pub fn new() -> Self {
        AggregatePublicKey { point: E::G1::zero() }
    }

    // Very important: you must verify a proof-of-possession for each public key!
    pub fn aggregate(&mut self, pubkey: &PublicKey<E>) {
        self.point.add_assign_mixed(&pubkey.point);
    }

    pub fn get_key(&self) -> PublicKey<E> {
        PublicKey { point: self.point.into_affine() }
    }
}

impl<E: Engine> Default for AggregatePublicKey<E> {
    fn default() -> Self {
        Self::new()
    }
}

impl<E: Engine> AggregateSignature<E> {
    pub fn new() -> Self {
        AggregateSignature { point: E::G2::zero() }
    }

    pub fn aggregate(&mut self, sig: &Signature<E>) {
        self.point.add_assign_mixed(&sig.point);
    }

    pub fn get_signature(&self) -> Signature<E> {
        Signature { point: self.point.into_affine() }
    }
}

impl<E: Engine> Default for AggregateSignature<E> {
    fn default() -> Self {
        Self::new()
    }
}

impl<E: Engine> BaseDecode for PublicKey<E> {}
impl<E: Engine> BaseDecode for SecretKey<E> {}
impl<E: Engine> BaseDecode for UncompressedSignature<E> {}
impl<E: Engine> BaseDecode for Signature<E> {}

pub type BlsSecretKey = SecretKey<Bls12>;
pub type BlsPublicKey = PublicKey<Bls12>;
pub type BlsSignature = Signature<Bls12>;
pub type BlsAggregatePublicKey = AggregatePublicKey<Bls12>;
pub type BlsAggregateSignature = AggregateSignature<Bls12>;

pub mod uncompressed_bs64_signature_serializer {
    use serde::{Deserialize, Deserializer, Serializer};

    use crate::crypto::aggregate_signature::{Bls12, BlsSignature, UncompressedSignature};
    use crate::serialize::{BaseDecode, BaseEncode};

    pub fn serialize<S>(sig: &BlsSignature, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&sig.encode_uncompressed().to_base())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<BlsSignature, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        let uncompressed = UncompressedSignature::<Bls12>::from_base(&s).unwrap();
        Ok(uncompressed.decode().unwrap())
    }
}

#[cfg(test)]
mod tests {
    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    use super::*;

    #[test]
    fn sign_verify() {
        let mut rng = XorShiftRng::seed_from_u64(1);

        let secret = (0..2).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();
        let pubkey = (0..2).map(|i| secret[i].get_public_key()).collect::<Vec<_>>();
        let message = (0..2).map(|i| format!("message {}", i)).collect::<Vec<_>>();
        let signature = (0..2).map(|i| secret[i].sign(message[i].as_bytes())).collect::<Vec<_>>();

        for i in 0..2 {
            for j in 0..2 {
                for k in 0..2 {
                    assert_eq!(
                        pubkey[i].verify(message[j].as_bytes(), &signature[k]),
                        (i == j) && (j == k)
                    );
                }
            }
        }
    }

    #[test]
    fn proof_verify() {
        let mut rng = XorShiftRng::seed_from_u64(2);

        let secret = (0..2).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();
        let pubkey = (0..2).map(|i| secret[i].get_public_key()).collect::<Vec<_>>();
        let proof = (0..2).map(|i| secret[i].get_proof_of_possession()).collect::<Vec<_>>();

        for i in 0..2 {
            for j in 0..2 {
                assert_eq!(pubkey[i].verify_proof_of_possession(&proof[j]), i == j);
            }
        }

        // make sure domain-separation is working
        let fake_proof = secret[0].sign(pubkey[0].compress().as_ref());
        assert!(!pubkey[0].verify_proof_of_possession(&fake_proof));
    }

    #[test]
    fn aggregate_signature() {
        let mut rng = XorShiftRng::seed_from_u64(3);

        let secret = (0..10).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();

        let mut signature = BlsAggregateSignature::new();
        let mut pubkey = BlsAggregatePublicKey::new();

        let message = "Hello, world!";

        for i in 0..10 {
            signature.aggregate(&secret[i].sign(message.as_bytes()));
            pubkey.aggregate(&secret[i].get_public_key());
        }

        assert!(pubkey.get_key().verify(message.as_bytes(), &signature.get_signature()));

        // Signature should not validate on empty pubkey set
        let blank_pk = BlsAggregatePublicKey::new().get_key();
        assert!(!blank_pk.verify(message.as_bytes(), &signature.get_signature()));

        // Blank signature should not validate on non-empty pubkey set
        let blank_signature = BlsAggregateSignature::new().get_signature();
        assert!(!pubkey.get_key().verify(message.as_bytes(), &blank_signature));

        // Blank signature does validate on empty pubkey set for any message.  It does seem a little
        // odd, but it's consistent.
        assert!(blank_pk.verify(message.as_bytes(), &blank_signature));
    }

    #[test]
    fn encoding() {
        let mut rng = XorShiftRng::seed_from_u64(4);

        let secret = BlsSecretKey::generate_from_rng(&mut rng);
        let _pubkey = secret.get_public_key();
        let message = "Hello, world!";
        let signature = secret.sign(message.as_bytes());

        let compressed = signature.compress();
        let uncompressed = signature.encode_uncompressed();

        assert_eq!(
            CompressedSignature::try_from(compressed.as_ref()).unwrap().decode().unwrap(),
            signature
        );
        assert_eq!(
            UncompressedSignature::try_from(uncompressed.as_ref()).unwrap().decode().unwrap(),
            signature
        );
        assert!(CompressedSignature::<Bls12>::try_from(uncompressed.as_ref()).is_err());
        assert!(UncompressedSignature::<Bls12>::try_from(compressed.as_ref()).is_err());
    }
}

'''
'''--- core/primitives/src/crypto/group_signature.rs ---
use core::fmt;
use std::convert::TryFrom;

use near_protos::types as types_proto;

use crate::crypto::aggregate_signature::{
    BlsAggregatePublicKey, BlsAggregateSignature, BlsPublicKey, BlsSignature,
};
use crate::logging::pretty_hash;
use crate::serialize::{base_format, BaseDecode, BaseEncode};
use crate::types::{PartialSignature, ValidatorMask};

#[derive(Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct GroupSignature {
    #[serde(with = "base_format")]
    pub signature: BlsSignature,
    pub authority_mask: ValidatorMask,
}

impl TryFrom<types_proto::GroupSignature> for GroupSignature {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: types_proto::GroupSignature) -> Result<Self, Self::Error> {
        BaseDecode::from_base(&proto.signature)
            .map(|signature| GroupSignature { signature, authority_mask: proto.authority_mask })
            .map_err(|e| format!("cannot decode signature {:?}", e).into())
    }
}

impl From<GroupSignature> for types_proto::GroupSignature {
    fn from(signature: GroupSignature) -> Self {
        types_proto::GroupSignature {
            signature: BaseEncode::to_base(&signature.signature),
            authority_mask: signature.authority_mask,
            ..Default::default()
        }
    }
}

impl fmt::Debug for GroupSignature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{:?} {:?}", self.authority_mask, pretty_hash(&self.signature.clone().to_base()))
    }
}

impl GroupSignature {
    // TODO (optimization): It's better to keep the signature in projective coordinates while
    // building it, then switch to affine coordinates at the end.  For the time being we just keep
    // it in affine coordinates always.
    pub fn add_signature(&mut self, signature: &PartialSignature, authority_id: usize) {
        if authority_id >= self.authority_mask.len() {
            self.authority_mask.resize(authority_id + 1, false);
        }
        if self.authority_mask[authority_id] {
            return;
        }
        let mut new_sig = BlsAggregateSignature::new();
        new_sig.aggregate(&signature);
        if self.signature != BlsSignature::default() {
            new_sig.aggregate(&self.signature);
        }
        self.signature = new_sig.get_signature();
        self.authority_mask[authority_id] = true;
    }

    pub fn authority_count(&self) -> usize {
        self.authority_mask.iter().filter(|&x| *x).count()
    }

    pub fn verify(&self, keys: &[BlsPublicKey], message: &[u8]) -> bool {
        if keys.len() < self.authority_mask.len() {
            return false;
        }
        // Empty signature + empty public key would pass verification
        if self.authority_count() == 0 {
            return false;
        }
        let mut group_key = BlsAggregatePublicKey::new();
        for (index, key) in keys.iter().enumerate() {
            if let Some(true) = self.authority_mask.get(index) {
                group_key.aggregate(&key);
            }
        }
        group_key.get_key().verify(message, &self.signature)
    }
}

impl Default for GroupSignature {
    fn default() -> Self {
        GroupSignature {
            signature: BlsSignature::empty(),
            authority_mask: ValidatorMask::default(),
        }
    }
}

'''
'''--- core/primitives/src/crypto/mod.rs ---
pub mod aggregate_signature;
pub mod group_signature;
pub mod signature;
pub mod signer;

'''
'''--- core/primitives/src/crypto/signature.rs ---
extern crate exonum_sodiumoxide as sodiumoxide;

use std::convert::TryFrom;
use std::fmt;
use std::hash::{Hash, Hasher};

pub use exonum_sodiumoxide::crypto::sign::ed25519::Seed;

use crate::logging::pretty_hash;
use crate::serialize::{from_base, to_base, BaseDecode};
use crate::types::ReadablePublicKey;

#[derive(Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]
pub struct PublicKey(pub sodiumoxide::crypto::sign::ed25519::PublicKey);

#[derive(Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct SecretKey(pub sodiumoxide::crypto::sign::ed25519::SecretKey);

#[derive(Clone, Eq, PartialEq, Serialize, Deserialize, Hash)]
pub struct Signature(pub sodiumoxide::crypto::sign::ed25519::Signature);

pub fn sign(data: &[u8], secret_key: &SecretKey) -> Signature {
    Signature(sodiumoxide::crypto::sign::ed25519::sign_detached(data, &secret_key.0))
}

pub fn verify(data: &[u8], signature: &Signature, public_key: &PublicKey) -> bool {
    sodiumoxide::crypto::sign::ed25519::verify_detached(&signature.0, data, &public_key.0)
}

pub fn get_key_pair() -> (PublicKey, SecretKey) {
    let (public_key, secret_key) = sodiumoxide::crypto::sign::ed25519::gen_keypair();
    (PublicKey(public_key), SecretKey(secret_key))
}

impl From<&PublicKey> for Vec<u8> {
    fn from(public_key: &PublicKey) -> Self {
        public_key.as_ref().to_vec()
    }
}

impl From<&SecretKey> for Vec<u8> {
    fn from(secret_key: &SecretKey) -> Self {
        secret_key.as_ref().to_vec()
    }
}

const SIG: [u8; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES] =
    [0u8; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];

pub const DEFAULT_SIGNATURE: Signature =
    Signature(sodiumoxide::crypto::sign::ed25519::Signature(SIG));

impl BaseDecode for PublicKey {}
impl BaseDecode for SecretKey {}

impl PublicKey {
    pub fn to_readable(&self) -> ReadablePublicKey {
        ReadablePublicKey(self.to_string())
    }
}

impl Hash for PublicKey {
    fn hash<H: Hasher>(&self, state: &mut H) {
        state.write(self.as_ref());
    }
}

impl TryFrom<&[u8]> for PublicKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES {
            return Err(format!(
                "bytes not the size {} of a public key {}: {:?}",
                bytes.len(),
                sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES,
                bytes
            )
            .into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES];
        array.copy_from_slice(bytes);
        let public_key = sodiumoxide::crypto::sign::ed25519::PublicKey(array);
        Ok(PublicKey(public_key))
    }
}

impl TryFrom<Vec<u8>> for PublicKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: Vec<u8>) -> Result<Self, Self::Error> {
        let bytes: &[u8] = bytes.as_ref();
        Self::try_from(bytes)
    }
}

impl TryFrom<&str> for PublicKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES];
        let bytes = from_base(s).map_err::<Self::Error, _>(|e| {
            format!("Failed to convert public key from base64: {}", e).into()
        })?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for public key", s).into());
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let public_key = sodiumoxide::crypto::sign::ed25519::PublicKey(array);
        Ok(PublicKey(public_key))
    }
}

impl TryFrom<&[u8]> for SecretKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES {
            return Err("bytes not the size of a secret key".into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES];
        array.copy_from_slice(bytes);
        let secret_key = sodiumoxide::crypto::sign::ed25519::SecretKey(array);
        Ok(SecretKey(secret_key))
    }
}

impl TryFrom<&str> for SecretKey {
    type Error = Box<dyn std::error::Error>;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES];
        let bytes = from_base(s).map_err::<Self::Error, _>(|e| {
            format!("Failed to convert secret key from base64: {}", e).into()
        })?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for secret key", s).into());
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let secret_key = sodiumoxide::crypto::sign::ed25519::SecretKey(array);
        Ok(SecretKey(secret_key))
    }
}

impl TryFrom<&[u8]> for Signature {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES {
            return Err("bytes not the size of a signature".into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];
        array.copy_from_slice(bytes);
        let signature = sodiumoxide::crypto::sign::ed25519::Signature(array);
        Ok(Signature(signature))
    }
}

impl TryFrom<Vec<u8>> for Signature {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: Vec<u8>) -> Result<Self, Self::Error> {
        let bytes: &[u8] = bytes.as_ref();
        Self::try_from(bytes)
    }
}

impl TryFrom<&str> for Signature {
    type Error = Box<dyn std::error::Error>;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];
        let bytes = from_base(s).map_err::<Self::Error, _>(|e| {
            format!("Failed to convert signature from base58: {}", e).into()
        })?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for signature", s).into());
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let signature = sodiumoxide::crypto::sign::ed25519::Signature(array);
        Ok(Signature(signature))
    }
}

impl std::convert::AsRef<[u8]> for PublicKey {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl<'a> From<&'a PublicKey> for String {
    fn from(h: &'a PublicKey) -> Self {
        to_base(&h.0)
    }
}

impl fmt::Debug for PublicKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for PublicKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl std::convert::AsRef<[u8]> for SecretKey {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl<'a> From<&'a SecretKey> for String {
    fn from(h: &'a SecretKey) -> Self {
        to_base(h)
    }
}

impl std::convert::AsRef<[u8]> for Signature {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl fmt::Debug for SecretKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for SecretKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl<'a> From<&'a Signature> for String {
    fn from(h: &'a Signature) -> Self {
        to_base(h)
    }
}

impl<'a> From<&'a Signature> for Vec<u8> {
    fn from(h: &'a Signature) -> Self {
        (h.0).0.to_vec()
    }
}

impl From<Signature> for Vec<u8> {
    fn from(h: Signature) -> Self {
        (h.0).0.to_vec()
    }
}

impl fmt::Debug for Signature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for Signature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}
//
//pub mod bs64_pub_key_format {
//    use std::convert::TryInto;
//
//    use serde::{de::Error, Deserialize, Deserializer, Serializer};
//
//    use super::PublicKey;
//
//    pub fn serialize<S>(public_key: &PublicKey, serializer: S) -> Result<S::Ok, S::Error>
//    where
//        S: Serializer,
//    {
//        serializer.serialize_str(String::from(public_key).as_str())
//    }
//
//    pub fn deserialize<'de, D>(deserializer: D) -> Result<PublicKey, D::Error>
//    where
//        D: Deserializer<'de>,
//    {
//        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
//    }
//}
//
//pub mod bs64_secret_key_format {
//    use std::convert::TryInto;
//
//    use serde::{de::Error, Deserialize, Deserializer, Serializer};
//
//    use super::SecretKey;
//
//    pub fn serialize<S>(secret_key: &SecretKey, serializer: S) -> Result<S::Ok, S::Error>
//    where
//        S: Serializer,
//    {
//        serializer.serialize_str(String::from(secret_key).as_str())
//    }
//
//    pub fn deserialize<'de, D>(deserializer: D) -> Result<SecretKey, D::Error>
//    where
//        D: Deserializer<'de>,
//    {
//        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
//    }
//}
//
//pub mod bs64_signature_format {
//    use std::convert::TryInto;
//
//    use serde::{de::Error, Deserialize, Deserializer, Serializer};
//
//    use super::Signature;
//
//    pub fn serialize<S>(signature: &Signature, serializer: S) -> Result<S::Ok, S::Error>
//    where
//        S: Serializer,
//    {
//        serializer.serialize_str(String::from(signature).as_str())
//    }
//
//    pub fn deserialize<'de, D>(deserializer: D) -> Result<Signature, D::Error>
//    where
//        D: Deserializer<'de>,
//    {
//        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
//    }
//}
//
//pub mod bs64_serializer {
//    use serde::{Deserialize, Deserializer, Serializer};
//
//    use crate::serialize::BaseEncoded;
//
//    pub fn serialize<T, S>(t: &T, serializer: S) -> Result<S::Ok, S::Error>
//    where
//        T: BaseEncoded,
//        S: Serializer,
//    {
//        serializer.serialize_str(&t.to_base())
//    }
//
//    pub fn deserialize<'de, T, D>(deserializer: D) -> Result<T, D::Error>
//    where
//        T: BaseEncoded,
//        D: Deserializer<'de>,
//    {
//        let s = String::deserialize(deserializer)?;
//        Ok(T::from_base(&s).unwrap())
//    }
//}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_verify() {
        let (public_key, private_key) = get_key_pair();
        let data = b"123";
        let signature = sign(data, &private_key);
        assert!(verify(data, &signature, &public_key));
    }
}

'''
'''--- core/primitives/src/crypto/signer.rs ---
use std::fs;
use std::fs::File;
use std::io::{Read, Write};
use std::path::Path;
use std::process;
use std::sync::Arc;

use rand::distributions::Alphanumeric;
use rand::rngs::OsRng;
use rand::Rng;

use crate::crypto::aggregate_signature::BlsPublicKey;
use crate::crypto::signature::{get_key_pair, sign, verify, PublicKey, SecretKey, Signature};
use crate::serialize::base_format;
use crate::types::{AccountId, PartialSignature};

/// Trait to abstract the signer account.
pub trait AccountSigner: Sync + Send {
    fn account_id(&self) -> AccountId;
}

/// Trait to abstract the way transaction signing with ed25519.
/// Can be used to not keep private key in the given binary via cross-process communication.
pub trait EDSigner: Sync + Send {
    fn public_key(&self) -> PublicKey;
    fn sign(&self, data: &[u8]) -> Signature;
    fn verify(&self, data: &[u8], signature: &Signature) -> bool;

    fn write_to_file(&self, _path: &Path) {
        unimplemented!();
    }
}

/// Trait to abstract the way signing with bls.
/// Can be used to not keep private key in the given binary via cross-process communication.
pub trait BLSSigner: Sync + Send {
    fn bls_public_key(&self) -> BlsPublicKey;
    fn bls_sign(&self, data: &[u8]) -> PartialSignature;
}

#[derive(Serialize, Deserialize)]
pub struct KeyFile {
    #[serde(with = "base_format")]
    pub public_key: PublicKey,
    #[serde(with = "base_format")]
    pub secret_key: SecretKey,
}

pub fn write_key_file(
    key_store_path: &Path,
    public_key: PublicKey,
    secret_key: SecretKey,
) -> String {
    if !key_store_path.exists() {
        fs::create_dir_all(key_store_path).unwrap();
    }

    let key_file = KeyFile { public_key, secret_key };
    let key_file_path = key_store_path.join(Path::new(&public_key.to_string()));
    let serialized = serde_json::to_string(&key_file).unwrap();
    fs::write(key_file_path, serialized).unwrap();
    public_key.to_string()
}

pub fn get_key_file(key_store_path: &Path, public_key: Option<String>) -> KeyFile {
    if !key_store_path.exists() {
        println!("Key store path does not exist: {:?}", &key_store_path);
        process::exit(3);
    }

    let mut key_files = fs::read_dir(key_store_path).unwrap();
    let key_file = key_files.next();
    let key_file_string = if key_files.count() != 0 {
        if let Some(p) = public_key {
            let key_file_path = key_store_path.join(Path::new(&p));
            fs::read_to_string(key_file_path).unwrap()
        } else {
            println!(
                "Public key must be specified when there is more than one \
                 file in the keystore"
            );
            process::exit(4);
        }
    } else {
        fs::read_to_string(key_file.unwrap().unwrap().path()).unwrap()
    };

    serde_json::from_str(&key_file_string).unwrap()
}

#[derive(Serialize, Deserialize)]
pub struct BlockProducerKeyFile {
    #[serde(with = "base_format")]
    pub public_key: PublicKey,
    #[serde(with = "base_format")]
    pub secret_key: SecretKey,
}

pub fn write_block_producer_key_file(
    key_store_path: &Path,
    public_key: PublicKey,
    secret_key: SecretKey,
) -> String {
    if !key_store_path.exists() {
        fs::create_dir_all(key_store_path).unwrap();
    }

    let key_file = BlockProducerKeyFile { public_key, secret_key };
    let key_file_path = key_store_path.join(Path::new(&key_file.public_key.to_string()));
    let serialized = serde_json::to_string(&key_file).unwrap();
    fs::write(key_file_path, serialized).unwrap();
    key_file.public_key.to_string()
}

pub fn get_block_producer_key_file(
    key_store_path: &Path,
    public_key: Option<String>,
) -> BlockProducerKeyFile {
    if !key_store_path.exists() {
        println!("Key store path does not exist: {:?}", &key_store_path);
        process::exit(3);
    }

    let mut key_files = fs::read_dir(key_store_path).unwrap();
    let key_file = key_files.next();
    let key_files_count = key_files.count();
    if key_files_count == 0 && key_file.is_none() {
        panic!("No key file found in {:?}. Run `cargo run --package keystore -- keygen --test-seed alice.near` to set up testing keys.", key_store_path);
    }
    let key_file_string = if key_files_count > 0 {
        if let Some(p) = public_key {
            let key_file_path = key_store_path.join(Path::new(&p));
            match fs::read_to_string(key_file_path.clone()) {
                Ok(content) => content,
                Err(err) => {
                    panic!("Failed to read key file {:?} with error: {}", key_file_path, err);
                }
            }
        } else {
            println!(
                "Public key must be specified when there is more than one \
                 file in the keystore"
            );
            process::exit(4);
        }
    } else {
        let path = key_file.unwrap().unwrap().path();
        match fs::read_to_string(path.clone()) {
            Ok(content) => content,
            Err(err) => {
                panic!("Failed to read key file {:?} with error: {}", path, err);
            }
        }
    };

    serde_json::from_str(&key_file_string).unwrap()
}

pub fn get_or_create_key_file(
    key_store_path: &Path,
    public_key: Option<String>,
) -> BlockProducerKeyFile {
    if !key_store_path.exists() {
        let (public_key, secret_key) = get_key_pair();
        let new_public_key = write_block_producer_key_file(key_store_path, public_key, secret_key);
        get_block_producer_key_file(key_store_path, Some(new_public_key))
    } else {
        get_block_producer_key_file(key_store_path, public_key)
    }
}

#[derive(Clone, Serialize, Deserialize)]
pub struct InMemorySigner {
    pub account_id: AccountId,
    #[serde(with = "base_format")]
    pub public_key: PublicKey,
    #[serde(with = "base_format")]
    pub secret_key: SecretKey,
}

impl InMemorySigner {
    pub fn new(account_id: String) -> Self {
        let (public_key, secret_key) = get_key_pair();
        Self { account_id, public_key, secret_key }
    }

    pub fn from_secret_key(
        account_id: String,
        public_key: PublicKey,
        secret_key: SecretKey,
    ) -> Self {
        Self { account_id, public_key, secret_key }
    }

    /// Read key file into signer.
    pub fn from_file(path: &Path) -> Self {
        let mut file = File::open(path).expect("Could not open key file.");
        let mut content = String::new();
        file.read_to_string(&mut content).expect("Could not read from key file.");
        InMemorySigner::from(content.as_str())
    }

    /// Initialize `InMemorySigner` with a random ED25519 and BLS keys, and random account id. Used
    /// for testing only.
    pub fn from_random() -> Self {
        let mut rng = OsRng::new().expect("Unable to generate random numbers");
        let account_id: String =
            rng.sample_iter(&Alphanumeric).filter(char::is_ascii_alphabetic).take(10).collect();
        let (public_key, secret_key) = get_key_pair();
        Self { account_id, public_key, secret_key }
    }
}

impl From<&str> for InMemorySigner {
    fn from(key_file: &str) -> Self {
        serde_json::from_str(key_file).expect("Failed to deserialize the key file.")
    }
}

impl From<InMemorySigner> for KeyFile {
    fn from(signer: InMemorySigner) -> KeyFile {
        KeyFile { public_key: signer.public_key, secret_key: signer.secret_key.clone() }
    }
}

impl From<Arc<InMemorySigner>> for KeyFile {
    fn from(signer: Arc<InMemorySigner>) -> KeyFile {
        KeyFile { public_key: signer.public_key, secret_key: signer.secret_key.clone() }
    }
}

impl AccountSigner for InMemorySigner {
    #[inline]
    fn account_id(&self) -> AccountId {
        self.account_id.clone()
    }
}

impl EDSigner for InMemorySigner {
    #[inline]
    fn public_key(&self) -> PublicKey {
        self.public_key
    }

    fn sign(&self, data: &[u8]) -> Signature {
        sign(data, &self.secret_key)
    }

    fn verify(&self, data: &[u8], signature: &Signature) -> bool {
        verify(data, signature, &self.public_key)
    }

    /// Save signer into key file.
    fn write_to_file(&self, path: &Path) {
        let mut file = File::create(path).expect("Failed to create / write a key file.");
        let str = serde_json::to_string_pretty(self).expect("Error serializing the key file.");
        if let Err(err) = file.write_all(str.as_bytes()) {
            panic!("Failed to write a key file {}", err);
        }
    }
}

'''
'''--- core/primitives/src/hash.rs ---
use std::convert::TryFrom;
use std::fmt;
use std::hash::{Hash, Hasher};

use exonum_sodiumoxide as sodiumoxide;
use exonum_sodiumoxide::crypto::hash::sha256::Digest;
use heapsize;

use crate::logging::pretty_hash;
use crate::serialize::{from_base, to_base, BaseDecode, Encode};

#[derive(Copy, Clone, PartialOrd, Ord, Serialize, Deserialize)]
pub struct CryptoHash(pub Digest);

impl<'a> From<&'a CryptoHash> for String {
    fn from(h: &'a CryptoHash) -> Self {
        to_base(&h.0)
    }
}

impl TryFrom<String> for CryptoHash {
    type Error = Box<dyn std::error::Error>;

    fn try_from(s: String) -> Result<Self, Self::Error> {
        let bytes = from_base(&s).map_err::<Self::Error, _>(|e| format!("{}", e).into())?;
        Self::try_from(bytes)
    }
}

impl Default for CryptoHash {
    fn default() -> Self {
        CryptoHash(Digest(Default::default()))
    }
}

impl AsRef<[u8]> for CryptoHash {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl AsMut<[u8]> for CryptoHash {
    fn as_mut(&mut self) -> &mut [u8] {
        (self.0).0.as_mut()
    }
}

impl BaseDecode for CryptoHash {}

impl TryFrom<&[u8]> for CryptoHash {
    type Error = Box<dyn std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != 32 {
            return Err("incorrect length for hash".into());
        }
        let mut buf = [0; 32];
        buf.copy_from_slice(bytes);
        Ok(CryptoHash(Digest(buf)))
    }
}

impl TryFrom<Vec<u8>> for CryptoHash {
    type Error = Box<dyn std::error::Error>;

    fn try_from(v: Vec<u8>) -> Result<Self, Self::Error> {
        Self::try_from(v.as_ref())
    }
}

impl From<CryptoHash> for Vec<u8> {
    fn from(hash: CryptoHash) -> Vec<u8> {
        (hash.0).0.to_vec()
    }
}

impl From<&CryptoHash> for Vec<u8> {
    fn from(hash: &CryptoHash) -> Vec<u8> {
        (hash.0).0.to_vec()
    }
}

impl fmt::Debug for CryptoHash {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for CryptoHash {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl Hash for CryptoHash {
    fn hash<H: Hasher>(&self, state: &mut H) {
        state.write(self.as_ref());
    }
}

impl PartialEq for CryptoHash {
    fn eq(&self, other: &CryptoHash) -> bool {
        self.0 == other.0
    }
}

impl Eq for CryptoHash {}

/// Calculates a hash of a bytes slice.
///
/// # Examples
///
/// The example below calculates the hash of the indicated data.
///
/// ```
/// let data = [1, 2, 3];
/// let hash = near_primitives::hash::hash(&data);
/// ```
pub fn hash(data: &[u8]) -> CryptoHash {
    CryptoHash(sodiumoxide::crypto::hash::sha256::hash(data))
}

pub fn hash_struct<T: Encode>(obj: &T) -> CryptoHash {
    hash(&obj.encode().expect("Serialization failed"))
}

impl heapsize::HeapSizeOf for CryptoHash {
    fn heap_size_of_children(&self) -> usize {
        0
    }
}

#[cfg(test)]
mod tests {
    use crate::serialize::base_format;

    use super::*;

    #[derive(Deserialize, Serialize)]
    struct Struct {
        #[serde(with = "base_format")]
        hash: CryptoHash,
    }

    #[test]
    fn test_serialize_success() {
        let hash = hash(&[0, 1, 2]);
        let s = Struct { hash };
        let encoded = serde_json::to_string(&s).unwrap();
        assert_eq!(encoded, "{\"hash\":\"CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf\"}");
    }

    #[test]
    fn test_serialize_default() {
        let s = Struct { hash: CryptoHash::default() };
        let encoded = serde_json::to_string(&s).unwrap();
        assert_eq!(encoded, "{\"hash\":\"11111111111111111111111111111111\"}");
    }

    #[test]
    fn test_deserialize_default() {
        let encoded = "{\"hash\":\"11111111111111111111111111111111\"}";
        let decoded: Struct = serde_json::from_str(&encoded).unwrap();
        assert_eq!(decoded.hash, CryptoHash::default());
    }

    #[test]
    fn test_deserialize_success() {
        let encoded = "{\"hash\":\"CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf\"}";
        let decoded: Struct = serde_json::from_str(&encoded).unwrap();
        assert_eq!(decoded.hash, hash(&[0, 1, 2]));
    }

    #[test]
    fn test_deserialize_not_base64() {
        let encoded = "\"---\"";
        match serde_json::from_str(&encoded) {
            Ok(CryptoHash(_)) => assert!(false, "should have failed"),
            Err(_) => (),
        }
    }

    #[test]
    fn test_deserialize_not_crypto_hash() {
        let encoded = "\"CjNSmWXTWhC3ELhRmWMTkRbU96wUACqxMtV1uGf\"";
        match serde_json::from_str(&encoded) {
            Ok(CryptoHash(_)) => assert!(false, "should have failed"),
            Err(_) => (),
        }
    }
}

'''
'''--- core/primitives/src/lib.rs ---
extern crate bincode;
extern crate byteorder;
extern crate exonum_sodiumoxide;
extern crate heapsize;
extern crate jemallocator;
extern crate pairing;
extern crate rand;
extern crate regex;
extern crate serde;
#[macro_use]
extern crate serde_derive;
extern crate serde_json;

#[global_allocator]
static ALLOC: jemallocator::Jemalloc = jemallocator::Jemalloc;

pub mod account;
//pub mod balance;
pub mod crypto;
pub mod hash;
pub mod logging;
pub mod merkle;
pub mod receipt;
pub mod rpc;
pub mod serialize;
pub mod sharding;
pub mod test_utils;
pub mod transaction;
pub mod types;
pub mod utils;

'''
'''--- core/primitives/src/logging.rs ---
use std::fmt::Debug;

use serde::Serialize;

use crate::serialize::to_base;

const VECTOR_MAX_LENGTH: usize = 5;
const STRING_PRINT_LEN: usize = 128;

pub fn pretty_vec<T: Debug>(buf: &[T]) -> String {
    if buf.len() <= VECTOR_MAX_LENGTH {
        format!("{:#?}", buf)
    } else {
        format!(
            "({})[{:#?}, {:#?}, … {:#?}, {:#?}]",
            buf.len(),
            buf[0],
            buf[1],
            buf[buf.len() - 2],
            buf[buf.len() - 1]
        )
    }
}

pub fn pretty_str(s: &str, print_len: usize) -> String {
    if s.len() <= print_len {
        format!("`{}`", s)
    } else {
        format!("({})`{}…`", s.len(), &s.chars().take(print_len).collect::<String>())
    }
}

pub fn pretty_hash(s: &str) -> String {
    pretty_str(s, STRING_PRINT_LEN)
}

pub fn pretty_utf8(buf: &[u8]) -> String {
    match std::str::from_utf8(buf) {
        Ok(s) => pretty_hash(s),
        Err(_) => {
            if buf.len() <= STRING_PRINT_LEN {
                pretty_hash(&to_base(buf))
            } else {
                pretty_vec(buf)
            }
        }
    }
}

pub fn pretty_result(result: &Option<Vec<u8>>) -> String {
    match result {
        Some(ref v) => pretty_utf8(&v),
        None => "None".to_string(),
    }
}

pub fn pretty_results(results: &[Option<Vec<u8>>]) -> String {
    let v: Vec<String> = results.iter().map(pretty_result).collect();
    format!("{:?}", pretty_vec(&v))
}

pub fn pretty_serializable<T: Serialize>(s: &T) -> String {
    match bincode::serialize(&s) {
        Ok(buf) => pretty_hash(&to_base(&buf)),
        Err(e) => format!("[failed to serialize: {}]", e),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    static HI_NEAR: &str = "Привет, NEAR";

    #[test]
    fn test_non_ut8_string_truncation() {
        assert_eq!(format!("({})`Привет…`", HI_NEAR.len()), pretty_str(HI_NEAR, 6));
    }

    #[test]
    fn test_non_ut8_more_bytes_same_char_count() {
        assert_eq!(
            format!("({})`{}…`", HI_NEAR.len(), HI_NEAR),
            pretty_str(HI_NEAR, HI_NEAR.chars().count())
        );
    }

    #[test]
    fn test_non_ut8_no_truncation() {
        assert_eq!(format!("`{}`", HI_NEAR), pretty_str(HI_NEAR, HI_NEAR.len()));
    }
}

'''
'''--- core/primitives/src/merkle.rs ---
use crate::hash::{hash, hash_struct};
use crate::serialize::Encode;
use crate::types::MerkleHash;

pub type MerklePath = Vec<(MerkleHash, Direction)>;

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left,
    Right,
}

fn combine_hash(hash1: MerkleHash, hash2: MerkleHash) -> MerkleHash {
    let mut combined: Vec<u8> = hash1.into();
    combined.append(&mut hash2.into());
    hash(&combined)
}

/// Merklize an array of items. If the array is empty, returns hash of 0
pub fn merklize<T: Encode>(arr: &[T]) -> (MerkleHash, Vec<MerklePath>) {
    if arr.is_empty() {
        return (MerkleHash::default(), vec![]);
    }
    let mut len = (arr.len() as u32).next_power_of_two();
    let mut hashes: Vec<_> = (0..len)
        .map(|i| if i < arr.len() as u32 { hash_struct(&arr[i as usize]) } else { hash_struct(&0) })
        .collect();
    // degenerate case
    if len == 1 {
        return (hashes[0], vec![vec![]]);
    }
    let mut paths: Vec<MerklePath> = (0..arr.len())
        .map(|i| {
            if i % 2 == 0 {
                vec![(hashes[(i + 1) as usize], Direction::Right)]
            } else {
                vec![(hashes[(i - 1) as usize], Direction::Left)]
            }
        })
        .collect();

    let mut counter = 1;
    while len > 1 {
        len /= 2;
        counter *= 2;
        for i in 0..len {
            let hash = combine_hash(hashes[2 * i as usize], hashes[(2 * i + 1) as usize]);
            hashes[i as usize] = hash;
            if len > 1 {
                if i % 2 == 0 {
                    for j in 0..counter {
                        let index = ((i + 1) * counter + j) as usize;
                        if index < arr.len() {
                            paths[index].push((hash, Direction::Left));
                        }
                    }
                } else {
                    for j in 0..counter {
                        let index = ((i - 1) * counter + j) as usize;
                        if index < arr.len() {
                            paths[index].push((hash, Direction::Right));
                        }
                    }
                }
            }
        }
    }
    (hashes[0], paths)
}

/// Verify merkle path for given item and corresponding path.
pub fn verify_path<T: Encode>(root: MerkleHash, path: &MerklePath, item: &T) -> bool {
    let mut hash = hash_struct(item);
    for (h, d) in path {
        match d {
            Direction::Left => {
                hash = combine_hash(*h, hash);
            }
            Direction::Right => {
                hash = combine_hash(hash, *h);
            }
        }
    }
    hash == root
}

#[cfg(test)]
mod tests {
    use super::*;
    use rand::rngs::StdRng;
    use rand::{Rng, SeedableRng};

    fn test_with_len(n: u32, rng: &mut StdRng) {
        let mut arr: Vec<u32> = vec![];
        for _ in 0..n {
            arr.push(rng.gen_range(0, 1000));
        }
        let (root, paths) = merklize(&arr);
        assert_eq!(paths.len() as u32, n);
        for (i, item) in arr.iter().enumerate() {
            assert!(verify_path(root, &paths[i], item));
        }
    }

    #[test]
    fn test_merkle_path() {
        let mut rng: StdRng = SeedableRng::seed_from_u64(1);
        for _ in 0..10 {
            let len: u32 = rng.gen_range(1, 50);
            test_with_len(len, &mut rng);
        }
    }

    #[test]
    fn test_incorrect_path() {
        let items = vec![111, 222, 333];
        let (root, paths) = merklize(&items);
        for i in 0..items.len() {
            assert!(!verify_path(root, &paths[(i + 1) % 3], &items[i]))
        }
    }
}

'''
'''--- core/primitives/src/network.rs ---
use near_protos::network as network_proto;
use protobuf::well_known_types::UInt32Value;
use protobuf::{RepeatedField, SingularPtrField};
use std::borrow::Borrow;
use std::convert::{Into, TryFrom, TryInto};
use std::fmt;
use std::fmt::{Display, Formatter};
use std::hash::{Hash, Hasher};
use std::iter::FromIterator;
use std::net::SocketAddr;

use crate::hash::CryptoHash;
use crate::types::{AccountId, PeerId};
use crate::utils::to_string_value;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PeerAddr {
    pub id: PeerId,
    pub addr: SocketAddr,
}

impl PeerAddr {
    pub fn parse(addr_id: &str) -> Result<Self, Box<std::error::Error>> {
        let addr_id: Vec<_> = addr_id.split('/').collect();
        let (addr, id) = (addr_id[0], addr_id[1]);
        Ok(PeerAddr {
            id: id.to_string().try_into()?,
            addr: addr
                .parse::<SocketAddr>()
                .map_err(|e| format!("Error parsing address {:?}: {:?}", addr, e))?,
        })
    }
}

impl Display for PeerAddr {
    fn fmt(&self, f: &mut Formatter) -> Result<(), std::fmt::Error> {
        write!(f, "{}/{}", self.addr, self.id)
    }
}

impl TryFrom<PeerInfo> for PeerAddr {
    type Error = Box<std::error::Error>;

    fn try_from(peer_info: PeerInfo) -> Result<Self, Self::Error> {
        match peer_info.addr {
            Some(addr) => Ok(PeerAddr { id: peer_info.id, addr }),
            None => Err(format!("PeerInfo {:?} doesn't have an address", peer_info).into()),
        }
    }
}

/// Info about the peer. If peer is an authority then we also know its account id.
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PeerInfo {
    pub id: PeerId,
    pub addr: Option<SocketAddr>,
    pub account_id: Option<AccountId>,
}

impl PeerInfo {
    pub fn addr_port(&self) -> Option<u16> {
        self.addr.map(|addr| addr.port())
    }
}

impl PartialEq for PeerInfo {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

impl Hash for PeerInfo {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.id.hash(state);
    }
}

impl Eq for PeerInfo {}

impl fmt::Display for PeerInfo {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if let Some(acc) = self.account_id.as_ref() {
            write!(f, "({}, {:?}, {})", self.id, self.addr, acc)
        } else {
            write!(f, "({}, {:?})", self.id, self.addr)
        }
    }
}

impl Borrow<PeerId> for PeerInfo {
    fn borrow(&self) -> &PeerId {
        &self.id
    }
}

impl From<PeerAddr> for PeerInfo {
    fn from(node_addr: PeerAddr) -> Self {
        PeerInfo { id: node_addr.id, addr: Some(node_addr.addr), account_id: None }
    }
}

impl TryFrom<network_proto::PeerInfo> for PeerInfo {
    type Error = Box<std::error::Error>;

    fn try_from(proto: network_proto::PeerInfo) -> Result<Self, Self::Error> {
        let addr = proto.addr.into_option().and_then(|s| s.value.parse::<SocketAddr>().ok());
        let account_id = proto.account_id.into_option().map(|s| s.value);
        Ok(PeerInfo { id: CryptoHash::try_from(proto.id)?, addr, account_id })
    }
}

impl From<PeerInfo> for network_proto::PeerInfo {
    fn from(peer_info: PeerInfo) -> network_proto::PeerInfo {
        let id = peer_info.id;
        let addr = SingularPtrField::from_option(
            peer_info.addr.map(|s| to_string_value(format!("{}", s))),
        );
        let account_id = SingularPtrField::from_option(peer_info.account_id.map(to_string_value));
        network_proto::PeerInfo { id: id.into(), addr, account_id, ..Default::default() }
    }
}

pub type PeersInfo = Vec<PeerInfo>;

#[derive(PartialEq, Eq, Clone, Debug, Serialize, Deserialize)]
pub struct Handshake {
    /// Protocol version.
    pub version: u32,
    /// Sender's peer id.
    pub peer_id: PeerId,
    /// Sender's account id, if present.
    pub account_id: Option<AccountId>,
    /// Sender's listening addr.
    pub listen_port: Option<u16>,
    /// Sender's information about known peers.
    pub peers_info: PeersInfo,
}

impl TryFrom<network_proto::Handshake> for Handshake {
    type Error = Box<std::error::Error>;

    fn try_from(proto: network_proto::Handshake) -> Result<Self, Self::Error> {
        let account_id = proto.account_id.into_option().map(|s| s.value);
        let listen_port = proto.listen_port.into_option().map(|v| v.value as u16);
        let peers_info =
            proto.peers_info.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(Handshake {
            version: proto.version,
            peer_id: proto.peer_id.try_into()?,
            account_id,
            listen_port,
            peers_info,
        })
    }
}

impl From<Handshake> for network_proto::Handshake {
    fn from(hand_shake: Handshake) -> network_proto::Handshake {
        let account_id = SingularPtrField::from_option(hand_shake.account_id.map(to_string_value));
        let listen_port = SingularPtrField::from_option(hand_shake.listen_port.map(|v| {
            let mut res = UInt32Value::new();
            res.set_value(u32::from(v));
            res
        }));
        network_proto::Handshake {
            version: hand_shake.version,
            peer_id: hand_shake.peer_id.into(),
            peers_info: RepeatedField::from_iter(
                hand_shake.peers_info.into_iter().map(std::convert::Into::into),
            ),
            account_id,
            listen_port,
            ..Default::default()
        }
    }
}

'''
'''--- core/primitives/src/receipt.rs ---
use crate::transaction::{ReceiptTransaction, TransactionResult};

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct ReceiptInfo {
    pub receipt: ReceiptTransaction,
    pub block_index: u64,
    pub result: TransactionResult,
}

'''
'''--- core/primitives/src/rpc.rs ---
use crate::serialize::base_vec_format;
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Debug)]
pub struct ABCIQueryResponse {
    pub code: u32,
    pub log: String,
    pub info: String,
    pub index: i64,
    #[serde(with = "base_vec_format")]
    pub key: Vec<u8>,
    #[serde(with = "base_vec_format")]
    pub value: Vec<u8>,
    pub proof: Vec<ProofOp>,
    pub height: i64,
    pub codespace: String,
}

impl ABCIQueryResponse {
    pub fn account<T: serde::Serialize>(key: &str, value: T) -> Self {
        ABCIQueryResponse {
            code: 0,
            log: "exists".to_string(),
            info: "".to_string(),
            index: -1,
            key: key.as_bytes().to_vec(),
            value: serde_json::to_string(&value).unwrap().as_bytes().to_vec(),
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }

    pub fn result(key: &str, value: Vec<u8>, logs: Vec<String>) -> Self {
        ABCIQueryResponse {
            code: 0,
            log: logs.join("\n"),
            info: "".to_string(),
            index: -1,
            key: key.as_bytes().to_vec(),
            value,
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }

    pub fn result_err(key: &str, message: String, logs: Vec<String>) -> Self {
        ABCIQueryResponse {
            code: 1,
            log: logs.join("\n"),
            info: message,
            index: -1,
            key: key.as_bytes().to_vec(),
            value: vec![],
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct ProofOp {
    pub field_type: String,
    pub key: Vec<u8>,
    pub data: Vec<u8>,
}

'''
'''--- core/primitives/src/serialize.rs ---
use std::convert::TryFrom;
use std::io;

use serde::{de::DeserializeOwned, Serialize};

pub type EncodeResult = Result<Vec<u8>, io::Error>;
pub type DecodeResult<T> = Result<T, io::Error>;

// encode a type to byte array
pub trait Encode {
    fn encode(&self) -> EncodeResult;
}

// decode from byte array
pub trait Decode: Sized {
    fn decode(data: &[u8]) -> DecodeResult<Self>;
}

impl<T: Serialize> Encode for T {
    fn encode(&self) -> EncodeResult {
        bincode::serialize(&self)
            .map_err(|_| io::Error::new(io::ErrorKind::Other, "Failed to serialize"))
    }
}

impl<T> Decode for T
where
    T: DeserializeOwned,
{
    fn decode(data: &[u8]) -> DecodeResult<Self> {
        bincode::deserialize(data)
            .map_err(|_| io::Error::new(io::ErrorKind::Other, "Failed to deserialize"))
    }
}

pub fn to_base<T: ?Sized + AsRef<[u8]>>(input: &T) -> String {
    bs58::encode(input).into_string()
}

pub fn from_base(s: &str) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
    bs58::decode(s).into_vec().map_err(|err| err.into())
}

pub fn from_base_buf(s: &str, buffer: &mut Vec<u8>) -> Result<(), Box<dyn std::error::Error>> {
    match bs58::decode(s).into(buffer) {
        Ok(_) => Ok(()),
        Err(err) => Err(err.into()),
    }
}

pub trait BaseEncode {
    fn to_base(&self) -> String;
}

impl<T> BaseEncode for T
where
    for<'a> &'a T: Into<Vec<u8>>,
{
    fn to_base(&self) -> String {
        to_base(&self.into())
    }
}

pub trait BaseDecode: for<'a> TryFrom<&'a [u8], Error = Box<dyn std::error::Error>> {
    fn from_base(s: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let bytes = from_base(s)?;
        Self::try_from(&bytes).map_err(|err| err.into())
    }
}

pub mod base_format {
    use serde::de;
    use serde::{Deserialize, Deserializer, Serializer};

    use super::{BaseDecode, BaseEncode};

    pub fn serialize<T, S>(data: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        T: BaseEncode,
        S: Serializer,
    {
        serializer.serialize_str(&data.to_base())
    }

    pub fn deserialize<'de, T, D>(deserializer: D) -> Result<T, D::Error>
    where
        T: BaseDecode + std::fmt::Debug,
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        T::from_base(&s).map_err(|err| de::Error::custom(err.to_string()))
    }
}

pub mod base_vec_format {
    use serde::de;
    use serde::{Deserialize, Deserializer, Serializer};

    use super::{from_base, to_base};

    pub fn serialize<S>(data: &[u8], serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&to_base(data))
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<Vec<u8>, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        from_base(&s).map_err(|err| de::Error::custom(err.to_string()))
    }
}

pub mod u128_hex_format {
    use serde::de;
    use serde::{Deserialize, Deserializer, Serializer};

    pub fn serialize<S>(num: &u128, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&format!("{:X}", num))
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<u128, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        u128::from_str_radix(s.trim_start_matches("0x"), 16).map_err(de::Error::custom)
    }
}

'''
'''--- core/primitives/src/sharding.rs ---
use crate::crypto::group_signature::GroupSignature;
use crate::hash::{hash_struct, CryptoHash};
use crate::merkle::{merklize, MerklePath};
use crate::types::MerkleHash;
use reed_solomon_erasure::{ReedSolomon, Shard};

pub struct MainChainBlockHeader {
    pub prev_block_hash: CryptoHash,
    pub height: u64,
    pub signature: GroupSignature,
}

pub struct MainChainBlockBody {
    pub shard_blocks: Vec<ShardChunkHeader>,
}

pub struct MainChainLocalBlock {
    pub header: MainChainBlockHeader,
    pub body: Option<MainChainBlockBody>,
}

#[derive(Serialize, Clone)]
pub struct ShardChunkHeader {
    pub prev_block_hash: CryptoHash,
    pub encoded_merkle_root: CryptoHash,
    pub height: u64,
}

#[derive(Default, Serialize)]
pub struct EncodedShardChunkBody {
    pub parts: Vec<Option<Shard>>,
}

#[derive(Serialize)]
pub struct EncodedShardChunk {
    pub header: ShardChunkHeader,
    pub content: EncodedShardChunkBody,
}

impl EncodedShardChunkBody {
    pub fn num_fetched_parts(&self) -> usize {
        let mut fetched_parts: usize = 0;

        for part in self.parts.iter() {
            if part.is_some() {
                fetched_parts += 1;
            }
        }

        return fetched_parts;
    }

    pub fn reconstruct(&mut self, data_shards: usize, parity_shards: usize) {
        let rs = ReedSolomon::new(data_shards, parity_shards).unwrap();
        rs.reconstruct_shards(self.parts.as_mut_slice()).unwrap();
    }

    pub fn get_merkle_hash_and_paths(&self) -> (MerkleHash, Vec<MerklePath>) {
        merklize(&self.parts.iter().map(|x| x.as_ref().unwrap()).collect::<Vec<_>>())
    }
}

impl EncodedShardChunk {
    pub fn from_header(header: ShardChunkHeader, total_shards: usize) -> Self {
        Self { header, content: EncodedShardChunkBody { parts: vec![None; total_shards] } }
    }

    pub fn from_parts_and_metadata(
        prev_block_hash: CryptoHash,
        height: u64,
        parts: Vec<Option<Shard>>,

        data_shards: usize,
        parity_shards: usize,
    ) -> Self {
        let mut content = EncodedShardChunkBody { parts };
        content.reconstruct(data_shards, parity_shards);
        let (encoded_merkle_root, _) = content.get_merkle_hash_and_paths();
        let header = ShardChunkHeader { prev_block_hash, encoded_merkle_root, height };

        Self { header, content }
    }

    pub fn chunk_hash(&self) -> CryptoHash {
        hash_struct(self)
    }
}

'''
'''--- core/primitives/src/test_utils.rs ---
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

use exonum_sodiumoxide::crypto::sign::ed25519::{keypair_from_seed, Seed};
use log::LevelFilter;
use rand::SeedableRng;
use rand_xorshift::XorShiftRng;

use crate::crypto::aggregate_signature::{BlsPublicKey, BlsSecretKey};
use crate::crypto::signature::{PublicKey, SecretKey};
use crate::crypto::signer::{EDSigner, InMemorySigner};
use crate::transaction::{SignedTransaction, TransactionBody};

pub fn init_test_logger() {
    let _ = env_logger::Builder::new()
        .filter_module("tokio_reactor", LevelFilter::Info)
        .filter_module("tokio_core", LevelFilter::Info)
        .filter_module("hyper", LevelFilter::Info)
        .filter(None, LevelFilter::Debug)
        .try_init();
}

pub fn init_test_module_logger(module: &str) {
    let _ = env_logger::Builder::new()
        .filter_module("tokio_reactor", LevelFilter::Info)
        .filter_module("tokio_core", LevelFilter::Info)
        .filter_module("hyper", LevelFilter::Info)
        .filter_module("cranelift_wasm", LevelFilter::Warn)
        .filter_module(module, LevelFilter::Debug)
        .filter(None, LevelFilter::Info)
        .try_init();
}

pub fn init_integration_logger() {
    let _ = env_logger::Builder::new()
        .filter(None, LevelFilter::Info)
        .filter(Some("actix_web"), LevelFilter::Warn)
        .try_init();
}

pub fn calculate_hash<T: Hash>(t: &T) -> u64 {
    let mut s = DefaultHasher::new();
    t.hash(&mut s);
    s.finish()
}

pub fn get_key_pair_from_seed(seed_string: &str) -> (PublicKey, SecretKey) {
    let mut seed: [u8; 32] = [b' '; 32];
    let len = ::std::cmp::min(32, seed_string.len());
    seed[..len].copy_from_slice(&seed_string.as_bytes()[..len]);

    let (public_key, secret_key) = keypair_from_seed(&Seed(seed));
    (PublicKey(public_key), SecretKey(secret_key))
}

pub fn get_public_key_from_seed(seed_string: &str) -> PublicKey {
    get_key_pair_from_seed(seed_string).0
}

pub fn get_bls_key_pair_from_seed(seed_string: &str) -> (BlsPublicKey, BlsSecretKey) {
    let mut rng = XorShiftRng::seed_from_u64(calculate_hash(&seed_string));
    let bls_secret_key = BlsSecretKey::generate_from_rng(&mut rng);
    (bls_secret_key.get_public_key(), bls_secret_key)
}

impl InMemorySigner {
    pub fn from_seed(account_id: &str, seed_string: &str) -> Self {
        let (public_key, secret_key) = get_key_pair_from_seed(seed_string);
        InMemorySigner { account_id: account_id.to_string(), public_key, secret_key }
    }
}

impl TransactionBody {
    pub fn sign(self, signer: &dyn EDSigner) -> SignedTransaction {
        let signature = signer.sign(self.get_hash().as_ref());
        SignedTransaction::new(signature, self, Some(signer.public_key()))
    }
}

'''
'''--- core/primitives/src/transaction.rs ---
use std::borrow::Borrow;
use std::convert::{TryFrom, TryInto};
use std::fmt;
use std::hash::{Hash, Hasher};

use protobuf::well_known_types::BytesValue;
use protobuf::SingularPtrField;

use near_protos::receipt as receipt_proto;
use near_protos::signed_transaction as transaction_proto;
use near_protos::Message as ProtoMessage;

use crate::account::AccessKey;
use crate::crypto::signature::{verify, PublicKey, Signature, DEFAULT_SIGNATURE};
use crate::hash::{hash, CryptoHash};
use crate::logging;
use crate::serialize::base_format;
use crate::types::{AccountId, Balance, CallbackId, Nonce, ShardId, StructSignature};
use crate::utils::{account_to_shard_id, proto_to_result};

pub type LogEntry = String;

#[derive(Hash, PartialEq, Eq, Debug, Clone, Serialize, Deserialize)]
pub enum TransactionBody {
    CreateAccount(CreateAccountTransaction),
    DeployContract(DeployContractTransaction),
    FunctionCall(FunctionCallTransaction),
    SendMoney(SendMoneyTransaction),
    Stake(StakeTransaction),
    SwapKey(SwapKeyTransaction),
    AddKey(AddKeyTransaction),
    DeleteKey(DeleteKeyTransaction),
}

impl TransactionBody {
    pub fn send_money(nonce: Nonce, originator: &str, receiver: &str, amount: Balance) -> Self {
        TransactionBody::SendMoney(SendMoneyTransaction {
            nonce,
            originator: originator.to_string(),
            receiver: receiver.to_string(),
            amount,
        })
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct CreateAccountTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub new_account_id: AccountId,
    pub amount: Balance,
    pub public_key: Vec<u8>,
}

impl TryFrom<transaction_proto::CreateAccountTransaction> for CreateAccountTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::CreateAccountTransaction) -> Result<Self, Self::Error> {
        Ok(CreateAccountTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_account_id: t.new_account_id,
            amount: t.amount.unwrap_or_default().try_into()?,
            public_key: t.public_key,
        })
    }
}

impl From<CreateAccountTransaction> for transaction_proto::CreateAccountTransaction {
    fn from(t: CreateAccountTransaction) -> transaction_proto::CreateAccountTransaction {
        transaction_proto::CreateAccountTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_account_id: t.new_account_id,
            amount: SingularPtrField::some(t.amount.into()),
            public_key: t.public_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for CreateAccountTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CreateAccountTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("new_account_id", &format_args!("{}", &self.new_account_id))
            .field("amount", &format_args!("{}", &self.amount))
            .field("public_key", &format_args!("{}", logging::pretty_utf8(&self.public_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct DeployContractTransaction {
    pub nonce: Nonce,
    pub contract_id: AccountId,
    pub wasm_byte_array: Vec<u8>,
}

impl fmt::Debug for DeployContractTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("DeployContractTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("contract_id", &format_args!("{}", &self.contract_id))
            .field(
                "wasm_byte_array",
                &format_args!("{}", logging::pretty_utf8(&self.wasm_byte_array)),
            )
            .finish()
    }
}

impl From<transaction_proto::DeployContractTransaction> for DeployContractTransaction {
    fn from(t: transaction_proto::DeployContractTransaction) -> Self {
        DeployContractTransaction {
            nonce: t.nonce,
            contract_id: t.contract_id,
            wasm_byte_array: t.wasm_byte_array,
        }
    }
}

impl From<DeployContractTransaction> for transaction_proto::DeployContractTransaction {
    fn from(t: DeployContractTransaction) -> transaction_proto::DeployContractTransaction {
        transaction_proto::DeployContractTransaction {
            nonce: t.nonce,
            contract_id: t.contract_id,
            wasm_byte_array: t.wasm_byte_array,
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct FunctionCallTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub contract_id: AccountId,
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub amount: Balance,
}

impl TryFrom<transaction_proto::FunctionCallTransaction> for FunctionCallTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::FunctionCallTransaction) -> Result<Self, Self::Error> {
        Ok(FunctionCallTransaction {
            nonce: t.nonce,
            originator: t.originator,
            contract_id: t.contract_id,
            method_name: t.method_name,
            args: t.args,
            amount: t.amount.unwrap_or_default().try_into()?,
        })
    }
}

impl From<FunctionCallTransaction> for transaction_proto::FunctionCallTransaction {
    fn from(t: FunctionCallTransaction) -> Self {
        transaction_proto::FunctionCallTransaction {
            nonce: t.nonce,
            originator: t.originator,
            contract_id: t.contract_id,
            method_name: t.method_name,
            args: t.args,
            amount: SingularPtrField::some(t.amount.into()),
            ..Default::default()
        }
    }
}

impl fmt::Debug for FunctionCallTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("FunctionCallTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("contract_id", &format_args!("{}", &self.contract_id))
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("amount", &format_args!("{}", &self.amount))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub struct SendMoneyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub receiver: AccountId,
    pub amount: Balance,
}

impl TryFrom<transaction_proto::SendMoneyTransaction> for SendMoneyTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::SendMoneyTransaction) -> Result<Self, Self::Error> {
        Ok(SendMoneyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            receiver: t.receiver,
            amount: t.amount.unwrap_or_default().try_into()?,
        })
    }
}

impl From<SendMoneyTransaction> for transaction_proto::SendMoneyTransaction {
    fn from(t: SendMoneyTransaction) -> Self {
        transaction_proto::SendMoneyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            receiver: t.receiver,
            amount: SingularPtrField::some(t.amount.into()),
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub struct StakeTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub amount: Balance,
    pub public_key: String,
}

impl TryFrom<transaction_proto::StakeTransaction> for StakeTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::StakeTransaction) -> Result<Self, Self::Error> {
        Ok(StakeTransaction {
            nonce: t.nonce,
            originator: t.originator,
            amount: t.amount.unwrap_or_default().try_into()?,
            public_key: t.public_key,
        })
    }
}

impl From<StakeTransaction> for transaction_proto::StakeTransaction {
    fn from(t: StakeTransaction) -> transaction_proto::StakeTransaction {
        transaction_proto::StakeTransaction {
            nonce: t.nonce,
            originator: t.originator,
            amount: SingularPtrField::some(t.amount.into()),
            public_key: t.public_key,
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct SwapKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    // one of the current keys to the account that will be swapped out
    pub cur_key: Vec<u8>,
    pub new_key: Vec<u8>,
}

impl From<transaction_proto::SwapKeyTransaction> for SwapKeyTransaction {
    fn from(t: transaction_proto::SwapKeyTransaction) -> Self {
        SwapKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            new_key: t.new_key,
        }
    }
}

impl From<SwapKeyTransaction> for transaction_proto::SwapKeyTransaction {
    fn from(t: SwapKeyTransaction) -> transaction_proto::SwapKeyTransaction {
        transaction_proto::SwapKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            new_key: t.new_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for SwapKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("SwapKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("cur_key", &format_args!("{}", logging::pretty_utf8(&self.cur_key)))
            .field("new_key", &format_args!("{}", logging::pretty_utf8(&self.new_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct AddKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub new_key: Vec<u8>,
    pub access_key: Option<AccessKey>,
}

impl TryFrom<transaction_proto::AddKeyTransaction> for AddKeyTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::AddKeyTransaction) -> Result<Self, Self::Error> {
        Ok(AddKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_key: t.new_key,
            access_key: t
                .access_key
                .into_option()
                .map_or(Ok(None), |x| AccessKey::try_from(x).map(Some))?,
        })
    }
}

impl From<AddKeyTransaction> for transaction_proto::AddKeyTransaction {
    fn from(t: AddKeyTransaction) -> transaction_proto::AddKeyTransaction {
        transaction_proto::AddKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_key: t.new_key,
            access_key: SingularPtrField::from_option(t.access_key.map(std::convert::Into::into)),
            ..Default::default()
        }
    }
}

impl fmt::Debug for AddKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AddKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("new_key", &format_args!("{}", logging::pretty_utf8(&self.new_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct DeleteKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub cur_key: Vec<u8>,
}

impl From<transaction_proto::DeleteKeyTransaction> for DeleteKeyTransaction {
    fn from(t: transaction_proto::DeleteKeyTransaction) -> Self {
        DeleteKeyTransaction { nonce: t.nonce, originator: t.originator, cur_key: t.cur_key }
    }
}

impl From<DeleteKeyTransaction> for transaction_proto::DeleteKeyTransaction {
    fn from(t: DeleteKeyTransaction) -> transaction_proto::DeleteKeyTransaction {
        transaction_proto::DeleteKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for DeleteKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("DeleteKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("cur_key", &format_args!("{}", logging::pretty_utf8(&self.cur_key)))
            .finish()
    }
}

impl TransactionBody {
    pub fn get_nonce(&self) -> u64 {
        match self {
            TransactionBody::Stake(t) => t.nonce,
            TransactionBody::SendMoney(t) => t.nonce,
            TransactionBody::DeployContract(t) => t.nonce,
            TransactionBody::FunctionCall(t) => t.nonce,
            TransactionBody::CreateAccount(t) => t.nonce,
            TransactionBody::SwapKey(t) => t.nonce,
            TransactionBody::AddKey(t) => t.nonce,
            TransactionBody::DeleteKey(t) => t.nonce,
        }
    }

    pub fn get_originator(&self) -> AccountId {
        match self {
            TransactionBody::Stake(t) => t.originator.clone(),
            TransactionBody::SendMoney(t) => t.originator.clone(),
            TransactionBody::DeployContract(t) => t.contract_id.clone(),
            TransactionBody::FunctionCall(t) => t.originator.clone(),
            TransactionBody::CreateAccount(t) => t.originator.clone(),
            TransactionBody::SwapKey(t) => t.originator.clone(),
            TransactionBody::AddKey(t) => t.originator.clone(),
            TransactionBody::DeleteKey(t) => t.originator.clone(),
        }
    }

    /// Returns option contract_id for Mana and Gas accounting
    pub fn get_contract_id(&self) -> Option<AccountId> {
        match self {
            TransactionBody::CreateAccount(_) => None,
            TransactionBody::DeployContract(t) => Some(t.contract_id.clone()),
            TransactionBody::FunctionCall(t) => Some(t.contract_id.clone()),
            TransactionBody::SendMoney(t) => Some(t.receiver.clone()),
            TransactionBody::Stake(_) => None,
            TransactionBody::SwapKey(_) => None,
            TransactionBody::AddKey(_) => None,
            TransactionBody::DeleteKey(_) => None,
        }
    }

    pub fn get_hash(&self) -> CryptoHash {
        let bytes = match self.clone() {
            TransactionBody::CreateAccount(t) => {
                let proto: transaction_proto::CreateAccountTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::DeployContract(t) => {
                let proto: transaction_proto::DeployContractTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::FunctionCall(t) => {
                let proto: transaction_proto::FunctionCallTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::SendMoney(t) => {
                let proto: transaction_proto::SendMoneyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::Stake(t) => {
                let proto: transaction_proto::StakeTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::SwapKey(t) => {
                let proto: transaction_proto::SwapKeyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::AddKey(t) => {
                let proto: transaction_proto::AddKeyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::DeleteKey(t) => {
                let proto: transaction_proto::DeleteKeyTransaction = t.into();
                proto.write_to_bytes()
            }
        };
        let bytes = bytes.unwrap();
        hash(&bytes)
    }
}

#[derive(Eq, Debug, Clone, Serialize, Deserialize)]
pub struct SignedTransaction {
    pub body: TransactionBody,
    pub signature: StructSignature,
    // In case this TX uses AccessKey, it needs to provide the public_key
    pub public_key: Option<PublicKey>,
    hash: CryptoHash,
}

impl SignedTransaction {
    pub fn new(
        signature: StructSignature,
        body: TransactionBody,
        public_key: Option<PublicKey>,
    ) -> Self {
        let hash = body.get_hash();
        Self { signature, body, public_key, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }

    // this is for tests
    pub fn empty() -> SignedTransaction {
        let body = TransactionBody::SendMoney(SendMoneyTransaction {
            nonce: 0,
            originator: AccountId::default(),
            receiver: AccountId::default(),
            amount: 0,
        });
        SignedTransaction {
            signature: DEFAULT_SIGNATURE,
            body,
            public_key: None,
            hash: CryptoHash::default(),
        }
    }
}

impl Hash for SignedTransaction {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl PartialEq for SignedTransaction {
    fn eq(&self, other: &SignedTransaction) -> bool {
        self.hash == other.hash
            && self.signature == other.signature
            && self.public_key == other.public_key
    }
}

impl TryFrom<transaction_proto::SignedTransaction> for SignedTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(t: transaction_proto::SignedTransaction) -> Result<Self, Self::Error> {
        let bytes;
        let body = match t.body {
            Some(transaction_proto::SignedTransaction_oneof_body::create_account(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::CreateAccount(CreateAccountTransaction::try_from(t)?)
            }
            Some(transaction_proto::SignedTransaction_oneof_body::deploy_contract(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::DeployContract(DeployContractTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::function_call(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::FunctionCall(FunctionCallTransaction::try_from(t)?)
            }
            Some(transaction_proto::SignedTransaction_oneof_body::send_money(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::SendMoney(SendMoneyTransaction::try_from(t)?)
            }
            Some(transaction_proto::SignedTransaction_oneof_body::stake(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::Stake(StakeTransaction::try_from(t)?)
            }
            Some(transaction_proto::SignedTransaction_oneof_body::swap_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::SwapKey(SwapKeyTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::add_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::AddKey(AddKeyTransaction::try_from(t)?)
            }
            Some(transaction_proto::SignedTransaction_oneof_body::delete_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::DeleteKey(DeleteKeyTransaction::try_from(t)?)
            }
            None => return Err("No such transaction body type".into()),
        };
        let bytes = bytes.map_err(|e| format!("{}", e))?;
        let hash = hash(&bytes);
        let public_key: Option<PublicKey> = t
            .public_key
            .into_option()
            .map(|v| PublicKey::try_from(&v.value as &[u8]))
            .transpose()
            .map_err(|e| format!("{}", e))?;
        let signature: Signature =
            Signature::try_from(&t.signature as &[u8]).map_err(|e| format!("{}", e))?;
        Ok(SignedTransaction { body, signature, public_key, hash })
    }
}

impl From<SignedTransaction> for transaction_proto::SignedTransaction {
    fn from(tx: SignedTransaction) -> transaction_proto::SignedTransaction {
        let body = match tx.body {
            TransactionBody::CreateAccount(t) => {
                transaction_proto::SignedTransaction_oneof_body::create_account(t.into())
            }
            TransactionBody::DeployContract(t) => {
                transaction_proto::SignedTransaction_oneof_body::deploy_contract(t.into())
            }
            TransactionBody::FunctionCall(t) => {
                transaction_proto::SignedTransaction_oneof_body::function_call(t.into())
            }
            TransactionBody::SendMoney(t) => {
                transaction_proto::SignedTransaction_oneof_body::send_money(t.into())
            }
            TransactionBody::Stake(t) => {
                transaction_proto::SignedTransaction_oneof_body::stake(t.into())
            }
            TransactionBody::SwapKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::swap_key(t.into())
            }
            TransactionBody::AddKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::add_key(t.into())
            }
            TransactionBody::DeleteKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::delete_key(t.into())
            }
        };
        transaction_proto::SignedTransaction {
            body: Some(body),
            signature: tx.signature.as_ref().to_vec(),
            public_key: SingularPtrField::from_option(tx.public_key.map(|v| {
                let mut res = BytesValue::new();
                res.set_value((&v).into());
                res
            })),
            ..Default::default()
        }
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, Debug, PartialEq, Eq)]
pub enum ReceiptBody {
    NewCall(AsyncCall),
    Callback(CallbackResult),
    Refund(Balance),
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct AsyncCall {
    pub amount: Balance,
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub callback: Option<CallbackInfo>,
    pub refund_account: AccountId,
}

impl TryFrom<receipt_proto::AsyncCall> for AsyncCall {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: receipt_proto::AsyncCall) -> Result<Self, Self::Error> {
        Ok(AsyncCall {
            amount: proto.amount.unwrap_or_default().try_into()?,
            method_name: proto.method_name,
            args: proto.args,
            callback: proto.callback.into_option().map(std::convert::Into::into),
            refund_account: proto.refund_account,
        })
    }
}

impl From<AsyncCall> for receipt_proto::AsyncCall {
    fn from(call: AsyncCall) -> Self {
        receipt_proto::AsyncCall {
            amount: SingularPtrField::some(call.amount.into()),
            method_name: call.method_name,
            args: call.args,
            callback: SingularPtrField::from_option(call.callback.map(std::convert::Into::into)),
            refund_account: call.refund_account,
            ..Default::default()
        }
    }
}

impl AsyncCall {
    pub fn new(
        method_name: Vec<u8>,
        args: Vec<u8>,
        amount: Balance,
        refund_account: AccountId,
    ) -> Self {
        AsyncCall { amount, method_name, args, callback: None, refund_account }
    }
}

impl fmt::Debug for AsyncCall {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AsyncCall")
            .field("amount", &format_args!("{}", &self.amount))
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("callback", &self.callback)
            .field("refund_account", &self.refund_account)
            .finish()
    }
}

#[derive(Clone, Serialize, Deserialize)]
pub struct Callback {
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub results: Vec<Option<Vec<u8>>>,
    pub amount: Balance,
    pub callback: Option<CallbackInfo>,
    pub result_counter: usize,
    pub refund_account: AccountId,
}

impl Callback {
    pub fn new(
        method_name: Vec<u8>,
        args: Vec<u8>,
        amount: Balance,
        refund_account: AccountId,
    ) -> Self {
        Callback {
            method_name,
            args,
            results: vec![],
            amount,
            callback: None,
            result_counter: 0,
            refund_account,
        }
    }
}

impl fmt::Debug for Callback {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("Callback")
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("results", &format_args!("{}", logging::pretty_results(&self.results)))
            .field("amount", &format_args!("{}", &self.amount))
            .field("callback", &self.callback)
            .field("result_counter", &format_args!("{}", &self.result_counter))
            .field("refund_account", &self.refund_account)
            .finish()
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CallbackInfo {
    // callback id
    pub id: CallbackId,
    // index to write to
    pub result_index: usize,
    // receiver
    pub receiver: AccountId,
}

impl From<receipt_proto::CallbackInfo> for CallbackInfo {
    fn from(proto: receipt_proto::CallbackInfo) -> Self {
        CallbackInfo {
            id: proto.id,
            result_index: proto.result_index as usize,
            receiver: proto.receiver,
        }
    }
}

impl From<CallbackInfo> for receipt_proto::CallbackInfo {
    fn from(info: CallbackInfo) -> Self {
        receipt_proto::CallbackInfo {
            id: info.id,
            result_index: info.result_index as u64,
            receiver: info.receiver,
            ..Default::default()
        }
    }
}

impl CallbackInfo {
    pub fn new(id: CallbackId, result_index: usize, receiver: AccountId) -> Self {
        CallbackInfo { id, result_index, receiver }
    }
}

impl fmt::Debug for CallbackInfo {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CallbackInfo")
            .field("id", &format_args!("{}", logging::pretty_utf8(&self.id)))
            .field("result_index", &format_args!("{}", self.result_index))
            .field("receiver", &format_args!("{}", self.receiver))
            .finish()
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CallbackResult {
    // callback id
    pub info: CallbackInfo,
    // callback result
    pub result: Option<Vec<u8>>,
}

impl TryFrom<receipt_proto::CallbackResult> for CallbackResult {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: receipt_proto::CallbackResult) -> Result<Self, Self::Error> {
        match proto_to_result(proto.info) {
            Ok(info) => Ok(CallbackResult {
                info: info.into(),
                result: proto.result.into_option().map(|v| v.value),
            }),
            Err(e) => Err(e),
        }
    }
}

impl From<CallbackResult> for receipt_proto::CallbackResult {
    fn from(result: CallbackResult) -> Self {
        receipt_proto::CallbackResult {
            info: SingularPtrField::some(result.info.into()),
            result: SingularPtrField::from_option(result.result.map(|v| {
                let mut res = BytesValue::new();
                res.set_value(v);
                res
            })),
            ..Default::default()
        }
    }
}

impl CallbackResult {
    pub fn new(info: CallbackInfo, result: Option<Vec<u8>>) -> Self {
        CallbackResult { info, result }
    }
}

impl fmt::Debug for CallbackResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CallbackResult")
            .field("info", &self.info)
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone)]
pub struct ReceiptTransaction {
    // sender is the immediate predecessor
    pub originator: AccountId,
    pub receiver: AccountId,
    // nonce will be a hash
    pub nonce: CryptoHash,
    pub body: ReceiptBody,
}

impl TryFrom<receipt_proto::ReceiptTransaction> for ReceiptTransaction {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: receipt_proto::ReceiptTransaction) -> Result<Self, Self::Error> {
        let body = match proto.body {
            Some(receipt_proto::ReceiptTransaction_oneof_body::new_call(new_call)) => {
                new_call.try_into().map(ReceiptBody::NewCall)
            }
            Some(receipt_proto::ReceiptTransaction_oneof_body::callback(callback)) => {
                callback.try_into().map(ReceiptBody::Callback)
            }
            Some(receipt_proto::ReceiptTransaction_oneof_body::refund(refund)) => {
                Ok(ReceiptBody::Refund(refund.try_into()?))
            }
            None => Err("No such receipt body type".into()),
        };
        match body {
            Ok(body) => Ok(ReceiptTransaction {
                originator: proto.originator,
                receiver: proto.receiver,
                nonce: proto.nonce.try_into()?,
                body,
            }),
            Err(e) => Err(e),
        }
    }
}

impl From<ReceiptTransaction> for receipt_proto::ReceiptTransaction {
    fn from(t: ReceiptTransaction) -> Self {
        let body = match t.body {
            ReceiptBody::NewCall(new_call) => {
                receipt_proto::ReceiptTransaction_oneof_body::new_call(new_call.into())
            }
            ReceiptBody::Callback(callback) => {
                receipt_proto::ReceiptTransaction_oneof_body::callback(callback.into())
            }
            ReceiptBody::Refund(refund) => {
                receipt_proto::ReceiptTransaction_oneof_body::refund(refund.into())
            }
        };
        receipt_proto::ReceiptTransaction {
            originator: t.originator,
            receiver: t.receiver,
            nonce: t.nonce.into(),
            body: Some(body),
            ..Default::default()
        }
    }
}

impl Borrow<CryptoHash> for ReceiptTransaction {
    fn borrow(&self) -> &CryptoHash {
        &self.nonce
    }
}

impl ReceiptTransaction {
    pub fn new(
        originator: AccountId,
        receiver: AccountId,
        nonce: CryptoHash,
        body: ReceiptBody,
    ) -> Self {
        ReceiptTransaction { originator, receiver, nonce, body }
    }

    pub fn shard_id(&self) -> ShardId {
        account_to_shard_id(&self.receiver)
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.nonce
    }
}

#[derive(Hash, Debug, PartialEq, Eq, Clone, Serialize, Deserialize)]
pub enum TransactionStatus {
    Unknown,
    Completed,
    Failed,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub enum FinalTransactionStatus {
    Unknown,
    Started,
    Failed,
    Completed,
}

impl Default for FinalTransactionStatus {
    fn default() -> Self {
        FinalTransactionStatus::Unknown
    }
}

impl FinalTransactionStatus {
    pub fn to_code(&self) -> u64 {
        match self {
            FinalTransactionStatus::Completed => 0,
            FinalTransactionStatus::Failed => 1,
            FinalTransactionStatus::Started => 2,
            FinalTransactionStatus::Unknown => std::u64::MAX,
        }
    }
}

impl Default for TransactionStatus {
    fn default() -> Self {
        TransactionStatus::Unknown
    }
}

#[derive(PartialEq, Clone, Serialize, Deserialize, Default)]
pub struct TransactionResult {
    /// Transaction status.
    pub status: TransactionStatus,
    /// Logs from this transaction.
    pub logs: Vec<LogEntry>,
    /// Receipt ids generated by this transaction.
    pub receipts: Vec<CryptoHash>,
    /// Execution Result
    pub result: Option<Vec<u8>>,
}

impl fmt::Debug for TransactionResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("TransactionResult")
            .field("status", &self.status)
            .field("logs", &format_args!("{}", logging::pretty_vec(&self.logs)))
            .field("receipts", &format_args!("{}", logging::pretty_vec(&self.receipts)))
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

/// Logs for transaction or receipt with given hash.
#[derive(PartialEq, Clone, Serialize, Deserialize)]
pub struct TransactionLogs {
    #[serde(with = "base_format")]
    pub hash: CryptoHash,
    pub lines: Vec<LogEntry>,
    pub receipts: Vec<CryptoHash>,
    pub result: Option<Vec<u8>>,
}

impl fmt::Debug for TransactionLogs {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("TransactionLogs")
            .field("hash", &self.hash)
            .field("lines", &format_args!("{}", logging::pretty_vec(&self.lines)))
            .field("receipts", &format_args!("{}", logging::pretty_vec(&self.receipts)))
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

/// Result of transaction and all of subsequent the receipts.
#[derive(PartialEq, Clone, Serialize, Deserialize, Default)]
pub struct FinalTransactionResult {
    /// Status of the whole transaction and it's receipts.
    pub status: FinalTransactionStatus,
    /// Logs per transaction / receipt ids ordered in DFS manner.
    pub logs: Vec<TransactionLogs>,
}

impl fmt::Debug for FinalTransactionResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("FinalTransactionResult")
            .field("status", &self.status)
            .field("logs", &format_args!("{}", logging::pretty_vec(&self.logs)))
            .finish()
    }
}

impl FinalTransactionResult {
    pub fn final_log(&self) -> String {
        let mut logs = vec![];
        for log in &self.logs {
            for line in &log.lines {
                logs.push(line.clone());
            }
        }
        logs.join("\n")
    }

    pub fn last_result(&self) -> Vec<u8> {
        for log in self.logs.iter().rev() {
            if let Some(r) = &log.result {
                return r.clone();
            }
        }
        vec![]
    }
}

/// Represents address of certain transaction within block
#[derive(Debug, PartialEq, Clone, Serialize, Deserialize)]
pub struct TransactionAddress {
    /// Block hash
    pub block_hash: CryptoHash,
    /// Transaction index within the block. If it is a receipt,
    /// index is the index in the receipt block.
    pub index: usize,
    /// Only for receipts. The shard that the receipt
    /// block is supposed to go
    pub shard_id: Option<ShardId>,
}

pub fn verify_transaction_signature(
    transaction: &SignedTransaction,
    public_keys: &[PublicKey],
) -> bool {
    let hash = transaction.get_hash();
    let hash = hash.as_ref();
    public_keys.iter().any(|key| verify(&hash, &transaction.signature, &key))
}

#[cfg(test)]
mod tests {
    use crate::crypto::signature::{get_key_pair, sign};

    use super::*;

    #[test]
    fn test_verify_transaction() {
        let (public_key, private_key) = get_key_pair();
        let mut transaction = SignedTransaction::empty();
        transaction.signature = sign(&transaction.hash.as_ref(), &private_key);
        let (wrong_public_key, _) = get_key_pair();
        let valid_keys = vec![public_key, wrong_public_key];
        assert!(verify_transaction_signature(&transaction, &valid_keys));

        let invalid_keys = vec![wrong_public_key];
        assert!(!verify_transaction_signature(&transaction, &invalid_keys));
    }
}

'''
'''--- core/primitives/src/types.rs ---
use std::convert::{TryFrom, TryInto};

use protobuf::SingularPtrField;

use near_protos::types as types_proto;

// pub use crate::balance::Balance;
use crate::crypto::aggregate_signature::BlsSignature;
use crate::crypto::signature::{PublicKey, Signature};
use crate::hash::CryptoHash;

/// Public key alias. Used to human readable public key.
#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct ReadablePublicKey(pub String);
#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct ReadableBlsPublicKey(pub String);
/// Account identifier. Provides access to user's state.
pub type AccountId = String;
// TODO: Separate cryptographic hash from the hashmap hash.
/// Signature of a struct, i.e. signature of the struct's hash. It is a simple signature, not to be
/// confused with the multisig.
pub type StructSignature = Signature;
/// Hash used by a struct implementing the Merkle tree.
pub type MerkleHash = CryptoHash;
/// Validator identifier in current group.
pub type ValidatorId = usize;
/// Mask which validators participated in multi sign.
pub type ValidatorMask = Vec<bool>;
/// Part of the signature.
pub type PartialSignature = BlsSignature;
/// StorageUsage is used to count the amount of storage used by a contract.
pub type StorageUsage = u64;
/// StorageUsageChange is used to count the storage usage within a single contract call.
pub type StorageUsageChange = i64;
/// Nonce for transactions.
pub type Nonce = u64;

pub type BlockIndex = u64;

pub type ShardId = u32;

pub type Balance = u128;

pub type ReceiptId = Vec<u8>;
pub type CallbackId = Vec<u8>;

/// Epoch for rotating validators.
pub type Epoch = u64;

#[derive(Clone, Hash, PartialEq, Eq, Debug)]
pub enum PromiseId {
    Receipt(ReceiptId),
    Callback(CallbackId),
    Joiner(Vec<ReceiptId>),
}

#[derive(Debug, PartialEq, Eq, Serialize, Deserialize, Hash, Clone)]
pub enum BlockId {
    Best,
    Number(BlockIndex),
    Hash(CryptoHash),
}

/// Stores validator and its stake.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ValidatorStake {
    /// Account that stakes money.
    pub account_id: AccountId,
    /// ED25591 Public key of the proposed validator.
    pub public_key: PublicKey,
    /// Stake / weight of the validator.
    pub amount: Balance,
}

impl ValidatorStake {
    pub fn new(account_id: AccountId, public_key: PublicKey, amount: Balance) -> Self {
        ValidatorStake { account_id, public_key, amount }
    }
}

impl TryFrom<types_proto::ValidatorStake> for ValidatorStake {
    type Error = Box<dyn std::error::Error>;

    fn try_from(proto: types_proto::ValidatorStake) -> Result<Self, Self::Error> {
        Ok(ValidatorStake {
            account_id: proto.account_id,
            public_key: PublicKey::try_from(proto.public_key.as_str())?,
            amount: proto.amount.unwrap_or_default().try_into()?,
        })
    }
}

impl From<ValidatorStake> for types_proto::ValidatorStake {
    fn from(validator: ValidatorStake) -> Self {
        types_proto::ValidatorStake {
            account_id: validator.account_id,
            public_key: validator.public_key.to_string(),
            amount: SingularPtrField::some(validator.amount.into()),
            ..Default::default()
        }
    }
}

impl PartialEq for ValidatorStake {
    fn eq(&self, other: &Self) -> bool {
        self.account_id == other.account_id && self.public_key == other.public_key
    }
}

impl Eq for ValidatorStake {}

'''
'''--- core/primitives/src/utils.rs ---
use std::convert::{AsRef, TryFrom, TryInto};
use std::fmt;

use byteorder::{LittleEndian, WriteBytesExt};
use lazy_static::lazy_static;
use protobuf::{well_known_types::StringValue, SingularPtrField};
use regex::Regex;

use crate::crypto::signature::PublicKey;
use crate::hash::{hash, CryptoHash};
use crate::types::{AccountId, ShardId};

pub mod col {
    pub const ACCOUNT: &[u8] = &[0];
    pub const CALLBACK: &[u8] = &[1];
    pub const CODE: &[u8] = &[2];
    pub const ACCESS_KEY: &[u8] = &[3];
}

fn key_for_column_account_id(column: &[u8], account_key: &AccountId) -> Vec<u8> {
    let mut key = column.to_vec();
    key.append(&mut account_key.clone().into_bytes());
    key
}

pub fn key_for_account(account_key: &AccountId) -> Vec<u8> {
    key_for_column_account_id(col::ACCOUNT, account_key)
}

pub fn prefix_for_access_key(account_id: &AccountId) -> Vec<u8> {
    let mut key = key_for_column_account_id(col::ACCESS_KEY, account_id);
    key.extend_from_slice(col::ACCESS_KEY);
    key
}

pub fn key_for_access_key(account_id: &AccountId, public_key: &PublicKey) -> Vec<u8> {
    let mut key = key_for_column_account_id(col::ACCESS_KEY, account_id);
    key.extend_from_slice(col::ACCESS_KEY);
    key.extend_from_slice(public_key.as_ref());
    key
}

pub fn key_for_code(account_key: &AccountId) -> Vec<u8> {
    key_for_column_account_id(col::CODE, account_key)
}

pub fn key_for_callback(id: &[u8]) -> Vec<u8> {
    let mut key = col::CALLBACK.to_vec();
    key.extend_from_slice(id);
    key
}

pub fn create_nonce_with_nonce(base: &CryptoHash, salt: u64) -> CryptoHash {
    let mut nonce: Vec<u8> = base.as_ref().to_owned();
    nonce.append(&mut index_to_bytes(salt));
    hash(&nonce)
}

pub fn index_to_bytes(index: u64) -> Vec<u8> {
    let mut bytes = vec![];
    bytes.write_u64::<LittleEndian>(index).expect("writing to bytes failed");
    bytes
}

#[allow(unused)]
pub fn account_to_shard_id(account_id: &AccountId) -> ShardId {
    // TODO: change to real sharding
    0
}

lazy_static! {
    static ref VALID_ACCOUNT_ID: Regex = Regex::new(r"^[a-z0-9@._\-]{5,32}$").unwrap();
}

/// const does not allow function call, so have to resort to this
pub fn system_account() -> AccountId {
    "system".to_string()
}

pub fn is_valid_account_id(account_id: &AccountId) -> bool {
    if *account_id == system_account() {
        return false;
    }
    VALID_ACCOUNT_ID.is_match(account_id)
}

pub fn to_string_value(s: String) -> StringValue {
    let mut res = StringValue::new();
    res.set_value(s);
    res
}

pub fn proto_to_result<T>(proto: SingularPtrField<T>) -> Result<T, Box<dyn std::error::Error>> {
    proto.into_option().ok_or_else(|| "Bad Proto".into())
}

pub fn proto_to_type<T, U>(proto: SingularPtrField<T>) -> Result<U, Box<dyn std::error::Error>>
where
    U: TryFrom<T, Error = Box<dyn std::error::Error>>,
{
    proto_to_result(proto).and_then(TryInto::try_into)
}

/// A wrapper around Option<T> that provides native Display trait.
/// Simplifies propagating automatic Display trait on parent structs.
pub struct DisplayOption<T>(pub Option<T>);

impl<T: fmt::Display> fmt::Display for DisplayOption<T> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self.0 {
            Some(ref v) => write!(f, "Some({})", v),
            None => write!(f, "None"),
        }
    }
}

impl<T> DisplayOption<T> {
    pub fn into(self) -> Option<T> {
        self.0
    }
}

impl<T> AsRef<Option<T>> for DisplayOption<T> {
    fn as_ref(&self) -> &Option<T> {
        &self.0
    }
}

impl<T: fmt::Display> From<Option<T>> for DisplayOption<T> {
    fn from(o: Option<T>) -> Self {
        DisplayOption(o)
    }
}

'''
'''--- core/protos/Cargo.toml ---
[package]
name = "near-protos"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"
build = "build.rs"

[dependencies]
protobuf = { version = "2.2.4", features = ["with-bytes"] }
byteorder = "1.2"

[build-dependencies]
protos-autogen = { path = "../../protos/builder" }

'''
'''--- core/protos/README.md ---
## Development
`.proto` files are under the `protos` directory. To add/delete protos, one also needs to change the include macro at the beginning of `src/lib.rs`. 

For example, if `example.proto` is added to `protos`, `include!(concat!(env!("OUT_DIR"), "/example.rs"))` needs to be added to `src/lib.rs`.
'''
'''--- core/protos/build.rs ---
use protos_autogen;

fn main() {
    protos_autogen::autogenerate();
}

'''
'''--- core/protos/src/lib.rs ---
include!(concat!(env!("OUT_DIR"), "/access_key.rs"));
include!(concat!(env!("OUT_DIR"), "/chain.rs"));
include!(concat!(env!("OUT_DIR"), "/network.rs"));
include!(concat!(env!("OUT_DIR"), "/receipt.rs"));
include!(concat!(env!("OUT_DIR"), "/signed_transaction.rs"));
include!(concat!(env!("OUT_DIR"), "/types.rs"));
include!(concat!(env!("OUT_DIR"), "/uint128.rs"));

pub use protobuf::Message;

pub mod uint128_ext;
'''
'''--- core/protos/src/uint128_ext.rs ---
use std::convert::TryFrom;
use std::io::Cursor;

use byteorder::LittleEndian;
use byteorder::ReadBytesExt;

use crate::uint128 as uint128_proto;

impl TryFrom<uint128_proto::Uint128> for u128 {
    type Error = Box<dyn std::error::Error>;

    fn try_from(value: uint128_proto::Uint128) -> Result<Self, Self::Error> {
        let len = value.number.len();
        if len > 16 {
            return Err(format!("uint128 proto has {} bytes, but expected up to 16.", len).into());
        }
        let mut rdr = Cursor::new(value.number);
        rdr.read_uint128::<LittleEndian>(len).map_err(|err| err.into())
    }
}

impl From<u128> for uint128_proto::Uint128 {
    fn from(value: u128) -> Self {
        uint128_proto::Uint128 {
            number: value.to_le_bytes().to_vec(),
            cached_size: Default::default(),
            unknown_fields: Default::default(),
        }
    }
}

'''
'''--- core/store/Cargo.toml ---
[package]
name = "near-store"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
byteorder = "1.2"
elastic-array = { version = "0.10" }
kvdb = "0.1"
kvdb-memorydb = "0.1"
kvdb-rocksdb = "0.1.3"
serde = "1.0"
serde_derive = "1.0"
cached = { git = "https://github.com/nearprotocol/cached", rev = "7e472eddef68607e344d5a106a0e6705d92e55be" }
log = "0.4"

near-primitives = { path = "../primitives" }

[dev-dependencies]
hex-literal = "0.1.1"
bencher = "0.1.5"
rand = "0.6"

[[bench]]
name = "trie_bench"
harness = false

'''
'''--- core/store/benches/trie_bench.rs ---
#[macro_use]
extern crate bencher;

use bencher::Bencher;
use rand::random;

use near_store::test_utils::create_trie;
use near_store::Trie;

fn rand_bytes() -> Vec<u8> {
    (0..10).map(|_| random::<u8>()).collect()
}

fn trie_lookup(bench: &mut Bencher) {
    let trie = create_trie();
    let root = Trie::empty_root();
    let mut changes = vec![];
    for _ in 0..100 {
        changes.push((rand_bytes(), Some(rand_bytes())));
    }
    let other_changes = changes.clone();
    let (state_update, root) = trie.update(&root, changes.drain(..)).unwrap().into(trie.clone()).unwrap();
    state_update.commit().expect("Failed to commit");

    bench.iter(|| {
        for _ in 0..1 {
            for (key, _) in other_changes.iter() {
                trie.get(&root, &key).unwrap();
            }
        }
    });
}

fn trie_update(bench: &mut Bencher) {
    let trie = create_trie();
    let root = Trie::empty_root();
    let mut changes = vec![];
    for _ in 0..100 {
        changes.push((rand_bytes(), Some(rand_bytes())));
    }

    bench.iter(|| {
        let mut this_changes = changes.clone();
        let _ = trie.update(&root, this_changes.drain(..));
    });
}

benchmark_group!(benches, trie_lookup, trie_update);
benchmark_main!(benches);

'''
'''--- core/store/src/lib.rs ---
use std::sync::Arc;
use std::{fmt, io};

use cached::{Cached, SizedCache};
pub use kvdb::DBValue;
use kvdb::{DBOp, DBTransaction, KeyValueDB};
use kvdb_rocksdb::{Database, DatabaseConfig};
use serde::de::DeserializeOwned;
use serde::Serialize;

use near_primitives::serialize::{to_base, Decode, Encode};

pub use crate::trie::{
    update::TrieUpdate, update::TrieUpdateIterator, Trie, TrieChanges, TrieIterator,
    WrappedTrieChanges,
};

pub mod test_utils;
mod trie;

pub const COL_BLOCK_MISC: Option<u32> = Some(0);
pub const COL_BLOCK: Option<u32> = Some(1);
pub const COL_BLOCK_HEADER: Option<u32> = Some(2);
pub const COL_BLOCK_INDEX: Option<u32> = Some(3);
pub const COL_STATE: Option<u32> = Some(4);
pub const COL_STATE_REF: Option<u32> = Some(5);
pub const COL_TRANSACTION_RESULT: Option<u32> = Some(6);
pub const COL_RECEIPTS: Option<u32> = Some(7);
pub const COL_PEERS: Option<u32> = Some(8);
pub const COL_VALIDATORS: Option<u32> = Some(9);
const NUM_COLS: u32 = 10;

pub struct Store {
    storage: Arc<dyn KeyValueDB>,
}

impl Store {
    pub fn new(storage: Arc<dyn KeyValueDB>) -> Store {
        Store { storage }
    }

    pub fn get(&self, column: Option<u32>, key: &[u8]) -> Result<Option<Vec<u8>>, io::Error> {
        self.storage.get(column, key).map(|a| a.map(|b| b.to_vec()))
    }

    pub fn get_ser<T: Decode + DeserializeOwned>(
        &self,
        column: Option<u32>,
        key: &[u8],
    ) -> Result<Option<T>, io::Error> {
        match self.storage.get(column, key) {
            Ok(Some(bytes)) => match Decode::decode(bytes.as_ref()) {
                Ok(result) => Ok(Some(result)),
                Err(e) => Err(e),
            },
            Ok(None) => Ok(None),
            Err(e) => Err(e),
        }
    }

    pub fn exists(&self, column: Option<u32>, key: &[u8]) -> Result<bool, io::Error> {
        self.storage.get(column, key).map(|value| value.is_some())
    }

    pub fn store_update(&self) -> StoreUpdate {
        StoreUpdate::new(self.storage.clone())
    }

    pub fn iter<'a>(
        &'a self,
        column: Option<u32>,
    ) -> Box<dyn Iterator<Item = (Box<[u8]>, Box<[u8]>)> + 'a> {
        self.storage.iter(column)
    }
}

/// Keeps track of current changes to the database and can commit all of them to the database.
pub struct StoreUpdate {
    storage: Arc<dyn KeyValueDB>,
    transaction: DBTransaction,
    /// Optionally has reference to the trie to clear cache on the commit.
    trie: Option<Arc<Trie>>,
}

impl StoreUpdate {
    pub fn new(storage: Arc<dyn KeyValueDB>) -> Self {
        let transaction = storage.transaction();
        StoreUpdate { storage, transaction, trie: None }
    }

    pub fn new_with_trie(storage: Arc<dyn KeyValueDB>, trie: Arc<Trie>) -> Self {
        let transaction = storage.transaction();
        StoreUpdate { storage, transaction, trie: Some(trie) }
    }

    pub fn set(&mut self, column: Option<u32>, key: &[u8], value: &[u8]) {
        self.transaction.put(column, key, value)
    }

    pub fn set_ser<T: Encode>(
        &mut self,
        column: Option<u32>,
        key: &[u8],
        value: &T,
    ) -> Result<(), io::Error> {
        let data = Encode::encode(value)?;
        self.set(column, key, &data);
        Ok(())
    }

    pub fn delete(&mut self, column: Option<u32>, key: &[u8]) {
        self.transaction.delete(column, key);
    }

    /// Merge another store update into this one.
    pub fn merge(&mut self, other: StoreUpdate) {
        if self.trie.is_none() {
            if let Some(trie) = other.trie {
                self.trie = Some(trie);
            }
        }
        self.merge_transaction(other.transaction);
    }

    /// Merge DB Transaction.
    pub fn merge_transaction(&mut self, transaction: DBTransaction) {
        for op in transaction.ops {
            match op {
                DBOp::Insert { col, key, value } => self.transaction.put(col, &key, &value),
                DBOp::Delete { col, key } => self.transaction.delete(col, &key),
            }
        }
    }

    pub fn commit(self) -> Result<(), io::Error> {
        if let Some(trie) = self.trie {
            trie.update_cache(&self.transaction)?;
        }
        self.storage.write(self.transaction)
    }
}

impl fmt::Debug for StoreUpdate {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "Store Update {{\n")?;
        for op in self.transaction.ops.iter() {
            match op {
                DBOp::Insert { col, key, value: _ } => {
                    write!(f, "  + {:?} {}\n", col, to_base(key))?
                }
                DBOp::Delete { col, key } => write!(f, "  - {:?} {}\n", col, to_base(key))?,
            }
        }
        write!(f, "}}\n")
    }
}

pub fn read_with_cache<'a, T: Decode + DeserializeOwned + 'a>(
    storage: &Store,
    col: Option<u32>,
    cache: &'a mut SizedCache<Vec<u8>, T>,
    key: &[u8],
) -> io::Result<Option<&'a T>> {
    let key_vec = key.to_vec();
    if cache.cache_get(&key_vec).is_some() {
        return Ok(Some(cache.cache_get(&key_vec).unwrap()));
    }
    if let Some(result) = storage.get_ser(col, key)? {
        cache.cache_set(key.to_vec(), result);
        return Ok(cache.cache_get(&key_vec));
    }
    Ok(None)
}

pub fn create_store(path: &str) -> Arc<Store> {
    let db_config = DatabaseConfig::with_columns(Some(NUM_COLS));
    let db = Arc::new(Database::open(&db_config, path).expect("Failed to open the database"));
    Arc::new(Store::new(db))
}

/// Reads an object from Trie.
pub fn get<T: DeserializeOwned>(state_update: &TrieUpdate, key: &[u8]) -> Option<T> {
    state_update.get(key).and_then(|data| Decode::decode(&data).ok())
}

/// Writes an object into Trie.
pub fn set<T: Serialize>(state_update: &mut TrieUpdate, key: Vec<u8>, value: &T) {
    value.encode().ok().map(|data| state_update.set(key, DBValue::from_vec(data))).or_else(|| None);
}

'''
'''--- core/store/src/test_utils.rs ---
use std::sync::Arc;

use crate::trie::Trie;
use crate::{Store, NUM_COLS};

/// Creates an in-memory database.
pub fn create_test_store() -> Arc<Store> {
    let db = Arc::new(kvdb_memorydb::create(NUM_COLS));
    Arc::new(Store::new(db))
}

/// Creates a Trie using an in-memory database.
pub fn create_trie() -> Arc<Trie> {
    let store = create_test_store();
    Arc::new(Trie::new(store))
}

'''
'''--- core/store/src/trie/mod.rs ---
use std::collections::HashMap;
use std::convert::TryFrom;
use std::fmt;
use std::io::{Cursor, ErrorKind, Read, Write};
use std::sync::{Arc, Mutex};

use byteorder::{LittleEndian, ReadBytesExt, WriteBytesExt};
use cached::{Cached, SizedCache};
pub use kvdb::DBValue;
use kvdb::{DBOp, DBTransaction};
use log::error;

use near_primitives::hash::{hash, CryptoHash};

use crate::{Store, StoreUpdate, COL_STATE};

use self::nibble_slice::NibbleSlice;

mod nibble_slice;
pub mod update;

const POISONED_LOCK_ERR: &str = "The lock was poisoned.";

#[derive(Clone, Hash, Debug, Copy)]
struct StorageHandle(usize);

#[derive(Clone, Hash, Debug)]
enum NodeHandle {
    InMemory(StorageHandle),
    Hash(CryptoHash),
}

#[derive(Clone, Hash, Debug)]
enum TrieNode {
    /// Null trie node. Could be an empty root or an empty branch entry.
    Empty,
    /// Key and value of the leaf node.
    Leaf(Vec<u8>, Vec<u8>),
    /// Branch of 16 possible children and value if key ends here.
    Branch(Box<[Option<NodeHandle>; 16]>, Option<Vec<u8>>),
    /// Key and child of extension.
    Extension(Vec<u8>, NodeHandle),
}

impl TrieNode {
    fn new(rc_node: RawTrieNode) -> TrieNode {
        match rc_node {
            RawTrieNode::Leaf(key, value) => TrieNode::Leaf(key, value),
            RawTrieNode::Branch(children, value) => {
                let mut new_children: Box<[Option<NodeHandle>; 16]> = Default::default();
                for i in 0..children.len() {
                    new_children[i] = children[i].map(NodeHandle::Hash);
                }
                TrieNode::Branch(new_children, value)
            }
            RawTrieNode::Extension(key, child) => TrieNode::Extension(key, NodeHandle::Hash(child)),
        }
    }

    fn print(
        &self,
        f: &mut dyn fmt::Write,
        memory: &NodesStorage,
        spaces: &mut String,
    ) -> fmt::Result {
        match self {
            TrieNode::Empty => {
                write!(f, "{}Empty", spaces)?;
            }
            TrieNode::Leaf(key, _value) => {
                let slice = NibbleSlice::from_encoded(key);
                write!(f, "{}Leaf({:?}, val)", spaces, slice.0)?;
            }
            TrieNode::Branch(children, value) => {
                writeln!(
                    f,
                    "{}Branch({}){{",
                    spaces,
                    if value.is_some() { "Some" } else { "None" }
                )?;
                spaces.push_str(" ");
                for (idx, child) in
                    children.iter().enumerate().filter(|(_idx, child)| child.is_some())
                {
                    let child = child.as_ref().unwrap();
                    write!(f, "{}{:01x}->", spaces, idx)?;
                    match child {
                        NodeHandle::Hash(hash) => {
                            write!(f, "{}", hash)?;
                        }
                        NodeHandle::InMemory(handle) => {
                            let child = memory.node_ref(*handle);
                            child.print(f, memory, spaces)?;
                        }
                    }
                    writeln!(f)?;
                }
                spaces.remove(spaces.len() - 1);
                write!(f, "{}}}", spaces)?;
            }
            TrieNode::Extension(key, child) => {
                let slice = NibbleSlice::from_encoded(key);
                writeln!(f, "{}Extension({:?})", spaces, slice)?;
                spaces.push_str(" ");
                match child {
                    NodeHandle::Hash(hash) => {
                        write!(f, "{}{}", spaces, hash)?;
                    }
                    NodeHandle::InMemory(handle) => {
                        let child = memory.node_ref(*handle);
                        child.print(f, memory, spaces)?;
                    }
                }
                writeln!(f)?;
                spaces.remove(spaces.len() - 1);
            }
        }
        Ok(())
    }

    #[allow(dead_code)]
    fn deep_to_string(&self, memory: &NodesStorage) -> String {
        let mut buf = String::new();
        self.print(&mut buf, memory, &mut "".to_string()).expect("printing failed");
        buf
    }
}

#[derive(Debug, Eq, PartialEq)]
#[allow(clippy::large_enum_variant)]
enum RawTrieNode {
    Leaf(Vec<u8>, Vec<u8>),
    Branch([Option<CryptoHash>; 16], Option<Vec<u8>>),
    Extension(Vec<u8>, CryptoHash),
}

struct NodesStorage {
    nodes: Vec<Option<TrieNode>>,
    refcount_changes: HashMap<CryptoHash, (Vec<u8>, i32)>,
}

const INVALID_STORAGE_HANDLE: &str = "invalid storage handle";

/// Local mutable storage that owns node objects.
impl NodesStorage {
    fn new() -> NodesStorage {
        NodesStorage { nodes: Vec::new(), refcount_changes: HashMap::new() }
    }

    fn destroy(&mut self, handle: StorageHandle) -> TrieNode {
        self.nodes
            .get_mut(handle.0)
            .expect(INVALID_STORAGE_HANDLE)
            .take()
            .expect(INVALID_STORAGE_HANDLE)
    }

    fn node_ref(&self, handle: StorageHandle) -> &TrieNode {
        self.nodes
            .get(handle.0)
            .expect(INVALID_STORAGE_HANDLE)
            .as_ref()
            .expect(INVALID_STORAGE_HANDLE)
    }

    fn store(&mut self, node: TrieNode) -> StorageHandle {
        self.nodes.push(Some(node));
        StorageHandle(self.nodes.len() - 1)
    }

    fn store_at(&mut self, handle: StorageHandle, node: TrieNode) {
        debug_assert!(self.nodes.get(handle.0).expect(INVALID_STORAGE_HANDLE).is_none());
        self.nodes[handle.0] = Some(node);
    }
}

const LEAF_NODE: u8 = 0;
const BRANCH_NODE_NO_VALUE: u8 = 1;
const BRANCH_NODE_WITH_VALUE: u8 = 2;
const EXTENSION_NODE: u8 = 3;

#[derive(Debug, Eq, PartialEq)]
struct RcTrieNode {
    data: RawTrieNode,
    rc: u32,
}

fn decode_children(cursor: &mut Cursor<&[u8]>) -> Result<[Option<CryptoHash>; 16], std::io::Error> {
    let mut children: [Option<CryptoHash>; 16] = Default::default();
    let bitmap = cursor.read_u16::<LittleEndian>()?;
    let mut pos = 1;
    for child in &mut children {
        if bitmap & pos != 0 {
            let mut arr = [0; 32];
            cursor.read_exact(&mut arr)?;
            *child = Some(CryptoHash::try_from(&arr[..]).unwrap());
        }
        pos <<= 1;
    }
    Ok(children)
}

impl RawTrieNode {
    fn encode_into(&self, out: &mut Vec<u8>) -> Result<(), std::io::Error> {
        let mut cursor = Cursor::new(out);
        match &self {
            RawTrieNode::Leaf(key, value) => {
                cursor.write_u8(LEAF_NODE)?;
                cursor.write_u32::<LittleEndian>(key.len() as u32)?;
                cursor.write_all(&key)?;
                cursor.write_u32::<LittleEndian>(value.len() as u32)?;
                cursor.write_all(&value)?;
            }
            RawTrieNode::Branch(children, value) => {
                if let Some(bytes) = value {
                    cursor.write_u8(BRANCH_NODE_WITH_VALUE)?;
                    cursor.write_u32::<LittleEndian>(bytes.len() as u32)?;
                    cursor.write_all(&bytes)?;
                } else {
                    cursor.write_u8(BRANCH_NODE_NO_VALUE)?;
                }
                let mut bitmap: u16 = 0;
                let mut pos: u16 = 1;
                for child in children.iter() {
                    if child.is_some() {
                        bitmap |= pos
                    }
                    pos <<= 1;
                }
                cursor.write_u16::<LittleEndian>(bitmap)?;
                for child in children.iter() {
                    if let Some(hash) = child {
                        cursor.write_all(hash.as_ref())?;
                    }
                }
            }
            RawTrieNode::Extension(key, child) => {
                cursor.write_u8(EXTENSION_NODE)?;
                cursor.write_u32::<LittleEndian>(key.len() as u32)?;
                cursor.write_all(&key)?;
                cursor.write_all(child.as_ref())?;
            }
        }
        Ok(())
    }

    #[allow(dead_code)]
    fn encode(&self) -> Result<Vec<u8>, std::io::Error> {
        let mut out = Vec::new();
        self.encode_into(&mut out)?;
        Ok(out)
    }

    fn decode(bytes: &[u8]) -> Result<Self, std::io::Error> {
        let mut cursor = Cursor::new(bytes);
        match cursor.read_u8()? {
            LEAF_NODE => {
                let key_length = cursor.read_u32::<LittleEndian>()?;
                let mut key = vec![0; key_length as usize];
                cursor.read_exact(&mut key)?;
                let value_length = cursor.read_u32::<LittleEndian>()?;
                let mut value = vec![0; value_length as usize];
                cursor.read_exact(&mut value)?;
                Ok(RawTrieNode::Leaf(key, value))
            }
            BRANCH_NODE_NO_VALUE => {
                let children = decode_children(&mut cursor)?;
                Ok(RawTrieNode::Branch(children, None))
            }
            BRANCH_NODE_WITH_VALUE => {
                let value_length = cursor.read_u32::<LittleEndian>()?;
                let mut value = vec![0; value_length as usize];
                cursor.read_exact(&mut value)?;
                let children = decode_children(&mut cursor)?;
                Ok(RawTrieNode::Branch(children, Some(value)))
            }
            EXTENSION_NODE => {
                let key_length = cursor.read_u32::<LittleEndian>()?;
                let mut key = vec![0; key_length as usize];
                cursor.read_exact(&mut key)?;
                let mut child = vec![0; 32];
                cursor.read_exact(&mut child)?;
                Ok(RawTrieNode::Extension(key, CryptoHash::try_from(child).unwrap()))
            }
            _ => Err(std::io::Error::new(std::io::ErrorKind::Other, "Wrong type")),
        }
    }
}

impl RcTrieNode {
    fn encode(data: &[u8], rc: u32) -> Result<Vec<u8>, std::io::Error> {
        let mut cursor = Cursor::new(Vec::with_capacity(data.len() + 4));
        cursor.write_all(data)?;
        cursor.write_u32::<LittleEndian>(rc)?;
        Ok(cursor.into_inner())
    }

    fn decode_raw(bytes: &[u8]) -> Result<(&[u8], u32), std::io::Error> {
        let mut cursor = Cursor::new(&bytes[bytes.len() - 4..]);
        let rc = cursor.read_u32::<LittleEndian>()?;
        Ok((&bytes[..bytes.len() - 4], rc))
    }

    fn decode(bytes: &[u8]) -> Result<(RawTrieNode, u32), std::io::Error> {
        let node = RawTrieNode::decode(&bytes[..bytes.len() - 4])?;
        let mut cursor = Cursor::new(&bytes[bytes.len() - 4..]);
        let rc = cursor.read_u32::<LittleEndian>()?;
        Ok((node, rc))
    }
}

pub struct TrieCachingStorage {
    store: Arc<Store>,
    cache: Arc<Mutex<SizedCache<CryptoHash, Option<Vec<u8>>>>>,
}

impl TrieCachingStorage {
    fn new(store: Arc<Store>) -> TrieCachingStorage {
        // TODO defend from huge values in cache
        TrieCachingStorage { store, cache: Arc::new(Mutex::new(SizedCache::with_size(10000))) }
    }

    fn retrieve_raw_bytes(&self, hash: &CryptoHash) -> Option<(Vec<u8>)> {
        let mut guard = self.cache.lock().expect(POISONED_LOCK_ERR);
        if let Some(val) = (*guard).cache_get(hash) {
            val.clone()
        } else {
            let result = if let Ok(Some(bytes)) = self.store.get(COL_STATE, hash.as_ref()) {
                Some(bytes)
            } else {
                None
            };
            (*guard).cache_set(*hash, result.clone());
            result
        }
    }

    fn retrieve_rc(&self, hash: &CryptoHash) -> Option<u32> {
        let mut guard = self.cache.lock().expect(POISONED_LOCK_ERR);
        if let Some(val) = (*guard).cache_get(hash) {
            val.as_ref().map(|vec| RcTrieNode::decode_raw(&vec).expect("failed to decode").1)
        } else {
            let val = if let Ok(Some(bytes)) = self.store.get(COL_STATE, hash.as_ref()) {
                Some(bytes)
            } else {
                None
            };
            let rc =
                val.as_ref().map(|vec| RcTrieNode::decode_raw(&vec).expect("failed to decode").1);
            (*guard).cache_set(*hash, val);
            rc
        }
    }

    fn retrieve_node(&self, hash: &CryptoHash) -> Result<TrieNode, String> {
        if let Some(bytes) = self.retrieve_raw_bytes(hash) {
            match RcTrieNode::decode(&bytes) {
                Ok((value, _)) => Ok(TrieNode::new(value)),
                Err(_) => Err(format!("Failed to decode node {}", hash)),
            }
        } else {
            Err(format!("Node {} not found in storage", hash))
        }
    }
}

pub struct Trie {
    storage: TrieCachingStorage,
}

///
/// TrieChanges stores delta for refcount.
/// Multiple versions of the state work the following way:
///         __changes1___state1
/// state0 /
///        \__changes2___state2
///
/// To store state0, state1 and state2, apply insertions from changes1 and changes2
///
/// Then, to discard state2, apply insertions from changes2 as deletions
///
/// Then, to discard state0, apply deletions from changes1.
/// deleting state0 while both state1 and state2 exist is not possible.
/// Applying deletions from changes1 while state2 exists makes accessing state2 invalid.
///
///
/// create a fork -> apply insertions
/// resolve a fork -> apply opposite of insertions
/// discard old parent which has no forks from it -> apply deletions
///
/// Having old_root and values in deletions allows to apply TrieChanges in reverse
///
/// StoreUpdate are the changes from current state refcount to refcount + delta.
pub struct TrieChanges {
    #[allow(dead_code)]
    old_root: CryptoHash,
    pub new_root: CryptoHash,
    insertions: Vec<(CryptoHash, Vec<u8>, u32)>, // key, value, rc
    deletions: Vec<(CryptoHash, Vec<u8>, u32)>,  // key, value, rc
}

impl TrieChanges {
    pub fn empty(old_root: CryptoHash) -> Self {
        TrieChanges { old_root, new_root: old_root, insertions: vec![], deletions: vec![] }
    }
    pub fn insertions_into(
        &self,
        trie: Arc<Trie>,
        store_update: &mut StoreUpdate,
    ) -> Result<(), Box<dyn std::error::Error>> {
        store_update.trie = Some(trie.clone());
        for (key, value, rc) in self.insertions.iter() {
            let storage_rc = trie.storage.retrieve_rc(&key).unwrap_or_default();
            let bytes = RcTrieNode::encode(&value, storage_rc + rc)?;
            store_update.set(COL_STATE, key.as_ref(), &bytes);
        }
        Ok(())
    }

    pub fn deletions_into(
        &self,
        trie: Arc<Trie>,
        store_update: &mut StoreUpdate,
    ) -> Result<(), Box<dyn std::error::Error>> {
        store_update.trie = Some(trie.clone());
        for (key, value, rc) in self.deletions.iter() {
            let storage_rc = trie.storage.retrieve_rc(&key).unwrap_or_default();
            assert!(*rc <= storage_rc);
            if *rc < storage_rc {
                let bytes = RcTrieNode::encode(&value, storage_rc - rc)?;
                store_update.set(COL_STATE, key.as_ref(), &bytes);
            } else {
                store_update.delete(COL_STATE, key.as_ref());
            }
        }
        Ok(())
    }

    pub fn into(
        self,
        trie: Arc<Trie>,
    ) -> Result<(StoreUpdate, CryptoHash), Box<dyn std::error::Error>> {
        let mut store_update =
            StoreUpdate::new_with_trie(trie.storage.store.storage.clone(), trie.clone());
        self.insertions_into(trie.clone(), &mut store_update)?;
        self.deletions_into(trie.clone(), &mut store_update)?;
        Ok((store_update, self.new_root))
    }
}

pub struct WrappedTrieChanges {
    trie: Arc<Trie>,
    trie_changes: TrieChanges,
}

impl WrappedTrieChanges {
    pub fn new(trie: Arc<Trie>, trie_changes: TrieChanges) -> Self {
        WrappedTrieChanges { trie, trie_changes }
    }

    pub fn insertions_into(
        &self,
        store_update: &mut StoreUpdate,
    ) -> Result<(), Box<dyn std::error::Error>> {
        self.trie_changes.insertions_into(self.trie.clone(), store_update)
    }

    pub fn deletions_into(
        &self,
        store_update: &mut StoreUpdate,
    ) -> Result<(), Box<dyn std::error::Error>> {
        self.trie_changes.deletions_into(self.trie.clone(), store_update)
    }
}

enum FlattenNodesCrumb {
    Entering,
    AtChild(Box<[Option<CryptoHash>; 16]>, usize),
    Exiting,
}

impl Trie {
    pub fn new(store: Arc<Store>) -> Self {
        Trie { storage: TrieCachingStorage::new(store) }
    }

    pub fn empty_root() -> CryptoHash {
        CryptoHash::default()
    }

    fn move_node_to_mutable(
        &self,
        memory: &mut NodesStorage,
        hash: &CryptoHash,
    ) -> Result<StorageHandle, Box<dyn std::error::Error>> {
        if *hash == Trie::empty_root() {
            Ok(memory.store(TrieNode::Empty))
        } else {
            if let Some(bytes) = self.storage.retrieve_raw_bytes(hash) {
                match RcTrieNode::decode(&bytes) {
                    Ok((value, _)) => {
                        let result = memory.store(TrieNode::new(value));
                        memory
                            .refcount_changes
                            .entry(*hash)
                            .or_insert_with(|| {
                                (
                                    RcTrieNode::decode_raw(&bytes)
                                        .expect("calling after decode()")
                                        .0
                                        .to_vec(),
                                    0,
                                )
                            })
                            .1 -= 1;
                        Ok(result)
                    }
                    Err(_) => Err(format!("Failed to decode node {}", hash).into()),
                }
            } else {
                Err(format!("Node {} not found in storage", hash).into())
            }
        }
    }

    fn retrieve_node(&self, hash: &CryptoHash) -> Result<TrieNode, String> {
        if *hash == Trie::empty_root() {
            return Ok(TrieNode::Empty);
        }
        self.storage.retrieve_node(hash)
    }

    fn lookup(&self, root: &CryptoHash, mut key: NibbleSlice) -> Result<Option<Vec<u8>>, String> {
        let mut hash = *root;

        loop {
            if hash == Trie::empty_root() {
                return Ok(None);
            }
            let node = match self.storage.retrieve_raw_bytes(&hash) {
                Some(bytes) => RcTrieNode::decode(&bytes)
                    .map(|trie_node| trie_node.0)
                    .map_err(|_| "Failed to decode node".to_string())?,
                _ => return Err(format!("Node {} not found in storage", hash)),
            };

            match node {
                RawTrieNode::Leaf(existing_key, value) => {
                    return Ok(if NibbleSlice::from_encoded(&existing_key).0 == key {
                        Some(value)
                    } else {
                        None
                    });
                }
                RawTrieNode::Extension(existing_key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&existing_key).0;
                    if key.starts_with(&existing_key) {
                        hash = child;
                        key = key.mid(existing_key.len());
                    } else {
                        return Ok(None);
                    }
                }
                RawTrieNode::Branch(mut children, value) => {
                    if key.is_empty() {
                        return Ok(value);
                    } else {
                        match children[key.at(0) as usize].take() {
                            Some(x) => {
                                hash = x;
                                key = key.mid(1);
                            }
                            None => return Ok(None),
                        }
                    }
                }
            };
        }
    }

    pub fn get(&self, root: &CryptoHash, key: &[u8]) -> Option<Vec<u8>> {
        let key = NibbleSlice::new(key);
        match self.lookup(root, key) {
            Ok(value) => value,
            Err(err) => {
                error!(target: "store", "Failed to lookup key={:?} for root={:?}: {}", key, root, err);
                None
            }
        }
    }

    /// Allowed to mutate nodes in NodesStorage.
    /// Insert while holding StorageHandles to NodesStorage is unsafe
    fn insert(
        &self,
        memory: &mut NodesStorage,
        node: StorageHandle,
        partial: NibbleSlice,
        value: Vec<u8>,
    ) -> Result<StorageHandle, Box<dyn std::error::Error>> {
        let root_handle = node;
        let mut handle = node;
        let mut value = Some(value);
        let mut partial = partial;

        loop {
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    let leaf_node =
                        TrieNode::Leaf(partial.encoded(true).into_vec(), value.take().unwrap());
                    memory.store_at(handle, leaf_node);
                    break;
                }
                TrieNode::Branch(mut children, existing_value) => {
                    // If the key ends here, store the value in branch's value.
                    if partial.is_empty() {
                        memory.store_at(
                            handle,
                            TrieNode::Branch(children, Some(value.take().unwrap())),
                        );
                        break;
                    } else {
                        let idx = partial.at(0) as usize;
                        let child = children[idx].take();
                        let child = match child {
                            Some(NodeHandle::Hash(hash)) => {
                                self.move_node_to_mutable(memory, &hash)?
                            }
                            Some(NodeHandle::InMemory(handle)) => handle,
                            None => memory.store(TrieNode::Empty),
                        };
                        children[idx] = Some(NodeHandle::InMemory(child));
                        memory.store_at(handle, TrieNode::Branch(children, existing_value));
                        handle = child;
                        partial = partial.mid(1);
                        continue;
                    }
                }
                TrieNode::Leaf(key, existing_value) => {
                    let existing_key = NibbleSlice::from_encoded(&key).0;
                    let common_prefix = partial.common_prefix(&existing_key);
                    if common_prefix == existing_key.len() && common_prefix == partial.len() {
                        // Equivalent leaf.
                        memory.store_at(handle, TrieNode::Leaf(key, value.take().unwrap()));
                        break;
                    } else if common_prefix == 0 {
                        let mut children = Default::default();
                        let branch_node = if existing_key.is_empty() {
                            TrieNode::Branch(children, Some(existing_value))
                        } else {
                            let idx = existing_key.at(0) as usize;
                            let new_leaf = TrieNode::Leaf(
                                existing_key.mid(1).encoded(true).into_vec(),
                                existing_value,
                            );
                            children[idx] = Some(NodeHandle::InMemory(memory.store(new_leaf)));
                            TrieNode::Branch(children, None)
                        };
                        memory.store_at(handle, branch_node);
                        continue;
                    } else if common_prefix == existing_key.len() {
                        let child = memory
                            .store(TrieNode::Branch(Default::default(), Some(existing_value)));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                existing_key.encoded(false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    } else {
                        // Partially shared prefix: convert to leaf and call recursively to add a branch.
                        let child = memory.store(TrieNode::Leaf(
                            existing_key.mid(common_prefix).encoded(true).into_vec(),
                            existing_value,
                        ));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                partial.encoded_leftmost(common_prefix, false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    }
                }
                TrieNode::Extension(key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&key).0;
                    let common_prefix = partial.common_prefix(&existing_key);
                    if common_prefix == 0 {
                        let idx = existing_key.at(0) as usize;
                        let mut children: Box<[Option<NodeHandle>; 16]> = Default::default();
                        children[idx] = if existing_key.len() == 1 {
                            Some(child)
                        } else {
                            let ext_node = TrieNode::Extension(
                                existing_key.mid(1).encoded(false).into_vec(),
                                child,
                            );
                            Some(NodeHandle::InMemory(memory.store(ext_node)))
                        };
                        let branch_node = TrieNode::Branch(children, None);
                        memory.store_at(handle, branch_node);
                        continue;
                    } else if common_prefix == existing_key.len() {
                        let child = match child {
                            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
                            NodeHandle::InMemory(handle) => handle,
                        };
                        memory.store_at(
                            handle,
                            TrieNode::Extension(key, NodeHandle::InMemory(child)),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    } else {
                        // Partially shared prefix: covert to shorter extension and recursively add a branch.
                        let child = memory.store(TrieNode::Extension(
                            existing_key.mid(common_prefix).encoded(false).into_vec(),
                            child,
                        ));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                existing_key.encoded_leftmost(common_prefix, false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    }
                }
            }
        }
        Ok(root_handle)
    }

    /// Deletes a node from the trie which has key = `partial` given root node.
    /// Returns (new root node or `None` if this was the node to delete, was it updated).
    /// While deleting keeps track of all the removed / updated nodes in `death_row`.
    fn delete(
        &self,
        memory: &mut NodesStorage,
        node: StorageHandle,
        partial: NibbleSlice,
    ) -> Result<(StorageHandle, bool), Box<dyn std::error::Error>> {
        let mut handle = node;
        let mut partial = partial;
        let root_node = handle;
        let mut path: Vec<StorageHandle> = Vec::new();
        let deleted: bool;
        loop {
            path.push(handle);
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    memory.store_at(handle, TrieNode::Empty);
                    deleted = false;
                    break;
                }
                TrieNode::Leaf(key, value) => {
                    if NibbleSlice::from_encoded(&key).0 == partial {
                        memory.store_at(handle, TrieNode::Empty);
                        deleted = true;
                        break;
                    } else {
                        memory.store_at(handle, TrieNode::Leaf(key, value));
                        deleted = false;
                        break;
                    }
                }
                TrieNode::Branch(mut children, value) => {
                    if partial.is_empty() {
                        if children.iter().filter(|&x| x.is_some()).count() == 0 {
                            memory.store_at(handle, TrieNode::Empty);
                            deleted = value.is_some();
                            break;
                        } else {
                            memory.store_at(handle, TrieNode::Branch(children, None));
                            deleted = value.is_some();
                            break;
                        }
                    } else {
                        let idx = partial.at(0) as usize;
                        if let Some(node_or_hash) = children[idx].take() {
                            let node = match node_or_hash {
                                NodeHandle::Hash(hash) => {
                                    self.move_node_to_mutable(memory, &hash)?
                                }
                                NodeHandle::InMemory(node) => node,
                            };
                            children[idx] = Some(NodeHandle::InMemory(node));
                            memory.store_at(handle, TrieNode::Branch(children, value));
                            handle = node;
                            partial = partial.mid(1);
                            continue;
                        } else {
                            memory.store_at(handle, TrieNode::Branch(children, value));
                            deleted = false;
                            break;
                        }
                    }
                }
                TrieNode::Extension(key, child) => {
                    let (common_prefix, existing_len) = {
                        let existing_key = NibbleSlice::from_encoded(&key).0;
                        (existing_key.common_prefix(&partial), existing_key.len())
                    };
                    if common_prefix == existing_len {
                        let node = match child {
                            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
                            NodeHandle::InMemory(node) => node,
                        };
                        memory
                            .store_at(handle, TrieNode::Extension(key, NodeHandle::InMemory(node)));
                        partial = partial.mid(existing_len);
                        handle = node;
                        continue;
                    } else {
                        memory.store_at(handle, TrieNode::Extension(key, child));
                        deleted = false;
                        break;
                    }
                }
            }
        }
        self.fix_nodes(memory, path)?;
        Ok((root_node, deleted))
    }

    fn fix_nodes(
        &self,
        memory: &mut NodesStorage,
        path: Vec<StorageHandle>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        for handle in path.into_iter().rev() {
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    memory.store_at(handle, TrieNode::Empty);
                }
                TrieNode::Leaf(key, value) => {
                    memory.store_at(handle, TrieNode::Leaf(key, value));
                }
                TrieNode::Branch(mut children, value) => {
                    children.iter_mut().for_each(|child| {
                        if let Some(NodeHandle::InMemory(h)) = child {
                            if let TrieNode::Empty = memory.node_ref(*h) {
                                *child = None
                            }
                        }
                    });
                    let num_children = children.iter().filter(|&x| x.is_some()).count();
                    if num_children == 0 {
                        if let Some(value) = value {
                            let empty = NibbleSlice::new(&[]).encoded(true).into_vec();
                            memory.store_at(handle, TrieNode::Leaf(empty, value));
                        } else {
                            memory.store_at(handle, TrieNode::Empty);
                        }
                    } else if num_children == 1 && value.is_none() {
                        // Branch with one child becomes extension
                        // Extension followed by leaf becomes leaf
                        // Extension followed by extension becomes extension
                        let idx =
                            children.iter().enumerate().find(|(_i, x)| x.is_some()).unwrap().0;
                        let key = NibbleSlice::new(&[(idx << 4) as u8])
                            .encoded_leftmost(1, false)
                            .into_vec();
                        self.fix_extension_node(
                            memory,
                            handle,
                            key,
                            children[idx].take().unwrap(),
                        )?;
                    } else {
                        memory.store_at(handle, TrieNode::Branch(children, value));
                    }
                }
                TrieNode::Extension(key, child) => {
                    self.fix_extension_node(memory, handle, key, child)?;
                }
            }
        }
        Ok(())
    }

    fn fix_extension_node(
        &self,
        memory: &mut NodesStorage,
        handle: StorageHandle,
        key: Vec<u8>,
        child: NodeHandle,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let child = match child {
            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
            NodeHandle::InMemory(h) => h,
        };
        match memory.destroy(child) {
            TrieNode::Empty => {
                memory.store_at(handle, TrieNode::Empty);
            }
            TrieNode::Leaf(child_key, value) => {
                let key = NibbleSlice::from_encoded(&key)
                    .0
                    .merge_encoded(&NibbleSlice::from_encoded(&child_key).0, true)
                    .into_vec();
                memory.store_at(handle, TrieNode::Leaf(key, value));
            }
            TrieNode::Branch(children, value) => {
                memory.store_at(child, TrieNode::Branch(children, value));
                memory.store_at(handle, TrieNode::Extension(key, NodeHandle::InMemory(child)));
            }
            TrieNode::Extension(child_key, child_child) => {
                let key = NibbleSlice::from_encoded(&key)
                    .0
                    .merge_encoded(&NibbleSlice::from_encoded(&child_key).0, false)
                    .into_vec();
                memory.store_at(handle, TrieNode::Extension(key, child_child));
            }
        }
        Ok(())
    }

    fn flatten_nodes(
        old_root: &CryptoHash,
        memory: NodesStorage,
        node: StorageHandle,
    ) -> Result<TrieChanges, Box<dyn std::error::Error>> {
        let mut stack: Vec<(StorageHandle, FlattenNodesCrumb)> = Vec::new();
        stack.push((node, FlattenNodesCrumb::Entering));
        let mut last_hash = CryptoHash::default();
        let mut buffer: Vec<u8> = Vec::new();
        let mut memory = memory;
        while let Some((node, position)) = stack.pop() {
            let raw_node = match memory.node_ref(node) {
                TrieNode::Empty => {
                    last_hash = Trie::empty_root();
                    continue;
                }
                TrieNode::Branch(children, value) => match position {
                    FlattenNodesCrumb::Entering => {
                        let new_children: [Option<CryptoHash>; 16] = Default::default();
                        stack.push((node, FlattenNodesCrumb::AtChild(Box::new(new_children), 0)));
                        continue;
                    }
                    FlattenNodesCrumb::AtChild(mut new_children, mut i) => {
                        if i > 0 && children[i - 1].is_some() {
                            new_children[i - 1] = Some(last_hash);
                        }
                        while i < 16 {
                            match children[i].as_ref() {
                                Some(NodeHandle::InMemory(_)) => {
                                    break;
                                }
                                Some(NodeHandle::Hash(hash)) => {
                                    new_children[i] = Some(*hash);
                                }
                                None => {}
                            }
                            i += 1;
                        }
                        if i < 16 {
                            match children[i].as_ref() {
                                Some(NodeHandle::InMemory(child_node)) => {
                                    stack.push((
                                        node,
                                        FlattenNodesCrumb::AtChild(new_children, i + 1),
                                    ));
                                    stack.push((*child_node, FlattenNodesCrumb::Entering));
                                    continue;
                                }
                                _ => unreachable!(),
                            }
                        }
                        RawTrieNode::Branch(*new_children, value.clone())
                    }
                    FlattenNodesCrumb::Exiting => unreachable!(),
                },
                TrieNode::Extension(key, child) => match position {
                    FlattenNodesCrumb::Entering => match child {
                        NodeHandle::InMemory(child) => {
                            stack.push((node, FlattenNodesCrumb::Exiting));
                            stack.push((*child, FlattenNodesCrumb::Entering));
                            continue;
                        }
                        NodeHandle::Hash(hash) => RawTrieNode::Extension(key.clone(), *hash),
                    },
                    FlattenNodesCrumb::Exiting => RawTrieNode::Extension(key.clone(), last_hash),
                    _ => unreachable!(),
                },
                TrieNode::Leaf(key, value) => RawTrieNode::Leaf(key.clone(), value.clone()),
            };
            raw_node.encode_into(&mut buffer)?;
            let key = hash(&buffer);

            let (_value, rc) =
                memory.refcount_changes.entry(key).or_insert_with(|| (buffer.clone(), 0));
            *rc += 1;
            buffer.clear();
            last_hash = key;
        }
        let (insertions, deletions) =
            Trie::convert_to_insertions_and_deletions(memory.refcount_changes);
        Ok(TrieChanges { old_root: *old_root, new_root: last_hash, insertions, deletions })
    }

    fn convert_to_insertions_and_deletions(
        changes: HashMap<CryptoHash, (Vec<u8>, i32)>,
    ) -> ((Vec<(CryptoHash, Vec<u8>, u32)>, Vec<(CryptoHash, Vec<u8>, u32)>)) {
        let mut deletions = Vec::new();
        let mut insertions = Vec::new();
        for (key, (value, rc)) in changes.into_iter() {
            if rc > 0 {
                insertions.push((key, value, rc as u32));
            } else if rc < 0 {
                deletions.push((key, value, (-rc) as u32));
            }
        }
        // Sort so that trie changes have unique representation
        insertions.sort();
        deletions.sort();
        (insertions, deletions)
    }

    pub fn update<I>(
        &self,
        root: &CryptoHash,
        changes: I,
    ) -> Result<TrieChanges, Box<dyn std::error::Error>>
    where
        I: Iterator<Item = (Vec<u8>, Option<Vec<u8>>)>,
    {
        let mut memory = NodesStorage::new();
        let mut root_node = self.move_node_to_mutable(&mut memory, root)?;
        for (key, value) in changes {
            let key = NibbleSlice::new(&key);
            match value {
                Some(arr) => {
                    root_node = self.insert(&mut memory, root_node, key, arr)?;
                }
                None => {
                    root_node = match self.delete(&mut memory, root_node, key)? {
                        (value, _) => value,
                    };
                }
            }
        }
        Trie::flatten_nodes(root, memory, root_node)
    }

    pub fn iter<'a>(
        &'a self,
        root: &CryptoHash,
    ) -> Result<TrieIterator<'a>, Box<dyn std::error::Error>> {
        TrieIterator::new(self, root)
    }

    #[inline]
    pub fn update_cache(&self, transaction: &DBTransaction) -> std::io::Result<()> {
        let mut guard = self.storage.cache.lock().expect(POISONED_LOCK_ERR);
        for op in &transaction.ops {
            match op {
                DBOp::Insert { col, ref key, ref value } if *col == COL_STATE => (*guard)
                    .cache_set(
                        CryptoHash::try_from(&key[..]).map_err(|_| {
                            std::io::Error::new(ErrorKind::Other, "Key is always a hash")
                        })?,
                        Some(value.to_vec()),
                    ),
                DBOp::Delete { col, ref key } if *col == COL_STATE => (*guard).cache_set(
                    CryptoHash::try_from(&key[..]).map_err(|_| {
                        std::io::Error::new(ErrorKind::Other, "Key is always a hash")
                    })?,
                    None,
                ),
                _ => {}
            }
        }
        Ok(())
    }
}

pub type TrieItem<'a> = Result<(Vec<u8>, DBValue), String>;

#[derive(Clone, Eq, PartialEq, Debug)]
enum CrumbStatus {
    Entering,
    At,
    AtChild(usize),
    Exiting,
}

#[derive(Debug)]
struct Crumb {
    node: TrieNode,
    status: CrumbStatus,
}

impl Crumb {
    fn increment(&mut self) {
        self.status = match (&self.status, &self.node) {
            (_, &TrieNode::Empty) => CrumbStatus::Exiting,
            (&CrumbStatus::Entering, _) => CrumbStatus::At,
            (&CrumbStatus::At, &TrieNode::Branch(_, _)) => CrumbStatus::AtChild(0),
            (&CrumbStatus::AtChild(x), &TrieNode::Branch(_, _)) if x < 15 => {
                CrumbStatus::AtChild(x + 1)
            }
            _ => CrumbStatus::Exiting,
        }
    }
}

pub struct TrieIterator<'a> {
    trie: &'a Trie,
    trail: Vec<Crumb>,
    key_nibbles: Vec<u8>,
    root: CryptoHash,
}

impl<'a> TrieIterator<'a> {
    #![allow(clippy::new_ret_no_self)]
    /// Create a new iterator.
    pub fn new(trie: &'a Trie, root: &CryptoHash) -> Result<Self, Box<dyn std::error::Error>> {
        let mut r = TrieIterator {
            trie,
            trail: Vec::with_capacity(8),
            key_nibbles: Vec::with_capacity(64),
            root: *root,
        };
        if let Ok(node) = trie.retrieve_node(root) {
            r.descend_into_node(&node);
            return Ok(r);
        }
        Err(format!("Root hash {} not found", root).into())
    }

    /// Position the iterator on the first element with key => `key`.
    pub fn seek(&mut self, key: &[u8]) -> Result<(), String> {
        self.trail.clear();
        self.key_nibbles.clear();
        let mut hash = NodeHandle::Hash(self.root);
        let mut key = NibbleSlice::new(key);
        loop {
            let node = match hash {
                NodeHandle::Hash(hash) => self.trie.retrieve_node(&hash)?,
                NodeHandle::InMemory(_node) => unreachable!(),
            };
            let copy_node = node.clone();
            match node {
                TrieNode::Empty => return Ok(()),
                TrieNode::Leaf(leaf_key, _) => {
                    let existing_key = NibbleSlice::from_encoded(&leaf_key).0;
                    self.trail.push(Crumb {
                        status: if existing_key >= key {
                            CrumbStatus::Entering
                        } else {
                            CrumbStatus::Exiting
                        },
                        node: copy_node,
                    });
                    self.key_nibbles.extend(existing_key.iter());
                    return Ok(());
                }
                TrieNode::Branch(mut children, _) => {
                    if key.is_empty() {
                        self.trail.push(Crumb { status: CrumbStatus::Entering, node: copy_node });
                        return Ok(());
                    } else {
                        let idx = key.at(0) as usize;
                        self.trail.push(Crumb {
                            status: CrumbStatus::AtChild(idx as usize),
                            node: copy_node,
                        });
                        self.key_nibbles.push(key.at(0));
                        if let Some(child) = children[idx].take() {
                            hash = child;
                            key = key.mid(1);
                        } else {
                            return Ok(());
                        }
                    }
                }
                TrieNode::Extension(ext_key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&ext_key).0;
                    if key.starts_with(&existing_key) {
                        self.trail.push(Crumb { status: CrumbStatus::At, node: copy_node });
                        self.key_nibbles.extend(existing_key.iter());
                        hash = child;
                        key = key.mid(existing_key.len());
                    } else {
                        self.descend_into_node(&copy_node);
                        return Ok(());
                    }
                }
            }
        }
    }

    fn descend_into_node(&mut self, node: &TrieNode) {
        self.trail.push(Crumb { status: CrumbStatus::Entering, node: node.clone() });
        match &self.trail.last().expect("Just pushed item").node {
            TrieNode::Leaf(ref key, _) | TrieNode::Extension(ref key, _) => {
                let key = NibbleSlice::from_encoded(key).0;
                self.key_nibbles.extend(key.iter());
            }
            _ => {}
        }
    }

    fn key(&self) -> Vec<u8> {
        let mut result = <Vec<u8>>::with_capacity(self.key_nibbles.len() / 2);
        for i in (1..self.key_nibbles.len()).step_by(2) {
            result.push(self.key_nibbles[i - 1] * 16 + self.key_nibbles[i]);
        }
        result
    }
}

impl<'a> Iterator for TrieIterator<'a> {
    type Item = TrieItem<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        enum IterStep {
            Continue,
            PopTrail,
            Descend(Result<Box<TrieNode>, String>),
        }
        loop {
            let iter_step = {
                self.trail.last_mut()?.increment();
                let b = self.trail.last().expect("Trail finished.");
                match (b.status.clone(), &b.node) {
                    (CrumbStatus::Exiting, n) => {
                        match n {
                            TrieNode::Leaf(ref key, _) | TrieNode::Extension(ref key, _) => {
                                let existing_key = NibbleSlice::from_encoded(&key).0;
                                let l = self.key_nibbles.len();
                                self.key_nibbles.truncate(l - existing_key.len());
                            }
                            TrieNode::Branch(_, _) => {
                                self.key_nibbles.pop();
                            }
                            _ => {}
                        }
                        IterStep::PopTrail
                    }
                    (CrumbStatus::At, TrieNode::Branch(_, value)) => {
                        if let Some(value) = value {
                            return Some(Ok((self.key(), DBValue::from_slice(value))));
                        } else {
                            IterStep::Continue
                        }
                    }
                    (CrumbStatus::At, TrieNode::Leaf(_, value)) => {
                        return Some(Ok((self.key(), DBValue::from_slice(value))));
                    }
                    (CrumbStatus::At, TrieNode::Extension(_, child)) => {
                        let next_node = match child {
                            NodeHandle::Hash(hash) => self.trie.retrieve_node(hash).map(Box::new),
                            NodeHandle::InMemory(_node) => unreachable!(),
                        };
                        IterStep::Descend(next_node)
                    }
                    (CrumbStatus::AtChild(i), TrieNode::Branch(children, _))
                        if children[i].is_some() =>
                    {
                        match i {
                            0 => self.key_nibbles.push(0),
                            i => {
                                *self.key_nibbles.last_mut().expect("Pushed child value before") =
                                    i as u8
                            }
                        }
                        let next_node = match &children[i] {
                            Some(NodeHandle::Hash(hash)) => {
                                self.trie.retrieve_node(&hash).map(Box::new)
                            }
                            Some(NodeHandle::InMemory(_node)) => unreachable!(),
                            _ => panic!("Wrapped with is_some()"),
                        };
                        IterStep::Descend(next_node)
                    }
                    (CrumbStatus::AtChild(i), TrieNode::Branch(_, _)) => {
                        if i == 0 {
                            self.key_nibbles.push(0);
                        }
                        IterStep::Continue
                    }
                    _ => panic!("Should never see Entering or AtChild without a Branch here."),
                }
            };
            match iter_step {
                IterStep::PopTrail => {
                    self.trail.pop();
                }
                IterStep::Descend(Ok(node)) => self.descend_into_node(&node),
                IterStep::Descend(Err(e)) => return Some(Err(e)),
                IterStep::Continue => {}
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use rand::seq::SliceRandom;
    use rand::{rngs::ThreadRng, Rng};

    use crate::test_utils::{create_test_store, create_trie};

    use super::*;

    type TrieChanges = Vec<(Vec<u8>, Option<Vec<u8>>)>;

    fn test_populate_trie(trie: Arc<Trie>, root: &CryptoHash, changes: TrieChanges) -> CryptoHash {
        let mut other_changes = changes.clone();
        let (store_update, root) =
            trie.update(root, other_changes.drain(..)).unwrap().into(trie.clone()).unwrap();
        store_update.commit().unwrap();
        for (key, value) in changes {
            assert_eq!(trie.get(&root, &key), value);
        }
        root
    }

    fn test_clear_trie(trie: Arc<Trie>, root: &CryptoHash, changes: TrieChanges) -> CryptoHash {
        let delete_changes: TrieChanges =
            changes.iter().map(|(key, _)| (key.clone(), None)).collect();
        let mut other_delete_changes = delete_changes.clone();
        let (store_update, root) =
            trie.update(root, other_delete_changes.drain(..)).unwrap().into(trie.clone()).unwrap();
        store_update.commit().unwrap();
        for (key, _) in delete_changes {
            assert_eq!(trie.get(&root, &key), None);
        }
        root
    }

    #[test]
    fn test_encode_decode() {
        let node = RawTrieNode::Leaf(vec![1, 2, 3], vec![123, 245, 255]);
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);

        let mut children: [Option<CryptoHash>; 16] = Default::default();
        children[3] = Some(CryptoHash::default());
        let node = RawTrieNode::Branch(children, Some(vec![123, 245, 255]));
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);

        let node = RawTrieNode::Extension(vec![123, 245, 255], CryptoHash::default());
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);
    }

    #[test]
    fn test_basic_trie() {
        let trie = create_trie();
        let empty_root = Trie::empty_root();
        assert_eq!(trie.get(&empty_root, &[122]), None);
        let changes = vec![
            (b"doge".to_vec(), Some(b"coin".to_vec())),
            (b"docu".to_vec(), Some(b"value".to_vec())),
            (b"do".to_vec(), Some(b"verb".to_vec())),
            (b"horse".to_vec(), Some(b"stallion".to_vec())),
            (b"dog".to_vec(), Some(b"puppy".to_vec())),
            (b"h".to_vec(), Some(b"value".to_vec())),
        ];
        let root = test_populate_trie(trie.clone(), &empty_root, changes.clone());
        let new_root = test_clear_trie(trie.clone(), &root, changes);
        assert_eq!(new_root, empty_root);
        assert_eq!(trie.iter(&new_root).unwrap().fold(0, |acc, _| acc + 1), 0);
    }

    #[test]
    fn test_trie_iter() {
        let trie = create_trie();
        let pairs = vec![
            (b"a".to_vec(), Some(b"111".to_vec())),
            (b"b".to_vec(), Some(b"222".to_vec())),
            (b"x".to_vec(), Some(b"333".to_vec())),
            (b"y".to_vec(), Some(b"444".to_vec())),
        ];
        let root = test_populate_trie(trie.clone(), &Trie::empty_root(), pairs.clone());
        let mut iter_pairs = vec![];
        for pair in trie.iter(&root).unwrap() {
            let (key, value) = pair.unwrap();
            iter_pairs.push((key, Some(value.to_vec())));
        }
        assert_eq!(pairs, iter_pairs);

        let mut other_iter = trie.iter(&root).unwrap();
        other_iter.seek(b"r").unwrap();
        assert_eq!(other_iter.next().unwrap().unwrap().0, b"x".to_vec());
    }

    #[test]
    fn test_trie_leaf_into_branch() {
        let trie = create_trie();
        let changes = vec![
            (b"dog".to_vec(), Some(b"puppy".to_vec())),
            (b"dog2".to_vec(), Some(b"puppy".to_vec())),
            (b"xxx".to_vec(), Some(b"puppy".to_vec())),
        ];
        test_populate_trie(trie, &Trie::empty_root(), changes);
    }

    #[test]
    fn test_trie_same_node() {
        let trie = create_trie();
        let changes = vec![
            (b"dogaa".to_vec(), Some(b"puppy".to_vec())),
            (b"dogbb".to_vec(), Some(b"puppy".to_vec())),
            (b"cataa".to_vec(), Some(b"puppy".to_vec())),
            (b"catbb".to_vec(), Some(b"puppy".to_vec())),
            (b"dogax".to_vec(), Some(b"puppy".to_vec())),
        ];
        test_populate_trie(trie, &Trie::empty_root(), changes);
    }

    #[test]
    fn test_trie_iter_seek_stop_at_extension() {
        let trie = create_trie();
        let changes = vec![
            (vec![0, 116, 101, 115, 116], Some(vec![0])),
            (vec![2, 116, 101, 115, 116], Some(vec![0])),
            (
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 98, 111, 98,
                    46, 110, 101, 97, 114,
                ],
                Some(vec![0]),
            ),
            (
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 110, 117,
                    108, 108,
                ],
                Some(vec![0]),
            ),
        ];
        let root = test_populate_trie(trie.clone(), &Trie::empty_root(), changes);
        let mut iter = trie.iter(&root).unwrap();
        iter.seek(&vec![0, 116, 101, 115, 116, 44]).unwrap();
        let mut pairs = vec![];
        for pair in iter {
            pairs.push(pair.unwrap().0);
        }
        assert_eq!(
            pairs[..2],
            [
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 98, 111, 98,
                    46, 110, 101, 97, 114
                ],
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 110, 117,
                    108, 108
                ],
            ]
        );
    }

    #[test]
    fn test_trie_remove_non_existent_key() {
        let trie = create_trie();
        let mut initial = vec![
            (vec![99, 44, 100, 58, 58, 49], Some(vec![1])),
            (vec![99, 44, 100, 58, 58, 50], Some(vec![1])),
            (vec![99, 44, 100, 58, 58, 50, 51], Some(vec![1])),
        ];
        let (store_update, root) = trie
            .update(&Trie::empty_root(), initial.drain(..))
            .unwrap()
            .into(trie.clone())
            .unwrap();
        store_update.commit().unwrap();

        let mut changes = vec![
            (vec![99, 44, 100, 58, 58, 45, 49], None),
            (vec![99, 44, 100, 58, 58, 50, 52], None),
        ];
        let (store_update, root) =
            trie.update(&root, changes.drain(..)).unwrap().into(trie.clone()).unwrap();
        store_update.commit().unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }
    }

    #[test]
    fn test_equal_leafs() {
        let trie = create_trie();
        let mut initial = vec![
            (vec![1, 2, 3], Some(vec![1])),
            (vec![2, 2, 3], Some(vec![1])),
            (vec![3, 2, 3], Some(vec![1])),
        ];
        let (store_update, root) = trie
            .update(&Trie::empty_root(), initial.drain(..))
            .unwrap()
            .into(trie.clone())
            .unwrap();
        store_update.commit().unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }

        let mut changes = vec![(vec![1, 2, 3], None)];
        let (store_update, root) =
            trie.update(&root, changes.drain(..)).unwrap().into(trie.clone()).unwrap();
        store_update.commit().unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }
    }

    fn gen_changes(rng: &mut ThreadRng) -> Vec<(Vec<u8>, Option<Vec<u8>>)> {
        let alphabet = &b"abcdefgh"[0..rng.gen_range(2, 8)];
        let max_length = rng.gen_range(2, 8);

        let mut state: HashMap<Vec<u8>, Vec<u8>> = HashMap::new();
        let mut result = Vec::new();
        let delete_probability = rng.gen_range(0.1, 0.5);
        let size = rng.gen_range(1, 20);
        for _ in 0..size {
            let key_length = rng.gen_range(1, max_length);
            let key: Vec<u8> =
                (0..key_length).map(|_| alphabet.choose(rng).unwrap().clone()).collect();

            let delete = rng.gen_range(0.0, 1.0) < delete_probability;
            if delete {
                let mut keys: Vec<_> = state.keys().cloned().collect();
                keys.push(key);
                let key = keys.choose(rng).unwrap().clone();
                state.remove(&key);
                result.push((key.clone(), None));
            } else {
                let value_length = rng.gen_range(1, max_length);
                let value: Vec<u8> =
                    (0..value_length).map(|_| alphabet.choose(rng).unwrap().clone()).collect();
                result.push((key.clone(), Some(value.clone())));
                state.insert(key, value);
            }
        }
        result
    }

    fn simplify_changes(
        changes: &Vec<(Vec<u8>, Option<Vec<u8>>)>,
    ) -> Vec<(Vec<u8>, Option<Vec<u8>>)> {
        let mut state: HashMap<Vec<u8>, Vec<u8>> = HashMap::new();
        for (key, value) in changes.iter() {
            if let Some(value) = value {
                state.insert(key.clone(), value.clone());
            } else {
                state.remove(key);
            }
        }
        let mut result: Vec<_> = state.into_iter().map(|(k, v)| (k, Some(v))).collect();
        result.sort();
        result
    }

    #[test]
    fn test_trie_unique() {
        let mut rng = rand::thread_rng();
        for _ in 0..100 {
            let trie = create_trie();
            let trie_changes = gen_changes(&mut rng);
            let simplified_changes = simplify_changes(&trie_changes);

            let (_store_update1, root1) = trie
                .update(&Trie::empty_root(), trie_changes.iter().cloned())
                .unwrap()
                .into(trie.clone())
                .unwrap();
            let (_store_update2, root2) = trie
                .update(&Trie::empty_root(), simplified_changes.iter().cloned())
                .unwrap()
                .into(trie.clone())
                .unwrap();
            if root1 != root2 {
                eprintln!("{:?}", trie_changes);
                eprintln!("{:?}", simplified_changes);
                eprintln!("root1: {}", root1);
                eprintln!("root2: {}", root2);
                panic!("MISMATCH!");
            }
            // TODO: compare state updates?
        }
    }

    #[test]
    fn test_trie_restart() {
        let store = create_test_store();
        let trie1 = Arc::new(Trie::new(store.clone()));
        let empty_root = Trie::empty_root();
        let changes = vec![
            (b"doge".to_vec(), Some(b"coin".to_vec())),
            (b"docu".to_vec(), Some(b"value".to_vec())),
            (b"do".to_vec(), Some(b"verb".to_vec())),
            (b"horse".to_vec(), Some(b"stallion".to_vec())),
            (b"dog".to_vec(), Some(b"puppy".to_vec())),
            (b"h".to_vec(), Some(b"value".to_vec())),
        ];
        let root = test_populate_trie(trie1, &empty_root, changes.clone());

        let trie2 = Arc::new(Trie::new(store));
        assert_eq!(trie2.get(&root, b"doge"), Some(b"coin".to_vec()));
    }
}

'''
'''--- core/store/src/trie/nibble_slice.rs ---
// Copyright 2015-2017 Parity Technologies (UK) Ltd.
// This file is part of Parity.

// Parity is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// Parity is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with Parity.  If not, see <http://www.gnu.org/licenses/>.

//! Nibble-orientated view onto byte-slice, allowing nibble-precision offsets.

use elastic_array::ElasticArray36;
use std::cmp::*;
use std::fmt;

/// Nibble-orientated view onto byte-slice, allowing nibble-precision offsets.
///
/// This is an immutable struct. No operations actually change it.
///
/// # Example
/// ```snippet
/// use patricia_trie::nibbleslice::NibbleSlice;
/// fn main() {
///   let d1 = &[0x01u8, 0x23, 0x45];
///   let d2 = &[0x34u8, 0x50, 0x12];
///   let d3 = &[0x00u8, 0x12];
///   let n1 = NibbleSlice::new(d1);			// 0,1,2,3,4,5
///   let n2 = NibbleSlice::new(d2);			// 3,4,5,0,1,2
///   let n3 = NibbleSlice::new_offset(d3, 1);	// 0,1,2
///   assert!(n1 > n3);							// 0,1,2,... > 0,1,2
///   assert!(n1 < n2);							// 0,... < 3,...
///   assert!(n2.mid(3) == n3);					// 0,1,2 == 0,1,2
///   assert!(n1.starts_with(&n3));
///   assert_eq!(n1.common_prefix(&n3), 3);
///   assert_eq!(n2.mid(3).common_prefix(&n1), 3);
/// }
/// ```
#[derive(Copy, Clone, Eq, Ord)]
pub struct NibbleSlice<'a> {
    data: &'a [u8],
    offset: usize,
}

/// Iterator type for a nibble slice.
pub struct NibbleSliceIterator<'a> {
    p: &'a NibbleSlice<'a>,
    i: usize,
}

impl<'a> Iterator for NibbleSliceIterator<'a> {
    type Item = u8;
    fn next(&mut self) -> Option<u8> {
        self.i += 1;
        if self.i <= self.p.len() {
            Some(self.p.at(self.i - 1))
        } else {
            None
        }
    }
}

impl<'a> NibbleSlice<'a> {
    /// Create a new nibble slice with the given byte-slice.
    pub fn new(data: &'a [u8]) -> Self {
        NibbleSlice::new_offset(data, 0)
    }

    /// Create a new nibble slice with the given byte-slice with a nibble offset.
    pub fn new_offset(data: &'a [u8], offset: usize) -> Self {
        NibbleSlice { data, offset }
    }

    /// Get an iterator for the series of nibbles.
    pub fn iter(&'a self) -> NibbleSliceIterator<'a> {
        NibbleSliceIterator { p: self, i: 0 }
    }

    /// Create a new nibble slice from the given HPE encoded data (e.g. output of `encoded()`).
    pub fn from_encoded(data: &'a [u8]) -> (NibbleSlice, bool) {
        (Self::new_offset(data, if data[0] & 16 == 16 { 1 } else { 2 }), data[0] & 32 == 32)
    }

    /// Is this an empty slice?
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Get the length (in nibbles, naturally) of this slice.
    #[inline]
    pub fn len(&self) -> usize {
        self.data.len() * 2 - self.offset
    }

    /// Get the nibble at position `i`.
    #[inline(always)]
    pub fn at(&self, i: usize) -> u8 {
        if (self.offset + i) & 1 == 1 {
            self.data[(self.offset + i) / 2] & 15u8
        } else {
            self.data[(self.offset + i) / 2] >> 4
        }
    }

    /// Return object which represents a view on to this slice (further) offset by `i` nibbles.
    pub fn mid(&self, i: usize) -> NibbleSlice<'a> {
        NibbleSlice { data: self.data, offset: self.offset + i }
    }

    /// Do we start with the same nibbles as the whole of `them`?
    pub fn starts_with(&self, them: &Self) -> bool {
        self.common_prefix(them) == them.len()
    }

    /// How many of the same nibbles at the beginning do we match with `them`?
    pub fn common_prefix(&self, them: &Self) -> usize {
        let s = min(self.len(), them.len());
        for i in 0..s {
            if self.at(i) != them.at(i) {
                return i;
            }
        }
        s
    }

    /// Encode while nibble slice in prefixed hex notation, noting whether it `is_leaf`.
    #[inline]
    pub fn encoded(&self, is_leaf: bool) -> ElasticArray36<u8> {
        let l = self.len();
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            r.push(self.at(i) * 16 + self.at(i + 1));
            i += 2;
        }
        r
    }

    pub fn merge_encoded(&self, other: &Self, is_leaf: bool) -> ElasticArray36<u8> {
        let l = self.len() + other.len();
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            let bit1 = if i < self.len() { self.at(i) } else { other.at(i - self.len()) };
            let bit2 = if i + 1 < l {
                if i + 1 < self.len() {
                    self.at(i + 1)
                } else {
                    other.at(i + 1 - self.len())
                }
            } else {
                0
            };

            r.push(bit1 * 16 + bit2);
            i += 2;
        }
        r
    }

    /// Encode only the leftmost `n` bytes of the nibble slice in prefixed hex notation,
    /// noting whether it `is_leaf`.
    pub fn encoded_leftmost(&self, n: usize, is_leaf: bool) -> ElasticArray36<u8> {
        let l = min(self.len(), n);
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            r.push(self.at(i) * 16 + self.at(i + 1));
            i += 2;
        }
        r
    }
}

impl<'a> PartialEq for NibbleSlice<'a> {
    fn eq(&self, them: &Self) -> bool {
        self.len() == them.len() && self.starts_with(them)
    }
}

impl<'a> PartialOrd for NibbleSlice<'a> {
    fn partial_cmp(&self, them: &Self) -> Option<Ordering> {
        let s = min(self.len(), them.len());
        for i in 0..s {
            match self.at(i).partial_cmp(&them.at(i)).unwrap() {
                Ordering::Less => return Some(Ordering::Less),
                Ordering::Greater => return Some(Ordering::Greater),
                _ => {}
            }
        }
        self.len().partial_cmp(&them.len())
    }
}

impl<'a> fmt::Debug for NibbleSlice<'a> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.is_empty() {
            return Ok(());
        }
        write!(f, "{:01x}", self.at(0))?;
        for i in 1..self.len() {
            write!(f, "'{:01x}", self.at(i))?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::NibbleSlice;
    use elastic_array::ElasticArray36;
    static D: &'static [u8; 3] = &[0x01u8, 0x23, 0x45];

    #[test]
    fn basics() {
        let n = NibbleSlice::new(D);
        assert_eq!(n.len(), 6);
        assert!(!n.is_empty());

        let n = NibbleSlice::new_offset(D, 6);
        assert!(n.is_empty());

        let n = NibbleSlice::new_offset(D, 3);
        assert_eq!(n.len(), 3);
        for i in 0..3 {
            assert_eq!(n.at(i), i as u8 + 3);
        }
    }

    #[test]
    fn iterator() {
        let n = NibbleSlice::new(D);
        let mut nibbles: Vec<u8> = vec![];
        nibbles.extend(n.iter());
        assert_eq!(nibbles, (0u8..6).collect::<Vec<_>>())
    }

    #[test]
    fn mid() {
        let n = NibbleSlice::new(D);
        let m = n.mid(2);
        for i in 0..4 {
            assert_eq!(m.at(i), i as u8 + 2);
        }
        let m = n.mid(3);
        for i in 0..3 {
            assert_eq!(m.at(i), i as u8 + 3);
        }
    }

    #[test]
    fn encoded() {
        let n = NibbleSlice::new(D);
        assert_eq!(n.encoded(false), ElasticArray36::from_slice(&[0x00, 0x01, 0x23, 0x45]));
        assert_eq!(n.encoded(true), ElasticArray36::from_slice(&[0x20, 0x01, 0x23, 0x45]));
        assert_eq!(n.mid(1).encoded(false), ElasticArray36::from_slice(&[0x11, 0x23, 0x45]));
        assert_eq!(n.mid(1).encoded(true), ElasticArray36::from_slice(&[0x31, 0x23, 0x45]));
    }

    #[test]
    fn from_encoded() {
        let n = NibbleSlice::new(D);
        assert_eq!((n, false), NibbleSlice::from_encoded(&[0x00, 0x01, 0x23, 0x45]));
        assert_eq!((n, true), NibbleSlice::from_encoded(&[0x20, 0x01, 0x23, 0x45]));
        assert_eq!((n.mid(1), false), NibbleSlice::from_encoded(&[0x11, 0x23, 0x45]));
        assert_eq!((n.mid(1), true), NibbleSlice::from_encoded(&[0x31, 0x23, 0x45]));
    }

    #[test]
    fn shared() {
        let n = NibbleSlice::new(D);

        let other = &[0x01u8, 0x23, 0x01, 0x23, 0x45, 0x67];
        let m = NibbleSlice::new(other);

        assert_eq!(n.common_prefix(&m), 4);
        assert_eq!(m.common_prefix(&n), 4);
        assert_eq!(n.mid(1).common_prefix(&m.mid(1)), 3);
        assert_eq!(n.mid(1).common_prefix(&m.mid(2)), 0);
        assert_eq!(n.common_prefix(&m.mid(4)), 6);
        assert!(!n.starts_with(&m.mid(4)));
        assert!(m.mid(4).starts_with(&n));
    }

    #[test]
    fn compare() {
        let other = &[0x01u8, 0x23, 0x01, 0x23, 0x45];
        let n = NibbleSlice::new(D);
        let m = NibbleSlice::new(other);

        assert!(n != m);
        assert!(n > m);
        assert!(m < n);

        assert!(n == m.mid(4));
        assert!(n >= m.mid(4));
        assert!(n <= m.mid(4));
    }

    #[test]
    fn nibble_indexing() {
        let encoded = vec![32, 116, 101, 115, 116];
        let n = NibbleSlice::from_encoded(&encoded).0;
        let nibbles: Vec<u8> = (0..n.len()).map(|i| n.at(i)).collect();
        assert_eq!(nibbles, vec![7, 4, 6, 5, 7, 3, 7, 4]);
    }
}

'''
'''--- core/store/src/trie/update.rs ---
use std::collections::BTreeMap;
use std::convert::identity;
use std::iter::Peekable;
use std::sync::Arc;

use kvdb::DBValue;
use log::debug;

use near_primitives::types::MerkleHash;

use crate::trie::TrieChanges;

use super::{Trie, TrieIterator};

/// Provides a way to access Storage and record changes with future commit.
pub struct TrieUpdate {
    pub trie: Arc<Trie>,
    root: MerkleHash,
    committed: BTreeMap<Vec<u8>, Option<Vec<u8>>>,
    prospective: BTreeMap<Vec<u8>, Option<Vec<u8>>>,
}

impl TrieUpdate {
    pub fn new(trie: Arc<Trie>, root: MerkleHash) -> Self {
        TrieUpdate { trie, root, committed: BTreeMap::default(), prospective: BTreeMap::default() }
    }
    pub fn get(&self, key: &[u8]) -> Option<DBValue> {
        if let Some(value) = self.prospective.get(key) {
            Some(DBValue::from_slice(value.as_ref()?))
        } else if let Some(value) = self.committed.get(key) {
            Some(DBValue::from_slice(value.as_ref()?))
        } else {
            self.trie.get(&self.root, key).map(DBValue::from_vec)
        }
    }
    pub fn set(&mut self, key: Vec<u8>, value: DBValue) -> Option<Vec<u8>> {
        self.prospective.insert(key, Some(value.into_vec())).and_then(identity)
    }
    pub fn remove(&mut self, key: &[u8]) -> Option<Vec<u8>> {
        self.prospective.insert(key.to_vec(), None).and_then(identity)
    }

    pub fn for_keys_with_prefix<F: FnMut(&[u8])>(&self, prefix: &[u8], mut f: F) {
        match self.iter(prefix) {
            Ok(iter) => {
                for key in iter {
                    f(&key);
                }
            }
            Err(e) => {
                debug!(target: "trie", "Error while iterating by prefix: {}", e);
            }
        }
    }

    pub fn commit(&mut self) {
        if self.committed.is_empty() {
            std::mem::swap(&mut self.prospective, &mut self.committed);
        } else {
            for (key, val) in std::mem::replace(&mut self.prospective, BTreeMap::new()).into_iter()
            {
                *self.committed.entry(key).or_default() = val;
            }
        }
    }
    pub fn rollback(&mut self) {
        self.prospective.clear();
    }
    pub fn finalize(mut self) -> Result<TrieChanges, Box<dyn std::error::Error>> {
        if !self.prospective.is_empty() {
            self.commit();
        }
        let TrieUpdate { trie, root, committed, .. } = self;
        trie.update(&root, committed.into_iter())
    }
    pub fn iter(&self, prefix: &[u8]) -> Result<TrieUpdateIterator, Box<dyn std::error::Error>> {
        TrieUpdateIterator::new(self, prefix, b"", None)
    }

    pub fn range(
        &self,
        prefix: &[u8],
        start: &[u8],
        end: &[u8],
    ) -> Result<TrieUpdateIterator, Box<dyn std::error::Error>> {
        TrieUpdateIterator::new(self, prefix, start, Some(end))
    }

    pub fn get_root(&self) -> MerkleHash {
        self.root
    }
}

struct MergeIter<'a, I: Iterator<Item = (&'a Vec<u8>, &'a Option<Vec<u8>>)>> {
    left: Peekable<I>,
    right: Peekable<I>,
}

impl<'a, I: Iterator<Item = (&'a Vec<u8>, &'a Option<Vec<u8>>)>> Iterator for MergeIter<'a, I> {
    type Item = (&'a Vec<u8>, &'a Option<Vec<u8>>);

    fn next(&mut self) -> Option<Self::Item> {
        let res = match (self.left.peek(), self.right.peek()) {
            (Some(&(ref left_key, _)), Some(&(ref right_key, _))) => {
                if left_key < right_key {
                    std::cmp::Ordering::Less
                } else if left_key == right_key {
                    std::cmp::Ordering::Equal
                } else {
                    std::cmp::Ordering::Greater
                }
            }
            (Some(_), None) => std::cmp::Ordering::Less,
            (None, Some(_)) => std::cmp::Ordering::Greater,
            (None, None) => return None,
        };

        // Check which elements comes first and only advance the corresponding iterator.
        // If two keys are equal, take the value from `right`.
        match res {
            std::cmp::Ordering::Less => self.left.next(),
            std::cmp::Ordering::Greater => self.right.next(),
            std::cmp::Ordering::Equal => {
                self.left.next();
                self.right.next()
            }
        }
    }
}

type MergeBTreeRange<'a> =
    MergeIter<'a, std::collections::btree_map::Range<'a, Vec<u8>, Option<Vec<u8>>>>;

pub struct TrieUpdateIterator<'a> {
    prefix: Vec<u8>,
    end_offset: Option<Vec<u8>>,
    trie_iter: Peekable<TrieIterator<'a>>,
    overlay_iter: Peekable<MergeBTreeRange<'a>>,
}

impl<'a> TrieUpdateIterator<'a> {
    #![allow(clippy::new_ret_no_self)]
    pub fn new(
        state_update: &'a TrieUpdate,
        prefix: &[u8],
        start: &[u8],
        end: Option<&[u8]>,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let mut trie_iter = state_update.trie.iter(&state_update.root)?;
        let mut start_offset = prefix.to_vec();
        start_offset.extend_from_slice(start);
        let end_offset = match end {
            Some(end) => {
                let mut p = prefix.to_vec();
                p.extend_from_slice(end);
                Some(p)
            }
            None => None,
        };
        trie_iter.seek(&start_offset)?;
        let committed_iter = state_update.committed.range(start_offset.clone()..);
        let prospective_iter = state_update.prospective.range(start_offset..);
        let overlay_iter =
            MergeIter { left: committed_iter.peekable(), right: prospective_iter.peekable() }
                .peekable();
        Ok(TrieUpdateIterator {
            prefix: prefix.to_vec(),
            end_offset,
            trie_iter: trie_iter.peekable(),
            overlay_iter,
        })
    }
}

impl<'a> Iterator for TrieUpdateIterator<'a> {
    type Item = Vec<u8>;

    fn next(&mut self) -> Option<Self::Item> {
        let stop_cond = |key: &Vec<u8>, prefix: &Vec<u8>, end_offset: &Option<Vec<u8>>| {
            !key.starts_with(prefix)
                || match end_offset {
                    Some(end) => key > end,
                    None => false,
                }
        };
        enum Ordering {
            Trie,
            Overlay,
            Both,
        }
        // Usually one iteration, unless need to skip None values in prospective / committed.
        loop {
            let res = {
                match (self.trie_iter.peek(), self.overlay_iter.peek()) {
                    (Some(&Ok((ref left_key, _))), Some(&(ref right_key, _))) => {
                        match (
                            stop_cond(left_key, &self.prefix, &self.end_offset),
                            stop_cond(*right_key, &self.prefix, &self.end_offset),
                        ) {
                            (false, false) => {
                                if left_key < *right_key {
                                    Ordering::Trie
                                } else if &left_key == right_key {
                                    Ordering::Both
                                } else {
                                    Ordering::Overlay
                                }
                            }
                            (false, true) => Ordering::Trie,
                            (true, false) => Ordering::Overlay,
                            (true, true) => {
                                return None;
                            }
                        }
                    }
                    (Some(&Ok((ref left_key, _))), None) => {
                        if stop_cond(left_key, &self.prefix, &self.end_offset) {
                            return None;
                        }
                        Ordering::Trie
                    }
                    (None, Some(&(ref right_key, _))) => {
                        if stop_cond(right_key, &self.prefix, &self.end_offset) {
                            return None;
                        }
                        Ordering::Overlay
                    }
                    (None, None) => return None,
                    (Some(&Err(_)), _) => return None,
                }
            };

            // Check which elements comes first and only advance the corresponding iterator.
            // If two keys are equal, take the value from `right`.
            return match res {
                Ordering::Trie => match self.trie_iter.next() {
                    Some(Ok(value)) => Some(value.0),
                    _ => None,
                },
                Ordering::Overlay => match self.overlay_iter.next() {
                    Some((key, Some(_))) => Some(key.clone()),
                    Some((_, None)) => continue,
                    None => None,
                },
                Ordering::Both => {
                    self.trie_iter.next();
                    match self.overlay_iter.next() {
                        Some((key, Some(_))) => Some(key.clone()),
                        Some((_, None)) => continue,
                        None => None,
                    }
                }
            };
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::test_utils::create_trie;

    use super::*;

    #[test]
    fn trie() {
        let trie = create_trie();
        let root = MerkleHash::default();
        let mut trie_update = TrieUpdate::new(trie.clone(), root);
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"xxx".to_vec(), DBValue::from_slice(b"puppy"));
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();
        let trie_update2 = TrieUpdate::new(trie.clone(), new_root);
        assert_eq!(trie_update2.get(b"dog").unwrap(), DBValue::from_slice(b"puppy"));
        let mut values = vec![];
        trie_update2.for_keys_with_prefix(b"dog", |key| values.push(key.to_vec()));
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);
    }

    #[test]
    fn trie_remove() {
        let trie = create_trie();

        // Delete non-existing element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.remove(b"dog");
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();
        assert_eq!(new_root, MerkleHash::default());

        // Add and right away delete element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.remove(b"dog");
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();
        assert_eq!(new_root, MerkleHash::default());

        // Add, apply changes and then delete element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();
        assert_ne!(new_root, MerkleHash::default());
        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.remove(b"dog");
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();
        assert_eq!(new_root, MerkleHash::default());
    }

    #[test]
    fn trie_iter() {
        let trie = create_trie();
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"aaa".to_vec(), DBValue::from_slice(b"puppy"));
        let (store_update, new_root) = trie_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().ok();

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"xxx".to_vec(), DBValue::from_slice(b"puppy"));

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);

        trie_update.rollback();

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec()]);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.remove(b"dog");

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values.len(), 0);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.commit();
        trie_update.remove(b"dog2");

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec()]);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.commit();
        trie_update.set(b"dog3".to_vec(), DBValue::from_slice(b"puppy"));

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec(), b"dog3".to_vec()]);

        let values: Vec<Vec<u8>> = trie_update.range(b"do", b"g", b"g2").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);

        let values: Vec<Vec<u8>> = trie_update.range(b"do", b"", b"xyz").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec(), b"dog3".to_vec()]);
    }
}

'''
'''--- docker/README.md ---
### Building

```bash
./build ${PACKAGE} ${IMAGE_TAG}
```

See other usage options with:

```bash
./build --help
``` 

'''
'''--- docker/scripts/hosted_alphanet_chain_spec.json ---
{
  "accounts": [
    ["alice.near","HatfVQ39tQqETM5iyUwvDa3nM4YCWTB8sYDFJ2NteBjs",1000000,10],
    ["near.0","4sB5pxJiXnmzTpZD9Tdp9v4ZekGKZdtW3XgE9qdDEzVs",1000000000,10],
    ["near.1","7URGgTSj2Ys5SxtXXm47CwHXn4SL8uFJ5Xynrk1JNeqe",1000000000,10],
    ["near.2","GawaQqyVoqb3aEgAJ9Wj2VD7jihLjrCYpmUGhZ6kKWAD",1000000000,10],
    ["near.3","CztoSUKPgiXxrN9RzxCbgQMJThoWZh6XgoM93FuJqPC3",1000000000,10]
  ],
  "initial_authorities":[
    ["near.0","4sB5pxJiXnmzTpZD9Tdp9v4ZekGKZdtW3XgE9qdDEzVs","7AQe13XmfMG7uFPajZ4fTMja3jHMxygYeQnQ6sycR5Gm3sUJoaNrWgCZ6PTKdRFPdd",50],
    ["near.1","7URGgTSj2Ys5SxtXXm47CwHXn4SL8uFJ5Xynrk1JNeqe","6uESzd7wb8rWyHYq7D2NgmhXe5xTVBU8TDkG6osJM5SVrfudBufVrkBFWcqcjAo48H",50],
    ["near.2","GawaQqyVoqb3aEgAJ9Wj2VD7jihLjrCYpmUGhZ6kKWAD","6TEvrVasfJdH8Mdz5K7fTGTiBTadWDS5ocXV5T6vdsRv1dQ6CCu51Yg4JevrRA6H1Y",50],
    ["near.3","CztoSUKPgiXxrN9RzxCbgQMJThoWZh6XgoM93FuJqPC3","7ExirLTsaJbHbCRykELEp2anF2pafUSVL3uj3KBDmT3RpuSdacc1SeQcTjoCKAMash",50]
  ],
  "genesis_wasm":[0,97,115,109,1,0,0,0,1,87,14,96,5,127,127,127,127,127,1,127,96,1,127,0,96,2,127,127,0,96,4,127,127,127,127,0,96,2,127,127,1,127,96,0,1,127,96,1,127,1,127,96,8,127,127,127,127,127,127,127,126,1,127,96,6,127,127,127,127,127,127,1,127,96,0,1,126,96,3,127,127,127,0,96,0,0,96,1,126,0,96,3,127,127,127,1,127,2,254,2,22,3,101,110,118,9,100,97,116,97,95,114,101,97,100,0,0,3,101,110,118,6,97,115,115,101,114,116,0,1,3,101,110,118,12,114,101,116,117,114,110,95,118,97,108,117,101,0,2,3,101,110,118,13,115,116,111,114,97,103,101,95,119,114,105,116,101,0,3,3,101,110,118,14,115,116,111,114,97,103,101,95,114,101,109,111,118,101,0,2,3,101,110,118,15,115,116,111,114,97,103,101,95,104,97,115,95,107,101,121,0,4,3,101,110,118,5,100,101,98,117,103,0,2,3,101,110,118,12,114,101,115,117,108,116,95,99,111,117,110,116,0,5,3,101,110,118,12,114,101,115,117,108,116,95,105,115,95,111,107,0,6,3,101,110,118,14,112,114,111,109,105,115,101,95,99,114,101,97,116,101,0,7,3,101,110,118,11,112,114,111,109,105,115,101,95,97,110,100,0,4,3,101,110,118,12,112,114,111,109,105,115,101,95,116,104,101,110,0,8,3,101,110,118,14,114,101,116,117,114,110,95,112,114,111,109,105,115,101,0,1,3,101,110,118,7,98,97,108,97,110,99,101,0,9,3,101,110,118,15,114,101,99,101,105,118,101,100,95,97,109,111,117,110,116,0,9,3,101,110,118,8,103,97,115,95,108,101,102,116,0,9,3,101,110,118,9,109,97,110,97,95,108,101,102,116,0,5,3,101,110,118,11,98,108,111,99,107,95,105,110,100,101,120,0,9,3,101,110,118,8,114,97,110,100,111,109,51,50,0,5,3,101,110,118,10,114,97,110,100,111,109,95,98,117,102,0,2,3,101,110,118,4,104,97,115,104,0,10,3,101,110,118,6,104,97,115,104,51,50,0,4,3,49,48,1,2,10,10,2,10,10,3,1,1,12,2,2,6,1,6,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,6,4,1,2,6,6,2,13,13,6,6,13,13,4,5,1,112,1,1,1,5,3,1,0,2,6,22,3,127,1,65,128,128,4,11,127,0,65,210,128,4,11,127,0,65,210,128,4,11,7,193,3,27,6,109,101,109,111,114,121,2,0,11,95,95,104,101,97,112,95,98,97,115,101,3,1,10,95,95,100,97,116,97,95,101,110,100,3,2,10,107,101,121,95,116,111,95,115,116,114,0,33,7,112,117,116,95,105,110,116,0,34,7,103,101,116,95,105,110,116,0,35,10,114,101,109,111,118,101,95,105,110,116,0,36,7,104,97,115,95,105,110,116,0,37,13,108,111,103,95,115,111,109,101,116,104,105,110,103,0,38,8,114,117,110,95,116,101,115,116,0,39,28,114,117,110,95,116,101,115,116,95,119,105,116,104,95,115,116,111,114,97,103,101,95,99,104,97,110,103,101,0,40,14,115,117,109,95,119,105,116,104,95,105,110,112,117,116,0,41,14,103,101,116,95,97,99,99,111,117,110,116,95,105,100,0,42,17,103,101,116,95,111,114,105,103,105,110,97,116,111,114,95,105,100,0,43,25,115,117,109,95,119,105,116,104,95,109,117,108,116,105,112,108,101,95,114,101,115,117,108,116,115,0,44,24,99,114,101,97,116,101,95,112,114,111,109,105,115,101,115,95,97,110,100,95,106,111,105,110,0,45,14,97,110,115,119,101,114,95,116,111,95,108,105,102,101,0,46,15,116,114,97,110,115,102,101,114,95,116,111,95,98,111,98,0,47,16,103,101,116,95,112,114,101,118,95,98,97,108,97,110,99,101,0,48,12,103,101,116,95,103,97,115,95,108,101,102,116,0,49,13,103,101,116,95,109,97,110,97,95,108,101,102,116,0,50,15,103,101,116,95,98,108,111,99,107,95,105,110,100,101,120,0,51,10,97,115,115,101,114,116,95,115,117,109,0,52,13,103,101,116,95,114,97,110,100,111,109,95,51,50,0,53,14,103,101,116,95,114,97,110,100,111,109,95,98,117,102,0,54,16,104,97,115,104,95,103,105,118,101,110,95,105,110,112,117,116,0,55,18,104,97,115,104,51,50,95,103,105,118,101,110,95,105,110,112,117,116,0,56,10,235,24,48,26,1,1,127,2,64,32,0,40,2,4,34,1,69,13,0,32,0,40,2,0,32,1,16,23,11,11,8,0,32,0,32,1,16,63,11,110,1,2,127,35,0,65,32,107,34,3,36,0,32,3,65,8,106,32,2,65,0,16,25,32,3,65,0,54,2,24,32,3,32,3,41,3,8,55,3,16,32,3,65,16,106,32,2,16,26,32,3,32,3,40,2,24,34,4,32,2,106,54,2,24,32,4,32,3,40,2,16,106,32,1,32,2,16,69,26,32,0,65,8,106,32,3,40,2,24,54,2,0,32,0,32,3,41,3,16,55,2,0,32,3,65,32,106,36,0,11,55,0,2,64,2,64,2,64,32,1,69,13,0,32,2,69,13,1,32,1,16,66,33,2,12,2,11,65,1,33,2,12,1,11,32,1,16,61,33,2,11,32,0,32,1,54,2,4,32,0,32,2,54,2,0,11,98,1,3,127,2,64,32,0,40,2,4,34,2,32,0,40,2,8,34,3,107,32,1,79,13,0,32,2,65,1,116,34,4,32,3,32,1,106,34,1,32,1,32,4,73,27,33,1,2,64,2,64,32,2,69,13,0,32,0,40,2,0,32,2,32,1,16,64,33,2,12,1,11,32,1,16,61,33,2,11,32,0,32,2,54,2,0,32,0,65,4,106,32,1,54,2,0,11,11,19,0,32,0,32,2,54,2,4,32,0,32,1,40,2,0,54,2,0,11,28,0,32,0,32,1,40,2,8,32,2,107,54,2,4,32,0,32,1,40,2,0,32,2,106,54,2,0,11,182,1,1,6,127,35,0,65,16,107,34,4,36,0,2,64,65,0,40,2,140,128,4,13,0,65,132,128,4,65,128,128,4,16,26,65,0,40,2,132,128,4,65,0,40,2,140,128,4,34,5,106,33,6,65,0,33,7,2,64,3,64,32,6,32,7,106,33,8,32,7,65,1,106,34,9,65,255,255,3,75,13,1,32,8,65,0,58,0,0,32,9,33,7,12,0,11,11,32,8,65,0,58,0,0,65,0,32,5,32,7,106,65,1,106,54,2,140,128,4,11,32,1,32,2,32,3,65,128,128,4,65,0,40,2,132,128,4,16,0,34,7,65,129,128,4,73,16,1,32,4,65,8,106,65,132,128,4,32,7,16,27,32,0,32,4,40,2,8,32,4,40,2,12,16,24,32,4,65,16,106,36,0,11,12,0,32,0,65,4,65,0,65,0,16,29,11,36,1,1,127,35,0,65,16,107,34,1,36,0,32,1,32,0,54,2,12,65,4,32,1,65,12,106,16,2,32,1,65,16,106,36,0,11,36,1,1,127,35,0,65,16,107,34,1,36,0,32,1,32,0,55,3,8,65,8,32,1,65,8,106,16,2,32,1,65,16,106,36,0,11,117,1,3,127,35,0,65,16,107,34,2,36,0,32,2,65,144,128,4,65,15,16,24,32,2,40,2,0,32,2,40,2,8,106,65,127,106,33,3,2,64,3,64,32,1,69,13,1,32,3,32,1,32,1,65,10,110,34,4,65,118,108,106,65,48,114,58,0,0,32,3,65,127,106,33,3,32,4,33,1,12,0,11,11,32,0,32,2,41,3,0,55,2,0,32,0,65,8,106,32,2,65,8,106,40,2,0,54,2,0,32,2,65,16,106,36,0,11,62,1,1,127,35,0,65,32,107,34,2,36,0,32,2,32,1,54,2,12,32,2,65,16,106,32,0,16,33,32,2,40,2,24,32,2,40,2,16,65,4,32,2,65,12,106,16,3,32,2,65,16,106,16,22,32,2,65,32,106,36,0,11,78,1,1,127,35,0,65,32,107,34,1,36,0,32,1,32,0,16,33,32,1,65,16,106,65,3,32,1,40,2,8,32,1,40,2,0,16,29,32,1,40,2,24,65,4,70,16,1,32,1,40,2,16,40,0,0,33,0,32,1,65,16,106,16,22,32,1,16,22,32,1,65,32,106,36,0,32,0,11,42,1,1,127,35,0,65,16,107,34,1,36,0,32,1,32,0,16,33,32,1,40,2,8,32,1,40,2,0,16,4,32,1,16,22,32,1,65,16,106,36,0,11,46,1,1,127,35,0,65,16,107,34,1,36,0,32,1,32,0,16,33,32,1,40,2,8,32,1,40,2,0,16,5,33,0,32,1,16,22,32,1,65,16,106,36,0,32,0,11,10,0,65,5,65,159,128,4,16,6,11,6,0,65,10,16,31,11,40,0,65,10,65,20,16,34,65,50,65,150,1,16,34,65,50,16,37,16,1,65,50,16,36,65,50,16,37,65,1,115,16,1,65,10,16,35,16,31,11,77,1,1,127,35,0,65,32,107,34,0,36,0,32,0,65,16,106,16,30,32,0,40,2,24,65,8,70,16,1,32,0,65,8,106,32,0,65,16,106,65,4,16,28,32,0,40,2,8,40,0,0,32,0,40,2,16,40,0,0,106,16,31,32,0,65,16,106,16,22,32,0,65,32,106,36,0,11,46,1,1,127,35,0,65,16,107,34,0,36,0,32,0,65,2,65,0,65,0,16,29,32,0,40,2,8,32,0,40,2,0,16,2,32,0,16,22,32,0,65,16,106,36,0,11,46,1,1,127,35,0,65,16,107,34,0,36,0,32,0,65,1,65,0,65,0,16,29,32,0,40,2,8,32,0,40,2,0,16,2,32,0,16,22,32,0,65,16,106,36,0,11,118,1,4,127,35,0,65,16,107,34,0,36,0,2,64,2,64,2,64,16,7,34,1,69,13,0,65,0,33,2,65,0,33,3,2,64,3,64,32,2,32,1,79,13,1,32,2,16,8,69,13,3,32,0,65,5,65,0,32,2,16,29,32,2,65,1,106,33,2,32,0,40,2,0,40,0,0,32,3,106,33,3,32,0,16,22,12,0,11,11,32,3,16,31,12,2,11,65,156,127,16,31,12,1,11,65,156,127,16,31,11,32,0,65,16,106,36,0,11,253,1,1,4,127,35,0,65,48,107,34,0,36,0,32,0,65,164,128,4,65,5,16,24,32,0,40,2,0,33,1,32,0,65,16,106,65,169,128,4,65,4,16,24,32,0,40,2,16,33,2,32,0,65,32,106,65,173,128,4,65,5,16,24,65,5,32,1,65,4,32,2,65,5,32,0,40,2,32,65,0,66,0,16,9,33,1,32,0,65,32,106,16,22,32,0,65,16,106,16,22,32,0,16,22,32,0,65,178,128,4,65,5,16,24,32,0,40,2,0,33,2,32,0,65,16,106,65,183,128,4,65,4,16,24,32,0,40,2,16,33,3,32,0,65,32,106,65,187,128,4,65,5,16,24,65,5,32,2,65,4,32,3,65,5,32,0,40,2,32,65,0,66,0,16,9,33,2,32,0,65,32,106,16,22,32,0,65,16,106,16,22,32,0,16,22,32,1,32,2,16,10,33,1,32,0,65,32,106,65,192,128,4,65,8,16,24,32,1,65,8,32,0,40,2,32,65,0,65,0,65,0,16,11,33,1,32,0,65,32,106,16,22,32,1,16,12,32,0,65,48,106,36,0,11,6,0,65,43,16,31,11,88,1,2,127,35,0,65,32,107,34,0,36,0,32,0,65,200,128,4,65,3,16,24,32,0,40,2,0,33,1,32,0,65,16,106,65,203,128,4,65,7,16,24,65,3,32,1,65,5,32,0,40,2,16,65,0,65,0,65,0,66,1,16,9,33,1,32,0,65,16,106,16,22,32,0,16,22,32,1,16,12,32,0,65,32,106,36,0,11,9,0,16,13,16,14,125,16,32,11,6,0,16,15,16,32,11,6,0,16,16,16,31,11,6,0,16,17,16,32,11,85,1,2,127,35,0,65,32,107,34,0,36,0,32,0,65,16,106,16,30,32,0,40,2,24,65,12,70,16,1,32,0,65,8,106,32,0,65,16,106,65,8,16,28,32,0,40,2,16,34,1,40,0,4,32,1,40,0,0,106,32,0,40,2,8,40,0,0,70,16,1,32,0,65,16,106,16,22,32,0,65,32,106,36,0,11,6,0,16,18,16,31,11,111,1,3,127,35,0,65,48,107,34,0,36,0,32,0,65,16,106,16,30,32,0,40,2,24,65,4,70,16,1,32,0,65,8,106,32,0,40,2,16,40,0,0,34,1,65,1,16,25,32,0,32,1,54,2,40,32,0,32,0,40,2,12,54,2,36,32,0,32,0,40,2,8,34,2,54,2,32,32,1,32,2,16,19,32,1,32,2,16,2,32,0,65,32,106,16,22,32,0,65,16,106,16,22,32,0,65,48,106,36,0,11,91,1,1,127,35,0,65,48,107,34,0,36,0,32,0,16,30,32,0,65,40,106,66,0,55,3,0,32,0,65,32,106,66,0,55,3,0,32,0,65,24,106,66,0,55,3,0,32,0,66,0,55,3,16,32,0,40,2,8,32,0,40,2,0,32,0,65,16,106,16,20,65,32,32,0,65,16,106,16,2,32,0,16,22,32,0,65,48,106,36,0,11,42,1,1,127,35,0,65,16,107,34,0,36,0,32,0,16,30,32,0,40,2,8,32,0,40,2,0,16,21,16,31,32,0,16,22,32,0,65,16,106,36,0,11,196,1,1,4,127,35,0,65,16,107,34,1,36,0,2,64,2,64,32,0,69,13,0,32,1,65,0,40,2,128,128,4,54,2,12,2,64,32,0,65,3,106,34,2,65,2,118,34,3,32,1,65,12,106,16,58,34,0,13,0,65,0,33,0,32,2,65,124,113,34,2,65,136,4,32,2,65,136,4,75,27,65,135,128,4,106,34,4,65,16,118,64,0,34,2,65,127,70,13,0,65,0,33,0,32,2,65,16,116,34,2,69,13,0,32,2,32,2,32,4,65,128,128,124,113,106,65,2,114,54,2,0,32,2,65,0,54,2,4,32,2,32,1,40,2,12,54,2,8,32,1,32,2,54,2,12,32,3,32,1,65,12,106,16,58,33,0,11,65,0,32,1,40,2,12,54,2,128,128,4,12,1,11,65,1,33,0,11,32,1,65,16,106,36,0,32,0,11,144,3,1,4,127,32,0,65,2,116,33,2,32,1,40,2,0,33,0,2,64,2,64,3,64,32,0,69,13,1,2,64,3,64,32,0,65,8,106,33,4,32,0,40,2,8,34,3,65,1,113,69,13,1,32,4,32,3,65,126,113,54,2,0,2,64,2,64,32,0,40,2,4,65,124,113,34,3,69,13,0,65,0,32,3,32,3,45,0,0,65,1,113,27,33,3,12,1,11,65,0,33,3,11,32,0,16,59,2,64,32,0,45,0,0,65,2,113,69,13,0,32,3,32,3,40,2,0,65,2,114,54,2,0,11,32,1,32,3,54,2,0,32,3,33,0,12,0,11,11,32,0,40,2,0,65,124,113,34,5,32,4,107,32,2,79,13,2,32,1,32,3,54,2,0,32,3,33,0,12,0,11,11,65,0,15,11,2,64,2,64,32,4,65,200,0,106,32,5,32,2,107,34,4,77,13,0,32,1,32,3,65,124,113,54,2,0,32,0,33,3,12,1,11,32,4,65,0,54,2,0,32,4,65,120,106,34,3,66,0,55,2,0,32,3,32,0,40,2,0,65,124,113,54,2,0,2,64,32,0,40,2,0,34,1,65,124,113,34,4,69,13,0,32,1,65,2,113,13,0,32,4,32,4,40,2,4,65,3,113,32,3,114,54,2,4,11,32,3,32,3,40,2,4,65,3,113,32,0,114,54,2,4,32,0,65,8,106,34,4,32,4,40,2,0,65,126,113,54,2,0,32,0,32,0,40,2,0,34,4,65,3,113,32,3,114,34,1,54,2,0,32,4,65,2,113,69,13,0,32,0,32,1,65,125,113,54,2,0,32,3,32,3,40,2,0,65,2,114,54,2,0,11,32,3,32,3,40,2,0,65,1,114,54,2,0,32,3,65,8,106,11,127,1,2,127,2,64,32,0,40,2,0,34,1,65,124,113,34,2,69,13,0,32,1,65,2,113,13,0,32,2,32,2,40,2,4,65,3,113,32,0,40,2,4,65,124,113,114,54,2,4,11,2,64,32,0,40,2,4,34,2,65,124,113,34,1,69,13,0,32,1,32,1,40,2,0,65,3,113,32,0,40,2,0,65,124,113,114,54,2,0,32,0,65,4,106,40,2,0,33,2,11,32,0,65,4,106,32,2,65,3,113,54,2,0,32,0,32,0,40,2,0,65,3,113,54,2,0,11,193,1,1,3,127,2,64,32,0,69,13,0,32,1,69,13,0,65,0,40,2,128,128,4,33,2,32,0,65,0,54,2,0,32,0,65,120,106,34,1,32,1,40,2,0,34,3,65,126,113,54,2,0,2,64,2,64,2,64,2,64,32,0,65,124,106,40,2,0,65,124,113,34,4,69,13,0,32,4,45,0,0,65,1,113,13,0,32,1,16,59,32,1,45,0,0,65,2,113,69,13,1,32,4,32,4,40,2,0,65,2,114,54,2,0,12,1,11,32,3,65,124,113,34,4,69,13,1,32,3,65,2,113,13,1,32,4,45,0,0,65,1,113,13,1,32,0,32,4,40,2,8,65,124,113,54,2,0,32,4,32,1,65,1,114,54,2,8,11,32,2,33,1,12,1,11,32,0,32,2,54,2,0,11,65,0,32,1,54,2,128,128,4,11,11,6,0,32,0,16,62,11,6,0,32,0,16,57,11,8,0,32,0,32,1,16,60,11,10,0,32,0,32,1,32,2,16,65,11,41,1,1,127,2,64,32,2,16,57,34,3,69,13,0,32,3,32,0,32,2,32,1,32,1,32,2,75,27,16,69,26,32,0,32,1,16,60,11,32,3,11,6,0,32,0,16,67,11,27,1,1,127,2,64,32,0,16,57,34,1,69,13,0,32,1,65,0,32,0,16,68,26,11,32,1,11,44,1,1,127,2,64,32,2,69,13,0,32,0,33,3,3,64,32,3,32,1,58,0,0,32,3,65,1,106,33,3,32,2,65,127,106,34,2,13,0,11,11,32,0,11,54,1,1,127,2,64,32,2,69,13,0,32,0,33,3,3,64,32,3,32,1,45,0,0,58,0,0,32,3,65,1,106,33,3,32,1,65,1,106,33,1,32,2,65,127,106,34,2,13,0,11,11,32,0,11,11,104,3,0,65,128,128,4,11,4,0,0,0,0,0,65,132,128,4,11,12,1,0,0,0,0,0,0,0,0,0,0,0,0,65,144,128,4,11,66,107,101,121,58,32,48,48,48,48,48,48,48,48,48,48,104,101,108,108,111,116,101,115,116,49,114,117,110,49,97,114,103,115,49,116,101,115,116,50,114,117,110,50,97,114,103,115,50,114,117,110,95,116,101,115,116,98,111,98,100,101,112,111,115,105,116,0,219,12,4,110,97,109,101,1,211,12,70,0,9,100,97,116,97,95,114,101,97,100,1,6,97,115,115,101,114,116,2,12,114,101,116,117,114,110,95,118,97,108,117,101,3,13,115,116,111,114,97,103,101,95,119,114,105,116,101,4,14,115,116,111,114,97,103,101,95,114,101,109,111,118,101,5,15,115,116,111,114,97,103,101,95,104,97,115,95,107,101,121,6,5,100,101,98,117,103,7,12,114,101,115,117,108,116,95,99,111,117,110,116,8,12,114,101,115,117,108,116,95,105,115,95,111,107,9,14,112,114,111,109,105,115,101,95,99,114,101,97,116,101,10,11,112,114,111,109,105,115,101,95,97,110,100,11,12,112,114,111,109,105,115,101,95,116,104,101,110,12,14,114,101,116,117,114,110,95,112,114,111,109,105,115,101,13,7,98,97,108,97,110,99,101,14,15,114,101,99,101,105,118,101,100,95,97,109,111,117,110,116,15,8,103,97,115,95,108,101,102,116,16,9,109,97,110,97,95,108,101,102,116,17,11,98,108,111,99,107,95,105,110,100,101,120,18,8,114,97,110,100,111,109,51,50,19,10,114,97,110,100,111,109,95,98,117,102,20,4,104,97,115,104,21,6,104,97,115,104,51,50,22,48,99,111,114,101,58,58,112,116,114,58,58,114,101,97,108,95,100,114,111,112,95,105,110,95,112,108,97,99,101,58,58,104,102,53,101,57,51,53,48,57,54,49,57,55,57,56,51,100,23,14,95,95,114,117,115,116,95,100,101,97,108,108,111,99,24,51,97,108,108,111,99,58,58,115,108,105,99,101,58,58,60,105,109,112,108,32,91,84,93,62,58,58,116,111,95,118,101,99,58,58,104,55,51,99,100,56,54,98,56,49,100,54,52,52,101,50,54,25,62,60,97,108,108,111,99,58,58,114,97,119,95,118,101,99,58,58,82,97,119,86,101,99,60,84,44,32,65,62,62,58,58,97,108,108,111,99,97,116,101,95,105,110,58,58,104,102,98,49,51,97,101,50,48,50,52,53,54,100,57,49,100,26,48,60,97,108,108,111,99,58,58,118,101,99,58,58,86,101,99,60,84,62,62,58,58,114,101,115,101,114,118,101,58,58,104,55,98,99,102,102,48,57,48,53,53,50,57,54,100,50,57,27,76,60,97,108,108,111,99,58,58,118,101,99,58,58,86,101,99,60,84,62,32,97,115,32,99,111,114,101,58,58,111,112,115,58,58,105,110,100,101,120,58,58,73,110,100,101,120,60,73,62,62,58,58,105,110,100,101,120,58,58,104,52,55,100,53,56,98,48,55,101,49,55,48,57,52,102,97,28,76,60,97,108,108,111,99,58,58,118,101,99,58,58,86,101,99,60,84,62,32,97,115,32,99,111,114,101,58,58,111,112,115,58,58,105,110,100,101,120,58,58,73,110,100,101,120,60,73,62,62,58,58,105,110,100,101,120,58,58,104,53,54,55,97,97,49,52,56,52,97,102,53,53,57,51,102,29,32,116,111,95,119,97,115,109,58,58,114,101,97,100,58,58,104,53,100,49,52,53,49,97,51,98,52,97,98,102,57,98,48,30,38,116,111,95,119,97,115,109,58,58,105,110,112,117,116,95,114,101,97,100,58,58,104,54,101,99,53,56,55,48,102,57,51,57,51,54,55,97,100,31,38,116,111,95,119,97,115,109,58,58,114,101,116,117,114,110,95,105,51,50,58,58,104,49,55,51,99,56,51,56,99,56,102,100,51,99,49,55,99,32,38,116,111,95,119,97,115,109,58,58,114,101,116,117,114,110,95,117,54,52,58,58,104,48,100,53,57,50,54,55,50,51,57,54,101,101,52,57,53,33,10,107,101,121,95,116,111,95,115,116,114,34,7,112,117,116,95,105,110,116,35,7,103,101,116,95,105,110,116,36,10,114,101,109,111,118,101,95,105,110,116,37,7,104,97,115,95,105,110,116,38,13,108,111,103,95,115,111,109,101,116,104,105,110,103,39,8,114,117,110,95,116,101,115,116,40,28,114,117,110,95,116,101,115,116,95,119,105,116,104,95,115,116,111,114,97,103,101,95,99,104,97,110,103,101,41,14,115,117,109,95,119,105,116,104,95,105,110,112,117,116,42,14,103,101,116,95,97,99,99,111,117,110,116,95,105,100,43,17,103,101,116,95,111,114,105,103,105,110,97,116,111,114,95,105,100,44,25,115,117,109,95,119,105,116,104,95,109,117,108,116,105,112,108,101,95,114,101,115,117,108,116,115,45,24,99,114,101,97,116,101,95,112,114,111,109,105,115,101,115,95,97,110,100,95,106,111,105,110,46,14,97,110,115,119,101,114,95,116,111,95,108,105,102,101,47,15,116,114,97,110,115,102,101,114,95,116,111,95,98,111,98,48,16,103,101,116,95,112,114,101,118,95,98,97,108,97,110,99,101,49,12,103,101,116,95,103,97,115,95,108,101,102,116,50,13,103,101,116,95,109,97,110,97,95,108,101,102,116,51,15,103,101,116,95,98,108,111,99,107,95,105,110,100,101,120,52,10,97,115,115,101,114,116,95,115,117,109,53,13,103,101,116,95,114,97,110,100,111,109,95,51,50,54,14,103,101,116,95,114,97,110,100,111,109,95,98,117,102,55,16,104,97,115,104,95,103,105,118,101,110,95,105,110,112,117,116,56,18,104,97,115,104,51,50,95,103,105,118,101,110,95,105,110,112,117,116,57,84,60,119,101,101,95,97,108,108,111,99,58,58,87,101,101,65,108,108,111,99,60,39,115,116,97,116,105,99,62,32,97,115,32,99,111,114,101,58,58,97,108,108,111,99,58,58,71,108,111,98,97,108,65,108,108,111,99,62,58,58,97,108,108,111,99,58,58,104,56,100,49,48,56,102,48,50,48,98,101,52,52,99,49,52,58,45,119,101,101,95,97,108,108,111,99,58,58,97,108,108,111,99,95,102,105,114,115,116,95,102,105,116,58,58,104,51,49,51,55,56,48,53,51,102,102,100,98,54,54,54,50,59,67,60,119,101,101,95,97,108,108,111,99,58,58,110,101,105,103,104,98,111,114,115,58,58,78,101,105,103,104,98,111,114,115,60,39,97,44,32,84,62,62,58,58,114,101,109,111,118,101,58,58,104,102,52,53,55,98,56,54,98,97,98,54,56,98,57,55,55,60,86,60,119,101,101,95,97,108,108,111,99,58,58,87,101,101,65,108,108,111,99,60,39,115,116,97,116,105,99,62,32,97,115,32,99,111,114,101,58,58,97,108,108,111,99,58,58,71,108,111,98,97,108,65,108,108,111,99,62,58,58,100,101,97,108,108,111,99,58,58,104,102,55,49,56,49,56,102,100,48,49,48,101,52,57,50,50,61,12,95,95,114,117,115,116,95,97,108,108,111,99,62,10,95,95,114,103,95,97,108,108,111,99,63,12,95,95,114,103,95,100,101,97,108,108,111,99,64,14,95,95,114,117,115,116,95,114,101,97,108,108,111,99,65,12,95,95,114,103,95,114,101,97,108,108,111,99,66,19,95,95,114,117,115,116,95,97,108,108,111,99,95,122,101,114,111,101,100,67,17,95,95,114,103,95,97,108,108,111,99,95,122,101,114,111,101,100,68,6,109,101,109,115,101,116,69,6,109,101,109,99,112,121,0,89,9,112,114,111,100,117,99,101,114,115,2,8,108,97,110,103,117,97,103,101,1,4,82,117,115,116,4,50,48,49,53,12,112,114,111,99,101,115,115,101,100,45,98,121,1,5,114,117,115,116,99,37,49,46,51,53,46,48,45,110,105,103,104,116,108,121,32,40,56,56,102,55,53,53,102,56,97,32,50,48,49,57,45,48,51,45,48,55,41],"authority_rotation":"ProofOfAuthority","boot_nodes":[]}

'''
'''--- docs/logo.svg ---
<svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 433 180.5"><defs><style>.cls-1{fill:url(#linear-gradient);}.cls-2{fill:#4a4f54;}</style><linearGradient id="linear-gradient" x1="40.11" y1="140.87" x2="140.87" y2="40.11" gradientUnits="userSpaceOnUse"><stop offset="0.21" stop-color="#4a4f54"/><stop offset="0.42" stop-color="#4a4f54" stop-opacity="0"/><stop offset="0.59" stop-color="#4a4f54" stop-opacity="0"/><stop offset="0.81" stop-color="#4a4f54"/></linearGradient></defs><title>near_logo</title><path class="cls-1" d="M48.84,144.5a12.32,12.32,0,0,0,9.35-4.28h0l84.42-97.93a12.32,12.32,0,0,0-10.45-5.79h0a12.31,12.31,0,0,0-9.31,4.24L38,138.09A12.34,12.34,0,0,0,48.84,144.5Z"/><path class="cls-2" d="M48.84,144.5a12.38,12.38,0,0,0,5.66-1.37V61.36l65.58,78.7a12.37,12.37,0,0,0,9.49,4.44h2.59a12.35,12.35,0,0,0,12.34-12.34V48.84A12.35,12.35,0,0,0,132.16,36.5h0a12.45,12.45,0,0,0-5.62,1.35v81.79L60.92,40.94a12.37,12.37,0,0,0-9.49-4.44H48.84A12.35,12.35,0,0,0,36.5,48.84v83.32A12.35,12.35,0,0,0,48.84,144.5Z"/><path class="cls-2" d="M225.71,64.25v52.5a.76.76,0,0,1-.75.75h-5.51a7.49,7.49,0,0,1-6.3-3.43l-24.78-38.3.85,19.13v21.85a.76.76,0,0,1-.75.75h-7.22a.76.76,0,0,1-.75-.75V64.25a.76.76,0,0,1,.75-.75h5.43a7.52,7.52,0,0,1,6.3,3.42l24.78,38.24L217,86.1V64.25a.75.75,0,0,1,.75-.75H225A.76.76,0,0,1,225.71,64.25Z"/><path class="cls-2" d="M299.51,117.5h-7.64a.75.75,0,0,1-.7-1L311.4,64.22a1.14,1.14,0,0,1,1.05-.72H322a1.14,1.14,0,0,1,1.05.72l20.23,52.26a.75.75,0,0,1-.7,1H335a.76.76,0,0,1-.71-.48L317.94,74a.75.75,0,0,0-1.41,0l-16.31,43A.76.76,0,0,1,299.51,117.5Z"/><path class="cls-2" d="M396.34,116.29,381.16,96.9c8.57-1.62,13.58-7.4,13.58-16.27,0-10.19-6.63-17.13-18.36-17.13H355.21a1.12,1.12,0,0,0-1.12,1.12h0a7.2,7.2,0,0,0,7.2,7.21h14.17c7.09,0,10.49,3.63,10.49,8.87s-3.32,9-10.49,9H355.21a1.13,1.13,0,0,0-1.12,1.13v26a.75.75,0,0,0,.75.75h7.22a.76.76,0,0,0,.75-.75V97.37h8.33l13.17,17.19a7.51,7.51,0,0,0,6,2.94h5.48A.75.75,0,0,0,396.34,116.29Z"/><path class="cls-2" d="M276.67,63.5h-33.5a1,1,0,0,0-1,1h0a7.33,7.33,0,0,0,7.33,7.33h27.17a.74.74,0,0,0,.75-.75V64.25A.75.75,0,0,0,276.67,63.5Zm0,45.67h-25a.76.76,0,0,1-.75-.75V94.88a.75.75,0,0,1,.75-.75h23.11a.75.75,0,0,0,.75-.75V86.54a.75.75,0,0,0-.75-.75H243.29a1.13,1.13,0,0,0-1.12,1.13v29.45a1.12,1.12,0,0,0,1.12,1.13h33.38a.75.75,0,0,0,.75-.75v-6.83A.74.74,0,0,0,276.67,109.17Z"/></svg>
'''
'''--- filesys-api/Cargo.toml ---
[package]
name                      = "filesys-api"
description               = "Implementation of an IPFS HTTP API client"
authors                   = ["Ferris Tseng <ferristseng@fastmail.fm>"]
documentation             = "https://docs.rs/ipfs-api"
repository                = "https://github.com/ferristseng/rust-ipfs-api"
keywords                  = ["ipfs"]
categories                = ["filesystem", "web-programming"]
version                   = "0.5.1"
readme                    = "../README.md"
license                   = "MIT OR Apache-2.0"

[badges]
travis-ci                 = { repository = "ferristseng/rust-ipfs-api" }

[features]
default                   = ["hyper", "hyper-multipart-rfc7578", "hyper-tls"]
actix                     = ["actix-web", "actix-multipart-rfc7578"]

[dependencies]
actix-multipart-rfc7578   = { version = "0.1", optional = true }
actix-web                 = { version = "0.7", optional = true }
bytes                     = "0.4"
failure                   = "0.1.5"
futures                   = "0.1.27"
http                      = "0.1"
hyper                     = { version = "0.12", optional = true }
hyper-tls                 = { version = "0.3.2", optional = true }
hyper-multipart-rfc7578   = { version = "0.3", optional = true }
serde                     = "1.0"
serde_derive              = "1.0"
serde_json                = "1.0"
serde_urlencoded          = "0.5"
tokio                     = "0.1.12"
tokio-codec               = "0.1.1"
tokio-io                  = "0.1.12"
walkdir                   = "2.2"
dirs                      = "1.0"
multiaddr                 = "0.3.1"

[dev-dependencies]
actix-multipart-rfc7578   = "0.1"
actix-web                 = "0.7"
hyper                     = "0.12"
hyper-tls                 = "0.3.2"
tokio-timer               = "0.2"
tar                       = "0.4"

'''
'''--- filesys-api/examples/add_file.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;
use std::fs::File;

// Creates an Ipfs client, and adds this source file to Ipfs.
//
fn main() {
    println!("note: this must be run in the root of the project repository");
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();
    let file = File::open(file!()).expect("could not read source file");
    let req = client
        .add(file)
        .map(|add| println!("added file: {:?}", add))
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/add_tar.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;
extern crate tar;

use futures::{Future, Stream};
use filesys_api::FileSysClient;
use std::io::Cursor;
use tar::Builder;

// Creates an Ipfs client, and adds this source file to Ipfs.
//
fn main() {
    println!("note: this must be run in the root of the project repository");
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    let mut buf = Vec::new();

    // Create a in-memory tar file with this source file as its contents.
    //
    {
        let mut builder = Builder::new(&mut buf);

        builder
            .append_path(file!())
            .expect("failed to create tar file");
        builder.finish().expect("failed to create tar file");
    }

    let cursor = Cursor::new(buf);
    let req = client
        .tar_add(cursor)
        .and_then(move |add| {
            println!("added tar file: {:?}", add);
            println!();

            client.tar_cat(&add.hash[..]).concat2()
        })
        .map(|cat| {
            println!("{}", String::from_utf8_lossy(&cat[..]));
            println!();
        })
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/bootstrap_default.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

// Lists clients in bootstrap list, then adds the default list, then removes
// them, and readds them.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    let bootstrap = client.bootstrap_list().map(|bootstrap| {
        println!("current bootstrap peers:");
        for peer in bootstrap.peers {
            println!("  {}", peer);
        }
    });

    let drop = client.bootstrap_rm_all().map(|drop| {
        println!("dropped:");
        for peer in drop.peers {
            println!("  {}", peer);
        }
    });

    let add = client.bootstrap_add_default().map(|add| {
        println!("added:");
        for peer in add.peers {
            println!("  {}", peer);
        }
    });

    let fut = bootstrap
        .and_then(|_| {
            println!();
            println!("dropping all bootstrap peers...");

            drop
        })
        .and_then(|_| {
            println!();
            println!("adding default peers...");

            add
        })
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/default_config.json ---
{
  "Identity": {
    "PeerID": "QmVRF8ZnT1ootg5vSrzS4ws8W8NwzF5q5MUCzfNK6ZmYeH"
  },
  "Datastore": {
    "StorageMax": "10GB",
    "StorageGCWatermark": 90,
    "GCPeriod": "1h",
    "Spec": {
      "mounts": [
        {
          "child": {
            "path": "blocks",
            "shardFunc": "/repo/flatfs/shard/v1/next-to-last/2",
            "sync": true,
            "type": "flatfs"
          },
          "mountpoint": "/blocks",
          "prefix": "flatfs.datastore",
          "type": "measure"
        },
        {
          "child": {
            "compression": "none",
            "path": "datastore",
            "type": "levelds"
          },
          "mountpoint": "/",
          "prefix": "leveldb.datastore",
          "type": "measure"
        }
      ],
      "type": "mount"
    },
    "HashOnRead": false,
    "BloomFilterSize": 0
  },
  "Addresses": {
    "Swarm": [
      "/ip4/0.0.0.0/tcp/4001",
      "/ip6/::/tcp/4001"
    ],
    "Announce": [],
    "NoAnnounce": [],
    "API": "/ip4/127.0.0.1/tcp/5001",
    "Gateway": "/ip4/127.0.0.1/tcp/8080"
  },
  "Mounts": {
    "IPFS": "/ipfs",
    "IPNS": "/ipns",
    "FuseAllowOther": false
  },
  "Discovery": {
    "MDNS": {
      "Enabled": true,
      "Interval": 10
    }
  },
  "Ipns": {
    "RepublishPeriod": "",
    "RecordLifetime": "",
    "ResolveCacheSize": 128
  },
  "Bootstrap": [
    "/dnsaddr/bootstrap.libp2p.io/ipfs/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN",
    "/dnsaddr/bootstrap.libp2p.io/ipfs/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa",
    "/dnsaddr/bootstrap.libp2p.io/ipfs/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb",
    "/dnsaddr/bootstrap.libp2p.io/ipfs/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt",
    "/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
    "/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd",
    "/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd"
  ],
  "Gateway": {
    "HTTPHeaders": {
      "Access-Control-Allow-Headers": [
        "X-Requested-With",
        "Range"
      ],
      "Access-Control-Allow-Methods": [
        "GET"
      ],
      "Access-Control-Allow-Origin": [
        "*"
      ]
    },
    "RootRedirect": "",
    "Writable": false,
    "PathPrefixes": []
  },
  "API": {
    "HTTPHeaders": null
  },
  "Swarm": {
    "AddrFilters": null,
    "DisableBandwidthMetrics": false,
    "DisableNatPortMap": false,
    "DisableRelay": false,
    "EnableRelayHop": false,
    "ConnMgr": {
      "Type": "basic",
      "LowWater": 600,
      "HighWater": 900,
      "GracePeriod": "20s"
    }
  },
  "Reprovider": {
    "Interval": "12h",
    "Strategy": "all"
  },
  "Experimental": {
    "FilestoreEnabled": false,
    "ShardingEnabled": false,
    "Libp2pStreamMounting": false
  }
}

'''
'''--- filesys-api/examples/dns.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

// Creates an Ipfs client, resolves ipfs.io, and lists the contents of it.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    let req = client
        .dns("ipfs.io", false)
        .and_then(move |dns| {
            println!("dns resolves to ({})", &dns.path);
            println!();

            client.file_ls(&dns.path[..])
        })
        .map(|contents| {
            println!("found contents:");
            for directory in contents.objects.values() {
                for file in directory.links.iter() {
                    println!("[{}] ({} bytes)", file.name, file.size);
                }
            }
        })
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/get_commands.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::{response, FileSysClient};

fn print_recursive(indent: usize, cmd: &response::CommandsResponse) {
    let cmd_indent = " ".repeat(indent * 4);
    let opt_indent = " ".repeat((indent + 1) * 4);

    println!("{}[{}]", cmd_indent, cmd.name);

    if cmd.options.len() > 0 {
        println!("{}* options:", cmd_indent);
        for options in cmd.options.iter() {
            println!("{}{}", opt_indent, &options.names[..].join(", "));
        }
    }

    if cmd.subcommands.len() > 0 {
        println!("{}- subcommands:", cmd_indent);
        for subcommand in cmd.subcommands.iter() {
            print_recursive(indent + 1, subcommand);
        }
    }
}

// Creates an Ipfs client, and gets a list of available commands from the
// Ipfs server.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();
    let req = client
        .commands()
        .map(|commands| print_recursive(0, &commands))
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/get_stats.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

// Creates an Ipfs client, and gets some stats about the Ipfs server.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    let bitswap_stats = client.stats_bitswap().map(|bitswap_stats| {
        println!("bitswap stats:");
        println!("  blocks recv: {}", bitswap_stats.blocks_received);
        println!("  data   recv: {}", bitswap_stats.data_received);
        println!("  blocks sent: {}", bitswap_stats.blocks_sent);
        println!("  data   sent: {}", bitswap_stats.data_sent);
        println!(
            "  peers:       {}",
            bitswap_stats.peers.join("\n               ")
        );
        println!(
            "  wantlist:    {}",
            bitswap_stats.wantlist.join("\n               ")
        );
        println!();
    });

    let bw_stats = client.stats_bw().map(|bw_stats| {
        println!("bandwidth stats:");
        println!("  total    in: {}", bw_stats.total_in);
        println!("  total   out: {}", bw_stats.total_out);
        println!("  rate     in: {}", bw_stats.rate_in);
        println!("  rate    out: {}", bw_stats.rate_out);
        println!();
    });

    let repo_stats = client.stats_repo().map(|repo_stats| {
        println!("repo stats:");
        println!("  num    objs: {}", repo_stats.num_objects);
        println!("  repo   size: {}", repo_stats.repo_size);
        println!("  repo   path: {}", repo_stats.repo_path);
        println!("  version    : {}", repo_stats.version);
    });

    let fut = bitswap_stats
        .and_then(|_| bw_stats)
        .and_then(|_| repo_stats)
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/get_swarm.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

// Creates an Ipfs client, and gets information about your local address, and
// connected peers.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    let local = client.swarm_addrs_local().map(|local| {
        println!();
        println!("your addrs:");
        for addr in local.strings {
            println!("  {}", addr);
        }
    });

    let connected = client.swarm_peers().map(|connected| {
        println!();
        println!("connected:");
        for peer in connected.peers {
            let streams: Vec<&str> = peer.streams.iter().map(|s| &s.protocol[..]).collect();
            println!("  addr:     {}", peer.addr);
            println!("  peer:     {}", peer.peer);
            println!("  latency:  {}", peer.latency);
            println!("  muxer:    {}", peer.muxer);
            println!("  streams:  {}", streams.join(", "));
            println!();
        }
    });

    let fut = local
        .and_then(|_| connected)
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/get_version.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

// Creates an Ipfs client, and gets the version of the Ipfs server.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();
    let req = client
        .version()
        .map(|version| println!("version: {:?}", version.version));

    let fut = req.map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/mfs.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::{response, FileSysClient};
use std::fs::File;

fn print_stat(stat: response::FilesStatResponse) {
    println!("  type     : {}", stat.typ);
    println!("  hash     : {}", stat.hash);
    println!("  size     : {}", stat.size);
    println!("  cum. size: {}", stat.cumulative_size);
    println!("  blocks   : {}", stat.blocks);
    println!();
}

// Creates an Ipfs client, and makes some calls to the Mfs Api.
//
fn main() {
    println!("note: this must be run in the root of the project repository");
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    println!("making /test...");
    println!();

    let mkdir = client.files_mkdir("/test", false);
    let mkdir_recursive = client.files_mkdir("/test/does/not/exist/yet", true);

    let file_stat = client.files_stat("/test/does");

    let src = File::open(file!()).expect("could not read source file");
    let file_write = client.files_write("/test/mfs.rs", true, true, src);

    let file_write_stat = client.files_stat("/test/mfs.rs");

    let file_rm = client.files_rm("/test", true);

    let fut = mkdir
        .and_then(|_| {
            println!("making dirs /test/does/not/exist/yet...");
            println!();

            mkdir_recursive
        })
        .and_then(|_| {
            println!("getting status of /test/does...");
            println!();

            file_stat
        })
        .and_then(|stat| {
            print_stat(stat);

            println!("writing source file to /test/mfs.rs");
            println!();

            file_write
        })
        .and_then(|_| file_write_stat)
        .and_then(|stat| {
            print_stat(stat);

            println!("removing /test...");
            println!();

            file_rm
        })
        .map(|_| println!("done!"))
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/ping_peer.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::{Future, Stream};
use filesys_api::{response::PingResponse, FileSysClient};

// Creates an Ipfs client, discovers a connected peer, and pings it using the
// streaming Api, and by collecting it into a collection.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();

    println!();
    println!("discovering connected peers...");

    let req = client
        .swarm_peers()
        .and_then(move |connected| {
            let peer = connected
                .peers
                .iter()
                .next()
                .expect("expected at least one peer");

            println!();
            println!("discovered peer ({})", peer.peer);
            println!();
            println!("streaming 10 pings...");

            let ping_stream = client.ping(&peer.peer[..], Some(10)).for_each(|ping| {
                println!("{:?}", ping);
                Ok(())
            });

            let ping_gather = client.ping(&peer.peer[..], Some(15)).collect();

            ping_stream.and_then(|_| {
                println!();
                println!("gathering 15 pings...");

                ping_gather
            })
        })
        .map(|pings: Vec<PingResponse>| {
            for ping in pings.iter() {
                println!("got response ({:?}) at ({})...", ping.text, ping.time);
            }
        })
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/pubsub.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;
extern crate tokio_timer;

use futures::{Future, Stream};
use filesys_api::FileSysClient;
use std::{
    thread,
    time::{Duration, Instant},
};
use tokio_timer::Interval;

static TOPIC: &'static str = "test";

fn get_client() -> FileSysClient {
    println!("connecting to localhost:5001...");

    FileSysClient::default()
}

// Creates an Ipfs client, and simultaneously publishes and reads from a pubsub
// topic.
//
fn main() {
    // This block will execute a repeating function that sends
    // a message to the "test" topic.
    //
    thread::spawn(move || {
        let client = get_client();
        let publish = Interval::new(Instant::now(), Duration::from_secs(1))
            .map_err(|e| eprintln!("{}", e))
            .for_each(move |_| {
                println!();
                println!("publishing message...");

                client
                    .pubsub_pub(TOPIC, "Hello World!")
                    .map_err(|e| eprintln!("{}", e))
            });

        println!();
        println!("starting task to publish messages to ({})...", TOPIC);

        #[cfg(feature = "hyper")]
        hyper::rt::run(publish);
        #[cfg(feature = "actix")]
        actix_web::actix::spawn(publish);
    });

    // This block will execute a future that suscribes to a topic,
    // and reads any incoming messages.
    //
    {
        let client = get_client();
        let req = client.pubsub_sub(TOPIC, false);

        println!();
        println!("waiting for messages on ({})...", TOPIC);
        let fut = req
            .take(5)
            .for_each(|msg| {
                println!();
                println!("received ({:?})", msg);

                Ok(())
            })
            .map_err(|e| eprintln!("{}", e));

        #[cfg(feature = "hyper")]
        hyper::rt::run(fut);
        #[cfg(feature = "actix")]
        actix_web::actix::run(|| {
            fut.then(|_| {
                actix_web::actix::System::current().stop();
                Ok(())
            })
        });
    }
}

'''
'''--- filesys-api/examples/replace_config.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;
use std::io::Cursor;

// Creates an Ipfs client, and replaces the config file with the default one.
//
fn main() {
    println!("note: this must be run in the root of the project repository");
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();
    let default_config = include_str!("default_config.json");
    let req = client
        .config_replace(Cursor::new(default_config))
        .map(|_| println!("replaced file"))
        .map_err(|e| println!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(req);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        req.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/examples/resolve_name.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[cfg(feature = "actix")]
extern crate actix_web;
extern crate futures;
#[cfg(feature = "hyper")]
extern crate hyper;
extern crate filesys_api;

use futures::Future;
use filesys_api::FileSysClient;

const IPFS_IPNS: &str = "/ipns/ipfs.io";

// Creates an Ipfs client, and resolves the Ipfs domain name, and
// publishes a path to Ipns.
//
fn main() {
    println!("connecting to localhost:5001...");

    let client = FileSysClient::default();
    let name_resolve = client
        .name_resolve(Some(IPFS_IPNS), true, false)
        .map(|resolved| {
            println!("{} resolves to: {}", IPFS_IPNS, &resolved.path);
        });

    let name_publish = client
        .name_publish(IPFS_IPNS, true, None, None, None)
        .and_then(move |publish| {
            println!("published {} to: /ipns/{}", IPFS_IPNS, &publish.name);

            client
                .name_resolve(Some(&publish.name), true, false)
                .map(move |resolved| {
                    println!("/ipns/{} resolves to: {}", &publish.name, &resolved.path);
                })
        });

    let fut = name_resolve
        .and_then(|_| name_publish)
        .map_err(|e| eprintln!("{}", e));

    #[cfg(feature = "hyper")]
    hyper::rt::run(fut);
    #[cfg(feature = "actix")]
    actix_web::actix::run(|| {
        fut.then(|_| {
            actix_web::actix::System::current().stop();
            Ok(())
        })
    });
}

'''
'''--- filesys-api/src/client.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//
#[cfg(feature = "actix")]
use actix_multipart::client::multipart;
#[cfg(feature = "actix")]
use actix_web::HttpMessage;
use bytes::Bytes;
use futures::{
    future,
    stream::{self, Stream},
    Future, IntoFuture,
};
use header::TRAILER;
use http::uri::{InvalidUri, Uri};
use http::StatusCode;
#[cfg(feature = "hyper")]
use hyper::client::{Client, HttpConnector};
#[cfg(feature = "hyper")]
use hyper_multipart::client::multipart;
#[cfg(feature = "hyper")]
use hyper_tls::HttpsConnector;
use multiaddr::{AddrComponent, ToMultiaddr};
use read::{JsonLineDecoder, LineDecoder, StreamReader};
use request::{self, ApiRequest};
use response::{self, Error};
use serde::{Deserialize, Serialize};
use serde_json;
use std::{
    fs,
    io::Read,
    net::{IpAddr, SocketAddr},
    path::{Path, PathBuf},
};
use tokio_codec::{Decoder, FramedRead};

/// A response returned by the HTTP client.
///
#[cfg(feature = "actix")]
type AsyncResponse<T> = Box<Future<Item = T, Error = Error> + 'static>;
#[cfg(feature = "hyper")]
type AsyncResponse<T> = Box<Future<Item = T, Error = Error> + Send + 'static>;

/// A future that returns a stream of responses.
///
#[cfg(feature = "actix")]
type AsyncStreamResponse<T> = Box<Stream<Item = T, Error = Error> + 'static>;
#[cfg(feature = "hyper")]
type AsyncStreamResponse<T> = Box<Stream<Item = T, Error = Error> + Send + 'static>;

#[cfg(feature = "actix")]
type Request = actix_web::client::ClientRequest;
#[cfg(feature = "hyper")]
type Request = http::Request<hyper::Body>;

#[cfg(feature = "actix")]
type Response = actix_web::client::ClientResponse;
#[cfg(feature = "hyper")]
type Response = http::Response<hyper::Body>;

/// Asynchronous Ipfs client.
///
#[derive(Clone)]
pub struct FileSysClient {
    base: Uri,
    #[cfg(feature = "hyper")]
    client: Client<HttpsConnector<HttpConnector>, hyper::Body>,
}

impl Default for FileSysClient {
    /// Creates an `FileSysClient` connected to the endpoint specified in ~/.handler/api.
    /// If not found, tries to connect to `localhost:5001`.
    ///
    fn default() -> FileSysClient {
        dirs::home_dir()
            .map(|home_dir| home_dir.join(".handler").join("api"))
            .and_then(|multiaddr_path| fs::read_to_string(&multiaddr_path).ok())
            .and_then(|multiaddr_str| multiaddr_str.to_multiaddr().ok())
            .and_then(|multiaddr| {
                let mut addr: Option<IpAddr> = None;
                let mut port: Option<u16> = None;
                for addr_component in multiaddr.iter() {
                    match addr_component {
                        AddrComponent::IP4(v4addr) => addr = Some(v4addr.into()),
                        AddrComponent::IP6(v6addr) => addr = Some(v6addr.into()),
                        AddrComponent::TCP(tcpport) => port = Some(tcpport),
                        _ => {
                            return None;
                        }
                    }
                }
                if let (Some(addr), Some(port)) = (addr, port) {
                    Some(SocketAddr::new(addr, port))
                } else {
                    None
                }
            })
            .map(FileSysClient::from)
            .unwrap_or_else(|| FileSysClient::new("localhost", 5001).unwrap())
    }
}

impl From<SocketAddr> for FileSysClient {
    fn from(socket_addr: SocketAddr) -> Self {
        FileSysClient::new(&socket_addr.ip().to_string(), socket_addr.port()).unwrap()
    }
}

impl FileSysClient {
    /// Creates a new `FileSysClient`.
    ///
    #[inline]
    pub fn new(host: &str, port: u16) -> Result<FileSysClient, InvalidUri> {
        Self::new_from_uri(format!("http://{}:{}", host, port).as_str())
    }

    /// Creates a new `FileSysClient` for any given URI.
    #[inline]
    pub fn new_from_uri(uri: &str) -> Result<FileSysClient, InvalidUri> {
        let base_path = FileSysClient::build_base_path(uri)?;

        Ok(FileSysClient {
            base: base_path,
            #[cfg(feature = "hyper")]
            client: {
                let connector = HttpsConnector::new(4).unwrap();
                Client::builder().keep_alive(false).build(connector)
            },
        })
    }

    /// Builds the base url path for the Ipfs api.
    ///
    fn build_base_path(uri: &str) -> Result<Uri, InvalidUri> {
        format!("{}/api/v0", uri).parse()
    }

    /// Builds the url for an api call.
    ///
    fn build_base_request<Req>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> Result<Request, Error>
    where
        Req: ApiRequest + Serialize,
    {
        let url = format!(
            "{}{}?{}",
            self.base,
            Req::PATH,
            ::serde_urlencoded::to_string(req)?
        );
        #[cfg(feature = "hyper")]
        let req = url.parse::<Uri>().map_err(From::from).and_then(move |url| {
            let mut builder = http::Request::builder();
            let mut builder = builder.method(Req::METHOD.clone()).uri(url);

            let req = if let Some(form) = form {
                form.set_body_convert::<hyper::Body, multipart::Body>(&mut builder)
            } else {
                builder.body(hyper::Body::empty())
            };

            req.map_err(From::from)
        });
        #[cfg(feature = "actix")]
        let req = if let Some(form) = form {
            Request::build()
                .method(Req::METHOD.clone())
                .uri(url)
                .content_type(form.content_type())
                .streaming(multipart::Body::from(form))
                .map_err(From::from)
        } else {
            Request::build()
                .method(Req::METHOD.clone())
                .uri(url)
                .finish()
                .map_err(From::from)
        };
        req
    }

    /// Builds an Api error from a response body.
    ///
    #[inline]
    fn build_error_from_body(chunk: Bytes) -> Error {
        match serde_json::from_slice(&chunk) {
            Ok(e) => Error::Api(e),
            Err(_) => match String::from_utf8(chunk.to_vec()) {
                Ok(s) => Error::Uncategorized(s),
                Err(e) => e.into(),
            },
        }
    }

    /// Processes a response that expects a json encoded body, returning an
    /// error or a deserialized json response.
    ///
    fn process_json_response<Res>(status: StatusCode, chunk: Bytes) -> Result<Res, Error>
    where
        for<'de> Res: 'static + Deserialize<'de>,
    {
        match status {
            StatusCode::OK => serde_json::from_slice(&chunk).map_err(From::from),
            _ => Err(Self::build_error_from_body(chunk)),
        }
    }

    /// Processes a response that returns a stream of json deserializable
    /// results.
    ///
    fn process_stream_response<D, Res>(res: Response, decoder: D) -> AsyncStreamResponse<Res>
    where
        D: 'static + Decoder<Item = Res, Error = Error> + Send,
        Res: 'static,
    {
        #[cfg(feature = "hyper")]
        let stream = FramedRead::new(
            StreamReader::new(res.into_body().map(|c| c.into_bytes()).from_err()),
            decoder,
        );

        #[cfg(feature = "actix")]
        let stream = FramedRead::new(StreamReader::new(res.payload().from_err()), decoder);

        Box::new(stream)
    }

    /// Generates a request, and returns the unprocessed response future.
    ///
    fn request_raw<Req>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncResponse<(StatusCode, Bytes)>
    where
        Req: ApiRequest + Serialize,
    {
        match self.build_base_request(req, form) {
            Ok(req) => {
                #[cfg(feature = "hyper")]
                let res = self
                    .client
                    .request(req)
                    .and_then(|res| {
                        let status = res.status();

                        res.into_body()
                            .concat2()
                            .map(move |chunk| (status, chunk.into_bytes()))
                    })
                    .from_err();
                #[cfg(feature = "actix")]
                let res = req
                    .send()
                    .timeout(std::time::Duration::from_secs(90))
                    .from_err()
                    .and_then(|x| {
                        let status = x.status();
                        x.body().map(move |body| (status, body)).from_err()
                    });
                Box::new(res)
            }
            Err(e) => Box::new(Err(e).into_future()),
        }
    }

    /// Generic method for making a request that expects back a streaming
    /// response.
    ///
    fn request_stream<Req, Res, F>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
        process: F,
    ) -> AsyncStreamResponse<Res>
    where
        Req: ApiRequest + Serialize,
        Res: 'static + Send,
        F: 'static + Fn(Response) -> AsyncStreamResponse<Res> + Send,
    {
        #[cfg(feature = "hyper")]
        match self.build_base_request(req, form) {
            Ok(req) => {
                let res = self
                    .client
                    .request(req)
                    .from_err()
                    .map(move |res| {
                        let stream: Box<Stream<Item = Res, Error = _> + Send + 'static> =
                            match res.status() {
                                StatusCode::OK => process(res),
                                // If the server responded with an error status code, the body
                                // still needs to be read so an error can be built. This block will
                                // read the entire body stream, then immediately return an error.
                                //
                                _ => Box::new(
                                    res.into_body()
                                        .concat2()
                                        .from_err()
                                        .and_then(|chunk| {
                                            Err(Self::build_error_from_body(chunk.into_bytes()))
                                        })
                                        .into_stream(),
                                ),
                            };

                        stream
                    })
                    .flatten_stream();
                Box::new(res)
            }
            Err(e) => Box::new(stream::once(Err(e))),
        }
        #[cfg(feature = "actix")]
        match self.build_base_request(req, form) {
            Ok(req) => {
                let res = req
                    .send()
                    .timeout(std::time::Duration::from_secs(90))
                    .from_err();
                Box::new(res.map(process).flatten_stream())
            }
            Err(e) => Box::new(stream::once(Err(e))),
        }
    }

    /// Generic method for making a request to the Ipfs server, and getting
    /// a deserializable response.
    ///
    fn request<Req, Res>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncResponse<Res>
    where
        Req: ApiRequest + Serialize,
        for<'de> Res: 'static + Deserialize<'de> + Send,
    {
        let res = self
            .request_raw(req, form)
            .and_then(|(status, chunk)| FileSysClient::process_json_response(status, chunk));

        Box::new(res)
    }

    /// Generic method for making a request to the Ipfs server, and getting
    /// back a response with no body.
    ///
    fn request_empty<Req>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncResponse<()>
    where
        Req: ApiRequest + Serialize,
    {
        let res = self
            .request_raw(req, form)
            .and_then(|(status, chunk)| match status {
                StatusCode::OK => Ok(()),
                _ => Err(Self::build_error_from_body(chunk)),
            });

        Box::new(res)
    }

    /// Generic method for making a request to the Ipfs server, and getting
    /// back a raw String response.
    ///
    fn request_string<Req>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncResponse<String>
    where
        Req: ApiRequest + Serialize,
    {
        let res = self
            .request_raw(req, form)
            .and_then(|(status, chunk)| match status {
                StatusCode::OK => String::from_utf8(chunk.to_vec()).map_err(From::from),
                _ => Err(Self::build_error_from_body(chunk)),
            });

        Box::new(res)
    }

    /// Generic method for making a request to the Ipfs server, and getting
    /// back a raw stream of bytes.
    ///
    fn request_stream_bytes<Req>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncStreamResponse<Bytes>
    where
        Req: ApiRequest + Serialize,
    {
        #[cfg(feature = "hyper")]
        let res = self.request_stream(req, form, |res| {
            Box::new(res.into_body().from_err().map(|c| c.into_bytes()))
        });
        #[cfg(feature = "actix")]
        let res = self.request_stream(req, form, |res| Box::new(res.payload().from_err()));
        res
    }

    /// Generic method to return a streaming response of deserialized json
    /// objects delineated by new line separators.
    ///
    fn request_stream_json<Req, Res>(
        &self,
        req: &Req,
        form: Option<multipart::Form<'static>>,
    ) -> AsyncStreamResponse<Res>
    where
        Req: ApiRequest + Serialize,
        for<'de> Res: 'static + Deserialize<'de> + Send,
    {
        self.request_stream(req, form, |res| {
            let parse_stream_error = if let Some(trailer) = res.headers().get(TRAILER) {
                // Response has the Trailer header set. The StreamError trailer
                // is used to indicate that there was an error while streaming
                // data with Ipfs.
                //
                if trailer == "X-Stream-Error" {
                    true
                } else {
                    let err = Error::UnrecognizedTrailerHeader(
                        String::from_utf8_lossy(trailer.as_ref()).into(),
                    );

                    // There was an unrecognized trailer value. If that is the case,
                    // create a stream that immediately errors.
                    //
                    return Box::new(stream::once(Err(err)));
                }
            } else {
                false
            };

            Box::new(FileSysClient::process_stream_response(
                res,
                JsonLineDecoder::new(parse_stream_error),
            ))
        })
    }
}

impl FileSysClient {
    /// Add file to Ipfs.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    /// use std::io::Cursor;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let data = Cursor::new("Hello World!");
    /// let req = client.add(data);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn add<R>(&self, data: R) -> AsyncResponse<response::AddResponse>
    where
        R: 'static + Read + Send,
    {
        let mut form = multipart::Form::default();

        form.add_reader("path", data);

        self.request(&request::Add, Some(form))
    }

    /// Add a path to Ipfs. Can be a file or directory.
    /// A hard limit of 128 open file descriptors is set such
    /// that any small additional files are stored in-memory.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let path = "./src";
    /// let req = client.add_path(path);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn add_path<P>(&self, path: P) -> AsyncResponse<response::AddResponse>
    where
        P: AsRef<Path>,
    {
        let mut form = multipart::Form::default();

        let prefix = path.as_ref().parent();

        let mut paths_to_add: Vec<(PathBuf, u64)> = vec![];

        for path in walkdir::WalkDir::new(path.as_ref()) {
            match path {
                Ok(entry) => {
                    if entry.file_type().is_file() {
                        let file_size =
                            entry.metadata().map(|metadata| metadata.len()).unwrap_or(0);
                        paths_to_add.push((entry.path().to_path_buf(), file_size));
                    }
                }
                Err(err) => {
                    return Box::new(future::err(Error::Io(err.into())));
                }
            }
        }

        paths_to_add.sort_unstable_by(|(_, a), (_, b)| a.cmp(b).reverse());

        let mut it = 0;
        const FILE_DESCRIPTOR_LIMIT: usize = 127;

        for (path, file_size) in paths_to_add {
            let file = std::fs::File::open(&path);
            if file.is_err() {
                return Box::new(future::err(file.unwrap_err().into()));
            }
            let file_name = match prefix {
                Some(prefix) => path.strip_prefix(prefix).unwrap(),
                None => path.as_path(),
            }
            .to_string_lossy();

            if it < FILE_DESCRIPTOR_LIMIT {
                form.add_reader_file("path", file.unwrap(), file_name);
                it += 1;
            } else {
                let mut buf = Vec::with_capacity(file_size as usize);
                if let Err(err) = file.unwrap().read_to_end(&mut buf) {
                    return Box::new(future::err(err.into()));
                }
                form.add_reader_file("path", std::io::Cursor::new(buf), file_name);
            }
        }

        Box::new(
            self.request_stream_json(&request::Add, Some(form))
                .collect()
                .map(|mut responses: Vec<response::AddResponse>| responses.pop().unwrap()),
        )
    }

    /// Returns the current ledger for a peer.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bitswap_ledger("QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bitswap_ledger(&self, peer: &str) -> AsyncResponse<response::BitswapLedgerResponse> {
        self.request(&request::BitswapLedger { peer }, None)
    }

    /// Triggers a reprovide.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bitswap_reprovide();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bitswap_reprovide(&self) -> AsyncResponse<response::BitswapReprovideResponse> {
        self.request_empty(&request::BitswapReprovide, None)
    }

    /// Returns some stats about the bitswap agent.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bitswap_stat();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bitswap_stat(&self) -> AsyncResponse<response::BitswapStatResponse> {
        self.request(&request::BitswapStat, None)
    }

    /// Remove a given block from your wantlist.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bitswap_unwant("QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bitswap_unwant(&self, key: &str) -> AsyncResponse<response::BitswapUnwantResponse> {
        self.request_empty(&request::BitswapUnwant { key }, None)
    }

    /// Shows blocks on the wantlist for you or the specified peer.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bitswap_wantlist(Some("QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bitswap_wantlist(
        &self,
        peer: Option<&str>,
    ) -> AsyncResponse<response::BitswapWantlistResponse> {
        self.request(&request::BitswapWantlist { peer }, None)
    }

    /// Gets a raw IPFS block.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let hash = "QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA";
    /// let req = client.block_get(hash).concat2();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn block_get(&self, hash: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::BlockGet { hash }, None)
    }

    /// Store input as an IPFS block.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    /// use std::io::Cursor;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let data = Cursor::new("Hello World!");
    /// let req = client.block_put(data);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn block_put<R>(&self, data: R) -> AsyncResponse<response::BlockPutResponse>
    where
        R: 'static + Read + Send,
    {
        let mut form = multipart::Form::default();

        form.add_reader("data", data);

        self.request(&request::BlockPut, Some(form))
    }

    /// Removes an IPFS block.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.block_rm("QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn block_rm(&self, hash: &str) -> AsyncResponse<response::BlockRmResponse> {
        self.request(&request::BlockRm { hash }, None)
    }

    /// Prints information about a raw IPFS block.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.block_stat("QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn block_stat(&self, hash: &str) -> AsyncResponse<response::BlockStatResponse> {
        self.request(&request::BlockStat { hash }, None)
    }

    /// Add default peers to the bootstrap list.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bootstrap_add_default();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bootstrap_add_default(&self) -> AsyncResponse<response::BootstrapAddDefaultResponse> {
        self.request(&request::BootstrapAddDefault, None)
    }

    /// Lists peers in bootstrap list.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bootstrap_list();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bootstrap_list(&self) -> AsyncResponse<response::BootstrapListResponse> {
        self.request(&request::BootstrapList, None)
    }

    /// Removes all peers in bootstrap list.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.bootstrap_rm_all();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn bootstrap_rm_all(&self) -> AsyncResponse<response::BootstrapRmAllResponse> {
        self.request(&request::BootstrapRmAll, None)
    }

    /// Returns the contents of an Ipfs object.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let hash = "QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA";
    /// let req = client.cat(hash).concat2();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn cat(&self, path: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::Cat { path }, None)
    }

    /// List available commands that the server accepts.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.commands();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn commands(&self) -> AsyncResponse<response::CommandsResponse> {
        self.request(&request::Commands, None)
    }

    /// Opens the config file for editing (on the server).
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.config_edit();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn config_edit(&self) -> AsyncResponse<response::ConfigEditResponse> {
        self.request(&request::ConfigEdit, None)
    }

    /// Replace the config file.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    /// use std::io::Cursor;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let config = Cursor::new("{..json..}");
    /// let req = client.config_replace(config);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn config_replace<R>(&self, data: R) -> AsyncResponse<response::ConfigReplaceResponse>
    where
        R: 'static + Read + Send,
    {
        let mut form = multipart::Form::default();

        form.add_reader("file", data);

        self.request_empty(&request::ConfigReplace, Some(form))
    }

    /// Show the current config of the server.
    ///
    /// Returns an unparsed json string, due to an unclear spec.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.config_show();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn config_show(&self) -> AsyncResponse<response::ConfigShowResponse> {
        self.request_string(&request::ConfigShow, None)
    }

    /// Returns information about a dag node in Ipfs.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.dag_get("QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dag_get(&self, path: &str) -> AsyncResponse<response::DagGetResponse> {
        self.request(&request::DagGet { path }, None)
    }

    // TODO /dag routes are experimental, and there isn't a whole lot of
    // documentation available for how this route works.
    //
    // /// Add a DAG node to Ipfs.
    // ///
    // #[inline]
    // pub fn dag_put<R>(&self, data: R) -> AsyncResponse<response::DagPutResponse>
    // where
    //     R: 'static + Read + Send,
    // {
    //     let mut form = multipart::Form::default();
    //
    //     form.add_reader("arg", data);
    //
    //     self.request(&request::DagPut, Some(form))
    // }

    // TODO /dag/resolve

    /// Query the DHT for all of the multiaddresses associated with a Peer ID.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let peer = "QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM";
    /// let req = client.dht_findpeer(peer).collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_findpeer(&self, peer: &str) -> AsyncStreamResponse<response::DhtFindPeerResponse> {
        self.request_stream_json(&request::DhtFindPeer { peer }, None)
    }

    /// Find peers in the DHT that can provide a specific value given a key.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let key = "QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA";
    /// let req = client.dht_findprovs(key).collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_findprovs(&self, key: &str) -> AsyncStreamResponse<response::DhtFindProvsResponse> {
        self.request_stream_json(&request::DhtFindProvs { key }, None)
    }

    /// Query the DHT for a given key.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let key = "QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA";
    /// let req = client.dht_get(key).collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_get(&self, key: &str) -> AsyncStreamResponse<response::DhtGetResponse> {
        self.request_stream_json(&request::DhtGet { key }, None)
    }

    /// Announce to the network that you are providing a given value.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let key = "QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA";
    /// let req = client.dht_provide(key).collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_provide(&self, key: &str) -> AsyncStreamResponse<response::DhtProvideResponse> {
        self.request_stream_json(&request::DhtProvide { key }, None)
    }

    /// Write a key/value pair to the DHT.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.dht_put("test", "Hello World!").collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_put(&self, key: &str, value: &str) -> AsyncStreamResponse<response::DhtPutResponse> {
        self.request_stream_json(&request::DhtPut { key, value }, None)
    }

    /// Find the closest peer given the peer ID by querying the DHT.
    ///
    /// ```no_run
    /// # extern crate futures;
    /// # extern crate filesys_api;
    /// #
    /// use futures::Stream;
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let peer = "QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM";
    /// let req = client.dht_query(peer).collect();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dht_query(&self, peer: &str) -> AsyncStreamResponse<response::DhtQueryResponse> {
        self.request_stream_json(&request::DhtQuery { peer }, None)
    }

    /// Clear inactive requests from the log.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.diag_cmds_clear();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn diag_cmds_clear(&self) -> AsyncResponse<response::DiagCmdsClearResponse> {
        self.request_empty(&request::DiagCmdsClear, None)
    }

    /// Set how long to keep inactive requests in the log.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.diag_cmds_set_time("1m");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn diag_cmds_set_time(
        &self,
        time: &str,
    ) -> AsyncResponse<response::DiagCmdsSetTimeResponse> {
        self.request_empty(&request::DiagCmdsSetTime { time }, None)
    }

    /// Print system diagnostic information.
    ///
    /// Note: There isn't good documentation on what this call is supposed to return.
    /// It might be platform dependent, but if it isn't, this can be fixed to return
    /// an actual object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.diag_sys();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn diag_sys(&self) -> AsyncResponse<response::DiagSysResponse> {
        self.request_string(&request::DiagSys, None)
    }

    /// Resolve DNS link.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.dns("ipfs.io", true);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn dns(&self, link: &str, recursive: bool) -> AsyncResponse<response::DnsResponse> {
        self.request(&request::Dns { link, recursive }, None)
    }

    /// List directory for Unix filesystem objects.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.file_ls(handler);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn file_ls(&self, path: &str) -> AsyncResponse<response::FileLsResponse> {
        self.request(&request::FileLs { path }, None)
    }

    /// Copy files into MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_cp("/path/to/file", "/dest");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_cp(&self, path: &str, dest: &str) -> AsyncResponse<response::FilesCpResponse> {
        self.request_empty(&request::FilesCp { path, dest }, None)
    }

    /// Flush a path's data to disk.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_flush(None);
    /// let req = client.files_flush(Some("/tmp"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_flush(&self, path: Option<&str>) -> AsyncResponse<response::FilesFlushResponse> {
        self.request_empty(&request::FilesFlush { path }, None)
    }

    /// List directories in MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_ls(None);
    /// let req = client.files_ls(Some("/tmp"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_ls(&self, path: Option<&str>) -> AsyncResponse<response::FilesLsResponse> {
        self.request(&request::FilesLs { path }, None)
    }

    /// Make directories in MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_mkdir("/test", false);
    /// let req = client.files_mkdir("/test/nested/dir", true);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_mkdir(
        &self,
        path: &str,
        parents: bool,
    ) -> AsyncResponse<response::FilesMkdirResponse> {
        self.request_empty(&request::FilesMkdir { path, parents }, None)
    }

    /// Copy files into MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_mv("/test/tmp.json", "/test/file.json");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_mv(&self, path: &str, dest: &str) -> AsyncResponse<response::FilesMvResponse> {
        self.request_empty(&request::FilesMv { path, dest }, None)
    }

    /// Read a file in MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_read("/test/file.json");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_read(&self, path: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::FilesRead { path }, None)
    }

    /// Remove a file in MFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_rm("/test/dir", true);
    /// let req = client.files_rm("/test/file.json", false);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_rm(
        &self,
        path: &str,
        recursive: bool,
    ) -> AsyncResponse<response::FilesRmResponse> {
        self.request_empty(&request::FilesRm { path, recursive }, None)
    }

    /// Display a file's status in MDFS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.files_stat("/test/file.json");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_stat(&self, path: &str) -> AsyncResponse<response::FilesStatResponse> {
        self.request(&request::FilesStat { path }, None)
    }

    /// Write to a mutable file in the filesystem.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    /// use std::fs::File;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let file = File::open("test.json").unwrap();
    /// let req = client.files_write("/test/file.json", true, true, file);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn files_write<R>(
        &self,
        path: &str,
        create: bool,
        truncate: bool,
        data: R,
    ) -> AsyncResponse<response::FilesWriteResponse>
    where
        R: 'static + Read + Send,
    {
        let mut form = multipart::Form::default();

        form.add_reader("data", data);

        self.request_empty(
            &request::FilesWrite {
                path,
                create,
                truncate,
            },
            Some(form),
        )
    }

    /// List blocks that are both in the filestore and standard block storage.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.filestore_dups();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn filestore_dups(&self) -> AsyncStreamResponse<response::FilestoreDupsResponse> {
        self.request_stream_json(&request::FilestoreDups, None)
    }

    /// List objects in filestore.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.filestore_ls(Some("QmYPP3BovR2m8UqCZxFbdXSit6SKgExxDkFAPLqiGsap4X"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn filestore_ls(
        &self,
        cid: Option<&str>,
    ) -> AsyncStreamResponse<response::FilestoreLsResponse> {
        self.request_stream_json(&request::FilestoreLs { cid }, None)
    }

    /// Verify objects in filestore.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.filestore_verify(None);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn filestore_verify(
        &self,
        cid: Option<&str>,
    ) -> AsyncStreamResponse<response::FilestoreVerifyResponse> {
        self.request_stream_json(&request::FilestoreVerify { cid }, None)
    }

    /// Download Ipfs object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.get("/test/file.json");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn get(&self, path: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::Get { path }, None)
    }

    /// Returns information about a peer.
    ///
    /// If `peer` is `None`, returns information about you.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.id(None);
    /// let req = client.id(Some("QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn id(&self, peer: Option<&str>) -> AsyncResponse<response::IdResponse> {
        self.request(&request::Id { peer }, None)
    }

    /// Create a new keypair.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::{FileSysClient, KeyType};
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.key_gen("test", KeyType::Rsa, 64);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn key_gen(
        &self,
        name: &str,
        kind: request::KeyType,
        size: i32,
    ) -> AsyncResponse<response::KeyGenResponse> {
        self.request(&request::KeyGen { name, kind, size }, None)
    }

    /// List all local keypairs.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.key_list();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn key_list(&self) -> AsyncResponse<response::KeyListResponse> {
        self.request(&request::KeyList, None)
    }

    /// Rename a keypair.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.key_rename("key_0", "new_name", false);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn key_rename(
        &self,
        name: &str,
        new: &str,
        force: bool,
    ) -> AsyncResponse<response::KeyRenameResponse> {
        self.request(&request::KeyRename { name, new, force }, None)
    }

    /// Remove a keypair.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.key_rm("key_0");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn key_rm(&self, name: &str) -> AsyncResponse<response::KeyRmResponse> {
        self.request(&request::KeyRm { name }, None)
    }

    /// Change the logging level for a logger.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::{FileSysClient, Logger, LoggingLevel};
    /// use std::borrow::Cow;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.log_level(Logger::All, LoggingLevel::Debug);
    /// let req = client.log_level(
    ///     Logger::Specific(Cow::Borrowed("web")),
    ///     LoggingLevel::Warning);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn log_level(
        &self,
        logger: request::Logger,
        level: request::LoggingLevel,
    ) -> AsyncResponse<response::LogLevelResponse> {
        self.request(&request::LogLevel { logger, level }, None)
    }

    /// List all logging subsystems.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.log_ls();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn log_ls(&self) -> AsyncResponse<response::LogLsResponse> {
        self.request(&request::LogLs, None)
    }

    /// Read the event log.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.log_tail();
    /// # }
    /// ```
    ///
    pub fn log_tail(&self) -> AsyncStreamResponse<String> {
        #[cfg(feature = "hyper")]
        let res = self
            .build_base_request(&request::LogTail, None)
            .map(|req| self.client.request(req).from_err())
            .into_future()
            .flatten()
            .map(|res| FileSysClient::process_stream_response(res, LineDecoder))
            .flatten_stream();
        #[cfg(feature = "actix")]
        let res = self
            .build_base_request(&request::LogTail, None)
            .into_future()
            .and_then(|req| {
                req.send()
                    .timeout(std::time::Duration::from_secs(90))
                    .from_err()
            })
            .map(|res| FileSysClient::process_stream_response(res, LineDecoder))
            .flatten_stream();
        Box::new(res)
    }

    /// List the contents of an Ipfs multihash.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.ls(None);
    /// let req = client.ls(Some("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn ls(&self, path: Option<&str>) -> AsyncResponse<response::LsResponse> {
        self.request(&request::Ls { path }, None)
    }

    // TODO /mount

    /// Publish an IPFS path to IPNS.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.name_publish(
    ///     "/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY",
    ///     false,
    ///     Some("12h"),
    ///     None,
    ///     None);
    /// # }
    /// ```
    ///
    pub fn name_publish(
        &self,
        path: &str,
        resolve: bool,
        lifetime: Option<&str>,
        ttl: Option<&str>,
        key: Option<&str>,
    ) -> AsyncResponse<response::NamePublishResponse> {
        self.request(
            &request::NamePublish {
                path,
                resolve,
                lifetime,
                ttl,
                key,
            },
            None,
        )
    }

    /// Resolve an IPNS name.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.name_resolve(
    ///     Some(handler),
    ///     true,
    ///     false);
    /// # }
    /// ```
    ///
    pub fn name_resolve(
        &self,
        name: Option<&str>,
        recursive: bool,
        nocache: bool,
    ) -> AsyncResponse<response::NameResolveResponse> {
        self.request(
            &request::NameResolve {
                name,
                recursive,
                nocache,
            },
            None,
        )
    }

    /// Output the raw bytes of an Ipfs object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_data("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_data(&self, key: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::ObjectData { key }, None)
    }

    /// Returns the diff of two Ipfs objects.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_diff(
    ///     "/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY",
    ///     "/ipfs/QmXdNSQx7nbdRvkjGCEQgVjVtVwsHvV8NmV2a8xzQVwuFA");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_diff(
        &self,
        key0: &str,
        key1: &str,
    ) -> AsyncResponse<response::ObjectDiffResponse> {
        self.request(&request::ObjectDiff { key0, key1 }, None)
    }

    /// Returns the data in an object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_get("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_get(&self, key: &str) -> AsyncResponse<response::ObjectGetResponse> {
        self.request(&request::ObjectGet { key }, None)
    }

    /// Returns the links that an object points to.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_links("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_links(&self, key: &str) -> AsyncResponse<response::ObjectLinksResponse> {
        self.request(&request::ObjectLinks { key }, None)
    }

    /// Create a new object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::{FileSysClient, ObjectTemplate};
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_new(None);
    /// let req = client.object_new(Some(ObjectTemplate::UnixFsDir));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_new(
        &self,
        template: Option<request::ObjectTemplate>,
    ) -> AsyncResponse<response::ObjectNewResponse> {
        self.request(&request::ObjectNew { template }, None)
    }

    // TODO /object/patch/add-link

    // TODO /object/patch/append-data

    // TODO /object/patch/rm-link

    // TODO /object/patch/set-data

    // TODO /object/put

    /// Returns the stats for an object.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.object_stat("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn object_stat(&self, key: &str) -> AsyncResponse<response::ObjectStatResponse> {
        self.request(&request::ObjectStat { key }, None)
    }

    // TODO /p2p/listener/close

    // TODO /p2p/listener/ls

    // TODO /p2p/listener/open

    // TODO /p2p/stream/close

    // TODO /p2p/stream/dial

    // TODO /p2p/stream/ls

    /// Pins a new object.
    ///
    /// The "recursive" option tells the server whether to
    /// pin just the top-level object, or all sub-objects
    /// it depends on.  For most cases you want it to be `true`.
    ///
    /// Does not yet implement the "progress" agument because
    /// reading it is kinda squirrelly.
    ///
    /// # Examples
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pin_add("QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ", true);
    /// # }
    /// ```
    #[inline]
    pub fn pin_add(&self, key: &str, recursive: bool) -> AsyncResponse<response::PinAddResponse> {
        self.request(
            &request::PinAdd {
                key,
                recursive: Some(recursive),
                progress: false,
            },
            None,
        )
    }

    /// Returns a list of pinned objects in local storage.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pin_ls(None, None);
    /// let req = client.pin_ls(
    ///     Some("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY"),
    ///     None);
    /// let req = client.pin_ls(None, Some("direct"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pin_ls(
        &self,
        key: Option<&str>,
        typ: Option<&str>,
    ) -> AsyncResponse<response::PinLsResponse> {
        self.request(&request::PinLs { key, typ }, None)
    }

    /// Removes a pinned object from local storage.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pin_rm(
    ///     "/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY",
    ///     false);
    /// let req = client.pin_rm(
    ///     "/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY",
    ///     true);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pin_rm(&self, key: &str, recursive: bool) -> AsyncResponse<response::PinRmResponse> {
        self.request(&request::PinRm { key, recursive }, None)
    }

    // TODO /pin/update

    // TODO /pin/verify

    /// Pings a peer.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.ping("QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64", None);
    /// let req = client.ping("QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64", Some(15));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn ping(
        &self,
        peer: &str,
        count: Option<i32>,
    ) -> AsyncStreamResponse<response::PingResponse> {
        self.request_stream_json(&request::Ping { peer, count }, None)
    }

    /// List subscribed pubsub topics.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pubsub_ls();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pubsub_ls(&self) -> AsyncResponse<response::PubsubLsResponse> {
        self.request(&request::PubsubLs, None)
    }

    /// List peers that are being published to.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pubsub_peers(None);
    /// let req = client.pubsub_peers(Some("feed"));
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pubsub_peers(
        &self,
        topic: Option<&str>,
    ) -> AsyncResponse<response::PubsubPeersResponse> {
        self.request(&request::PubsubPeers { topic }, None)
    }

    /// Publish a message to a topic.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pubsub_pub("feed", "Hello World!");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pubsub_pub(
        &self,
        topic: &str,
        payload: &str,
    ) -> AsyncResponse<response::PubsubPubResponse> {
        self.request_empty(&request::PubsubPub { topic, payload }, None)
    }

    /// Subscribes to a pubsub topic.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.pubsub_sub("feed", false);
    /// let req = client.pubsub_sub("feed", true);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn pubsub_sub(
        &self,
        topic: &str,
        discover: bool,
    ) -> AsyncStreamResponse<response::PubsubSubResponse> {
        self.request_stream_json(&request::PubsubSub { topic, discover }, None)
    }

    /// Gets a list of local references.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.refs_local();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn refs_local(&self) -> AsyncStreamResponse<response::RefsLocalResponse> {
        self.request_stream_json(&request::RefsLocal, None)
    }

    // TODO /repo/fsck

    // TODO /repo/gc

    // TODO /repo/stat

    // TODO /repo/verify

    // TODO /repo/version

    // TODO /resolve

    /// Shutdown the Ipfs daemon.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.shutdown();
    /// # }
    /// ```
    ///
    pub fn shutdown(&self) -> AsyncResponse<response::ShutdownResponse> {
        self.request_empty(&request::Shutdown, None)
    }

    /// Returns bitswap stats.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.stats_bitswap();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn stats_bitswap(&self) -> AsyncResponse<response::StatsBitswapResponse> {
        self.request(&request::StatsBitswap, None)
    }

    /// Returns bandwidth stats.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.stats_bw();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn stats_bw(&self) -> AsyncResponse<response::StatsBwResponse> {
        self.request(&request::StatsBw, None)
    }

    /// Returns repo stats.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.stats_repo();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn stats_repo(&self) -> AsyncResponse<response::StatsRepoResponse> {
        self.request(&request::StatsRepo, None)
    }

    // TODO /swarm/addrs/listen

    /// Return a list of local addresses.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.swarm_addrs_local();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn swarm_addrs_local(&self) -> AsyncResponse<response::SwarmAddrsLocalResponse> {
        self.request(&request::SwarmAddrsLocal, None)
    }

    // TODO /swarm/connect

    // TODO /swarm/disconnect

    // TODO /swarm/filters/add

    // TODO /swarm/filters/rm

    /// Return a list of peers with open connections.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.swarm_peers();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn swarm_peers(&self) -> AsyncResponse<response::SwarmPeersResponse> {
        self.request(&request::SwarmPeers, None)
    }

    /// Add a tar file to Ipfs.
    ///
    /// Note: `data` should already be a tar file. If it isn't the Api will return
    /// an error.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    /// use std::fs::File;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let tar = File::open("/path/to/file.tar").unwrap();
    /// let req = client.tar_add(tar);
    /// # }
    /// ```
    ///
    #[inline]
    pub fn tar_add<R>(&self, data: R) -> AsyncResponse<response::TarAddResponse>
    where
        R: 'static + Read + Send,
    {
        let mut form = multipart::Form::default();

        form.add_reader("file", data);

        self.request(&request::TarAdd, Some(form))
    }

    /// Export a tar file from Ipfs.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.tar_cat("/ipfs/QmVrLsEDn27sScp3k23sgZNefVTjSAL3wpgW1iWPi4MgoY");
    /// # }
    /// ```
    ///
    #[inline]
    pub fn tar_cat(&self, path: &str) -> AsyncStreamResponse<Bytes> {
        self.request_stream_bytes(&request::TarCat { path }, None)
    }

    /// Returns information about the Ipfs server version.
    ///
    /// ```no_run
    /// # extern crate filesys_api;
    /// #
    /// use filesys_api::FileSysClient;
    ///
    /// # fn main() {
    /// let client = FileSysClient::default();
    /// let req = client.version();
    /// # }
    /// ```
    ///
    #[inline]
    pub fn version(&self) -> AsyncResponse<response::VersionResponse> {
        self.request(&request::Version, None)
    }
}

'''
'''--- filesys-api/src/header.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

pub use http::header::TRAILER;

pub const X_STREAM_ERROR: &str = "x-stream-error";

'''
'''--- filesys-api/src/lib.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#![recursion_limit = "128"]

//! Rust library for connecting to the IPFS HTTP API using tokio.
//!
//! ## Usage
//!
//! ```toml
//! [dependencies]
//! filesys-api = "0.5.1"
//! ```
//!
//! You can use `actix-web` as a backend instead of `hyper`.
//!
//! ```toml
//! [dependencies]
//! ipfs-api = { version = "0.5.1", features = ["actix"], default-features = false }
//! ```
//!
//! ## Examples
//!
//! ### Writing a file to IPFS
//!
//! #### With Hyper
//!
//! ```no_run
//! # extern crate hyper;
//! # extern crate filesys_api;
//! #
//! use hyper::rt::Future;
//! use filesys_api::FileSysClient;
//! use std::io::Cursor;
//!
//! # fn main() {
//! let client = FileSysClient::default();
//! let data = Cursor::new("Hello World!");
//!
//! let req = client
//!     .add(data)
//!     .map(|res| {
//!         println!("{}", res.hash);
//!     })
//!     .map_err(|e| eprintln!("{}", e));
//!
//! hyper::rt::run(req);
//! # }
//! ```
//!
//! #### With Actix
//!
//! ```no_run
//! # extern crate actix_web;
//! # extern crate futures;
//! # extern crate filesys_api;
//! #
//! use futures::future::Future;
//! use filesys_api::FileSysClient;
//! use std::io::Cursor;
//!
//! # fn main() {
//! let client = FileSysClient::default();
//! let data = Cursor::new("Hello World!");
//!
//! let req = client
//!     .add(data)
//!     .map(|res| {
//!         println!("{}", res.hash);
//!     })
//!     .map_err(|e| eprintln!("{}", e));
//!
//! actix_web::actix::run(|| {
//!     req.then(|_| {
//!         actix_web::actix::System::current().stop();
//!         Ok(())
//!     })
//! });
//! # }
//! ```
//!
//! ### Reading a file from IPFS
//!
//! #### With Hyper
//!
//! ```no_run
//! # extern crate futures;
//! # extern crate hyper;
//! # extern crate filesys_api;
//! #
//! use futures::{Future, Stream};
//! use filesys_api::FileSysClient;
//! use std::io::{self, Write};
//!
//! # fn main() {
//! let client = FileSysClient::default();
//!
//! let req = client
//!     .get("/test/file.json")
//!     .concat2()
//!     .map(|res| {
//!         let out = io::stdout();
//!         let mut out = out.lock();
//!
//!         out.write_all(&res).unwrap();
//!     })
//!     .map_err(|e| eprintln!("{}", e));
//!
//! hyper::rt::run(req);
//! # }
//! ```
//!
//! #### With Actix
//!
//! ```no_run
//! # extern crate futures;
//! # extern crate actix_web;
//! # extern crate filesys_api;
//! #
//! use futures::{Future, Stream};
//! use filesys_api::FileSysClient;
//! use std::io::{self, Write};
//!
//! # fn main() {
//! let client = FileSysClient::default();
//!
//! let req = client
//!     .get("/test/file.json")
//!     .concat2()
//!     .map(|res| {
//!         let out = io::stdout();
//!         let mut out = out.lock();
//!
//!         out.write_all(&res).unwrap();
//!     })
//!     .map_err(|e| eprintln!("{}", e));
//!
//! actix_web::actix::run(|| {
//!     req.then(|_| {
//!         actix_web::actix::System::current().stop();
//!         Ok(())
//!     })
//! });
//! # }
//! ```
//!
//! ### Additional Examples
//!
//! There are also a bunch of examples included in the project, which
//! I used for testing
//!
//! For a list of examples, run:
//!
//! ```sh
//! $ cargo run --example
//! ```
//!
//! You can run any of the examples with cargo:
//!
//! ```sh
//! $ cargo run -p ipfs-api --example add_file
//! ```
//!
//! To run an example with the `actix-web` backend, use:
//!
//! ```sh
//! $ cargo run -p ipfs-api --features actix --no-default-features --example add_file
//! ```
//!

#[cfg(feature = "actix")]
extern crate actix_multipart_rfc7578 as actix_multipart;
#[cfg(feature = "actix")]
extern crate actix_web;

#[cfg(feature = "hyper")]
extern crate hyper;
#[cfg(feature = "hyper")]
extern crate hyper_multipart_rfc7578 as hyper_multipart;
#[cfg(feature = "hyper")]
extern crate hyper_tls;

extern crate bytes;
#[macro_use]
extern crate failure;
extern crate futures;
extern crate http;
extern crate serde;
#[macro_use]
extern crate serde_derive;
extern crate dirs;
extern crate multiaddr;
extern crate serde_json;
extern crate serde_urlencoded;
extern crate tokio;
extern crate tokio_codec;
extern crate tokio_io;
extern crate walkdir;

pub use client::FileSysClient;
pub use request::{KeyType, Logger, LoggingLevel, ObjectTemplate};

mod client;
mod header;
mod read;
mod request;
pub mod response;

'''
'''--- filesys-api/src/read.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use bytes::{Bytes, BytesMut};
use futures::{Async, Stream};
use header::X_STREAM_ERROR;
use response::Error;
use serde::Deserialize;
use serde_json;
use std::{
    cmp,
    io::{self, Read},
    marker::PhantomData,
};
use tokio_codec::Decoder;
use tokio_io::AsyncRead;

/// A decoder for a response where each line is a full json object.
///
pub struct JsonLineDecoder<T> {
    /// Set to true if the stream can contain a X-Stream-Error header,
    /// which indicates an error while streaming.
    ///
    parse_stream_error: bool,

    ty: PhantomData<T>,
}

impl<T> JsonLineDecoder<T> {
    #[inline]
    pub fn new(parse_stream_error: bool) -> JsonLineDecoder<T> {
        JsonLineDecoder {
            parse_stream_error,
            ty: PhantomData,
        }
    }
}

impl<T> Decoder for JsonLineDecoder<T>
where
    for<'de> T: Deserialize<'de>,
{
    type Item = T;

    type Error = Error;

    /// Tries to find a new line character. If it does, it will split the buffer,
    /// and parse the first slice.
    ///
    fn decode(&mut self, src: &mut BytesMut) -> Result<Option<Self::Item>, Self::Error> {
        let nl_index = src.iter().position(|b| *b == b'\n');

        if let Some(pos) = nl_index {
            let slice = src.split_to(pos + 1);
            let slice = &slice[..slice.len() - 1];

            match serde_json::from_slice(slice) {
                Ok(json) => Ok(json),
                // If a JSON object couldn't be parsed from the response, it is possible
                // that a stream error trailing header was returned. If the JSON decoder
                // was configured to parse these kinds of error, it should try. If a header
                // couldn't be parsed, it will return the original error.
                //
                Err(e) => {
                    if self.parse_stream_error {
                        match slice.iter().position(|&x| x == b':') {
                            Some(colon) if &slice[..colon] == X_STREAM_ERROR.as_bytes() => {
                                let e = Error::StreamError(
                                    String::from_utf8_lossy(&slice[colon + 2..]).into(),
                                );

                                Err(e)
                            }
                            _ => Err(e.into()),
                        }
                    } else {
                        Err(e.into())
                    }
                }
            }
        } else {
            Ok(None)
        }
    }
}

/// A decoder that reads a line at a time.
///
pub struct LineDecoder;

impl Decoder for LineDecoder {
    type Item = String;

    type Error = Error;

    /// Attempts to find a new line character, and returns the entire line if
    /// it finds one.
    ///
    fn decode(&mut self, src: &mut BytesMut) -> Result<Option<Self::Item>, Self::Error> {
        let nl_index = src.iter().position(|b| *b == b'\n');

        if let Some(pos) = nl_index {
            let slice = src.split_to(pos + 1);

            Ok(Some(
                String::from_utf8_lossy(&slice[..slice.len() - 1]).into_owned(),
            ))
        } else {
            Ok(None)
        }
    }
}

/// The state of a stream returning Chunks.
///
enum ReadState {
    /// A chunk is ready to be read from.
    ///
    Ready(Bytes, usize),

    /// The next chunk isn't ready yet.
    ///
    NotReady,
}

/// Reads from a stream of chunks asynchronously.
///
pub struct StreamReader<S> {
    stream: S,
    state: ReadState,
}

impl<S> StreamReader<S>
where
    S: Stream<Item = Bytes, Error = Error>,
{
    #[inline]
    pub fn new(stream: S) -> StreamReader<S> {
        StreamReader {
            stream,
            state: ReadState::NotReady,
        }
    }
}

impl<S> Read for StreamReader<S>
where
    S: Stream<Item = Bytes, Error = Error>,
{
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        loop {
            let ret;

            match self.state {
                // Stream yielded a Chunk to read.
                //
                ReadState::Ready(ref mut chunk, ref mut pos) => {
                    let chunk_start = *pos;
                    let len = cmp::min(buf.len(), chunk.len() - chunk_start);
                    let chunk_end = chunk_start + len;

                    buf[..len].copy_from_slice(&chunk[chunk_start..chunk_end]);
                    *pos += len;

                    if *pos == chunk.len() {
                        ret = len;
                    } else {
                        return Ok(len);
                    }
                }
                // Stream is not ready, and a Chunk needs to be read.
                //
                ReadState::NotReady => {
                    match self.stream.poll() {
                        // Polling stream yielded a Chunk that can be read from.
                        //
                        Ok(Async::Ready(Some(chunk))) => {
                            self.state = ReadState::Ready(chunk, 0);

                            continue;
                        }
                        // Polling stream yielded EOF.
                        //
                        Ok(Async::Ready(None)) => return Ok(0),
                        // Stream could not be read from.
                        //
                        Ok(Async::NotReady) => return Err(io::ErrorKind::WouldBlock.into()),
                        Err(e) => return Err(io::Error::new(io::ErrorKind::Other, e.to_string())),
                    }
                }
            }

            self.state = ReadState::NotReady;

            return Ok(ret);
        }
    }
}

impl<S> AsyncRead for StreamReader<S> where S: Stream<Item = Bytes, Error = Error> {}

'''
'''--- filesys-api/src/request/add.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

pub struct Add;

impl_skip_serialize!(Add);

impl ApiRequest for Add {
    const PATH: &'static str = "/add";

    const METHOD: &'static Method = &Method::POST;
}

'''
'''--- filesys-api/src/request/bitswap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct BitswapLedger<'a> {
    #[serde(rename = "arg")]
    pub peer: &'a str,
}

impl<'a> ApiRequest for BitswapLedger<'a> {
    const PATH: &'static str = "/bitswap/ledger";
}

pub struct BitswapReprovide;

impl_skip_serialize!(BitswapReprovide);

impl ApiRequest for BitswapReprovide {
    const PATH: &'static str = "/bitswap/reprovide";
}

pub struct BitswapStat;

impl_skip_serialize!(BitswapStat);

impl ApiRequest for BitswapStat {
    const PATH: &'static str = "/bitswap/stat";
}

#[derive(Serialize)]
pub struct BitswapUnwant<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for BitswapUnwant<'a> {
    const PATH: &'static str = "/bitswap/stat";
}

#[derive(Serialize)]
pub struct BitswapWantlist<'a> {
    pub peer: Option<&'a str>,
}

impl<'a> ApiRequest for BitswapWantlist<'a> {
    const PATH: &'static str = "/bitswap/wantlist";
}

'''
'''--- filesys-api/src/request/block.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

#[derive(Serialize)]
pub struct BlockGet<'a> {
    #[serde(rename = "arg")]
    pub hash: &'a str,
}

impl<'a> ApiRequest for BlockGet<'a> {
    const PATH: &'static str = "/block/get";
}

pub struct BlockPut;

impl_skip_serialize!(BlockPut);

impl ApiRequest for BlockPut {
    const PATH: &'static str = "/block/put";

    const METHOD: &'static Method = &Method::POST;
}

#[derive(Serialize)]
pub struct BlockRm<'a> {
    #[serde(rename = "arg")]
    pub hash: &'a str,
}

impl<'a> ApiRequest for BlockRm<'a> {
    const PATH: &'static str = "/block/rm";
}

#[derive(Serialize)]
pub struct BlockStat<'a> {
    #[serde(rename = "arg")]
    pub hash: &'a str,
}

impl<'a> ApiRequest for BlockStat<'a> {
    const PATH: &'static str = "/block/stat";
}

'''
'''--- filesys-api/src/request/bootstrap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct BootstrapAddDefault;

impl_skip_serialize!(BootstrapAddDefault);

impl ApiRequest for BootstrapAddDefault {
    const PATH: &'static str = "/bootstrap/add/default";
}

pub struct BootstrapList;

impl_skip_serialize!(BootstrapList);

impl ApiRequest for BootstrapList {
    const PATH: &'static str = "/bootstrap/list";
}

pub struct BootstrapRmAll;

impl_skip_serialize!(BootstrapRmAll);

impl ApiRequest for BootstrapRmAll {
    const PATH: &'static str = "/bootstrap/rm/all";
}

'''
'''--- filesys-api/src/request/cat.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Cat<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for Cat<'a> {
    const PATH: &'static str = "/cat";
}

'''
'''--- filesys-api/src/request/commands.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct Commands;

impl_skip_serialize!(Commands);

impl ApiRequest for Commands {
    const PATH: &'static str = "/commands";
}

'''
'''--- filesys-api/src/request/config.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

pub struct ConfigEdit;

impl_skip_serialize!(ConfigEdit);

impl ApiRequest for ConfigEdit {
    const PATH: &'static str = "/config/edit";
}

pub struct ConfigReplace;

impl_skip_serialize!(ConfigReplace);

impl ApiRequest for ConfigReplace {
    const PATH: &'static str = "/config/replace";

    const METHOD: &'static Method = &Method::POST;
}

pub struct ConfigShow;

impl_skip_serialize!(ConfigShow);

impl ApiRequest for ConfigShow {
    const PATH: &'static str = "/config/show";
}

'''
'''--- filesys-api/src/request/dag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

#[derive(Serialize)]
pub struct DagGet<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for DagGet<'a> {
    const PATH: &'static str = "/dag/get";
}

pub struct DagPut;

impl_skip_serialize!(DagPut);

impl ApiRequest for DagPut {
    const PATH: &'static str = "/dag/put";

    const METHOD: &'static Method = &Method::POST;
}

'''
'''--- filesys-api/src/request/dht.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct DhtFindPeer<'a> {
    #[serde(rename = "arg")]
    pub peer: &'a str,
}

impl<'a> ApiRequest for DhtFindPeer<'a> {
    const PATH: &'static str = "/dht/findpeer";
}

#[derive(Serialize)]
pub struct DhtFindProvs<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for DhtFindProvs<'a> {
    const PATH: &'static str = "/dht/findprovs";
}

#[derive(Serialize)]
pub struct DhtGet<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for DhtGet<'a> {
    const PATH: &'static str = "/dht/get";
}

#[derive(Serialize)]
pub struct DhtProvide<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for DhtProvide<'a> {
    const PATH: &'static str = "/dht/provide";
}

#[derive(Serialize)]
pub struct DhtPut<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,

    #[serde(rename = "arg")]
    pub value: &'a str,
}

impl<'a> ApiRequest for DhtPut<'a> {
    const PATH: &'static str = "/dht/put";
}

#[derive(Serialize)]
pub struct DhtQuery<'a> {
    #[serde(rename = "arg")]
    pub peer: &'a str,
}

impl<'a> ApiRequest for DhtQuery<'a> {
    const PATH: &'static str = "/dht/query";
}

'''
'''--- filesys-api/src/request/diag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct DiagCmdsClear;

impl_skip_serialize!(DiagCmdsClear);

impl ApiRequest for DiagCmdsClear {
    const PATH: &'static str = "/diag/cmds/clear";
}

#[derive(Serialize)]
pub struct DiagCmdsSetTime<'a> {
    #[serde(rename = "arg")]
    pub time: &'a str,
}

impl<'a> ApiRequest for DiagCmdsSetTime<'a> {
    const PATH: &'static str = "/diag/cmds/set-time";
}

pub struct DiagSys;

impl_skip_serialize!(DiagSys);

impl ApiRequest for DiagSys {
    const PATH: &'static str = "/diag/sys";
}

'''
'''--- filesys-api/src/request/dns.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Dns<'a> {
    #[serde(rename = "arg")]
    pub link: &'a str,

    pub recursive: bool,
}

impl<'a> ApiRequest for Dns<'a> {
    const PATH: &'static str = "/dns";
}

'''
'''--- filesys-api/src/request/file.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct FileLs<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for FileLs<'a> {
    const PATH: &'static str = "/file/ls";
}

'''
'''--- filesys-api/src/request/files.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

#[derive(Serialize)]
pub struct FilesCp<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    #[serde(rename = "arg")]
    pub dest: &'a str,
}

impl<'a> ApiRequest for FilesCp<'a> {
    const PATH: &'static str = "/files/cp";
}

#[derive(Serialize)]
pub struct FilesFlush<'a> {
    #[serde(rename = "arg")]
    pub path: Option<&'a str>,
}

impl<'a> ApiRequest for FilesFlush<'a> {
    const PATH: &'static str = "/files/flush";
}

#[derive(Serialize)]
pub struct FilesLs<'a> {
    #[serde(rename = "arg")]
    pub path: Option<&'a str>,
}

impl<'a> ApiRequest for FilesLs<'a> {
    const PATH: &'static str = "/files/ls";
}

#[derive(Serialize)]
pub struct FilesMkdir<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    pub parents: bool,
}

impl<'a> ApiRequest for FilesMkdir<'a> {
    const PATH: &'static str = "/files/mkdir";
}

#[derive(Serialize)]
pub struct FilesMv<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    #[serde(rename = "arg")]
    pub dest: &'a str,
}

impl<'a> ApiRequest for FilesMv<'a> {
    const PATH: &'static str = "/files/mv";
}

#[derive(Serialize)]
pub struct FilesRead<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for FilesRead<'a> {
    const PATH: &'static str = "/files/read";
}

#[derive(Serialize)]
pub struct FilesRm<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    pub recursive: bool,
}

impl<'a> ApiRequest for FilesRm<'a> {
    const PATH: &'static str = "/files/rm";
}

#[derive(Serialize)]
pub struct FilesStat<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for FilesStat<'a> {
    const PATH: &'static str = "/files/stat";
}

#[derive(Serialize)]
pub struct FilesWrite<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    pub create: bool,

    pub truncate: bool,
}

impl<'a> ApiRequest for FilesWrite<'a> {
    const PATH: &'static str = "/files/write";

    const METHOD: &'static Method = &Method::POST;
}

'''
'''--- filesys-api/src/request/filestore.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct FilestoreDups;

impl_skip_serialize!(FilestoreDups);

impl ApiRequest for FilestoreDups {
    const PATH: &'static str = "/filestore/dups";
}

#[derive(Serialize)]
pub struct FilestoreLs<'a> {
    #[serde(rename = "arg")]
    pub cid: Option<&'a str>,
}

impl<'a> ApiRequest for FilestoreLs<'a> {
    const PATH: &'static str = "/filestore/ls";
}

#[derive(Serialize)]
pub struct FilestoreVerify<'a> {
    #[serde(rename = "arg")]
    pub cid: Option<&'a str>,
}

impl<'a> ApiRequest for FilestoreVerify<'a> {
    const PATH: &'static str = "/filestore/verify";
}

'''
'''--- filesys-api/src/request/get.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Get<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for Get<'a> {
    const PATH: &'static str = "/get";
}

'''
'''--- filesys-api/src/request/id.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Id<'a> {
    #[serde(rename = "arg")]
    pub peer: Option<&'a str>,
}

impl<'a> ApiRequest for Id<'a> {
    const PATH: &'static str = "/id";
}

'''
'''--- filesys-api/src/request/key.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;
use serde::ser::{Serialize, Serializer};

#[derive(Copy, Clone)]
pub enum KeyType {
    Rsa,
    Ed25519,
}

impl Serialize for KeyType {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let s = match self {
            KeyType::Rsa => "rsa",
            KeyType::Ed25519 => "ed25519",
        };

        serializer.serialize_str(s)
    }
}

#[derive(Serialize)]
pub struct KeyGen<'a> {
    #[serde(rename = "arg")]
    pub name: &'a str,

    #[serde(rename = "type")]
    pub kind: KeyType,

    pub size: i32,
}

impl<'a> ApiRequest for KeyGen<'a> {
    const PATH: &'static str = "/key/gen";
}

pub struct KeyList;

impl_skip_serialize!(KeyList);

impl ApiRequest for KeyList {
    const PATH: &'static str = "/key/list";
}

#[derive(Serialize)]
pub struct KeyRename<'a, 'b> {
    #[serde(rename = "arg")]
    pub name: &'a str,

    #[serde(rename = "arg")]
    pub new: &'b str,

    pub force: bool,
}

impl<'a, 'b> ApiRequest for KeyRename<'a, 'b> {
    const PATH: &'static str = "/key/rename";
}

#[derive(Serialize)]
pub struct KeyRm<'a> {
    #[serde(rename = "arg")]
    pub name: &'a str,
}

impl<'a> ApiRequest for KeyRm<'a> {
    const PATH: &'static str = "/key/rm";
}

'''
'''--- filesys-api/src/request/log.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;
use serde::ser::{Serialize, Serializer};
use std::borrow::Cow;

#[derive(Copy, Clone)]
pub enum LoggingLevel {
    Debug,
    Info,
    Warning,
    Error,
    Critical,
}

impl Serialize for LoggingLevel {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let s = match self {
            LoggingLevel::Debug => "debug",
            LoggingLevel::Info => "info",
            LoggingLevel::Warning => "warning",
            LoggingLevel::Error => "error",
            LoggingLevel::Critical => "critical",
        };

        serializer.serialize_str(s)
    }
}

pub enum Logger<'a> {
    All,
    Specific(Cow<'a, str>),
}

impl<'a> Serialize for Logger<'a> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let s = match self {
            Logger::All => "*",
            Logger::Specific(ref logger) => logger.as_ref(),
        };

        serializer.serialize_str(s)
    }
}

#[derive(Serialize)]
pub struct LogLevel<'a> {
    #[serde(rename = "arg")]
    pub logger: Logger<'a>,

    #[serde(rename = "arg")]
    pub level: LoggingLevel,
}

impl<'a> ApiRequest for LogLevel<'a> {
    const PATH: &'static str = "/log/level";
}

pub struct LogLs;

impl_skip_serialize!(LogLs);

impl ApiRequest for LogLs {
    const PATH: &'static str = "/log/ls";
}

pub struct LogTail;

impl_skip_serialize!(LogTail);

impl ApiRequest for LogTail {
    const PATH: &'static str = "/log/tail";
}

'''
'''--- filesys-api/src/request/ls.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Ls<'a> {
    #[serde(rename = "arg")]
    pub path: Option<&'a str>,
}

impl<'a> ApiRequest for Ls<'a> {
    const PATH: &'static str = "/ls";
}

#[cfg(test)]
mod tests {
    use super::Ls;

    serialize_url_test!(test_serializes_0, Ls { path: Some("test") }, "arg=test");
    serialize_url_test!(test_serializes_1, Ls { path: None }, "");
}

'''
'''--- filesys-api/src/request/mod.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

pub use self::add::*;
pub use self::bitswap::*;
pub use self::block::*;
pub use self::bootstrap::*;
pub use self::cat::*;
pub use self::commands::*;
pub use self::config::*;
pub use self::dag::*;
pub use self::dht::*;
pub use self::diag::*;
pub use self::dns::*;
pub use self::file::*;
pub use self::files::*;
pub use self::filestore::*;
pub use self::get::*;
pub use self::id::*;
pub use self::key::*;
pub use self::log::*;
pub use self::ls::*;
pub use self::name::*;
pub use self::object::*;
pub use self::pin::*;
pub use self::ping::*;
pub use self::pubsub::*;
pub use self::refs::*;
pub use self::shutdown::*;
pub use self::stats::*;
pub use self::swarm::*;
pub use self::tar::*;
pub use self::version::*;

/// Create a test to verify that serializing a `ApiRequest` returns the expected
/// url encoded string.
///
#[cfg(test)]
macro_rules! serialize_url_test {
    ($f: ident, $obj: expr, $exp: expr) => {
        #[test]
        fn $f() {
            assert_eq!(::serde_urlencoded::to_string($obj), Ok($exp.to_string()))
        }
    };
}

/// Implements the `Serialize` trait for types that do not require
/// serialization. This provides a workaround for a limitation in
/// `serde_urlencoded`, that prevents unit structs from being serialized.
///
macro_rules! impl_skip_serialize {
    ($ty: ty) => {
        impl ::serde::Serialize for $ty {
            fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
            where
                S: ::serde::Serializer,
            {
                serializer.serialize_none()
            }
        }
    };
}

mod add;
mod bitswap;
mod block;
mod bootstrap;
mod cat;
mod commands;
mod config;
mod dag;
mod dht;
mod diag;
mod dns;
mod file;
mod files;
mod filestore;
mod get;
mod id;
mod key;
mod log;
mod ls;
mod name;
mod object;
mod pin;
mod ping;
mod pubsub;
mod refs;
mod shutdown;
mod stats;
mod swarm;
mod tar;
mod version;

/// A request that can be made against the Ipfs API.
///
pub trait ApiRequest {
    /// Returns the API path that this request can be called on.
    ///
    /// All paths should begin with '/'.
    ///
    const PATH: &'static str;

    /// Method used to make the request.
    ///
    const METHOD: &'static ::http::Method = &::http::Method::GET;
}

'''
'''--- filesys-api/src/request/name.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct NamePublish<'a, 'b, 'c, 'd> {
    #[serde(rename = "arg")]
    pub path: &'a str,

    pub resolve: bool,

    pub lifetime: Option<&'b str>,

    pub ttl: Option<&'c str>,

    pub key: Option<&'d str>,
}

impl<'a, 'b, 'c, 'd> ApiRequest for NamePublish<'a, 'b, 'c, 'd> {
    const PATH: &'static str = "/name/publish";
}

#[derive(Serialize)]
pub struct NameResolve<'a> {
    #[serde(rename = "arg")]
    pub name: Option<&'a str>,

    pub recursive: bool,

    pub nocache: bool,
}

impl<'a> ApiRequest for NameResolve<'a> {
    const PATH: &'static str = "/name/resolve";
}

'''
'''--- filesys-api/src/request/object.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;
use serde::ser::{Serialize, Serializer};

#[derive(Serialize)]
pub struct ObjectData<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for ObjectData<'a> {
    const PATH: &'static str = "/object/data";
}

#[derive(Serialize)]
pub struct ObjectDiff<'a> {
    #[serde(rename = "arg")]
    pub key0: &'a str,

    #[serde(rename = "arg")]
    pub key1: &'a str,
}

impl<'a> ApiRequest for ObjectDiff<'a> {
    const PATH: &'static str = "/object/diff";
}

#[derive(Serialize)]
pub struct ObjectGet<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for ObjectGet<'a> {
    const PATH: &'static str = "/object/get";
}

#[derive(Serialize)]
pub struct ObjectLinks<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for ObjectLinks<'a> {
    const PATH: &'static str = "/object/links";
}

#[derive(Copy, Clone)]
pub enum ObjectTemplate {
    UnixFsDir,
}

impl Serialize for ObjectTemplate {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let s = match self {
            ObjectTemplate::UnixFsDir => "unixfs-dir",
        };

        serializer.serialize_str(s)
    }
}

#[derive(Serialize)]
pub struct ObjectNew {
    #[serde(rename = "arg")]
    pub template: Option<ObjectTemplate>,
}

impl ApiRequest for ObjectNew {
    const PATH: &'static str = "/object/new";
}

#[derive(Serialize)]
pub struct ObjectStat<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,
}

impl<'a> ApiRequest for ObjectStat<'a> {
    const PATH: &'static str = "/object/stat";
}

#[cfg(test)]
mod tests {
    use super::ObjectDiff;

    serialize_url_test!(
        test_serializes_0,
        ObjectDiff {
            key0: "test",
            key1: "test2",
        },
        "arg=test&arg=test2"
    );
}

'''
'''--- filesys-api/src/request/pin.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct PinAdd<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,

    pub recursive: Option<bool>,
    pub progress: bool,
}

impl<'a> ApiRequest for PinAdd<'a> {
    const PATH: &'static str = "/pin/add";
}

#[derive(Serialize)]
pub struct PinLs<'a> {
    #[serde(rename = "arg")]
    pub key: Option<&'a str>,

    #[serde(rename = "type")]
    pub typ: Option<&'a str>,
}

impl<'a> ApiRequest for PinLs<'a> {
    const PATH: &'static str = "/pin/ls";
}

#[derive(Serialize)]
pub struct PinRm<'a> {
    #[serde(rename = "arg")]
    pub key: &'a str,

    pub recursive: bool,
}

impl<'a> ApiRequest for PinRm<'a> {
    const PATH: &'static str = "/pin/rm";
}

'''
'''--- filesys-api/src/request/ping.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

#[derive(Serialize)]
pub struct Ping<'a> {
    #[serde(rename = "arg")]
    pub peer: &'a str,

    pub count: Option<i32>,
}

impl<'a> ApiRequest for Ping<'a> {
    const PATH: &'static str = "/ping";
}

'''
'''--- filesys-api/src/request/pubsub.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct PubsubLs;

impl_skip_serialize!(PubsubLs);

impl ApiRequest for PubsubLs {
    const PATH: &'static str = "/pubsub/ls";
}

#[derive(Serialize)]
pub struct PubsubPeers<'a> {
    #[serde(rename = "arg")]
    pub topic: Option<&'a str>,
}

impl<'a> ApiRequest for PubsubPeers<'a> {
    const PATH: &'static str = "/pubsub/peers";
}

#[derive(Serialize)]
pub struct PubsubPub<'a> {
    #[serde(rename = "arg")]
    pub topic: &'a str,

    #[serde(rename = "arg")]
    pub payload: &'a str,
}

impl<'a> ApiRequest for PubsubPub<'a> {
    const PATH: &'static str = "/pubsub/pub";
}

#[derive(Serialize)]
pub struct PubsubSub<'a> {
    #[serde(rename = "arg")]
    pub topic: &'a str,

    pub discover: bool,
}

impl<'a> ApiRequest for PubsubSub<'a> {
    const PATH: &'static str = "/pubsub/sub";
}

'''
'''--- filesys-api/src/request/refs.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct RefsLocal;

impl_skip_serialize!(RefsLocal);

impl ApiRequest for RefsLocal {
    const PATH: &'static str = "/refs/local";
}

'''
'''--- filesys-api/src/request/shutdown.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct Shutdown;

impl_skip_serialize!(Shutdown);

impl ApiRequest for Shutdown {
    const PATH: &'static str = "/shutdown";
}

'''
'''--- filesys-api/src/request/stats.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct StatsBitswap;

impl_skip_serialize!(StatsBitswap);

impl ApiRequest for StatsBitswap {
    const PATH: &'static str = "/stats/bitswap";
}

pub struct StatsBw;

impl_skip_serialize!(StatsBw);

impl ApiRequest for StatsBw {
    const PATH: &'static str = "/stats/bw";
}

pub struct StatsRepo;

impl_skip_serialize!(StatsRepo);

impl ApiRequest for StatsRepo {
    const PATH: &'static str = "/stats/repo";
}

'''
'''--- filesys-api/src/request/swarm.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct SwarmAddrsLocal;

impl_skip_serialize!(SwarmAddrsLocal);

impl ApiRequest for SwarmAddrsLocal {
    const PATH: &'static str = "/swarm/addrs/local";
}

pub struct SwarmPeers;

impl_skip_serialize!(SwarmPeers);

impl ApiRequest for SwarmPeers {
    const PATH: &'static str = "/swarm/peers";
}

'''
'''--- filesys-api/src/request/tar.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use http::Method;
use request::ApiRequest;

pub struct TarAdd;

impl_skip_serialize!(TarAdd);

impl ApiRequest for TarAdd {
    const PATH: &'static str = "/tar/add";

    const METHOD: &'static Method = &Method::POST;
}

#[derive(Serialize)]
pub struct TarCat<'a> {
    #[serde(rename = "arg")]
    pub path: &'a str,
}

impl<'a> ApiRequest for TarCat<'a> {
    const PATH: &'static str = "/tar/cat";
}

'''
'''--- filesys-api/src/request/version.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use request::ApiRequest;

pub struct Version;

impl_skip_serialize!(Version);

impl ApiRequest for Version {
    const PATH: &'static str = "/version";
}

'''
'''--- filesys-api/src/response/add.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct AddResponse {
    pub name: String,
    pub hash: String,
    pub size: String,
}

'''
'''--- filesys-api/src/response/bitswap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BitswapLedgerResponse {
    pub peer: String,
    pub value: f64,
    pub sent: u64,
    pub recv: u64,
    pub exchanged: u64,
}

pub type BitswapReprovideResponse = ();

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BitswapStatResponse {
    pub provide_buf_len: i32,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub wantlist: Vec<String>,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub peers: Vec<String>,

    pub blocks_received: u64,
    pub data_received: u64,
    pub blocks_sent: u64,
    pub data_sent: u64,
    pub dup_blks_received: u64,
    pub dup_data_received: u64,
}

pub type BitswapUnwantResponse = ();

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BitswapWantlistResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub keys: Vec<String>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_bitswap_stat_0, BitswapStatResponse);
}

'''
'''--- filesys-api/src/response/block.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BlockPutResponse {
    pub key: String,
    pub size: u64,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BlockRmResponse {
    pub hash: String,
    pub error: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BlockStatResponse {
    pub key: String,
    pub size: u64,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_block_stat_0, BlockStatResponse);
}

'''
'''--- filesys-api/src/response/bootstrap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BootstrapAddDefaultResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub peers: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BootstrapListResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub peers: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct BootstrapRmAllResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub peers: Vec<String>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_bootstrap_list_0, BootstrapListResponse);
}

'''
'''--- filesys-api/src/response/commands.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct CommandsResponseOptions {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub names: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct CommandsResponse {
    pub name: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub subcommands: Vec<CommandsResponse>,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub options: Vec<CommandsResponseOptions>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_commands_0, CommandsResponse);
}

'''
'''--- filesys-api/src/response/config.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

pub type ConfigEditResponse = ();

pub type ConfigReplaceResponse = ();

pub type ConfigShowResponse = String;

'''
'''--- filesys-api/src/response/dag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;
use std::collections::HashMap;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct DagIpfsHeader {
    pub name: String,
    pub size: u64,

    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub cid: HashMap<String, String>,
}

#[derive(Debug, Deserialize)]
pub struct DagGetResponse {
    pub data: Option<String>,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<DagIpfsHeader>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct DagPutResponse {
    pub cid: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_dag_get_0, DagGetResponse);
}

'''
'''--- filesys-api/src/response/dht.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;
use serde::de::{Deserialize, Deserializer, Error};

/// See
/// [libp2p](https://github.com/libp2p/go-libp2p-routing/blob/master/notifications/query.go#L16).
///
#[derive(Debug)]
pub enum DhtType {
    SendingQuery,
    PeerResponse,
    FinalPeer,
    QueryError,
    Provider,
    Value,
    AddingPeer,
    DialingPeer,
}

impl<'de> Deserialize<'de> for DhtType {
    #[inline]
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        match deserializer.deserialize_i64(serde::IntegerVisitor)? {
            0 => Ok(DhtType::SendingQuery),
            1 => Ok(DhtType::PeerResponse),
            2 => Ok(DhtType::FinalPeer),
            3 => Ok(DhtType::QueryError),
            4 => Ok(DhtType::Provider),
            5 => Ok(DhtType::Value),
            6 => Ok(DhtType::AddingPeer),
            7 => Ok(DhtType::DialingPeer),
            i => Err(D::Error::custom(format!("unknown dht type '{}'", i))),
        }
    }
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct DhtPeerResponse {
    #[serde(rename = "ID")]
    pub id: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub addrs: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct DhtMessage {
    #[serde(rename = "ID")]
    pub id: String,

    #[serde(rename = "Type")]
    pub typ: DhtType,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub responses: Vec<DhtPeerResponse>,

    pub extra: String,
}

pub type DhtFindPeerResponse = DhtMessage;

pub type DhtFindProvsResponse = DhtMessage;

pub type DhtGetResponse = DhtMessage;

pub type DhtProvideResponse = DhtMessage;

pub type DhtPutResponse = DhtMessage;

pub type DhtQueryResponse = DhtMessage;

'''
'''--- filesys-api/src/response/diag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

pub type DiagCmdsClearResponse = ();

pub type DiagCmdsSetTimeResponse = ();

pub type DiagSysResponse = String;

'''
'''--- filesys-api/src/response/dns.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct DnsResponse {
    pub path: String,
}

'''
'''--- filesys-api/src/response/error.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//
#[cfg(feature = "actix")]
use actix_web;
use http;
#[cfg(feature = "hyper")]
use hyper;
use serde_json;
use serde_urlencoded;
use std;
use std::string::FromUtf8Error;

#[derive(Fail, Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
#[fail(display = "{}", message)]
pub struct ApiError {
    pub message: String,
    pub code: u8,
}

#[derive(Fail, Debug)]
pub enum Error {
    /// Foreign errors.
    #[cfg(feature = "hyper")]
    #[fail(display = "hyper client error '{}'", _0)]
    Client(hyper::Error),

    #[cfg(feature = "actix")]
    #[fail(display = "actix client error '{}'", _0)]
    Client(actix_web::error::Error),

    #[cfg(feature = "actix")]
    #[fail(display = "actix client payload error '{}'", _0)]
    ClientPayload(actix_web::error::PayloadError),

    #[cfg(feature = "actix")]
    #[fail(display = "actix client send request error '{}'", _0)]
    ClientSend(actix_web::client::SendRequestError),

    #[fail(display = "http error '{}'", _0)]
    Http(http::Error),

    #[fail(display = "json parse error '{}'", _0)]
    Parse(serde_json::Error),

    #[fail(display = "utf8 decoding error '{}'", _0)]
    ParseUtf8(FromUtf8Error),

    #[fail(display = "uri error '{}'", _0)]
    Url(http::uri::InvalidUri),

    #[fail(display = "io error '{}'", _0)]
    Io(std::io::Error),

    #[fail(display = "url encoding error '{}'", _0)]
    EncodeUrl(serde_urlencoded::ser::Error),

    /// An error returned by the Ipfs api.
    #[fail(display = "api returned error '{}'", _0)]
    Api(ApiError),

    /// A stream error indicated in the Trailer header.
    #[fail(display = "api returned an error while streaming: '{}'", _0)]
    StreamError(String),

    /// API returned a trailer header with unrecognized value.
    #[fail(display = "api returned a trailer header with unknown value: '{}'", _0)]
    UnrecognizedTrailerHeader(String),

    #[fail(display = "api returned unknwon error '{}'", _0)]
    Uncategorized(String),
}

#[cfg(feature = "hyper")]
impl From<hyper::Error> for Error {
    fn from(err: hyper::Error) -> Error {
        Error::Client(err)
    }
}

#[cfg(feature = "actix")]
impl From<actix_web::error::Error> for Error {
    fn from(err: actix_web::error::Error) -> Error {
        Error::Client(err)
    }
}

#[cfg(feature = "actix")]
impl From<actix_web::client::SendRequestError> for Error {
    fn from(err: actix_web::client::SendRequestError) -> Error {
        Error::ClientSend(err)
    }
}

#[cfg(feature = "actix")]
impl From<actix_web::error::PayloadError> for Error {
    fn from(err: actix_web::error::PayloadError) -> Error {
        Error::ClientPayload(err)
    }
}

impl From<http::Error> for Error {
    fn from(err: http::Error) -> Error {
        Error::Http(err)
    }
}

impl From<serde_json::Error> for Error {
    fn from(err: serde_json::Error) -> Error {
        Error::Parse(err)
    }
}

impl From<FromUtf8Error> for Error {
    fn from(err: FromUtf8Error) -> Error {
        Error::ParseUtf8(err)
    }
}

impl From<http::uri::InvalidUri> for Error {
    fn from(err: http::uri::InvalidUri) -> Error {
        Error::Url(err)
    }
}

impl From<std::io::Error> for Error {
    fn from(err: std::io::Error) -> Error {
        Error::Io(err)
    }
}

impl From<serde_urlencoded::ser::Error> for Error {
    fn from(err: serde_urlencoded::ser::Error) -> Error {
        Error::EncodeUrl(err)
    }
}

'''
'''--- filesys-api/src/response/file.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::{serde, IpfsHeader};
use std::collections::HashMap;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct IpfsDetailedFile {
    pub hash: String,
    pub size: u64,

    #[serde(rename = "Type")]
    pub typ: String,

    #[serde(default)]
    pub links: Vec<IpfsHeader>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FileLsResponse {
    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub arguments: HashMap<String, String>,

    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub objects: HashMap<String, IpfsDetailedFile>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_file_ls_0, FileLsResponse);
    deserialize_test!(v0_file_ls_1, FileLsResponse);
}

'''
'''--- filesys-api/src/response/files.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

pub type FilesCpResponse = ();

pub type FilesFlushResponse = ();

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FilesEntry {
    pub name: String,

    // This is a protocol buffer enum type defined in
    // https://github.com/ipfs/go-ipfs/blob/master/unixfs/pb/unixfs.proto ...
    // So it might be some other type than u64, but certainly shouldn't be *bigger* than u64.
    #[serde(rename = "Type")]
    pub typ: u64,
    pub size: u64,
    pub hash: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FilesLsResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub entries: Vec<FilesEntry>,
}

pub type FilesMkdirResponse = ();

pub type FilesMvResponse = ();

pub type FilesRmResponse = ();

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FilesStatResponse {
    pub hash: String,
    pub size: u64,
    pub cumulative_size: u64,
    pub blocks: u64,

    #[serde(rename = "Type")]
    pub typ: String,
}

pub type FilesWriteResponse = ();

#[cfg(test)]
mod tests {
    deserialize_test!(v0_files_ls_0, FilesLsResponse);
    deserialize_test!(v0_files_stat_0, FilesStatResponse);
}

'''
'''--- filesys-api/src/response/filestore.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FilestoreDupsResponse {
    #[serde(rename = "Ref")]
    pub reference: String,

    pub err: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct FilestoreObject {
    pub status: i32,
    pub error_msg: String,
    pub key: String,
    pub file_path: String,
    pub offset: u64,
    pub size: u64,
}

pub type FilestoreLsResponse = FilestoreObject;

pub type FilestoreVerifyResponse = FilestoreObject;

'''
'''--- filesys-api/src/response/id.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct IdResponse {
    #[serde(rename = "ID")]
    pub id: String,

    pub public_key: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub addresses: Vec<String>,

    pub agent_version: String,
    pub protocol_version: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_id_0, IdResponse);
}

'''
'''--- filesys-api/src/response/key.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct KeyPair {
    pub name: String,
    pub id: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct KeyPairList {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub keys: Vec<KeyPair>,
}

pub type KeyGenResponse = KeyPair;

pub type KeyListResponse = KeyPairList;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct KeyRenameResponse {
    pub was: String,
    pub now: String,
    pub id: String,
    pub overwrite: bool,
}

pub type KeyRmResponse = KeyPairList;

#[cfg(test)]
mod tests {
    deserialize_test!(v0_key_gen_0, KeyGenResponse);
    deserialize_test!(v0_key_list_0, KeyListResponse);
    deserialize_test!(v0_key_rename_0, KeyRenameResponse);
}

'''
'''--- filesys-api/src/response/log.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct LogLevelResponse {
    pub message: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct LogLsResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_log_ls_0, LogLsResponse);
}

'''
'''--- filesys-api/src/response/ls.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct IpfsFile {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsFileHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct IpfsFileHeader {
    pub name: String,
    pub hash: String,
    pub size: u64,

    #[serde(rename = "Type")]
    pub typ: u32,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct LsResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub objects: Vec<IpfsFile>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_ls_0, LsResponse);
    deserialize_test!(v0_ls_1, LsResponse);
}

'''
'''--- filesys-api/src/response/mod.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

//! This module contains structures returned by the IPFS API.

pub use self::add::*;
pub use self::bitswap::*;
pub use self::block::*;
pub use self::bootstrap::*;
pub use self::commands::*;
pub use self::config::*;
pub use self::dag::*;
pub use self::dht::*;
pub use self::diag::*;
pub use self::dns::*;
pub use self::error::*;
pub use self::file::*;
pub use self::files::*;
pub use self::filestore::*;
pub use self::id::*;
pub use self::key::*;
pub use self::log::*;
pub use self::ls::*;
pub use self::mount::*;
pub use self::name::*;
pub use self::object::*;
pub use self::pin::*;
pub use self::ping::*;
pub use self::pubsub::*;
pub use self::refs::*;
pub use self::repo::*;
pub use self::resolve::*;
pub use self::shutdown::*;
pub use self::stats::*;
pub use self::swarm::*;
pub use self::tar::*;
pub use self::version::*;

/// Create a test to deserialize a file to the given instance.
///
#[cfg(test)]
macro_rules! deserialize_test {
    ($f: ident, $ty: ident) => {
        #[test]
        fn $f() {
            let raw = include_str!(concat!("tests/", stringify!($f), ".json"));

            match ::serde_json::from_str::<super::$ty>(raw) {
                Ok(_) => assert!(true),
                Err(e) => assert!(false, format!("failed with error: {}", e)),
            };
        }
    };
}

mod add;
mod bitswap;
mod block;
mod bootstrap;
mod commands;
mod config;
mod dag;
mod dht;
mod diag;
mod dns;
mod error;
mod file;
mod files;
mod filestore;
mod id;
mod key;
mod log;
mod ls;
mod mount;
mod name;
mod object;
mod pin;
mod ping;
mod pubsub;
mod refs;
mod repo;
mod resolve;
mod serde;
mod shutdown;
mod stats;
mod swarm;
mod tar;
mod version;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct IpfsHeader {
    pub name: String,
    pub hash: String,
    pub size: u64,

    #[serde(rename = "Type")]
    pub typ: Option<String>,
}

'''
'''--- filesys-api/src/response/mount.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct MountResponse {
    #[serde(rename = "IPFS")]
    pub ipfs: String,

    #[serde(rename = "IPNS")]
    pub ipns: String,

    pub fuse_allow_other: bool,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_mount_0, MountResponse);
}

'''
'''--- filesys-api/src/response/name.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct NamePublishResponse {
    pub name: String,
    pub value: String,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct NameResolveResponse {
    pub path: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_name_resolve_0, NameResolveResponse);
}

'''
'''--- filesys-api/src/response/object.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::{serde, IpfsHeader};
use std::collections::HashMap;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectDiff {
    #[serde(rename = "Type")]
    pub typ: u64,

    pub path: String,

    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub before: HashMap<String, String>,

    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub after: HashMap<String, String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectDiffResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub changes: Vec<ObjectDiff>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectGetResponse {
    pub data: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectLinksResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectNewResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectPatchAddLinkResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectPatchAppendDataResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectPatchRmLinkResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectPatchSetDataResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectPutResponse {
    pub hash: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub links: Vec<IpfsHeader>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ObjectStatResponse {
    pub hash: String,
    pub num_links: u64,
    pub block_size: u64,
    pub links_size: u64,
    pub data_size: u64,
    pub cumulative_size: u64,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_object_diff_0, ObjectDiffResponse);
    deserialize_test!(v0_object_links_0, ObjectLinksResponse);
    deserialize_test!(v0_object_stat_0, ObjectStatResponse);
}

'''
'''--- filesys-api/src/response/pin.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;
use std::collections::HashMap;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PinAddResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub pins: Vec<String>,

    pub progress: Option<i32>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PinType {
    #[serde(rename = "Type")]
    pub typ: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PinLsResponse {
    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub keys: HashMap<String, PinType>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PinRmResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub pins: Vec<String>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_pin_ls_0, PinLsResponse);
    deserialize_test!(v0_pin_add_0, PinAddResponse);
}

'''
'''--- filesys-api/src/response/ping.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PingResponse {
    pub success: bool,
    pub time: i64,
    pub text: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_ping_0, PingResponse);
    deserialize_test!(v0_ping_1, PingResponse);
    deserialize_test!(v0_ping_2, PingResponse);
}

'''
'''--- filesys-api/src/response/pubsub.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PubsubLsResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct PubsubPeersResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

pub type PubsubPubResponse = ();

#[derive(Debug, Deserialize)]
pub struct PubsubSubResponse {
    pub from: Option<String>,
    pub data: Option<String>,
    pub seqno: Option<String>,

    #[serde(rename = "topicIDs")]
    pub topic_ids: Option<Vec<String>>,

    #[serde(rename = "XXX_unrecognized")]
    pub unrecognized: Option<Vec<u8>>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_pubsub_ls_0, PubsubLsResponse);
    deserialize_test!(v0_pubsub_ls_1, PubsubLsResponse);
    deserialize_test!(v0_pubsub_peers_0, PubsubPeersResponse);
    deserialize_test!(v0_pubsub_sub_0, PubsubSubResponse);
    deserialize_test!(v0_pubsub_sub_1, PubsubSubResponse);
}

'''
'''--- filesys-api/src/response/refs.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RefsLocalResponse {
    #[serde(rename = "Ref")]
    pub reference: String,

    pub err: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_refs_local_0, RefsLocalResponse);
}

'''
'''--- filesys-api/src/response/repo.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;
use std::collections::HashMap;

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RepoFsckResponse {
    pub message: String,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RepoGcResponse {
    #[serde(deserialize_with = "serde::deserialize_hashmap")]
    pub key: HashMap<String, String>,
    pub error: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RepoStatResponse {
    pub num_objects: u64,
    pub repo_size: u64,
    pub repo_path: String,
    pub version: String,
}

// Defined in go-ipfs:master core/commands/repo.go
#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RepoVerifyResponse {
    pub message: String,
    // Could technically be an i64 but this is probably safest?
    pub progress: i32,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct RepoVersionResponse {
    pub version: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_repo_gc_0, RepoGcResponse);
    deserialize_test!(v0_repo_stat_0, RepoStatResponse);
    deserialize_test!(v0_repo_verify_0, RepoVerifyResponse);
    deserialize_test!(v0_repo_verify_1, RepoVerifyResponse);
    deserialize_test!(v0_repo_version_0, RepoVersionResponse);
}

'''
'''--- filesys-api/src/response/resolve.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ResolveResponse {
    pub path: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_resolve_0, ResolveResponse);
}

'''
'''--- filesys-api/src/response/serde.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use serde::de::{Deserialize, Deserializer, MapAccess, SeqAccess, Visitor};
use std::collections::HashMap;
use std::error::Error;
use std::fmt;
use std::marker::PhantomData;

pub struct IntegerVisitor;

impl<'de> Visitor<'de> for IntegerVisitor {
    type Value = i64;

    fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
        formatter.write_str("integer")
    }

    fn visit_i8<E>(self, num: i8) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num.into())
    }

    fn visit_i32<E>(self, num: i32) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num.into())
    }

    fn visit_i64<E>(self, num: i64) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num)
    }

    fn visit_u8<E>(self, num: u8) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num.into())
    }

    fn visit_u32<E>(self, num: u32) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num.into())
    }

    fn visit_u64<E>(self, num: u64) -> Result<Self::Value, E>
    where
        E: Error,
    {
        Ok(num as i64)
    }
}

/// Deserializes a sequence or null values as a vec.
///
pub fn deserialize_vec<'de, T, D>(deserializer: D) -> Result<Vec<T>, D::Error>
where
    D: Deserializer<'de>,
    T: Deserialize<'de>,
{
    // Visits a sequence or null type, returning either the sequence
    // or an empty vector.
    //
    struct VecVisitor<T>(PhantomData<T>);

    impl<'de, T> Visitor<'de> for VecVisitor<T>
    where
        T: Deserialize<'de>,
    {
        type Value = Vec<T>;

        fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
            formatter.write_str("sequence or unit")
        }

        fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
        where
            A: SeqAccess<'de>,
        {
            let mut vec = Vec::new();

            while let Some(item) = seq.next_element()? {
                vec.push(item);
            }

            Ok(vec)
        }

        fn visit_none<E>(self) -> Result<Self::Value, E>
        where
            E: Error,
        {
            Ok(Default::default())
        }

        fn visit_some<D>(self, deserializer: D) -> Result<Self::Value, D::Error>
        where
            D: Deserializer<'de>,
        {
            deserializer.deserialize_seq(VecVisitor(PhantomData))
        }
    }

    deserializer.deserialize_option(VecVisitor(PhantomData))
}

/// Deserializes a map or null values as a HashMap.
///
pub fn deserialize_hashmap<'de, T, D>(deserializer: D) -> Result<HashMap<String, T>, D::Error>
where
    D: Deserializer<'de>,
    T: Deserialize<'de>,
{
    // Visits a map or null type, returning either the mapping
    // or an empty HashMap.
    //
    struct MapVisitor<T>(PhantomData<T>);

    impl<'de, T> Visitor<'de> for MapVisitor<T>
    where
        T: Deserialize<'de>,
    {
        type Value = HashMap<String, T>;

        fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
            formatter.write_str("map or unit")
        }

        fn visit_map<A>(self, mut map: A) -> Result<Self::Value, A::Error>
        where
            A: MapAccess<'de>,
        {
            let mut hashmap = HashMap::new();

            while let Some((key, value)) = map.next_entry()? {
                hashmap.insert(key, value);
            }

            Ok(hashmap)
        }

        fn visit_none<E>(self) -> Result<Self::Value, E>
        where
            E: Error,
        {
            Ok(Default::default())
        }

        fn visit_some<D>(self, deserializer: D) -> Result<Self::Value, D::Error>
        where
            D: Deserializer<'de>,
        {
            deserializer.deserialize_map(MapVisitor(PhantomData))
        }
    }

    deserializer.deserialize_option(MapVisitor(PhantomData))
}

'''
'''--- filesys-api/src/response/shutdown.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

pub type ShutdownResponse = ();

'''
'''--- filesys-api/src/response/stats.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::{BitswapStatResponse, RepoStatResponse};

pub type StatsBitswapResponse = BitswapStatResponse;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct StatsBwResponse {
    pub total_in: u64,
    pub total_out: u64,
    pub rate_in: f64,
    pub rate_out: f64,
}

pub type StatsRepoResponse = RepoStatResponse;

#[cfg(test)]
mod tests {
    deserialize_test!(v0_stats_bw_0, StatsBwResponse);
}

'''
'''--- filesys-api/src/response/swarm.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use response::serde;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmAddrsLocalResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmAddrsConnectResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmAddrsDisconnectResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmFiltersAddResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmFiltersRmResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub strings: Vec<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmPeerStream {
    pub protocol: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmPeer {
    pub addr: String,
    pub peer: String,
    pub latency: String,
    pub muxer: String,

    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub streams: Vec<SwarmPeerStream>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct SwarmPeersResponse {
    #[serde(deserialize_with = "serde::deserialize_vec")]
    pub peers: Vec<SwarmPeer>,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_swarm_addrs_local_0, SwarmAddrsLocalResponse);
    deserialize_test!(v0_swarm_peers_0, SwarmPeersResponse);
    deserialize_test!(v0_swarm_peers_1, SwarmPeersResponse);
    deserialize_test!(v0_swarm_peers_2, SwarmPeersResponse);
}

'''
'''--- filesys-api/src/response/tar.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct TarAddResponse {
    pub name: String,
    pub hash: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_tar_add_0, TarAddResponse);
}

'''
'''--- filesys-api/src/response/tests/v0_bitswap_stat_0.json ---
{
  "ProvideBufLen": 0,
  "Wantlist": null,
  "Peers": [
    "QmNMVHJTSZHTWMWBbmBrQgkA1hZPWYuVJx2DpSGESWW6Kn",
    "QmNPE3t4LjScFzvcqsoy935sBqwZgJsZwQAEky5wqQvDdY",
    "QmNREDDtG6AYYF5WkbALCe4zunyFAmdrikCnwaVmPx6kX9",
    "QmNRuQrwtGgeVQgndTny4A4Rukg7GR7vzDJrVJxUBfqevk",
    "QmNTZy7TfXvsHczwwV3EYbxRZN5gthgicG9GiroD7C4ZrP",
    "QmNU6sCSZ88ukfCV5dBWvgjjrerki7DQdvtnpFCG7oEmg5",
    "QmNbfsY8eCRRyppfpJLTarsphUUY1GGU55G99kgJSfXvRL",
    "QmNdPwvMx28B2izWWoQTrV5htg6zCNYhXwJnX2ZmCYTDUB",
    "QmNnMBRw4Ap2tMzihSQPEMaCdKg1scztpNaW9bHJF2XamU",
    "QmNqnFQNN522wpzvwXresRcEBGqbvMKHqH9yjVPeHLdmdK",
    "QmNsbnz931WZRd6PMBKg7Y1DzSErg9LRndAcr4WfA84oNN",
    "QmNtZZUjHkugicGsN7Uqj8mKWWDVtsAWzRQdKHntSJyuTq",
    "QmNwJpkft8wptZwS8a5RpqGqJUV9hUhJ2afFzZxCwXybCY",
    "QmNwo6GSBWgRj39YoCfpinwgNJKQPeqp4MZD4dwXNpEjEu",
    "QmNxH5ukKsVMVqpWnSEV8a5Z6a1sgadZ4UdsXHYx5iPWbG",
    "QmNz4kQsW9vv7XSJKGiBRpJDHKfbZNPS6ycbSG2fSSgAq9",
    "QmNzViZ9QbsHtscwuMACnLg4wZnh8hFzJdhxw7oPBRGdUW",
    "QmP2g9yAeWRxEibagcW3VMaFKTNBkx5GREnn9cy9AwwhhS",
    "QmP2zdRMVSPk7HoTYT6Hs2i4reUz2NBVevKFQXwk7ugoA6",
    "QmP4MkMxv7BmukrCGQodkHgfStMvvsGyoqJoKKv2q3dC8Y",
    "QmP6JzWD2GgwmU1NatFi2XAKqVsEEnyHX97gS2fz5xCm66",
    "QmP7DRUXFXWVQrytCFEynsh3v1jAPXbaHfWBoUDKZhsKkA",
    "QmP8MkArujgu1fth3iDZWXogrfExVe8V4CvKkS18F97LzS",
    "QmPK9W4RGheHqpmm6LiXZ1ramM7dMDDsSrs36Y8TfZJqqB",
    "QmPNhiqGg81o2Perk2i7VNvvVuuLLUMKDxMNwVauP8r5Yv",
    "QmPRc9QX3jkNoTG6qrRXeXuoCapf7PC3VKZpZpZpEfaAVQ",
    "QmPU2xTqv4MuDYrbJTEsnYYGR4ChDaVBVGBUh4yrnwEZ3x",
    "QmPWCn6mmzoFT6NK7YxDR8UqfzoqjJWEj3rqPyrQmzmg5n",
    "QmPWkbDDnmCVdeVKaazwx2LNBH3McPGS5jriBHYp8MT6c8",
    "QmPZpdB6w1NyhN4QUn4scvkojk3x5PCghkFUH9S2J2sKKS",
    "QmPa57uzGBMMUB52kDgTZvtiKBqkHXAANVjW4PfC39DEs4",
    "QmPeCS6UkPMY3DyuXVcLt8DfvTuWCdpA86HrtdkYoV2pe2",
    "QmPgR3KdnvVsvNH4UzHW1tM2edBwam8KzQC7t65t4kgykB",
    "QmPknn9dVwwLKqrmEYEcdpgSdWRsKSVsWnWKYZtxo57f4j",
    "QmPzpoFobcvaxG5cBEn59JhCLoifmnN8AB35iNt5MHQupV",
    "QmQ1ZQvNwTzB2bxtcLcmUqtYvdD9ztudSgExkYcRECqMAb",
    "QmQ6q6LTRMLwjaNns5unMfMJy96SUgyWCLLSGq1ztchq9Q",
    "QmQ85u4dH4EPRpNxLxBMvUCHCUyuyZgBZsfW81rzh51FtY",
    "QmQ8CTrT3ttBHasa4x635LWYhRBehh2amucvWkXGJ86gix",
    "QmQ8MYL1ANybPTM5uamhzTnPwDwCFgfrdpYo9cwiEmVsge",
    "QmQ9W8XbGf7bocnDMPXaQGTrKC8hjUL1Sh2vrhTYGqoo9Y",
    "QmQAkbMZRqdRjWrbzXGvMJ8abZhUa6Q5Ky8sr6A2FX8spR",
    "QmQArKLQkH76TFCA6iEs9PN2RAt5v1VwuozqYdE1BiUzgo",
    "QmQBruCCqHeY2CwfAqKRu1jdSsfs3kRoHY2yN5rgyTYcES",
    "QmQDj7tke8fBby556Bdsbr6hMa4xAgqov3EoiGYSScGtRh",
    "QmQLW2mhJYPmhYmhkA2FZwFGdEXFjnsprB5DfBxCMRdBk9",
    "QmQPHAYukjXfuHjTjNZHqcfwdoMc7arpWppbD458TC2VuA",
    "QmQQVXUUTrNxWv2bbCvV7R34H3qwKuj6Hyv8U8TDzq3ZZb",
    "QmQRgj6h3Cum2wYxLMpSNhhsZZ6FETYoww3Hymec761BNu",
    "QmQYVwbLePXyG6ka448jPfDUenXDDbdP4VrXH2mLfGcUYk",
    "QmQZu8YDURjeX5a8QXy7ApWAumDt55Jae3Y54Cka9Xonna",
    "QmQm54AzmvQM5wcPJzGu86g6MhjV22WtsCrb19jZMHAb3f",
    "QmR1mXyic9jSbyzLtnBU9gjbFY8K3TFHrpvJK88LSyPnd9",
    "QmR54YH1v59BRuoNipwPBm5QrqKq28fQWUwou8uiunyX6B",
    "QmR5fDnrrER8aigmLRZmRVMtRFLAHwGZfVf4NeWmtRjfJ4",
    "QmR7oYWAjJhWzhbEJ413W7SzB95GspHqb47cfLNmDQfrK4",
    "QmR9GANQNJqiWczcaRzKUp2JVvCk6pFvVZnWCMQBH3xF61",
    "QmRFXBDmJgPyqD9vquvJe59ukaZeaA1UytBo3HvkYCNyv5",
    "QmRMGUWGHHzriYQbHh8icWykJjTJQFmAGRVxo6MyVoWY9U",
    "QmRUaCytYoaHe4ZypSNmBrHYYHTbH1ZxCyrNwiHvCtzQhD",
    "QmRWoGAPW7nc3iNpPCLwe8QptnBGwsxBW9e3JEvtigr6Tt",
    "QmRf4ERGvYpVo6HRa2VueZT8pWi8YvyLS3rW6ad2y83tdN",
    "QmRfBcTWqezedgFTLX1pvZTwQUg7PDaTwx4SEKmUpN6rQ8",
    "QmRfnwNhkoWYRzvxqTHsvZvfnawSgqNBoCxN84H8nCRcHA",
    "QmRg3nPAW7WWkokGGznZFJMRjMTPXeMoqbG2H4Ejzj3bc9",
    "QmRgUq6apXeFhmsgBSV4QwfEFaWKYfFGHMkHg3RAPc1TM7",
    "QmRgW3mgf9fBn4kEvrypRwMbgzFS4Z7baPStfDdAir5DJX",
    "QmRmfDtFHBFDR1JQA8NxUWTTR5mLWk3nE5xigBRmsTnDon",
    "QmRnbKrLuYnvNdJeYNQspqveSaHVwmD8qnovEiCtUHEQjM",
    "QmRtRvnbtCqhNomcpchzF7GQ82Ln2UoeQVuLbtATXRn3FZ",
    "QmRv1GNseNP1krEwHDjaQMeQVJy41879QcDwpJVhY8SWve",
    "QmRvfRjoCCwVLbVAiYWqJJCiQKqGqSuKckv4eDKEHZXxZu",
    "QmRx5wi2aQoh3GYcySU6y2RSWZxE3MxXSFDSJgiNBPEBot",
    "QmRzLwHyXckrUPxySxHDkSHtQFgAMkcJSKvJkrjV1NKfbX",
    "QmS1WGBBzRGbzu6ecjxM5YSfJ43z3AxGiwn4kqHfxc6XAP",
    "QmSCqQqDH1NccUdxQAKiZ7BVMLf8uK7MfffBT1DXthmov5",
    "QmSF2ZVkh7PsWUG15QXbr6QeWaeVdaEVL3FjC8mFN9vwkZ",
    "QmSGdSSmiJ2JQHqgBg7Es48BzcepeKtieKs5pwekVjtvev",
    "QmSHyJzdmQzdz7rRYPPPT5dr6z4c5HHrXqxgAjhGfJRHoq",
    "QmSL9rRtVr6zMVbEkLM5cAWxtn39SkV9gVAy8XxR7fY7ub",
    "QmSMSC9SmN1wmfPsiCHxm5uuprL1ciRxkpaUqXRDkGCSDU",
    "QmSMsHDDj3a7sTs4GgWAuC8XSzwN6Gs9zuMftNc5QRtwYT",
    "QmSYMmKGmU5XLAbYSorKhhdkNgM4dvVqPgGky8f9YXeFkq",
    "QmSeAsN8J6mD8kSDZMcBcV9NsQbrGpA5mr6iLiHU5SfEn5",
    "QmSjjcHsV5k46tjq1ybccFUpYSSrDUyTxLvsH6pjLUowpX",
    "QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3",
    "QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx",
    "QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm",
    "QmSraCsx5vMGxMcKTnLrY92AVaF2DLijphDGZADpdxCYum",
    "QmSwxMNzSRR5RrohuZRmsmi2QUfwvWFPo1Kw31qRNEhTRE",
    "QmSxrFXq85asEujMX7HpRRZP98cPsYDCnpTtqBuCh5DBKk",
    "QmT1q92VyoqysvC268kegsdxeNLR8gkEgpFzmnKWfqp29V",
    "QmT4WAYU3VcLzqqi8UYcwXNopU1MLgk8ZthxSSNiBDE3aF",
    "QmTFJ6RhHiw9tRnZQ2zMkZ9xHFJKeXokQRGwFwQ61mzTiw",
    "QmTHroCBe269wMTHBzz9asFDBYGhoZW6YV972oTzTrP5TS",
    "QmTM772soX6HLtaZMCiUbsWsi9XTFmRvsSZmRQTJ48ByE5",
    "QmTQ8xAth4jo8k68P95tUn6KXkN9VxRRUBENKMSirRUxEp",
    "QmTRzs8GCkG57qWmeXxD4ns2Mi4tQL5ExonKHDrHNTJd9B",
    "QmTSVPyzDvDRNZgx84E7q8s5L549NxZjTY7uA2Y1B2PNhp",
    "QmTT7kS7aj3biFa6wDo9aYQEw6LJhKBQxGfSsvAnvwQRZh",
    "QmTWG4AtyXxLPtZ6iahoaT8HBA2cDSSeAvkbrzNVT8KS4p",
    "QmTd8hdQwH2GsghzyKGBrpJ1NVntxpQRS65sohQ2sjHofK",
    "QmTfgYcqzT6CjFXJu9aUy2TBQY6LHNiK4L3hPVU56uHtiW",
    "QmTm7RdPXbvdSwKQdjEcbtm4JKv1VebzJR7RDra3DpiWd7",
    "QmTrKQxEJWVNro1FWSN3tgQKZ9zPUv9MNLSra6eKbsk3HP",
    "QmTtRKJY9EpxD7XuJoni2uYGxSnk2vdXLknSse2R9HmG1r",
    "QmTtggHgG1tjAHrHfBDBLPmUvn5BwNRpZY4qMJRXnQ7bQj",
    "QmTufLSBgzM3WGjVurXfwii5YpoVPSKxYqzc19em9fw88P",
    "QmTwha4XUm8kR1fUnhffp7L1zHYHNyuXeWLi928jkrFJn5",
    "QmU355SfH2H2RdkQXQciLucFKMnpQBvpFnzUd9LFyEHxYi",
    "QmU5tbU6UYSACHZVGCbyGSnVGP7eJLTskZVSAkRVLvZt9e",
    "QmU9sFP6jagGXaXJ5Af7shgbMkAFk7toRW8Vzct5qsucV6",
    "QmUBuxbW9JzHHs1WW89YhWgo45cK8YXWf2utaDRyqsQJvW",
    "QmUFzAjw53b7kHHCLr4F7doCpuFWpRYhqykUUu6dKFJcXQ",
    "QmUHKXqq4e56BRu16D8wKHsqc8Ere3w6gLLqrfMF7djTwe",
    "QmUK6NhDJWArXeqrh5dp8CWcs4dD8TEmc2JGwiEevEU712",
    "QmULwuyabPw2tJcWaA2qQcQiD3JACNQL1PheoqQeY8t91U",
    "QmUc1fB7vYuZLxUvEJPb6w2z5apKRgmKqWjCm7A8yG9u81",
    "QmUfQxnm88UGoNHhnZ6DHuqc4Gks8n7r8XW4R4bnbx9nFH",
    "QmUgqiWPyheTEbfFPkGempMoUMutezU9WLKbUtxe4xNL7w",
    "QmUijC2Ktf9cRafS1E9ow8jhRNVH9znaNebY5vSRjZEthS",
    "QmUmmSF3869T6UeQKptZS1KHAT6BQPSQxUL9dZK3yXtZ5S",
    "QmUnwLT7GK8yCxHrpEELTyHVwGFhiZFwmjrq3jypG9n1k8",
    "QmUofTDmSkpYQJgKDoFwWmLNZ4mkvpQ7ejPHMawRydmhwN",
    "QmUpEZC8VTsQBCbqtcJ16ghhnNHD79N6CUjAj2A7Ti35R6",
    "QmUpnY2gAsWFPYeZoAifhhhvRA77FNsmaivQKYAjGeEYtM",
    "QmUyabZMM1U6AauSChXSTKk5JSpTLE6PcyNyPQdQ8ifkBc",
    "QmV2rmHtQEi3zyJm4rRtLaCu1ZMFS4N82J5ZrFAsQYdrBR",
    "QmVDAMnPwK5C7ctedjdfYi92AUr7j2Tg4yg3JeupjKdfVF",
    "QmVGfjk3zd8uUPpt5JTaRqx1UZ2gPqLatYPsMxnt6E4yhf",
    "QmVHh1B9dbhXvf3Vgu5soyrKRqisyJYLCXSbjQvzu5BHmF",
    "QmVPCaHpUJ2eKVMSgb54zZhYRUKokNsX32C4PSRWiKWY6w",
    "QmVQtZBzUhU2BoYvaAnwcQMZCoP2tokqNd5uWAWuzfycX5",
    "QmVTUpMBxrU1yHAvoUDqJ6Q4qLUM44TZDMVnDSgUVJEpvS",
    "QmVVKpcKTsRBKHNzUUSoWXe2HRwa46YisLez9SBaEzFRvB",
    "QmVWdrES8m8qDHpHpXi4bVwmgJpGtnCE8qqnd8NFsAm4Rg",
    "QmVaNgbwQi69fegB6e5oCAAoAyTkaugoFGH7RCJvR6mwN6",
    "QmVaUD4sack94cZCWEcQsVVTH3MfBaSKGoX368VREwVEgP",
    "QmVbRQKW6fcH2zeWnKTCJwDBirv9WWX6pdvwRUuDGwCn9x",
    "QmVjEQAUXCEQMDmvgtsd5f2EsgTbg33Cpis5TDM3uVP9Vs",
    "QmVk8DsWXJEKQDavJrkKPgkngmwJpVUqt7fieZkQBQtaa7",
    "QmVkkYeUYC4FQ2aB3SB44jBwfQTv1Ej4DJxiJG4mSZbn3j",
    "QmVpArddqSWeapqyRVgGAyjGqxjgs77PjWtHWjUE6Hc4YM",
    "QmVsQLzNz19BWiiSAo6ymfy4rHA2U2vbwBpZqSFvBrZr8m",
    "QmVuuGmiHf7ndzwD3kDxD2e1pJPSLMrAdVywxmR1hCjGQ1",
    "QmVvWyHBz86fr7oHXrcbYCnLgwd2SGDQad5WvZ3e176Ex9",
    "QmVvfcTy357kv79CJjcfqd9coEqLgzssRJ6zsbeE2Q4VKw",
    "QmW1j4nmBMnbyJbgs38airHo5neDMzpJ1yQRF8s6vPvtgL",
    "QmW9yCnWLKu7Xv7LByMNxRk1iY6Ghe3V4G73H5yRQW72pz",
    "QmWFJuL6mhn8sskpuDfkEiDR3XbmyQdrZCm5eRwe3hLgZ8",
    "QmWFYZoa1WZx7uLwsHsfkHPXgQnjvyo13X7QFa57xFa6Nt",
    "QmWNu6YcYcPCMPiZuEvnegJR8rggLkQwQn9PfWnLXPaJ18",
    "QmWPkUoiPBPDCCvmCsUZDLzw9nLyCUUp51YV6x4MjU7hNP",
    "QmWRs1vEm4d512yVxdXLJuMqmQcwRD767i3xHMo5mB3P4v",
    "QmWSJh12NHGKVzjeYHbMko1AgNMtFfySH7wEL48KkiUFf9",
    "QmWTiQrXvmA4N4x6KRvFcaXdDeeGkekToWBsDGbpgV6zJ2",
    "QmWXqCDUQxHfnzZkxQRcLSuXEyR46TA7Y2A6DKUrFhmLj3",
    "QmWezbPXmHNoznwhDodtuHsL4BcxEo7nhVAmtcE8qu5Low",
    "QmWghs28BoawS5TrzaLCu9hERpCAGaCYWH9sWrbK3HGSEY",
    "QmWhRpY3wdz7ncbNsLvrND5XJzBAQbAzqdo9xHgaM2sQDq",
    "QmWjDFBnA41gBqxjy5SkLTkv5JeZFQLDfB6cpZbj9EV5dq",
    "QmWkmnyswaY3obqdFSgAma6qkMsoStHHx6My7HLEr9Hg7b",
    "QmWmJfJKfJmKtRqsTnygmWgJfsmHnXo4p3Uc1Atf8N5iQ5",
    "QmWo54fjnhX8R7zbjdtk3XGqV2U7QJCVuS56ffX8s3DTEM",
    "QmWooSC2V1tS7iPmFDuwNbN5GBGbucpsRjpd1DBznPog3Q",
    "QmWpwCwGxziLvVz9hUdbQDLVB3qcEuBDt1VreV1ZeoagF7",
    "QmWt2QfGLqgcZV2RWW7MK2FCMqWbZjga6iYYZc79n3freD",
    "QmWvSzzYotq6zop4Vo8XyLXa9JU1ztmDXLj44sgHwhUwpd",
    "QmX2EMjpYqSRN6HYLHu4jBnh1oWoGYninjpFYDnvy7JHsD",
    "QmX64Tjh1MfUMVkM9gr4vZThJT8YHLewfQ7HyqaHHTj3Q5",
    "QmX6HBaLdtsS2p2GFNqzh2844wTFgMU2ufTboTZHvvs6rU",
    "QmX95Sm2wqZHoLGpMsMHQPMnkeiWnMLBYJZUeoZaiAWbnC",
    "QmX96Up3SA3AKKqeaJHvCizbj7GNdGf4mTQLLSrEoQUc6e",
    "QmX9LKWB3iv85PTytmW6msaV8UtrHyzw2AU1QSK48jdPpe",
    "QmX9Nhr56k7K2JBQbu9JBpF2s1AQk8WpmZc6v4sqZERMRu",
    "QmXBcnLY9XonGuBigwSbx6fpMhPRn1p5Yw2Sutf3xXhype",
    "QmXGBgWo7kMHuiPJvBJDLsei6jymsLARh8c1HUu6Uh1kF2",
    "QmXHMcHDEtGxRvMBWEiSN2psHD3hfi1susbvvn4UjKDjqd",
    "QmXK7nyzK1cJwdbEFFcT7gTzsz94vnR2ZDkKBD37VEwbyC",
    "QmXKd1pJxTqTWNgGENcX2daiGLgWRPDDsXJe8eecQCr6Vh",
    "QmXQQjcUG5Q7MbWtPHGyMWBi1JR8cuUSYUe3CLk9RCScWf",
    "QmXVgWdfyxDqb349raWJqsCXfQ6U3WBPYQE8shuU92zVMd",
    "QmXcJbdTdrKtfYj2ji9Vtk7xX2tzPAcPo2iwfvEpoW97ku",
    "QmXdpR4e2p1zmzqybi8dRderPoZNWsLdL5Te7KJ77qiiZd",
    "QmXe3fpBwaNNrpkxP4mvw7G97rfcGJSgJWe1ZcRtE36uE4",
    "QmXepNs7tnbFxNQVGNx5aKHwWx4FCHqfCtDkddqx9JY6EZ",
    "QmXnz2NZK4YPk67eEGxwhoEL3SiMg6H3F89gVHHan7CNjA",
    "QmXqmicbyUEJXYmFB8Rgh4X2FxcyVpJM6MWEJY8BsWkAno",
    "QmXtyRJmYkpKM3vJ5dWj7JpPKBHHUZS4aWGX9RFeg4v8WQ",
    "QmXvprA7YpHwwBkh9yjiUMqHKk5NT9FNJ1BXo6cFW6cNjh",
    "QmY4RygsQGFCpb1eqegoETon2jWUPnhwokGq59eCSnMgm8",
    "QmY54zq6q81jn9fep23REJPA9UtbKrfH4bLALnCSnk7R5a",
    "QmY5ArCT1e4ujPb9KdfFsjvkeDQ5ao4qZKT32difepRCqv",
    "QmY5gqgoPVtRi1B65P4S7vZLiRsQm22qnTLnWykbcxBuRt",
    "QmY6qA7wnmp6MvFTAAk8epT8rxYzYS52UuB6f4Ddpgs8ah",
    "QmY6x7RMscmpcrFitDkyRrC17CMM2uud3j6Gtxf3epQW48",
    "QmYCLRXcux9BrLSkv3SuGEW6iu7nUD7QSg3YVHcLZjS5AT",
    "QmYDLVrZDpYgssE5mE1EkmzZ2iHmrfhJozwZM1sGgnMeZX",
    "QmYDt3TopyRaiNNd3Swxew5ThMgNw8Kq2E3UpuR42JBDFF",
    "QmYDuo31sahP1hk1cQpZ76e4RGAG7XG67KJdeX3RJcaNxA",
    "QmYHk2VWWNAbc4zU5oyemfadBYMtNmutqXHjSDV8hm5E7g",
    "QmYNoVUo4zGHt67qw2mF7teNS97G4pu77eBJ45bZ2SNosR",
    "QmYR8KdRagoXSjodmUR3vhwLC33G8HPeGYyH8kX9zZdkAg",
    "QmYSejdWa7Mar3rKzCVYEcpQSVAySG3UZUWBxVbUJeM2xJ",
    "QmYbAMm8nFi6Rhm5ciwT4vZGKM4v4Kf9pUtTuoDmCcJAkU",
    "QmYdn8trPQMRZEURK3BRrwh2kSMrb6r6xMoFr1AC1hRmNG",
    "QmYdoobRER9gUG937f1ZjYaT3eyR1vJnjtLj8UtzFvm3XW",
    "QmYfXRuVWMWFRJxUSFPHtScTNR9CU2samRsTK15VFJPpvh",
    "QmYhF2JYMN9TV17j8KaBixFGGemKpAQ81bH2YMQrMbnLav",
    "QmYkQ9SxH71iT6AttBajMqrrkPx1rmm8eBnRuZuqWDLBxB",
    "QmYozfG6MLB67hqGkwL7imyvwMVWufAjHrw6zWpdq72ff5",
    "QmYpJrWgUyjFXf3VgubApACXFBKz6NCb9EZRnKcKPtJcYA",
    "QmYsba1iUFdW4EAMfXvACxZvrwjtP4wyZF5MDQvoaScNPS",
    "QmYtbCRoM8Wizht8bPnX7TQVKos44BDJGBoei9uVnWTiP2",
    "QmYuu24QFs7HZHxeLt8jRAASuHCDWtGNbw79hmQQ8SeGCQ",
    "QmYyLEEy31b8jE3nTP5v24BW7vqfaQdJfJ8njtasJBggtH",
    "QmYz2NwXZfTPqdCa6XUD5NRb5ACErzgdaPiJxEZS5v3CM9",
    "QmZ2SFwzcduERuXcp6WQW9MxMsWMeRL4jxvGVRJQNpRx5F",
    "QmZ86ow1byeyhNRJEatWxGPJKcnQKG7s51MtbHdxxUddTH",
    "QmZA2RwzAw8Bh74wXXkzEHyCyJKR8uSwKKVYvDw4RVHCfp",
    "QmZFeXyPSJESCMnKXJmaSBjqBxGhyRLr2L4rzD3LPXYieg",
    "QmZHXsEzAopSHRELiBPDCWaPHq2u8XZTgg53UFRQEoXuBH",
    "QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic",
    "QmZNDMgzpB7bnUWxHw6h1ua7f27hWiSPz58Z4N1G6erZuW",
    "QmZRMZhCENDj8dFcimoXoqJ6ki4tsJPyaV4xyuKTdFSzMR",
    "QmZSaevcMfNAphuV5zAqdyPi1G8CipspLfNcpwXMK2wbKr",
    "QmZSe5GZJb5jcKQZzQmdWaFtimTHafjvtxyMMTJy5nZ6hN",
    "QmZY7MtK8ZbG1suwrxc7xEYZ2hQLf1dAWPRHhjxC8rjq8E",
    "QmZnX3G3aHviKciXqGVwgMjBBaqeN2p2wNxMVRVEddzcbB",
    "QmZnoFDoFBUcd9YVWQTYneaToWqtAkTqAq8zziYmUSYRKA",
    "QmZrzE3Gye318CU7ZsZ3YeEnw6L7RkbhBvmfU7ebRQEF54",
    "QmZuLBG9vPxbjtv7FxAQp78aqA48npLc4Xa4LKaP1jDNQA",
    "QmZwg62wMWnrwSv2UXJ2YDpfDcTnZvLXXbKQDWyLWYeL2o",
    "Qma6jGJKAfYQ4ufvLVwsmxBNLKUZonHYAJGPrNNijJkooN",
    "QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
    "QmaDirsw8diTgocnfweQf353W6mxCqyvW85edMd6iQnNTt",
    "QmaEERp9HNATPYiCCowLmBdbxuorTgJycTT5iLDD1QPa48",
    "QmaEPhisncP7U491SiEhh7vocgpn5CCx4gweMY1LiuqU8D",
    "QmaGKbtq8UTCx2iNu74Q73QmCp5M2GFzWSESe4ECT7fRW3",
    "QmaLKRweJ9CmChGduNWeT1N5z1m89smZd5GdfwTUV7oD3o",
    "QmaNrWGb4WocHcciZaeVJYeDyNyVy6dKESMJHRcP8sWuWM",
    "QmaNtrhLFmsJPTP3mXyxZ9J4B1uHxPodQ1BEUBwjD2zDvQ",
    "QmaQcV5Y1me1dridkvnLU9GJj9UxjJMh1kk3mar8CQoH1s",
    "QmaeXrsLHWm4gbjyEUJ4NtPsF3d36mXVzY5eTBQHLdMQ19",
    "Qmanmvd9A9nDfuEyw65Y5ToiknBZmDcM35xFqTSeuQns7n",
    "QmarXBVQBH35nVj4RwNQQdU29RD5oQ4yJsvmY4v53vYgTE",
    "QmaxQjoV9rKE3cwsvh8dpn172UpRWJFtq5L7t4QySQQWcm",
    "Qmb3MUc2ePE9DBL74jw5JoyeDDd3rrg8x2h5nwzLxgq9oC",
    "Qmb5cpQ6FQxVKXTiLCEF5gDDZLTg27UaghXVn6KAmP89q3",
    "QmbE9eo6PXuSHAASumNVZBKvPsVpSjgRDEqoMNHJ49cBKz",
    "QmbFAC6qx19vnT92iYRit2LwcXf4xXr6sdvUPxsXbkGpMi",
    "QmbFHeGezS2USVhDdyjxxhNVpTEqaQSreaWJFVX1A7DgUv",
    "QmbFYyUMaxFyms1PNq8r77d7iGwwTbbF3ggTSeCrTqpjiz",
    "QmbJgvyhCgUeLeu7UgjQTjy4aZtnri81NmzMPL8TQYqABg",
    "QmbLmcM3SkK6sfk2bGjtgxwaCUH1416TrxhZPCwyY6ZSFe",
    "QmbNd9g1jGHq9RjyP9omsz1p8rMasgbjAxtxUdoY2Nb2NB",
    "QmbPfWMBXs2FDDc5aRLRgmCuCe44wxDLgNnkrFpJGs8P43",
    "QmbYS7VgpsaYdwph8Unjf9JNBcLg8uvHx4c9p77Bcc1CUo",
    "QmbcnUACW8DtQuzRfb2Vog3ASG6Ahk3b11hfsEprq5E7Yb",
    "QmbeAJBncHtAuc7XSYC8qaGX6LzwcXGjXhRAMegqAvqDpJ",
    "QmbhVM2bpiVAr36D32HrEkbdrAaeEVBqbhzc9o1Zsn8qa2",
    "QmbmGd2UtaqokEzrPHW38KMLnX99t32ejbWMo7cYKoJQws",
    "Qmbq8uaCa7xi7DwRWyMiPLxheV2rWCt6Fc8Lt9KfaGB5N4",
    "QmbqE6UfCJaXST3i65zbr649s8cJCUoP9m3UFUrXcNgeDn",
    "QmbrMSthQKi8TY5efgvYHJvByA1L15YpSaWp3TC1TBWz55",
    "Qmbt1aUEhY6mW7XsDxaZ4CAtBGcvqppax4oVBxmMCk3ooc",
    "QmbtTW3Lj5ad3UotQ7YzKx8bSSaXKirn2ggxxaZWV28z3D",
    "QmbtpFe74b5pg9T8YC1DSi3uevU9AfG4rpzUtCAjTLgRtF",
    "Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6",
    "QmbvbpagRCbinshyH3XfA2ivg4F7wXwbsKoqMSgq4wUYvs",
    "QmbxFa3FMsYP3egnW7HV7Y1a5PSruii2TtnQaMd51Xhzeq",
    "Qmc2JRqfGbPMMNHPAYVScGFu6iahuefGyfvVhotGvdiJT4",
    "Qmc5G9z5fPJ7EhSza9GA5b5Wdc48z1xN6LS5tpGnhGZMBn",
    "Qmc6BT5st167aMtJX4hM1CTRP3R9DKxgyZvpfB8xJfWnaD",
    "Qmc6VH8a3o9czPQsTyn9f5F12UbcwrZyh8y7svNX17m8Pe",
    "Qmc9NBKZwcGnNCYEaK4YtrQJdAgwN4Tmgj4yyyisgqjV77",
    "QmcBo4w7P85xdqocDjHna8xKUtPYDicbT9X2mZRpWUEq6p",
    "QmcF7erAGXUEtokiBU9fGNmzUHoD79ueXK1vn15vZYLe49",
    "QmcGzTiCfKvJAnW5D2P12XbvB8WjSNFDxZotwaZuLNb8ce",
    "QmcHDpRTB8YnKNJxKwUtQodm58EDmn1aqXYGii1BJYWVAY",
    "QmcJF3RQuys5G5afxnKwR9YLiwcPsec6sQ6VXhhbzawRGx",
    "QmcLkXzEcWLJ4R6rW3WM4KLZswY7JRWewx2dJxdJ19Xgvv",
    "QmcP8J9x9HChPDrcm8tx2FEAPxaJ8uCtCTMvexwjuSgHyj",
    "QmcWLQdFNhegtTE5xdXHRix5f8viNqsEzYTAS2nfFDboaQ",
    "QmcXwPxAuUYFuLNMcJ2grwrTiaE1ruxGN125QcHpzh8YMd",
    "QmcZrBqWBYV3RGsPuhQX11QzpKAQ8SYfMYL1dGXuPmaDYF",
    "QmcmTqKUdasx9xwbG2DcyY95q6GcMzx8uUC9fVqdTyETrZ",
    "QmcrX91uHjD8iaxMveHggUXBpiBUbxDxQrJGQ2N4ysi6wC",
    "QmcsYMi6jQb8dWeLkBD4kUHiC3XsJd8iEMG48EMkTCpUqo",
    "Qmctr2g81xXyF2Hi8BDHzfG19QPL184PKjRWbv6biMFfbg",
    "Qmd4up4kjr8TNWc4rx6r4bFwpe6TJQjVVmfwtiv4q3FSPx",
    "Qmd9HEzbwynye56RGkp7R111WUJP5fC4nXyycPsriXesch",
    "QmdBC7chfTZPR796n5PkhWaqxyou3SQd5ZTYRWRdeC4Wtd",
    "QmdDtVo8YqA2j9aggPCo9S6zPEW93WVTGRtYJATzVn6E94",
    "QmdJt1K9TE5hRDsedRcNXcC1RhU2zhiDwfDypxKyH4E6Us",
    "QmdKXzwTFU3c8imSq4SW3x8gFtTES7zJ8iM1nhvsNhnLKB",
    "QmdPoJBDcBm2m2kqdQiDt8ohhMBNfcD5e1pEgqR1ZRmHdq",
    "QmdPvRMQgYzMogpsF9DLd8YR1baJKGBcEnjTtXSAEnAR3w",
    "QmdRDG3kspGb4Gpi6rsUGshLsHuGbnxHLULBmt9y5RtH6b",
    "QmdRPxfc3CSUKda75APzQJ7HsbEAWyQBQvXKNMagYyWtTr",
    "QmdRbBXyC55mkzx3qNPpfek9AVMcC8MBL7NfprTN1S5rrm",
    "QmdUr1hNjhUAYTQo8tQfpfYCXNG4z5V6QLt9uoXjkWiKRJ",
    "QmdXVqepnR6ijiZKBL7QJXNeMhZ2wUY111MyFuZdk2WNae",
    "QmdXmFMZS934vrxT3c2hMstwvK9yizFwEiEwHA3YGLxaMt",
    "QmdYPXFAwXV4UNBdZgJE8672LA4rFAqQ8jVEMmwK7TLbpM",
    "QmdbgJfUwSNfYz7afm7Q5aXAtvQnezHgrC45PFhWfECFco",
    "Qmdcsu36sXAv8oVLQanBRn6ffqSCcxpFToBeiZHG1U5ws1",
    "Qmdf24YfetVeEekeTPcZaYghtViAUJUAQ6iSVL9UgU9YSw",
    "QmdfkQ1RzJAV6o6pjnB438fP6yUPmTr19MNLWfroecrPKT",
    "QmdhatZkb9KBupS1Hzv4cWsBrwnKEtSmBQqKphTvks91cf",
    "Qmdi8Yz9f5NdKoTXj8gBfHnFNqbtc8o1NoE12wMgWMwAQf",
    "Qmdo2W7TnGVLBzAUB8tJKDG8sd3Fi2CZjFhsTkekk5gevM",
    "QmdqWNxvJRS28ow1mK38P4PogcWKMDqc1dpsiQXp1qa1K3",
    "QmdqtJ8dcD5SZagvx1afgY9d6fTxmsd67V9MZUBwgH7zTv",
    "QmdtVoH1CP8iNarYDdzsSQum36qYSsyNr5gVbDWnPGootX",
    "QmdxtNRkqspKXWnNZh95sfK74PuKecLrG4wNKHwcjaYEv8",
    "Qme63idhHJ2awgkdG952iddw5Ta9nrfQB3Bpn83V1Bqgvv",
    "QmeBKMuNB5BrcZAUHTugjXPJRa19aYrmztVuc11EAXNxUi",
    "QmeDwUksWtdJcYM6fdue5abNM4ZuqCQZD3XWbFDaUYEfdw",
    "QmeFr81vNcUx8uE631jz4ofCt6MiCiaA48uvMcvvBUMuLX",
    "QmeM9rJsk6Ke57xMwMuCkJBb9pYGx7qVRkgzVD6zhxPaBx",
    "QmeMBmf5VvuSrFwhazsP8YmPLtqE4s5LxWGaoTWbfAM5s4",
    "QmeW92PaNQHJzFM1fJ97JmojmWvGCkyzp1VFj4RURcGZkv",
    "QmeWdgoZezpdHz1PX8Ly8AeDQahFkBNtHn6qKeNtWP1jB6",
    "Qmebkhi9TJLor6Y9qBFahKsebPmQLKSXn4Br7F6HHTU584",
    "QmecfcC2Hrq8UYQWaK6UABmbe4a41MQ8kbCngmCyBwqev8",
    "QmepgFW7BHEtU4pZJdxaNiv75mKLLRQnPi1KaaXmQN4V1a",
    "Qmeq1KSdYPTcehBeBtj2ZDUdakYqGkynAQNJj4zYXP1TyN",
    "QmesyEdiREsxUPn89gRTq3SLoMzKGdxcwS77cQhB1qS3pG",
    "QmeuhwdKxtAhWPE9m9yTBUDWaik8dg6orcmY37ScUxoqt7",
    "Qmf45NoQXq25AfKp7cZFTSjMF3WbDurVHf3BBk1ydj21R5",
    "Qmf7ypoPjzfSxjTJmvkX8yGBjtQtjC4kRDRa3UB48BVd73",
    "QmfDQdBxcDrm5QyZWHeze25BrDepWMJd2RqAUd3bEHgEZJ",
    "QmfDmdSUYQsrBAxdNhZMadS66F3xewbfY9vEy8T5mZqzAt",
    "QmfFgDQPC2maBf3LiB8bhPaHReW5YK4oJWoVfYXnriPTUW",
    "QmfJiKrxLsFdUioekkG6CES6Kjm7zUUqmkkAvk8x6ZRpwa",
    "QmfM9xyC83FGQodS99fdJYyLwsVm3KQf8FjzNiWU9Cijeu",
    "QmfMrzyS55EQNm5XddybdCEvDv4W5TuNCifAMoCsubzKnV"
  ],
  "BlocksReceived": 115,
  "DataReceived": 77179,
  "BlocksSent": 0,
  "DataSent": 0,
  "DupBlksReceived": 111,
  "DupDataReceived": 74507
}

'''
'''--- filesys-api/src/response/tests/v0_block_stat_0.json ---
{
  "Key": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB",
  "Size": 1102
}

'''
'''--- filesys-api/src/response/tests/v0_bootstrap_list_0.json ---
{
  "Peers": [
    "/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
    "/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z",
    "/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm",
    "/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd",
    "/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3",
    "/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx",
    "/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z",
    "/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm",
    "/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd",
    "/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3",
    "/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_commands_0.json ---
{
  "Name": "ipfs",
  "Subcommands": [
    {
      "Name": "diag",
      "Subcommands": [
        {
          "Name": "sys",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "cmds",
          "Subcommands": [
            {
              "Name": "set-time",
              "Subcommands": [],
              "Options": []
            },
            {
              "Name": "clear",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "name",
      "Subcommands": [
        {
          "Name": "publish",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "resolve"
              ]
            },
            {
              "Names": [
                "lifetime",
                "t"
              ]
            },
            {
              "Names": [
                "ttl"
              ]
            },
            {
              "Names": [
                "key",
                "k"
              ]
            }
          ]
        },
        {
          "Name": "resolve",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "recursive",
                "r"
              ]
            },
            {
              "Names": [
                "nocache",
                "n"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "bitswap",
      "Subcommands": [
        {
          "Name": "ledger",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "wantlist",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "peer",
                "p"
              ]
            }
          ]
        },
        {
          "Name": "stat",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "unwant",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "shutdown",
      "Subcommands": [],
      "Options": []
    },
    {
      "Name": "block",
      "Subcommands": [
        {
          "Name": "stat",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "get",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "put",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "format",
                "f"
              ]
            },
            {
              "Names": [
                "mhtype"
              ]
            },
            {
              "Names": [
                "mhlen"
              ]
            }
          ]
        },
        {
          "Name": "rm",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "force",
                "f"
              ]
            },
            {
              "Names": [
                "quiet",
                "q"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "config",
      "Subcommands": [
        {
          "Name": "show",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "edit",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "replace",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": [
        {
          "Names": [
            "bool"
          ]
        },
        {
          "Names": [
            "json"
          ]
        }
      ]
    },
    {
      "Name": "dht",
      "Subcommands": [
        {
          "Name": "query",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        },
        {
          "Name": "findprovs",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            },
            {
              "Names": [
                "num-providers",
                "n"
              ]
            }
          ]
        },
        {
          "Name": "findpeer",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        },
        {
          "Name": "get",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        },
        {
          "Name": "put",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        },
        {
          "Name": "provide",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            },
            {
              "Names": [
                "recursive",
                "r"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "dns",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "recursive",
            "r"
          ]
        }
      ]
    },
    {
      "Name": "p2p",
      "Subcommands": [
        {
          "Name": "stream",
          "Subcommands": [
            {
              "Name": "ls",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "headers",
                    "v"
                  ]
                }
              ]
            },
            {
              "Name": "dial",
              "Subcommands": [],
              "Options": []
            },
            {
              "Name": "close",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "all",
                    "a"
                  ]
                }
              ]
            }
          ],
          "Options": []
        },
        {
          "Name": "listener",
          "Subcommands": [
            {
              "Name": "close",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "all",
                    "a"
                  ]
                }
              ]
            },
            {
              "Name": "ls",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "headers",
                    "v"
                  ]
                }
              ]
            },
            {
              "Name": "open",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "version",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "number",
            "n"
          ]
        },
        {
          "Names": [
            "commit"
          ]
        },
        {
          "Names": [
            "repo"
          ]
        },
        {
          "Names": [
            "all"
          ]
        }
      ]
    },
    {
      "Name": "add",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "recursive",
            "r"
          ]
        },
        {
          "Names": [
            "quiet",
            "q"
          ]
        },
        {
          "Names": [
            "quieter",
            "Q"
          ]
        },
        {
          "Names": [
            "silent"
          ]
        },
        {
          "Names": [
            "progress",
            "p"
          ]
        },
        {
          "Names": [
            "trickle",
            "t"
          ]
        },
        {
          "Names": [
            "only-hash",
            "n"
          ]
        },
        {
          "Names": [
            "wrap-with-directory",
            "w"
          ]
        },
        {
          "Names": [
            "hidden",
            "H"
          ]
        },
        {
          "Names": [
            "chunker",
            "s"
          ]
        },
        {
          "Names": [
            "pin"
          ]
        },
        {
          "Names": [
            "raw-leaves"
          ]
        },
        {
          "Names": [
            "nocopy"
          ]
        },
        {
          "Names": [
            "fscache"
          ]
        },
        {
          "Names": [
            "cid-version"
          ]
        },
        {
          "Names": [
            "hash"
          ]
        }
      ]
    },
    {
      "Name": "object",
      "Subcommands": [
        {
          "Name": "patch",
          "Subcommands": [
            {
              "Name": "append-data",
              "Subcommands": [],
              "Options": []
            },
            {
              "Name": "add-link",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "create",
                    "p"
                  ]
                }
              ]
            },
            {
              "Name": "rm-link",
              "Subcommands": [],
              "Options": []
            },
            {
              "Name": "set-data",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": []
        },
        {
          "Name": "data",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "get",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "new",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "put",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "inputenc"
              ]
            },
            {
              "Names": [
                "datafieldenc"
              ]
            }
          ]
        },
        {
          "Name": "stat",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "diff",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            }
          ]
        },
        {
          "Name": "links",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "headers",
                "v"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "repo",
      "Subcommands": [
        {
          "Name": "gc",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "quiet",
                "q"
              ]
            },
            {
              "Names": [
                "stream-errors"
              ]
            }
          ]
        },
        {
          "Name": "stat",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "human"
              ]
            }
          ]
        },
        {
          "Name": "fsck",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "version",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "quiet",
                "q"
              ]
            }
          ]
        },
        {
          "Name": "verify",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "stats",
      "Subcommands": [
        {
          "Name": "bw",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "peer",
                "p"
              ]
            },
            {
              "Names": [
                "proto",
                "t"
              ]
            },
            {
              "Names": [
                "poll"
              ]
            },
            {
              "Names": [
                "interval",
                "i"
              ]
            }
          ]
        },
        {
          "Name": "repo",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "human"
              ]
            }
          ]
        },
        {
          "Name": "bitswap",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "file",
      "Subcommands": [
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "tar",
      "Subcommands": [
        {
          "Name": "add",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "cat",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "cat",
      "Subcommands": [],
      "Options": []
    },
    {
      "Name": "key",
      "Subcommands": [
        {
          "Name": "rm",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "l"
              ]
            }
          ]
        },
        {
          "Name": "gen",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "type",
                "t"
              ]
            },
            {
              "Names": [
                "size",
                "s"
              ]
            }
          ]
        },
        {
          "Name": "list",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "l"
              ]
            }
          ]
        },
        {
          "Name": "rename",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "force",
                "f"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "mount",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "ipfs-path",
            "f"
          ]
        },
        {
          "Names": [
            "ipns-path",
            "n"
          ]
        }
      ]
    },
    {
      "Name": "pin",
      "Subcommands": [
        {
          "Name": "add",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "recursive",
                "r"
              ]
            },
            {
              "Names": [
                "progress"
              ]
            }
          ]
        },
        {
          "Name": "rm",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "recursive",
                "r"
              ]
            }
          ]
        },
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "type",
                "t"
              ]
            },
            {
              "Names": [
                "quiet",
                "q"
              ]
            }
          ]
        },
        {
          "Name": "verify",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose"
              ]
            },
            {
              "Names": [
                "quiet",
                "q"
              ]
            }
          ]
        },
        {
          "Name": "update",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "unpin"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "tour",
      "Subcommands": [
        {
          "Name": "list",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "next",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "restart",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "refs",
      "Subcommands": [
        {
          "Name": "local",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": [
        {
          "Names": [
            "format"
          ]
        },
        {
          "Names": [
            "edges",
            "e"
          ]
        },
        {
          "Names": [
            "unique",
            "u"
          ]
        },
        {
          "Names": [
            "recursive",
            "r"
          ]
        }
      ]
    },
    {
      "Name": "resolve",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "recursive",
            "r"
          ]
        }
      ]
    },
    {
      "Name": "swarm",
      "Subcommands": [
        {
          "Name": "peers",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "verbose",
                "v"
              ]
            },
            {
              "Names": [
                "streams"
              ]
            },
            {
              "Names": [
                "latency"
              ]
            }
          ]
        },
        {
          "Name": "addrs",
          "Subcommands": [
            {
              "Name": "local",
              "Subcommands": [],
              "Options": [
                {
                  "Names": [
                    "id"
                  ]
                }
              ]
            }
          ],
          "Options": []
        },
        {
          "Name": "connect",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "disconnect",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "filters",
          "Subcommands": [
            {
              "Name": "rm",
              "Subcommands": [],
              "Options": []
            },
            {
              "Name": "add",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "commands",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "flags",
            "f"
          ]
        }
      ]
    },
    {
      "Name": "dag",
      "Subcommands": [
        {
          "Name": "put",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "format",
                "f"
              ]
            },
            {
              "Names": [
                "input-enc"
              ]
            }
          ]
        },
        {
          "Name": "get",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "files",
      "Subcommands": [
        {
          "Name": "mv",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "l"
              ]
            }
          ]
        },
        {
          "Name": "stat",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "format"
              ]
            },
            {
              "Names": [
                "hash"
              ]
            },
            {
              "Names": [
                "size"
              ]
            }
          ]
        },
        {
          "Name": "flush",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "read",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "offset",
                "o"
              ]
            },
            {
              "Names": [
                "count",
                "n"
              ]
            }
          ]
        },
        {
          "Name": "write",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "offset",
                "o"
              ]
            },
            {
              "Names": [
                "create",
                "e"
              ]
            },
            {
              "Names": [
                "truncate",
                "t"
              ]
            },
            {
              "Names": [
                "count",
                "n"
              ]
            }
          ]
        },
        {
          "Name": "cp",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "mkdir",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "parents",
                "p"
              ]
            }
          ]
        },
        {
          "Name": "rm",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "recursive",
                "r"
              ]
            }
          ]
        }
      ],
      "Options": [
        {
          "Names": [
            "f",
            "flush"
          ]
        }
      ]
    },
    {
      "Name": "id",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "format",
            "f"
          ]
        }
      ]
    },
    {
      "Name": "pubsub",
      "Subcommands": [
        {
          "Name": "sub",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "discover"
              ]
            }
          ]
        },
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "peers",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "pub",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "update",
      "Subcommands": [],
      "Options": []
    },
    {
      "Name": "filestore",
      "Subcommands": [
        {
          "Name": "dups",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "file-order"
              ]
            }
          ]
        },
        {
          "Name": "verify",
          "Subcommands": [],
          "Options": [
            {
              "Names": [
                "file-order"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "bootstrap",
      "Subcommands": [
        {
          "Name": "list",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "add",
          "Subcommands": [
            {
              "Name": "default",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": [
            {
              "Names": [
                "default"
              ]
            }
          ]
        },
        {
          "Name": "rm",
          "Subcommands": [
            {
              "Name": "all",
              "Subcommands": [],
              "Options": []
            }
          ],
          "Options": [
            {
              "Names": [
                "all"
              ]
            }
          ]
        }
      ],
      "Options": []
    },
    {
      "Name": "get",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "output",
            "o"
          ]
        },
        {
          "Names": [
            "archive",
            "a"
          ]
        },
        {
          "Names": [
            "compress",
            "C"
          ]
        },
        {
          "Names": [
            "compression-level",
            "l"
          ]
        }
      ]
    },
    {
      "Name": "log",
      "Subcommands": [
        {
          "Name": "level",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "ls",
          "Subcommands": [],
          "Options": []
        },
        {
          "Name": "tail",
          "Subcommands": [],
          "Options": []
        }
      ],
      "Options": []
    },
    {
      "Name": "ls",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "headers",
            "v"
          ]
        },
        {
          "Names": [
            "resolve-type"
          ]
        }
      ]
    },
    {
      "Name": "ping",
      "Subcommands": [],
      "Options": [
        {
          "Names": [
            "count",
            "n"
          ]
        }
      ]
    }
  ],
  "Options": [
    {
      "Names": [
        "config",
        "c"
      ]
    },
    {
      "Names": [
        "debug",
        "D"
      ]
    },
    {
      "Names": [
        "help"
      ]
    },
    {
      "Names": [
        "h"
      ]
    },
    {
      "Names": [
        "local",
        "L"
      ]
    },
    {
      "Names": [
        "api"
      ]
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_dag_get_0.json ---
{
  "data": null,
  "links": [
    {
      "Name": "yellow-pearl.pdf",
      "Size": 93263014,
      "Cid": {
        "/": "QmfDTYvLJ55nPN5WF9QQNbvfBy6c688eUakzXcwBPfT5cp"
      }
    },
    {
      "Name": "yoojin-grace-wuertz-mother-tongue.pdf",
      "Size": 207474,
      "Cid": {
        "/": "QmciFb6GbdL9rzMV7TA6wcxuytHA8rWT7bHNVBW7aMiokn"
      }
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_file_ls_0.json ---
{
  "Arguments": {
    "/ipfs/QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG": "QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG"
  },
  "Objects": {
    "QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG": {
      "Hash": "QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG",
      "Size": 0,
      "Type": "Directory",
      "Links": [
        {
          "Name": "about",
          "Hash": "QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V",
          "Size": 1677,
          "Type": "File"
        },
        {
          "Name": "contact",
          "Hash": "QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y",
          "Size": 189,
          "Type": "File"
        },
        {
          "Name": "help",
          "Hash": "QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7",
          "Size": 311,
          "Type": "File"
        },
        {
          "Name": "quick-start",
          "Hash": "QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha",
          "Size": 1717,
          "Type": "File"
        },
        {
          "Name": "readme",
          "Hash": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB",
          "Size": 1091,
          "Type": "File"
        },
        {
          "Name": "security-notes",
          "Hash": "QmTumTjvcYCAvRRwQ8sDRxh8ezmrcr88YFU7iYNroGGTBZ",
          "Size": 1016,
          "Type": "File"
        }
      ]
    }
  }
}

'''
'''--- filesys-api/src/response/tests/v0_file_ls_1.json ---
{
  "Arguments": null,
  "Objects": null
}

'''
'''--- filesys-api/src/response/tests/v0_files_ls_0.json ---
{
  "Entries": null
}

'''
'''--- filesys-api/src/response/tests/v0_files_stat_0.json ---
{
  "Hash": "QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn",
  "Size": 0,
  "CumulativeSize": 4,
  "Blocks": 0,
  "Type": "directory"
}

'''
'''--- filesys-api/src/response/tests/v0_id_0.json ---
{
  "ID": "QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
  "PublicKey": "CAASpgQwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCh9cDnwNXlVq/A6EVm+MVldzrbVI3cIZypaIYToAlsLf0GmATISWhUW5yd8Z3RMcyECLd4Hffd+vIIpCqCFSPOA5VRZKYtyra9EN0m+FB1F1Z8oSjwCgVthja5VJ3bWcpydih3XJC9kdYlGtvf02v2ignDv+aeGxWH6PMaS1WvyAlee29mgxZfnA7wrRsi2Lc3Se4CqkZWbNX3qf9usQmf42s2Or1OEpMQim1HOjSed6yhXkmyD/5htCIus6Y06Egdcaf9zuqIogRPpc7d4d7jFOJ4gLxxPKV4gUaE6F4NIc/0DiPDQfE+4aBkUvKEZkmZhilz5R1pK1eM2bfeideGrWuuvPjfw0PbjtpDShWSlZGRfFK/FnQTWRSdDnCSvJGZKPHVsly0iw+Qp6BbDrKa3KmT+JPG+xN6U6XEcKijCbV0u0/YCHm959zCN+ryzpoXuRkwMt+ZyL9VGYdWHuJkoJcw+QKWEFcWJeDQ4eKn+QRppqSA7QjPm0w68FZ7/pq/RwB52Mx9fyLvyDWY+GyeBnjK954imamcR8jQV+fzuK9AGFyN1JmhwWfDWNerg69lgZRM4Li2vSz+S/gMjJ5/Yf6UgW33nhKuXoLFiPiUuG/VmdpZEvh1TeKiPy0VKYRaVXCnLY2FNzJbld08adnKMLgYbCAXDRCVW32iFoIscwIDAQAB",
  "Addresses": [
    "/ip4/104.131.131.82/tcp/4001"
  ],
  "AgentVersion": "go-ipfs/0.4.11-rc1/",
  "ProtocolVersion": "ipfs/0.1.0"
}

'''
'''--- filesys-api/src/response/tests/v0_key_gen_0.json ---
{
  "Name": "test2",
  "Id": "QmXyKWg9HzHer8YKyBVs7iwQbMnxTDMQxPFZCJVfhgW2gF"
}

'''
'''--- filesys-api/src/response/tests/v0_key_list_0.json ---
{
  "Keys": [
    {
      "Name": "self",
      "Id": "QmSf2fesXJ9t7Vz91t5Ryhb6NmyXiZ6y9nddCeRgauKCCz"
    },
    {
      "Name": "test",
      "Id": "QmXnVxhRRiQ5UTb6vkeTcP2AKA2NetyYsNksnp46or6gAT"
    },
    {
      "Name": "test2",
      "Id": "QmXyKWg9HzHer8YKyBVs7iwQbMnxTDMQxPFZCJVfhgW2gF"
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_key_rename_0.json ---
{
  "Was":"test0",
  "Now":"test",
  "Id":"QmPLabRUDjgGUmLTQwbBzbFtRGH3jaC33jbHKBtyQ7TfrC",
  "Overwrite":false
}

'''
'''--- filesys-api/src/response/tests/v0_key_rm_0.json ---
{
  "Keys": [
    {
      "Name":"test",
      "Id":"QmPLabRUDjgGUmLTQwbBzbFtRGH3jaC33jbHKBtyQ7TfrC"
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_log_ls_0.json ---
{
  "Strings": [
    "engine",
    "bitswap_network",
    "commands/cli",
    "relay",
    "core/server",
    "tcp-tpt",
    "lock",
    "fsrepo",
    "transport",
    "secio",
    "conn",
    "pin",
    "ping",
    "gc",
    "routing/record",
    "core",
    "coreunix",
    "metrics-prometheus",
    "reuseport-poll",
    "blockservice",
    "mdns",
    "floodsub",
    "net/identify",
    "basichost",
    "filestore",
    "mfs",
    "ipns-repub",
    "multiplex",
    "providers",
    "peerqueue",
    "commands/http",
    "mocknet",
    "bitswap",
    "ipfsaddr",
    "chunk",
    "table",
    "peer",
    "mockrouter",
    "addrutil",
    "node",
    "corerepo",
    "plugin/loader",
    "path",
    "routedhost",
    "reprovider",
    "dht",
    "command",
    "fuse/ipfs",
    "supernode/proxy",
    "cmd/ipfs",
    "eventlog",
    "fuse/ipns",
    "cmds/files",
    "tarfmt",
    "nat",
    "bstestnet",
    "mount",
    "namesys",
    "peerstore",
    "connmgr",
    "boguskey",
    "dht.pb",
    "flatfs",
    "blockstore",
    "swarm2",
    "core/commands",
    "supernode"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_ls_0.json ---
{
  "Objects": [
    {
      "Hash": "/ipns/ipfs.io/",
      "Links": [
        {
          "Name": "author",
          "Hash": "QmRouqeAuSRHuAhgksVGyj5bHwoaGCeHvrucvZHjLycRge",
          "Size": 59289,
          "Type": 1
        },
        {
          "Name": "contact-ipfs",
          "Hash": "QmSbkzhqyXfLvKtgRppMc7FVJC3m7tbchrqXtYeSh54jBe",
          "Size": 5847,
          "Type": 1
        },
        {
          "Name": "css",
          "Hash": "QmRNaib6Pz2PUVLpEbMkEdETu5cup77Dtkief58o4NRPaM",
          "Size": 42684,
          "Type": 1
        },
        {
          "Name": "docs",
          "Hash": "QmTG4WSv8bL4JMqbeYmzGGo8k75zx73Cz3uzLnGMV6oLmE",
          "Size": 254520,
          "Type": 1
        },
        {
          "Name": "fonts",
          "Hash": "QmX7GQcyrVaKnS24y6nvU4LEB9hkcK5TkxoxRBaGFUUD6Q",
          "Size": 914365,
          "Type": 1
        },
        {
          "Name": "images",
          "Hash": "QmZMWv34NMLbhBxWysqViFdiMkGf4WtfXc5GQDnV8NWo5J",
          "Size": 1509477,
          "Type": 1
        },
        {
          "Name": "index.html",
          "Hash": "QmbsAqjLSQJ76TCAB6YwBpktTdUP3B9adkU4XtSsTuHpSs",
          "Size": 17226,
          "Type": 2
        },
        {
          "Name": "js",
          "Hash": "QmbbctxCiwug9dYiRgbi1kdJGxht7wELYtgx2Lh7LjtpLK",
          "Size": 753757,
          "Type": 1
        },
        {
          "Name": "legal",
          "Hash": "QmSvqDBPaEk6CSAU1sZW4ve2Vgmb9FdM2BvVKvNsChLnbt",
          "Size": 5759,
          "Type": 1
        },
        {
          "Name": "media",
          "Hash": "QmZfLAvPwPasDwAH5bC7nChwjSGYGkabZGV4YLfCn8LKwT",
          "Size": 12890,
          "Type": 1
        },
        {
          "Name": "sitemap.xml",
          "Hash": "QmYBpz8u7FhtwzyeMMq2Qj4PMpPA5e8WTLgUmTrCvNGWoy",
          "Size": 4667,
          "Type": 2
        }
      ]
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_ls_1.json ---
{
  "Objects": [
    {
      "Hash": "/ipfs/QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG",
      "Links": [
        {
          "Name": "about",
          "Hash": "QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V",
          "Size": 1688,
          "Type": 2
        },
        {
          "Name": "contact",
          "Hash": "QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y",
          "Size": 200,
          "Type": 2
        },
        {
          "Name": "help",
          "Hash": "QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7",
          "Size": 322,
          "Type": 2
        },
        {
          "Name": "quick-start",
          "Hash": "QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha",
          "Size": 1728,
          "Type": 2
        },
        {
          "Name": "readme",
          "Hash": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB",
          "Size": 1102,
          "Type": 2
        },
        {
          "Name": "security-notes",
          "Hash": "QmTumTjvcYCAvRRwQ8sDRxh8ezmrcr88YFU7iYNroGGTBZ",
          "Size": 1027,
          "Type": 2
        }
      ]
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_mount_0.json ---
{
  "IPFS": "/home/ftseng/.ipfsmnt/ipfs",
  "IPNS": "/home/ftseng/.ipfsmnt/ipns",
  "FuseAllowOther": false
}

'''
'''--- filesys-api/src/response/tests/v0_name_resolve_0.json ---
{
  "Path": "/ipfs/QmeqJJqSyNKt6d9SFRR1Rec6MNGJX6hdfnhUi2Bphec79Y"
}

'''
'''--- filesys-api/src/response/tests/v0_object_diff_0.json ---
{
  "Changes": [
    {
      "Type": 2,
      "Path": "",
      "Before": {
        "/": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB"
      },
      "After": {
        "/": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB"
      }
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_object_links_0.json ---
{
  "Hash": "QmVLDAhCY3X9P2uRudKAryuQFPM5zqA3Yij1dY8FpGbL7T",
  "Links": [
    {
      "Name": "about",
      "Hash": "QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V",
      "Size": 1688
    },
    {
      "Name": "contact",
      "Hash": "QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y",
      "Size": 200
    },
    {
      "Name": "help",
      "Hash": "QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7",
      "Size": 322
    },
    {
      "Name": "ping",
      "Hash": "QmejvEPop4D7YUadeGqYWmZxHhLc4JBUCzJJHWMzdcMe2y",
      "Size": 12
    },
    {
      "Name": "quick-start",
      "Hash": "QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha",
      "Size": 1728
    },
    {
      "Name": "readme",
      "Hash": "QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB",
      "Size": 1102
    },
    {
      "Name": "security-notes",
      "Hash": "QmQ5vhrL7uv6tuoN9KeVBwd4PwfQkXdVVmDLUZuTNxqgvm",
      "Size": 1173
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_object_stat_0.json ---
{
  "Hash": "QmVLDAhCY3X9P2uRudKAryuQFPM5zqA3Yij1dY8FpGbL7T",
  "NumLinks": 7,
  "BlockSize": 355,
  "LinksSize": 353,
  "DataSize": 2,
  "CumulativeSize": 6580
}

'''
'''--- filesys-api/src/response/tests/v0_pin_add_0.json ---
{
  "Pins": [
    "QmQ5vhrL7uv6tuoN9KeVBwd4PwfQkXdVVmDLUZuTNxqgvm"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_pin_ls_0.json ---
{
  "Keys": {
    "QmQ5vhrL7uv6tuoN9KeVBwd4PwfQkXdVVmDLUZuTNxqgvm": {
      "Type": "indirect through QmVLDAhCY3X9P2uRudKAryuQFPM5zqA3Yij1dY8FpGbL7T"
    }
  }
}

'''
'''--- filesys-api/src/response/tests/v0_ping_0.json ---
{
  "Success": true,
  "Time": 0,
  "Text": "PING QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ."
}

'''
'''--- filesys-api/src/response/tests/v0_ping_1.json ---
{
  "Success": true,
  "Time": 81228717,
  "Text": ""
}

'''
'''--- filesys-api/src/response/tests/v0_ping_2.json ---
{
  "Success": true,
  "Time": 0,
  "Text": "Average latency: 88.31ms"
}

'''
'''--- filesys-api/src/response/tests/v0_pubsub_ls_0.json ---
{
  "Strings": null
}

'''
'''--- filesys-api/src/response/tests/v0_pubsub_ls_1.json ---
{
  "Strings": [
    "foo"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_pubsub_peers_0.json ---
{"Strings":["QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z","QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64","QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm","QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd"]}

'''
'''--- filesys-api/src/response/tests/v0_pubsub_sub_0.json ---
{
  "from": "EiBAJAepdoWzxaYQ96XXlU8D8ulsjX7sMHIUUwe7qrmNsw==",
  "data": "SGVsbG8h",
  "seqno": "FOukwQ2f9C8=",
  "topicIDs": [
    "foo"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_pubsub_sub_1.json ---
{}

'''
'''--- filesys-api/src/response/tests/v0_refs_local_0.json ---
{
  "Ref": "QmSvqDBPaEk6CSAU1sZW4ve2Vgmb9FdM2BvVKvNsChLnbt",
  "Err": ""
}

'''
'''--- filesys-api/src/response/tests/v0_repo_gc_0.json ---
{
  "Key": {
    "/": "QmSvqDBPaEk6CSAU1sZW4ve2Vgmb9FdM2BvVKvNsChLnbt"
  }
}

'''
'''--- filesys-api/src/response/tests/v0_repo_stat_0.json ---
{"NumObjects":13,"RepoSize":27387827,"RepoPath":"/home/ftseng/.ipfs","Version":"fs-repo@6","StorageMax":10000000000}

'''
'''--- filesys-api/src/response/tests/v0_repo_verify_0.json ---
{
  "Message": "",
  "Progress": 1
}

'''
'''--- filesys-api/src/response/tests/v0_repo_verify_1.json ---
{
  "Message": "verify complete, all blocks validated.",
  "Progress": 0
}

'''
'''--- filesys-api/src/response/tests/v0_repo_version_0.json ---
{
  "Version": "6"
}

'''
'''--- filesys-api/src/response/tests/v0_resolve_0.json ---
{
  "Path": "/ipfs/QmZfLAvPwPasDwAH5bC7nChwjSGYGkabZGV4YLfCn8LKwT"
}

'''
'''--- filesys-api/src/response/tests/v0_stats_bw_0.json ---
{
  "TotalIn": 13869129,
  "TotalOut": 8120401,
  "RateIn": 191.88670148419368,
  "RateOut": 13.787621471639223
}

'''
'''--- filesys-api/src/response/tests/v0_swarm_addrs_local_0.json ---
{
  "Strings": [
    "/ip4/127.0.0.1/tcp/4001",
    "/ip4/192.168.1.185/tcp/4001",
    "/ip4/98.115.121.45/tcp/4001",
    "/ip6/::1/tcp/4001"
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_swarm_peers_0.json ---
{
  "Peers": [
    {
      "Addr": "/ip4/104.236.151.122/tcp/4001",
      "Peer": "QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/104.236.76.40/tcp/4001",
      "Peer": "QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/146.185.156.246/tcp/4001",
      "Peer": "QmdxtNRkqspKXWnNZh95sfK74PuKecLrG4wNKHwcjaYEv8",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/162.243.248.213/tcp/4001",
      "Peer": "QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/178.62.61.185/tcp/4001",
      "Peer": "QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/188.40.114.11/tcp/4001",
      "Peer": "QmZY7MtK8ZbG1suwrxc7xEYZ2hQLf1dAWPRHhjxC8rjq8E",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/192.241.220.29/tcp/4001",
      "Peer": "QmYbAMm8nFi6Rhm5ciwT4vZGKM4v4Kf9pUtTuoDmCcJAkU",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/194.254.61.213/tcp/4001",
      "Peer": "QmXtyRJmYkpKM3vJ5dWj7JpPKBHHUZS4aWGX9RFeg4v8WQ",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/31.172.137.10/tcp/13727",
      "Peer": "QmYLNAbh1PmttVgYRnjbKZM7ukwqquMquejFN9D5mzaTQa",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/43.229.62.238/tcp/4001",
      "Peer": "QmRCCsK6Zkd8PjMGD8MyoM14j76sTDonHRM6uv6NBg27hF",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/81.4.120.158/tcp/4001",
      "Peer": "QmQ9W8XbGf7bocnDMPXaQGTrKC8hjUL1Sh2vrhTYGqoo9Y",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/98.214.191.195/tcp/60389",
      "Peer": "QmNU6sCSZ88ukfCV5dBWvgjjrerki7DQdvtnpFCG7oEmg5",
      "Latency": "",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_swarm_peers_1.json ---
{
  "Peers": [
    {
      "Addr": "/ip4/35.167.26.28/tcp/4001",
      "Peer": "QmNRuQrwtGgeVQgndTny4A4Rukg7GR7vzDJrVJxUBfqevk",
      "Latency": "393.975341ms",
      "Muxer": "*sm_yamux.conn",
      "Streams": [
        {
          "Protocol": ""
        },
        {
          "Protocol": "/ipfs/bitswap"
        }
      ]
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_swarm_peers_2.json ---
{
  "Peers": [
    {
      "Addr": "/ip4/104.131.131.82/tcp/4001",
      "Peer": "QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
      "Latency": "821.60077ms",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/104.236.151.122/tcp/4001",
      "Peer": "QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx",
      "Latency": "205.432977ms",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/178.62.61.185/tcp/4001",
      "Peer": "QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3",
      "Latency": "1.744576368s",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    },
    {
      "Addr": "/ip4/35.167.26.28/tcp/4001",
      "Peer": "QmNRuQrwtGgeVQgndTny4A4Rukg7GR7vzDJrVJxUBfqevk",
      "Latency": "393.975341ms",
      "Muxer": "*sm_yamux.conn",
      "Streams": null
    }
  ]
}

'''
'''--- filesys-api/src/response/tests/v0_tar_add_0.json ---
{
  "Name": "test.tar",
  "Hash": "QmSJ3UjnffgzAc5Fnnw4tojjhk6mhkV77eoxMYJZ5DWZ98",
  "Size": "3083"
}

'''
'''--- filesys-api/src/response/tests/v0_version_0.json ---
{
  "Version": "0.4.11",
  "Commit": "",
  "Repo": "6",
  "System": "amd64/linux",
  "Golang": "go1.9"
}

'''
'''--- filesys-api/src/response/version.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[derive(Debug, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct VersionResponse {
    pub version: String,
    pub commit: String,
    pub repo: String,
    pub system: String,
    pub golang: String,
}

#[cfg(test)]
mod tests {
    deserialize_test!(v0_version_0, VersionResponse);
}

'''
'''--- filesys-cli/Cargo.toml ---
[package]
name                      = "filesys-cli"
description               = "A CLI to interact with IPFS"
authors                   = ["Ferris Tseng <ferristseng@fastmail.fm>"]
repository                = "https://github.com/ferristseng/rust-ipfs-api"
version                   = "0.4.1"
readme                    = "../README.md"
license                   = "MIT OR Apache-2.0"

[dependencies]
clap                      = "2.32"
futures                   = "0.1"
hyper                     = "0.12"
filesys-api                  = { path = "../filesys-api" }

'''
'''--- filesys-cli/src/command/add.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::{CliCommand, EXPECTED_FILE};
use futures::Future;
use std::path::Path;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "add";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand add =>
                (about: "Add file to IPFS")
                (@arg INPUT: +required "File to add")
                (@arg recursive: -r --recursive "Add directory paths recursively. Default: false")
        )
    }

    handle!(
        (args, client) => {
            let path = args.value_of("INPUT").unwrap();
            if !args.is_present("recursive") && Path::new(path).is_dir() {
                panic!(EXPECTED_FILE);
            }
            client
                .add_path(path)
                .map(|response| {
                    println!();
                    println!("  name    : {}", response.name);
                    println!("  hash    : {}", response.hash);
                    println!("  size    : {}", response.size);
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/bitswap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "bitswap";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand bitswap =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand ledger =>
                    (about: "Show the current ledger for a peer")
                    (@arg PEER: +required "Peer to inspect")
                )
                (@subcommand reprovide =>
                    (about: "Triggers a reprovide")
                )
                (@subcommand stat =>
                    (about: "Show some diagnostic information on the bitswap agent")
                )
                (@subcommand unwant =>
                    (about: "Remove a given block from your wantlist")
                    (@arg KEY: +required "Key of the block to remove")
                )
                (@subcommand wantlist =>
                    (about: "Shows blocks currently on the wantlist")
                )
        )
    }

    handle!(
        client;
        ("ledger", args) => {
            let peer = args.value_of("PEER").unwrap();

            client
                .bitswap_ledger(peer)
                .map(|ledger| {
                    println!();
                    println!("  peer      : {}", ledger.peer);
                    println!("  value     : {}", ledger.value);
                    println!("  sent      : {}", ledger.sent);
                    println!("  recv      : {}", ledger.recv);
                    println!("  exchanged : {}", ledger.exchanged);
                    println!();
                })
        },
        ("reprovide", _args) => {
            client.bitswap_reprovide().map(|_| ())
        },
        ("stat", _args) => {
            client
                .bitswap_stat()
                .map(|stat| {
                    println!();
                    println!("  provide_buf_len        : {}", stat.provide_buf_len);
                    println!("  wantlist               :");
                    for want in stat.wantlist {
                        println!("    {}", want);
                    }
                    println!("  peers                  :");
                    for peer in stat.peers {
                        println!("    {}", peer);
                    }
                    println!("  blocks_received        : {}", stat.blocks_received);
                    println!("  data_received          : {}", stat.data_received);
                    println!("  blocks_sent            : {}", stat.blocks_sent);
                    println!("  data_sent              : {}", stat.data_sent);
                    println!("  dup_blks_received      : {}", stat.dup_blks_received);
                    println!("  dup_data_received      : {}", stat.dup_data_received);
                    println!();
                })
        },
        ("unwant", args) => {
            let key = args.value_of("KEY").unwrap();

            client
                .bitswap_unwant(key)
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("wantlist", args) => {
            let peer = args.value_of("PEER");

            client
                .bitswap_wantlist(peer)
                .map(|wantlist| {
                    println!();
                    println!("  wantlist               :");
                    for key in wantlist.keys {
                        println!("    {}", key);
                    }
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/block.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::{verify_file, CliCommand, EXPECTED_FILE};
use futures::{Future, Stream};
use std::fs::File;
use std::io::{self, Write};

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "block";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand block =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand get =>
                    (about: "Get a raw IPFS block")
                    (@arg KEY: +required "The base58 multihash of an existing block")
                )
                (@subcommand put =>
                    (about: "Store a file as an IPFS block")
                    (@arg INPUT: +required {verify_file} "The file to store as an IPFS block")
                )
                (@subcommand rm =>
                    (about: "Removes an IPFS block")
                    (@arg KEY: +required "The base58 multihash of a block to remove")
                )
                (@subcommand stat =>
                    (about: "Get information about a raw IPFS block")
                    (@arg KEY: +required "The base58 multihash of the block to retrieve")
                )
        )
    }

    handle!(
        client;
        ("get", args) => {
            let key = args.value_of("KEY").unwrap();

            client
                .block_get(key)
                .for_each(|chunk| io::stdout().write_all(&chunk).map_err(From::from))
        },
        ("put", args) => {
            let path = args.value_of("INPUT").unwrap();
            let file = File::open(path).expect(EXPECTED_FILE);

            client
                .block_put(file)
                .map(|block| {
                    println!();
                    println!("  key     : {}", block.key);
                    println!("  size    : {}", block.size);
                    println!();
                })
        },
        ("rm", args) => {
            let key = args.value_of("KEY").unwrap();

            client
                .block_rm(key)
                .map(|rm| {
                    println!();
                    println!("  hash    : {}", rm.hash);
                    if let Some(error) = rm.error {
                        println!("  error   : {}", error);
                    }
                    println!();
                })
        },
        ("stat", args) => {
            let key = args.value_of("KEY").unwrap();

            client
                .block_stat(key)
                .map(|stat| {
                    println!();
                    println!("  key     : {}", stat.key);
                    println!("  size    : {}", stat.size);
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/bootstrap.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

fn print_peers(peers: &[String]) {
    println!();
    println!("  peers                  :");
    for peer in peers {
        println!("    {}", peer);
    }
    println!();
}

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "bootstrap";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand bootstrap =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand add =>
                    (@setting SubcommandRequiredElseHelp)
                    (@subcommand default =>
                        (about: "Add default peers to the bootstrap list")
                    )
                )
                (@subcommand list =>
                    (about: "Show peers in the bootstrap list")
                )
                (@subcommand rm =>
                    (@setting SubcommandRequiredElseHelp)
                    (@subcommand all =>
                        (about: "Remove all peers from the bootstrap list")
                    )
                )
        )
    }

    handle!(
        client;
        ("add") => {
            ("default", _args) => {
                client.bootstrap_add_default().map(|peers| print_peers(&peers.peers))
            }
        },
        ("list", _args) => {
            client.bootstrap_list().map(|peers| print_peers(&peers.peers))
        },
        ("rm") => {
            ("all", _args) => {
                client.bootstrap_rm_all().map(|peers| print_peers(&peers.peers))
            }
        }
    );
}

'''
'''--- filesys-cli/src/command/cat.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::{Future, Stream};
use std::io::{self, Write};

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "cat";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand cat =>
                (about: "Show IPFS object data")
                (@arg PATH: +required "The path of the IPFS object to get")
        )
    }

    handle!(
        (args, client) => {
            let path = args.value_of("PATH").unwrap();

            client
                .cat(&path)
                .for_each(|chunk| io::stdout().write_all(&chunk).map_err(From::from))
        }
    );
}

'''
'''--- filesys-cli/src/command/commands.rs ---
// Copyright 2017 rust-filesys-api Developers
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;
use filesys_api::response::CommandsResponse;

fn recursive_print_commands(cmd: CommandsResponse, stack: &mut Vec<String>) {
    if cmd.subcommands.is_empty() {
        println!("  {} {}", stack.join(" "), cmd.name);
    } else {
        let (name, subcommands) = (cmd.name, cmd.subcommands);

        stack.push(name);

        for subcommand in subcommands {
            recursive_print_commands(subcommand, stack);
        }

        stack.pop();
    }
}

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "commands";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand commands =>
                (about: "List all available commands")
        )
    }

    handle!(
        (_args, client) => {
            client.commands().map(|commands| {
                println!();
                recursive_print_commands(commands, &mut Vec::new());
                println!();
            })
        }
    );
}

'''
'''--- filesys-cli/src/command/config.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::{verify_file, CliCommand, EXPECTED_FILE};
use futures::Future;
use std::fs::File;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "config";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand config =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand edit =>
                    (about: "Open the config file for editing")
                )
                (@subcommand replace =>
                    (about: "Replace the config file")
                    (@arg INPUT: +required {verify_file} "Config file to replace with")
                )
                (@subcommand show =>
                    (about: "Show the config file")
                )
        )
    }

    handle!(
        client;
        ("edit", _args) => {
            client.config_edit().map(|_| ())
        },
        ("replace", args) => {
            let path = args.value_of("INPUT").unwrap();
            let config = File::open(path).expect(EXPECTED_FILE);

            client.config_replace(config).map(|_| ())
        },
        ("show", _args) => {
            client.config_show().map(|config| println!("{}", config))
        }
    );
}

'''
'''--- filesys-cli/src/command/dag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "dag";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand dag =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand get =>
                    (about: "Get a dag node from IPFS")
                    (@arg KEY: +required "The key of the object to get")
                )
        )
    }

    handle!(
        client;
        ("get", args) => {
            let key = args.value_of("KEY").unwrap();

            client.dag_get(key).map(|dag| {
                println!();
                if let Some(data) = dag.data {
                    println!("  data                   :");
                    println!("{}", data);
                }
                println!("  links                  :");
                for link in dag.links {
                    println!("    {} ({}) ({:?})", link.name, link.size, link.cid);
                }
                println!();
            })
        }
    );
}

'''
'''--- filesys-cli/src/command/dht.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::{Future, Stream};
use filesys_api::response::DhtMessage;

fn print_dht_response<E>(res: DhtMessage) -> Result<(), E> {
    println!();
    println!("  id                     : {}", res.id);
    println!("  type                   : {:?}", res.typ);
    println!("  responses              :");
    for peer_res in res.responses {
        println!("    id        : {}", peer_res.id);
        println!("    addrs     :");
        for addr in peer_res.addrs {
            println!("      {}", addr);
        }
        println!();
    }
    println!("  extra                  : {}", res.extra);
    println!();

    Ok(())
}

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "dht";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand dht =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand findpeer =>
                    (about: "Query the DHT for all of the multiaddresses associated with a Peer ID")
                    (@arg PEER: +required "Peer to search for")
                )
                (@subcommand findprovs =>
                    (about: "Find peers in the DHT that can provide the given key")
                    (@arg KEY: +required "Key to search for")
                )
                (@subcommand get =>
                    (about: "Given a key, query the DHT for its best value")
                    (@arg KEY: +required "The key search for")
                )
                (@subcommand provide =>
                    (about: "Announce to the network that you are providing the given values")
                    (@arg KEY: +required "The key you are providing")
                )
                (@subcommand put =>
                    (about: "Write a key/value pair to the DHT")
                    (@arg KEY: +required "The key to store the value at")
                    (@arg VALUE: +required "The value to store")
                )
                (@subcommand query =>
                    (about: "Find the closest peer to a given peer by querying the DHT")
                    (@arg PEER: +required "The peer to run the query against")
                )
        )
    }

    handle!(
        client;
        ("findpeer", args) => {
            let peer = args.value_of("PEER").unwrap();

            client.dht_findpeer(peer).for_each(print_dht_response)
        },
        ("findprovs", args) => {
            let key = args.value_of("KEY").unwrap();

            client.dht_findprovs(key).for_each(print_dht_response)
        },
        ("get", args) => {
            let key = args.value_of("KEY").unwrap();

            client.dht_get(key).for_each(print_dht_response)
        },
        ("provide", args) => {
            let key = args.value_of("KEY").unwrap();

            client.dht_provide(&key).for_each(print_dht_response)
        },
        ("put", args) => {
            let key = args.value_of("KEY").unwrap();
            let val = args.value_of("VALUE").unwrap();

            client.dht_put(key, val).for_each(print_dht_response)
        },
        ("query", args) => {
            let peer = args.value_of("PEER").unwrap();

            client.dht_query(peer).for_each(print_dht_response)
        }
    );
}

'''
'''--- filesys-cli/src/command/diag.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::{App, Arg, SubCommand};
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "diag";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        // The clap macro does not allow hyphenated command names,
        // so the `set-time` command has to be manually instantiated.
        //
        let set_time_command = SubCommand::with_name("set-time")
            .about("Set how long to keep inactive requests in the log")
            .arg(
                Arg::with_name("TIME")
                    .required(true)
                    .index(1)
                    .help("Time to keep inactive requests in the log"),
            );

        clap_app!(
            @subcommand diag =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand cmds =>
                    (@setting SubcommandRequiredElseHelp)
                    (@subcommand clear =>
                        (about: "Clear inactive requests from the log")
                    )
                    (subcommand: set_time_command)
                )
                (@subcommand sys =>
                    (about: "Print system diagnostic information")
                )
        )
    }

    handle!(
        client;
        ("cmds") => {
            ("clear", _args) => {
                client
                    .diag_cmds_clear()
                    .map(|_| {
                        println!("");
                        println!("  OK");
                        println!("");
                    })
            },
            ("set-time", args) => {
                let time = args.value_of("TIME").unwrap();

                client
                    .diag_cmds_set_time(&time)
                    .map(|_| {
                        println!("");
                        println!("  OK");
                        println!("");
                    })
            }
        },
        ("sys", _args) => {
            client
                .diag_sys()
                .map(|sys| {
                    println!();
                    println!("  {}", sys);
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/dns.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "dns";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand dns =>
                (about: "Resolve a DNS link")
                (@arg PATH: +required "The domain name to resolve")
                (@arg recursive: -r --recursive "Resolve until the result is not a DNS link")
        )
    }

    handle!(
        (args, client) => {
            let path = args.value_of("PATH").unwrap();

            client
                .dns(path, args.is_present("recursive"))
                .map(|res| {
                    println!();
                    println!("  path    : {}", res.path);
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/file.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "file";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand file =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand ls =>
                    (about: "List directory contents for Unix filesystem objects")
                    (@arg PATH: +required "The path to list links from")
                )
        )
    }

    handle!(
        client;
        ("ls", args) => {
            let path = args.value_of("PATH").unwrap();

            client
                .file_ls(path)
                .map(|ls| {
                    println!();
                    println!("  arguments              :");
                    for (k, arg) in ls.arguments {
                        println!("    arg        : {}", k);
                        println!("    value      : {}", arg);
                        println!();
                    }
                    println!("  objects                :");
                    for (k, obj) in ls.objects {
                        println!("    key        : {}", k);
                        println!("    hash       : {}", obj.hash);
                        println!("    size       : {}", obj.size);
                        println!("    type       : {}", obj.typ);
                        println!("    links      :");
                        for link in obj.links {
                            println!("      name       : {}", link.name);
                            println!("      hash       : {}", link.hash);
                            println!("      size       : {}", link.size);
                            if let Some(ref typ) = link.typ {
                                println!("      type       : {}", typ);
                            }
                            println!();
                        }
                    }
                    println!();
                })
        }
    );
}

'''
'''--- filesys-cli/src/command/files.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::{verify_file, CliCommand, EXPECTED_FILE};
use futures::{Future, Stream};
use std::fs::File;
use std::io::{self, Write};

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "files";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand files =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand cp =>
                    (about: "Copy files in MFS")
                    (@arg SRC: +required "The source object to copy")
                    (@arg DEST: +required "The destination to copy the object to")
                )
                (@subcommand flush =>
                    (about: "Flush a path's data to disk")
                    (@arg PATH: "The path to flush")
                )
                (@subcommand ls =>
                    (about: "List directories in MFS")
                    (@arg PATH: "The past to list")
                )
                (@subcommand mkdir =>
                    (about: "Make directories in MFS")
                    (@arg PATH: +required "The directory to create")
                    (@arg parents: -p --parents "Create parents if the directory \
                        does not already exist")
                )
                (@subcommand mv =>
                    (about: "Move files in MFS")
                    (@arg SRC: +required "The source object to move")
                    (@arg DEST: +required "The destination to move the object to")
                )
                (@subcommand read =>
                    (about: "Read a file in MFS")
                    (@arg PATH: +required "The path to read")
                )
                (@subcommand rm =>
                    (about: "Remove a file in MFS")
                    (@arg PATH: +required "The file to remove")
                    (@arg recursive: -r --recursive "Recursively remove directories")
                )
                (@subcommand stat =>
                    (about: "Display status for a file in MFS")
                    (@arg PATH: +required "The file to get status for")
                )
                (@subcommand write =>
                    (about: "Write a file to MFS")
                    (@arg DEST: +required "The path to write to")
                    (@arg INPUT: +required {verify_file} "The file to write")
                    (@arg create: --create "Create the file if it does not exist")
                    (@arg truncate: --truncate "Truncate the file before writing")
                )
        )
    }

    handle!(
        client;
        ("cp", args) => {
            let src = args.value_of("SRC").unwrap();
            let dest = args.value_of("DEST").unwrap();

            client
                .files_cp(src, dest)
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("flush", args) => {
            let path = args.value_of("PATH");

            client
                .files_flush(path)
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("ls", args) => {
            let path = args.value_of("PATH");

            client
                .files_ls(path)
                .map(|ls| {
                    println!();
                    println!("  entries                :");
                    for entry in ls.entries {
                        println!("    name       : {}", entry.name);
                        println!("    type       : {}", entry.typ);
                        println!("    size       : {}", entry.size);
                        println!("    hash       : {}", entry.hash);
                        println!();
                    }
                    println!();
                })
        },
        ("mkdir", args) => {
            let path = args.value_of("PATH").unwrap();

            client
                .files_mkdir(path, args.is_present("parents"))
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("mv", args) => {
            let src = args.value_of("SRC").unwrap();
            let dest = args.value_of("DEST").unwrap();

            client
                .files_mv(src, dest)
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("read", args) => {
            let path = args.value_of("PATH").unwrap();

            client
                .files_read(path)
                .for_each(|chunk| io::stdout().write_all(&chunk).map_err(From::from))
        },
        ("rm", args) => {
            let path = args.value_of("PATH").unwrap();

            client
                .files_rm(path, args.is_present("recursive"))
                .map(|_| {
                    println!();
                    println!("  OK");
                    println!();
                })
        },
        ("stat", args) => {
            let path = args.value_of("PATH").unwrap();
            client
                .files_stat(path)
                .map(|stat| {
                    println!();
                    println!("  hash                   : {}", stat.hash);
                    println!("  size                   : {}", stat.size);
                    println!("  cumulative_size        : {}", stat.cumulative_size);
                    println!("  blocks                 : {}", stat.blocks);
                    println!("  type                   : {}", stat.typ);
                    println!();
                })
        },
        ("write", args) => {
            let dest = args.value_of("DEST").unwrap();
            let path = args.value_of("INPUT").unwrap();
            let file = File::open(path).expect(EXPECTED_FILE);

            client.files_write(
                dest,
                args.is_present("create"),
                args.is_present("truncate"),
                file,
            ).map(|_| {
                println!();
                println!("  OK");
                println!();
            })
        }
    );
}

'''
'''--- filesys-cli/src/command/filestore.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::{Future, Stream};
use filesys_api::response::FilestoreObject;

fn print_filestore_object<E>(obj: FilestoreObject) -> Result<(), E> {
    println!("  status                 : {}", obj.status);
    println!("  error_msg              : {}", obj.error_msg);
    println!("  key                    : {}", obj.key);
    println!("  file_path              : {}", obj.file_path);
    println!("  offset                 : {}", obj.offset);
    println!("  size                   : {}", obj.size);
    println!();

    Ok(())
}

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "filestore";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand filestore =>
                (@setting SubcommandRequiredElseHelp)
                (@subcommand dups =>
                    (about: "List blocks that are both in the filestore and standard block storage")
                )
                (@subcommand ls =>
                    (about: "List objects in the filestore")
                    (@arg CID: "Cid of the object to list")
                )
                (@subcommand verify =>
                    (about: "Verify objects in the filestore")
                    (@arg CID: "Cid of the object to verify")
                )
        )
    }

    handle!(
        client;
        ("dups", _args) => {
            println!();

            client
                .filestore_dups()
                .for_each(|dup| {
                    println!("  ref     : {}", dup.reference);
                    println!("  err     : {}", dup.err);
                    println!();

                    Ok(())
                })
        },
        ("ls", args) => {
            let cid = args.value_of("CID");

            println!();

            client
                .filestore_ls(cid)
                .for_each(print_filestore_object)
        },
        ("verify", args) => {
            let cid = args.value_of("CID");

            println!();

            client
                .filestore_verify(cid)
                .for_each(print_filestore_object)
        }
    );
}

'''
'''--- filesys-cli/src/command/mod.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::{App, ArgMatches};
use futures::Future;
use filesys_api::FileSysClient;
use std::error::Error;
use std::fs;
use std::path::Path;

pub type CommandExecutable = Box<Future<Item = (), Error = ()> + 'static + Send>;

pub const EXPECTED_FILE: &str = "expected to read input file";

/// Verifies that a path points to a file that exists, and not a directory.
///
pub fn verify_file<P>(path: P) -> Result<(), String>
where
    P: AsRef<Path>,
{
    match fs::metadata(path) {
        Ok(ref metadata) if metadata.is_file() => Ok(()),
        Ok(_) => Err("file must not be a directory".into()),
        Err(e) => Err(e.description().into()),
    }
}

pub trait CliCommand {
    /// Name of the command.
    ///
    const NAME: &'static str;

    /// Returns the signature of the application.
    ///
    fn signature<'a, 'b>() -> App<'a, 'b>;

    /// Creates a future representing the request to make.
    ///
    fn handle(client: &FileSysClient, args: &ArgMatches) -> CommandExecutable;
}

macro_rules! handle_case {
    // Base macro case. Converts an expression into a boxed future.
    //
    ($run: expr) => {
        {
            let future = $run;

            return Box::new(future.map_err(|e| eprintln!("{}", e)))
        }
    };
    // Base case for nested subcommand (e.g. /bootstrap/add).
    //
    (
        $subcommand: ident;
        ($key: pat) => { $(($inner_key: pat, $args: ident) => $run: expr),* }
    ) => {
        if let ($key, Some(args)) = $subcommand {
            let inner_subcommand = args.subcommand();

            $(
                handle_case!(inner_subcommand; ($inner_key, $args) => $run);
            )*
        }
    };
    // Base case for subcommand.
    //
    (
        $subcommand: ident;
        ($key: pat, $args: pat) => $run: expr
    ) => {
        if let ($key, Some($args)) = $subcommand {
            handle_case!($run)
        }
    };
    // Recursive case for nested subcommand.
    //
    (
        $subcommand: ident;
        ($key: pat) => { $(($inner_key: pat, $args: ident) => $run: expr),* },
        $($rest_args: tt => $rest_run: tt),*
    ) => {
        handle_case!($subcommand; ($key) => { $(($inner_key, $args) => $run),* });

        $(
            handle_case!($subcommand; $rest_args => $rest_run);
        )*
    };
    // Recursive case fo subcommand.
    //
    (
        $subcommand: ident;
        ($key: pat, $args: pat) => $run: expr,
        $($rest_args: tt => $rest_run: tt),*
    ) => {
        handle_case!($subcommand; ($key, $args) => $run);

        $(
            handle_case!($subcommand; $rest_args => $rest_run);
        )*
    }
}

macro_rules! handle {
    // Command with no subcommands.
    //
    (
        ($args: ident, $client: ident) => $run: expr
    ) => {
        fn handle(
            client: &::filesys_api::FileSysClient,
            args: &::clap::ArgMatches,
        ) -> ::command::CommandExecutable {
            let $args = args;
            let $client = client;

            handle_case!($run)
        }
    };
    // Command with one or more subcommands.
    //
    (
        $client: ident;
        $($args: tt => $run: tt),*
    ) => {
        fn handle(
            client: &::filesys_api::FileSysClient,
            args: &::clap::ArgMatches,
        ) -> ::command::CommandExecutable {
            let $client = client;
            let subcommand = args.subcommand();

            handle_case!(subcommand; $($args => $run),*);

            unreachable!()
        }
    }
}

pub mod add;
pub mod bitswap;
pub mod block;
pub mod bootstrap;
pub mod cat;
pub mod commands;
pub mod config;
pub mod dag;
pub mod dht;
pub mod diag;
pub mod dns;
pub mod file;
pub mod files;
pub mod filestore;
pub mod shutdown;
pub mod version;

'''
'''--- filesys-cli/src/command/shutdown.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "shutdown";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand shutdown =>
                (about: "Shutdown IPFS daemon")
        )
    }

    handle!(
        (_args, client) => {
            client.shutdown().map(|_| ())
        }
    );
}

'''
'''--- filesys-cli/src/command/version.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

use clap::App;
use command::CliCommand;
use futures::Future;

pub struct Command;

impl CliCommand for Command {
    const NAME: &'static str = "version";

    fn signature<'a, 'b>() -> App<'a, 'b> {
        clap_app!(
            @subcommand version =>
                (about: "Show ipfs version information")
        )
    }

    handle!(
        (_args, client) => {
            client.version().map(|version| {
                println!();
                println!("  version : {}", version.version);
                println!("  commit  : {}", version.commit);
                println!("  repo    : {}", version.repo);
                println!("  system  : {}", version.system);
                println!("  golang  : {}", version.golang);
                println!();
            })
        }
    );
}

'''
'''--- filesys-cli/src/main.rs ---
// Copyright 2017 rust-filesys-api Developers
//
// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or
// http://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or
// http://opensource.org/licenses/MIT>, at your option. This file may not be
// copied, modified, or distributed except according to those terms.
//

#[macro_use]
extern crate clap;
extern crate futures;
extern crate hyper;
extern crate filesys_api;

use command::CliCommand;
use filesys_api::FileSysClient;

mod command;

macro_rules! main {
    ($($cmd:ident);*) => {
        fn main() {
            let matches = clap_app!(
                app =>
                    (name: "IPFS CLI")
                    (about: "CLI for Go IPFS")
                    (version: crate_version!())
                    (author: "Ferris T. <ferristseng@fastmail.fm>")
                    (@setting SubcommandRequiredElseHelp)
                    $((subcommand: <command::$cmd::Command>::signature()))*
            ).get_matches();

            let client = FileSysClient::default();
            let command = match matches.subcommand() {
                $(
                (<command::$cmd::Command>::NAME, Some(args)) => {
                    <command::$cmd::Command>::handle(&client, args)
                }
                )*
                _ => unreachable!(),
            };

            hyper::rt::run(command);
        }
    }
}

main!(
    add;
    bitswap; block; bootstrap;
    cat; commands; config;
    dag; dht; diag; dns;
    file; files; filestore;
    shutdown;
    version
);

'''
'''--- filesysmint/Cargo.toml ---
[package]
name = "filesysmint"
version = "0.1.0"
authors = ["filesys Inc <hello@filesys.com>"]
edition = "2018"

[dependencies]
abci = "0.4"
log = "0.4"
env_logger = "0.6"
protobuf = { version = "2.2.4", features = ["with-bytes"] }
base64 = "0.10.0"
serde_json = "1.0"
clap = "2.32"

primitives = { path = "../runtime/primitives" }
near-protos = { path = "../runtime/protos" }
storage = { path = "../runtime/storage" }
node-runtime = { path = "../runtime/runtime" }
verifier = { path = "../runtime/verifier" }
#ipfstools = { path = "../ipfstools"}

[dev-dependencies]
tempdir = "0.3"
reqwest = "0.9"
hex = "0.3"
serde = "1.0"
serde_derive = "1.0"

testlib = { path = "../test-utils/testlib" }

'''
'''--- filesysmint/README.md ---
# NEARMint

NEAR application layer running with Tendermint consensus.

## Installation

0. Install general development tools.

Ubuntu:

    sudo apt-get install binutils-dev libcurl4-openssl-dev zlib1g-dev libdw-dev libiberty-dev cmake gcc build-essential libssl-dev pkg-config protobuf-compiler

1. Follow instruction on Tendermint installation: https://tendermint.com/docs/introduction/install.html

2. Install rust

```
curl https://sh.rustup.rs -sSf | sh
```

3. Download this repo

    git clone https://github.com/nearprotocol/nearcore

## Configure

### Tendermint

    tendermint init

You can modify configuration of the node in `~/.tendermint/config/config.toml`.

Specifically, change RPC server to 3030 port:
```$toml
[rpc]
laddr = "tcp://0.0.0.0:3030"
```

## Running

Start in one console tendermint (from any location if it was installed, or from directory you put binary into):

    tendermint node
    
Note, that if you want to reset state of tendermint that has already ran, use `tendermint unsafe_reset_all`.

In the second console:

    cargo run --package nearmint
    
Note, that if you want to reset state of nearmint that has already ran, use `rm -rf storage`.
    
## Running local cluster

Note, this is done way easier on Ubuntu and we will be working on simplifying it for Mac OS.

Link `tendermint` binary to target/release folder

    ln -s 

We use docker compose to spin up 4 node local cluster:

    cargo run --release --package nearmint
    cd ops/local
    docker-compose up

## Development

To run single validator mode (e.g. DevNet mode), you can set Tendermint validator key to `alice.near` key in `~/.tendermint/config/priv_validator_key.json`:

```json
{
  "address": "27B2B6C138DDF7B77E4318A22CAE1A38F55AA29A",
  "pub_key": {
    "type": "tendermint/PubKeyEd25519",
    "value": "D1al8CjfwInsfDnBGDsyG02Pibpb7J4XYoA8wkkfbvg="
  },
  "priv_key": {
    "type": "tendermint/PrivKeyEd25519",
    "value": "YWxpY2UubmVhciAgICAgICAgICAgICAgICAgICAgICAPVqXwKN/Aiex8OcEYOzIbTY+JulvsnhdigDzCSR9u+A=="
  }
}
```

And then when running `nearmint` use `--devnet` flag, e.g. `cargo run --package nearmint -- --devnet` or `target/release/nearmint --devnet`.
    
## Interacting

Use JSONRPC to send transaction:

    http post localhost:26657 method=broadcast_tx_commit jsonrpc=2.0 id=dontcare tx=0x<hex bytes of transaction>

See full list of JSONRPC

    http get localhost:26657

'''
'''--- filesysmint/src/lib.rs ---
use std::collections::HashMap;
use std::convert::TryFrom;
use std::convert::TryInto;
use std::fs;
use std::path::Path;
use std::sync::RwLock;
use std::sync::{Arc, Mutex};

use abci::*;
use log::{error, info};
use protobuf::parse_from_bytes;

use node_runtime::adapter::{query_client, RuntimeAdapter};
use node_runtime::chain_spec::ChainSpec;
use node_runtime::ethereum::EthashProvider;
use node_runtime::state_viewer::{AccountViewCallResult, TrieViewer};
use node_runtime::{ApplyState, Runtime, ETHASH_CACHE_PATH};
use primitives::crypto::signature::PublicKey;
use primitives::traits::ToBytes;
use primitives::transaction::{SignedTransaction, TransactionStatus};
use primitives::types::{AccountId, AuthorityStake, MerkleHash};
use primitives::utils::prefix_for_access_key;
use storage::test_utils::create_beacon_shard_storages;
use storage::{create_storage, GenericStorage, ShardChainStorage, Trie, TrieUpdate};
use verifier::TransactionVerifier;

const POISONED_LOCK_ERR: &str = "The lock was poisoned.";
const STORAGE_PATH: &str = "storage";

/// Connector of NEAR Core with Tendermint.
pub struct FileSysMint {
    chain_spec: ChainSpec,
    runtime: Runtime,
    pub trie: Arc<Trie>,
    trie_viewer: TrieViewer,
    storage: Arc<RwLock<ShardChainStorage>>,
    pub root: MerkleHash,
    state_update: Option<TrieUpdate>,
    apply_state: Option<ApplyState>,
    authority_proposals: Vec<AuthorityStake>,
    pub height: u64,
}

fn get_storage_path(base_path: &Path) -> String {
    let mut storage_path = base_path.to_owned();
    storage_path.push(STORAGE_PATH);
    match fs::canonicalize(storage_path.clone()) {
        Ok(path) => info!("Opening storage database at {:?}", path),
        _ => info!("Could not resolve {:?} path", storage_path),
    };
    storage_path.to_str().unwrap().to_owned()
}

impl FileSysMint {
    pub fn new_from_storage(
        base_path: &Path,
        storage: Arc<RwLock<ShardChainStorage>>,
        chain_spec: ChainSpec,
    ) -> Self {
        let trie = Arc::new(Trie::new(storage.clone()));
        let mut ethash_path = base_path.to_owned();
        ethash_path.push(ETHASH_CACHE_PATH);
        let ethash_provider = Arc::new(Mutex::new(EthashProvider::new(ethash_path.as_path())));
        let runtime = Runtime::new(ethash_provider.clone());
        let trie_viewer = TrieViewer::new(ethash_provider);

        // Compute genesis from current spec.
        let state_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        let (genesis_root, db_changes) = runtime.apply_genesis_state(
            state_update,
            &chain_spec.accounts,
            &chain_spec.genesis_wasm,
            &chain_spec.initial_authorities,
        );

        storage
            .write()
            .expect(POISONED_LOCK_ERR)
            .blockchain_storage_mut()
            .set_genesis_hash(genesis_root)
            .expect("Failed to set genesis hash");

        let maybe_best_hash = storage
            .write()
            .expect(POISONED_LOCK_ERR)
            .blockchain_storage_mut()
            .best_block_hash()
            .map(Option::<&_>::cloned);
        let (root, height) = if let Ok(Some(best_hash)) = maybe_best_hash {
            (
                best_hash,
                storage
                    .write()
                    .expect(POISONED_LOCK_ERR)
                    .blockchain_storage_mut()
                    .best_block_index()
                    .unwrap()
                    .unwrap(),
            )
        } else {
            // Apply genesis.
            trie.apply_changes(db_changes).expect("Failed to commit genesis state");
            (genesis_root, 0)
        };

        FileSysMint {
            chain_spec,
            runtime,
            trie,
            trie_viewer,
            storage,
            root,
            apply_state: None,
            state_update: None,
            authority_proposals: Vec::default(),
            height,
        }
    }

    pub fn new(base_path: &Path, chain_spec: ChainSpec) -> Self {
        let (_, mut storage) = create_storage(&get_storage_path(base_path), 1);
        let storage = storage.pop().unwrap();

        Self::new_from_storage(base_path, storage, chain_spec)
    }

    /// In memory instance of filesysmint used for test
    pub fn new_for_test(chain_spec: ChainSpec) -> Self {
        let (_, storage) = create_beacon_shard_storages();
        Self::new_from_storage(Path::new("test"), storage, chain_spec)
    }
}

fn convert_tx(data: &[u8]) -> Result<SignedTransaction, String> {
    parse_from_bytes::<near_protos::signed_transaction::SignedTransaction>(&data)
        .map_err(|e| format!("Protobuf error: {}", e))
        .and_then(TryInto::try_into)
}

impl RuntimeAdapter for FileSysMint {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        let state_update = TrieUpdate::new(self.trie.clone(), self.root);
        self.trie_viewer.view_account(&state_update, account_id)
    }

    fn call_function(
        &self,
        contract_id: &AccountId,
        method_name: &str,
        args: &[u8],
        logs: &mut Vec<String>,
    ) -> Result<Vec<u8>, String> {
        let state_update = TrieUpdate::new(self.trie.clone(), self.root);
        self.trie_viewer.call_function(
            state_update,
            self.height,
            contract_id,
            method_name,
            args,
            logs,
        )
    }

    fn view_access_key(&self, account_id: &String) -> Result<Vec<PublicKey>, String> {
        let state_update = TrieUpdate::new(self.trie.clone(), self.root);
        let prefix = prefix_for_access_key(account_id);
        match state_update.iter(&prefix) {
            Ok(iter) => iter
                .map(|key| {
                    let public_key = &key[prefix.len()..];
                    PublicKey::try_from(public_key).map_err(|e| format!("{}", e))
                })
                .collect::<Result<Vec<_>, String>>(),
            Err(e) => Err(e),
        }
    }
}

impl Application for FileSysMint {
    fn info(&mut self, req: &RequestInfo) -> ResponseInfo {
        info!("Info: {:?}", req);
        let mut resp = ResponseInfo::new();
        if self.height > 0 {
            resp.set_last_block_app_hash(self.root.as_ref().to_vec());
            resp.set_last_block_height(self.height as i64);
        }
        resp
    }

    fn query(&mut self, req: &RequestQuery) -> ResponseQuery {
        let mut resp = ResponseQuery::new();
        match query_client(self, &req.path, &req.data, req.height as u64, req.prove) {
            Ok(response) => {
                resp.key = response.key;
                resp.value = response.value;
                resp.log = response.log;
                resp.code = response.code;
                resp.height = response.height;
                resp.info = response.info;
                resp.index = response.index;
            }
            Err(e) => {
                resp.code = 1;
                resp.log = e;
            }
        }
        resp
    }

    fn check_tx(&mut self, req: &RequestCheckTx) -> ResponseCheckTx {
        let mut resp = ResponseCheckTx::new();
        match convert_tx(&req.tx) {
            Ok(tx) => {
                info!("Check tx: {:?}", tx);
                let state_update = TrieUpdate::new(self.trie.clone(), self.root);
                let verifier = TransactionVerifier::new(&state_update);
                if let Err(e) = verifier.verify_transaction(&tx) {
                    error!("Failed check tx: {:?}, error: {}", req.tx, e);
                    resp.code = 1;
                }
            }
            Err(err) => {
                info!("Failed check tx: {:?}, error: {:?}", req.tx, err);
                resp.code = 1;
            }
        };
        resp
    }

    fn init_chain(&mut self, req: &RequestInitChain) -> ResponseInitChain {
        info!("Init chain: {:?}", req);
        let mut resp = ResponseInitChain::new();
        for (_, public_key, _, amount) in self.chain_spec.initial_authorities.iter() {
            let mut validator = ValidatorUpdate::new();
            let mut pub_key = PubKey::new();
            pub_key.set_field_type("ed25519".to_string());
            pub_key.data = PublicKey::try_from(public_key.0.as_str())
                .expect("Failed to parse public key in chain spec")
                .to_bytes();
            validator.set_pub_key(pub_key);
            validator.power = *amount as i64;
            resp.validators.push(validator);
        }
        resp
    }

    fn begin_block(&mut self, req: &RequestBeginBlock) -> ResponseBeginBlock {
        info!("Begin block: {:?}", req);
        self.apply_state = Some(ApplyState {
            root: self.root,
            shard_id: 0,
            block_index: req.header.clone().unwrap().height as u64,
            parent_block_hash: self.root,
        });
        self.state_update = Some(TrieUpdate::new(self.trie.clone(), self.root));
        ResponseBeginBlock::new()
    }

    fn deliver_tx(&mut self, p: &RequestDeliverTx) -> ResponseDeliverTx {
        let mut resp = ResponseDeliverTx::new();
        if let Ok(tx) = convert_tx(&p.tx) {
            if let (Some(state_update), Some(apply_state)) =
                (&mut self.state_update, &self.apply_state)
            {
                let mut incoming_receipts = HashMap::default();
                let tx_result = Runtime::process_transaction(
                    &self.runtime,
                    state_update,
                    apply_state.block_index,
                    &tx,
                    &mut incoming_receipts,
                    &mut self.authority_proposals,
                );
                let mut logs = tx_result.logs;
                if let Some(result) = tx_result.result {
                    resp.data = result;
                }
                if tx_result.status != TransactionStatus::Completed {
                    resp.code = 2;
                } else {
                    let mut receipts = incoming_receipts.remove(&0).unwrap_or_else(|| vec![]);
                    while !receipts.is_empty() {
                        let mut new_receipts = HashMap::default();
                        for receipt in receipts.iter() {
                            let receipt_result = Runtime::process_receipt(
                                &mut self.runtime,
                                state_update,
                                0,
                                apply_state.block_index,
                                receipt,
                                &mut new_receipts,
                            );
                            logs.extend(receipt_result.logs);
                            if receipt_result.status != TransactionStatus::Completed {
                                resp.code = 1;
                            }
                            if let Some(result) = receipt_result.result {
                                resp.data = result;
                            }
                        }
                        receipts = new_receipts.remove(&0).unwrap_or_else(|| vec![]);
                    }
                }
                resp.log = logs.join("\n");
            }
        } else {
            resp.code = 1;
        }
        resp
    }

    fn end_block(&mut self, req: &RequestEndBlock) -> ResponseEndBlock {
        info!("End block: {:?}", req);
        self.height = req.height as u64;
        ResponseEndBlock::new()
    }

    fn commit(&mut self, req: &RequestCommit) -> ResponseCommit {
        let mut resp = ResponseCommit::new();
        if let Some(state_update) = self.state_update.take() {
            info!("Commit: {:?}", req);
            let (new_root, db_changes) = state_update.finalize();
            self.trie.apply_changes(db_changes).expect("Failed to commit to database");
            if let Some(apply_state) = &self.apply_state {
                let mut guard = self.storage.write().expect(POISONED_LOCK_ERR);
                guard
                    .blockchain_storage_mut()
                    .set_best_block_index(apply_state.block_index)
                    .expect("FAILED");
                guard.blockchain_storage_mut().set_best_block_hash(new_root).expect("FAILED");
            }
            self.state_update = None;
            self.apply_state = None;
            self.root = new_root;
        }
        resp.data = self.root.as_ref().to_vec();
        resp
    }
}

#[cfg(test)]
mod tests {
    use protobuf::Message;

    use node_runtime::adapter::RuntimeAdapter;
    use node_runtime::chain_spec::{ChainSpec, TESTING_INIT_BALANCE};
    use primitives::crypto::signer::InMemorySigner;
    use primitives::hash::CryptoHash;
    use primitives::transaction::TransactionBody;
    use primitives::types::StructSignature;

    use super::*;

    #[test]
    fn test_apply_block() {
        let chain_spec = ChainSpec::default_devnet();
        let mut filesysmint = FileSysMint::new_for_test(chain_spec);
        let req_init = RequestInitChain::new();
        let resp_init = filesysmint.init_chain(&req_init);
        assert_eq!(resp_init.validators.len(), 1);
        let mut req_begin_block = RequestBeginBlock::new();
        let mut h = Header::new();
        h.height = 1;
        let mut last_block_id = BlockID::new();
        last_block_id.hash = CryptoHash::default().as_ref().to_vec();
        h.set_last_block_id(last_block_id);
        req_begin_block.set_header(h);
        filesysmint.begin_block(&req_begin_block);
        let signer = InMemorySigner::from_seed("alice.near", "alice.near");
        // Send large enough amount of money so that we can simultaneously check whether they were
        // debited and whether the rent was applied too.
        let money_to_send = 1_000_000;
        let tx: near_protos::signed_transaction::SignedTransaction =
            TransactionBody::send_money(1, "alice.near", "bob.near", money_to_send)
                .sign(&signer)
                .into();
        let mut deliver_req = RequestDeliverTx::new();
        deliver_req.tx = tx.write_to_bytes().unwrap();
        let deliver_resp = filesysmint.deliver_tx(&deliver_req);
        assert_eq!(deliver_resp.log, "");
        assert_eq!(deliver_resp.code, 0);
        let mut req_end_block = RequestEndBlock::new();
        req_end_block.height = 1;
        filesysmint.end_block(&req_end_block);
        let req_commit = RequestCommit::new();
        filesysmint.commit(&req_commit);

        let alice_info = filesysmint.view_account(&"alice.near".to_string()).unwrap();
        // Should be strictly less, because the rent was applied too.
        assert!(alice_info.amount < TESTING_INIT_BALANCE - money_to_send);
        let bob_info = filesysmint.view_account(&"bob.near".to_string()).unwrap();
        // The balance was applied but the rent was not subtracted because we have not performed
        // interactions from that account.
        assert_eq!(bob_info.amount, TESTING_INIT_BALANCE + money_to_send);
        assert_eq!(filesysmint.height, 1);

        let mut req_query = RequestQuery::new();
        req_query.path = "account/alice.near".to_string();
        let resp_query = filesysmint.query(&req_query);
        assert_eq!(resp_query.code, 0);
        let resp: AccountViewCallResult = serde_json::from_slice(&resp_query.value).unwrap();
        assert_eq!(resp.amount, alice_info.amount);
    }

    #[test]
    fn test_invalid_transaction() {
        let chain_spec = ChainSpec::default_devnet();
        let mut filesysmint = FileSysMint::new_for_test(chain_spec);
        let fake_signature = StructSignature::try_from(&[0u8; 64] as &[u8]).unwrap();
        let body = TransactionBody::send_money(1, "alice.near", "bob.near", 10);
        let invalid_tx: near_protos::signed_transaction::SignedTransaction =
            SignedTransaction::new(fake_signature, body, None).into();
        let mut req_tx = RequestCheckTx::new();
        req_tx.set_tx(invalid_tx.write_to_bytes().unwrap());
        let resp_tx = filesysmint.check_tx(&req_tx);
        assert_eq!(resp_tx.code, 1);
    }
}

'''
'''--- filesysmint/src/main.rs ---
use clap::{App, Arg};
use env_logger::Builder;
use std::path::PathBuf;

use filesysmint::FileSysMint;
use node_runtime::chain_spec::ChainSpec;

const DEFAULT_BASE_PATH: &str = "";
//
const DEFAULT_FILE_LOG: &str = "info";
const DEFAULT_FILE_PATH: &str = ".filesys";
const DEFAULT_XDG_APP_NAME: &str = ".filesys";
const DEFAULT_CONFIG_FILE: &str = "config.json";

fn main() {
    // Parse command line arguments.
    let matches = App::new("Filesysmint")
        .args(&[
            Arg::with_name("base_path")
                .short("d")
                .long("base-path")
                .value_name("PATH")
                .help("Specify a base path for persisted files.")
                .default_value(DEFAULT_BASE_PATH)
                .takes_value(true),
            Arg::with_name("chain_spec_file")
                .short("c")
                .long("chain-spec-file")
                .value_name("CHAIN_SPEC")
                .help("Specify a file location to read a custom chain spec.")
                .takes_value(true),
            Arg::with_name("devnet")
                .long("devnet")
                .help("Run with DevNet validator configuration (single alice.near validator)")
                .takes_value(false),
            Arg::with_name("abci_address")
                .short("a")
                .long("abci-address")
                .value_name("ABCI_Address")
                .help("Specify ip address and port for Tendermint ABCI")
                .default_value("127.0.0.1:26658")
                .takes_value(true),
            Arg::with_name("file_path")
                .short("f")
                .long("file_path")
                .value_name("FILE_PATH")
                .help("Set the repo directory, defaults to ~/.filesys/repo")
                .default_value(DEFAULT_FILE_PATH)
                .takes_value(true),
        ])
        .get_matches();
    let base_path = matches.value_of("base_path").map(PathBuf::from).unwrap();
    let chain_spec = if matches.is_present("devnet") {
        ChainSpec::default_devnet()
    } else {
        let chain_spec_path = matches.value_of("chain_spec_file").map(PathBuf::from);
        ChainSpec::from_file_or_default(&chain_spec_path, ChainSpec::default_poa())
    };
    let addr = matches.value_of("abci_address").map(|address| address.parse().unwrap()).unwrap();
    let file_path = matches.value_of("file_path").map(PathBuf::from).unwrap();

    // Setup logging.
    let mut builder = Builder::from_default_env();
    builder.default_format_timestamp_nanos(true);
    builder.filter(None, log::LevelFilter::Info);
    builder.try_init().unwrap();

    // Fire it up!
    abci::run(addr, FileSysMint::new(&base_path, chain_spec));
}

'''
'''--- filesysmint/tests/test.rs ---
use node_runtime::state_viewer::AccountViewCallResult;
use primitives::crypto::signature::PublicKey;
use primitives::rpc::JsonRpcResponse;
use protobuf::Message;
use std::process::{Child, Command};
use std::thread;
use std::time::Duration;
use testlib::test_helpers::wait;

/// Test node that contains the subprocesses of tendermint and filesysmint.
/// Used for shutting down the processes gracefully.
struct TestNode {
    tendermint: Child,
    nearmint: Child,
    storage_path: String,
}

impl TestNode {
    fn kill(&mut self) {
        self.tendermint.kill().expect("fail to kill tendermint node");
        self.nearmint.kill().expect("fail to kill filesysmint");
    }
}

impl Drop for TestNode {
    fn drop(&mut self) {
        self.kill();
        Command::new("tendermint")
            .arg("unsafe_reset_all")
            .output()
            .expect("fail to reset tendermint");
        Command::new("rm")
            .args(&["-rf", &self.storage_path])
            .output()
            .expect("fail to delete test storage");
    }
}

fn start_nearmint(path: &str) -> TestNode {
    let tendermint = Command::new("tendermint")
        .args(&["node", "--rpc.laddr", "tcp://0.0.0.0:3030"])
        .spawn()
        .expect("fail to spawn tendermint");
    let nearmint = Command::new("cargo")
        .args(&["run", "--package", "filesysmint", "--", "--base-path", path, "--devnet"])
        .spawn()
        .expect("fail to spawn filesysmint");
    wait(
        || {
            let client = reqwest::Client::new();
            let response = client.post("http://127.0.0.1:3030/health").send();
            response.is_ok()
        },
        1000,
        60000,
    );
    thread::sleep(Duration::from_secs(5));
    TestNode { tendermint, nearmint, storage_path: path.to_string() }
}

fn view_account_request(account_id: &str) -> Option<AccountViewCallResult> {
    let client = reqwest::Client::new();
    let mut response = client
        .post("http://127.0.0.1:3030/abci_query")
        .form(&[("path", format!("\"account/{}\"", account_id))])
        .send()
        .unwrap();
    let response: JsonRpcResponse = response.json().expect("cannot decode response");
    response
        .result
        .unwrap()
        .as_object()
        .and_then(|m| m.get("response"))
        .unwrap()
        .as_object()
        .and_then(|m| m.get("value"))
        .and_then(|v| {
            let bytes = base64::decode(v.as_str().unwrap()).unwrap();
            serde_json::from_str::<AccountViewCallResult>(std::str::from_utf8(&bytes).unwrap()).ok()
        })
}

fn view_access_key_request(account_id: &str) -> Option<Vec<PublicKey>> {
    let client = reqwest::Client::new();
    let mut response = client
        .post("http://127.0.0.1:3030/abci_query")
        .form(&[("path", format!("\"access_key/{}\"", account_id))])
        .send()
        .unwrap();
    let response: JsonRpcResponse = response.json().expect("cannot decode response");
    response
        .result
        .unwrap()
        .as_object()
        .and_then(|m| m.get("response"))
        .unwrap()
        .as_object()
        .and_then(|m| m.get("value"))
        .and_then(|v| {
            let bytes = base64::decode(v.as_str().unwrap()).unwrap();
            serde_json::from_str::<Vec<PublicKey>>(std::str::from_utf8(&bytes).unwrap()).ok()
        })
}

fn submit_tx(tx: near_protos::signed_transaction::SignedTransaction) -> JsonRpcResponse {
    let client = reqwest::Client::new();
    let tx_bytes = tx.write_to_bytes().expect("write to bytes failed");
    let mut response = client
        .post("http://127.0.0.1:3030/broadcast_tx_commit")
        .form(&[("tx", format!("0x{}", hex::encode(&tx_bytes)))])
        .send()
        .unwrap();
    let response: JsonRpcResponse = response.json().expect("cannot decode response");
    response
}

#[cfg(test)]
mod test {
    use super::*;
    use node_runtime::chain_spec::TESTING_INIT_BALANCE;
    use primitives::account::AccessKey;
    use primitives::crypto::signer::InMemorySigner;
    use primitives::hash::hash;
    use primitives::transaction::{
        AddKeyTransaction, CreateAccountTransaction, DeployContractTransaction, TransactionBody,
    };
    use testlib::test_helpers::heavy_test;

    #[test]
    fn test_send_tx() {
        heavy_test(|| {
            let storage_path = "tmp/test_send_tx";
            let _test_node = start_nearmint(storage_path);
            let signer = InMemorySigner::from_seed("alice.near", "alice.near");
            let money_to_send = 1_000_000;
            let tx: near_protos::signed_transaction::SignedTransaction =
                TransactionBody::send_money(1, "alice.near", "bob.near", money_to_send)
                    .sign(&signer)
                    .into();
            submit_tx(tx);

            let alice_account = view_account_request("alice.near").unwrap();
            assert!(alice_account.amount < TESTING_INIT_BALANCE - money_to_send);
            let bob_account = view_account_request("bob.near").unwrap();
            assert_eq!(bob_account.amount, TESTING_INIT_BALANCE + money_to_send);
        });
    }

    #[test]
    fn test_create_account() {
        heavy_test(|| {
            let storage_path = "tmp/test_create_account";
            let _test_node = start_nearmint(storage_path);
            let signer = InMemorySigner::from_seed("alice.near", "alice.near");
            let money_to_send = 1_000_000;
            let tx: near_protos::signed_transaction::SignedTransaction =
                TransactionBody::CreateAccount(CreateAccountTransaction {
                    nonce: 1,
                    originator: "alice.near".to_string(),
                    new_account_id: "test.near".to_string(),
                    amount: money_to_send,
                    public_key: signer.public_key.0[..].to_vec(),
                })
                .sign(&signer)
                .into();
            submit_tx(tx);

            let alice_account = view_account_request("alice.near").unwrap();
            assert!(alice_account.amount < TESTING_INIT_BALANCE - money_to_send);
            let eve_account = view_account_request("test.near").unwrap();
            assert_eq!(eve_account.amount, money_to_send);
        });
    }

    #[test]
    fn test_deploy_contract() {
        heavy_test(|| {
            let storage_path = "tmp/test_create_account";
            let _test_node = start_nearmint(storage_path);
            let signer = InMemorySigner::from_seed("alice.near", "alice.near");
            let money_to_send = 1_000_000;
            let tx: near_protos::signed_transaction::SignedTransaction =
                TransactionBody::CreateAccount(CreateAccountTransaction {
                    nonce: 1,
                    originator: "alice.near".to_string(),
                    new_account_id: "test.near".to_string(),
                    amount: money_to_send,
                    public_key: signer.public_key.0[..].to_vec(),
                })
                .sign(&signer)
                .into();
            submit_tx(tx);

            let wasm_binary: &[u8] = include_bytes!("../../tests/hello.wasm");
            let tx: near_protos::signed_transaction::SignedTransaction =
                TransactionBody::DeployContract(DeployContractTransaction {
                    nonce: 1,
                    contract_id: "test.near".to_string(),
                    wasm_byte_array: wasm_binary.to_vec(),
                })
                .sign(&signer)
                .into();
            submit_tx(tx);
            let eve_account = view_account_request("test.near").unwrap();
            assert!(eve_account.amount > 0);
            assert!(eve_account.amount < money_to_send);
            assert_eq!(eve_account.code_hash, hash(wasm_binary));
        });
    }

    #[test]
    fn test_view_access_key() {
        heavy_test(|| {
            let storage_path = "tmp/test_view_acccess_key";
            let _test_node = start_nearmint(storage_path);
            let signer = InMemorySigner::from_seed("alice.near", "alice.near");
            let signer1 = InMemorySigner::from_seed("alice.near", "test");
            let access_key =
                AccessKey { amount: 10, balance_owner: None, contract_id: None, method_name: None };
            let tx: near_protos::signed_transaction::SignedTransaction =
                TransactionBody::AddKey(AddKeyTransaction {
                    nonce: 1,
                    originator: "alice.near".to_string(),
                    new_key: signer1.public_key.0[..].to_vec(),
                    access_key: Some(access_key),
                })
                .sign(&signer)
                .into();
            submit_tx(tx);
            let keys = view_access_key_request("alice.near").unwrap();
            assert_eq!(keys, vec![signer1.public_key]);
        });
    }
}

'''
'''--- filesysmint/tools/bench/__init__.py ---

'''
'''--- filesysmint/tools/bench/b58.py ---
import binascii

alphabet = b'123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'

def _b58encode_int(i):
    string = b''
    while i:
        i, idx = divmod(i, 58)
        string = alphabet[idx:idx + 1] + string
    return string

def b58encode(v):
    """
    :param v: bytes object or integer list representation of bytes
    :return: base58 encoded bytes
    """
    p, acc = 1, 0
    for c in reversed(list(bytearray(v))):
        acc += p * c
        p = p << 8

    result = _b58encode_int(acc)

    return result

def b58decode(s):
    if not s:
        return b''

    # Convert the string to an integer
    n = 0
    for char in s.encode('utf-8'):
        n *= 58
        if char not in alphabet:
            msg = "Character {} is not a valid base58 character".format(char)
            raise Exception(msg)

        digit = alphabet.index(char)
        n += digit

    # Convert the integer to bytes
    h = '%x' % n
    if len(h) % 2:
        h = '0' + h
    res = binascii.unhexlify(h.encode('utf8'))

    # Add padding back.
    pad = 0
    for c in s[:-1]:
        if c == alphabet[0]:
            pad += 1
        else:
            break

    return b'\x00' * pad + res

'''
'''--- filesysmint/tools/bench/key_store.py ---
import json
import os

import ed25519

import b58

class AmbiguousPublicKey(Exception):
    def __init__(self):
        msg = 'public key must be specified if there is more ' \
              'than one key in the key store'
        super(AmbiguousPublicKey, self).__init__(msg)

class NoKeyPairs(Exception):
    pass

class KeyStore(object):
    @staticmethod
    def _create_key_pair(seed=None):
        if seed is not None:
            if len(seed) > 32:
                raise Exception('max seed length is 32')

            seed = seed.encode('utf-8')

        kwargs = {}
        if seed is not None:
            kwargs['entropy'] = lambda x: seed.ljust(32)

        return ed25519.create_keypair(**kwargs)

    def create_key_pair(self, seed=None):
        raise NotImplementedError

    def sign(self, data, public_key=None):
        raise NotImplementedError

    def get_only_public_key(self):
        raise NotImplementedError

class InMemoryKeyStore(KeyStore):
    def __init__(self):
        self._key_pairs = {}

    def create_key_pair(self, seed=None):
        (secret_key, public_key) = self._create_key_pair(seed)
        encoded = b58.b58encode(public_key.to_bytes()).decode('utf-8')
        self._key_pairs[encoded] = secret_key
        return encoded

    def sign(self, data, public_key=None):
        if public_key is None:
            public_key = self.get_only_public_key()

        secret_key = self._key_pairs[public_key]
        return secret_key.sign(data)

    def get_only_public_key(self):
        if len(self._key_pairs) > 1:
            raise AmbiguousPublicKey
        elif len(self._key_pairs) == 0:
            raise NoKeyPairs

        return list(self._key_pairs.keys())[0]

class FileKeyStore(KeyStore):
    def __init__(self, path):
        self._path = path

    def create_key_pair(self, seed=None):
        if not os.path.exists(self._path):
            os.makedirs(self._path)

        (secret_key, public_key) = self._create_key_pair(seed)
        encoded_pub = b58.b58encode(public_key.to_bytes()).decode('utf-8')
        encoded_secret = b58.b58encode(secret_key.to_bytes()).decode('utf-8')

        with open(os.path.join(self._path, encoded_pub), 'w') as f:
            key_file = {
                'public_key': encoded_pub,
                'secret_key': encoded_secret,
            }
            f.write(json.dumps(key_file))

        return encoded_pub

    def sign(self, data, public_key=None):
        if public_key is None:
            public_key = self.get_only_public_key()

        with open(os.path.join(self._path, public_key)) as f:
            key_file = json.loads(f.read())
            encoded_secret = key_file['secret_key']

        secret_key = b58.b58decode(encoded_secret)
        secret_key = ed25519.SigningKey(secret_key)
        return secret_key.sign(data)

    def get_only_public_key(self):
        if not os.path.exists(self._path):
            raise NoKeyPairs

        pub_keys = os.listdir(self._path)
        if len(pub_keys) > 1:
            raise AmbiguousPublicKey
        elif len(pub_keys) == 0:
            raise NoKeyPairs

        return pub_keys[0]

'''
'''--- filesysmint/tools/bench/lib.py ---
import json
import base64
import hashlib
import time
import random
import collections

try:
    from urllib2 import urlopen, Request, HTTPError, URLError, quote
except ImportError:
    from urllib.request import urlopen, Request
    from urllib.error import HTTPError, URLError
    from urllib.parse import quote

import protos.signed_transaction_pb2 as signed_transaction
from key_store import InMemoryKeyStore

def _post(url, data=''):
    if data != '':
        data = json.dumps(data).encode('utf-8')
    
    request = Request(url, data=data)

    if data is not None:
        request.add_header('Content-Type', 'application/json')

    connection = urlopen(request)
    return connection

class RPC(object):

    def __init__(self, server_url):
        self._server_url = server_url

    def _call_rpc(self, method_name, params):
        data = {
            'method': method_name,
            'jsonrpc': '2.0',
            'params': params,
            'id': 'dontcare'
        }
        try:
            connection = _post(self._server_url, data)
            raw = connection.read()
            return json.loads(raw.decode('utf-8'))
        except HTTPError as e:
            if e.code == 400:
                raise Exception(e.fp.read())
            raise
        except URLError:
            error = "Connection to {} refused. "
            raise

    def query(self, path, args=''):
        result = self._call_rpc('abci_query', [path, args, '0', False])
        return result['result']['response']

    def send_transaction(self, transaction, wait=False):
        data = transaction.SerializeToString()
        data = base64.b64encode(data).decode('utf8')
        result = self._call_rpc('broadcast_tx_commit' if wait else 'broadcast_tx_async', [data])
        return result

    def get_header(self, index):
        return self._call_rpc('block', [str(index)])

    def status(self):
        return self._call_rpc('status', [])

    def get_account(self, account_id):
        response = rpc.query('account/%s' % account_id)
        return json.loads(base64.b64decode(response['value']))

    def call_function(self, contract_id, method_name, args):
        return self.query('call/%s/%s' % (contract_id, method_name), args.encode('hex'))

class User(object):

    def __init__(self, rpc, account_id, public_key=None, keystore=None):
        self._rpc = rpc
        self._account_id = account_id
        self._nonce = rpc.get_account(account_id)['nonce']
        if keystore is None:
            keystore = InMemoryKeyStore()
        self._keystore = keystore
        if public_key is None:
            public_key = keystore.create_key_pair(seed=account_id)
        self._public_key = public_key

    @property
    def account_id(self):
        return self._account_id

    def view_account(self):
        return self._rpc.get_account(self._account_id)

    def _sign_transaction_body(self, body):
        body = body.SerializeToString()
        m = hashlib.sha256()
        m.update(body)
        data = m.digest()
        return self._keystore.sign(data, self._public_key)

    def create_user(self, account_id, amount):
        raise NotImplemented

    def send_money(self, receiver, amount, wait=False):
        self._nonce += 1
        send_money = signed_transaction.SendMoneyTransaction()
        send_money.nonce = self._nonce
        send_money.originator = self._account_id
        send_money.receiver = receiver
        send_money.amount = amount

        signature = self._sign_transaction_body(send_money)

        transaction = signed_transaction.SignedTransaction()
        transaction.send_money.CopyFrom(send_money)
        transaction.signature = signature
        
        return self._rpc.send_transaction(transaction, wait=wait)

if __name__ == "__main__":
    rpc = RPC('http://localhost:3030/')
    alice = User(rpc, "alice.near")
    print(alice.view_account())
    print(alice.send_money('bob.near', 10, wait=True))

'''
'''--- filesysmint/tools/bench/main.py ---
import time
import random
import collections
from datetime import datetime

from lib import RPC, User

def block_time_to_timestamp(t):
    return datetime.timestamp(datetime.strptime(t, '%Y-%m-%dT%H:%M:%S.%fZ'))

def benchmark(rpc, users, duration):
    start_status = rpc.status()
    start_height = int(start_status['result']['sync_info']['latest_block_height'])
    start_time = time.time()

    num_transactions = 0
    while time.time() - start_time < duration:
        user = random.choice(users)
        other_user = random.choice(users)
        result = user.send_money(other_user.account_id, 1, wait=False)
        num_transactions += 1

    end_time = time.time()
    elapsed = end_time - start_time
    end_status = rpc.status()
    end_height = int(end_status['result']['sync_info']['latest_block_height'])

    index = end_height
    num_blocks_per_sec = collections.defaultdict(int)
    num_tx_per_sec = collections.defaultdict(int)
    start_block_time = block_time_to_timestamp(start_status['result']['sync_info']['latest_block_time'])
    end_block_time = block_time_to_timestamp(end_status['result']['sync_info']['latest_block_time'])
    while index > start_height:
        header = rpc.get_header(index)
        index -= 1
        block_time = block_time_to_timestamp(header['result']['block_meta']['header']['time'])
        num_txs = int(header['result']['block_meta']['header']['num_txs'])
        if block_time > end_block_time:
            continue
        if block_time < start_block_time:
            break

        sec = int(block_time - start_block_time)
        num_blocks_per_sec[sec] += 1
        num_tx_per_sec[sec] += num_txs

    print("Submitted: %d tx in %.2fs, tps=%.2f, blocks=%d" % (
        num_transactions, elapsed, num_transactions / elapsed, end_height - start_height
    ))
    print(num_blocks_per_sec)
    print(num_tx_per_sec)
    keys = sorted(num_blocks_per_sec.keys())
    for key in keys:
        print("second=%d. blocks=%d. num tx=%d." % (key, num_blocks_per_sec[key], num_tx_per_sec[key]))
    if len(keys) > 2:
        avg_tps = sum([num_tx_per_sec[x] for x in keys[1:]]) / (keys[-1] - 1)
        print("Avg tps = %d w/o first block" % avg_tps)

if __name__ == "__main__":
    rpc = RPC('http://localhost:3030/')
    alice = User(rpc, "alice.near")
    bob = User(rpc, "bob.near")

    benchmark(rpc, [alice, bob], 10)

'''
'''--- filesysmint/tools/bench/protos/__init__.py ---
from . import signed_transaction_pb2

'''
'''--- filesysmint/tools/bench/protos/signed_transaction_pb2.py ---
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: protos/signed_transaction.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()

DESCRIPTOR = _descriptor.FileDescriptor(
  name='protos/signed_transaction.proto',
  package='',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=_b('\n\x1fprotos/signed_transaction.proto\"y\n\x18\x43reateAccountTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x16\n\x0enew_account_id\x18\x03 \x01(\t\x12\x0e\n\x06\x61mount\x18\x04 \x01(\x04\x12\x12\n\npublic_key\x18\x05 \x01(\x0c\"X\n\x19\x44\x65ployContractTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x13\n\x0b\x63ontract_id\x18\x02 \x01(\t\x12\x17\n\x0fwasm_byte_array\x18\x03 \x01(\x0c\"\x84\x01\n\x17\x46unctionCallTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x13\n\x0b\x63ontract_id\x18\x03 \x01(\t\x12\x13\n\x0bmethod_name\x18\x04 \x01(\x0c\x12\x0c\n\x04\x61rgs\x18\x05 \x01(\x0c\x12\x0e\n\x06\x61mount\x18\x06 \x01(\x04\"[\n\x14SendMoneyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x10\n\x08receiver\x18\x03 \x01(\t\x12\x0e\n\x06\x61mount\x18\x04 \x01(\x04\"E\n\x10StakeTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0e\n\x06\x61mount\x18\x03 \x01(\x04\"Y\n\x12SwapKeyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0f\n\x07\x63ur_key\x18\x03 \x01(\x0c\x12\x0f\n\x07new_key\x18\x04 \x01(\x0c\"\xc7\x02\n\x11SignedTransaction\x12\x11\n\tsignature\x18\x01 \x01(\x0c\x12\x33\n\x0e\x63reate_account\x18\x02 \x01(\x0b\x32\x19.CreateAccountTransactionH\x00\x12\x35\n\x0f\x64\x65ploy_contract\x18\x03 \x01(\x0b\x32\x1a.DeployContractTransactionH\x00\x12\x31\n\rfunction_call\x18\x04 \x01(\x0b\x32\x18.FunctionCallTransactionH\x00\x12+\n\nsend_money\x18\x05 \x01(\x0b\x32\x15.SendMoneyTransactionH\x00\x12\"\n\x05stake\x18\x06 \x01(\x0b\x32\x11.StakeTransactionH\x00\x12\'\n\x08swap_key\x18\x07 \x01(\x0b\x32\x13.SwapKeyTransactionH\x00\x42\x06\n\x04\x62odyb\x06proto3')
)

_CREATEACCOUNTTRANSACTION = _descriptor.Descriptor(
  name='CreateAccountTransaction',
  full_name='CreateAccountTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='CreateAccountTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='CreateAccountTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='new_account_id', full_name='CreateAccountTransaction.new_account_id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='CreateAccountTransaction.amount', index=3,
      number=4, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='public_key', full_name='CreateAccountTransaction.public_key', index=4,
      number=5, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=35,
  serialized_end=156,
)

_DEPLOYCONTRACTTRANSACTION = _descriptor.Descriptor(
  name='DeployContractTransaction',
  full_name='DeployContractTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='DeployContractTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contract_id', full_name='DeployContractTransaction.contract_id', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='wasm_byte_array', full_name='DeployContractTransaction.wasm_byte_array', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=158,
  serialized_end=246,
)

_FUNCTIONCALLTRANSACTION = _descriptor.Descriptor(
  name='FunctionCallTransaction',
  full_name='FunctionCallTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='FunctionCallTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='FunctionCallTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contract_id', full_name='FunctionCallTransaction.contract_id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='method_name', full_name='FunctionCallTransaction.method_name', index=3,
      number=4, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='args', full_name='FunctionCallTransaction.args', index=4,
      number=5, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='FunctionCallTransaction.amount', index=5,
      number=6, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=249,
  serialized_end=381,
)

_SENDMONEYTRANSACTION = _descriptor.Descriptor(
  name='SendMoneyTransaction',
  full_name='SendMoneyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='SendMoneyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='SendMoneyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='receiver', full_name='SendMoneyTransaction.receiver', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='SendMoneyTransaction.amount', index=3,
      number=4, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=383,
  serialized_end=474,
)

_STAKETRANSACTION = _descriptor.Descriptor(
  name='StakeTransaction',
  full_name='StakeTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='StakeTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='StakeTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='StakeTransaction.amount', index=2,
      number=3, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=476,
  serialized_end=545,
)

_SWAPKEYTRANSACTION = _descriptor.Descriptor(
  name='SwapKeyTransaction',
  full_name='SwapKeyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='SwapKeyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='SwapKeyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='cur_key', full_name='SwapKeyTransaction.cur_key', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='new_key', full_name='SwapKeyTransaction.new_key', index=3,
      number=4, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=547,
  serialized_end=636,
)

_SIGNEDTRANSACTION = _descriptor.Descriptor(
  name='SignedTransaction',
  full_name='SignedTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='signature', full_name='SignedTransaction.signature', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='create_account', full_name='SignedTransaction.create_account', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='deploy_contract', full_name='SignedTransaction.deploy_contract', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='function_call', full_name='SignedTransaction.function_call', index=3,
      number=4, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='send_money', full_name='SignedTransaction.send_money', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='stake', full_name='SignedTransaction.stake', index=5,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='swap_key', full_name='SignedTransaction.swap_key', index=6,
      number=7, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='body', full_name='SignedTransaction.body',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=639,
  serialized_end=966,
)

_SIGNEDTRANSACTION.fields_by_name['create_account'].message_type = _CREATEACCOUNTTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['deploy_contract'].message_type = _DEPLOYCONTRACTTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['function_call'].message_type = _FUNCTIONCALLTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['send_money'].message_type = _SENDMONEYTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['stake'].message_type = _STAKETRANSACTION
_SIGNEDTRANSACTION.fields_by_name['swap_key'].message_type = _SWAPKEYTRANSACTION
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['create_account'])
_SIGNEDTRANSACTION.fields_by_name['create_account'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['deploy_contract'])
_SIGNEDTRANSACTION.fields_by_name['deploy_contract'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['function_call'])
_SIGNEDTRANSACTION.fields_by_name['function_call'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['send_money'])
_SIGNEDTRANSACTION.fields_by_name['send_money'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['stake'])
_SIGNEDTRANSACTION.fields_by_name['stake'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['swap_key'])
_SIGNEDTRANSACTION.fields_by_name['swap_key'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
DESCRIPTOR.message_types_by_name['CreateAccountTransaction'] = _CREATEACCOUNTTRANSACTION
DESCRIPTOR.message_types_by_name['DeployContractTransaction'] = _DEPLOYCONTRACTTRANSACTION
DESCRIPTOR.message_types_by_name['FunctionCallTransaction'] = _FUNCTIONCALLTRANSACTION
DESCRIPTOR.message_types_by_name['SendMoneyTransaction'] = _SENDMONEYTRANSACTION
DESCRIPTOR.message_types_by_name['StakeTransaction'] = _STAKETRANSACTION
DESCRIPTOR.message_types_by_name['SwapKeyTransaction'] = _SWAPKEYTRANSACTION
DESCRIPTOR.message_types_by_name['SignedTransaction'] = _SIGNEDTRANSACTION
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

CreateAccountTransaction = _reflection.GeneratedProtocolMessageType('CreateAccountTransaction', (_message.Message,), dict(
  DESCRIPTOR = _CREATEACCOUNTTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:CreateAccountTransaction)
  ))
_sym_db.RegisterMessage(CreateAccountTransaction)

DeployContractTransaction = _reflection.GeneratedProtocolMessageType('DeployContractTransaction', (_message.Message,), dict(
  DESCRIPTOR = _DEPLOYCONTRACTTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:DeployContractTransaction)
  ))
_sym_db.RegisterMessage(DeployContractTransaction)

FunctionCallTransaction = _reflection.GeneratedProtocolMessageType('FunctionCallTransaction', (_message.Message,), dict(
  DESCRIPTOR = _FUNCTIONCALLTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:FunctionCallTransaction)
  ))
_sym_db.RegisterMessage(FunctionCallTransaction)

SendMoneyTransaction = _reflection.GeneratedProtocolMessageType('SendMoneyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SENDMONEYTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SendMoneyTransaction)
  ))
_sym_db.RegisterMessage(SendMoneyTransaction)

StakeTransaction = _reflection.GeneratedProtocolMessageType('StakeTransaction', (_message.Message,), dict(
  DESCRIPTOR = _STAKETRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:StakeTransaction)
  ))
_sym_db.RegisterMessage(StakeTransaction)

SwapKeyTransaction = _reflection.GeneratedProtocolMessageType('SwapKeyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SWAPKEYTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SwapKeyTransaction)
  ))
_sym_db.RegisterMessage(SwapKeyTransaction)

SignedTransaction = _reflection.GeneratedProtocolMessageType('SignedTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SIGNEDTRANSACTION,
  __module__ = 'protos.signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SignedTransaction)
  ))
_sym_db.RegisterMessage(SignedTransaction)

# @@protoc_insertion_point(module_scope)

'''
'''--- ipfstools/.travis.yml ---
language: rust
rust:
  - nightly-2019-03-01
cache: cargo
script:
  - cargo test

'''
'''--- ipfstools/Cargo.toml ---
[package]
name = "ipfstools"
version = "0.1.0"
authors = ["filesys Inc <hello@filesys.com>"]
edition = "2018"

[dependencies]
byteorder = "*"
cbor = { git = "https://github.com/dvc94ch/rust-cbor", branch = "read-data-item" }
cid = { git = "https://github.com/multiformats/rust-cid", branch = "master" }
storage = { path = "../runtime/storage" }
domain = "*"
env_logger = "*"
failure = "*"
fnv = "*"
futures-preview = { version = "=0.3.0-alpha.13", features = ["compat"] }
tokio = "*"
libp2p = { version = "*", git = "https://github.com/libp2p/rust-libp2p", rev = "5655624" }
log = "*"
multibase = "*"
multihash = "*"
parity-multiaddr = { version = "*", git = "https://github.com/libp2p/rust-libp2p", rev = "5655624" }
parity-multihash = { version = "*", git = "https://github.com/libp2p/rust-libp2p", rev = "5655624" }
protobuf = "2.0.2"
rand = "0.6"
rustc-serialize = "0.3"
serde = "1.0"
serde_derive = "1.0"
serde_json = "1.0"
tokio = { version = "0.1.16", features = ["async-await-preview"]  }
xdg = "*"
'''
'''--- ipfstools/README.md ---
# Rust IPFS implementation
[![Build Status](https://travis-ci.org/dvc94ch/rust-ipfs.svg?branch=master)](https://travis-ci.org/dvc94ch/rust-ipfs)

Currently implements an altruistic bitswap strategy over mdns.

## Getting started
```rust
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Ipfs, IpfsOptions, Ipld, Types};
use futures::join;

fn main() {
    let options = IpfsOptions::<Types>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);

    tokio::run_async(async move {
        // Start daemon and initialize repo
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);
        await!(ipfs.init_repo()).unwrap();
        await!(ipfs.open_repo()).unwrap();

        // Create a DAG
        let block1: Ipld = "block1".to_string().into();
        let block2: Ipld = "block2".to_string().into();
        let f1 = ipfs.put_dag(block1);
        let f2 = ipfs.put_dag(block2);
        let (res1, res2) = join!(f1, f2);
        let root: Ipld = vec![res1.unwrap(), res2.unwrap()].into();
        let path = await!(ipfs.put_dag(root)).unwrap();

        // Query the DAG
        let path1 = path.sub_path("0").unwrap();
        let path2 = path.sub_path("1").unwrap();
        let f1 = ipfs.get_dag(path1);
        let f2 = ipfs.get_dag(path2);
        let (res1, res2) = join!(f1, f2);
        println!("Received block with contents: {:?}", res1.unwrap());
        println!("Received block with contents: {:?}", res2.unwrap());

        // Exit
        ipfs.exit_daemon();
    });
}
```

## License
ISC License

Copyright (c) 2019, David Craven and others

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.

'''
'''--- ipfstools/examples/client1.rs ---
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Ipfs, IpfsOptions, Ipld, Types};
use futures::join;

fn main() {
    let options = IpfsOptions::<Types>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);

    tokio::run_async(async move {
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);
        await!(ipfs.init_repo()).unwrap();
        await!(ipfs.open_repo()).unwrap();

        let block1: Ipld = "block1".to_string().into();
        let block2: Ipld = "block2".to_string().into();
        let f1 = ipfs.put_dag(block1);
        let f2 = ipfs.put_dag(block2);
        let (res1, res2) = join!(f1, f2);

        let root: Ipld = vec![res1.unwrap(), res2.unwrap()].into();
        await!(ipfs.put_dag(root)).unwrap();
    });
}

'''
'''--- ipfstools/examples/client2.rs ---
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Ipfs, IpfsOptions, IpfsPath, TestTypes};
use futures::join;

fn main() {
    let options = IpfsOptions::<TestTypes>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);
    let path = IpfsPath::from_str("/ipfs/zdpuB1caPcm4QNXeegatVfLQ839Lmprd5zosXGwRUBJHwj66X").unwrap();

    tokio::run_async(async move {
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);

        let f1 = ipfs.get_dag(path.sub_path("0").unwrap());
        let f2 = ipfs.get_dag(path.sub_path("1").unwrap());
        let (res1, res2) = join!(f1, f2);
        println!("Received block with contents: {:?}", res1.unwrap());
        println!("Received block with contents: {:?}", res2.unwrap());

        ipfs.exit_daemon();
    });
}

'''
'''--- ipfstools/examples/ipfs_bitswap_test.rs ---
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Block, Ipfs, IpfsOptions, TestTypes};
use std::convert::TryInto;

fn main() {
    let options = IpfsOptions::<TestTypes>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);

    tokio::run_async(async move {
        // Start daemon and initialize repo
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);
        await!(ipfs.init_repo()).unwrap();
        await!(ipfs.open_repo()).unwrap();

        // Create a Block
        await!(ipfs.put_block(Block::from("block-provide"))).unwrap();

        // Retrive a Block
        let block = await!(ipfs.get_block(Block::from("block-want\n").cid())).unwrap();
        let contents: String = block.into();
        println!("block contents: {:?}", contents);

        // Add a file
        await!(ipfs.add("./examples/block.data".into())).unwrap();

        // Get a file
        let path = "/QmSy5pnHk1EnvE5dmJSyFKG5unXLGjPpBuJJCBQkBTvBaW".try_into().unwrap();
        let file = await!(ipfs.get(path)).unwrap();
        let contents: String = file.into();
        println!("file contents: {:?}", contents);
    });
}

'''
'''--- ipfstools/examples/ipfs_ipns_test.rs ---
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Ipfs, IpfsOptions, IpfsPath, PeerId, TestTypes};

fn main() {
    let options = IpfsOptions::<TestTypes>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);

    tokio::run_async(async move {
        // Start daemon and initialize repo
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);
        await!(ipfs.init_repo()).unwrap();
        await!(ipfs.open_repo()).unwrap();

        // Create a Block
        let ipfs_path = await!(ipfs.put_dag("block v0".into())).unwrap();
        // Publish a Block
        let ipns_path = await!(ipfs.publish_ipns(&PeerId::random(), &ipfs_path)).unwrap();

        // Resolve a Block
        let new_ipfs_path = await!(ipfs.resolve_ipns(&ipns_path)).unwrap();
        assert_eq!(ipfs_path, new_ipfs_path);

        // Resolve dnslink
        let ipfs_path = IpfsPath::from_str("/ipns/ipfs.io").unwrap();
        println!("Resolving {:?}", ipfs_path.to_string());
        let ipfs_path = await!(ipfs.resolve_ipns(&ipfs_path)).unwrap();
        println!("Resolved stage 1: {:?}", ipfs_path.to_string());
        let ipfs_path = await!(ipfs.resolve_ipns(&ipfs_path)).unwrap();
        println!("Resolved stage 2: {:?}", ipfs_path.to_string());

        ipfs.exit_daemon();
    });
}

'''
'''--- ipfstools/examples/readme.rs ---
#![feature(async_await, await_macro, futures_api)]
use ipfs::{Ipfs, IpfsOptions, Ipld, Types};
use futures::join;

fn main() {
    let options = IpfsOptions::<Types>::default();
    env_logger::Builder::new().parse_filters(&options.ipfs_log).init();
    let mut ipfs = Ipfs::new(options);

    tokio::run_async(async move {
        // Start daemon and initialize repo
        let fut = ipfs.start_daemon().unwrap();
        tokio::spawn_async(fut);
        await!(ipfs.init_repo()).unwrap();
        await!(ipfs.open_repo()).unwrap();

        // Create a DAG
        let block1: Ipld = "block1".to_string().into();
        let block2: Ipld = "block2".to_string().into();
        let f1 = ipfs.put_dag(block1);
        let f2 = ipfs.put_dag(block2);
        let (res1, res2) = join!(f1, f2);
        let root: Ipld = vec![res1.unwrap(), res2.unwrap()].into();
        let path = await!(ipfs.put_dag(root)).unwrap();

        // Query the DAG
        let path1 = path.sub_path("0").unwrap();
        let path2 = path.sub_path("1").unwrap();
        let f1 = ipfs.get_dag(path1);
        let f2 = ipfs.get_dag(path2);
        let (res1, res2) = join!(f1, f2);
        println!("Received block with contents: {:?}", res1.unwrap());
        println!("Received block with contents: {:?}", res2.unwrap());

        // Exit
        ipfs.exit_daemon();
    });
}

'''
'''--- ipfstools/regen_protobuf_structs.sh ---
#!/usr/bin/env sh

protoc --rust_out src/bitswap src/bitswap/bitswap_pb.proto
protoc --rust_out src/ipld/formats/pb src/ipld/formats/pb/dag_pb.proto
protoc --rust_out src/ipns src/ipns/ipns_pb.proto

'''
'''--- ipfstools/src/bitswap/behaviour.rs ---
//! Handles the `/ipfs/bitswap/1.0.0` and `/ipfs/bitswap/1.1.0` protocols. This
//! allows exchanging IPFS blocks.
//!
//! # Usage
//!
//! The `Bitswap` struct implements the `NetworkBehaviour` trait. When used, it
//! will allow providing and reciving IPFS blocks.
use crate::bitswap::ledger::{Ledger, Message, Priority, I, O};
use crate::bitswap::protocol::BitswapConfig;
use crate::bitswap::strategy::{Strategy, StrategyEvent};
use crate::block::{Block, Cid};
use crate::p2p::SwarmTypes;
use fnv::FnvHashSet;
use libp2p::core::swarm::{
    ConnectedPoint, NetworkBehaviour, NetworkBehaviourAction, PollParameters,
};
use libp2p::core::protocols_handler::{OneShotHandler, ProtocolsHandler};
use libp2p::{Multiaddr, PeerId};
use std::collections::{HashMap, VecDeque};
use std::marker::PhantomData;
use tokio::prelude::*;

/// Network behaviour that handles sending and receiving IPFS blocks.
pub struct Bitswap<TSubstream, TSwarmTypes: SwarmTypes> {
    /// Marker to pin the generics.
    marker: PhantomData<TSubstream>,
    /// Queue of events to report to the user.
    events: VecDeque<NetworkBehaviourAction<Message<O>, ()>>,
    /// List of peers to send messages to.
    target_peers: FnvHashSet<PeerId>,
    /// Ledger
    connected_peers: HashMap<PeerId, Ledger>,
    /// Wanted blocks
    wanted_blocks: HashMap<Cid, Priority>,
    /// Strategy
    strategy: TSwarmTypes::TStrategy,
}

impl<TSubstream, TSwarmTypes: SwarmTypes> Bitswap<TSubstream, TSwarmTypes> {
    /// Creates a `Bitswap`.
    pub fn new(strategy: TSwarmTypes::TStrategy) -> Self {
        debug!("bitswap: new");
        Bitswap {
            marker: PhantomData,
            events: VecDeque::new(),
            target_peers: FnvHashSet::default(),
            connected_peers: HashMap::new(),
            wanted_blocks: HashMap::new(),
            strategy,
        }
    }

    /// Connect to peer.
    ///
    /// Called from Kademlia behaviour.
    pub fn connect(&mut self, peer_id: PeerId) {
        debug!("bitswap: connect");
        if self.target_peers.insert(peer_id.clone()) {
            debug!("  queuing dial_peer to {}", peer_id.to_base58());
            self.events.push_back(NetworkBehaviourAction::DialPeer {
                peer_id: peer_id.clone(),
            });
        }
        debug!("");
    }

    /// Sends a block to the peer.
    ///
    /// Called from a Strategy.
    pub fn send_block(&mut self, peer_id: PeerId, block: Block) {
        debug!("bitswap: send_block");
        let ledger = self.connected_peers.get_mut(&peer_id)
            .expect("Peer not in ledger?!");
        let message = ledger.send_block(block);
        debug!("  queuing block for {}", peer_id.to_base58());
        self.events.push_back(NetworkBehaviourAction::SendEvent {
            peer_id,
            event: message,
        });
        debug!("");
    }

    /// Sends the wantlist to the peer.
    fn send_want_list(&mut self, peer_id: PeerId) {
        debug!("bitswap: send_want_list");
        if !self.wanted_blocks.is_empty() {
            let mut message = Message::new();
            for (cid, priority) in &self.wanted_blocks {
                message.want_block(cid, *priority);
            }
            debug!("  queuing wanted blocks");
            self.events.push_back(NetworkBehaviourAction::SendEvent {
                peer_id: peer_id.clone(),
                event: message,
            });
        }
    }

    /// Queues the wanted block for all peers.
    ///
    /// A user request
    pub fn want_block(&mut self, cid: Cid, priority: Priority) {
        debug!("bitswap: want_block");
        for (peer_id, ledger) in self.connected_peers.iter_mut() {
            let message = ledger.want_block(&cid, priority);
            debug!("  queuing want for {}", peer_id.to_base58());
            self.events.push_back(NetworkBehaviourAction::SendEvent {
                peer_id: peer_id.to_owned(),
                event: message,
            });
        }
        self.wanted_blocks.insert(cid, priority);
        debug!("");
    }

    /// Removes the block from our want list and updates all peers.
    ///
    /// Can be either a user request or be called when the block
    /// was received.
    pub fn cancel_block(&mut self, cid: &Cid) {
        debug!("bitswap: cancel_block");
        for (peer_id, ledger) in self.connected_peers.iter_mut() {
            let message = ledger.cancel_block(cid);
            if message.is_some() {
                debug!("  queuing cancel for {}", peer_id.to_base58());
                self.events.push_back(NetworkBehaviourAction::SendEvent {
                    peer_id: peer_id.to_owned(),
                    event: message.unwrap(),
                });
            }
        }
        self.wanted_blocks.remove(cid);
        debug!("");
    }
}

impl<TSubstream, TSwarmTypes: SwarmTypes> NetworkBehaviour for Bitswap<TSubstream, TSwarmTypes>
where
    TSubstream: AsyncRead + AsyncWrite,
{
    type ProtocolsHandler = OneShotHandler<TSubstream, BitswapConfig, Message<O>, InnerMessage>;
    type OutEvent = ();

    fn new_handler(&mut self) -> Self::ProtocolsHandler {
        debug!("bitswap: new_handler");
        Default::default()
    }

    fn addresses_of_peer(&mut self, _peer_id: &PeerId) -> Vec<Multiaddr> {
        debug!("bitswap: addresses_of_peer");
        Vec::new()
    }

    fn inject_connected(&mut self, peer_id: PeerId, cp: ConnectedPoint) {
        debug!("bitswap: inject_connected");
        debug!("  peer_id: {}", peer_id.to_base58());
        debug!("  connected_point: {:?}", cp);
        let ledger = Ledger::new();
        self.connected_peers.insert(peer_id.clone(), ledger);
        self.send_want_list(peer_id);
        debug!("");
    }

    fn inject_disconnected(&mut self, peer_id: &PeerId, cp: ConnectedPoint) {
        debug!("bitswap: inject_disconnected {:?}", cp);
        debug!("  peer_id: {}", peer_id.to_base58());
        debug!("  connected_point: {:?}", cp);
        debug!("");
        //self.connected_peers.remove(peer_id);
    }

    fn inject_node_event(
        &mut self,
        source: PeerId,
        event: InnerMessage,
    ) {
        debug!("bitswap: inject_node_event");
        debug!("{:?}", event);
        let message = match event {
            InnerMessage::Rx(message) => {
                message
            },
            InnerMessage::Tx => {
                return;
            },
        };
        debug!("  received message");

        // Update the ledger.
        let ledger = self.connected_peers.get_mut(&source)
            .expect("Peer not in ledger?!");
        ledger.update_incoming_stats(&message);

        // Process incoming messages.
        for block in message.blocks() {
            // Cancel the block.
            self.cancel_block(&block.cid());
            self.strategy.process_block(source.clone(), block.to_owned());
        }
        for (cid, priority) in message.want() {
            self.strategy.process_want(source.clone(), cid.to_owned(), *priority);
        }
        // TODO: Remove cancelled `Want` events from the queue.
        // TODO: Remove cancelled blocks from `SendEvent`.
        debug!("");
    }

    fn poll(
        &mut self,
        _: &mut PollParameters,
    ) -> Async<NetworkBehaviourAction<
            <Self::ProtocolsHandler as ProtocolsHandler>::InEvent, Self::OutEvent>> {
        // TODO concat messages to same destination to reduce traffic.
        if let Some(event) = self.events.pop_front() {
            if let NetworkBehaviourAction::SendEvent { peer_id, event } = event {
                let ledger = self.connected_peers.get_mut(&peer_id);
                if ledger.is_none() {
                    debug!("  requeueing send event to {}", peer_id.to_base58());
                    self.events.push_back(NetworkBehaviourAction::SendEvent {
                        peer_id,
                        event,
                    });
                } else {
                    ledger.unwrap().update_outgoing_stats(&event);
                    debug!("  send_message to {}", peer_id.to_base58());
                    return Async::Ready(NetworkBehaviourAction::SendEvent {
                        peer_id,
                        event,
                    });
                }
            } else {
                debug!("{:?}", event);
                debug!("");
                return Async::Ready(event);
            }
        }

        match self.strategy.poll() {
            Some(StrategyEvent::Send { peer_id, block }) => {
                self.send_block(peer_id, block);
                task::current().notify();
            }
            None => {}
        }

        Async::NotReady
    }
}

/// Transmission between the `OneShotHandler` and the `BitswapHandler`.
#[derive(Debug)]
pub enum InnerMessage {
    /// We received a `Message` from a remote.
    Rx(Message<I>),
    /// We successfully sent a `Message`.
    Tx,
}

impl From<Message<I>> for InnerMessage {
    #[inline]
    fn from(message: Message<I>) -> InnerMessage {
        InnerMessage::Rx(message)
    }
}

impl From<()> for InnerMessage {
    #[inline]
    fn from(_: ()) -> InnerMessage {
        InnerMessage::Tx
    }
}

'''
'''--- ipfstools/src/bitswap/bitswap_pb.rs ---
// This file is generated by rust-protobuf 2.0.2. Do not edit
// @generated

// https://github.com/Manishearth/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy)]

#![cfg_attr(rustfmt, rustfmt_skip)]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unsafe_code)]
#![allow(unused_imports)]
#![allow(unused_results)]

use protobuf::Message as Message_imported_for_functions;
use protobuf::ProtobufEnum as ProtobufEnum_imported_for_functions;

#[derive(PartialEq,Clone,Default)]
pub struct Message {
    // message fields
    pub wantlist: ::protobuf::SingularPtrField<Message_Wantlist>,
    pub blocks: ::protobuf::RepeatedField<::std::vec::Vec<u8>>,
    pub payload: ::protobuf::RepeatedField<Message_Block>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl Message {
    pub fn new() -> Message {
        ::std::default::Default::default()
    }

    // .Message.Wantlist wantlist = 1;

    pub fn clear_wantlist(&mut self) {
        self.wantlist.clear();
    }

    pub fn has_wantlist(&self) -> bool {
        self.wantlist.is_some()
    }

    // Param is passed by value, moved
    pub fn set_wantlist(&mut self, v: Message_Wantlist) {
        self.wantlist = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_wantlist(&mut self) -> &mut Message_Wantlist {
        if self.wantlist.is_none() {
            self.wantlist.set_default();
        }
        self.wantlist.as_mut().unwrap()
    }

    // Take field
    pub fn take_wantlist(&mut self) -> Message_Wantlist {
        self.wantlist.take().unwrap_or_else(|| Message_Wantlist::new())
    }

    pub fn get_wantlist(&self) -> &Message_Wantlist {
        self.wantlist.as_ref().unwrap_or_else(|| Message_Wantlist::default_instance())
    }

    // repeated bytes blocks = 2;

    pub fn clear_blocks(&mut self) {
        self.blocks.clear();
    }

    // Param is passed by value, moved
    pub fn set_blocks(&mut self, v: ::protobuf::RepeatedField<::std::vec::Vec<u8>>) {
        self.blocks = v;
    }

    // Mutable pointer to the field.
    pub fn mut_blocks(&mut self) -> &mut ::protobuf::RepeatedField<::std::vec::Vec<u8>> {
        &mut self.blocks
    }

    // Take field
    pub fn take_blocks(&mut self) -> ::protobuf::RepeatedField<::std::vec::Vec<u8>> {
        ::std::mem::replace(&mut self.blocks, ::protobuf::RepeatedField::new())
    }

    pub fn get_blocks(&self) -> &[::std::vec::Vec<u8>] {
        &self.blocks
    }

    // repeated .Message.Block payload = 3;

    pub fn clear_payload(&mut self) {
        self.payload.clear();
    }

    // Param is passed by value, moved
    pub fn set_payload(&mut self, v: ::protobuf::RepeatedField<Message_Block>) {
        self.payload = v;
    }

    // Mutable pointer to the field.
    pub fn mut_payload(&mut self) -> &mut ::protobuf::RepeatedField<Message_Block> {
        &mut self.payload
    }

    // Take field
    pub fn take_payload(&mut self) -> ::protobuf::RepeatedField<Message_Block> {
        ::std::mem::replace(&mut self.payload, ::protobuf::RepeatedField::new())
    }

    pub fn get_payload(&self) -> &[Message_Block] {
        &self.payload
    }
}

impl ::protobuf::Message for Message {
    fn is_initialized(&self) -> bool {
        for v in &self.wantlist {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.payload {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.wantlist)?;
                },
                2 => {
                    ::protobuf::rt::read_repeated_bytes_into(wire_type, is, &mut self.blocks)?;
                },
                3 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.payload)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if let Some(ref v) = self.wantlist.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        for value in &self.blocks {
            my_size += ::protobuf::rt::bytes_size(2, &value);
        };
        for value in &self.payload {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if let Some(ref v) = self.wantlist.as_ref() {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        for v in &self.blocks {
            os.write_bytes(2, &v)?;
        };
        for v in &self.payload {
            os.write_tag(3, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> Message {
        Message::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<Message_Wantlist>>(
                    "wantlist",
                    |m: &Message| { &m.wantlist },
                    |m: &mut Message| { &mut m.wantlist },
                ));
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "blocks",
                    |m: &Message| { &m.blocks },
                    |m: &mut Message| { &mut m.blocks },
                ));
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<Message_Block>>(
                    "payload",
                    |m: &Message| { &m.payload },
                    |m: &mut Message| { &mut m.payload },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<Message>(
                    "Message",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static Message {
        static mut instance: ::protobuf::lazy::Lazy<Message> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const Message,
        };
        unsafe {
            instance.get(Message::new)
        }
    }
}

impl ::protobuf::Clear for Message {
    fn clear(&mut self) {
        self.clear_wantlist();
        self.clear_blocks();
        self.clear_payload();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for Message {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for Message {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct Message_Wantlist {
    // message fields
    pub entries: ::protobuf::RepeatedField<Message_Wantlist_Entry>,
    pub full: bool,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl Message_Wantlist {
    pub fn new() -> Message_Wantlist {
        ::std::default::Default::default()
    }

    // repeated .Message.Wantlist.Entry entries = 1;

    pub fn clear_entries(&mut self) {
        self.entries.clear();
    }

    // Param is passed by value, moved
    pub fn set_entries(&mut self, v: ::protobuf::RepeatedField<Message_Wantlist_Entry>) {
        self.entries = v;
    }

    // Mutable pointer to the field.
    pub fn mut_entries(&mut self) -> &mut ::protobuf::RepeatedField<Message_Wantlist_Entry> {
        &mut self.entries
    }

    // Take field
    pub fn take_entries(&mut self) -> ::protobuf::RepeatedField<Message_Wantlist_Entry> {
        ::std::mem::replace(&mut self.entries, ::protobuf::RepeatedField::new())
    }

    pub fn get_entries(&self) -> &[Message_Wantlist_Entry] {
        &self.entries
    }

    // bool full = 2;

    pub fn clear_full(&mut self) {
        self.full = false;
    }

    // Param is passed by value, moved
    pub fn set_full(&mut self, v: bool) {
        self.full = v;
    }

    pub fn get_full(&self) -> bool {
        self.full
    }
}

impl ::protobuf::Message for Message_Wantlist {
    fn is_initialized(&self) -> bool {
        for v in &self.entries {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.entries)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.full = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.entries {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if self.full != false {
            my_size += 2;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        for v in &self.entries {
            os.write_tag(1, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if self.full != false {
            os.write_bool(2, self.full)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> Message_Wantlist {
        Message_Wantlist::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<Message_Wantlist_Entry>>(
                    "entries",
                    |m: &Message_Wantlist| { &m.entries },
                    |m: &mut Message_Wantlist| { &mut m.entries },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                    "full",
                    |m: &Message_Wantlist| { &m.full },
                    |m: &mut Message_Wantlist| { &mut m.full },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<Message_Wantlist>(
                    "Message_Wantlist",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static Message_Wantlist {
        static mut instance: ::protobuf::lazy::Lazy<Message_Wantlist> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const Message_Wantlist,
        };
        unsafe {
            instance.get(Message_Wantlist::new)
        }
    }
}

impl ::protobuf::Clear for Message_Wantlist {
    fn clear(&mut self) {
        self.clear_entries();
        self.clear_full();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for Message_Wantlist {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for Message_Wantlist {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct Message_Wantlist_Entry {
    // message fields
    pub block: ::std::vec::Vec<u8>,
    pub priority: i32,
    pub cancel: bool,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl Message_Wantlist_Entry {
    pub fn new() -> Message_Wantlist_Entry {
        ::std::default::Default::default()
    }

    // bytes block = 1;

    pub fn clear_block(&mut self) {
        self.block.clear();
    }

    // Param is passed by value, moved
    pub fn set_block(&mut self, v: ::std::vec::Vec<u8>) {
        self.block = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_block(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.block
    }

    // Take field
    pub fn take_block(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.block, ::std::vec::Vec::new())
    }

    pub fn get_block(&self) -> &[u8] {
        &self.block
    }

    // int32 priority = 2;

    pub fn clear_priority(&mut self) {
        self.priority = 0;
    }

    // Param is passed by value, moved
    pub fn set_priority(&mut self, v: i32) {
        self.priority = v;
    }

    pub fn get_priority(&self) -> i32 {
        self.priority
    }

    // bool cancel = 3;

    pub fn clear_cancel(&mut self) {
        self.cancel = false;
    }

    // Param is passed by value, moved
    pub fn set_cancel(&mut self, v: bool) {
        self.cancel = v;
    }

    pub fn get_cancel(&self) -> bool {
        self.cancel
    }
}

impl ::protobuf::Message for Message_Wantlist_Entry {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.block)?;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.priority = tmp;
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.cancel = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.block.is_empty() {
            my_size += ::protobuf::rt::bytes_size(1, &self.block);
        }
        if self.priority != 0 {
            my_size += ::protobuf::rt::value_size(2, self.priority, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.cancel != false {
            my_size += 2;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if !self.block.is_empty() {
            os.write_bytes(1, &self.block)?;
        }
        if self.priority != 0 {
            os.write_int32(2, self.priority)?;
        }
        if self.cancel != false {
            os.write_bool(3, self.cancel)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> Message_Wantlist_Entry {
        Message_Wantlist_Entry::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "block",
                    |m: &Message_Wantlist_Entry| { &m.block },
                    |m: &mut Message_Wantlist_Entry| { &mut m.block },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                    "priority",
                    |m: &Message_Wantlist_Entry| { &m.priority },
                    |m: &mut Message_Wantlist_Entry| { &mut m.priority },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                    "cancel",
                    |m: &Message_Wantlist_Entry| { &m.cancel },
                    |m: &mut Message_Wantlist_Entry| { &mut m.cancel },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<Message_Wantlist_Entry>(
                    "Message_Wantlist_Entry",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static Message_Wantlist_Entry {
        static mut instance: ::protobuf::lazy::Lazy<Message_Wantlist_Entry> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const Message_Wantlist_Entry,
        };
        unsafe {
            instance.get(Message_Wantlist_Entry::new)
        }
    }
}

impl ::protobuf::Clear for Message_Wantlist_Entry {
    fn clear(&mut self) {
        self.clear_block();
        self.clear_priority();
        self.clear_cancel();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for Message_Wantlist_Entry {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for Message_Wantlist_Entry {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct Message_Block {
    // message fields
    pub prefix: ::std::vec::Vec<u8>,
    pub data: ::std::vec::Vec<u8>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl Message_Block {
    pub fn new() -> Message_Block {
        ::std::default::Default::default()
    }

    // bytes prefix = 1;

    pub fn clear_prefix(&mut self) {
        self.prefix.clear();
    }

    // Param is passed by value, moved
    pub fn set_prefix(&mut self, v: ::std::vec::Vec<u8>) {
        self.prefix = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_prefix(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.prefix
    }

    // Take field
    pub fn take_prefix(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.prefix, ::std::vec::Vec::new())
    }

    pub fn get_prefix(&self) -> &[u8] {
        &self.prefix
    }

    // bytes data = 2;

    pub fn clear_data(&mut self) {
        self.data.clear();
    }

    // Param is passed by value, moved
    pub fn set_data(&mut self, v: ::std::vec::Vec<u8>) {
        self.data = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_data(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.data
    }

    // Take field
    pub fn take_data(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.data, ::std::vec::Vec::new())
    }

    pub fn get_data(&self) -> &[u8] {
        &self.data
    }
}

impl ::protobuf::Message for Message_Block {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.prefix)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.data)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.prefix.is_empty() {
            my_size += ::protobuf::rt::bytes_size(1, &self.prefix);
        }
        if !self.data.is_empty() {
            my_size += ::protobuf::rt::bytes_size(2, &self.data);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if !self.prefix.is_empty() {
            os.write_bytes(1, &self.prefix)?;
        }
        if !self.data.is_empty() {
            os.write_bytes(2, &self.data)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> Message_Block {
        Message_Block::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "prefix",
                    |m: &Message_Block| { &m.prefix },
                    |m: &mut Message_Block| { &mut m.prefix },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "data",
                    |m: &Message_Block| { &m.data },
                    |m: &mut Message_Block| { &mut m.data },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<Message_Block>(
                    "Message_Block",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static Message_Block {
        static mut instance: ::protobuf::lazy::Lazy<Message_Block> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const Message_Block,
        };
        unsafe {
            instance.get(Message_Block::new)
        }
    }
}

impl ::protobuf::Clear for Message_Block {
    fn clear(&mut self) {
        self.clear_prefix();
        self.clear_data();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for Message_Block {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for Message_Block {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n\x1csrc/bitswap/bitswap_pb.proto\"\xd6\x02\n\x07Message\x12-\n\x08want\
    list\x18\x01\x20\x01(\x0b2\x11.Message.WantlistR\x08wantlist\x12\x16\n\
    \x06blocks\x18\x02\x20\x03(\x0cR\x06blocks\x12(\n\x07payload\x18\x03\x20\
    \x03(\x0b2\x0e.Message.BlockR\x07payload\x1a\xa4\x01\n\x08Wantlist\x121\
    \n\x07entries\x18\x01\x20\x03(\x0b2\x17.Message.Wantlist.EntryR\x07entri\
    es\x12\x12\n\x04full\x18\x02\x20\x01(\x08R\x04full\x1aQ\n\x05Entry\x12\
    \x14\n\x05block\x18\x01\x20\x01(\x0cR\x05block\x12\x1a\n\x08priority\x18\
    \x02\x20\x01(\x05R\x08priority\x12\x16\n\x06cancel\x18\x03\x20\x01(\x08R\
    \x06cancel\x1a3\n\x05Block\x12\x16\n\x06prefix\x18\x01\x20\x01(\x0cR\x06\
    prefix\x12\x12\n\x04data\x18\x02\x20\x01(\x0cR\x04dataJ\x9e\n\n\x06\x12\
    \x04\0\0\x1c\x01\n\x08\n\x01\x0c\x12\x03\0\0\x12\n\n\n\x02\x04\0\x12\x04\
    \x02\0\x1c\x01\n\n\n\x03\x04\0\x01\x12\x03\x02\x08\x0f\n\x0c\n\x04\x04\0\
    \x03\0\x12\x04\x03\x02\x11\x03\n\x0c\n\x05\x04\0\x03\0\x01\x12\x03\x03\n\
    \x12\n\x0e\n\x06\x04\0\x03\0\x03\0\x12\x04\x04\x04\x0b\x11\n\x0e\n\x07\
    \x04\0\x03\0\x03\0\x01\x12\x03\x04\x0c\x11\nQ\n\x08\x04\0\x03\0\x03\0\
    \x02\0\x12\x03\x06\x18(\x1a@\x20the\x20block\x20cid\x20(cidV0\x20in\x20b\
    itswap\x201.0.0,\x20cidV1\x20in\x20bitswap\x201.1.0)\n\n\x11\n\t\x04\0\
    \x03\0\x03\0\x02\0\x04\x12\x04\x06\x18\x04\x13\n\x10\n\t\x04\0\x03\0\x03\
    \0\x02\0\x05\x12\x03\x06\x18\x1d\n\x10\n\t\x04\0\x03\0\x03\0\x02\0\x01\
    \x12\x03\x06\x1e#\n\x10\n\t\x04\0\x03\0\x03\0\x02\0\x03\x12\x03\x06&'\n:\
    \n\x08\x04\0\x03\0\x03\0\x02\x01\x12\x03\x08\x18+\x1a)\x20the\x20priorit\
    y\x20(normalized).\x20default\x20to\x201\n\n\x11\n\t\x04\0\x03\0\x03\0\
    \x02\x01\x04\x12\x04\x08\x18\x06(\n\x10\n\t\x04\0\x03\0\x03\0\x02\x01\
    \x05\x12\x03\x08\x18\x1d\n\x10\n\t\x04\0\x03\0\x03\0\x02\x01\x01\x12\x03\
    \x08\x1e&\n\x10\n\t\x04\0\x03\0\x03\0\x02\x01\x03\x12\x03\x08)*\n0\n\x08\
    \x04\0\x03\0\x03\0\x02\x02\x12\x03\n\x18(\x1a\x1f\x20whether\x20this\x20\
    revokes\x20an\x20entry\n\n\x11\n\t\x04\0\x03\0\x03\0\x02\x02\x04\x12\x04\
    \n\x18\x08+\n\x10\n\t\x04\0\x03\0\x03\0\x02\x02\x05\x12\x03\n\x18\x1c\n\
    \x10\n\t\x04\0\x03\0\x03\0\x02\x02\x01\x12\x03\n\x1d#\n\x10\n\t\x04\0\
    \x03\0\x03\0\x02\x02\x03\x12\x03\n&'\n+\n\x06\x04\0\x03\0\x02\0\x12\x03\
    \x0e\x04\x1f\x1a\x1c\x20a\x20list\x20of\x20wantlist\x20entries\n\n\x0e\n\
    \x07\x04\0\x03\0\x02\0\x04\x12\x03\x0e\x04\x0c\n\x0e\n\x07\x04\0\x03\0\
    \x02\0\x06\x12\x03\x0e\r\x12\n\x0e\n\x07\x04\0\x03\0\x02\0\x01\x12\x03\
    \x0e\x13\x1a\n\x0e\n\x07\x04\0\x03\0\x02\0\x03\x12\x03\x0e\x1d\x1e\nD\n\
    \x06\x04\0\x03\0\x02\x01\x12\x03\x10\x04\x12\x1a5\x20whether\x20this\x20\
    is\x20the\x20full\x20wantlist.\x20default\x20to\x20false\n\n\x0f\n\x07\
    \x04\0\x03\0\x02\x01\x04\x12\x04\x10\x04\x0e\x1f\n\x0e\n\x07\x04\0\x03\0\
    \x02\x01\x05\x12\x03\x10\x04\x08\n\x0e\n\x07\x04\0\x03\0\x02\x01\x01\x12\
    \x03\x10\t\r\n\x0e\n\x07\x04\0\x03\0\x02\x01\x03\x12\x03\x10\x10\x11\n\
    \x0c\n\x04\x04\0\x03\x01\x12\x04\x13\x02\x17\x03\n\x0c\n\x05\x04\0\x03\
    \x01\x01\x12\x03\x13\n\x0f\nY\n\x06\x04\0\x03\x01\x02\0\x12\x03\x15\x04\
    \x15\x1aJ\x20CID\x20prefix\x20(cid\x20version,\x20multicodec\x20and\x20m\
    ultihash\x20prefix\x20(type\x20+\x20length)\n\n\x0f\n\x07\x04\0\x03\x01\
    \x02\0\x04\x12\x04\x15\x04\x13\x11\n\x0e\n\x07\x04\0\x03\x01\x02\0\x05\
    \x12\x03\x15\x04\t\n\x0e\n\x07\x04\0\x03\x01\x02\0\x01\x12\x03\x15\n\x10\
    \n\x0e\n\x07\x04\0\x03\x01\x02\0\x03\x12\x03\x15\x13\x14\n\r\n\x06\x04\0\
    \x03\x01\x02\x01\x12\x03\x16\x04\x13\n\x0f\n\x07\x04\0\x03\x01\x02\x01\
    \x04\x12\x04\x16\x04\x15\x15\n\x0e\n\x07\x04\0\x03\x01\x02\x01\x05\x12\
    \x03\x16\x04\t\n\x0e\n\x07\x04\0\x03\x01\x02\x01\x01\x12\x03\x16\n\x0e\n\
    \x0e\n\x07\x04\0\x03\x01\x02\x01\x03\x12\x03\x16\x11\x12\n\x0b\n\x04\x04\
    \0\x02\0\x12\x03\x19\x02\x18\n\r\n\x05\x04\0\x02\0\x04\x12\x04\x19\x02\
    \x17\x03\n\x0c\n\x05\x04\0\x02\0\x06\x12\x03\x19\x02\n\n\x0c\n\x05\x04\0\
    \x02\0\x01\x12\x03\x19\x0b\x13\n\x0c\n\x05\x04\0\x02\0\x03\x12\x03\x19\
    \x16\x17\n3\n\x04\x04\0\x02\x01\x12\x03\x1a\x02\x1c\"&\x20used\x20to\x20\
    send\x20Blocks\x20in\x20bitswap\x201.0.0\n\n\x0c\n\x05\x04\0\x02\x01\x04\
    \x12\x03\x1a\x02\n\n\x0c\n\x05\x04\0\x02\x01\x05\x12\x03\x1a\x0b\x10\n\
    \x0c\n\x05\x04\0\x02\x01\x01\x12\x03\x1a\x11\x17\n\x0c\n\x05\x04\0\x02\
    \x01\x03\x12\x03\x1a\x1a\x1b\n3\n\x04\x04\0\x02\x02\x12\x03\x1b\x02\x1d\
    \"&\x20used\x20to\x20send\x20Blocks\x20in\x20bitswap\x201.1.0\n\n\x0c\n\
    \x05\x04\0\x02\x02\x04\x12\x03\x1b\x02\n\n\x0c\n\x05\x04\0\x02\x02\x06\
    \x12\x03\x1b\x0b\x10\n\x0c\n\x05\x04\0\x02\x02\x01\x12\x03\x1b\x11\x18\n\
    \x0c\n\x05\x04\0\x02\x02\x03\x12\x03\x1b\x1b\x1cb\x06proto3\
";

static mut file_descriptor_proto_lazy: ::protobuf::lazy::Lazy<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::lazy::Lazy {
    lock: ::protobuf::lazy::ONCE_INIT,
    ptr: 0 as *const ::protobuf::descriptor::FileDescriptorProto,
};

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    unsafe {
        file_descriptor_proto_lazy.get(|| {
            parse_descriptor_proto()
        })
    }
}

'''
'''--- ipfstools/src/bitswap/ledger.rs ---
use crate::block::{Block, Cid};
use crate::bitswap::bitswap_pb;
use crate::error::Error;
use protobuf::Message as ProtobufMessage;
use std::collections::HashMap;
use std::marker::PhantomData;

pub type Priority = i32;

/// The Ledger contains the history of transactions with a peer.
#[derive(Debug)]
pub struct Ledger {
    /// The number of blocks sent to the peer.
    sent_blocks: usize,
    /// The number of blocks received from the peer.
    received_blocks: usize,
    /// The list of wanted blocks sent to the peer.
    sent_want_list: HashMap<Cid, Priority>,
    /// The list of wanted blocks received from the peer.
    received_want_list: HashMap<Cid, Priority>,
}

impl Ledger {
    /// Creates a new `PeerLedger`.
    pub fn new() -> Self {
        Ledger {
            sent_blocks: 0,
            received_blocks: 0,
            sent_want_list: HashMap::new(),
            received_want_list: HashMap::new(),
        }
    }

    pub fn send_block(&mut self, block: Block) -> Message<O> {
        let mut message = Message::new();
        message.add_block(block);
        message
    }

    pub fn want_block(&mut self, cid: &Cid, priority: Priority) -> Message<O> {
        let mut message = Message::new();
        message.want_block(cid, priority);
        message
    }

    pub fn cancel_block(&mut self, cid: &Cid) -> Option<Message<O>> {
        if self.sent_want_list.contains_key(cid) {
            let mut message = Message::new();
            message.cancel_block(cid);
            Some(message)
        } else {
            None
        }
    }

    pub fn update_outgoing_stats(&mut self, message: &Message<O>) {
        self.sent_blocks += message.blocks.len();
        for cid in message.cancel() {
            self.sent_want_list.remove(cid);
        }
        for (cid, priority) in message.want() {
            self.sent_want_list.insert(cid.to_owned(), *priority);
        }
    }

    pub fn update_incoming_stats(&mut self, message: &Message<I>) {
        self.received_blocks += message.blocks.len();
        for cid in message.cancel() {
            self.received_want_list.remove(cid);
        }
        for (cid, priority) in message.want() {
            self.received_want_list.insert(cid.to_owned(), *priority);
        }
    }
}

#[derive(Debug, Clone, PartialEq)]
pub struct I;
#[derive(Debug, Clone, PartialEq)]
pub struct O;

/// A bitswap message.
#[derive(Clone, PartialEq)]
pub struct Message<T> {
    /// Message tag
    _phantom_data: PhantomData<T>,
    /// List of wanted blocks.
    want: HashMap<Cid, Priority>,
    /// List of blocks to cancel.
    cancel: Vec<Cid>,
    /// Wheather it is the full list of wanted blocks.
    full: bool,
    /// List of blocks to send.
    blocks: Vec<Block>,
}

impl<T> Message<T> {
    /// Creates a new bitswap message.
    pub fn new() -> Self {
        Message {
            _phantom_data: PhantomData,
            want: HashMap::new(),
            cancel: Vec::new(),
            full: false,
            blocks: Vec::new(),
        }
    }

    /// Returns the list of blocks.
    pub fn blocks(&self) -> &Vec<Block> {
        &self.blocks
    }

    /// Returns the list of wanted blocks.
    pub fn want(&self) -> &HashMap<Cid, Priority> {
        &self.want
    }

    /// Returns the list of cancelled blocks.
    pub fn cancel(&self) -> &Vec<Cid> {
        &self.cancel
    }

    /// Adds a `Block` to the message.
    pub fn add_block(&mut self, block: Block) {
        self.blocks.push(block);
    }

    /// Removes the block from the message.
    #[allow(unused)]
    pub fn remove_block(&mut self, cid: &Cid) {
        self.blocks.drain_filter(|block| block.cid() == cid);
    }

    /// Adds a block to the want list.
    pub fn want_block(&mut self, cid: &Cid, priority: Priority) {
        self.want.insert(cid.to_owned(), priority);
    }

    /// Adds a block to the cancel list.
    pub fn cancel_block(&mut self, cid: &Cid) {
        self.cancel.push(cid.to_owned());
    }

    /// Removes the block from the want list.
    #[allow(unused)]
    pub fn remove_want_block(&mut self, cid: &Cid) {
        self.want.remove(cid);
    }
}

impl Message<O> {
    /// Turns this `Message` into a message that can be sent to a substream.
    pub fn into_bytes(&self) -> Vec<u8> {
        let mut proto = bitswap_pb::Message::new();
        let mut wantlist = bitswap_pb::Message_Wantlist::new();
        for (cid, priority) in self.want() {
            let mut entry = bitswap_pb::Message_Wantlist_Entry::new();
            entry.set_block(cid.to_bytes());
            entry.set_priority(*priority as _);
            wantlist.mut_entries().push(entry);
        }
        for cid in self.cancel() {
            let mut entry = bitswap_pb::Message_Wantlist_Entry::new();
            entry.set_block(cid.to_bytes());
            entry.set_cancel(true);
            wantlist.mut_entries().push(entry);
        }
        proto.set_wantlist(wantlist);
        for block in self.blocks() {
            let mut payload = bitswap_pb::Message_Block::new();
            payload.set_prefix(block.cid().prefix().as_bytes());
            payload.set_data(block.data().to_vec());
            proto.mut_payload().push(payload);
        }
        proto
            .write_to_bytes()
            .expect("there is no situation in which the protobuf message can be invalid")
    }

}

impl Message<I> {
    /// Creates a `Message` from bytes that were received from a substream.
    pub fn from_bytes(bytes: &Vec<u8>) -> Result<Self, Error> {
        let proto: bitswap_pb::Message = protobuf::parse_from_bytes(bytes)?;
        let mut message = Message::new();
        for entry in proto.get_wantlist().get_entries() {
            let cid = Cid::from(entry.get_block())?;
            if entry.get_cancel() {
                message.cancel_block(&cid);
            } else {
                message.want_block(&cid, entry.get_priority() as _);
            }
        }
        for payload in proto.get_payload() {
            let prefix = cid::Prefix::new_from_bytes(payload.get_prefix())?;
            let cid = cid::Cid::new_from_prefix(&prefix, payload.get_data());
            let block = Block::new(payload.get_data().to_vec(), cid);
            message.add_block(block);
        }
        Ok(message)
    }
}

impl<T> std::fmt::Debug for Message<T> {
    fn fmt(&self, fmt: &mut std::fmt::Formatter) -> Result<(), std::fmt::Error> {
        for (cid, priority) in self.want() {
            writeln!(fmt, "want: {} {}", cid.to_string(), priority)?;
        }
        for cid in self.cancel() {
            writeln!(fmt, "cancel: {}", cid.to_string())?;
        }
        for block in self.blocks() {
            writeln!(fmt, "block: {}", block.cid().to_string())?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    /*
    use super::*;

    #[test]
    fn test_empty_message_to_from_bytes() {
        let message = Message::new();
        let bytes = message.clone().into_bytes();
        let new_message = Message::from_bytes(&bytes).unwrap();
        assert_eq!(message, new_message);
    }

    #[test]
    fn test_want_message_to_from_bytes() {
        let mut message = Message::new();
        let block = Block::from("hello world");
        message.want_block(&block.cid(), 1);
        let bytes = message.clone().into_bytes();
        let new_message = Message::from_bytes(&bytes).unwrap();
        assert_eq!(message, new_message);
    }

    #[test]
    fn test_cancel_message_to_from_bytes() {
        let mut message = Message::new();
        let block = Block::from("hello world");
        message.cancel_block(&block.cid());
        let bytes = message.clone().into_bytes();
        let new_message = Message::from_bytes(&bytes).unwrap();
        assert_eq!(message, new_message);
    }

    #[test]
    fn test_payload_message_to_from_bytes() {
        let mut message = Message::new();
        let block = Block::from("hello world");
        message.add_block(block);
        let bytes = message.clone().into_bytes();
        let new_message = Message::from_bytes(&bytes).unwrap();
        assert_eq!(message, new_message);
    }

    #[test]
    fn test_ledger_send_block() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let mut ledger = Ledger::new();
        ledger.add_block(block_1);
        ledger.add_block(block_2);
        ledger.send_message().unwrap();
        assert_eq!(ledger.sent_blocks, 2);
    }

    #[test]
    fn test_ledger_remove_block() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let mut ledger = Ledger::new();
        ledger.add_block(block_1.clone());
        ledger.add_block(block_2);
        ledger.remove_block(&block_1.cid());
        ledger.send_message().unwrap();
        assert_eq!(ledger.sent_blocks, 1);
    }

    #[test]
    fn test_ledger_send_want() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let mut ledger = Ledger::new();
        ledger.want_block(&block_1.cid(), 1);
        ledger.want_block(&block_2.cid(), 1);
        ledger.cancel_block(&block_1.cid());
        ledger.send_message().unwrap();
        let mut want_list = HashMap::new();
        want_list.insert(block_2.cid(), 1);
        assert_eq!(ledger.sent_want_list, want_list);
    }

    #[test]
    fn test_ledger_send_cancel() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let mut ledger = Ledger::new();
        ledger.want_block(&block_1.cid(), 1);
        ledger.want_block(&block_2.cid(), 1);
        ledger.send_message().unwrap();
        ledger.cancel_block(&block_1.cid());
        ledger.send_message().unwrap();
        let mut want_list = HashMap::new();
        want_list.insert(block_2.cid(), 1);
        assert_eq!(ledger.sent_want_list, want_list);
    }

    #[test]
    fn test_ledger_receive() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let mut message = Message::new();
        message.add_block(block_1);
        message.want_block(&block_2.cid(), 1);

        let mut ledger = Ledger::new();
        ledger.receive_message(&message);

        assert_eq!(ledger.received_blocks, 1);
        let mut want_list = HashMap::new();
        want_list.insert(block_2.cid(), 1);
        assert_eq!(ledger.received_want_list, want_list);

        let mut message = Message::new();
        message.cancel_block(&block_2.cid());
        ledger.receive_message(&message);
        assert_eq!(ledger.received_want_list, HashMap::new());
    }
    */
}

'''
'''--- ipfstools/src/bitswap/mod.rs ---
//! Bitswap protocol implementation
pub mod behaviour;
pub mod ledger;
mod bitswap_pb;
pub mod strategy;
pub mod protocol;

pub use self::behaviour::Bitswap;
pub use self::protocol::BitswapError;
pub use self::ledger::Priority;
pub use self::strategy::{AltruisticStrategy, Strategy};

'''
'''--- ipfstools/src/bitswap/protocol.rs ---
/// Reperesents a prototype for an upgrade to handle the bitswap protocol.
///
/// The protocol works the following way:
///
/// - TODO

use crate::bitswap::ledger::{Message, I, O};
use crate::error::Error;
use libp2p::core::{InboundUpgrade, OutboundUpgrade, UpgradeInfo, upgrade};
use protobuf::ProtobufError;
use std::{io, iter};
use tokio::prelude::*;

// Undocumented, but according to JS we our messages have a max size of 512*1024
// https://github.com/ipfs/js-ipfs-bitswap/blob/d8f80408aadab94c962f6b88f343eb9f39fa0fcc/src/decision-engine/index.js#L16
const MAX_BUF_SIZE : usize = 524288;

#[derive(Clone, Debug, Default)]
pub struct BitswapConfig {}

impl UpgradeInfo for BitswapConfig {
    type Info = &'static [u8];
    type InfoIter = iter::Once<Self::Info>;

    fn protocol_info(&self) -> Self::InfoIter {
        // b"/ipfs/bitswap", b"/ipfs/bitswap/1.0.0"
        iter::once(b"/ipfs/bitswap/1.1.0")
    }
}

impl<TSocket> InboundUpgrade<TSocket> for BitswapConfig
where
    TSocket: AsyncRead + AsyncWrite,
{
    type Output = Message<I>;
    type Error = Error;
    type Future = upgrade::ReadOneThen<TSocket, (), fn(Vec<u8>, ()) -> Result<Self::Output, Self::Error>>;

    #[inline]
    fn upgrade_inbound(self, socket: TSocket, info: Self::Info) -> Self::Future {
        debug!("upgrade_inbound: {}", std::str::from_utf8(info).unwrap());
        upgrade::read_one_then(socket, MAX_BUF_SIZE, (), |packet, ()| {
            let message = Message::from_bytes(&packet)?;
            debug!("inbound message: {:?}", message);
            Ok(message)
        })
    }
}

#[derive(Debug)]
pub enum BitswapError {
    ReadError(upgrade::ReadOneError),
    ProtobufError(ProtobufError),
}

impl From<upgrade::ReadOneError> for BitswapError {
    #[inline]
    fn from(err: upgrade::ReadOneError) -> Self {
        BitswapError::ReadError(err)
    }
}

impl From<ProtobufError> for BitswapError {
    #[inline]
    fn from(err: ProtobufError) -> Self {
        BitswapError::ProtobufError(err)
    }
}

impl std::fmt::Display for BitswapError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match *self {
            BitswapError::ReadError(ref err) =>
                write!(f, "Error while reading from socket: {}", err),
            BitswapError::ProtobufError(ref err) =>
                write!(f, "Error while decoding protobuf: {}", err),
        }
    }
}

impl std::error::Error for BitswapError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match *self {
            BitswapError::ReadError(ref err) => Some(err),
            BitswapError::ProtobufError(ref err) => Some(err),
        }
    }
}

impl UpgradeInfo for Message<O> {
    type Info = &'static [u8];
    type InfoIter = iter::Once<Self::Info>;

    fn protocol_info(&self) -> Self::InfoIter {
        // b"/ipfs/bitswap", b"/ipfs/bitswap/1.0.0"
        iter::once(b"/ipfs/bitswap/1.1.0")
    }
}

impl<TSocket> OutboundUpgrade<TSocket> for Message<O>
where
    TSocket: AsyncRead + AsyncWrite,
{
    type Output = ();
    type Error = io::Error;
    type Future = upgrade::WriteOne<TSocket>;

    #[inline]
    fn upgrade_outbound(self, socket: TSocket, info: Self::Info) -> Self::Future {
        debug!("upgrade_outbound: {}", std::str::from_utf8(info).unwrap());
        let bytes = self.into_bytes();
        upgrade::write_one(socket, bytes)
    }
}

#[cfg(test)]
mod tests {
    /*
    use futures::prelude::*;
    use libp2p::core::upgrade;
    use super::*;
    use tokio::net::{TcpListener, TcpStream};

    // TODO: rewrite tests with the MemoryTransport
    // TODO: figure out why it doesn't exit
    #[test]
    fn test_upgrade() {
        let listener = TcpListener::bind(&"127.0.0.1:0".parse().unwrap()).unwrap();
        let listener_addr = listener.local_addr().unwrap();

        let _server = listener
            .incoming()
            .into_future()
            .map_err(|(e, _)| e)
            .and_then(|(c, _)| {
                println!("upgrading server");
                upgrade::apply_inbound(c.unwrap(), BitswapConfig::default())
                    .map_err(|_| panic!())
            })
            .map(|_| ());

        let _client = TcpStream::connect(&listener_addr)
            .and_then(|c| {
                println!("upgrading client");
                upgrade::apply_outbound(c, Message::new())
                    .map_err(|_| panic!())
            });

        //tokio::run(server.select(client).map(|_| ()).map_err(|_| panic!()));
    }*/
}

'''
'''--- ipfstools/src/bitswap/strategy.rs ---
use crate::block::{Block, Cid};
use crate::bitswap::Priority;
use crate::repo::{Repo, RepoTypes};
use libp2p::PeerId;
use std::sync::mpsc::{channel, Sender, Receiver};

pub trait Strategy<TRepoTypes: RepoTypes>: Send + Unpin {
    fn new(repo: Repo<TRepoTypes>) -> Self;
    fn process_want(&mut self, source: PeerId, cid: Cid, priority: Priority);
    fn process_block(&mut self, source: PeerId, block: Block);
    fn poll(&mut self) -> Option<StrategyEvent>;
}

pub enum StrategyEvent {
    Send {
        peer_id: PeerId,
        block: Block,
    }
}

pub struct AltruisticStrategy<TRepoTypes: RepoTypes> {
    repo: Repo<TRepoTypes>,
    events: (Sender<StrategyEvent>, Receiver<StrategyEvent>),
}

impl<TRepoTypes: RepoTypes> Strategy<TRepoTypes> for AltruisticStrategy<TRepoTypes> {
    fn new(repo: Repo<TRepoTypes>) -> Self {
        AltruisticStrategy {
            repo,
            events: channel::<StrategyEvent>(),
        }
    }

    fn process_want(
        &mut self,
        source: PeerId,
        cid: Cid,
        priority: Priority,
    ) {
        info!("Peer {} wants block {} with priority {}",
              source.to_base58(), cid.to_string(), priority);
        let events = self.events.0.clone();
        let future = self.repo.get_block(&cid);
        tokio::spawn_async(async move {
            let block = await!(future).unwrap();
            events.send(StrategyEvent::Send {
                peer_id: source,
                block: block,
            }).unwrap();
        });
    }

    fn process_block(&mut self, source: PeerId, block: Block) {
        info!("Received block {} from peer {}",
              block.cid().to_string(),
              source.to_base58());
        let future = self.repo.put_block(block);
        tokio::spawn_async(async move {
            await!(future).unwrap();
        });
    }

    fn poll(&mut self) -> Option<StrategyEvent> {
        self.events.1.try_recv().ok()
    }
}

#[cfg(test)]
mod tests {
    /*use super::*;
    use crate::block::Block;

    #[test]
    fn test_altruistic_strategy() {
        let block_1 = Block::from("1");
        let block_2 = Block::from("2");
        let repo = Repo::new();
        repo.put(block_1.clone());
        let mut strategy = AltruisticStrategy::new(repo);
        let mut ledger = Ledger::new();
        let peer_id = PeerId::random();
        ledger.peer_connected(peer_id.clone());
        strategy.receive_want(&mut ledger, &peer_id, block_1.cid(), 1);
        strategy.receive_want(&mut ledger, &peer_id, block_2.cid(), 1);
        ledger.send_messages();
        let peer_ledger = ledger.peer_ledger(&peer_id);
        assert_eq!(peer_ledger.sent_blocks(), 1);
    }*/
}

'''
'''--- ipfstools/src/block.rs ---
//! Block
pub use cid::Cid;
pub use crate::error::Error;
pub use crate::path::{IpfsPath, PathRoot};

#[derive(Clone, Debug, PartialEq)]
/// An immutable ipfs block.
pub struct Block {
    data: Vec<u8>,
    cid: Cid,
}

impl Block {
    /// Creates a new immutable ipfs block.
    pub fn new(data: Vec<u8>, cid: Cid) -> Self {
        Block {
            data,
            cid,
        }
    }

    /// Returns the size of the block in bytes.
    pub fn size(&self) -> usize {
        self.data.len()
    }

    /// Returns the content id of the block.
    pub fn cid(&self) -> &Cid {
        &self.cid
    }

    /// Returns the data of the block.
    pub fn data(&self) -> &Vec<u8> {
        &self.data
    }

    /// Returns the ipfs path of the block.
    pub fn path(&self, path: &str) -> Result<IpfsPath, Error> {
        IpfsPath::new(PathRoot::Ipld(self.cid.clone())).into_sub_path(path)
    }
}

impl From<&str> for Block {
    fn from(content: &str) -> Block {
        let prefix = cid::Prefix {
            version: cid::Version::V0,
            codec: cid::Codec::DagProtobuf,
            mh_type: multihash::Hash::SHA2256,
            mh_len: 32,
        };
        let data = content.as_bytes().to_vec();
        let cid = cid::Cid::new_from_prefix(&prefix, &data);
        Block::new(data, cid)
    }
}

impl Into<String> for Block {
    fn into(self) -> String {
        String::from_utf8_lossy(self.data()).to_string()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_raw_block_cid() {
        let content = "hello\n".as_bytes();
        let cid = "zb2rhcc1wJn2GHDLT2YkmPq5b69cXc2xfRZZmyufbjFUfBkxr";
        let prefix = cid::Prefix {
            version: cid::Version::V1,
            codec: cid::Codec::Raw,
            mh_type: multihash::Hash::SHA2256,
            mh_len: 32,
        };
        let computed_cid = cid::Cid::new_from_prefix(
            &prefix,
            &content,
        ).to_string();
        assert_eq!(cid, computed_cid);
    }

    #[test]
    fn test_dag_pb_block_cid() {
        let content = "hello\n".as_bytes();
        let cid = "QmUJPTFZnR2CPGAzmfdYPghgrFtYFB6pf1BqMvqfiPDam8";
        let prefix = cid::Prefix {
            version: cid::Version::V0,
            codec: cid::Codec::DagProtobuf,
            mh_type: multihash::Hash::SHA2256,
            mh_len: 32,
        };
        let computed_cid = cid::Cid::new_from_prefix(
            &prefix,
            &content,
        ).to_string();
        assert_eq!(cid, computed_cid);
    }

    #[test]
    fn test_block() {
        let block = Block::from("hello block\n");
        assert_eq!(block.cid().to_string(),
                   "QmVNrZhKw9JwYa4YPEZVccQxfgQJq993yP78QEN28927vq");
        assert_eq!(block.size(), 12);
    }
}

'''
'''--- ipfstools/src/config.rs ---
use libp2p::{Multiaddr, PeerId};
use libp2p::multiaddr::Protocol;
use libp2p::secio::SecioKeyPair;
use rand::{Rng, rngs::EntropyRng};
use serde_derive::{Serialize, Deserialize};
use std::fs;
use std::path::Path;

const BOOTSTRAP_NODES: &[&'static str] = &[
    "/ip4/104.131.131.82/tcp/4001/p2p/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
    "/ip4/104.236.179.241/tcp/4001/p2p/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip4/104.236.76.40/tcp/4001/p2p/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip4/128.199.219.111/tcp/4001/p2p/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip4/178.62.158.247/tcp/4001/p2p/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd",
    "/ip6/2400:6180:0:d0::151:6001/tcp/4001/p2p/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu",
    "/ip6/2604:a880:1:20::203:d001/tcp/4001/p2p/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM",
    "/ip6/2604:a880:800:10::4a:5001/tcp/4001/p2p/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64",
    "/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/p2p/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd",
];

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ConfigFile {
    raw_key: [u8; 32],
    bootstrap: Vec<Multiaddr>,
}

impl ConfigFile {
    pub fn new<P: AsRef<Path>>(path: P) -> Self {
        fs::read_to_string(&path).map(|content| {
            serde_json::from_str(&content).unwrap()
        }).unwrap_or_else(|_| {
            let config = ConfigFile::default();
            let string = serde_json::to_string_pretty(&config).unwrap();
            fs::write(path, string).unwrap();
            config
        })
    }

    pub fn secio_key_pair(&self) -> SecioKeyPair {
        SecioKeyPair::ed25519_raw_key(&self.raw_key).unwrap()
    }

    pub fn peer_id(&self) -> PeerId {
        self.secio_key_pair().to_peer_id()
    }

    pub fn bootstrap(&self) -> Vec<(Multiaddr, PeerId)> {
        let mut bootstrap = Vec::new();
        for addr in &self.bootstrap {
            let mut addr = addr.to_owned();
            let peer_id = match addr.pop() {
                Some(Protocol::P2p(hash)) => PeerId::from_multihash(hash).unwrap(),
                _ => panic!("No peer id for addr"),
            };
            bootstrap.push((addr, peer_id));
        }
        bootstrap
    }
}

impl Default for ConfigFile {
    fn default() -> Self {
	      let raw_key: [u8; 32] = EntropyRng::new().gen();
        let bootstrap = BOOTSTRAP_NODES.iter().map(|node| {
            node.parse().unwrap()
        }).collect();
        ConfigFile {
            raw_key,
            bootstrap,
        }
    }
}

'''
'''--- ipfstools/src/error.rs ---
pub use failure::Error;

'''
'''--- ipfstools/src/future.rs ---
use crate::block::{Block, Cid};
use crate::error::Error;
use crate::repo::BlockStore;
use futures::future::FutureObj;
use futures::prelude::*;
use std::future::Future;
use std::pin::Pin;
use std::task::{Poll, Waker};

pub struct BlockFuture<TBlockStore: BlockStore> {
    block_store: TBlockStore,
    cid: Cid,
    future: FutureObj<'static, Result<Option<Block>, Error>>,
}

impl<TBlockStore: BlockStore> BlockFuture<TBlockStore> {
    pub fn new(block_store: TBlockStore, cid: Cid) -> Self {
        let future = block_store.get(&cid);
        BlockFuture {
            block_store,
            cid,
            future,
        }
    }
}

impl<TBlockStore: BlockStore> Future for BlockFuture<TBlockStore> {
    type Output = Result<Block, Error>;

    fn poll(mut self: Pin<&mut Self>, waker: &Waker) -> Poll<Self::Output> {
        return match self.future.poll_unpin(waker) {
            Poll::Ready(Ok(Some(block))) => Poll::Ready(Ok(block)),
            Poll::Ready(Ok(None)) => {
                let future = self.block_store.get(&self.cid);
                self.get_mut().future = future;
                tokio::prelude::task::current().notify();
                //waker.wake();
                Poll::Pending
            },
            Poll::Ready(Err(err)) => {
                Poll::Ready(Err(err))
            },
            Poll::Pending => Poll::Pending,
        }
    }
}

'''
'''--- ipfstools/src/ipld/dag.rs ---
use crate::error::Error;
use crate::ipld::Ipld;
use crate::path::{IpfsPath, IpfsPathError, PathRoot, SubPath};
use crate::repo::{Repo, RepoTypes};
use cid::Codec;
use core::future::Future;

#[derive(Clone)]
pub struct IpldDag<Types: RepoTypes> {
    repo: Repo<Types>,
}

impl<Types: RepoTypes> IpldDag<Types> {
    pub fn new(repo: Repo<Types>) -> Self {
        IpldDag {
            repo,
        }
    }

    pub fn put(&self, data: Ipld, codec: Codec) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        let repo = self.repo.clone();
        async move {
            let block = data.to_block(codec)?;
            let cid = await!(repo.put_block(block))?;
            Ok(IpfsPath::new(PathRoot::Ipld(cid)))
        }
    }

    pub fn get(&self, path: IpfsPath) -> impl Future<Output=Result<Ipld, Error>> {
        let repo = self.repo.clone();
        async move {
            let cid = match path.root().cid() {
                Some(cid) => cid,
                None => bail!("expected cid"),
            };
            let mut ipld = Ipld::from(&await!(repo.get_block(&cid))?)?;
            for sub_path in path.iter() {
                if !can_resolve(&ipld, sub_path) {
                    let path = sub_path.to_owned();
                    return Err(IpfsPathError::ResolveError { ipld, path }.into());
                }
                ipld = resolve(ipld, sub_path);
                ipld = match ipld {
                    Ipld::Link(root) => {
                        match root.cid() {
                            Some(cid) => Ipld::from(&await!(repo.get_block(cid))?)?,
                            None => bail!("expected cid"),
                        }
                    }
                    ipld => ipld,
                };
            }
            Ok(ipld)
        }
    }
}

fn can_resolve(ipld: &Ipld, sub_path: &SubPath) -> bool {
    match sub_path {
        SubPath::Key(key) => {
            if let Ipld::Object(ref map) = ipld {
                if map.contains_key(key) {
                    return true;
                }
            }
        }
        SubPath::Index(index) => {
            if let Ipld::Array(ref vec) = ipld {
                if *index < vec.len() {
                    return true;
                }
            }
        }
    }
    false
}

fn resolve(ipld: Ipld, sub_path: &SubPath) -> Ipld {
    match sub_path {
        SubPath::Key(key) => {
            if let Ipld::Object(mut map) = ipld {
                return map.remove(key).unwrap()
            }
        }
        SubPath::Index(index) => {
            if let Ipld::Array(mut vec) = ipld {
                return vec.swap_remove(*index)
            }
        }
    }
    panic!();
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::repo::tests::create_mock_repo;
    use std::collections::HashMap;

    #[test]
    fn test_resolve_root_cid() {
        tokio::run_async(async {
            let repo = create_mock_repo();
            let dag = IpldDag::new(repo);
            let data = Ipld::Array(vec![Ipld::U64(1), Ipld::U64(2), Ipld::U64(3)]);
            let path = await!(dag.put(data.clone(), Codec::DagCBOR)).unwrap();

            let res = await!(dag.get(path)).unwrap();
            assert_eq!(res, data);

        });
    }

    #[test]
    fn test_resolve_array_elem() {
        tokio::run_async(async {
            let repo = create_mock_repo();
            let dag = IpldDag::new(repo);
            let data: Ipld = vec![1, 2, 3].into();
            let path = await!(dag.put(data.clone(), Codec::DagCBOR)).unwrap();
            let res = await!(dag.get(path.sub_path("1").unwrap())).unwrap();
            assert_eq!(res, Ipld::U64(2));
        });
    }

    #[test]
    fn test_resolve_nested_array_elem() {
        tokio::run_async(async {
            let repo = create_mock_repo();
            let dag = IpldDag::new(repo);
            let data = Ipld::Array(vec![Ipld::U64(1), Ipld::Array(vec![Ipld::U64(2)]), Ipld::U64(3)]);
            let path = await!(dag.put(data.clone(), Codec::DagCBOR)).unwrap();
            let res = await!(dag.get(path.sub_path("1/0").unwrap())).unwrap();
            assert_eq!(res, Ipld::U64(2));
        });
    }

    #[test]
    fn test_resolve_object_elem() {
        tokio::run_async(async {
            let repo = create_mock_repo();
            let dag = IpldDag::new(repo);
            let mut data = HashMap::new();
            data.insert("key", false);
            let path = await!(dag.put(data.into(), Codec::DagCBOR)).unwrap();
            let res = await!(dag.get(path.sub_path("key").unwrap())).unwrap();
            assert_eq!(res, Ipld::Bool(false));
        });
    }

    #[test]
    fn test_resolve_cid_elem() {
        tokio::run_async(async {
            let repo = create_mock_repo();
            let dag = IpldDag::new(repo);
            let data1 = vec![1].into();
            let path1 = await!(dag.put(data1, Codec::DagCBOR)).unwrap();
            let data2 = vec![path1.root().to_owned()].into();
            let path = await!(dag.put(data2, Codec::DagCBOR)).unwrap();
            let res = await!(dag.get(path.sub_path("0/0").unwrap())).unwrap();
            assert_eq!(res, Ipld::U64(1));
        });
    }
}

'''
'''--- ipfstools/src/ipld/error.rs ---
use cid::Codec;

#[derive(Debug)]
pub enum IpldError {
    UnsupportedCodec(Codec),
}

impl std::error::Error for IpldError {
    fn description(&self) -> &str {
        match *self {
            IpldError::UnsupportedCodec(_) => "unsupported codec",
        }
    }
}

impl std::fmt::Display for IpldError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match *self {
            IpldError::UnsupportedCodec(ref codec) => {
                write!(f, "Unsupported codec {:?}", codec)
            }
        }
    }
}

'''
'''--- ipfstools/src/ipld/formats/cbor.rs ---
use cbor::{Cbor, Decoder, Encoder};
pub use cbor::{CborBytes, CborTagEncode, CborError, ReadError};
use cid::Prefix;
use crate::block::Cid;
use crate::error::Error;
use crate::ipld::Ipld;
use rustc_serialize::{Encodable, Encoder as RustcEncoder};

pub(crate) const PREFIX: Prefix = Prefix {
    version: cid::Version::V1,
    codec: cid::Codec::DagCBOR,
    mh_type: multihash::Hash::SHA2256,
    mh_len: 32,
};

pub(crate) fn decode(bytes: Vec<u8>) -> Result<Ipld, Error> {
    let mut d = Decoder::from_bytes(bytes);
    let cbor: Cbor = d.read_data_item(None)?;
    cbor_to_ipld(cbor)
}

pub(crate) fn encode(data: &Ipld) -> Result<Vec<u8>, Error> {
    let mut e = Encoder::from_memory();
    data.encode(&mut e)?;
    Ok(e.as_bytes().to_owned())
}

fn cbor_to_ipld(cbor: Cbor) -> Result<Ipld, Error> {
    let ipld = match cbor {
        Cbor::Break => {
            let err = ReadError::Other("Break.".into());
            return Err(CborError::Decode(err).into())
        }
        Cbor::Undefined => Ipld::Null,
        Cbor::Null => Ipld::Null,
        Cbor::Bool(b) => Ipld::Bool(b),
        Cbor::Unsigned(u) => Ipld::U64(u.into_u64()),
        Cbor::Signed(i) => Ipld::I64(i.into_i64()),
        Cbor::Float(f) => Ipld::F64(f.into_f64()),
        Cbor::Bytes(bytes) => Ipld::Bytes(bytes.0),
        Cbor::Unicode(string) => Ipld::String(string),
        Cbor::Array(vec) => {
            let ipld_vec = vec.into_iter()
                .map(|item| cbor_to_ipld(item))
                .collect::<Result<_, _>>()?;
            Ipld::Array(ipld_vec)
        }
        Cbor::Map(map) => {
            let ipld_map = map.into_iter()
                .map(|(k, v)| {
                    Ok((k, cbor_to_ipld(v)?))
                })
                .collect::<Result<_, Error>>()?;
            Ipld::Object(ipld_map)
        }
        Cbor::Tag(tag) => {
            if tag.tag == 42 {
                if let Cbor::Bytes(bytes) = *tag.data {
                    Ipld::Link(Cid::from(bytes.0)?.into())
                } else {
                    println!("{:?}", *tag.data);
                    let err = ReadError::Other("Invalid CID.".into());
                    return Err(CborError::Decode(err).into())
                }
            } else {
                let err = ReadError::Other("Unknown tag {}.".into());
                return Err(CborError::Decode(err).into())
            }
        }
    };
    Ok(ipld)
}

impl Encodable for Ipld {
    fn encode<E: RustcEncoder>(&self, e: &mut E) -> Result<(), E::Error> {
        match *self {
            Ipld::U64(ref u) => {
                u.encode(e)
            }
            Ipld::I64(ref i) => {
                i.encode(e)
            }
            Ipld::Bytes(ref bytes) => {
                cbor::CborBytes(bytes.to_owned()).encode(e)
            }
            Ipld::String(ref string) => {
                string.encode(e)
            }
            Ipld::Array(ref vec) => {
                vec.encode(e)
            }
            Ipld::Object(ref map) => {
                map.encode(e)
            }
            Ipld::F64(f) => {
                f.encode(e)
            },
            Ipld::Bool(b) => {
                b.encode(e)
            },
            Ipld::Null => {
                e.emit_nil()
            },
            Ipld::Link(ref root) => {
                let bytes = cbor::CborBytes(root.to_bytes());
                cbor::CborTagEncode::new(42, &bytes).encode(e)
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::block::Block;

    #[test]
    fn test_encode_decode() {
        let data = Ipld::Array(vec![Ipld::U64(1), Ipld::U64(2), Ipld::U64(3)]);
        let bytes = encode(&data).unwrap();
        let data2 = decode(bytes).unwrap();
        assert_eq!(data, data2);
    }

    #[test]
    fn test_cid_encode_decode() {
        let cid = Block::from("hello").cid().to_owned();
        let data = Ipld::Link(cid.into());
        let bytes = encode(&data).unwrap();
        let data2 = decode(bytes).unwrap();
        assert_eq!(data, data2);
    }
}

'''
'''--- ipfstools/src/ipld/formats/mod.rs ---
pub mod cbor;
pub mod pb;

'''
'''--- ipfstools/src/ipld/formats/pb/dag_pb.rs ---
// This file is generated by rust-protobuf 2.0.2. Do not edit
// @generated

// https://github.com/Manishearth/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy)]

#![cfg_attr(rustfmt, rustfmt_skip)]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unsafe_code)]
#![allow(unused_imports)]
#![allow(unused_results)]

use protobuf::Message as Message_imported_for_functions;
use protobuf::ProtobufEnum as ProtobufEnum_imported_for_functions;

#[derive(PartialEq,Clone,Default)]
pub struct PBLink {
    // message fields
    pub Hash: ::std::vec::Vec<u8>,
    pub Name: ::std::string::String,
    pub Tsize: u64,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl PBLink {
    pub fn new() -> PBLink {
        ::std::default::Default::default()
    }

    // bytes Hash = 1;

    pub fn clear_Hash(&mut self) {
        self.Hash.clear();
    }

    // Param is passed by value, moved
    pub fn set_Hash(&mut self, v: ::std::vec::Vec<u8>) {
        self.Hash = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_Hash(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.Hash
    }

    // Take field
    pub fn take_Hash(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.Hash, ::std::vec::Vec::new())
    }

    pub fn get_Hash(&self) -> &[u8] {
        &self.Hash
    }

    // string Name = 2;

    pub fn clear_Name(&mut self) {
        self.Name.clear();
    }

    // Param is passed by value, moved
    pub fn set_Name(&mut self, v: ::std::string::String) {
        self.Name = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_Name(&mut self) -> &mut ::std::string::String {
        &mut self.Name
    }

    // Take field
    pub fn take_Name(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.Name, ::std::string::String::new())
    }

    pub fn get_Name(&self) -> &str {
        &self.Name
    }

    // uint64 Tsize = 3;

    pub fn clear_Tsize(&mut self) {
        self.Tsize = 0;
    }

    // Param is passed by value, moved
    pub fn set_Tsize(&mut self, v: u64) {
        self.Tsize = v;
    }

    pub fn get_Tsize(&self) -> u64 {
        self.Tsize
    }
}

impl ::protobuf::Message for PBLink {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.Hash)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.Name)?;
                },
                3 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_uint64()?;
                    self.Tsize = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.Hash.is_empty() {
            my_size += ::protobuf::rt::bytes_size(1, &self.Hash);
        }
        if !self.Name.is_empty() {
            my_size += ::protobuf::rt::string_size(2, &self.Name);
        }
        if self.Tsize != 0 {
            my_size += ::protobuf::rt::value_size(3, self.Tsize, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if !self.Hash.is_empty() {
            os.write_bytes(1, &self.Hash)?;
        }
        if !self.Name.is_empty() {
            os.write_string(2, &self.Name)?;
        }
        if self.Tsize != 0 {
            os.write_uint64(3, self.Tsize)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> PBLink {
        PBLink::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "Hash",
                    |m: &PBLink| { &m.Hash },
                    |m: &mut PBLink| { &mut m.Hash },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                    "Name",
                    |m: &PBLink| { &m.Name },
                    |m: &mut PBLink| { &mut m.Name },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeUint64>(
                    "Tsize",
                    |m: &PBLink| { &m.Tsize },
                    |m: &mut PBLink| { &mut m.Tsize },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<PBLink>(
                    "PBLink",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static PBLink {
        static mut instance: ::protobuf::lazy::Lazy<PBLink> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const PBLink,
        };
        unsafe {
            instance.get(PBLink::new)
        }
    }
}

impl ::protobuf::Clear for PBLink {
    fn clear(&mut self) {
        self.clear_Hash();
        self.clear_Name();
        self.clear_Tsize();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for PBLink {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for PBLink {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct PBNode {
    // message fields
    pub Links: ::protobuf::RepeatedField<PBLink>,
    pub Data: ::std::vec::Vec<u8>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl PBNode {
    pub fn new() -> PBNode {
        ::std::default::Default::default()
    }

    // repeated .PBLink Links = 2;

    pub fn clear_Links(&mut self) {
        self.Links.clear();
    }

    // Param is passed by value, moved
    pub fn set_Links(&mut self, v: ::protobuf::RepeatedField<PBLink>) {
        self.Links = v;
    }

    // Mutable pointer to the field.
    pub fn mut_Links(&mut self) -> &mut ::protobuf::RepeatedField<PBLink> {
        &mut self.Links
    }

    // Take field
    pub fn take_Links(&mut self) -> ::protobuf::RepeatedField<PBLink> {
        ::std::mem::replace(&mut self.Links, ::protobuf::RepeatedField::new())
    }

    pub fn get_Links(&self) -> &[PBLink] {
        &self.Links
    }

    // bytes Data = 1;

    pub fn clear_Data(&mut self) {
        self.Data.clear();
    }

    // Param is passed by value, moved
    pub fn set_Data(&mut self, v: ::std::vec::Vec<u8>) {
        self.Data = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_Data(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.Data
    }

    // Take field
    pub fn take_Data(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.Data, ::std::vec::Vec::new())
    }

    pub fn get_Data(&self) -> &[u8] {
        &self.Data
    }
}

impl ::protobuf::Message for PBNode {
    fn is_initialized(&self) -> bool {
        for v in &self.Links {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                2 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.Links)?;
                },
                1 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.Data)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.Links {
            let len = value.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if !self.Data.is_empty() {
            my_size += ::protobuf::rt::bytes_size(1, &self.Data);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        for v in &self.Links {
            os.write_tag(2, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if !self.Data.is_empty() {
            os.write_bytes(1, &self.Data)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> PBNode {
        PBNode::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<PBLink>>(
                    "Links",
                    |m: &PBNode| { &m.Links },
                    |m: &mut PBNode| { &mut m.Links },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "Data",
                    |m: &PBNode| { &m.Data },
                    |m: &mut PBNode| { &mut m.Data },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<PBNode>(
                    "PBNode",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static PBNode {
        static mut instance: ::protobuf::lazy::Lazy<PBNode> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const PBNode,
        };
        unsafe {
            instance.get(PBNode::new)
        }
    }
}

impl ::protobuf::Clear for PBNode {
    fn clear(&mut self) {
        self.clear_Links();
        self.clear_Data();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for PBNode {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for PBNode {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n\x20src/ipld/formats/pb/dag_pb.proto\"F\n\x06PBLink\x12\x12\n\x04Hash\
    \x18\x01\x20\x01(\x0cR\x04Hash\x12\x12\n\x04Name\x18\x02\x20\x01(\tR\x04\
    Name\x12\x14\n\x05Tsize\x18\x03\x20\x01(\x04R\x05Tsize\";\n\x06PBNode\
    \x12\x1d\n\x05Links\x18\x02\x20\x03(\x0b2\x07.PBLinkR\x05Links\x12\x12\n\
    \x04Data\x18\x01\x20\x01(\x0cR\x04DataJ\xf6\x04\n\x06\x12\x04\0\0\x12\
    \x01\n\x08\n\x01\x0c\x12\x03\0\0\x12\n$\n\x02\x04\0\x12\x04\x03\0\n\x01\
    \x1a\x18\x20An\x20IPFS\x20MerkleDAG\x20Link\n\n\n\n\x03\x04\0\x01\x12\
    \x03\x03\x08\x0e\n-\n\x04\x04\0\x02\0\x12\x03\x05\x02\x11\x1a\x20\x20mul\
    tihash\x20of\x20the\x20target\x20object\n\n\r\n\x05\x04\0\x02\0\x04\x12\
    \x04\x05\x02\x03\x10\n\x0c\n\x05\x04\0\x02\0\x05\x12\x03\x05\x02\x07\n\
    \x0c\n\x05\x04\0\x02\0\x01\x12\x03\x05\x08\x0c\n\x0c\n\x05\x04\0\x02\0\
    \x03\x12\x03\x05\x0f\x10\n;\n\x04\x04\0\x02\x01\x12\x03\x07\x02\x12\x1a.\
    \x20utf\x20string\x20name.\x20should\x20be\x20unique\x20per\x20object\n\
    \n\r\n\x05\x04\0\x02\x01\x04\x12\x04\x07\x02\x05\x11\n\x0c\n\x05\x04\0\
    \x02\x01\x05\x12\x03\x07\x02\x08\n\x0c\n\x05\x04\0\x02\x01\x01\x12\x03\
    \x07\t\r\n\x0c\n\x05\x04\0\x02\x01\x03\x12\x03\x07\x10\x11\n/\n\x04\x04\
    \0\x02\x02\x12\x03\t\x02\x13\x1a\"\x20cumulative\x20size\x20of\x20target\
    \x20object\n\n\r\n\x05\x04\0\x02\x02\x04\x12\x04\t\x02\x07\x12\n\x0c\n\
    \x05\x04\0\x02\x02\x05\x12\x03\t\x02\x08\n\x0c\n\x05\x04\0\x02\x02\x01\
    \x12\x03\t\t\x0e\n\x0c\n\x05\x04\0\x02\x02\x03\x12\x03\t\x11\x12\n$\n\
    \x02\x04\x01\x12\x04\r\0\x12\x01\x1a\x18\x20An\x20IPFS\x20MerkleDAG\x20N\
    ode\n\n\n\n\x03\x04\x01\x01\x12\x03\r\x08\x0e\n$\n\x04\x04\x01\x02\0\x12\
    \x03\x0f\x02\x1c\x1a\x17\x20refs\x20to\x20other\x20objects\n\n\x0c\n\x05\
    \x04\x01\x02\0\x04\x12\x03\x0f\x02\n\n\x0c\n\x05\x04\x01\x02\0\x06\x12\
    \x03\x0f\x0b\x11\n\x0c\n\x05\x04\x01\x02\0\x01\x12\x03\x0f\x12\x17\n\x0c\
    \n\x05\x04\x01\x02\0\x03\x12\x03\x0f\x1a\x1b\n\x1f\n\x04\x04\x01\x02\x01\
    \x12\x03\x11\x02\x11\x1a\x12\x20opaque\x20user\x20data\n\n\r\n\x05\x04\
    \x01\x02\x01\x04\x12\x04\x11\x02\x0f\x1c\n\x0c\n\x05\x04\x01\x02\x01\x05\
    \x12\x03\x11\x02\x07\n\x0c\n\x05\x04\x01\x02\x01\x01\x12\x03\x11\x08\x0c\
    \n\x0c\n\x05\x04\x01\x02\x01\x03\x12\x03\x11\x0f\x10b\x06proto3\
";

static mut file_descriptor_proto_lazy: ::protobuf::lazy::Lazy<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::lazy::Lazy {
    lock: ::protobuf::lazy::ONCE_INIT,
    ptr: 0 as *const ::protobuf::descriptor::FileDescriptorProto,
};

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    unsafe {
        file_descriptor_proto_lazy.get(|| {
            parse_descriptor_proto()
        })
    }
}

'''
'''--- ipfstools/src/ipld/formats/pb/mod.rs ---
use crate::block::Cid;
use crate::error::Error;
use crate::ipld::Ipld;
use crate::path::PathRoot;
use cid::Prefix;
use protobuf::Message;
use std::collections::HashMap;
use std::convert::{TryFrom, TryInto};

mod dag_pb;

pub(crate) const PREFIX: Prefix = Prefix {
    version: cid::Version::V0,
    codec: cid::Codec::DagProtobuf,
    mh_type: multihash::Hash::SHA2256,
    mh_len: 32,
};

pub(crate) fn decode(bytes: &Vec<u8>) -> Result<Ipld, Error> {
    Ok(PbNode::from_bytes(bytes)?.into())
}

pub(crate) fn encode(data: Ipld) -> Result<Vec<u8>, Error> {
    let pb_node: PbNode = match data.to_owned().try_into() {
        Ok(pb_node) => pb_node,
        Err(_) => bail!("ipld data is not compatible with dag_pb format"),
    };
    Ok(pb_node.into_bytes())
}

pub(crate) struct PbLink {
    pub cid: PathRoot,
    pub name: String,
    pub size: u64,
}

pub(crate) struct PbNode {
    pub links: Vec<PbLink>,
    pub data: Vec<u8>,
}

impl PbNode {
    fn from_bytes(bytes: &Vec<u8>) -> Result<Self, Error> {
        let proto: dag_pb::PBNode = protobuf::parse_from_bytes(bytes)?;
        let data = proto.get_Data().to_vec();
        let mut links = Vec::new();
        for link in proto.get_Links() {
            let cid = Cid::from(link.get_Hash())?.into();
            let name = link.get_Name().to_string();
            let size = link.get_Tsize();
            links.push(PbLink {
                cid,
                name,
                size,
            });
        }
        Ok(PbNode {
            links,
            data,
        })
    }

    fn into_bytes(self) -> Vec<u8> {
        let mut proto = dag_pb::PBNode::new();
        proto.set_Data(self.data);
        for link in self.links {
            let mut pb_link = dag_pb::PBLink::new();
            pb_link.set_Hash(link.cid.to_bytes());
            pb_link.set_Name(link.name);
            pb_link.set_Tsize(link.size);
            proto.mut_Links().push(pb_link);
        }
        proto
            .write_to_bytes()
            .expect("there is no situation in which the protobuf message can be invalid")
    }
}

impl Into<Ipld> for PbNode {
    fn into(self) -> Ipld {
        let mut map = HashMap::<&str, Ipld>::new();
        map.insert("Links", self.links.into());
        map.insert("Data", self.data.into());
        map.into()
    }
}

impl Into<Ipld> for PbLink {
    fn into(self) -> Ipld {
        let mut map = HashMap::<&str, Ipld>::new();
        map.insert("Hash", self.cid.into());
        map.insert("Name", self.name.into());
        map.insert("Tsize", self.size.into());
        map.into()
    }
}

impl TryFrom<Ipld> for PbNode {
    type Error = std::option::NoneError;

    fn try_from(ipld: Ipld) -> Result<PbNode, Self::Error> {
        match ipld {
            Ipld::Object(mut map) => {
                let links: Vec<Ipld> = map.remove("Links")?.try_into()?;
                let links: Vec<PbLink> = links.into_iter()
                    .map(|link| link.try_into()).collect::<Result<_, Self::Error>>()?;
                let data: Vec<u8> = map.remove("Data")?.try_into()?;
                Ok(PbNode {
                    links,
                    data,
                })
            }
            _ => None?
        }
    }
}

impl TryFrom<Ipld> for PbLink {
    type Error = std::option::NoneError;

    fn try_from(ipld: Ipld) -> Result<PbLink, Self::Error> {
        match ipld {
            Ipld::Object(mut map) => {
                let cid: PathRoot = map.remove("Hash")?.try_into()?;
                let name: String = map.remove("Name")?.try_into()?;
                let size: u64 = map.remove("Tsize")?.try_into()?;
                Ok(PbLink {
                    cid,
                    name,
                    size,
                })
            }
            _ => None?
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_encode_decode() {
        //let pb_link = HashMap::<&str, Ipld>::new();
        //pb_link.insert("Hash", Cid::from());
        //pb_link.insert("Tsize", 13.into());

        let links: Vec<Ipld> = vec![];
        let mut pb_node = HashMap::<&str, Ipld>::new();
        pb_node.insert("Data", "Here is some data\n".as_bytes().to_vec().into());
        pb_node.insert("Links", links.into());
        let data: Ipld = pb_node.into();

        let bytes = encode(data.clone()).unwrap();
        let data2 = decode(&bytes).unwrap();
        assert_eq!(data, data2);
    }
}

'''
'''--- ipfstools/src/ipld/ipld.rs ---
use crate::block::{Block, Cid};
use crate::error::Error;
use crate::ipld::{formats, IpldError};
use crate::path::{IpfsPath, PathRoot};
use cid::Codec;
use std::collections::HashMap;
use std::convert::TryInto;

/// An enum over all possible IPLD types.
#[derive(Clone, Debug, PartialEq)]
pub enum Ipld {
    /// Represents an unsigned integer.
    U64(u64),
    /// Represents a signed integer.
    I64(i64),
    /// Represents a byte string.
    Bytes(Vec<u8>),
    /// Represents an UTF-8 string.
    String(String),
    /// Represents a list.
    Array(Vec<Ipld>),
    /// Represents a map.
    Object(HashMap<String, Ipld>),
    /// Represents a floating point value.
    F64(f64),
    /// Represents a boolean value.
    Bool(bool),
    /// Represents the absence of a value or the value undefined.
    Null,
    /// Represents a link to an Ipld node
    Link(PathRoot),
}

impl Ipld {
    pub fn to_block(&self, codec: Codec) -> Result<Block, Error> {
        let (prefix, bytes) = match codec {
            Codec::DagCBOR => {
                (
                    formats::cbor::PREFIX,
                    formats::cbor::encode(&self)?,
                )
            }
            Codec::DagProtobuf => {
                (
                    formats::pb::PREFIX,
                    formats::pb::encode(self.to_owned())?,
                )
            }
            codec => return Err(IpldError::UnsupportedCodec(codec).into()),
        };
        let cid = cid::Cid::new_from_prefix(&prefix, &bytes);
        Ok(Block::new(bytes, cid))
    }

    pub fn to_dag_cbor(&self) -> Result<Block, Error> {
        self.to_block(Codec::DagCBOR)
    }

    pub fn to_dag_pb(&self) -> Result<Block, Error> {
        self.to_block(Codec::DagProtobuf)
    }

    pub fn from(block: &Block) -> Result<Self, Error> {
        let data = match block.cid().prefix().codec {
            Codec::DagCBOR => {
                formats::cbor::decode(block.data().to_owned())?
            }
            Codec::DagProtobuf => {
                formats::pb::decode(block.data())?
            }
            codec => return Err(IpldError::UnsupportedCodec(codec).into()),
        };
        Ok(data)
    }
}

impl From<u32> for Ipld {
    fn from(u: u32) -> Self {
        Ipld::U64(u as u64)
    }
}

impl From<u64> for Ipld {
    fn from(u: u64) -> Self {
        Ipld::U64(u)
    }
}

impl From<i32> for Ipld {
    fn from(i: i32) -> Self {
        Ipld::I64(i as i64)
    }
}

impl From<i64> for Ipld {
    fn from(i: i64) -> Self {
        Ipld::I64(i)
    }
}

impl From<Vec<u8>> for Ipld {
    fn from(bytes: Vec<u8>) -> Self {
        Ipld::Bytes(bytes)
    }
}

impl From<String> for Ipld {
    fn from(string: String) -> Self {
        Ipld::String(string)
    }
}

impl From<&str> for Ipld {
    fn from(string: &str) -> Self {
        Ipld::String(string.to_string())
    }
}

impl<T: Into<Ipld>> From<Vec<T>> for Ipld {
    fn from(vec: Vec<T>) -> Self {
        Ipld::Array(vec.into_iter().map(|ipld| ipld.into()).collect())
    }
}

impl<T: Into<Ipld>> From<HashMap<String, T>> for Ipld {
    fn from(map: HashMap<String, T>) -> Self {
        Ipld::Object(map.into_iter().map(|(k, v)| (k, v.into())).collect())
    }
}

impl<T: Into<Ipld>> From<HashMap<&str, T>> for Ipld {
    fn from(map: HashMap<&str, T>) -> Self {
        Ipld::Object(map.into_iter().map(|(k, v)| (k.to_string(), v.into())).collect())
    }
}

impl From<f64> for Ipld {
    fn from(f: f64) -> Self {
        Ipld::F64(f)
    }
}

impl From<bool> for Ipld {
    fn from(b: bool) -> Self {
        Ipld::Bool(b)
    }
}

impl From<Cid> for Ipld {
    fn from(cid: Cid) -> Self {
        Ipld::Link(cid.into())
    }
}

impl From<PathRoot> for Ipld {
    fn from(root: PathRoot) -> Self {
        Ipld::Link(root)
    }
}

impl From<IpfsPath> for Ipld {
    fn from(path: IpfsPath) -> Self {
        Ipld::Link(path.root().to_owned())
    }
}

impl TryInto<u64> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<u64, Self::Error> {
        match self {
            Ipld::U64(u) => Ok(u),
            _ => Err(None?)
        }
    }
}

impl TryInto<i64> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<i64, Self::Error> {
        match self {
            Ipld::I64(i) => Ok(i),
            _ => Err(None?)
        }
    }
}

impl TryInto<Vec<u8>> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<Vec<u8>, Self::Error> {
        match self {
            Ipld::Bytes(bytes) => Ok(bytes),
            _ => Err(None?)
        }
    }
}

impl TryInto<String> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<String, Self::Error> {
        match self {
            Ipld::String(string) => Ok(string),
            _ => Err(None?)
        }
    }
}

impl TryInto<Vec<Ipld>> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<Vec<Ipld>, Self::Error> {
        match self {
            Ipld::Array(vec) => Ok(vec),
            _ => Err(None?)
        }
    }
}

impl TryInto<HashMap<String, Ipld>> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<HashMap<String, Ipld>, Self::Error> {
        match self {
            Ipld::Object(map) => Ok(map),
            _ => Err(None?)
        }
    }
}

impl TryInto<f64> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<f64, Self::Error> {
        match self {
            Ipld::F64(f) => Ok(f),
            _ => Err(None?)
        }
    }
}

impl TryInto<bool> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<bool, Self::Error> {
        match self {
            Ipld::Bool(b) => Ok(b),
            _ => Err(None?)
        }
    }
}

impl TryInto<PathRoot> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<PathRoot, Self::Error> {
        match self {
            Ipld::Link(root) => Ok(root),
            _ => Err(None?)
        }
    }
}

impl TryInto<Cid> for Ipld {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<Cid, Self::Error> {
        match self {
            Ipld::Link(root) => root.try_into(),
            _ => Err(None?)
        }
    }
}

'''
'''--- ipfstools/src/ipld/mod.rs ---
pub mod dag;
pub mod error;
pub mod formats;
pub mod ipld;

pub use self::dag::IpldDag;
pub use self::error::IpldError;
pub use self::ipld::Ipld;

'''
'''--- ipfstools/src/ipns/dns.rs ---
use crate::error::Error;
use crate::path::IpfsPath;
use domain::core::bits::{Dname, Question};
use domain::core::iana::Rtype;
use domain::core::rdata::Txt;
use domain::resolv::{Resolver, StubResolver};
use domain::resolv::stub::resolver::Query;
use std::future::Future;
use std::pin::Pin;
use std::task::{Poll, Waker};
use std::str::FromStr;
use tokio::prelude::{Async, Future as FutureOld, future::SelectOk, future::select_ok};

#[derive(Debug, Fail)]
#[fail(display = "no dnslink entry")]
pub struct DnsLinkError;

pub struct DnsLinkFuture {
    query: SelectOk<Query>,
}

impl Future for DnsLinkFuture {
    type Output = Result<IpfsPath, Error>;

    fn poll(self: Pin<&mut Self>, _waker: &Waker) -> Poll<Self::Output> {
        let _self = self.get_mut();
        loop {
            let poll = _self.query.poll();
            if poll.is_err() {
                return Poll::Ready(Err(DnsLinkError.into()));
            }
            match poll.unwrap() {
                Async::Ready((answer, rest)) => {
                    for record in answer.answer()?.limit_to::<Txt>() {
                        let txt = record?;
                        let bytes = txt.data().text();
                        let string = String::from_utf8_lossy(&bytes).to_string();
                        if string.starts_with("dnslink=") {
                            let path = IpfsPath::from_str(&string[8..])?;
                            return Poll::Ready(Ok(path));
                        }
                    }
                    if rest.len() > 0 {
                        _self.query = select_ok(rest);
                    } else {
                        return Poll::Ready(Err(DnsLinkError.into()))
                    }
                }
                Async::NotReady => return Poll::Pending,
            }
        }
    }
}

pub fn resolve(domain: &str) -> Result<DnsLinkFuture, Error> {
    let mut dnslink = "_dnslink.".to_string();
    dnslink.push_str(domain);
    let qname = Dname::from_str(&dnslink[9..])?;
    let question = Question::new_in(qname, Rtype::Txt);
    let query1 = StubResolver::new().query(question);

    let qname = Dname::from_str(&dnslink)?;
    let question = Question::new_in(qname, Rtype::Txt);
    let query2 = StubResolver::new().query(question);

    Ok(DnsLinkFuture {
        query: select_ok(vec![query1, query2]),
    })
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_resolve1() {
        tokio::run_async(async {
            let res = await!(resolve("ipfs.io").unwrap()).unwrap().to_string();
            assert_eq!(res, "/ipns/website.ipfs.io");
        })
    }

    fn test_resolve2() {
        tokio::run_async(async {
            let res = await!(resolve("website.ipfs.io").unwrap()).unwrap().to_string();
            assert_eq!(res, "/ipfs/QmYfHCcUQBjyvrLfQ8Cnt2YAEiLDNRqMXAeHndM6fDW8yB");
        })
    }
}

'''
'''--- ipfstools/src/ipns/entry.rs ---
use crate::error::Error;
use crate::ipns::ipns_pb as proto;
use crate::path::IpfsPath;
use byteorder::{BigEndian, ReadBytesExt, WriteBytesExt};
use libp2p::core::PublicKey;
use libp2p::secio::SecioKeyPair;
use protobuf::{self, ProtobufError, Message as ProtobufMessage};
use std::time::{Duration, SystemTime};

#[derive(Clone, Debug, PartialEq)]
pub struct IpnsEntry {
    value: String,
    seq: u64,
    validity: SystemTime,
    public_key: PublicKey,
    signature: Vec<u8>,
}

impl IpnsEntry {
    pub fn new(value: String, seq: u64, ttl: Duration, key: &SecioKeyPair) -> Self {
        let validity = SystemTime::now() + ttl;
        let public_key = key.to_public_key();
        let signature = IpnsEntry::sign(&validity, &value, &key);
        IpnsEntry {
            value,
            seq,
            validity,
            public_key,
            signature,
        }
    }

    pub fn seq(&self) -> u64 {
        self.seq
    }

    pub fn from_path(path: &IpfsPath, seq: u64, key: &SecioKeyPair) -> Self {
        let value = path.to_string();
        // TODO what is a reasonable default?
        let ttl = Duration::new(1, 0);
        IpnsEntry::new(value, seq, ttl, key)
    }

    fn sign(_validity: &SystemTime, _value: &String, _key: &SecioKeyPair) -> Vec<u8> {
        // TODO
        Vec::new()
    }

    pub fn to_bytes(&self) -> Vec<u8> {
        let mut proto = proto::IpnsEntry::new();
        proto.set_value(self.value.as_bytes().to_vec());
        proto.set_sequence(self.seq);
        let nanos = self.validity
            .duration_since(SystemTime::UNIX_EPOCH)
            .unwrap()
            .as_nanos();
        let mut validity = vec![];
        validity.write_u64::<BigEndian>(nanos as u64).unwrap();
        proto.set_validityType(proto::IpnsEntry_ValidityType::EOL);
        proto.set_validity(validity);
        proto.set_signature(self.signature.clone());
        proto.set_pubKey(self.public_key.clone().into_protobuf_encoding());
        proto
            .write_to_bytes()
            .expect("there is no situation in which the protobuf message can be invalid")
    }

    pub fn from_bytes(bytes: &Vec<u8>) -> Result<Self, ProtobufError> {
        let proto: proto::IpnsEntry = protobuf::parse_from_bytes(bytes)?;
        let value = String::from_utf8_lossy(proto.get_value()).to_string();
        let public_key = PublicKey::from_protobuf_encoding(proto.get_pubKey())?;
        let nanos = proto.get_validity().read_u64::<BigEndian>()?;
        let validity = SystemTime::UNIX_EPOCH + Duration::from_nanos(nanos);
        let ipns = IpnsEntry {
            value,
            seq: proto.get_sequence(),
            validity,
            signature: proto.get_signature().to_vec(),
            public_key,
        };
        Ok(ipns)
    }

    pub fn is_valid(&self) -> bool {
        // TODO
        true
    }

    pub fn resolve(&self) -> Result<IpfsPath, Error> {
        IpfsPath::from_str(&self.value)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_valid() {
        let value = "/ipfs/".into();
        let duration = Duration::new(1, 0);
        let key = SecioKeyPair::ed25519_generated().unwrap();
        let ipns = IpnsEntry::new(value, 0, duration, &key);
        assert!(ipns.is_valid());
    }

    #[test]
    fn test_to_from_bytes() {
        let value = "/ipfs/".into();
        let duration = Duration::new(1, 0);
        let key = SecioKeyPair::ed25519_generated().unwrap();
        let ipns = IpnsEntry::new(value, 0, duration, &key);
        let bytes = ipns.to_bytes();
        let ipns2 = IpnsEntry::from_bytes(&bytes).unwrap();
        assert_eq!(ipns, ipns2);
    }

    #[test]
    fn test_from_path() {
        let key = SecioKeyPair::ed25519_generated().unwrap();
        let path = IpfsPath::from_str("/ipfs/QmUJPTFZnR2CPGAzmfdYPghgrFtYFB6pf1BqMvqfiPDam8").unwrap();
        let ipns = IpnsEntry::from_path(&path, 0, &key);
        assert_eq!(path, ipns.resolve().unwrap());
    }
}

'''
'''--- ipfstools/src/ipns/ipns_pb.rs ---
// This file is generated by rust-protobuf 2.0.2. Do not edit
// @generated

// https://github.com/Manishearth/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy)]

#![cfg_attr(rustfmt, rustfmt_skip)]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unsafe_code)]
#![allow(unused_imports)]
#![allow(unused_results)]

use protobuf::Message as Message_imported_for_functions;
use protobuf::ProtobufEnum as ProtobufEnum_imported_for_functions;

#[derive(PartialEq,Clone,Default)]
pub struct IpnsEntry {
    // message fields
    pub value: ::std::vec::Vec<u8>,
    pub signature: ::std::vec::Vec<u8>,
    pub validityType: IpnsEntry_ValidityType,
    pub validity: ::std::vec::Vec<u8>,
    pub sequence: u64,
    pub ttl: u64,
    pub pubKey: ::std::vec::Vec<u8>,
    // special fields
    unknown_fields: ::protobuf::UnknownFields,
    cached_size: ::protobuf::CachedSize,
}

impl IpnsEntry {
    pub fn new() -> IpnsEntry {
        ::std::default::Default::default()
    }

    // bytes value = 1;

    pub fn clear_value(&mut self) {
        self.value.clear();
    }

    // Param is passed by value, moved
    pub fn set_value(&mut self, v: ::std::vec::Vec<u8>) {
        self.value = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_value(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.value
    }

    // Take field
    pub fn take_value(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.value, ::std::vec::Vec::new())
    }

    pub fn get_value(&self) -> &[u8] {
        &self.value
    }

    // bytes signature = 2;

    pub fn clear_signature(&mut self) {
        self.signature.clear();
    }

    // Param is passed by value, moved
    pub fn set_signature(&mut self, v: ::std::vec::Vec<u8>) {
        self.signature = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_signature(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.signature
    }

    // Take field
    pub fn take_signature(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.signature, ::std::vec::Vec::new())
    }

    pub fn get_signature(&self) -> &[u8] {
        &self.signature
    }

    // .IpnsEntry.ValidityType validityType = 3;

    pub fn clear_validityType(&mut self) {
        self.validityType = IpnsEntry_ValidityType::EOL;
    }

    // Param is passed by value, moved
    pub fn set_validityType(&mut self, v: IpnsEntry_ValidityType) {
        self.validityType = v;
    }

    pub fn get_validityType(&self) -> IpnsEntry_ValidityType {
        self.validityType
    }

    // bytes validity = 4;

    pub fn clear_validity(&mut self) {
        self.validity.clear();
    }

    // Param is passed by value, moved
    pub fn set_validity(&mut self, v: ::std::vec::Vec<u8>) {
        self.validity = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_validity(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.validity
    }

    // Take field
    pub fn take_validity(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.validity, ::std::vec::Vec::new())
    }

    pub fn get_validity(&self) -> &[u8] {
        &self.validity
    }

    // uint64 sequence = 5;

    pub fn clear_sequence(&mut self) {
        self.sequence = 0;
    }

    // Param is passed by value, moved
    pub fn set_sequence(&mut self, v: u64) {
        self.sequence = v;
    }

    pub fn get_sequence(&self) -> u64 {
        self.sequence
    }

    // uint64 ttl = 6;

    pub fn clear_ttl(&mut self) {
        self.ttl = 0;
    }

    // Param is passed by value, moved
    pub fn set_ttl(&mut self, v: u64) {
        self.ttl = v;
    }

    pub fn get_ttl(&self) -> u64 {
        self.ttl
    }

    // bytes pubKey = 7;

    pub fn clear_pubKey(&mut self) {
        self.pubKey.clear();
    }

    // Param is passed by value, moved
    pub fn set_pubKey(&mut self, v: ::std::vec::Vec<u8>) {
        self.pubKey = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_pubKey(&mut self) -> &mut ::std::vec::Vec<u8> {
        &mut self.pubKey
    }

    // Take field
    pub fn take_pubKey(&mut self) -> ::std::vec::Vec<u8> {
        ::std::mem::replace(&mut self.pubKey, ::std::vec::Vec::new())
    }

    pub fn get_pubKey(&self) -> &[u8] {
        &self.pubKey
    }
}

impl ::protobuf::Message for IpnsEntry {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.value)?;
                },
                2 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.signature)?;
                },
                3 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.validityType, 3, &mut self.unknown_fields)?
                },
                4 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.validity)?;
                },
                5 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_uint64()?;
                    self.sequence = tmp;
                },
                6 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_uint64()?;
                    self.ttl = tmp;
                },
                7 => {
                    ::protobuf::rt::read_singular_proto3_bytes_into(wire_type, is, &mut self.pubKey)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.value.is_empty() {
            my_size += ::protobuf::rt::bytes_size(1, &self.value);
        }
        if !self.signature.is_empty() {
            my_size += ::protobuf::rt::bytes_size(2, &self.signature);
        }
        if self.validityType != IpnsEntry_ValidityType::EOL {
            my_size += ::protobuf::rt::enum_size(3, self.validityType);
        }
        if !self.validity.is_empty() {
            my_size += ::protobuf::rt::bytes_size(4, &self.validity);
        }
        if self.sequence != 0 {
            my_size += ::protobuf::rt::value_size(5, self.sequence, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.ttl != 0 {
            my_size += ::protobuf::rt::value_size(6, self.ttl, ::protobuf::wire_format::WireTypeVarint);
        }
        if !self.pubKey.is_empty() {
            my_size += ::protobuf::rt::bytes_size(7, &self.pubKey);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream) -> ::protobuf::ProtobufResult<()> {
        if !self.value.is_empty() {
            os.write_bytes(1, &self.value)?;
        }
        if !self.signature.is_empty() {
            os.write_bytes(2, &self.signature)?;
        }
        if self.validityType != IpnsEntry_ValidityType::EOL {
            os.write_enum(3, self.validityType.value())?;
        }
        if !self.validity.is_empty() {
            os.write_bytes(4, &self.validity)?;
        }
        if self.sequence != 0 {
            os.write_uint64(5, self.sequence)?;
        }
        if self.ttl != 0 {
            os.write_uint64(6, self.ttl)?;
        }
        if !self.pubKey.is_empty() {
            os.write_bytes(7, &self.pubKey)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &::std::any::Any {
        self as &::std::any::Any
    }
    fn as_any_mut(&mut self) -> &mut ::std::any::Any {
        self as &mut ::std::any::Any
    }
    fn into_any(self: Box<Self>) -> ::std::boxed::Box<::std::any::Any> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> IpnsEntry {
        IpnsEntry::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::MessageDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::MessageDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                let mut fields = ::std::vec::Vec::new();
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "value",
                    |m: &IpnsEntry| { &m.value },
                    |m: &mut IpnsEntry| { &mut m.value },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "signature",
                    |m: &IpnsEntry| { &m.signature },
                    |m: &mut IpnsEntry| { &mut m.signature },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<IpnsEntry_ValidityType>>(
                    "validityType",
                    |m: &IpnsEntry| { &m.validityType },
                    |m: &mut IpnsEntry| { &mut m.validityType },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "validity",
                    |m: &IpnsEntry| { &m.validity },
                    |m: &mut IpnsEntry| { &mut m.validity },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeUint64>(
                    "sequence",
                    |m: &IpnsEntry| { &m.sequence },
                    |m: &mut IpnsEntry| { &mut m.sequence },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeUint64>(
                    "ttl",
                    |m: &IpnsEntry| { &m.ttl },
                    |m: &mut IpnsEntry| { &mut m.ttl },
                ));
                fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBytes>(
                    "pubKey",
                    |m: &IpnsEntry| { &m.pubKey },
                    |m: &mut IpnsEntry| { &mut m.pubKey },
                ));
                ::protobuf::reflect::MessageDescriptor::new::<IpnsEntry>(
                    "IpnsEntry",
                    fields,
                    file_descriptor_proto()
                )
            })
        }
    }

    fn default_instance() -> &'static IpnsEntry {
        static mut instance: ::protobuf::lazy::Lazy<IpnsEntry> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const IpnsEntry,
        };
        unsafe {
            instance.get(IpnsEntry::new)
        }
    }
}

impl ::protobuf::Clear for IpnsEntry {
    fn clear(&mut self) {
        self.clear_value();
        self.clear_signature();
        self.clear_validityType();
        self.clear_validity();
        self.clear_sequence();
        self.clear_ttl();
        self.clear_pubKey();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for IpnsEntry {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for IpnsEntry {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum IpnsEntry_ValidityType {
    EOL = 0,
}

impl ::protobuf::ProtobufEnum for IpnsEntry_ValidityType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<IpnsEntry_ValidityType> {
        match value {
            0 => ::std::option::Option::Some(IpnsEntry_ValidityType::EOL),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [IpnsEntry_ValidityType] = &[
            IpnsEntry_ValidityType::EOL,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static mut descriptor: ::protobuf::lazy::Lazy<::protobuf::reflect::EnumDescriptor> = ::protobuf::lazy::Lazy {
            lock: ::protobuf::lazy::ONCE_INIT,
            ptr: 0 as *const ::protobuf::reflect::EnumDescriptor,
        };
        unsafe {
            descriptor.get(|| {
                ::protobuf::reflect::EnumDescriptor::new("IpnsEntry_ValidityType", file_descriptor_proto())
            })
        }
    }
}

impl ::std::marker::Copy for IpnsEntry_ValidityType {
}

impl ::std::default::Default for IpnsEntry_ValidityType {
    fn default() -> Self {
        IpnsEntry_ValidityType::EOL
    }
}

impl ::protobuf::reflect::ProtobufValue for IpnsEntry_ValidityType {
    fn as_ref(&self) -> ::protobuf::reflect::ProtobufValueRef {
        ::protobuf::reflect::ProtobufValueRef::Enum(self.descriptor())
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n\x16src/ipns/ipns_pb.proto\"\xf7\x01\n\tIpnsEntry\x12\x14\n\x05value\
    \x18\x01\x20\x01(\x0cR\x05value\x12\x1c\n\tsignature\x18\x02\x20\x01(\
    \x0cR\tsignature\x12;\n\x0cvalidityType\x18\x03\x20\x01(\x0e2\x17.IpnsEn\
    try.ValidityTypeR\x0cvalidityType\x12\x1a\n\x08validity\x18\x04\x20\x01(\
    \x0cR\x08validity\x12\x1a\n\x08sequence\x18\x05\x20\x01(\x04R\x08sequenc\
    e\x12\x10\n\x03ttl\x18\x06\x20\x01(\x04R\x03ttl\x12\x16\n\x06pubKey\x18\
    \x07\x20\x01(\x0cR\x06pubKey\"\x17\n\x0cValidityType\x12\x07\n\x03EOL\
    \x10\0J\xd9\x07\n\x06\x12\x04\0\0\x12\x01\n\x08\n\x01\x0c\x12\x03\0\0\
    \x12\n\n\n\x02\x04\0\x12\x04\x02\0\x12\x01\n\n\n\x03\x04\0\x01\x12\x03\
    \x02\x08\x11\n\x0c\n\x04\x04\0\x04\0\x12\x04\x03\x02\x05\x03\n\x0c\n\x05\
    \x04\0\x04\0\x01\x12\x03\x03\x07\x13\nD\n\x06\x04\0\x04\0\x02\0\x12\x03\
    \x04\x04\x0c\"5\x20setting\x20an\x20EOL\x20says\x20\"this\x20record\x20i\
    s\x20valid\x20until...\"\n\n\x0e\n\x07\x04\0\x04\0\x02\0\x01\x12\x03\x04\
    \x04\x07\n\x0e\n\x07\x04\0\x04\0\x02\0\x02\x12\x03\x04\n\x0b\n\x17\n\x04\
    \x04\0\x02\0\x12\x03\x06\x02\x12\"\n\x20required\n\n\r\n\x05\x04\0\x02\0\
    \x04\x12\x04\x06\x02\x05\x03\n\x0c\n\x05\x04\0\x02\0\x05\x12\x03\x06\x02\
    \x07\n\x0c\n\x05\x04\0\x02\0\x01\x12\x03\x06\x08\r\n\x0c\n\x05\x04\0\x02\
    \0\x03\x12\x03\x06\x10\x11\n\x17\n\x04\x04\0\x02\x01\x12\x03\x07\x02\x16\
    \"\n\x20required\n\n\r\n\x05\x04\0\x02\x01\x04\x12\x04\x07\x02\x06\x12\n\
    \x0c\n\x05\x04\0\x02\x01\x05\x12\x03\x07\x02\x07\n\x0c\n\x05\x04\0\x02\
    \x01\x01\x12\x03\x07\x08\x11\n\x0c\n\x05\x04\0\x02\x01\x03\x12\x03\x07\
    \x14\x15\n\x0b\n\x04\x04\0\x02\x02\x12\x03\x08\x02\x20\n\r\n\x05\x04\0\
    \x02\x02\x04\x12\x04\x08\x02\x07\x16\n\x0c\n\x05\x04\0\x02\x02\x06\x12\
    \x03\x08\x02\x0e\n\x0c\n\x05\x04\0\x02\x02\x01\x12\x03\x08\x0f\x1b\n\x0c\
    \n\x05\x04\0\x02\x02\x03\x12\x03\x08\x1e\x1f\n\x0b\n\x04\x04\0\x02\x03\
    \x12\x03\t\x02\x15\n\r\n\x05\x04\0\x02\x03\x04\x12\x04\t\x02\x08\x20\n\
    \x0c\n\x05\x04\0\x02\x03\x05\x12\x03\t\x02\x07\n\x0c\n\x05\x04\0\x02\x03\
    \x01\x12\x03\t\x08\x10\n\x0c\n\x05\x04\0\x02\x03\x03\x12\x03\t\x13\x14\n\
    \x0b\n\x04\x04\0\x02\x04\x12\x03\n\x02\x16\n\r\n\x05\x04\0\x02\x04\x04\
    \x12\x04\n\x02\t\x15\n\x0c\n\x05\x04\0\x02\x04\x05\x12\x03\n\x02\x08\n\
    \x0c\n\x05\x04\0\x02\x04\x01\x12\x03\n\t\x11\n\x0c\n\x05\x04\0\x02\x04\
    \x03\x12\x03\n\x14\x15\n\x0b\n\x04\x04\0\x02\x05\x12\x03\x0b\x02\x11\n\r\
    \n\x05\x04\0\x02\x05\x04\x12\x04\x0b\x02\n\x16\n\x0c\n\x05\x04\0\x02\x05\
    \x05\x12\x03\x0b\x02\x08\n\x0c\n\x05\x04\0\x02\x05\x01\x12\x03\x0b\t\x0c\
    \n\x0c\n\x05\x04\0\x02\x05\x03\x12\x03\x0b\x0f\x10\n\xb5\x02\n\x04\x04\0\
    \x02\x06\x12\x03\x11\x02\x13\x1a\xa7\x02\x20in\x20order\x20for\x20nodes\
    \x20to\x20properly\x20validate\x20a\x20record\x20upon\x20receipt,\x20the\
    y\n\x20need\x20the\x20public\x20key\x20associated\x20with\x20it.\x20For\
    \x20old\x20RSA\x20keys,\x20its\x20easiest\n\x20if\x20we\x20just\x20send\
    \x20this\x20as\x20part\x20of\x20the\x20record\x20itself.\x20For\x20newer\
    \x20ed25519\n\x20keys,\x20the\x20public\x20key\x20can\x20be\x20embedded\
    \x20in\x20the\x20peerID,\x20making\x20this\x20field\n\x20unnecessary.\n\
    \n\r\n\x05\x04\0\x02\x06\x04\x12\x04\x11\x02\x0b\x11\n\x0c\n\x05\x04\0\
    \x02\x06\x05\x12\x03\x11\x02\x07\n\x0c\n\x05\x04\0\x02\x06\x01\x12\x03\
    \x11\x08\x0e\n\x0c\n\x05\x04\0\x02\x06\x03\x12\x03\x11\x11\x12b\x06proto\
    3\
";

static mut file_descriptor_proto_lazy: ::protobuf::lazy::Lazy<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::lazy::Lazy {
    lock: ::protobuf::lazy::ONCE_INIT,
    ptr: 0 as *const ::protobuf::descriptor::FileDescriptorProto,
};

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    unsafe {
        file_descriptor_proto_lazy.get(|| {
            parse_descriptor_proto()
        })
    }
}

'''
'''--- ipfstools/src/ipns/mod.rs ---
#![allow(dead_code)]
use crate::error::Error;
use crate::path::{IpfsPath, PathRoot};
use crate::repo::{Repo, RepoTypes};
use std::future::Future;

mod dns;
mod entry;
mod ipns_pb;

pub struct Ipns<Types: RepoTypes> {
    repo: Repo<Types>,
}

impl<Types: RepoTypes> Ipns<Types> {
    pub fn new(repo: Repo<Types>) -> Self {
        Ipns {
            repo
        }
    }

    /// Resolves a ipns path to an ipld path.
    pub fn resolve(&self, path: &IpfsPath) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        let path = path.to_owned();
        async move {
            match path.root() {
                PathRoot::Ipld(_) => Ok(path),
                PathRoot::Dns(domain) => {
                    Ok(await!(dns::resolve(domain)?)?)
                },
                _ => Ok(path),
            }
        }
    }

    /// Publishes an ipld path.
    pub fn publish(&self, path: &IpfsPath) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        let path = path.to_owned();
        async move {
            match path.root() {
                PathRoot::Ipld(_) => Ok(path),
                PathRoot::Dns(domain) => {
                    Ok(await!(dns::resolve(domain)?)?)
                },
                _ => Ok(path),

            }
        }
    }
}

'''
'''--- ipfstools/src/lib.rs ---
//! IPFS node implementation
//#![deny(missing_docs)]
#![deny(warnings)]
#![feature(async_await, await_macro, futures_api)]
#![feature(drain_filter)]
#![feature(try_trait)]

#[macro_use] extern crate failure;
#[macro_use] extern crate log;
use futures::prelude::*;
pub use libp2p::PeerId;
use std::marker::PhantomData;
use std::path::PathBuf;
use std::pin::Pin;
use std::sync::mpsc::{channel, Sender, Receiver};
use std::task::{Poll, Waker};
use tokio::prelude::{Async, Stream as StreamOld};

pub mod bitswap;
pub mod block;
mod config;
pub mod error;
mod future;
pub mod ipld;
pub mod ipns;
pub mod p2p;
pub mod path;
pub mod repo;
pub mod unixfs;

pub use self::block::{Block, Cid};
use self::config::ConfigFile;
pub use self::error::Error;
use self::ipld::IpldDag;
pub use self::ipld::Ipld;
use self::ipns::Ipns;
pub use self::p2p::SwarmTypes;
use self::p2p::{create_swarm, SwarmOptions, TSwarm};
pub use self::path::IpfsPath;
pub use self::repo::RepoTypes;
use self::repo::{create_repo, RepoOptions, Repo, RepoEvent};
use self::unixfs::File;

static IPFS_LOG: &str = "info";
static IPFS_PATH: &str = ".ipfstools";
static XDG_APP_NAME: &str = "ipfstools";
static CONFIG_FILE: &str = "config.json";

/// All types can be changed at compile time by implementing
/// `IpfsTypes`.
pub trait IpfsTypes: SwarmTypes + RepoTypes {}
impl<T: RepoTypes> SwarmTypes for T {
    type TStrategy = bitswap::strategy::AltruisticStrategy<Self>;
}
impl<T: SwarmTypes + RepoTypes> IpfsTypes for T {}

/// Default IPFS types.
#[derive(Clone)]
pub struct Types;
impl RepoTypes for Types {
    type TBlockStore = repo::fs::FsBlockStore;
}

/// Testing IPFS types
#[derive(Clone)]
pub struct TestTypes;
impl RepoTypes for TestTypes {
    type TBlockStore = repo::mem::MemBlockStore;
}

/// Ipfs options
#[derive(Clone, Debug)]
pub struct IpfsOptions<Types: IpfsTypes> {
    _marker: PhantomData<Types>,
    /// The ipfs log level that should be passed to env_logger.
    pub ipfs_log: String,
    /// The path of the ipfs repo.
    pub ipfs_path: PathBuf,
    /// The ipfs config.
    pub config: ConfigFile,
}

impl Default for IpfsOptions<Types> {
    /// Create `IpfsOptions` from environment.
    fn default() -> Self {
        let ipfs_log = std::env::var("IPFS_LOG").unwrap_or(IPFS_LOG.into());
        let ipfs_path = std::env::var("IPFS_PATH").unwrap_or_else(|_| {
            let mut ipfs_path = std::env::var("HOME").unwrap_or("".into());
            ipfs_path.push_str("/");
            ipfs_path.push_str(IPFS_PATH);
            ipfs_path
        }).into();
        let xdg_dirs = xdg::BaseDirectories::with_prefix(XDG_APP_NAME).unwrap();
        let path = xdg_dirs.place_config_file(CONFIG_FILE).unwrap();
        let config = ConfigFile::new(path);

        IpfsOptions {
            _marker: PhantomData,
            ipfs_log,
            ipfs_path,
            config
        }
    }
}

impl Default for IpfsOptions<TestTypes> {
    /// Creates `IpfsOptions` for testing without reading or writing to the
    /// file system.
    fn default() -> Self {
        let ipfs_log = std::env::var("IPFS_LOG").unwrap_or(IPFS_LOG.into());
        let ipfs_path = std::env::var("IPFS_PATH").unwrap_or(IPFS_PATH.into()).into();
        let config = ConfigFile::default();
        IpfsOptions {
            _marker: PhantomData,
            ipfs_log,
            ipfs_path,
            config,
        }
    }
}

/// Ipfs struct creates a new IPFS node and is the main entry point
/// for interacting with IPFS.
pub struct Ipfs<Types: IpfsTypes> {
    repo: Repo<Types>,
    repo_events: Option<Receiver<RepoEvent>>,
    dag: IpldDag<Types>,
    ipns: Ipns<Types>,
    swarm: Option<TSwarm<Types>>,
    exit_events: Vec<Sender<IpfsEvent>>,
}

enum IpfsEvent {
    Exit,
}

impl<Types: IpfsTypes> Ipfs<Types> {
    /// Creates a new ipfs node.
    pub fn new(options: IpfsOptions<Types>) -> Self {
        let repo_options = RepoOptions::<Types>::from(&options);
        let (repo, repo_events) = create_repo(repo_options);
        let swarm_options = SwarmOptions::<Types>::from(&options);
        let swarm = create_swarm(swarm_options, repo.clone());
        let dag = IpldDag::new(repo.clone());
        let ipns = Ipns::new(repo.clone());

        Ipfs {
            repo,
            dag,
            ipns,
            repo_events: Some(repo_events),
            swarm: Some(swarm),
            exit_events: Vec::default(),
        }
    }

    /// Initialize the ipfs repo.
    pub fn init_repo(&self) -> impl Future<Output=Result<(), Error>> {
        self.repo.init()
    }

    /// Open the ipfs repo.
    pub fn open_repo(&self) -> impl Future<Output=Result<(), Error>> {
        self.repo.open()
    }

    /// Puts a block into the ipfs repo.
    pub fn put_block(&self, block: Block) -> impl Future<Output=Result<Cid, Error>> {
        self.repo.put_block(block)
    }

    /// Retrives a block from the ipfs repo.
    pub fn get_block(&self, cid: &Cid) -> impl Future<Output=Result<Block, Error>> {
        self.repo.get_block(cid)
    }

    /// Remove block from the ipfs repo.
    pub fn remove_block(&self, cid: &Cid) -> impl Future<Output=Result<(), Error>> {
        self.repo.remove_block(cid)
    }

    /// Puts an ipld dag node into the ipfs repo.
    pub fn put_dag(&self, ipld: Ipld) -> impl Future<Output=Result<IpfsPath, Error>> {
        self.dag.put(ipld, cid::Codec::DagCBOR)
    }

    /// Gets an ipld dag node from the ipfs repo.
    pub fn get_dag(&self, path: IpfsPath) -> impl Future<Output=Result<Ipld, Error>> {
        self.dag.get(path)
    }

    /// Adds a file into the ipfs repo.
    pub fn add(&self, path: PathBuf) -> impl Future<Output=Result<IpfsPath, Error>> {
        let dag = self.dag.clone();
        async move {
            let file = await!(File::new(path))?;
            let path = await!(file.put_unixfs_v1(&dag))?;
            Ok(path)
        }
    }

    /// Gets a file from the ipfs repo.
    pub fn get(&self, path: IpfsPath) -> impl Future<Output=Result<File, Error>> {
        File::get_unixfs_v1(&self.dag, path)
    }

    /// Resolves a ipns path to an ipld path.
    pub fn resolve_ipns(&self, path: &IpfsPath) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        self.ipns.resolve(path)
    }

    /// Publishes an ipld path.
    pub fn publish_ipns(&self, path: &IpfsPath) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        self.ipns.publish(path)
    }

    /// Start daemon.
    pub fn start_daemon(&mut self) -> Option<IpfsFuture<Types>> {
        self.repo_events.take().map(|repo_events|{
            let (sender, receiver) = channel::<IpfsEvent>();
            self.exit_events.push(sender);

            IpfsFuture {
                repo_events,
                exit_events: receiver,
                swarm: Box::new(self.swarm.take().unwrap()),
            }
        })
    }

    /// Exit daemon.
    pub fn exit_daemon(&mut self) {
        for s in self.exit_events.drain(..) {
            let _ = s.send(IpfsEvent::Exit);
        }
    }
}

pub struct IpfsFuture<Types: SwarmTypes> {
    swarm: Box<TSwarm<Types>>,
    repo_events: Receiver<RepoEvent>,
    exit_events: Receiver<IpfsEvent>,
}

impl<Types: SwarmTypes> Future for IpfsFuture<Types> {
    type Output = ();

    fn poll(self: Pin<&mut Self>, _waker: &Waker) -> Poll<Self::Output> {
        let _self = self.get_mut();
        loop {
            if let Ok(IpfsEvent::Exit) = _self.exit_events.try_recv() {
                return Poll::Ready(());
            }

            loop {
                if let Ok(event) = _self.repo_events.try_recv() {
                    match event {
                        RepoEvent::WantBlock(cid) => {
                            _self.swarm.want_block(cid);
                        }
                        RepoEvent::ProvideBlock(cid) => {
                            _self.swarm.provide_block(cid);
                        }
                        RepoEvent::UnprovideBlock(cid) => {
                            _self.swarm.stop_providing_block(&cid);
                        }
                    }
                } else {
                    break
                }
            }

            let poll = _self.swarm.poll().expect("Error while polling swarm");
            match poll {
                Async::Ready(Some(_)) => {},
                Async::Ready(None) => {
                    return Poll::Ready(());
                },
                Async::NotReady => {
                    return Poll::Pending;
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_put_and_get_block() {
        let options = IpfsOptions::<TestTypes>::default();
        let mut ipfs = Ipfs::new(options);
        let block = Block::from("hello block\n");

        tokio::run_async(async move {
            let fut = ipfs.start_daemon().unwrap();
            tokio::spawn_async(fut);

            let cid = await!(ipfs.put_block(block.clone())).unwrap();
            let new_block = await!(ipfs.get_block(&cid)).unwrap();
            assert_eq!(block, new_block);

            ipfs.exit_daemon();
        });
    }

    #[test]
    fn test_put_and_get_dag() {
        let options = IpfsOptions::<TestTypes>::default();
        let mut ipfs = Ipfs::new(options);

        tokio::run_async(async move {
            let fut = ipfs.start_daemon().unwrap();
            tokio::spawn_async(fut);

            let data: Ipld = vec![-1, -2, -3].into();
            let cid = await!(ipfs.put_dag(data.clone())).unwrap();
            let new_data = await!(ipfs.get_dag(cid.into())).unwrap();
            assert_eq!(data, new_data);

            ipfs.exit_daemon();
        });
    }
}

'''
'''--- ipfstools/src/p2p/behaviour.rs ---
use crate::bitswap::{Bitswap, Strategy};
use crate::block::Cid;
use crate::p2p::{SwarmOptions, SwarmTypes};
use crate::repo::Repo;
use libp2p::{NetworkBehaviour, PeerId};
use libp2p::core::swarm::NetworkBehaviourEventProcess;
use libp2p::core::muxing::{StreamMuxerBox, SubstreamRef};
use libp2p::identify::{Identify, IdentifyEvent};
use libp2p::kad::{Kademlia, KademliaOut as KademliaEvent};
use libp2p::mdns::{Mdns, MdnsEvent};
use libp2p::ping::{Ping, PingEvent};
use libp2p::floodsub::{Floodsub, FloodsubEvent};
//use parity_multihash::Multihash;
use std::sync::Arc;
use tokio::prelude::*;

/// Behaviour type.
#[derive(NetworkBehaviour)]
pub struct Behaviour<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes> {
    mdns: Mdns<TSubstream>,
    kademlia: Kademlia<TSubstream>,
    bitswap: Bitswap<TSubstream, TSwarmTypes>,
    ping: Ping<TSubstream>,
    identify: Identify<TSubstream>,
    floodsub: Floodsub<TSubstream>,
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<MdnsEvent> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, event: MdnsEvent) {
        match event {
            MdnsEvent::Discovered(list) => {
                for (peer, _) in list {
                    debug!("mdns: Discovered peer {}", peer.to_base58());
                    self.bitswap.connect(peer.clone());
                    self.floodsub.add_node_to_partial_view(peer);
                }
            }
            MdnsEvent::Expired(list) => {
                for (peer, _) in list {
                    if !self.mdns.has_node(&peer) {
                        debug!("mdns: Expired peer {}", peer.to_base58());
                        self.floodsub.remove_node_from_partial_view(&peer);
                    }
                }
            }
        }
    }
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<KademliaEvent> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, event: KademliaEvent) {
        match event {
            KademliaEvent::Discovered { peer_id, addresses: _, ty } => {
                debug!("kad: Discovered peer {} {:?}", peer_id.to_base58(), ty);
            }
            KademliaEvent::FindNodeResult { key, closer_peers } => {
                if closer_peers.is_empty() {
                    info!("kad: Could not find closer peer to {}", key.to_base58());
                }
                for peer in closer_peers {
                    info!("kad: Found closer peer {} to {}", peer.to_base58(), key.to_base58());
                }
            }
            KademliaEvent::GetProvidersResult {
                key,
                provider_peers,
                ..
            } => {
                let cid = PeerId::from_multihash(key).unwrap().to_base58();
                if provider_peers.is_empty() {
                    info!("kad: Could not find provider for {}", cid);
                } else {
                    for peer in provider_peers {
                        info!("kad: {} provided by {}", cid, peer.to_base58());
                        self.bitswap.connect(peer);
                    }
                }
            }
        }
    }
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<()> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, _event: ()) {}
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<PingEvent> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, event: PingEvent) {
        match event {
            PingEvent::PingSuccess { peer, time } => {
                debug!("ping: rtt to {} is {} ms", peer.to_base58(), time.as_millis());
            }
        }
    }
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<IdentifyEvent> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, event: IdentifyEvent) {
        debug!("identify: {:?}", event);
    }
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes>
    NetworkBehaviourEventProcess<FloodsubEvent> for
    Behaviour<TSubstream, TSwarmTypes>
{
    fn inject_event(&mut self, event: FloodsubEvent) {
        debug!("floodsub: {:?}", event);
    }
}

impl<TSubstream: AsyncRead + AsyncWrite, TSwarmTypes: SwarmTypes> Behaviour<TSubstream, TSwarmTypes>
{
    /// Create a Kademlia behaviour with the IPFS bootstrap nodes.
    pub fn new(options: SwarmOptions<TSwarmTypes>, repo: Repo<TSwarmTypes>) -> Self {
        info!("Local peer id: {}", options.peer_id.to_base58());

        let mdns = Mdns::new_with_legacy().expect("Failed to create mDNS service");

        let mut kademlia = Kademlia::new(options.peer_id.to_owned());
        for (addr, peer_id) in &options.bootstrap {
            kademlia.add_not_connected_address(peer_id, addr.to_owned());
        }

        let strategy = TSwarmTypes::TStrategy::new(repo);
        let bitswap = Bitswap::new(strategy);
        let ping = Ping::new();
        let identify = Identify::new(
            "/ipfs/0.1.0".into(),
            "ipfstools".into(),
            options.key_pair.to_public_key(),
        );
        let floodsub = Floodsub::new(options.peer_id.to_owned());

        Behaviour {
            mdns,
            kademlia,
            bitswap,
            ping,
            identify,
            floodsub,
        }
    }

    pub fn want_block(&mut self, cid: Cid) {
        info!("Want block {}", cid.to_string());
        //let hash = Multihash::from_bytes(cid.to_bytes()).unwrap();
        //self.kademlia.get_providers(hash);
        self.bitswap.want_block(cid, 1);
    }

    pub fn provide_block(&mut self, cid: Cid) {
        info!("Providing block {}", cid.to_string());
        //let hash = Multihash::from_bytes(cid.to_bytes()).unwrap();
        //self.kademlia.add_providing(PeerId::from_multihash(hash).unwrap());
    }

    pub fn stop_providing_block(&mut self, cid: &Cid) {
        info!("Finished providing block {}", cid.to_string());
        //let hash = Multihash::from_bytes(cid.to_bytes()).unwrap();
        //self.kademlia.remove_providing(&hash);
    }
}

/// Behaviour type.
pub(crate) type TBehaviour<TSwarmTypes> = Behaviour<SubstreamRef<Arc<StreamMuxerBox>>, TSwarmTypes>;

/// Create a IPFS behaviour with the IPFS bootstrap nodes.
pub fn build_behaviour<TSwarmTypes: SwarmTypes>(options: SwarmOptions<TSwarmTypes>, repo: Repo<TSwarmTypes>) -> TBehaviour<TSwarmTypes> {
    Behaviour::new(options, repo)
}

'''
'''--- ipfstools/src/p2p/mod.rs ---
//! P2P handling for IPFS nodes.
use crate::bitswap::Strategy;
use crate::IpfsOptions;
use crate::repo::{Repo, RepoTypes};
use libp2p::{Multiaddr, PeerId};
use libp2p::core::Swarm;
use libp2p::secio::SecioKeyPair;
use std::marker::PhantomData;

mod behaviour;
mod transport;

pub type TSwarm<SwarmTypes> = Swarm<transport::TTransport, behaviour::TBehaviour<SwarmTypes>>;

pub trait SwarmTypes: RepoTypes + Sized {
    type TStrategy: Strategy<Self>;
}

pub struct SwarmOptions<TSwarmTypes: SwarmTypes> {
    _marker: PhantomData<TSwarmTypes>,
    pub key_pair: SecioKeyPair,
    pub peer_id: PeerId,
    pub bootstrap: Vec<(Multiaddr, PeerId)>,
}

impl<TSwarmTypes: SwarmTypes> From<&IpfsOptions<TSwarmTypes>> for SwarmOptions<TSwarmTypes> {
    fn from(options: &IpfsOptions<TSwarmTypes>) -> Self {
        let key_pair = options.config.secio_key_pair();
        let peer_id = key_pair.to_peer_id();
        let bootstrap = options.config.bootstrap();
        SwarmOptions {
            _marker: PhantomData,
            key_pair,
            peer_id,
            bootstrap,
        }
    }
}

/// Creates a new IPFS swarm.
pub fn create_swarm<TSwarmTypes: SwarmTypes>(options: SwarmOptions<TSwarmTypes>, repo: Repo<TSwarmTypes>) -> TSwarm<TSwarmTypes> {
    let peer_id = options.peer_id.clone();

    // Set up an encrypted TCP transport over the Mplex protocol.
    let transport = transport::build_transport(&options);

    // Create a Kademlia behaviour
    let behaviour = behaviour::build_behaviour(options, repo);

    // Create a Swarm
    let mut swarm = libp2p::core::Swarm::new(transport, behaviour, peer_id);

    // Listen on all interfaces and whatever port the OS assigns
    let addr = Swarm::listen_on(&mut swarm, "/ip4/127.0.0.1/tcp/0".parse().unwrap()).unwrap();
    info!("Listening on {:?}", addr);

    swarm
}

'''
'''--- ipfstools/src/p2p/transport.rs ---
use crate::p2p::{SwarmOptions, SwarmTypes};
use libp2p::{PeerId, Transport};
use libp2p::core::muxing::StreamMuxerBox;
use libp2p::core::transport::boxed::Boxed;
use libp2p::core::upgrade::{self, InboundUpgradeExt, OutboundUpgradeExt,
                            SelectUpgrade};
use libp2p::mplex::MplexConfig;
use libp2p::secio::SecioConfig;
use libp2p::tcp::TcpConfig;
use libp2p::yamux::Config as YamuxConfig;
use std::io::{Error, ErrorKind};
use std::time::Duration;
use tokio::prelude::*;

/// Transport type.
pub(crate) type TTransport = Boxed<(PeerId, StreamMuxerBox), Error>;

/// Builds the transport that serves as a common ground for all connections.
///
/// Set up an encrypted TCP transport over the Mplex protocol.
pub fn build_transport<TSwarmTypes: SwarmTypes>(options: &SwarmOptions<TSwarmTypes>) -> TTransport {
    let transport = TcpConfig::new();
    let secio_config = SecioConfig::new(options.key_pair.to_owned());
    let yamux_config = YamuxConfig::default();
    let mplex_config = MplexConfig::new();

    transport
        .with_upgrade(secio_config)
        .and_then(move |out, endpoint| {
            let peer_id = out.remote_key.into_peer_id();
            let peer_id2 = peer_id.clone();
            let upgrade = SelectUpgrade::new(yamux_config, mplex_config)
                .map_inbound(move |muxer| (peer_id, muxer))
                .map_outbound(move |muxer| (peer_id2, muxer));

            upgrade::apply(out.stream, upgrade, endpoint)
                .map(|(peer_id, muxer)| (peer_id, StreamMuxerBox::new(muxer)))
        })
        .with_timeout(Duration::from_secs(20))
        .map_err(|err| Error::new(ErrorKind::Other, err))
        .boxed()
}

'''
'''--- ipfstools/src/path/error.rs ---
use crate::ipld::Ipld;
use crate::path::SubPath;

#[derive(Debug)]
pub enum IpfsPathError {
    InvalidPath(String),
    ResolveError {
        ipld: Ipld,
        path: SubPath,
    },
    ExpectedIpldPath,
}

impl std::error::Error for IpfsPathError {
    fn description(&self) -> &str {
        match *self {
            IpfsPathError::InvalidPath(_) => "invalid path",
            IpfsPathError::ResolveError { .. } => "error resolving path",
            IpfsPathError::ExpectedIpldPath => "expected ipld path",
        }
    }
}

impl std::fmt::Display for IpfsPathError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match *self {
            IpfsPathError::InvalidPath(ref path) => {
                write!(f, "Invalid path {:?}", path)
            }
            IpfsPathError::ResolveError { ref path, .. } => {
                write!(f, "Can't resolve {}", path.to_string())
            }
            IpfsPathError::ExpectedIpldPath => {
                write!(f, "Expected ipld path but found ipns path")
            }
        }
    }
}

'''
'''--- ipfstools/src/path/mod.rs ---
use crate::block::Cid;
use crate::error::Error;
use libp2p::PeerId;
use std::convert::{TryFrom, TryInto};
use std::str::FromStr;

pub mod error;
pub use self::error::IpfsPathError;

#[derive(Clone, Debug, PartialEq)]
pub struct IpfsPath {
    root: PathRoot,
    path: Vec<SubPath>,
}

impl IpfsPath {
    pub fn new(root: PathRoot) -> Self {
        IpfsPath {
            root,
            path: Vec::new(),
        }
    }

    pub fn from_str(string: &str) -> Result<Self, Error> {
        let mut subpath = string.split("/");
        let empty = subpath.next();
        let root_type = subpath.next();
        let key = subpath.next();

        let root = match (empty, root_type, key) {
            (Some(""), Some("ipfs"), Some(key)) => PathRoot::Ipld(Cid::from(key)?),
            (Some(""), Some("ipld"), Some(key)) => PathRoot::Ipld(Cid::from(key)?),
            (Some(""), Some("ipns"), Some(key)) => {
                match PeerId::from_str(key).ok() {
                    Some(peer_id) => PathRoot::Ipns(peer_id),
                    None => PathRoot::Dns(key.to_string())
                }
            },
            _ => return Err(IpfsPathError::InvalidPath(string.to_owned()).into()),
        };
        let mut path = IpfsPath::new(root);
        path.push_str(&subpath.collect::<Vec<&str>>().join("/"))?;
        Ok(path)
    }

    pub fn root(&self) -> &PathRoot {
        &self.root
    }

    pub fn set_root(&mut self, root: PathRoot) {
        self.root = root;
    }

    pub fn push<T: Into<SubPath>>(&mut self, sub_path: T) {
        self.path.push(sub_path.into());
    }

    pub fn push_str(&mut self, string: &str) -> Result<(), Error> {
        if string.is_empty() {
            return Ok(());
        }
        for sub_path in string.split("/") {
            if sub_path == "" {
                return Err(IpfsPathError::InvalidPath(string.to_owned()).into());
            }
            let index = sub_path.parse::<usize>();
            if index.is_ok() {
                self.push(index.unwrap());
            } else {
                self.push(sub_path);
            }
        }
        Ok(())
    }

    pub fn sub_path(&self, string: &str) -> Result<Self, Error> {
        let mut path = self.to_owned();
        path.push_str(string)?;
        Ok(path)
    }

    pub fn into_sub_path(mut self, string: &str) -> Result<Self, Error> {
        self.push_str(string)?;
        Ok(self)
    }

    pub fn iter(&self) -> impl Iterator<Item=&SubPath> {
        self.path.iter()
    }

    pub fn to_string(&self) -> String {
        let mut path = self.root.to_string();
        for sub_path in &self.path {
            path.push_str("/");
            path.push_str(&sub_path.to_string());
        }
        path
    }
}

impl TryFrom<&str> for IpfsPath {
    type Error = Error;

    fn try_from(string: &str) -> Result<Self, Self::Error> {
        IpfsPath::from_str(string)
    }
}

impl<T: Into<PathRoot>> From<T> for IpfsPath {
    fn from(root: T) -> Self {
        IpfsPath::new(root.into())
    }
}

impl TryInto<Cid> for IpfsPath {
    type Error = Error;

    fn try_into(self) -> Result<Cid, Self::Error> {
        match self.root().cid() {
            Some(cid) => Ok(cid.to_owned()),
            None => bail!("expected cid"),
        }
    }
}

impl TryInto<PeerId> for IpfsPath {
    type Error = Error;

    fn try_into(self) -> Result<PeerId, Self::Error> {
        match self.root().peer_id() {
            Some(peer_id) => Ok(peer_id.to_owned()),
            None => bail!("expected peer id"),
        }
    }
}

#[derive(Clone, Debug, PartialEq)]
pub enum PathRoot {
    Ipld(Cid),
    Ipns(PeerId),
    Dns(String),
}

impl PathRoot {
    pub fn is_ipld(&self) -> bool {
        match self {
            PathRoot::Ipld(_) => true,
            _ => false,
        }
    }

    pub fn is_ipns(&self) -> bool {
        match self {
            PathRoot::Ipns(_) => true,
            _ => false,
        }
    }

    pub fn cid(&self) -> Option<&Cid> {
        match self {
            PathRoot::Ipld(cid) => Some(cid),
            _ => None,
        }
    }

    pub fn peer_id(&self) -> Option<&PeerId> {
        match self {
            PathRoot::Ipns(peer_id) => Some(peer_id),
            _ => None,
        }
    }

    pub fn to_string(&self) -> String {
        let (prefix, key) = match self {
            PathRoot::Ipld(cid) => ("/ipfs/", cid.to_string()),
            PathRoot::Ipns(peer_id) => ("/ipns/", peer_id.to_base58()),
            PathRoot::Dns(domain) => ("/ipns/", domain.to_owned()),
        };
        let mut string = prefix.to_string();
        string.push_str(&key);
        string
    }

    pub fn to_bytes(&self) -> Vec<u8> {
        match self {
            PathRoot::Ipld(cid) => cid.to_bytes(),
            PathRoot::Ipns(peer_id) => peer_id.as_bytes().to_vec(),
            PathRoot::Dns(domain) => domain.as_bytes().to_vec(),
        }
    }
}

impl From<Cid> for PathRoot {
    fn from(cid: Cid) -> Self {
        PathRoot::Ipld(cid)
    }
}

impl From<PeerId> for PathRoot {
    fn from(peer_id: PeerId) -> Self {
        PathRoot::Ipns(peer_id)
    }
}

impl TryInto<Cid> for PathRoot {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<Cid, Self::Error> {
        match self {
            PathRoot::Ipld(cid) => Ok(cid),
            _ => None?,
        }
    }
}

impl TryInto<PeerId> for PathRoot {
    type Error = std::option::NoneError;

    fn try_into(self) -> Result<PeerId, Self::Error> {
        match self {
            PathRoot::Ipns(peer_id) => Ok(peer_id),
            _ => None?,
        }
    }
}

#[derive(Clone, Debug, PartialEq)]
pub enum SubPath {
    Key(String),
    Index(usize),
}

impl From<String> for SubPath {
    fn from(key: String) -> Self {
        SubPath::Key(key)
    }
}

impl From<&str> for SubPath {
    fn from(key: &str) -> Self {
        SubPath::from(key.to_string())
    }
}

impl From<usize> for SubPath {
    fn from(index: usize) -> Self {
        SubPath::Index(index)
    }
}

impl SubPath {
    pub fn is_key(&self) -> bool {
        match *self {
            SubPath::Key(_) => true,
            _ => false,
        }
    }

    pub fn to_key<'a>(&'a self) -> Option<&'a String> {
        match self {
            SubPath::Key(ref key) => Some(key),
            _ => None,
        }
    }

    pub fn is_index(&self) -> bool {
        match self {
            SubPath::Index(_) => true,
            _ => false,
        }
    }

    pub fn to_index(&self) -> Option<usize> {
        match self {
            SubPath::Index(index) => Some(*index),
            _ => None,
        }
    }

    pub fn to_string(&self) -> String {
        match self {
            SubPath::Key(ref key) => key.to_owned(),
            SubPath::Index(index) => index.to_string(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::block::Block;

    #[test]
    fn test_from() {
        let res = Block::from("hello").path("key/3").unwrap();

        let cid = Block::from("hello").cid().to_owned();
        let mut path = IpfsPath::new(PathRoot::Ipld(cid));
        path.push("key");
        path.push(3);

        assert_eq!(path, res);
    }

    #[test]
    fn test_from_errors() {
        let block = Block::from("hello");
        assert!(block.path("").is_ok());
        assert!(block.path("/").is_err());
        assert!(block.path("/abc").is_err());
        assert!(block.path("abc/").is_err());
        assert!(block.path("abc//de").is_err());
    }

    #[test]
    fn test_from_str() {
        let string = "/ipld/QmRN6wdp1S2A5EtjW9A3M1vKSBuQQGcgvuhoMUoEz4iiT5/key/3";
        let res = IpfsPath::from_str(string).unwrap();

        let cid = Block::from("hello").cid().to_owned();
        let mut path = IpfsPath::new(PathRoot::Ipld(cid));
        path.push("key");
        path.push(3);

        assert_eq!(path, res);
    }

    #[test]
    fn test_from_str_errors() {
        assert!(IpfsPath::from_str("").is_err());
        assert!(IpfsPath::from_str("/").is_err());
        assert!(IpfsPath::from_str("/QmRN").is_err());
    }

    #[test]
    fn test_to_string() {
        let path = Block::from("hello").path("key/3").unwrap();
        let res = "/ipfs/QmRN6wdp1S2A5EtjW9A3M1vKSBuQQGcgvuhoMUoEz4iiT5/key/3";
        assert_eq!(path.to_string(), res);
    }
}

'''
'''--- ipfstools/src/repo/ds.rs ---
use crate::block::Cid;

pub use errors::Error;
pub use types::*;
pub use storage::DB;
use std::path::PathBuf;

pub trait BlockStore: Clone + Send + Sync + Unpin + 'static {
    fn new(path: PathBuf) -> Self;
    fn init(&self) ->
    FutureObj<'static, Result<(), Error>>;
    fn open(&self) ->
    FutureObj<'static, Result<(), Error>>;
    fn contains(&self, cid: &Cid) ->
    FutureObj<'static, Result<bool, Error>>;
    fn get(&self, cid: &Cid) ->
    FutureObj<'static, Result<Option<Block>, Error>>;
    fn put(&self, block: Block) ->
    FutureObj<'static, Result<Cid, Error>>;
    fn remove(&self, cid: &Cid) ->
    FutureObj<'static, Result<(), Error>>;
}

/// An object capable of storing and retrieving objects implementing `StoreItem`.
///
/// A `Store` is fundamentally backed by a key-value database, however it provides support for
/// columns. A simple column implementation might involve prefixing a key with some bytes unique to
/// each column.
pub trait DataStore : Sync + Send + Sized +Clone + Unpin + 'static{

    /// Store an item in `Self`.
    fn put(&self, col: Column, key: &[u8], value: &[u8]) -> Result<(), DBError>;

    /// Retrieve an item from `Self`.
    fn get(&self, col: Column, key: &[u8]) -> Result<Option<Vec<u8>>, Error>;

    /// Returns `true` if the given key represents an item in `Self`.
    fn exists(&self, col: Column, key: &[u8]) -> Result<bool, Error> ;

    /// Remove an item from `Self`.
    fn delete(&self, col: Column, key: &[u8]) -> Result<(), Error> ;

    /// Given the root of an existing block in the store (`start_block_root`), return a parent
    /// block with the specified `slot`.
    ///
    /// Returns `None` if no parent block exists at that slot, or if `slot` is greater than the
    /// slot of `start_block_root`.
    fn get_block_at_preceeding_slot(
        &self,
        start_block_root: Cid,
        slot: Slot,
    ) -> Result<Option<(Cid, BeaconBlock)>, Error> {
        block_at_slot::get_block_at_preceeding_slot(self, slot, start_block_root)
    }
}

/// A on-disk database which implements the DataStore trait.
///
/// This implementation uses RocksDB with default options.
pub struct DBStore {
    path: PathBuf,
    db:Arc<Mutex<Option<DB>>>,
}

impl DBStore {

    fn open(path:&PathBuf) -> Self {
        // Rocks options.
        let mut options = Options::default();
        options.create_if_missing(true);

        // Ensure the path exists.
        fs::create_dir_all(&path).unwrap_or_else(|_| panic!("Unable to create {:?}", &path));
        let db_path = path.join("database");
        let columns = columns.unwrap_or(&COLUMNS);

        if db_path.exists() {
            Self {
                path:db_path,
                db: DB::open_cf(&options, db_path, &COLUMNS)
                    .expect("Unable to open local database"),
            }
        } else {
            let mut db = Self {
                path:db_path,
                db: DB::open(&options, db_path).expect("Unable to open local database"),
            };
            for cf in columns {
                db.create_col(cf).unwrap();
            }
            db
        }
    }

    /// Create a RocksDB column family. Corresponds to the
/// `create_cf()` function on the RocksDB API.
    #[allow(dead_code)]
    fn create_col(&mut self, col: &str) -> Result<(), DBError> {
        match self.db.create_cf(col, &Options::default()) {
            Err(e) => Err(e.into()),
            Ok(_) => Ok(()),
        }
    }
}

impl DataStore for DBStore {

    /// Corresponds to the `get_cf()` method on the RocksDB API.
    /// Will attempt to get the `ColumnFamily` and return an Err
    /// if it fails.
    fn get(&self, col: Column, key: &[u8]) -> Result<Option<Vec<u8>>, Error> {

        let db = self.db.lock().unwrap();
        let db = self.db.as_ref().unwrap();
        let get = self.db.get_cf(cf, &key)?.map(|value| value.to_vec());
        Ok(get)
    }

    /// Set some value for some key on some column.
    ///
    /// Corresponds to the `cf_handle()` method on the RocksDB API.
    /// Will attempt to get the `ColumnFamily` and return an Err
    /// if it fails.
    fn put(&self, col: Column, key: &[u8], value: &[u8]) -> Result<(), DBError> {

        match self.db.cf_handle(col) {
            None => Err(DecodeError::BytesInvalid(
                "Unknown column".to_string(),
            )),
            Some(handle) => self.db.put_cf(handle, key, val).map_err(|e| e.into()),
        }
    }

    /// Returns `true` if the given key represents an item in `Self`.
    fn exists(&self, col: Column, key: &[u8]) -> Result<bool, Error>{
        /*
         * I'm not sure if this is the correct way to read if some
         * block exists. Naively I would expect this to unncessarily
         * copy some data, but I could be wrong.
         */
        match self.db.cf_handle(col) {
            None => Err(DecodeError::BytesInvalid(
                "Unknown column".to_string(),
            )),
            Some(handle) => Ok(self.db.get_cf(handle, key)?.is_some()),
        }
    }

    /// Delete the value for some key on some column.
    ///
    /// Corresponds to the `delete_cf()` method on the RocksDB API.
    /// Will attempt to get the `ColumnFamily` and return an Err
    /// if it fails.
    fn delete(&self, col: Column, key: &[u8]) -> Result<(), Error> {
        match self.db.cf_handle(col) {
            None => Err(DecodeError::BytesInvalid(
                "Unknown column".to_string(),
            )),
            Some(handle) => {
                self.db.delete_cf(handle, key)?;
                Ok(())
            }
        }
    }
}
'''
'''--- ipfstools/src/repo/fs.rs ---
//! Persistent fs backed repo
use crate::block::{Cid, Block};
use crate::error::Error;
use crate::repo::BlockStore;
use futures::compat::*;
use futures::future::FutureObj;
use std::collections::HashSet;
use std::ffi::OsStr;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};
use tokio::prelude::{Future as OldFuture, Stream as OldStream};
use tokio::fs;

#[derive(Clone, Debug)]
pub struct FsBlockStore {
    path: PathBuf,
    cids: Arc<Mutex<HashSet<Cid>>>,
}

impl BlockStore for FsBlockStore {
    fn new(path: PathBuf) -> Self {
        FsBlockStore {
            path,
            cids: Arc::new(Mutex::new(HashSet::new()))
        }
    }

    fn init(&self) -> FutureObj<'static, Result<(), Error>> {
        let path = self.path.clone();
        FutureObj::new(Box::new(async move {
            await!(fs::create_dir_all(path).compat())?;
            Ok(())
        }))
    }

    fn open(&self) -> FutureObj<'static, Result<(), Error>> {
        let path = self.path.clone();
        let cids = self.cids.clone();
        FutureObj::new(Box::new(async move {
            await!(fs::read_dir(path).flatten_stream().for_each(|dir| {
                let path = dir.path();
                if path.extension() == Some(OsStr::new("data")) {
                    let cid_str = path.file_stem().unwrap();
                    let cid = Cid::from(cid_str.to_str().unwrap()).unwrap();
                    cids.lock().unwrap().insert(cid);
                }
                Ok(())
            }).compat())?;
            Ok(())
        }))
    }

    fn contains(&self, cid: &Cid) -> FutureObj<'static, Result<bool, Error>> {
        let contains = self.cids.lock().unwrap().contains(cid);
        FutureObj::new(Box::new(async move {
            Ok(contains)
        }))
    }

    fn get(&self, cid: &Cid) -> FutureObj<'static, Result<Option<Block>, Error>> {
        let path = block_path(self.path.clone(), cid);
        let cid = cid.to_owned();
        FutureObj::new(Box::new(async move {
            let file = match await!(fs::File::open(path).compat()) {
                Ok(file) => file,
                Err(err) => {
                    if err.kind() == std::io::ErrorKind::NotFound {
                        return Ok(None);
                    } else {
                        return Err(err.into());
                    }
                }
            };
            let (_, data) = await!(tokio::io::read_to_end(file, Vec::new()).compat())?;
            let block = Block::new(data, cid);
            Ok(Some(block))
        }))
    }

    fn put(&self, block: Block) -> FutureObj<'static, Result<Cid, Error>> {
        let path = block_path(self.path.clone(), &block.cid());
        let cids = self.cids.clone();
        FutureObj::new(Box::new(async move {
            let file = await!(fs::File::create(path).compat())?;
            let data = block.data();
            await!(tokio::io::write_all(file, &*data).compat())?;
            cids.lock().unwrap().insert(block.cid().to_owned());
            Ok(block.cid().to_owned())
        }))
    }

    fn remove(&self, cid: &Cid) -> FutureObj<'static, Result<(), Error>> {
        let path = block_path(self.path.clone(), cid);
        let cid = cid.to_owned();
        let cids = self.cids.clone();
        let contains = self.contains(&cid);
        FutureObj::new(Box::new(async move {
            if await!(contains)? {
                await!(fs::remove_file(path).compat())?;
                cids.lock().unwrap().remove(&cid);
            }
            Ok(())
        }))
    }
}

fn block_path(mut base: PathBuf, cid: &Cid) -> PathBuf {
    let mut file = cid.to_string();
    file.push_str(".data");
    base.push(file);
    base
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env::temp_dir;

    #[test]
    fn test_fs_blockstore() {
        let mut tmp = temp_dir();
        tmp.push("blockstore1");
        std::fs::remove_dir_all(tmp.clone()).ok();
        let store = FsBlockStore::new(tmp.clone());

        tokio::run_async(async move {
            let block = Block::from("1");
            let cid = block.cid();

            assert_eq!(await!(store.init()).unwrap(), ());
            assert_eq!(await!(store.open()).unwrap(), ());

            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), None);
            let remove = store.remove(cid);
            assert_eq!(await!(remove).unwrap(), ());

            let put = store.put(block.clone());
            assert_eq!(await!(put).unwrap(), cid.to_owned());
            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), true);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), Some(block.clone()));

            let remove = store.remove(cid);
            assert_eq!(await!(remove).unwrap(), ());
            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), None);
        });

        std::fs::remove_dir_all(tmp).ok();
    }

    #[test]
    fn test_fs_blockstore_open() {
        let mut tmp = temp_dir();
        tmp.push("blockstore2");
        std::fs::remove_dir_all(tmp.clone()).ok();

        let blockstore_path = tmp.clone();
        tokio::run_async(async move {
            let block = Block::from("1");

            let block_store = FsBlockStore::new(blockstore_path.clone());
            await!(block_store.init()).unwrap();
            await!(block_store.open()).unwrap();

            assert!(!await!(block_store.contains(block.cid())).unwrap());
            await!(block_store.put(block.clone())).unwrap();

            let block_store = FsBlockStore::new(blockstore_path);
            await!(block_store.open()).unwrap();
            assert!(await!(block_store.contains(block.cid())).unwrap());
            assert_eq!(await!(block_store.get(block.cid())).unwrap().unwrap(), block);
        });

        std::fs::remove_dir_all(tmp).ok();
    }

    #[test]
    fn test_rocks_datastore() {
        let mut tmp = temp_dir();
        tmp.push("datastore1");
        std::fs::remove_dir_all(tmp.clone()).ok();
        let store = RocksDataStore::new(tmp.clone());

        tokio::run_async(async move {
            let col = Column::Ipns;
            let key = [1, 2, 3, 4];
            let value = [5, 6, 7, 8];

            assert_eq!(await!(store.init()).unwrap(), ());
            assert_eq!(await!(store.open()).unwrap(), ());

            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), None);
            let remove = store.remove(col, &key);
            assert_eq!(await!(remove).unwrap(), ());

            let put = store.put(col, &key, &value);
            assert_eq!(await!(put).unwrap(), ());
            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), true);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), Some(value.to_vec()));

            let remove = store.remove(col, &key);
            assert_eq!(await!(remove).unwrap(), ());
            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), None);
        });

        std::fs::remove_dir_all(tmp).ok();
    }
}

'''
'''--- ipfstools/src/repo/mem.rs ---
//! Volatile memory backed repo
use crate::block::{Cid, Block};
use crate::error::Error;
use crate::repo::{BlockStore};
use futures::future::FutureObj;
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};

#[derive(Clone, Debug)]
pub struct MemBlockStore {
    blocks: Arc<Mutex<HashMap<Cid, Block>>>,
}

impl BlockStore for MemBlockStore {
    fn new(_path: PathBuf) -> Self {
        MemBlockStore {
            blocks: Arc::new(Mutex::new(HashMap::new()))
        }
    }

    fn init(&self) -> FutureObj<'static, Result<(), Error>> {
        FutureObj::new(Box::new(futures::future::ok(())))
    }

    fn open(&self) -> FutureObj<'static, Result<(), Error>> {
        FutureObj::new(Box::new(futures::future::ok(())))
    }

    fn contains(&self, cid: &Cid) -> FutureObj<'static, Result<bool, Error>> {
        let contains = self.blocks.lock().unwrap().contains_key(cid);
        FutureObj::new(Box::new(futures::future::ok(contains)))
    }

    fn get(&self, cid: &Cid) -> FutureObj<'static, Result<Option<Block>, Error>> {
        let block = self.blocks.lock().unwrap()
            .get(cid)
            .map(|block| block.to_owned());
        FutureObj::new(Box::new(futures::future::ok(block)))
    }

    fn put(&self, block: Block) -> FutureObj<'static, Result<Cid, Error>> {
        let cid = block.cid().to_owned();
        self.blocks.lock().unwrap()
            .insert(cid.clone(), block);
        FutureObj::new(Box::new(futures::future::ok(cid)))
    }

    fn remove(&self, cid: &Cid) -> FutureObj<'static, Result<(), Error>> {
        self.blocks.lock().unwrap().remove(cid);
        FutureObj::new(Box::new(futures::future::ok(())))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env::temp_dir;

    #[test]
    fn test_mem_blockstore() {
        let tmp = temp_dir();
        let store = MemBlockStore::new(tmp);
        tokio::run_async(async move {
            let block = Block::from("1");
            let cid = block.cid();

            assert_eq!(await!(store.init()).unwrap(), ());
            assert_eq!(await!(store.open()).unwrap(), ());

            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), None);
            let remove = store.remove(cid);
            assert_eq!(await!(remove).unwrap(), ());

            let put = store.put(block.clone());
            assert_eq!(await!(put).unwrap(), cid.to_owned());
            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), true);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), Some(block.clone()));

            let remove = store.remove(cid);
            assert_eq!(await!(remove).unwrap(), ());
            let contains = store.contains(cid);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(cid);
            assert_eq!(await!(get).unwrap(), None);
        });
    }

    #[test]
    fn test_mem_datastore() {
        let tmp = temp_dir();
        let store = MemDataStore::new(tmp);
        tokio::run_async(async move {
            let col = Column::Ipns;
            let key = [1, 2, 3, 4];
            let value = [5, 6, 7, 8];

            assert_eq!(await!(store.init()).unwrap(), ());
            assert_eq!(await!(store.open()).unwrap(), ());

            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), None);
            let remove = store.remove(col, &key);
            assert_eq!(await!(remove).unwrap(), ());

            let put = store.put(col, &key, &value);
            assert_eq!(await!(put).unwrap(), ());
            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), true);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), Some(value.to_vec()));

            let remove = store.remove(col, &key);
            assert_eq!(await!(remove).unwrap(), ());
            let contains = store.contains(col, &key);
            assert_eq!(await!(contains).unwrap(), false);
            let get = store.get(col, &key);
            assert_eq!(await!(get).unwrap(), None);
        });
    }
}

'''
'''--- ipfstools/src/repo/mod.rs ---
//! IPFS repo
use crate::block::{Cid, Block};
use crate::error::Error;
use crate::future::BlockFuture;
use crate::IpfsOptions;
use core::future::Future;
use futures::future::FutureObj;
use std::marker::PhantomData;
use std::path::PathBuf;
use std::sync::mpsc::{channel, Sender, Receiver};

pub mod mem;
pub mod fs;

pub trait RepoTypes: Clone + Send + Sync + 'static {
    type TBlockStore: BlockStore;
}

#[derive(Clone, Debug)]
pub struct RepoOptions<TRepoTypes: RepoTypes> {
    _marker: PhantomData<TRepoTypes>,
    path: PathBuf,
}

impl<TRepoTypes: RepoTypes> From<&IpfsOptions<TRepoTypes>> for RepoOptions<TRepoTypes> {
    fn from(options: &IpfsOptions<TRepoTypes>) -> Self {
        RepoOptions {
            _marker: PhantomData,
            path: options.ipfs_path.clone(),
        }
    }
}

pub fn create_repo<TRepoTypes: RepoTypes>(options: RepoOptions<TRepoTypes>) -> (Repo<TRepoTypes>, Receiver<RepoEvent>) {
    Repo::new(options)
}

pub trait BlockStore: Clone + Send + Sync + Unpin + 'static {
    fn new(path: PathBuf) -> Self;
    fn init(&self) ->
        FutureObj<'static, Result<(), Error>>;
    fn open(&self) ->
        FutureObj<'static, Result<(), Error>>;
    fn contains(&self, cid: &Cid) ->
        FutureObj<'static, Result<bool, Error>>;
    fn get(&self, cid: &Cid) ->
        FutureObj<'static, Result<Option<Block>, Error>>;
    fn put(&self, block: Block) ->
        FutureObj<'static, Result<Cid, Error>>;
    fn remove(&self, cid: &Cid) ->
        FutureObj<'static, Result<(), Error>>;
}

#[derive(Clone, Copy, Debug)]
pub enum Column {
    Ipns
}

#[derive(Clone, Copy, Debug)]
pub enum DBColumn {
    BeaconBlock,
    BeaconState,
    ShardBlock,
}

#[derive(Clone, Debug)]
pub struct Repo<TRepoTypes: RepoTypes> {
    block_store: TRepoTypes::TBlockStore,
    events: Sender<RepoEvent>,
}

#[derive(Clone, Debug)]
pub enum RepoEvent {
    WantBlock(Cid),
    ProvideBlock(Cid),
    UnprovideBlock(Cid),
}

impl<TRepoTypes: RepoTypes> Repo<TRepoTypes> {
    pub fn new(options: RepoOptions<TRepoTypes>) -> (Self, Receiver<RepoEvent>) {
        let mut blockstore_path = options.path.clone();
        blockstore_path.push("blockstore");
        let block_store = TRepoTypes::TBlockStore::new(blockstore_path);
        let (sender, receiver) = channel::<RepoEvent>();

        (Repo {
            block_store,
            events: sender,
        }, receiver)
    }

    pub fn init(&self) -> FutureObj<'static, Result<(), Error>> {
        self.block_store.init()
    }

    pub fn open(&self) -> FutureObj<'static, Result<(), Error>> {
        self.block_store.open()
    }

    /// Puts a block into the block store.
    pub fn put_block(&self, block: Block) ->
    impl Future<Output=Result<Cid, Error>>
    {
        let events = self.events.clone();
        let block_store = self.block_store.clone();
        async move {
            let cid = await!(block_store.put(block))?;
            // sending only fails if no one is listening anymore
            // and that is okay with us.
            let _ = events.send(RepoEvent::ProvideBlock(cid.clone()));
            Ok(cid)
        }
    }

    /// Retrives a block from the block store.
    pub fn get_block(&self, cid: &Cid) ->
    impl Future<Output=Result<Block, Error>>
    {
        let cid = cid.to_owned();
        let events = self.events.clone();
        let block_store = self.block_store.clone();
        async move {
            if !await!(block_store.contains(&cid))? {
                // sending only fails if no one is listening anymore
                // and that is okay with us.
                let _ = events.send(RepoEvent::WantBlock(cid.clone()));
            }
            await!(BlockFuture::new(block_store, cid))
        }
    }

    /// Remove block from the block store.
    pub fn remove_block(&self, cid: &Cid)
        -> impl Future<Output=Result<(), Error>>
    {
        // sending only fails if no one is listening anymore
        // and that is okay with us.
        let _ = self.events.send(RepoEvent::UnprovideBlock(cid.to_owned()));
        self.block_store.remove(cid)
    }
}

#[cfg(test)]
pub(crate) mod tests {
    use super::*;
    use std::env::temp_dir;

    #[derive(Clone)]
    pub struct Types;

    impl RepoTypes for Types {
        type TBlockStore = mem::MemBlockStore;
    }

    pub fn create_mock_repo() -> Repo<Types> {
        let mut tmp = temp_dir();
        tmp.push("ipfstools-repo");
        let options: RepoOptions<Types> = RepoOptions {
            _marker: PhantomData,
            path: tmp,
        };
        let (r, _) = Repo::new(options);
        r
    }

    #[test]
    fn test_repo() {
        let mut tmp = temp_dir();
        tmp.push("ipfstools-repo");
        let options: RepoOptions<Types> = RepoOptions {
            _marker: PhantomData,
            path: tmp,
        };
        let (repo, _) = Repo::new(options);
        tokio::run_async(async move {
            await!(repo.init()).unwrap();
        });
    }
}

'''
'''--- ipfstools/src/unixfs/mod.rs ---
use crate::error::Error;
use crate::ipld::{Ipld, IpldDag, formats::pb::PbNode};
use crate::path::IpfsPath;
use crate::repo::RepoTypes;
use core::future::Future;
use futures::compat::*;
use std::collections::HashMap;
use std::convert::TryInto;
use std::path::PathBuf;

pub struct File {
    data: Vec<u8>,
}

impl File {
    pub fn new(path: PathBuf) -> impl Future<Output=Result<Self, Error>> {
        async move {
            let file = await!(tokio::fs::File::open(path).compat())?;
            let (_, data) = await!(tokio::io::read_to_end(file, Vec::new()).compat())?;
            Ok(File {
                data
            })
        }
    }

    pub fn get_unixfs_v1<T: RepoTypes>(dag: &IpldDag<T>, path: IpfsPath) ->
    impl Future<Output=Result<Self, Error>> {
        let future = dag.get(path);
        async move {
            let ipld = await!(future)?;
            let pb_node: PbNode = match ipld.try_into() {
                Ok(pb_node) => pb_node,
                Err(_) => bail!("invalid dag_pb node"),
            };
            Ok(File {
                data: pb_node.data,
            })
        }
    }

    pub fn put_unixfs_v1<T: RepoTypes>(&self, dag: &IpldDag<T>) ->
    impl Future<Output=Result<IpfsPath, Error>>
    {
        let links: Vec<Ipld> = vec![];
        let mut pb_node = HashMap::<&str, Ipld>::new();
        pb_node.insert("Data", self.data.clone().into());
        pb_node.insert("Links", links.into());
        let ipld = pb_node.into();
        dag.put(ipld, cid::Codec::DagProtobuf)
    }
}

impl From<Vec<u8>> for File {
    fn from(data: Vec<u8>) -> Self {
        File {
            data,
        }
    }
}

impl From<&str> for File {
    fn from(string: &str) -> Self {
        File {
            data: string.as_bytes().to_vec()
        }
    }
}

impl Into<String> for File {
    fn into(self) -> String {
        String::from_utf8_lossy(&self.data).to_string()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::block::Cid;
    use crate::repo::tests::create_mock_repo;

    #[test]
    fn test_file_cid() {
        let repo = create_mock_repo();
        let dag = IpldDag::new(repo);
        let file = File::from("\u{8}\u{2}\u{12}\u{12}Here is some data\n\u{18}\u{12}");
        let cid = Cid::from("QmSy5pnHk1EnvE5dmJSyFKG5unXLGjPpBuJJCBQkBTvBaW").unwrap();

        tokio::run_async(async move {
            let path = await!(file.put_unixfs_v1(&dag)).unwrap();
            assert_eq!(cid.to_string(), path.root().cid().unwrap().to_string());
        });
    }
}

'''
'''--- near/Cargo.toml ---
[package]
name = "near"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
actix = "0.8.1"
byteorder = "1.2"
kvdb = "0.1"
kvdb-memorydb = "0.1"
log = "0.4"
env_logger = "0.6.0"
chrono = { version = "0.4.4", features = ["serde"] }
futures = "0.1"
clap = "2.32"
rand = "0.6.5"
serde = "1.0"
serde_derive = "1.0"
serde_json = "1.0"
dirs = "1.0.5"

near-primitives = { path = "../core/primitives" }
near-store = { path = "../core/store" }
node-runtime = { path = "../runtime/runtime" }
near-chain = { path = "../chain/chain" }
near-client = { path = "../chain/client" }
near-pool = { path = "../chain/pool" }
near-network = { path = "../chain/network" }
near-jsonrpc = { path = "../chain/jsonrpc" }
near-verifier = { path = "../runtime/verifier" }

[dev-dependencies]
tempdir = "0.3"

'''
'''--- near/src/config.rs ---
use std::convert::TryInto;
use std::fs::File;
use std::io::{Read, Write};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Duration;
use std::{cmp, fs};

use chrono::{DateTime, NaiveDateTime, Utc};
use log::info;
use rand::distributions::Alphanumeric;
use rand::{thread_rng, Rng};
use serde_derive::{Deserialize, Serialize};

use near_client::BlockProducer;
use near_client::ClientConfig;
use near_jsonrpc::RpcConfig;
use near_network::test_utils::open_port;
use near_network::NetworkConfig;
use near_primitives::crypto::signer::{EDSigner, InMemorySigner, KeyFile};
use near_primitives::serialize::{to_base, u128_hex_format};
use near_primitives::types::{AccountId, Balance, BlockIndex, ReadablePublicKey, ValidatorId};

/// Initial balance used in tests.
pub const TESTING_INIT_BALANCE: Balance = 1_000_000_000_000_000;

/// Validator's stake used in tests.
pub const TESTING_INIT_STAKE: Balance = 50_000_000;

/// One NEAR in atto-NEARs.
pub const NEAR_TOKEN: Balance = 1_000_000_000_000_000_000;

/// Initial token supply.
pub const INITIAL_TOKEN_SUPPLY: Balance = 1_000_000_000 * NEAR_TOKEN;

pub const CONFIG_FILENAME: &str = "config.json";
pub const GENESIS_CONFIG_FILENAME: &str = "genesis.json";
pub const NODE_KEY_FILE: &str = "node_key.json";
pub const VALIDATOR_KEY_FILE: &str = "validator_key.json";

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Network {
    /// Address to listen for incoming connections.
    pub addr: String,
    /// Address to advertise to peers for them to connect.
    /// If empty, will use the same port as the addr, and will introspect on the listener.
    pub external_address: String,
    /// Comma separated list of nodes to connect to.
    pub boot_nodes: String,
    /// Maximum number of peers.
    pub max_peers: u32,
    /// Handshake timeout.
    pub handshake_timeout: Duration,
    /// Duration before trying to reconnect to a peer.
    pub reconnect_delay: Duration,
    /// Skip waiting for peers before starting node.
    pub skip_sync_wait: bool,
    /// Ban window for peers who misbehave.
    pub ban_window: Duration,
}

impl Default for Network {
    fn default() -> Self {
        Network {
            addr: "0.0.0.0:24567".to_string(),
            external_address: "".to_string(),
            boot_nodes: "".to_string(),
            max_peers: 40,
            handshake_timeout: Duration::from_secs(20),
            reconnect_delay: Duration::from_secs(60),
            skip_sync_wait: false,
            ban_window: Duration::from_secs(3 * 60 * 60),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Consensus {
    /// Minimum number of peers to start syncing.
    pub min_num_peers: usize,
    /// Minimum duration before producing block.
    pub min_block_production_delay: Duration,
    /// Maximum duration before producing block or skipping height.
    pub max_block_production_delay: Duration,
    /// Produce empty blocks, use `false` for testing.
    pub produce_empty_blocks: bool,
}

impl Default for Consensus {
    fn default() -> Self {
        Consensus {
            min_num_peers: 3,
            min_block_production_delay: Duration::from_secs(1),
            max_block_production_delay: Duration::from_secs(6),
            produce_empty_blocks: true,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Config {
    pub genesis_file: String,
    pub validator_key_file: String,
    pub node_key_file: String,
    pub rpc: RpcConfig,
    pub network: Network,
    pub consensus: Consensus,
}

impl Default for Config {
    fn default() -> Self {
        Config {
            genesis_file: GENESIS_CONFIG_FILENAME.to_string(),
            validator_key_file: VALIDATOR_KEY_FILE.to_string(),
            node_key_file: NODE_KEY_FILE.to_string(),
            rpc: RpcConfig::default(),
            network: Network::default(),
            consensus: Consensus::default(),
        }
    }
}

impl Config {
    pub fn from_file(path: &PathBuf) -> Self {
        let mut file = File::open(path).expect("Could not open config file.");
        let mut content = String::new();
        file.read_to_string(&mut content).expect("Could not read from config file.");
        Config::from(content.as_str())
    }

    pub fn write_to_file(&self, path: &PathBuf) {
        let mut file = File::create(path).expect("Failed to create / write a config file.");
        let str = serde_json::to_string_pretty(self).expect("Error serializing the config.");
        if let Err(err) = file.write_all(str.as_bytes()) {
            panic!("Failed to write a config file {}", err);
        }
    }
}

impl From<&str> for Config {
    fn from(content: &str) -> Self {
        serde_json::from_str(content).expect("Failed to deserialize config")
    }
}

#[derive(Clone)]
pub struct NearConfig {
    config: Config,
    pub client_config: ClientConfig,
    pub network_config: NetworkConfig,
    pub rpc_config: RpcConfig,
    pub block_producer: Option<BlockProducer>,
    pub genesis_config: GenesisConfig,
}

impl NearConfig {
    pub fn new(
        config: Config,
        genesis_config: &GenesisConfig,
        network_key_pair: KeyFile,
        block_producer: Option<&BlockProducer>,
    ) -> Self {
        NearConfig {
            config: config.clone(),
            client_config: ClientConfig {
                chain_id: genesis_config.chain_id.clone(),
                rpc_addr: config.rpc.addr.clone(),
                min_block_production_delay: Duration::from_millis(100),
                max_block_production_delay: Duration::from_millis(2000),
                block_expected_weight: 1000,
                skip_sync_wait: config.network.skip_sync_wait,
                sync_check_period: Duration::from_secs(10),
                sync_step_period: Duration::from_millis(10),
                sync_weight_threshold: 0,
                sync_height_threshold: 1,
                min_num_peers: 1,
                fetch_info_period: Duration::from_millis(100),
                log_summary_period: Duration::from_secs(10),
                produce_empty_blocks: config.consensus.produce_empty_blocks,
            },
            network_config: NetworkConfig {
                public_key: network_key_pair.public_key,
                secret_key: network_key_pair.secret_key,
                account_id: block_producer.map(|bp| bp.account_id.clone()),
                addr: if config.network.addr.is_empty() {
                    None
                } else {
                    Some(config.network.addr.parse().unwrap())
                },
                boot_nodes: if config.network.boot_nodes.is_empty() {
                    vec![]
                } else {
                    config
                        .network
                        .boot_nodes
                        .split(",")
                        .map(|chunk| chunk.try_into().unwrap())
                        .collect()
                },
                handshake_timeout: config.network.handshake_timeout,
                reconnect_delay: config.network.reconnect_delay,
                bootstrap_peers_period: Duration::from_secs(60),
                peer_max_count: config.network.max_peers,
                ban_window: config.network.ban_window,
                max_send_peers: 512,
                peer_expiration_duration: Duration::from_secs(7 * 24 * 60 * 60),
            },
            rpc_config: config.rpc,
            genesis_config: genesis_config.clone(),
            block_producer: block_producer.map(Clone::clone),
        }
    }
}

impl NearConfig {
    /// Test tool to save configs back to the folder.
    /// Useful for dynamic creating testnet configs and then saving them in different folders.
    pub fn save_to_dir(&self, dir: &Path) {
        fs::create_dir_all(dir).expect("Failed to create directory");

        self.config.write_to_file(&dir.join(CONFIG_FILENAME));

        if let Some(block_producer) = &self.block_producer {
            block_producer.signer.write_to_file(&dir.join(self.config.validator_key_file.clone()));
        }

        let network_signer = InMemorySigner::from_secret_key(
            "".to_string(),
            self.network_config.public_key.clone(),
            self.network_config.secret_key.clone(),
        );
        network_signer.write_to_file(&dir.join(self.config.node_key_file.clone()));

        self.genesis_config.write_to_file(&dir.join(self.config.genesis_file.clone()));
    }
}

#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]
pub struct AccountInfo {
    pub account_id: AccountId,
    pub public_key: ReadablePublicKey,
    #[serde(with = "u128_hex_format")]
    pub amount: Balance,
}

/// Runtime configuration, defining genesis block.
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct GenesisConfig {
    /// Official time of blockchain start.
    pub genesis_time: DateTime<Utc>,
    /// ID of the blockchain. This must be unique for every blockchain.
    /// If your testnet blockchains do not have unique chain IDs, you will have a bad time.
    pub chain_id: String,
    /// Number of block producer seats at genesis.
    pub num_block_producers: ValidatorId,
    /// Defines number of shards and number of validators per each shard at genesis.
    pub block_producers_per_shard: Vec<ValidatorId>,
    /// Expected number of fisherman per shard.
    pub avg_fisherman_per_shard: Vec<ValidatorId>,
    /// Enable dynamic re-sharding.
    pub dynamic_resharding: bool,
    /// Epoch length counted in blocks.
    pub epoch_length: BlockIndex,
    /// List of initial validators.
    pub validators: Vec<AccountInfo>,
    /// List of accounts / balances at genesis.
    pub accounts: Vec<AccountInfo>,
    /// List of contract code per accounts. Contract code encoded in base64.
    pub contracts: Vec<(AccountId, String)>,
}

impl GenesisConfig {
    pub fn legacy_test(seeds: Vec<&str>, num_validators: usize) -> Self {
        let mut validators = vec![];
        let mut accounts = vec![];
        let mut contracts = vec![];
        let default_test_contract =
            to_base(include_bytes!("../../runtime/wasm/runtest/res/wasm_with_mem.wasm").as_ref());
        for (i, account) in seeds.iter().enumerate() {
            let signer = InMemorySigner::from_seed(account, account);
            if i < num_validators {
                validators.push(AccountInfo {
                    account_id: account.to_string(),
                    public_key: signer.public_key.to_readable(),
                    amount: TESTING_INIT_STAKE,
                });
            }
            accounts.push(AccountInfo {
                account_id: account.to_string(),
                public_key: signer.public_key.to_readable(),
                amount: TESTING_INIT_BALANCE,
            });
            contracts.push((account.to_string(), default_test_contract.clone()))
        }
        GenesisConfig {
            genesis_time: Utc::now(),
            chain_id: random_chain_id(),
            num_block_producers: num_validators,
            block_producers_per_shard: vec![num_validators],
            avg_fisherman_per_shard: vec![0],
            dynamic_resharding: false,
            epoch_length: 10,
            validators,
            accounts,
            contracts,
        }
    }

    pub fn test(seeds: Vec<&str>) -> Self {
        let num_validators = seeds.len();
        Self::legacy_test(seeds, num_validators)
    }

    pub fn testing_spec(num_accounts: usize, num_validators: usize) -> Self {
        let mut accounts = vec![];
        let mut validators = vec![];
        for i in 0..num_accounts {
            let account_id = format!("near.{}", i);
            let signer = InMemorySigner::from_seed(&account_id, &account_id);
            if i < num_validators {
                validators.push(AccountInfo {
                    account_id: account_id.clone(),
                    public_key: signer.public_key.to_readable(),
                    amount: TESTING_INIT_STAKE,
                });
            }
            accounts.push(AccountInfo {
                account_id,
                public_key: signer.public_key.to_readable(),
                amount: TESTING_INIT_BALANCE,
            });
        }
        GenesisConfig {
            genesis_time: Utc::now(),
            chain_id: random_chain_id(),
            num_block_producers: num_validators,
            block_producers_per_shard: vec![num_validators],
            avg_fisherman_per_shard: vec![0],
            dynamic_resharding: false,
            epoch_length: 10,
            validators,
            accounts,
            contracts: vec![],
        }
    }

    /// Reads GenesisConfig from a file.
    pub fn from_file(path: &PathBuf) -> Self {
        let mut file = File::open(path).expect("Could not open genesis config file.");
        let mut content = String::new();
        file.read_to_string(&mut content).expect("Could not read from genesis config file.");
        GenesisConfig::from(content.as_str())
    }

    /// Writes GenesisConfig to the file.
    pub fn write_to_file(&self, path: &PathBuf) {
        let mut file = File::create(path).expect("Failed to create / write a genesis config file.");
        let str =
            serde_json::to_string_pretty(self).expect("Error serializing the genesis config.");
        if let Err(err) = file.write_all(str.as_bytes()) {
            panic!("Failed to write a genesis config file {}", err);
        }
    }
}

impl From<&str> for GenesisConfig {
    fn from(config: &str) -> Self {
        serde_json::from_str(config).expect("Failed to deserialize the genesis config.")
    }
}

fn random_chain_id() -> String {
    format!("test-chain-{}", thread_rng().sample_iter(&Alphanumeric).take(5).collect::<String>())
}

/// Official TestNet configuration.
pub fn testnet_genesis() -> GenesisConfig {
    GenesisConfig {
        genesis_time: DateTime::from_utc(NaiveDateTime::from_timestamp(1559628805, 0), Utc),
        chain_id: "testnet".to_string(),
        num_block_producers: 4,
        block_producers_per_shard: vec![4],
        avg_fisherman_per_shard: vec![100],
        dynamic_resharding: true,
        epoch_length: 20000,
        validators: vec![AccountInfo {
            account_id: ".near".to_string(),
            public_key: ReadablePublicKey(
                "DuZSg3DRUQDiR5Wvq5Viifaw2FXPimer2omyNBqUytua".to_string(),
            ),
            amount: 5_000_000 * NEAR_TOKEN,
        }],
        accounts: vec![AccountInfo {
            account_id: ".near".to_string(),
            public_key: ReadablePublicKey(
                "DuZSg3DRUQDiR5Wvq5Viifaw2FXPimer2omyNBqUytua".to_string(),
            ),
            amount: INITIAL_TOKEN_SUPPLY,
        }],
        contracts: vec![],
    }
}

/// Initializes genesis and client configs and stores in the given folder
pub fn init_configs(
    dir: &Path,
    chain_id: Option<&str>,
    account_id: Option<&str>,
    test_seed: Option<&str>,
) {
    fs::create_dir_all(dir).expect("Failed to create directory");
    // Check if config already exists in home dir.
    if dir.join(CONFIG_FILENAME).exists() {
        let config = Config::from_file(&dir.join(CONFIG_FILENAME));
        let genesis_config = GenesisConfig::from_file(&dir.join(config.genesis_file));
        panic!("Found existing config in {} with chain-id = {}. Use unsafe_reset_all to clear the folder.", dir.to_str().unwrap(), genesis_config.chain_id);
    }
    let chain_id = chain_id.map(|c| c.to_string()).unwrap_or(random_chain_id());
    match chain_id.as_ref() {
        "mainnet" => {
            // TODO:
            unimplemented!();
        }
        "testnet" => {
            if test_seed.is_some() {
                panic!("Test seed is not supported for official TestNet");
            }
            let config = Config::default();
            config.write_to_file(&dir.join(CONFIG_FILENAME));

            // If account id was given, create new key pair for this validator.
            if let Some(account_id) = account_id {
                let signer = InMemorySigner::new(account_id.to_string());
                info!(target: "near", "Use key {} for {} to stake.", signer.public_key, account_id);
                signer.write_to_file(&dir.join(config.validator_key_file));
            }

            let network_signer = InMemorySigner::new("".to_string());
            network_signer.write_to_file(&dir.join(config.node_key_file));

            testnet_genesis().write_to_file(&dir.join(config.genesis_file));
            info!(target: "near", "Generated node key and genesis file in {}", dir.to_str().unwrap());
        }
        _ => {
            // Create new configuration, key files and genesis for one validator.
            let mut config = Config::default();
            config.network.skip_sync_wait = true;
            config.write_to_file(&dir.join(CONFIG_FILENAME));

            let account_id = account_id.unwrap_or("test.near").to_string();

            let signer = if let Some(test_seed) = test_seed {
                InMemorySigner::from_seed(&account_id, test_seed)
            } else {
                InMemorySigner::new(account_id.clone())
            };
            signer.write_to_file(&dir.join(config.validator_key_file));

            let network_signer = InMemorySigner::new("".to_string());
            network_signer.write_to_file(&dir.join(config.node_key_file));

            let genesis_config = GenesisConfig {
                genesis_time: Utc::now(),
                chain_id,
                num_block_producers: 1,
                block_producers_per_shard: vec![1],
                avg_fisherman_per_shard: vec![0],
                dynamic_resharding: false,
                epoch_length: 1000,
                validators: vec![AccountInfo {
                    account_id: account_id.clone(),
                    public_key: signer.public_key.to_readable(),
                    amount: TESTING_INIT_STAKE,
                }],
                accounts: vec![AccountInfo {
                    account_id,
                    public_key: signer.public_key.to_readable(),
                    amount: TESTING_INIT_BALANCE,
                }],
                contracts: vec![],
            };
            genesis_config.write_to_file(&dir.join(config.genesis_file));
            info!(target: "near", "Generated node key, validator key, genesis file in {}", dir.to_str().unwrap());
        }
    }
}

pub fn create_testnet_configs_from_seeds(
    seeds: Vec<String>,
    num_non_validators: usize,
    local_ports: bool,
) -> (Vec<Config>, Vec<InMemorySigner>, Vec<InMemorySigner>, GenesisConfig) {
    let num_validators = seeds.len() - num_non_validators;
    let signers =
        seeds.iter().map(|seed| InMemorySigner::new(seed.to_string())).collect::<Vec<_>>();
    let network_signers =
        (0..seeds.len()).map(|_| InMemorySigner::from_random()).collect::<Vec<_>>();
    let accounts = seeds
        .iter()
        .enumerate()
        .map(|(i, seed)| AccountInfo {
            account_id: seed.to_string(),
            public_key: signers[i].public_key.to_readable(),
            amount: TESTING_INIT_BALANCE,
        })
        .collect::<Vec<_>>();
    let validators = seeds
        .iter()
        .enumerate()
        .take(seeds.len() - num_non_validators)
        .map(|(i, seed)| AccountInfo {
            account_id: seed.to_string(),
            public_key: signers[i].public_key.to_readable(),
            amount: TESTING_INIT_STAKE,
        })
        .collect::<Vec<_>>();
    let genesis_config = GenesisConfig {
        genesis_time: Utc::now(),
        chain_id: random_chain_id(),
        num_block_producers: num_validators,
        block_producers_per_shard: vec![num_validators],
        avg_fisherman_per_shard: vec![0],
        dynamic_resharding: false,
        epoch_length: 10,
        validators,
        accounts,
        contracts: vec![],
    };
    let mut configs = vec![];
    let first_node_port = open_port();
    for i in 0..seeds.len() {
        let mut config = Config::default();
        if local_ports {
            config.network.addr =
                format!("127.0.0.1:{}", if i == 0 { first_node_port } else { open_port() });
            config.rpc.addr = format!("127.0.0.1:{}", open_port());
            config.network.boot_nodes = if i == 0 {
                "".to_string()
            } else {
                format!("{}@127.0.0.1:{}", network_signers[0].public_key, first_node_port)
            };
            config.network.skip_sync_wait = num_validators == 1;
            config.consensus.min_num_peers =
                cmp::min(num_validators - 1, config.consensus.min_num_peers);
        }
        configs.push(config);
    }
    (configs, signers, network_signers, genesis_config)
}

/// Create testnet configuration. If `local_ports` is true,
/// sets up new ports for all nodes except the first one and sets boot node to it.
pub fn create_testnet_configs(
    num_validators: usize,
    num_non_validators: usize,
    prefix: &str,
    local_ports: bool,
) -> (Vec<Config>, Vec<InMemorySigner>, Vec<InMemorySigner>, GenesisConfig) {
    create_testnet_configs_from_seeds(
        (0..(num_validators + num_non_validators))
            .map(|i| format!("{}{}", prefix, i))
            .collect::<Vec<_>>(),
        num_non_validators,
        local_ports,
    )
}

pub fn init_testnet_configs(
    dir: &Path,
    num_validators: usize,
    num_non_validators: usize,
    prefix: &str,
) {
    let (configs, signers, network_signers, genesis_config) =
        create_testnet_configs(num_validators, num_non_validators, prefix, false);
    for i in 0..(num_validators + num_non_validators) {
        let node_dir = dir.join(format!("{}{}", prefix, i));
        fs::create_dir_all(node_dir.clone()).expect("Failed to create directory");

        signers[i].write_to_file(&node_dir.join(configs[i].validator_key_file.clone()));
        network_signers[i].write_to_file(&node_dir.join(configs[i].node_key_file.clone()));

        genesis_config.write_to_file(&node_dir.join(configs[i].genesis_file.clone()));
        configs[i].write_to_file(&node_dir.join(CONFIG_FILENAME));
        info!(target: "near", "Generated node key, validator key, genesis file in {}", node_dir.to_str().unwrap());
    }
}

pub fn load_config(dir: &Path) -> NearConfig {
    let config = Config::from_file(&dir.join(CONFIG_FILENAME));
    let genesis_config = GenesisConfig::from_file(&dir.join(config.genesis_file.clone()));
    let signer = Arc::new(InMemorySigner::from_file(&dir.join(config.validator_key_file.clone())));
    let block_producer = BlockProducer::from(signer);
    let network_signer = InMemorySigner::from_file(&dir.join(config.node_key_file.clone()));
    NearConfig::new(config, &genesis_config, network_signer.into(), Some(&block_producer))
}

pub fn load_test_config(seed: &str, port: u16, genesis_config: &GenesisConfig) -> NearConfig {
    let mut config = Config::default();
    config.network.addr = format!("0.0.0.0:{}", port);
    config.rpc.addr = format!("0.0.0.0:{}", port + 100);
    let signer = Arc::new(InMemorySigner::from_seed(seed, seed));
    let block_producer = BlockProducer::from(signer.clone());
    NearConfig::new(config, &genesis_config, signer.into(), Some(&block_producer))
}

#[cfg(test)]
mod tests {
    use serde_json::json;

    use near_primitives::types::ReadablePublicKey;

    use super::*;

    #[test]
    fn test_deserialize() {
        let data = json!({
            "genesis_time": "2019-05-07T00:10:14.434719Z",
            "chain_id": "test-chain-XYQAS",
            "num_block_producers": 1,
            "block_producers_per_shard": [1],
            "avg_fisherman_per_shard": [1],
            "dynamic_resharding": false,
            "epoch_length": 100,
            "accounts": [{"account_id": "alice.near", "public_key": "6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq", "amount": "0x64"}],
            "validators": [{"account_id": "alice.near", "public_key": "6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq", "amount": "32"}],
            "contracts": [],
        });
        let spec = GenesisConfig::from(data.to_string().as_str());
        assert_eq!(
            spec.validators[0],
            AccountInfo {
                account_id: "alice.near".to_string(),
                public_key: ReadablePublicKey(
                    "6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq".to_string()
                ),
                amount: 50
            }
        );
    }
}

'''
'''--- near/src/lib.rs ---
use std::fs;
use std::path::Path;
use std::sync::Arc;

use actix::{Actor, Addr, AsyncContext};
use log::info;

use near_client::{ClientActor, ViewClientActor};
use near_jsonrpc::start_http;
use near_network::PeerManagerActor;
use near_store::create_store;

pub use crate::config::{init_configs, load_config, load_test_config, GenesisConfig, NearConfig, NEAR_TOKEN};
pub use crate::runtime::NightshadeRuntime;

pub mod config;
mod runtime;
mod validator_manager;

const STORE_PATH: &str = "data";

pub fn get_store_path(base_path: &Path) -> String {
    let mut store_path = base_path.to_owned();
    store_path.push(STORE_PATH);
    match fs::canonicalize(store_path.clone()) {
        Ok(path) => info!(target: "near", "Opening store database at {:?}", path),
        _ => {
            info!(target: "near", "Did not find {:?} path, will be creating new store database", store_path)
        }
    };
    store_path.to_str().unwrap().to_owned()
}

pub fn start_with_config(
    home_dir: &Path,
    config: NearConfig,
) -> (Addr<ClientActor>, Addr<ViewClientActor>) {
    let store = create_store(&get_store_path(home_dir));
    let runtime =
        Arc::new(NightshadeRuntime::new(home_dir, store.clone(), config.genesis_config.clone()));

    let view_client = ViewClientActor::new(
        store.clone(),
        config.genesis_config.genesis_time.clone(),
        runtime.clone(),
    )
    .unwrap()
    .start();
    let view_client1 = view_client.clone();
    let client = ClientActor::create(move |ctx| {
        let network_actor =
            PeerManagerActor::new(store.clone(), config.network_config, ctx.address().recipient())
                .unwrap()
                .start();

        start_http(config.rpc_config, ctx.address(), view_client1);

        ClientActor::new(
            config.client_config,
            store.clone(),
            config.genesis_config.genesis_time,
            runtime,
            network_actor.recipient(),
            config.block_producer,
        )
        .unwrap()
    });
    (client, view_client)
}

'''
'''--- near/src/main.rs ---
use std::fs;
use std::path::Path;

use actix::System;
use clap::{App, Arg, SubCommand};
use log::{info, LevelFilter};

use near::config::init_testnet_configs;
use near::{get_store_path, init_configs, load_config, start_with_config};

fn init_logging(verbose: bool) {
    if verbose {
        env_logger::Builder::new()
            .filter_module("tokio_reactor", LevelFilter::Info)
            .filter_module("cranelift_codegen", LevelFilter::Warn)
            .filter_module("cranelift_wasm", LevelFilter::Warn)
            .filter(None, LevelFilter::Debug)
            .init();
    } else {
        env_logger::Builder::new()
            .filter_module("tokio_reactor", LevelFilter::Info)
            .filter(Some("near"), LevelFilter::Info)
            .filter(Some("info"), LevelFilter::Info)
            .filter(None, LevelFilter::Warn)
            .init();
    }
}

fn get_default_home() -> String {
    match std::env::var("NEAR_HOME") {
        Ok(home) => home,
        Err(_) => match dirs::home_dir() {
            Some(mut home) => {
                home.push(".near");
                home.as_path().to_str().unwrap().to_string()
            }
            None => "".to_string(),
        },
    }
}

fn main() {
    let default_home = get_default_home();
    let matches = App::new("NEAR Protocol Node v0.1")
        .arg(Arg::with_name("verbose").long("verbose").help("Verbose logging").takes_value(false))
        .arg(
            Arg::with_name("home")
                .long("home")
                .default_value(&default_home)
                .help("Directory for config and data (default \"~/.near\")")
                .takes_value(true),
        )
        .subcommand(SubCommand::with_name("init").about("Initializes NEAR configuration")
            .arg(Arg::with_name("chain-id").long("chain-id").takes_value(true).help("Chain ID, by default creates new random"))
            .arg(Arg::with_name("account-id").long("account-id").takes_value(true).help("Account ID for initial validator"))
            .arg(Arg::with_name("test-seed").long("test-seed").takes_value(true).help("Specify private key generated from seed (TESTING ONLY)"))
        )
        .subcommand(SubCommand::with_name("testnet").about("Setups testnet configuration with all necessary files (validator key, node key, genesis and config)")
            .arg(Arg::with_name("v").long("v").takes_value(true).help("Number of validators to initialize the testnet with (default 4)"))
            .arg(Arg::with_name("n").long("n").takes_value(true).help("Number of non-validators to initialize the testnet with (default 0)"))
            .arg(Arg::with_name("prefix").long("prefix").takes_value(true).help("Prefix the directory name for each node with (node results in node0, node1, ...) (default \"node\")"))
        )
        .subcommand(SubCommand::with_name("run").about("Runs NEAR node")
            .arg(Arg::with_name("produce-empty-blocks").long("produce-empty-blocks").help("Set this to false to only produce blocks when there are txs or receipts (default true)").default_value("true").takes_value(true))
        )
        .subcommand(SubCommand::with_name("unsafe_reset_data").about("(unsafe) Remove all the data, effectively resetting node to genesis state (keeps genesis and config)"))
        .subcommand(SubCommand::with_name("unsafe_reset_all").about("(unsafe) Remove all the config, keys, data and effectively removing all information about the network"))
        .get_matches();

    init_logging(matches.is_present("verbose"));

    let home_dir = matches.value_of("home").map(|dir| Path::new(dir)).unwrap();

    match matches.subcommand() {
        ("init", Some(args)) => {
            // TODO: Check if `home` exists. If exists check what networks we already have there.
            let chain_id = args.value_of("chain-id");
            let account_id = args.value_of("account-id");
            let test_seed = args.value_of("test-seed");
            init_configs(home_dir, chain_id, account_id, test_seed);
        }
        ("testnet", Some(args)) => {
            let num_validators = args
                .value_of("v")
                .map(|x| x.parse().expect("Failed to parse number of validators"))
                .unwrap_or(4);
            let num_non_validators = args
                .value_of("n")
                .map(|x| x.parse().expect("Failed to parse number of non-validators"))
                .unwrap_or(0);
            let prefix = args.value_of("prefix").unwrap_or("node");
            init_testnet_configs(home_dir, num_validators, num_non_validators, prefix);
        }
        ("run", Some(args)) => {
            // Load configs from home.
            let mut near_config = load_config(home_dir);
            // Override some parameters from command line.
            if let Some(produce_empty_blocks) = args
                .value_of("produce-empty-blocks")
                .map(|x| x.parse().expect("Failed to parse boolean"))
            {
                near_config.client_config.produce_empty_blocks = produce_empty_blocks;
            }

            let system = System::new("NEAR");
            start_with_config(home_dir, near_config);
            system.run().unwrap();
        }
        ("unsafe_reset_data", Some(_args)) => {
            let store_path = get_store_path(home_dir);
            info!(target: "near", "Removing all data from {}", store_path);
            fs::remove_dir_all(store_path).expect("Removing data failed");
        }
        ("unsafe_reset_all", Some(_args)) => {
            info!(target: "near", "Removing all data and config from {}", home_dir.to_str().unwrap());
            fs::remove_dir_all(home_dir).expect("Removing data and config failed.");
        }
        (_, _) => unreachable!(),
    }
}

'''
'''--- near/src/runtime.rs ---
use std::convert::TryFrom;
use std::io::Cursor;
use std::path::Path;
use std::sync::{Arc, Mutex, RwLock};

use byteorder::{LittleEndian, ReadBytesExt};
use log::debug;

use near_chain::{
    BlockHeader, Error, ErrorKind, ReceiptResult, RuntimeAdapter, ValidTransaction, Weight,
};
use near_primitives::account::AccessKey;
use near_primitives::crypto::signature::{PublicKey, Signature};
use near_primitives::hash::{hash, CryptoHash};
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::transaction::{ReceiptTransaction, SignedTransaction, TransactionResult};
use near_primitives::types::{AccountId, BlockIndex, Epoch, MerkleHash, ShardId, ValidatorStake};
use near_primitives::utils::prefix_for_access_key;
use near_store::{get, Store, StoreUpdate, Trie, TrieUpdate, WrappedTrieChanges};
use near_verifier::TransactionVerifier;
use node_runtime::adapter::query_client;
use node_runtime::ethereum::EthashProvider;
use node_runtime::state_viewer::{AccountViewCallResult, TrieViewer, ViewStateResult};
use node_runtime::{ApplyState, Runtime, ETHASH_CACHE_PATH};

use crate::config::GenesisConfig;
use crate::validator_manager::{ValidatorEpochConfig, ValidatorManager};

const POISONED_LOCK_ERR: &str = "The lock was poisoned.";

/// Defines Nightshade state transition, validator rotation and block weight for fork choice rule.
/// TODO: this possibly should be merged with the runtime cargo or at least reconsiled on the interfaces.
pub struct NightshadeRuntime {
    genesis_config: GenesisConfig,

    pub trie: Arc<Trie>,
    trie_viewer: TrieViewer,
    runtime: Runtime,
    validator_manager: RwLock<ValidatorManager>,
}

impl NightshadeRuntime {
    pub fn new(home_dir: &Path, store: Arc<Store>, genesis_config: GenesisConfig) -> Self {
        let trie = Arc::new(Trie::new(store.clone()));
        let mut ethash_dir = home_dir.to_owned();
        ethash_dir.push(ETHASH_CACHE_PATH);
        let ethash_provider = Arc::new(Mutex::new(EthashProvider::new(ethash_dir.as_path())));
        let runtime = Runtime::new(ethash_provider.clone());
        let trie_viewer = TrieViewer::new(ethash_provider);
        let initial_epoch_config = ValidatorEpochConfig {
            rng_seed: [0; 32],
            num_shards: genesis_config.block_producers_per_shard.len() as ShardId,
            num_block_producers: genesis_config.num_block_producers,
            block_producers_per_shard: genesis_config.block_producers_per_shard.clone(),
            avg_fisherman_per_shard: genesis_config.avg_fisherman_per_shard.clone(),
        };
        let validator_manager = RwLock::new(
            ValidatorManager::new(
                initial_epoch_config,
                genesis_config
                    .validators
                    .iter()
                    .map(|account_info| ValidatorStake {
                        account_id: account_info.account_id.clone(),
                        public_key: PublicKey::try_from(account_info.public_key.0.as_str())
                            .unwrap(),
                        amount: account_info.amount,
                    })
                    .collect(),
                store,
            )
            .expect("Failed to start Validator Manager"),
        );
        NightshadeRuntime { genesis_config, trie, runtime, trie_viewer, validator_manager }
    }

    /// Returns current epoch and position in the epoch for given height.
    fn height_to_epoch(&self, height: BlockIndex) -> (Epoch, BlockIndex) {
        (height / self.genesis_config.epoch_length, height % self.genesis_config.epoch_length)
    }
}

impl RuntimeAdapter for NightshadeRuntime {
    fn genesis_state(&self, shard_id: ShardId) -> (StoreUpdate, MerkleHash) {
        let accounts = self
            .genesis_config
            .accounts
            .iter()
            .filter_map(|account_info| {
                if self.account_id_to_shard_id(&account_info.account_id) == shard_id {
                    Some((
                        account_info.account_id.clone(),
                        account_info.public_key.clone(),
                        account_info.amount,
                    ))
                } else {
                    None
                }
            })
            .collect::<Vec<_>>();
        let validators = self
            .genesis_config
            .validators
            .iter()
            .filter_map(|account_info| {
                if self.account_id_to_shard_id(&account_info.account_id) == shard_id {
                    Some((
                        account_info.account_id.clone(),
                        account_info.public_key.clone(),
                        account_info.amount,
                    ))
                } else {
                    None
                }
            })
            .collect::<Vec<_>>();
        let contracts = self
            .genesis_config
            .contracts
            .iter()
            .filter(|(account_id, _)| self.account_id_to_shard_id(account_id) == shard_id)
            .cloned()
            .collect::<Vec<_>>();
        let state_update = TrieUpdate::new(self.trie.clone(), MerkleHash::default());
        let (store_update, state_root) =
            self.runtime.apply_genesis_state(state_update, &accounts, &validators, &contracts);
        (store_update, state_root)
    }

    fn compute_block_weight(
        &self,
        prev_header: &BlockHeader,
        header: &BlockHeader,
    ) -> Result<Weight, Error> {
        let account_info = &self.genesis_config.validators
            [(header.height as usize) % self.genesis_config.validators.len()];
        if !header.verify_block_producer(
            &PublicKey::try_from(account_info.public_key.0.as_str()).unwrap(),
        ) {
            return Err(ErrorKind::InvalidBlockProposer.into());
        }
        Ok(prev_header.total_weight.next(header.approval_sigs.len() as u64))
    }

    fn get_epoch_block_proposers(
        &self,
        height: BlockIndex,
    ) -> Result<Vec<(AccountId, u64)>, Box<dyn std::error::Error>> {
        let (epoch, _) = self.height_to_epoch(height);
        let mut vm = self.validator_manager.write().expect(POISONED_LOCK_ERR);
        let validator_assignemnt = vm.get_validators(epoch)?;
        Ok(validator_assignemnt
            .block_producers
            .iter()
            .enumerate()
            .map(|(index, seats)| {
                (validator_assignemnt.validators[index].account_id.clone(), *seats)
            })
            .collect())
    }

    fn get_block_proposer(
        &self,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>> {
        let (epoch, idx) = self.height_to_epoch(height);
        let mut vm = self.validator_manager.write().expect(POISONED_LOCK_ERR);
        let validator_assignemnt = vm.get_validators(epoch)?;
        let total_seats: u64 = validator_assignemnt.block_producers.iter().sum();
        let mut cur_seats = 0;
        for (i, seats) in validator_assignemnt.block_producers.iter().enumerate() {
            if cur_seats + seats > idx % total_seats {
                return Ok(validator_assignemnt.validators[i].account_id.clone());
            }
            cur_seats += seats;
        }
        unreachable!()
    }

    fn get_chunk_proposer(
        &self,
        shard_id: ShardId,
        height: BlockIndex,
    ) -> Result<AccountId, Box<dyn std::error::Error>> {
        let (epoch, idx) = self.height_to_epoch(height);
        let mut vm = self.validator_manager.write().expect(POISONED_LOCK_ERR);
        let validator_assignemnt = vm.get_validators(epoch)?;
        let total_seats: u64 = validator_assignemnt.chunk_producers[shard_id as usize]
            .iter()
            .map(|(_, seats)| seats)
            .sum();
        let mut cur_seats = 0;
        for (index, seats) in validator_assignemnt.chunk_producers[shard_id as usize].iter() {
            if cur_seats + seats > idx % total_seats {
                return Ok(validator_assignemnt.validators[*index].account_id.clone());
            }
            cur_seats += seats;
        }
        unreachable!()
    }

    fn check_validator_signature(&self, _account_id: &AccountId, _signature: &Signature) -> bool {
        true
    }

    fn num_shards(&self) -> ShardId {
        // TODO: should be dynamic.
        self.genesis_config.block_producers_per_shard.len() as ShardId
    }

    fn account_id_to_shard_id(&self, account_id: &AccountId) -> ShardId {
        let mut cursor = Cursor::new((hash(&account_id.clone().into_bytes()).0).0);
        cursor.read_u32::<LittleEndian>().expect("Must not happened")
            % (self.genesis_config.block_producers_per_shard.len() as ShardId)
    }

    fn validate_tx(
        &self,
        _shard_id: ShardId,
        state_root: MerkleHash,
        transaction: SignedTransaction,
    ) -> Result<ValidTransaction, String> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        let verifier = TransactionVerifier::new(&state_update);
        if let Err(err) = verifier.verify_transaction(&transaction) {
            debug!(target: "runtime", "Tx {:?} validation failed: {:?}", transaction, err);
            return Err(err);
        }
        Ok(ValidTransaction { transaction })
    }

    fn apply_transactions(
        &self,
        shard_id: ShardId,
        state_root: &MerkleHash,
        block_index: BlockIndex,
        prev_block_hash: &CryptoHash,
        receipts: &Vec<Vec<ReceiptTransaction>>,
        transactions: &Vec<SignedTransaction>,
    ) -> Result<
        (WrappedTrieChanges, MerkleHash, Vec<TransactionResult>, ReceiptResult),
        Box<dyn std::error::Error>,
    > {
        let apply_state = ApplyState {
            root: state_root.clone(),
            shard_id,
            block_index,
            parent_block_hash: *prev_block_hash,
        };
        let state_update = TrieUpdate::new(self.trie.clone(), apply_state.root);
        let apply_result =
            self.runtime.apply(state_update, &apply_state, &receipts, &transactions)?;

        // Deal with validator proposals and epoch finishing.
        let mut vm = self.validator_manager.write().expect(POISONED_LOCK_ERR);
        vm.add_proposals(
            state_root.clone(),
            apply_result.root.clone(),
            apply_result.validator_proposals,
        );
        // If epoch changed, finalize previous epoch.
        // TODO: right now at least one block per epoch is required.
        let (epoch, _) = self.height_to_epoch(block_index);
        if vm.last_epoch() != epoch {
            // TODO(779): provide source of randomness here.
            let mut rng_seed = [0; 32];
            rng_seed.copy_from_slice(prev_block_hash.as_ref());
            // TODO(973): calculate number of shards for dynamic resharding.
            let epoch_config = ValidatorEpochConfig {
                rng_seed,
                num_shards: self.genesis_config.block_producers_per_shard.len() as ShardId,
                num_block_producers: self.genesis_config.num_block_producers,
                block_producers_per_shard: self.genesis_config.block_producers_per_shard.clone(),
                avg_fisherman_per_shard: self.genesis_config.avg_fisherman_per_shard.clone(),
            };
            vm.finalize_epoch(epoch - 1, epoch_config, apply_result.root.clone())?;
        }

        Ok((
            WrappedTrieChanges::new(self.trie.clone(), apply_result.trie_changes),
            apply_result.root,
            apply_result.tx_result,
            apply_result.new_receipts,
        ))
    }

    fn query(
        &self,
        state_root: MerkleHash,
        height: BlockIndex,
        path: &str,
        data: &[u8],
    ) -> Result<ABCIQueryResponse, Box<dyn std::error::Error>> {
        query_client(self, state_root, height, path, data)
    }
}

impl node_runtime::adapter::RuntimeAdapter for NightshadeRuntime {
    fn view_account(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<AccountViewCallResult, Box<dyn std::error::Error>> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        self.trie_viewer.view_account(&state_update, account_id)
    }

    fn call_function(
        &self,
        state_root: MerkleHash,
        height: BlockIndex,
        contract_id: &AccountId,
        method_name: &str,
        args: &[u8],
        logs: &mut Vec<String>,
    ) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        self.trie_viewer.call_function(state_update, height, contract_id, method_name, args, logs)
    }

    fn view_access_key(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, Box<dyn std::error::Error>> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        self.trie_viewer.view_access_key(&state_update, account_id, public_key)
    }

    fn view_access_keys(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<Vec<(PublicKey, AccessKey)>, Box<dyn std::error::Error>> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        let prefix = prefix_for_access_key(account_id);
        match state_update.iter(&prefix) {
            Ok(iter) => iter
                .map(|key| {
                    let public_key = &key[prefix.len()..];
                    let access_key =
                        get::<AccessKey>(&state_update, &key).ok_or("Missing key from iterator")?;
                    PublicKey::try_from(public_key)
                        .map_err(|err| format!("{}", err).into())
                        .map(|key| (key, access_key))
                })
                .collect::<Result<Vec<_>, Box<dyn std::error::Error>>>(),
            Err(e) => Err(e),
        }
    }

    fn view_state(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<ViewStateResult, Box<dyn std::error::Error>> {
        let state_update = TrieUpdate::new(self.trie.clone(), state_root);
        self.trie_viewer.view_state(&state_update, account_id)
    }
}

'''
'''--- near/src/test_utils.rs ---

'''
'''--- near/src/validator_manager.rs ---
use std::collections::hash_map::Entry;
use std::collections::HashMap;
use std::fmt;
use std::iter;
use std::sync::Arc;

use rand::seq::SliceRandom;
use rand::{rngs::StdRng, SeedableRng};
use serde_derive::{Deserialize, Serialize};

use near_primitives::hash::CryptoHash;
use near_primitives::types::{Balance, Epoch, MerkleHash, ShardId, ValidatorId, ValidatorStake};
use near_primitives::utils::index_to_bytes;
use near_store::{Store, COL_VALIDATORS};

#[derive(Eq, PartialEq)]
pub enum ValidatorError {
    /// Error calculating threshold from given stakes for given number of seats.
    /// Only should happened if calling code doesn't check for integer value of stake > number of seats.
    ThresholdError(Balance, u64),
    /// Requesting validators for an epoch that wasn't computed yet.
    EpochOutOfBounds,
    /// Number of selected seats doesn't match requested.
    SelectedSeatsMismatch(u64, ValidatorId),
    /// Other error.
    Other(String),
}

impl std::error::Error for ValidatorError {}

impl fmt::Debug for ValidatorError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            ValidatorError::ThresholdError(stakes_sum, num_seats) => write!(
                f,
                "Total stake {} must be higher than the number of seats {}",
                stakes_sum, num_seats
            ),
            ValidatorError::EpochOutOfBounds => write!(f, "Epoch out of bounds"),
            ValidatorError::SelectedSeatsMismatch(selected, required) => write!(
                f,
                "Number of selected seats {} < total number of seats {}",
                selected, required
            ),
            ValidatorError::Other(err) => write!(f, "Other: {}", err),
        }
    }
}

impl fmt::Display for ValidatorError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", self)
    }
}

impl From<std::io::Error> for ValidatorError {
    fn from(error: std::io::Error) -> ValidatorError {
        ValidatorError::Other(error.to_string())
    }
}

/// Find threshold of stake per seat, given provided stakes and required number of seats.
fn find_threshold(stakes: &[Balance], num_seats: u64) -> Result<Balance, ValidatorError> {
    let stakes_sum: Balance = stakes.iter().sum();
    if stakes_sum < num_seats.into() {
        return Err(ValidatorError::ThresholdError(stakes_sum, num_seats));
    }
    let (mut left, mut right): (Balance, Balance) = (1, stakes_sum + 1);
    'outer: loop {
        if left == right - 1 {
            break Ok(left);
        }
        let mid = (left + right) / 2;
        let mut current_sum: Balance = 0;
        for item in stakes.iter() {
            current_sum += item / mid;
            if current_sum >= num_seats as u128 {
                left = mid;
                continue 'outer;
            }
        }
        right = mid;
    }
}

const LAST_EPOCH_KEY: &[u8] = b"LAST_EPOCH";

/// Epoch config, determines validator assignment for given epoch.
/// Can change from epoch to epoch depending on the sharding and other parameters, etc.
#[derive(Clone)]
pub struct ValidatorEpochConfig {
    /// Source of randomnes.
    pub rng_seed: [u8; 32],
    /// Number of shards currently.
    pub num_shards: ShardId,
    /// Number of block producers.
    pub num_block_producers: ValidatorId,
    /// Number of block producers per each shard.
    pub block_producers_per_shard: Vec<ValidatorId>,
    /// Expected number of fisherman per each shard.
    pub avg_fisherman_per_shard: Vec<ValidatorId>,
}

/// Information about validator seat assignments.
#[derive(Default, Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]
pub struct ValidatorAssignment {
    /// List of current validators.
    pub validators: Vec<ValidatorStake>,
    /// Weights for each of the validators responsible for block production.
    pub block_producers: Vec<u64>,
    /// Per each shard, ids and seats of validators that are responsible.
    pub chunk_producers: Vec<Vec<(ValidatorId, u64)>>,
    /// Weight of given validator used to determine how many shards they will validate.
    pub fishermen: Vec<(ValidatorId, u64)>,
}

/// Manages current validators and validator proposals in the current epoch across different forks.
pub struct ValidatorManager {
    store: Arc<Store>,
    last_epoch: Epoch,
    proposals: HashMap<CryptoHash, Vec<ValidatorStake>>,
    epoch_validators: HashMap<Epoch, ValidatorAssignment>,
}

/// Calculates new seat assignments based on current seat assignemnts and proposals.
fn proposals_to_assignments(
    epoch_config: ValidatorEpochConfig,
    current_assignments: &ValidatorAssignment,
    proposals: Vec<ValidatorStake>,
) -> Result<ValidatorAssignment, ValidatorError> {
    // TODO: kick out previous validators that didn't produce blocks.

    // Combine proposals with rollovers.
    let mut ordered_proposals = proposals;
    let mut indices = HashMap::new();
    for (i, p) in ordered_proposals.iter().enumerate() {
        indices.insert(p.account_id.clone(), i);
    }
    for r in current_assignments.validators.iter() {
        match indices.entry(r.account_id.clone()) {
            Entry::Occupied(e) => {
                let i = *e.get();
                ordered_proposals[i].amount += r.amount;
            }
            Entry::Vacant(e) => {
                e.insert(ordered_proposals.len());
                ordered_proposals.push(r.clone());
            }
        }
    }

    // Get the threshold given current number of seats and stakes.
    let num_fisherman_seats: usize = epoch_config.avg_fisherman_per_shard.iter().sum();
    let num_seats = epoch_config.num_block_producers + num_fisherman_seats;
    let stakes = ordered_proposals.iter().map(|p| p.amount).collect::<Vec<_>>();
    let threshold = find_threshold(&stakes, num_seats as u64)?;

    // Duplicate each proposal for number of seats it has.
    let mut dup_proposals = ordered_proposals
        .iter()
        .enumerate()
        .flat_map(|(i, p)| iter::repeat(i).take((p.amount / threshold) as usize))
        .collect::<Vec<_>>();
    if dup_proposals.len() < num_seats as usize {
        return Err(ValidatorError::SelectedSeatsMismatch(dup_proposals.len() as u64, num_seats));
    }

    // Shuffle duplicate proposals.
    let mut rng: StdRng = SeedableRng::from_seed(epoch_config.rng_seed);
    dup_proposals.shuffle(&mut rng);

    // Block producers are aggregated group of first `num_block_producers` proposals.
    let mut block_producers = Vec::new();
    block_producers.resize(ordered_proposals.len(), 0);
    for i in 0..epoch_config.num_block_producers {
        block_producers[dup_proposals[i]] += 1;
    }

    // Collect proposals into block producer assignments.
    let mut chunk_producers: Vec<Vec<(ValidatorId, u64)>> = vec![];
    let mut last_index: usize = 0;
    for num_seats in epoch_config.block_producers_per_shard.iter() {
        let mut cp_to_index: HashMap<ValidatorId, usize> = HashMap::default();
        let mut cp: Vec<(ValidatorId, u64)> = vec![];
        for i in 0..*num_seats {
            let proposal_index = dup_proposals[(i + last_index) % epoch_config.num_block_producers];
            if let Some(j) = cp_to_index.get(&proposal_index) {
                cp[*j as usize].1 += 1;
            } else {
                cp_to_index.insert(proposal_index, cp.len());
                cp.push((proposal_index, 1));
            }
        }
        chunk_producers.push(cp);
        last_index = (last_index + num_seats) % epoch_config.num_block_producers;
    }

    // TODO: implement fishermen allocation.

    Ok(ValidatorAssignment {
        validators: ordered_proposals,
        block_producers,
        chunk_producers,
        fishermen: vec![],
    })
}

impl ValidatorManager {
    pub fn new(
        initial_epoch_config: ValidatorEpochConfig,
        initial_validators: Vec<ValidatorStake>,
        store: Arc<Store>,
    ) -> Result<Self, ValidatorError> {
        let proposals = HashMap::default();
        let mut epoch_validators = HashMap::default();
        let last_epoch = match store.get_ser(COL_VALIDATORS, LAST_EPOCH_KEY) {
            // TODO: check consistency of the db by querying it here?
            Ok(Some(value)) => value,
            Ok(None) => {
                let initial_assigment = proposals_to_assignments(
                    initial_epoch_config,
                    &ValidatorAssignment::default(),
                    initial_validators,
                )?;
                epoch_validators.insert(0, initial_assigment.clone());
                epoch_validators.insert(1, initial_assigment);
                0
            }
            Err(err) => return Err(ValidatorError::Other(err.to_string())),
        };
        Ok(ValidatorManager { store, last_epoch, proposals, epoch_validators })
    }

    #[inline]
    pub fn last_epoch(&self) -> Epoch {
        self.last_epoch
    }

    pub fn get_validators(&mut self, epoch: Epoch) -> Result<&ValidatorAssignment, ValidatorError> {
        if !self.epoch_validators.contains_key(&epoch) {
            match self
                .store
                .get_ser(COL_VALIDATORS, &index_to_bytes(epoch))
                .map_err(|err| ValidatorError::Other(err.to_string()))?
            {
                Some(validators) => self.epoch_validators.insert(epoch, validators),
                None => return Err(ValidatorError::EpochOutOfBounds),
            };
        }
        match self.epoch_validators.get(&epoch) {
            Some(validators) => Ok(validators),
            None => Err(ValidatorError::Other("Should not happened".to_string())),
        }
    }

    /// Add proposals from given header into validators.
    pub fn add_proposals(
        &mut self,
        prev_state_root: MerkleHash,
        new_state_root: MerkleHash,
        mut proposals: Vec<ValidatorStake>,
    ) {
        // TODO: keep track of size here to make sure we can't be spammed storing all forks.
        let mut current_proposals = self.proposals.remove(&prev_state_root).unwrap_or(vec![]);
        current_proposals.append(&mut proposals);
        self.proposals.insert(new_state_root, current_proposals);
    }

    /// Call when `epoch` is finished to compute `epoch` + 2 validators.
    pub fn finalize_epoch(
        &mut self,
        epoch: Epoch,
        next_epoch_config: ValidatorEpochConfig,
        state_root: MerkleHash,
    ) -> Result<(), ValidatorError> {
        // If there are any proposals in given branch.
        if let Some(proposals) = self.proposals.remove(&state_root) {
            let mut store_update = self.store.store_update();
            let assignment = proposals_to_assignments(
                next_epoch_config,
                self.get_validators(epoch)?,
                proposals,
            )?;
            self.last_epoch = epoch + 1;
            store_update.set_ser(COL_VALIDATORS, &index_to_bytes(epoch + 2), &assignment)?;
            store_update.set_ser(COL_VALIDATORS, LAST_EPOCH_KEY, &self.last_epoch)?;
            store_update.commit().map_err(|err| ValidatorError::Other(err.to_string()))?;
        }
        self.proposals.clear();
        Ok(())
    }
}

#[cfg(test)]
mod test {
    use near_primitives::hash::hash;
    use near_primitives::test_utils::get_key_pair_from_seed;
    use near_store::test_utils::create_test_store;

    use super::*;

    fn stake(account_id: &str, amount: Balance) -> ValidatorStake {
        let (public_key, _) = get_key_pair_from_seed(account_id);
        ValidatorStake::new(account_id.to_string(), public_key, amount)
    }

    fn assignment(
        mut accounts: Vec<(&str, Balance)>,
        block_producers: Vec<u64>,
        chunk_producers: Vec<Vec<(usize, u64)>>,
        fishermen: Vec<(usize, u64)>,
    ) -> ValidatorAssignment {
        ValidatorAssignment {
            validators: accounts
                .drain(..)
                .map(|(account_id, amount)| ValidatorStake {
                    account_id: account_id.to_string(),
                    public_key: get_key_pair_from_seed(account_id).0,
                    amount,
                })
                .collect(),
            block_producers,
            chunk_producers,
            fishermen,
        }
    }

    fn config(
        num_shards: ShardId,
        num_block_producers: usize,
        num_fisherman: usize,
    ) -> ValidatorEpochConfig {
        ValidatorEpochConfig {
            rng_seed: [0; 32],
            num_shards,
            num_block_producers,
            block_producers_per_shard: (0..num_shards).map(|_| num_block_producers).collect(),
            avg_fisherman_per_shard: (0..num_shards).map(|_| num_fisherman).collect(),
        }
    }

    #[test]
    fn test_find_threshold() {
        assert_eq!(find_threshold(&[1_000_000, 1_000_000, 10], 10).unwrap(), 200_000);
        assert_eq!(find_threshold(&[1_000_000_000, 10], 10).unwrap(), 100_000_000);
        assert_eq!(find_threshold(&[1_000_000_000], 1_000_000_000).unwrap(), 1);
        assert_eq!(find_threshold(&[1_000, 1, 1, 1, 1, 1, 1, 1, 1, 1], 1).unwrap(), 1_000);
        assert!(find_threshold(&[1, 1, 2], 100).is_err());
    }

    #[test]
    fn test_proposals_to_assignments() {
        assert_eq!(
            proposals_to_assignments(
                config(2, 1, 1),
                &ValidatorAssignment::default(),
                vec![stake("test1", 1_000_000)]
            )
            .unwrap(),
            assignment(
                vec![("test1", 1_000_000)],
                vec![1],
                vec![vec![(0, 1)], vec![(0, 1)]],
                vec![]
            )
        );
        assert_eq!(
            proposals_to_assignments(
                ValidatorEpochConfig {
                    rng_seed: [0; 32],
                    num_shards: 5,
                    num_block_producers: 6,
                    block_producers_per_shard: vec![6, 2, 2, 2, 2],
                    avg_fisherman_per_shard: vec![6, 2, 2, 2, 2]
                },
                &ValidatorAssignment::default(),
                vec![
                    stake("test1", 1_000_000),
                    stake("test2", 1_000_000),
                    stake("test3", 1_000_000)
                ]
            )
            .unwrap(),
            assignment(
                vec![("test1", 1_000_000), ("test2", 1_000_000), ("test3", 1_000_000)],
                vec![3, 2, 1],
                vec![
                    // Shard 0 is block produced / validated by all block producers & fisherman.
                    vec![(0, 3), (1, 2), (2, 1)],
                    vec![(0, 1), (1, 1)],
                    vec![(0, 2)],
                    vec![(1, 1), (2, 1)],
                    vec![(0, 1), (1, 1)]
                ],
                vec![]
            )
        );
    }

    #[test]
    fn test_stake_validator() {
        let store = create_test_store();
        let config = config(1, 2, 2);
        let validators = vec![stake("test1", 1_000_000)];
        let mut am =
            ValidatorManager::new(config.clone(), validators.clone(), store.clone()).unwrap();
        let (sr1, sr2) = (hash(&vec![1]), hash(&vec![2]));
        am.add_proposals(sr1, sr2, vec![stake("test2", 1_000_000)]);
        let expected0 = assignment(vec![("test1", 1_000_000)], vec![2], vec![vec![(0, 2)]], vec![]);
        assert_eq!(am.get_validators(0).unwrap(), &expected0);
        assert_eq!(am.get_validators(1).unwrap(), &expected0);
        assert_eq!(am.get_validators(2), Err(ValidatorError::EpochOutOfBounds));
        am.finalize_epoch(0, config.clone(), sr2).unwrap();
        assert_eq!(am.last_epoch(), 1);
        assert_eq!(
            am.get_validators(2).unwrap(),
            &assignment(
                vec![("test2", 1_000_000), ("test1", 1_000_000)],
                vec![1, 1],
                vec![vec![(0, 1), (1, 1)]],
                vec![]
            )
        );

        // Start another validator manager from the same store to check that it saved the state.
        let mut am2 = ValidatorManager::new(config, validators, store).unwrap();
        assert_eq!(am2.last_epoch(), 1);
        assert_eq!(
            am2.get_validators(2).unwrap(),
            &assignment(
                vec![("test2", 1_000_000), ("test1", 1_000_000)],
                vec![1, 1],
                vec![vec![(0, 1), (1, 1)]],
                vec![]
            )
        );
    }

    /// Test handling forks across the epoch finalization.
    #[test]
    #[ignore]
    fn test_fork_finalization() {
        // TODO: figure out which fork to finalize.
    }
}

'''
'''--- near/tests/run_nodes.rs ---
use actix::{Actor, System};
use futures::future::Future;
use tempdir::TempDir;

use near::{load_test_config, start_with_config, GenesisConfig};
use near_client::GetBlock;
use near_network::test_utils::{convert_boot_nodes, WaitOrTimeout, open_port};
use near_primitives::test_utils::init_test_logger;

fn run_nodes(num_nodes: usize) {
    init_test_logger();

    let validators = (0..num_nodes).map(|i| format!("test{}", i + 1)).collect::<Vec<_>>();
    let genesis_config = GenesisConfig::test(validators.iter().map(|v| v.as_str()).collect());

    let mut near_configs = vec![];
    let first_node = open_port();
    for i in 0..num_nodes {
        let mut near_config = load_test_config(&validators[i], if i == 0 { first_node } else { open_port() }, &genesis_config);
        if i > 0 {
            near_config.network_config.boot_nodes = convert_boot_nodes(vec![(&validators[0], first_node)]);
        }
        near_configs.push(near_config);
    }

    let system = System::new("NEAR");

    let mut view_clients = vec![];
    for (i, near_config) in near_configs.drain(..).enumerate() {
        let dir = TempDir::new(&format!("two_nodes_{}", i)).unwrap();
        let (_client, view_client) = start_with_config(dir.path(), near_config);
        view_clients.push(view_client)
    }

    let view_client = view_clients.pop().unwrap();
    WaitOrTimeout::new(
        Box::new(move |_ctx| {
            actix::spawn(view_client.send(GetBlock::Best).then(|res| {
                match &res {
                    Ok(Ok(b)) if b.header.height > 4 && b.header.total_weight.to_num() > 6 => {
                        System::current().stop()
                    }
                    Err(_) => return futures::future::err(()),
                    _ => {}
                };
                futures::future::ok(())
            }));
        }),
        100,
        60000,
    )
        .start();

    system.run().unwrap();
}

/// Runs two nodes that should produce blocks one after another.
#[test]
fn run_nodes_2() {
    run_nodes(2);
}

#[test]
fn run_nodes_4() {
    run_nodes(4);
}

'''
'''--- near/tests/runtime_fork.rs ---
use std::collections::HashMap;
use std::sync::Arc;

use tempdir::TempDir;

use near::{get_store_path, GenesisConfig, NightshadeRuntime};
use near_chain::{Block, Chain, Provenance};
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::test_utils::init_test_logger;
use near_primitives::transaction::TransactionBody;
use near_store::create_store;

#[test]
fn runtime_hanldle_fork() {
    init_test_logger();

    let tmp_dir = TempDir::new("handle_fork").unwrap();
    let store = create_store(&get_store_path(tmp_dir.path()));
    let genesis_config = GenesisConfig::testing_spec(2, 1);
    let signer = Arc::new(InMemorySigner::from_seed("near.0", "near.0"));
    let runtime =
        Arc::new(NightshadeRuntime::new(tmp_dir.path(), store.clone(), genesis_config.clone()));

    let mut chain = Chain::new(store, runtime, genesis_config.genesis_time).unwrap();

    let tx1 = TransactionBody::send_money(1, "near.0", "near.1", 100).sign(&*signer);
    let tx2 = TransactionBody::send_money(1, "near.0", "near.1", 500).sign(&*signer);
    let tx3 = TransactionBody::send_money(2, "near.0", "near.1", 100).sign(&*signer);
    let state_root = chain.get_post_state_root(&chain.genesis().hash()).unwrap().clone();
    let b1 = Block::produce(
        chain.genesis(),
        1,
        state_root,
        vec![tx1],
        HashMap::default(),
        vec![],
        signer.clone(),
    );
    chain.process_block(b1.clone(), Provenance::NONE, |_, _, _| {}).unwrap();
    let b2 = Block::produce(
        chain.genesis(),
        2,
        state_root,
        vec![tx2],
        HashMap::default(),
        vec![],
        signer.clone(),
    );
    chain.process_block(b2, Provenance::NONE, |_, _, _| {}).unwrap();
    let state_root3 = chain.get_post_state_root(&b1.hash()).unwrap().clone();
    let b3 = Block::produce(
        &b1.header,
        3,
        state_root3,
        vec![tx3],
        HashMap::default(),
        vec![],
        signer.clone(),
    );
    chain.process_block(b3, Provenance::NONE, |_, _, _| {}).unwrap();
}

'''
'''--- near/tests/stake_nodes.rs ---
use actix::{Actor, System};
use futures::future::Future;
use tempdir::TempDir;

use near::{load_test_config, start_with_config, GenesisConfig};
use near_client::Status;
use near_network::test_utils::{convert_boot_nodes, open_port, WaitOrTimeout};
use near_network::NetworkClientMessages;
use near_primitives::serialize::BaseEncode;
use near_primitives::test_utils::init_test_logger;
use near_primitives::transaction::{StakeTransaction, TransactionBody};

/// Runs one validator network, sends staking transaction for the second node and
/// waits until it becomes a validator.
#[test]
fn test_stake_nodes() {
    init_test_logger();

    let genesis_config = GenesisConfig::testing_spec(2, 1);
    let first_node = open_port();
    let near1 = load_test_config("near.0", first_node, &genesis_config);
    let mut near2 = load_test_config("near.1", open_port(), &genesis_config);
    near2.network_config.boot_nodes = convert_boot_nodes(vec![("near.0", first_node)]);

    let system = System::new("NEAR");

    let dir1 = TempDir::new("sync_nodes_1").unwrap();
    let (client1, _view_client1) = start_with_config(dir1.path(), near1);
    let dir2 = TempDir::new("sync_nodes_2").unwrap();
    let (client2, _view_client2) = start_with_config(dir2.path(), near2.clone());

    let tx = TransactionBody::Stake(StakeTransaction {
        nonce: 1,
        originator: "near.1".to_string(),
        amount: 50_000_000,
        public_key: near2.block_producer.clone().unwrap().signer.public_key().to_base(),
    })
    .sign(&*near2.block_producer.clone().unwrap().signer);
    actix::spawn(client1.send(NetworkClientMessages::Transaction(tx)).map(|_| ()).map_err(|_| ()));

    WaitOrTimeout::new(
        Box::new(move |_ctx| {
            actix::spawn(client2.send(Status {}).then(|res| {
                if res.unwrap().unwrap().validators.len() == 2 {
                    System::current().stop()
                }
                futures::future::ok(())
            }));
        }),
        100,
        60000,
    )
    .start();

    system.run().unwrap();
}

'''
'''--- near/tests/sync_nodes.rs ---
use std::sync::Arc;

use actix::{Actor, System};
use futures::future::Future;
use tempdir::TempDir;

use near::{load_test_config, start_with_config, GenesisConfig, NightshadeRuntime};
use near_chain::{Block, BlockHeader, Chain};
use near_client::GetBlock;
use near_network::test_utils::{convert_boot_nodes, WaitOrTimeout};
use near_network::{NetworkClientMessages, PeerInfo};
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::test_utils::init_test_logger;
use near_store::test_utils::create_test_store;

/// Utility to generate genesis header from config for testing purposes.
fn genesis_header(genesis_config: GenesisConfig) -> BlockHeader {
    let dir = TempDir::new("unused").unwrap();
    let store = create_test_store();
    let genesis_time = genesis_config.genesis_time.clone();
    let runtime = Arc::new(NightshadeRuntime::new(dir.path(), store.clone(), genesis_config));
    let chain = Chain::new(store, runtime, genesis_time).unwrap();
    chain.genesis().clone()
}

/// One client is in front, another must sync to it before they can produce blocks.
#[test]
fn sync_nodes() {
    init_test_logger();

    let genesis_config = GenesisConfig::test(vec!["other"]);
    let genesis_header = genesis_header(genesis_config.clone());

    let mut near1 = load_test_config("test1", 25123, &genesis_config);
    near1.network_config.boot_nodes = convert_boot_nodes(vec![("test2", 25124)]);
    let mut near2 = load_test_config("test2", 25124, &genesis_config);
    near2.network_config.boot_nodes = convert_boot_nodes(vec![("test1", 25123)]);

    let system = System::new("NEAR");

    let dir1 = TempDir::new("sync_nodes_1").unwrap();
    let (client1, _) = start_with_config(dir1.path(), near1);

    let mut blocks = vec![];
    let mut prev = &genesis_header;
    let signer = Arc::new(InMemorySigner::from_seed("other", "other"));
    for _ in 0..=10 {
        let block = Block::empty(prev, signer.clone());
        let _ = client1.do_send(NetworkClientMessages::Block(
            block.clone(),
            PeerInfo::random().id,
            true,
        ));
        blocks.push(block);
        prev = &blocks[blocks.len() - 1].header;
    }

    let dir2 = TempDir::new("sync_nodes_2").unwrap();
    let (_, view_client2) = start_with_config(dir2.path(), near2);

    WaitOrTimeout::new(
        Box::new(move |_ctx| {
            actix::spawn(view_client2.send(GetBlock::Best).then(|res| {
                match &res {
                    Ok(Ok(b)) if b.header.height == 11 => System::current().stop(),
                    Err(_) => return futures::future::err(()),
                    _ => {}
                };
                futures::future::ok(())
            }));
        }),
        100,
        60000,
    )
    .start();

    system.run().unwrap();
}

'''
'''--- neardev/devkey.json ---
{"public_key":"2HAQanJwM4mU6hdPWuT25ze3JNNcAK9mrnS2WyMzZbH3","secret_key":"4xLT31U1B5Cg3FZQpBKCftw78unNG2D7SJv4wV5xsx821myw4KZTWygjSt3LTxvL5SwUTqwjnugHF2xcG6Kbnwvy","account_id":"roger_near_wallet"}
'''
'''--- nearlib/.eslintrc.yml ---
env:
  es6: true
  node: true
extends: 'eslint:recommended'
parserOptions:
  ecmaVersion: 2018
  ecmaFeatures:
    experimentalObjectRestSpread: true
rules:
  indent:
    - error
    - 4
  linebreak-style:
    - error
    - unix
  quotes:
    - error
    - single
  semi:
    - error
    - always
  no-console: off
globals:
  jasmine: true
  window: true
  fetch: true
  Headers: true
  document: true

'''
'''--- nearlib/API.md ---
# API

<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

### Table of Contents

-   [require](#require)
-   [KeyPair](#keypair)
    -   [getPublicKey](#getpublickey)
    -   [getSecretKey](#getsecretkey)
        -   [Examples](#examples)
    -   [fromRandomSeed](#fromrandomseed)
        -   [Examples](#examples-1)
    -   [encodeBufferInBs58](#encodebufferinbs58)
        -   [Parameters](#parameters)
        -   [Examples](#examples-2)
-   [KeyPair](#keypair-1)
    -   [Parameters](#parameters-1)
    -   [getPublicKey](#getpublickey-1)
    -   [getSecretKey](#getsecretkey-1)
        -   [Examples](#examples-3)
    -   [fromRandomSeed](#fromrandomseed-1)
        -   [Examples](#examples-4)
    -   [encodeBufferInBs58](#encodebufferinbs58-1)
        -   [Parameters](#parameters-2)
        -   [Examples](#examples-5)
-   [Account](#account)
    -   [Parameters](#parameters-3)
    -   [Examples](#examples-6)
    -   [createAccount](#createaccount)
        -   [Parameters](#parameters-4)
        -   [Examples](#examples-7)
    -   [addAccessKey](#addaccesskey)
        -   [Parameters](#parameters-5)
        -   [Examples](#examples-8)
    -   [createAccountWithRandomKey](#createaccountwithrandomkey)
        -   [Parameters](#parameters-6)
        -   [Examples](#examples-9)
    -   [viewAccount](#viewaccount)
        -   [Parameters](#parameters-7)
        -   [Examples](#examples-10)
-   [Near](#near)
    -   [Parameters](#parameters-8)
    -   [callViewFunction](#callviewfunction)
        -   [Parameters](#parameters-9)
        -   [Examples](#examples-11)
    -   [scheduleFunctionCall](#schedulefunctioncall)
        -   [Parameters](#parameters-10)
        -   [Examples](#examples-12)
    -   [deployContract](#deploycontract)
        -   [Parameters](#parameters-11)
        -   [Examples](#examples-13)
    -   [getTransactionStatus](#gettransactionstatus)
        -   [Parameters](#parameters-12)
        -   [Examples](#examples-14)
    -   [waitForTransactionResult](#waitfortransactionresult)
        -   [Parameters](#parameters-13)
        -   [Examples](#examples-15)
    -   [loadContract](#loadcontract)
        -   [Parameters](#parameters-14)
        -   [Examples](#examples-16)
    -   [createDefaultConfig](#createdefaultconfig)
        -   [Parameters](#parameters-15)
        -   [Examples](#examples-17)
-   [WalletAccessKey](#walletaccesskey)
    -   [Parameters](#parameters-16)
    -   [Examples](#examples-18)
    -   [isSignedIn](#issignedin)
        -   [Examples](#examples-19)
    -   [getAccountId](#getaccountid)
        -   [Examples](#examples-20)
    -   [requestSignIn](#requestsignin)
        -   [Parameters](#parameters-17)
    -   [signOut](#signout)
        -   [Examples](#examples-21)
    -   [signBuffer](#signbuffer)
        -   [Parameters](#parameters-18)
-   [WalletAccount](#walletaccount)
    -   [Parameters](#parameters-19)
    -   [Examples](#examples-22)
    -   [isSignedIn](#issignedin-1)
        -   [Examples](#examples-23)
    -   [getAccountId](#getaccountid-1)
        -   [Examples](#examples-24)
    -   [requestSignIn](#requestsignin-1)
        -   [Parameters](#parameters-20)
        -   [Examples](#examples-25)
    -   [signOut](#signout-1)
        -   [Examples](#examples-26)
    -   [signBuffer](#signbuffer-1)
        -   [Parameters](#parameters-21)

## require

Wallet based account and signer that uses external wallet through the iframe to sign transactions.

## KeyPair

Access Key based signer that uses Wallet to authorize app on the account and receive the access key.

### getPublicKey

Get the public key.

### getSecretKey

Get the secret key.

#### Examples

```javascript
// Passing existing key into a function to store in local storage
 async setKey(accountId, key) {
     window.localStorage.setItem(
         BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
     window.localStorage.setItem(
         BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
 }
```

### fromRandomSeed

Generate a new keypair from a random seed

#### Examples

```javascript
const keyWithRandomSeed = KeyPair.fromRandomSeed();
keyWithRandomSeed.getPublicKey()
// returns [PUBLIC_KEY]

keyWithRandomSeed.getSecretKey()
// returns [SECRET_KEY]
```

### encodeBufferInBs58

Encode a buffer as string using bs58

#### Parameters

-   `buffer` **[Buffer](https://nodejs.org/api/buffer.html)** 

#### Examples

```javascript
KeyPair.encodeBufferInBs58(key.publicKey)
```

## KeyPair

This class provides key pair functionality (generating key pairs, encoding key pairs).

### Parameters

-   `publicKey` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** 
-   `secretKey` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** 

### getPublicKey

Get the public key.

### getSecretKey

Get the secret key.

#### Examples

```javascript
// Passing existing key into a function to store in local storage
 async setKey(accountId, key) {
     window.localStorage.setItem(
         BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
     window.localStorage.setItem(
         BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
 }
```

### fromRandomSeed

Generate a new keypair from a random seed

#### Examples

```javascript
const keyWithRandomSeed = KeyPair.fromRandomSeed();
keyWithRandomSeed.getPublicKey()
// returns [PUBLIC_KEY]

keyWithRandomSeed.getSecretKey()
// returns [SECRET_KEY]
```

### encodeBufferInBs58

Encode a buffer as string using bs58

#### Parameters

-   `buffer` **[Buffer](https://nodejs.org/api/buffer.html)** 

#### Examples

```javascript
KeyPair.encodeBufferInBs58(key.publicKey)
```

## Account

Near account and account related operations.

### Parameters

-   `nearClient`  

### Examples

```javascript
const account = new Account(nearjs.nearClient);
```

### createAccount

Creates a new account with a given name and key,

#### Parameters

-   `newAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** id of the new account.
-   `publicKey` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** public key to associate with the new account
-   `amount` **[number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** amount of tokens to transfer from originator account id to the new account as part of the creation.
-   `originator`  
-   `originatorAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** existing account on the blockchain to use for transferring tokens into the new account

#### Examples

```javascript
const createAccountResponse = await account.createAccount(
   mainTestAccountName,
   keyWithRandomSeed.getPublicKey(),
   1000,
   aliceAccountName);
```

### addAccessKey

Adds a new access key to the owners account for an some app to use.

#### Parameters

-   `ownersAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** id of the owner's account.
-   `newPublicKey` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** public key for the access key.
-   `contractId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** if the given contractId is not empty, then this access key will only be able to call
         the given contractId.
-   `methodName` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** If the given method name is not empty, then this access key will only be able to call
         the given method name.
-   `fundingOwner` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account id to own the funding of this access key. If empty then account owner is used by default.
         fundingOwner should be used if this access key would be sponsored by the app. In this case the app would
         prefer to own funding of this access key, to get it back when the key is removed.
-   `fundingAmount` **[number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** amount of funding to withdraw from the owner's account and put to this access key.
         Make sure you that you don't fund the access key when the fundingOwner is different from the account's owner.

#### Examples

```javascript
const addAccessKeyResponse = await account.addAccessKey(
   accountId,
   keyWithRandomSeed.getPublicKey(),
   contractId,
   "",
   "",
   10);
```

### createAccountWithRandomKey

Creates a new account with a new random key pair. Returns the key pair to the caller. It's the caller's responsibility to
manage this key pair.

#### Parameters

-   `newAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** id of the new account
-   `amount` **[number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** amount of tokens to transfer from originator account id to the new account as part of the creation.
-   `originatorAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** existing account on the blockchain to use for transferring tokens into the new account

#### Examples

```javascript
const createAccountResponse = await account.createAccountWithRandomKey(
    newAccountName,
    amount,
    aliceAccountName);
```

### viewAccount

Returns an existing account with a given `accountId`

#### Parameters

-   `accountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** id of the account to look up

#### Examples

```javascript
const viewAccountResponse = await account.viewAccount(existingAccountId);
```

## Near

Javascript library for interacting with near.

### Parameters

-   `nearClient` **NearClient** 

### callViewFunction

Calls a view function. Returns the same value that the function returns.

#### Parameters

-   `contractAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account id of the contract
-   `methodName` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** method to call
-   `args` **[object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)** arguments to pass to the method

#### Examples

```javascript
const viewFunctionResponse = await near.callViewFunction(
  contractAccountId, 
  methodName, 
  args);
```

### scheduleFunctionCall

Schedules an asynchronous function call. Returns a hash which can be used to
check the status of the transaction later.

#### Parameters

-   `amount` **[number](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number)** amount of tokens to transfer as part of the operation
-   `originator`  
-   `contractId`  
-   `methodName` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** method to call
-   `args` **[object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)** arguments to pass to the method
-   `sender` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account id of the sender
-   `contractAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account id of the contract

#### Examples

```javascript
const scheduleResult = await near.scheduleFunctionCall(
    0,
    aliceAccountName,
    contractName,
    'setValue', // this is the function defined in a wasm file that we are calling
    setArgs);
```

### deployContract

Deploys a smart contract to the block chain

#### Parameters

-   `contractId`  
-   `wasmByteArray`  
-   `contractAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account id of the contract
-   `wasmArray` **[Uint8Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array)** wasm binary

#### Examples

```javascript
const response =  await nearjs.deployContract(contractName, data);
```

### getTransactionStatus

Get a status of a single transaction identified by the transaction hash.

#### Parameters

-   `transactionHash` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** unique identifier of the transaction

#### Examples

```javascript
// get the result of a transaction status call
const result = await this.getTransactionStatus(transactionHash)
```

### waitForTransactionResult

Wait until transaction is completed or failed.
Automatically sends logs from contract to `console.log`.

[MAX_STATUS_POLL_ATTEMPTS](MAX_STATUS_POLL_ATTEMPTS) defines how many attempts are made.
[STATUS_POLL_PERIOD_MS](STATUS_POLL_PERIOD_MS) defines delay between subsequent [getTransactionStatus](getTransactionStatus) calls.

#### Parameters

-   `transactionResponseOrHash` **([string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String) \| [object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object))** hash of transaction or object returned from [submitTransaction](submitTransaction)
-   `options` **[object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)** object used to pass named parameters (optional, default `{}`)
    -   `options.contractAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** specifies contract ID for better logs and error messages

#### Examples

```javascript
const result = await this.waitForTransactionResult(transactionHash);
```

### loadContract

Load given contract and expose it's methods.

Every method is taking named arguments as JS object, e.g.:
`{ paramName1: "val1", paramName2: 123 }`

View method returns promise which is resolved to result when it's available.
State change method returns promise which is resolved when state change is succesful and rejected otherwise.

Note that `options` param is only needed temporary while contract introspection capabilities are missing.

#### Parameters

-   `contractAccountId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** contract account name
-   `options` **[object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)** object used to pass named parameters
    -   `options.sender` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** account name of user which is sending transactions
    -   `options.viewMethods` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)>** list of view methods to load (which don't change state)
    -   `options.changeMethods` **[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)&lt;[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)>** list of methods to load that change state

#### Examples

```javascript
// this example would be a counter app with a contract that contains the incrementCounter and decrementCounter methods
window.contract = await near.loadContract(config.contractName, {
  viewMethods: ["getCounter"],
  changeMethods: ["incrementCounter", "decrementCounter"],
  sender: nearlib.dev.myAccountId
});
```

Returns **[object](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object)** object with methods corresponding to given contract methods.

### createDefaultConfig

Generate a default configuration for nearlib

#### Parameters

-   `nodeUrl` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** url of the near node to connect to (optional, default `'http://localhost:3030'`)

#### Examples

```javascript
Near.createDefaultConfig();
```

## WalletAccessKey

Access Key based signer that uses Wallet to authorize app on the account and receive the access key.

### Parameters

-   `appKeyPrefix`  
-   `walletBaseUrl`   (optional, default `'https://wallet.nearprotocol.com'`)
-   `signer`   (optional, default `null`)

### Examples

```javascript
// if importing WalletAccessKey directly
const walletAccount = new WalletAccessKey(contractName, walletBaseUrl)
// if importing in all of nearLib and calling from variable
const walletAccount = new nearlib.WalletAccessKey(contractName, walletBaseUrl)
// To access this signer globally
window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl);
// To provide custom signer where the keys would be stored
window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl, customSigner);
```

### isSignedIn

Returns true, if this WalletAccount is authorized with the wallet.

#### Examples

```javascript
walletAccount.isSignedIn();
```

### getAccountId

Returns authorized Account ID.

#### Examples

```javascript
walletAccount.getAccountId();
```

### requestSignIn

Redirects current page to the wallet authentication page.

#### Parameters

-   `contractId` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** contract ID of the application
-   `title` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** name of the application
-   `successUrl` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** url to redirect on success
-   `failureUrl` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** url to redirect on failure

### signOut

Sign out from the current account

#### Examples

```javascript
walletAccount.signOut();
```

### signBuffer

Sign a buffer. If the key for originator is not present,
this operation will fail.

#### Parameters

-   `buffer` **[Uint8Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array)** 
-   `originator` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** 

## WalletAccount

Wallet based account and signer that uses external wallet through the iframe to sign transactions.

### Parameters

-   `appKeyPrefix`  
-   `walletBaseUrl`   (optional, default `'https://wallet.nearprotocol.com'`)

### Examples

```javascript
// if importing WalletAccount directly
const walletAccount = new WalletAccount(contractName, walletBaseUrl)
// if importing in all of nearLib and calling from variable 
const walletAccount = new nearlib.WalletAccount(contractName, walletBaseUrl)
// To access wallet globally use:
window.walletAccount = new nearlib.WalletAccount(config.contractName, walletBaseUrl);
```

### isSignedIn

Returns true, if this WalletAccount is authorized with the wallet.

#### Examples

```javascript
walletAccount.isSignedIn();
```

### getAccountId

Returns authorized Account ID.

#### Examples

```javascript
walletAccount.getAccountId();
```

### requestSignIn

Redirects current page to the wallet authentication page.

#### Parameters

-   `contract_id` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** contract ID of the application
-   `title` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** name of the application
-   `success_url` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** url to redirect on success
-   `failure_url` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** url to redirect on failure

#### Examples

```javascript
walletAccount.requestSignIn(
    myContractId,
    title,
    onSuccessHref,
    onFailureHref);
```

### signOut

Sign out from the current account

#### Examples

```javascript
walletAccount.signOut();
```

### signBuffer

Sign a buffer. If the key for originator is not present,
this operation will fail.

#### Parameters

-   `buffer` **[Uint8Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array)** 
-   `originator` **[string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)** 

'''
'''--- nearlib/README.md ---
# Near lib

Near lib is a javascript library for development of dapps on near.

## Install dependencies

```
npm install
```
## Integration Test

Start the node by following instructions from nearcore/README.md, then
```
npm test
```
Contract "hello.wasm" source code location: <https://github.com/nearprotocol/nearcore/tree/master/tests/hello>

'''
'''--- nearlib/account.js ---
const bs58 = require('bs58');

const { google, AccessKey, AddKeyTransaction, CreateAccountTransaction, SignedTransaction } = require('./protos');
const KeyPair = require('./signing/key_pair');

/**
 * Near account and account related operations. 
 * @example
 * const account = new Account(nearjs.nearClient);
 */
class Account {
    constructor(nearClient) {
        this.nearClient = nearClient;
    }

    /**
     * Creates a new account with a given name and key,
     * @param {string} newAccountId id of the new account.
     * @param {string} publicKey public key to associate with the new account
     * @param {number} amount amount of tokens to transfer from originator account id to the new account as part of the creation. 
     * @param {string} originatorAccountId existing account on the blockchain to use for transferring tokens into the new account
     * @example
     * const createAccountResponse = await account.createAccount(
     *    mainTestAccountName,
     *    keyWithRandomSeed.getPublicKey(),
     *    1000,
     *    aliceAccountName);
     */
    async createAccount(newAccountId, publicKey, amount, originator) {
        const nonce = await this.nearClient.getNonce(originator);
        publicKey = bs58.decode(publicKey);
        const createAccount = CreateAccountTransaction.create({
            nonce,
            originator,
            newAccountId,
            publicKey,
        });
        // Integers with value of 0 must be omitted
        // https://github.com/dcodeIO/protobuf.js/issues/1138
        if (amount !== 0) {
            createAccount.amount = amount;
        }

        const buffer = CreateAccountTransaction.encode(createAccount).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            originator,
        );

        const signedTransaction = SignedTransaction.create({
            createAccount,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Adds a new access key to the owners account for an some app to use.
     * @param {string} ownersAccountId id of the owner's account.
     * @param {string} newPublicKey public key for the access key.
     * @param {string} contractId if the given contractId is not empty, then this access key will only be able to call
     *      the given contractId.
     * @param {string} methodName If the given method name is not empty, then this access key will only be able to call
     *      the given method name.
     * @param {string} fundingOwner account id to own the funding of this access key. If empty then account owner is used by default.
     *      fundingOwner should be used if this access key would be sponsored by the app. In this case the app would
     *      prefer to own funding of this access key, to get it back when the key is removed.
     * @param {number} fundingAmount amount of funding to withdraw from the owner's account and put to this access key.
     *      Make sure you that you don't fund the access key when the fundingOwner is different from the account's owner.
     * @example
     * const addAccessKeyResponse = await account.addAccessKey(
     *    accountId,
     *    keyWithRandomSeed.getPublicKey(),
     *    contractId,
     *    "",
     *    "",
     *    10);
     */
    async addAccessKey(ownersAccountId, newPublicKey, contractId, methodName, fundingOwner, fundingAmount) {
        const nonce = await this.nearClient.getNonce(ownersAccountId);
        newPublicKey = bs58.decode(newPublicKey);
        const accessKey = AccessKey.create({});
        if (contractId) {
            accessKey.contractId = google.protobuf.StringValue.create({
                value: contractId,
            });
        }
        if (methodName) {
            accessKey.methodName = google.protobuf.BytesValue.create({
                value: new Uint8Array(Buffer.from(methodName)),
            });
        }
        if (fundingOwner) {
            accessKey.balanceOwner = google.protobuf.StringValue.create({
                value: fundingOwner,
            });
        }
        if (fundingAmount > 0) {
            accessKey.amount = fundingAmount;
        }
        const addKey = AddKeyTransaction.create({
            nonce,
            originator: ownersAccountId,
            newKey: newPublicKey,
            accessKey,
        });
        const buffer = AddKeyTransaction.encode(addKey).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            ownersAccountId,
        );

        const signedTransaction = SignedTransaction.create({
            addKey,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return this.nearClient.submitTransaction(signedTransaction);
    }

    /**
    * Creates a new account with a new random key pair. Returns the key pair to the caller. It's the caller's responsibility to
    * manage this key pair.
    * @param {string} newAccountId id of the new account
    * @param {number} amount amount of tokens to transfer from originator account id to the new account as part of the creation. 
    * @param {string} originatorAccountId existing account on the blockchain to use for transferring tokens into the new account
    * @example
    * const createAccountResponse = await account.createAccountWithRandomKey(
    *     newAccountName,
    *     amount,
    *     aliceAccountName);
    */
    async createAccountWithRandomKey (newAccountId, amount, originatorAccountId) {
        const keyWithRandomSeed = KeyPair.fromRandomSeed();
        const createAccountResult = await this.createAccount(
            newAccountId,
            keyWithRandomSeed.getPublicKey(),
            amount,
            originatorAccountId,
        );
        return { key: keyWithRandomSeed, ...createAccountResult }; 
    }

    /**
     * Returns an existing account with a given `accountId`
     * @param {string} accountId id of the account to look up 
     * @example
     * const viewAccountResponse = await account.viewAccount(existingAccountId);
     */
    async viewAccount (accountId) {
        return await this.nearClient.viewAccount(accountId);
    }
}
module.exports = Account;

'''
'''--- nearlib/browser-exports.js ---
require('error-polyfill');
window.nearlib = require('./index');
window.nearlib.dev = require('./dev');
window.Buffer = Buffer;

'''
'''--- nearlib/browser.js ---
const Near = require('./near');
const NearClient = require('./nearclient');
const Account = require('./account');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const InMemoryKeyStore = require('./signing/in_memory_key_store');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const LocalNodeConnection = require('./local_node_connection');
const KeyPair = require('./signing/key_pair');
const WalletAccount = require('./wallet-account');
const dev = require('./dev');
const AccountInfo = require('./signing/account_info');
const WalletAccessKey = require('./wallet-access-key');

module.exports = { Near, NearClient, Account, SimpleKeyStoreSigner, InMemoryKeyStore, BrowserLocalStorageKeystore, LocalNodeConnection, KeyPair, WalletAccount, dev, AccountInfo, WalletAccessKey };

'''
'''--- nearlib/dev.js ---
const Near = require('./near');
const NearClient = require('./nearclient');
const Account = require('./account');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const LocalNodeConnection = require('./local_node_connection');
const KeyPair = require('./signing/key_pair');
const sendJson = require('./internal/send-json');

const storageAccountIdKey = 'dev_near_user';

// This key will only be available on dev/test environments. Do not rely on it for anything that runs on mainnet.
const devKey = new KeyPair(
    '22skMptHjFWNyuEWY22ftn2AbLPSYpmYwGJRGwpNHbTV',
    '2wyRcSwSuHtRVmkMCGjPwnzZmQLeXLzLLyED1NDMt4BjnKgQL6tF85yBx6Jr26D2dUNeC716RBoTxntVHsegogYw'
);
const devAccountName = 'alice.near';
const localNodeUrl = 'http://localhost:3030';

module.exports = {
    getConfig: async function() {
        return JSON.parse(decodeURIComponent(getCookie('fiddleConfig'))) || {};
    },
    /**
     * Create a connection which can perform operations on behalf of a given account.
     * @param {object} options object to pass named parameters.
     * @param {Object} options.nodeUrl specifies node url. accountId specifies account id. key_pair is the key pair for account
     * @param {boolean} options.useDevAccount specify to use development account to create accounts / deploy contracts. Should be used only on TestNet.
     * @param {string} options.accountId account ID to use.
     * @param {string} options.networkId id associated with this network, for key management purposes.
     */
    connect: async function(options = {}) {
        // construct full options objects based on params, and fill in with defaults.
        this.options = Object.assign({deps: {}}, options);
        this.deps = this.options.deps;
        if (this.options.useDevAccount) {
            this.options.accountId = devAccountName;
            this.options.key = devKey;
        }
        this.options.helperUrl = this.options.helperUrl || this.options.baseUrl;
        if (!this.deps.createAccount) {
            if (this.options.helperUrl) {
                this.deps.createAccount = this.createAccountWithContractHelper.bind(this);
            } else {
                this.deps.createAccount = this.createAccountWithLocalNodeConnection.bind(this);
            }
        }
        this.options.networkId = this.options.networkId || 'localhost';
        this.options.nodeUrl = this.options.nodeUrl || (await this.getConfig()).nodeUrl || localNodeUrl;
        this.deps.keyStore = this.deps.keyStore || new BrowserLocalStorageKeystore(this.options.networkId);
        this.deps.storage = this.deps.storage || window.localStorage;

        const nearClient = new NearClient(
            new SimpleKeyStoreSigner(this.deps.keyStore), new LocalNodeConnection(this.options.nodeUrl));
        this.near = new Near(nearClient);
        if (this.options.accountId && this.options.key) {
            this.deps.keyStore.setKey(this.options.accountId, this.options.key);
        }
        if (!this.options.accountId) {
            await this.getOrCreateDevUser();
        }
        return this.near;
    },
    getOrCreateDevUser: async function () {
        let tempUserAccountId = this.deps.storage.getItem(storageAccountIdKey);
        const accountKey = await this.deps.keyStore.getKey(tempUserAccountId);
        if (tempUserAccountId && accountKey) {
            // Make sure the user actually exists with valid keys and recreate it if it doesn't
            const accountLib = new Account(this.near.nearClient);
            try {
                await accountLib.viewAccount(tempUserAccountId);
                return tempUserAccountId;
            } catch (e) {
                console.log('Error looking up temp account', e);
                // Something went wrong! Recreate user by continuing the flow
            }
        } else {
            tempUserAccountId = 'devuser' + Date.now();
        }
        const keypair = KeyPair.fromRandomSeed();
        const createAccount = this.deps.createAccount ? this.deps.createAccount :
            async (accountId, newAccountPublicKey) =>
                this.createAccountWithContractHelper(await this.getConfig(), accountId, newAccountPublicKey);
        await createAccount.bind(this, tempUserAccountId, keypair.getPublicKey())();
        this.deps.keyStore.setKey(tempUserAccountId, keypair);
        this.deps.storage.setItem(storageAccountIdKey, tempUserAccountId);
        return tempUserAccountId;
    },
    get myAccountId() {
        return this.deps.storage.getItem(storageAccountIdKey);
    },
    /**
     * Function to create an account on local node. This will not work on non-dev environments.
     */
    createAccountWithLocalNodeConnection: async function (newAccountName, newAccountPublicKey) {
        const account = new Account(this.near.nearClient);
        this.deps.keyStore.setKey(devAccountName, devKey); // need to have dev account in key store to use this.
        const createAccountResponse = await account.createAccount(newAccountName, newAccountPublicKey, 1, devAccountName);
        await this.near.waitForTransactionResult(createAccountResponse);
    },
    /**
     * Function to create an account on near-hosted devnet using contract helper. This will not work on non-dev environments.
     */
    createAccountWithContractHelper: async function (newAccountId, publicKey) {
        return await sendJson('POST', `${this.options.helperUrl}/account`, {
            newAccountId: newAccountId,
            newAccountPublicKey: publicKey
        });
    }
};

function getCookie(name) {
    var v = document.cookie.match('(^|;) ?' + name + '=([^;]*)(;|$)');
    return v ? v[2] : null;
}

'''
'''--- nearlib/dist/nearlib.js ---
(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
(function (Buffer){
const bs58 = require('bs58');

const { google, AccessKey, AddKeyTransaction, CreateAccountTransaction, SignedTransaction } = require('./protos');
const KeyPair = require('./signing/key_pair');

/**
 * Near account and account related operations. 
 * @example
 * const account = new Account(nearjs.nearClient);
 */
class Account {
    constructor(nearClient) {
        this.nearClient = nearClient;
    }

    /**
     * Creates a new account with a given name and key,
     * @param {string} newAccountId id of the new account.
     * @param {string} publicKey public key to associate with the new account
     * @param {number} amount amount of tokens to transfer from originator account id to the new account as part of the creation. 
     * @param {string} originatorAccountId existing account on the blockchain to use for transferring tokens into the new account
     * @example
     * const createAccountResponse = await account.createAccount(
     *    mainTestAccountName,
     *    keyWithRandomSeed.getPublicKey(),
     *    1000,
     *    aliceAccountName);
     */
    async createAccount(newAccountId, publicKey, amount, originator) {
        const nonce = await this.nearClient.getNonce(originator);
        publicKey = bs58.decode(publicKey);
        const createAccount = CreateAccountTransaction.create({
            nonce,
            originator,
            newAccountId,
            publicKey,
        });
        // Integers with value of 0 must be omitted
        // https://github.com/dcodeIO/protobuf.js/issues/1138
        if (amount !== 0) {
            createAccount.amount = amount;
        }

        const buffer = CreateAccountTransaction.encode(createAccount).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            originator,
        );

        const signedTransaction = SignedTransaction.create({
            createAccount,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Adds a new access key to the owners account for an some app to use.
     * @param {string} ownersAccountId id of the owner's account.
     * @param {string} newPublicKey public key for the access key.
     * @param {string} contractId if the given contractId is not empty, then this access key will only be able to call
     *      the given contractId.
     * @param {string} methodName If the given method name is not empty, then this access key will only be able to call
     *      the given method name.
     * @param {string} fundingOwner account id to own the funding of this access key. If empty then account owner is used by default.
     *      fundingOwner should be used if this access key would be sponsored by the app. In this case the app would
     *      prefer to own funding of this access key, to get it back when the key is removed.
     * @param {number} fundingAmount amount of funding to withdraw from the owner's account and put to this access key.
     *      Make sure you that you don't fund the access key when the fundingOwner is different from the account's owner.
     * @example
     * const addAccessKeyResponse = await account.addAccessKey(
     *    accountId,
     *    keyWithRandomSeed.getPublicKey(),
     *    contractId,
     *    "",
     *    "",
     *    10);
     */
    async addAccessKey(ownersAccountId, newPublicKey, contractId, methodName, fundingOwner, fundingAmount) {
        const nonce = await this.nearClient.getNonce(ownersAccountId);
        newPublicKey = bs58.decode(newPublicKey);
        const accessKey = AccessKey.create({});
        if (contractId) {
            accessKey.contractId = google.protobuf.StringValue.create({
                value: contractId,
            });
        }
        if (methodName) {
            accessKey.methodName = google.protobuf.BytesValue.create({
                value: new Uint8Array(Buffer.from(methodName)),
            });
        }
        if (fundingOwner) {
            accessKey.balanceOwner = google.protobuf.StringValue.create({
                value: fundingOwner,
            });
        }
        if (fundingAmount > 0) {
            accessKey.amount = fundingAmount;
        }
        const addKey = AddKeyTransaction.create({
            nonce,
            originator: ownersAccountId,
            newKey: newPublicKey,
            accessKey,
        });
        const buffer = AddKeyTransaction.encode(addKey).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            ownersAccountId,
        );

        const signedTransaction = SignedTransaction.create({
            addKey,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return this.nearClient.submitTransaction(signedTransaction);
    }

    /**
    * Creates a new account with a new random key pair. Returns the key pair to the caller. It's the caller's responsibility to
    * manage this key pair.
    * @param {string} newAccountId id of the new account
    * @param {number} amount amount of tokens to transfer from originator account id to the new account as part of the creation. 
    * @param {string} originatorAccountId existing account on the blockchain to use for transferring tokens into the new account
    * @example
    * const createAccountResponse = await account.createAccountWithRandomKey(
    *     newAccountName,
    *     amount,
    *     aliceAccountName);
    */
    async createAccountWithRandomKey (newAccountId, amount, originatorAccountId) {
        const keyWithRandomSeed = KeyPair.fromRandomSeed();
        const createAccountResult = await this.createAccount(
            newAccountId,
            keyWithRandomSeed.getPublicKey(),
            amount,
            originatorAccountId,
        );
        return { key: keyWithRandomSeed, ...createAccountResult }; 
    }

    /**
     * Returns an existing account with a given `accountId`
     * @param {string} accountId id of the account to look up 
     * @example
     * const viewAccountResponse = await account.viewAccount(existingAccountId);
     */
    async viewAccount (accountId) {
        return await this.nearClient.viewAccount(accountId);
    }
}
module.exports = Account;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"./signing/key_pair":71,"bs58":20,"buffer":21}],2:[function(require,module,exports){
(function (Buffer){
require('error-polyfill');
window.nearlib = require('./index');
window.nearlib.dev = require('./dev');
window.Buffer = Buffer;

}).call(this,require("buffer").Buffer)
},{"./dev":4,"./index":3,"buffer":21,"error-polyfill":28}],3:[function(require,module,exports){
const Near = require('./near');
const NearClient = require('./nearclient');
const Account = require('./account');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const InMemoryKeyStore = require('./signing/in_memory_key_store');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const LocalNodeConnection = require('./local_node_connection');
const KeyPair = require('./signing/key_pair');
const WalletAccount = require('./wallet-account');
const dev = require('./dev');
const AccountInfo = require('./signing/account_info');
const WalletAccessKey = require('./wallet-access-key');

module.exports = { Near, NearClient, Account, SimpleKeyStoreSigner, InMemoryKeyStore, BrowserLocalStorageKeystore, LocalNodeConnection, KeyPair, WalletAccount, dev, AccountInfo, WalletAccessKey };

},{"./account":1,"./dev":4,"./local_node_connection":6,"./near":7,"./nearclient":8,"./signing/account_info":68,"./signing/browser_local_storage_key_store":69,"./signing/in_memory_key_store":70,"./signing/key_pair":71,"./signing/simple_key_store_signer":72,"./wallet-access-key":73,"./wallet-account":74}],4:[function(require,module,exports){
const Near = require('./near');
const NearClient = require('./nearclient');
const Account = require('./account');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const LocalNodeConnection = require('./local_node_connection');
const KeyPair = require('./signing/key_pair');
const sendJson = require('./internal/send-json');

const storageAccountIdKey = 'dev_near_user';

// This key will only be available on dev/test environments. Do not rely on it for anything that runs on mainnet.
const devKey = new KeyPair(
    '22skMptHjFWNyuEWY22ftn2AbLPSYpmYwGJRGwpNHbTV',
    '2wyRcSwSuHtRVmkMCGjPwnzZmQLeXLzLLyED1NDMt4BjnKgQL6tF85yBx6Jr26D2dUNeC716RBoTxntVHsegogYw'
);
const devAccountName = 'alice.near';
const localNodeUrl = 'http://localhost:3030';

module.exports = {
    getConfig: async function() {
        return JSON.parse(decodeURIComponent(getCookie('fiddleConfig'))) || {};
    },
    /**
     * Create a connection which can perform operations on behalf of a given account.
     * @param {object} options object to pass named parameters.
     * @param {Object} options.nodeUrl specifies node url. accountId specifies account id. key_pair is the key pair for account
     * @param {boolean} options.useDevAccount specify to use development account to create accounts / deploy contracts. Should be used only on TestNet.
     * @param {string} options.accountId account ID to use.
     * @param {string} options.networkId id associated with this network, for key management purposes.
     */
    connect: async function(options = {}) {
        // construct full options objects based on params, and fill in with defaults.
        this.options = Object.assign({deps: {}}, options);
        this.deps = this.options.deps;
        if (this.options.useDevAccount) {
            this.options.accountId = devAccountName;
            this.options.key = devKey;
        }
        this.options.helperUrl = this.options.helperUrl || this.options.baseUrl;
        if (!this.deps.createAccount) {
            if (this.options.helperUrl) {
                this.deps.createAccount = this.createAccountWithContractHelper.bind(this);
            } else {
                this.deps.createAccount = this.createAccountWithLocalNodeConnection.bind(this);
            }
        }
        this.options.networkId = this.options.networkId || 'localhost';
        this.options.nodeUrl = this.options.nodeUrl || (await this.getConfig()).nodeUrl || localNodeUrl;
        this.deps.keyStore = this.deps.keyStore || new BrowserLocalStorageKeystore(this.options.networkId);
        this.deps.storage = this.deps.storage || window.localStorage;

        const nearClient = new NearClient(
            new SimpleKeyStoreSigner(this.deps.keyStore), new LocalNodeConnection(this.options.nodeUrl));
        this.near = new Near(nearClient);
        if (this.options.accountId && this.options.key) {
            this.deps.keyStore.setKey(this.options.accountId, this.options.key);
        }
        if (!this.options.accountId) {
            await this.getOrCreateDevUser();
        }
        return this.near;
    },
    getOrCreateDevUser: async function () {
        let tempUserAccountId = this.deps.storage.getItem(storageAccountIdKey);
        const accountKey = await this.deps.keyStore.getKey(tempUserAccountId);
        if (tempUserAccountId && accountKey) {
            // Make sure the user actually exists with valid keys and recreate it if it doesn't
            const accountLib = new Account(this.near.nearClient);
            try {
                await accountLib.viewAccount(tempUserAccountId);
                return tempUserAccountId;
            } catch (e) {
                console.log('Error looking up temp account', e);
                // Something went wrong! Recreate user by continuing the flow
            }
        } else {
            tempUserAccountId = 'devuser' + Date.now();
        }
        const keypair = KeyPair.fromRandomSeed();
        const createAccount = this.deps.createAccount ? this.deps.createAccount :
            async (accountId, newAccountPublicKey) =>
                this.createAccountWithContractHelper(await this.getConfig(), accountId, newAccountPublicKey);
        await createAccount.bind(this, tempUserAccountId, keypair.getPublicKey())();
        this.deps.keyStore.setKey(tempUserAccountId, keypair);
        this.deps.storage.setItem(storageAccountIdKey, tempUserAccountId);
        return tempUserAccountId;
    },
    get myAccountId() {
        return this.deps.storage.getItem(storageAccountIdKey);
    },
    /**
     * Function to create an account on local node. This will not work on non-dev environments.
     */
    createAccountWithLocalNodeConnection: async function (newAccountName, newAccountPublicKey) {
        const account = new Account(this.near.nearClient);
        this.deps.keyStore.setKey(devAccountName, devKey); // need to have dev account in key store to use this.
        const createAccountResponse = await account.createAccount(newAccountName, newAccountPublicKey, 1, devAccountName);
        await this.near.waitForTransactionResult(createAccountResponse);
    },
    /**
     * Function to create an account on near-hosted devnet using contract helper. This will not work on non-dev environments.
     */
    createAccountWithContractHelper: async function (newAccountId, publicKey) {
        return await sendJson('POST', `${this.options.helperUrl}/account`, {
            newAccountId: newAccountId,
            newAccountPublicKey: publicKey
        });
    }
};

function getCookie(name) {
    var v = document.cookie.match('(^|;) ?' + name + '=([^;]*)(;|$)');
    return v ? v[2] : null;
}

},{"./account":1,"./internal/send-json":5,"./local_node_connection":6,"./near":7,"./nearclient":8,"./signing/browser_local_storage_key_store":69,"./signing/key_pair":71,"./signing/simple_key_store_signer":72}],5:[function(require,module,exports){
let fetch = (typeof window === 'undefined' || window.name == 'nodejs') ? require('node-fetch') : window.fetch;

const createError = require('http-errors');

module.exports = async function sendJson(method, url, json) {
    const response = await fetch(url, {
        method: method,
        body: method != 'GET' ? JSON.stringify(json) : undefined,
        headers: { 'Content-type': 'application/json; charset=utf-8' }
    });
    if (!response.ok) {
        throw createError(response.status, await response.text());
    }
    if (response.status === 204) {
        // No Content
        return null;
    }
    return await response.json();
};

},{"http-errors":37,"node-fetch":19}],6:[function(require,module,exports){
const sendJson = require('./internal/send-json');

class LocalNodeConnection {
    constructor (baseUrl) {
        this.baseUrl = baseUrl;
    }

    async request(methodName, params) {
        return await sendJson('POST', `${this.baseUrl}/${methodName}`, params);
    }
}

module.exports = LocalNodeConnection;

},{"./internal/send-json":5}],7:[function(require,module,exports){
(function (Buffer){
const createError = require('http-errors');

const NearClient = require('./nearclient');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const LocalNodeConnection = require('./local_node_connection');
const {
    DeployContractTransaction, FunctionCallTransaction, SignedTransaction
} = require('./protos');

const MAX_STATUS_POLL_ATTEMPTS = 10;
const STATUS_POLL_PERIOD_MS = 2000;

/**
 * Javascript library for interacting with near.
 */
class Near {
    /**
     * Constructs near with an instance of nearclient.
     * @constructor
     * @param {NearClient} nearClient
     * @example
     * const nearClient = new nearlib.NearClient(
     *   walletAccount, 
     *   new nearlib.LocalNodeConnection(config.nodeUrl));
     * const near = new nearlib.Near(nearClient);
     */
    constructor(nearClient) {
        this.nearClient = nearClient;
    }

    /**
     * Generate a default configuration for nearlib
     * @param {string} nodeUrl url of the near node to connect to
     * @example
     * Near.createDefaultConfig();
     */
    static createDefaultConfig(nodeUrl = 'http://localhost:3030') {
        return new Near(new NearClient(
            new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore()),
            new LocalNodeConnection(nodeUrl)
        ));
    }

    /**
     * Calls a view function. Returns the same value that the function returns.
     * @param {string} contractAccountId account id of the contract
     * @param {string} methodName method to call
     * @param {object} args arguments to pass to the method
     * @example
     * const viewFunctionResponse = await near.callViewFunction(
     *   contractAccountId, 
     *   methodName, 
     *   args);
     */
    async callViewFunction(contractAccountId, methodName, args) {
        return this.nearClient.callViewFunction(contractAccountId, methodName, args);
    }

    /**
     * Schedules an asynchronous function call. Returns a hash which can be used to
     * check the status of the transaction later.
     * @param {number} amount amount of tokens to transfer as part of the operation
     * @param {string} sender account id of the sender
     * @param {string} contractAccountId account id of the contract
     * @param {string} methodName method to call
     * @param {object} args arguments to pass to the method
     * @example
     * const scheduleResult = await near.scheduleFunctionCall(
     *     0,
     *     aliceAccountName,
     *     contractName,
     *     'setValue', // this is the function defined in a wasm file that we are calling
     *     setArgs);
     */
    async scheduleFunctionCall(amount, originator, contractId, methodName, args) {
        if (!args) {
            args = {};
        }
        methodName = new Uint8Array(Buffer.from(methodName));
        args = new Uint8Array(Buffer.from(JSON.stringify(args)));
        const nonce = await this.nearClient.getNonce(originator);
        const functionCall = FunctionCallTransaction.create({
            nonce,
            originator,
            contractId,
            methodName,
            args,
        });
        // Integers with value of 0 must be omitted
        // https://github.com/dcodeIO/protobuf.js/issues/1138
        if (amount !== 0) {
            functionCall.amount = amount;
        }

        const buffer = FunctionCallTransaction.encode(functionCall).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            originator,
        );

        const signedTransaction = SignedTransaction.create({
            functionCall,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return await this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Deploys a smart contract to the block chain
     * @param {string} contractAccountId account id of the contract
     * @param {Uint8Array} wasmArray wasm binary
     * @example
     * const response =  await nearjs.deployContract(contractName, data);
     */
    async deployContract(contractId, wasmByteArray) {
        const nonce = await this.nearClient.getNonce(contractId);

        const deployContract = DeployContractTransaction.create({
            nonce,
            contractId,
            wasmByteArray,
        });

        const buffer = DeployContractTransaction.encode(deployContract).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            contractId,
        );

        const signedTransaction = SignedTransaction.create({
            deployContract,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return await this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Get a status of a single transaction identified by the transaction hash.
     * @param {string} transactionHash unique identifier of the transaction
     * @example
     * // get the result of a transaction status call
     * const result = await this.getTransactionStatus(transactionHash)
     */
    async getTransactionStatus(transactionHash) {
        return this.nearClient.getTransactionStatus(transactionHash);
    }

    /**
     * Wait until transaction is completed or failed.
     * Automatically sends logs from contract to `console.log`.
     *
     * {@link MAX_STATUS_POLL_ATTEMPTS} defines how many attempts are made.
     * {@link STATUS_POLL_PERIOD_MS} defines delay between subsequent {@link getTransactionStatus} calls.
     *
     * @param {string | object} transactionResponseOrHash hash of transaction or object returned from {@link submitTransaction}
     * @param {object} options object used to pass named parameters
     * @param {string} options.contractAccountId specifies contract ID for better logs and error messages
     * @example
     * const result = await this.waitForTransactionResult(transactionHash);
     */
    async waitForTransactionResult(transactionResponseOrHash, options = {}) {
        const transactionHash = transactionResponseOrHash.hasOwnProperty('hash') ? transactionResponseOrHash.hash : transactionResponseOrHash;
        const contractAccountId = options.contractAccountId || 'unknown contract';
        let alreadyDisplayedLogs = [];
        let result;
        for (let i = 0; i < MAX_STATUS_POLL_ATTEMPTS; i++) {
            await sleep(STATUS_POLL_PERIOD_MS);
            result = (await this.getTransactionStatus(transactionHash));
            let j;
            for (j = 0; j < alreadyDisplayedLogs.length && alreadyDisplayedLogs[j] == result.logs[j]; j++);
            if (j != alreadyDisplayedLogs.length) {
                console.warn('new logs:', result.logs, 'iconsistent with already displayed logs:', alreadyDisplayedLogs);
            }
            for (; j < result.logs.length; ++j) {
                const line = result.logs[j];
                console.log(`[${contractAccountId}]: ${line}`);
                alreadyDisplayedLogs.push(line);
            }
            if (result.status == 'Completed') {
                if (result.value) {
                    result.lastResult = JSON.parse(Buffer.from(result.value, 'base64').toString());
                }
                return result;
            }
            if (result.status == 'Failed') {
                const errorMessage = result.logs.find(it => it.startsWith('ABORT:')) || '';
                const hash = Buffer.from(transactionHash).toString('base64');
                throw createError(400, `Transaction ${hash} on ${contractAccountId} failed. ${errorMessage}`);
            }
        }
        throw createError(408, `Exceeded ${MAX_STATUS_POLL_ATTEMPTS} status check attempts ` +
            `for transaction ${transactionHash} on ${contractAccountId} with status: ${result.status}`);
    }

    /**
     * Load given contract and expose it's methods.
     *
     * Every method is taking named arguments as JS object, e.g.:
     * `{ paramName1: "val1", paramName2: 123 }`
     *
     * View method returns promise which is resolved to result when it's available.
     * State change method returns promise which is resolved when state change is succesful and rejected otherwise.
     *
     * Note that `options` param is only needed temporary while contract introspection capabilities are missing.
     *
     * @param {string} contractAccountId contract account name
     * @param {object} options object used to pass named parameters
     * @param {string} options.sender account name of user which is sending transactions
     * @param {string[]} options.viewMethods list of view methods to load (which don't change state)
     * @param {string[]} options.changeMethods list of methods to load that change state
     * @returns {object} object with methods corresponding to given contract methods.
     * @example
     * // this example would be a counter app with a contract that contains the incrementCounter and decrementCounter methods
     * window.contract = await near.loadContract(config.contractName, {
     *   viewMethods: ["getCounter"],
     *   changeMethods: ["incrementCounter", "decrementCounter"],
     *   sender: nearlib.dev.myAccountId
     * });
     */
    async loadContract(contractAccountId, options) {
        // TODO: Move this to account context to avoid options.sender
        let contract = {};
        let near = this;
        options.viewMethods.forEach((methodName) => {
            contract[methodName] = async function (args) {
                args = args || {};
                return near.callViewFunction(contractAccountId, methodName, args);
            };
        });
        options.changeMethods.forEach((methodName) => {
            contract[methodName] = async function (args) {
                args = args || {};
                const response = await near.scheduleFunctionCall(0, options.sender, contractAccountId, methodName, args);
                return near.waitForTransactionResult(response.hash, { contractAccountId });
            };
        });
        return contract;
    }
}

function sleep(time) {
    return new Promise(function (resolve) {
        setTimeout(resolve, time);
    });
}

module.exports = Near;

}).call(this,require("buffer").Buffer)
},{"./local_node_connection":6,"./nearclient":8,"./protos":67,"./signing/browser_local_storage_key_store":69,"./signing/simple_key_store_signer":72,"buffer":21,"http-errors":37}],8:[function(require,module,exports){
(function (Buffer){
const { SignedTransaction } = require('./protos');

/**
 * Client for communicating with near blockchain. 
 */

function _arrayBufferToBase64(buffer) {
    return Buffer.from(buffer).toString('base64');
}

function _base64ToBuffer(str) {
    return new Buffer.from(str, 'base64');
}

class NearClient {
    constructor(signer, nearConnection) {
        this.signer = signer;
        this.nearConnection = nearConnection;
    }

    async viewAccount(accountId) {
        const response = await this.jsonRpcRequest('abci_query', [`account/${accountId}`, '', '0', false]);
        return JSON.parse(_base64ToBuffer(response.response.value).toString());
    }

    async submitTransaction(signedTransaction) {
        const buffer = SignedTransaction.encode(signedTransaction).finish();
        const transaction = _arrayBufferToBase64(buffer);
        const params = [transaction];
        const response = await this.jsonRpcRequest('broadcast_tx_async', params);
        response.hash = Buffer.from(response.hash, 'hex');
        return response;
    }

    async callViewFunction(contractAccountId, methodName, args) {
        if (!args) {
            args = {};
        }
        const serializedArgs = Buffer.from(JSON.stringify(args)).toString('hex');
        const result = await this.jsonRpcRequest('abci_query', [`call/${contractAccountId}/${methodName}`, serializedArgs, '0', false]);
        const response = result.response;
        let logs = [];
        if (response.log !== undefined && response.log.length > 0) {
            logs = response.log.split('\n');
        }
        logs.forEach(line => {
            console.log(`[${contractAccountId}]: ${line}`);
        });
        // If error, raise exception after printing logs.
        const code = response.code || 0;
        if (code != 0) {
            throw Error(response.info);
        }
        const json = JSON.parse(_base64ToBuffer(response.value).toString());
        return json;
    }

    async getTransactionStatus(transactionHash) {
        const encodedHash = _arrayBufferToBase64(transactionHash);
        const response = await this.jsonRpcRequest('tx', [encodedHash, false]);
        // tx_result has default values: code = 0, logs: '', data: ''.
        const codes = { 0: 'Completed', 1: 'Failed', 2: 'Started' };
        const status = codes[response.tx_result.code || 0] || 'Unknown';
        let logs = [];
        if (response.tx_result !== undefined && response.tx_result.log !== undefined && response.tx_result.log.length > 0) {
            logs = response.tx_result.log.split('\n');
        }
        return { logs, status, value: response.tx_result.data };
    }

    async getNonce(accountId) {
        return (await this.viewAccount(accountId)).nonce + 1;
    }

    async jsonRpcRequest(method, params) {
        const request = {
            jsonrpc: '2.0',
            method,
            params,
            id: Date.now().toString(),
        };
        const response = await this.nearConnection.request('', request);
        if (response.error) {
            throw Error(`Error calling ${method} with ${params}: ${response.error.message}.\nFull response: ${JSON.stringify(response)}`);
        }
        return response.result;
    }

    async request(methodName, params) {
        return this.nearConnection.request(methodName, params);
    }
}

module.exports = NearClient;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"buffer":21}],9:[function(require,module,exports){
"use strict";
module.exports = asPromise;

/**
 * Callback as used by {@link util.asPromise}.
 * @typedef asPromiseCallback
 * @type {function}
 * @param {Error|null} error Error, if any
 * @param {...*} params Additional arguments
 * @returns {undefined}
 */

/**
 * Returns a promise from a node-style callback function.
 * @memberof util
 * @param {asPromiseCallback} fn Function to call
 * @param {*} ctx Function context
 * @param {...*} params Function arguments
 * @returns {Promise<*>} Promisified function
 */
function asPromise(fn, ctx/*, varargs */) {
    var params  = new Array(arguments.length - 1),
        offset  = 0,
        index   = 2,
        pending = true;
    while (index < arguments.length)
        params[offset++] = arguments[index++];
    return new Promise(function executor(resolve, reject) {
        params[offset] = function callback(err/*, varargs */) {
            if (pending) {
                pending = false;
                if (err)
                    reject(err);
                else {
                    var params = new Array(arguments.length - 1),
                        offset = 0;
                    while (offset < params.length)
                        params[offset++] = arguments[offset];
                    resolve.apply(null, params);
                }
            }
        };
        try {
            fn.apply(ctx || null, params);
        } catch (err) {
            if (pending) {
                pending = false;
                reject(err);
            }
        }
    });
}

},{}],10:[function(require,module,exports){
"use strict";

/**
 * A minimal base64 implementation for number arrays.
 * @memberof util
 * @namespace
 */
var base64 = exports;

/**
 * Calculates the byte length of a base64 encoded string.
 * @param {string} string Base64 encoded string
 * @returns {number} Byte length
 */
base64.length = function length(string) {
    var p = string.length;
    if (!p)
        return 0;
    var n = 0;
    while (--p % 4 > 1 && string.charAt(p) === "=")
        ++n;
    return Math.ceil(string.length * 3) / 4 - n;
};

// Base64 encoding table
var b64 = new Array(64);

// Base64 decoding table
var s64 = new Array(123);

// 65..90, 97..122, 48..57, 43, 47
for (var i = 0; i < 64;)
    s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;

/**
 * Encodes a buffer to a base64 encoded string.
 * @param {Uint8Array} buffer Source buffer
 * @param {number} start Source start
 * @param {number} end Source end
 * @returns {string} Base64 encoded string
 */
base64.encode = function encode(buffer, start, end) {
    var parts = null,
        chunk = [];
    var i = 0, // output index
        j = 0, // goto index
        t;     // temporary
    while (start < end) {
        var b = buffer[start++];
        switch (j) {
            case 0:
                chunk[i++] = b64[b >> 2];
                t = (b & 3) << 4;
                j = 1;
                break;
            case 1:
                chunk[i++] = b64[t | b >> 4];
                t = (b & 15) << 2;
                j = 2;
                break;
            case 2:
                chunk[i++] = b64[t | b >> 6];
                chunk[i++] = b64[b & 63];
                j = 0;
                break;
        }
        if (i > 8191) {
            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
            i = 0;
        }
    }
    if (j) {
        chunk[i++] = b64[t];
        chunk[i++] = 61;
        if (j === 1)
            chunk[i++] = 61;
    }
    if (parts) {
        if (i)
            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
        return parts.join("");
    }
    return String.fromCharCode.apply(String, chunk.slice(0, i));
};

var invalidEncoding = "invalid encoding";

/**
 * Decodes a base64 encoded string to a buffer.
 * @param {string} string Source string
 * @param {Uint8Array} buffer Destination buffer
 * @param {number} offset Destination offset
 * @returns {number} Number of bytes written
 * @throws {Error} If encoding is invalid
 */
base64.decode = function decode(string, buffer, offset) {
    var start = offset;
    var j = 0, // goto index
        t;     // temporary
    for (var i = 0; i < string.length;) {
        var c = string.charCodeAt(i++);
        if (c === 61 && j > 1)
            break;
        if ((c = s64[c]) === undefined)
            throw Error(invalidEncoding);
        switch (j) {
            case 0:
                t = c;
                j = 1;
                break;
            case 1:
                buffer[offset++] = t << 2 | (c & 48) >> 4;
                t = c;
                j = 2;
                break;
            case 2:
                buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;
                t = c;
                j = 3;
                break;
            case 3:
                buffer[offset++] = (t & 3) << 6 | c;
                j = 0;
                break;
        }
    }
    if (j === 1)
        throw Error(invalidEncoding);
    return offset - start;
};

/**
 * Tests if the specified string appears to be base64 encoded.
 * @param {string} string String to test
 * @returns {boolean} `true` if probably base64 encoded, otherwise false
 */
base64.test = function test(string) {
    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);
};

},{}],11:[function(require,module,exports){
"use strict";
module.exports = EventEmitter;

/**
 * Constructs a new event emitter instance.
 * @classdesc A minimal event emitter.
 * @memberof util
 * @constructor
 */
function EventEmitter() {

    /**
     * Registered listeners.
     * @type {Object.<string,*>}
     * @private
     */
    this._listeners = {};
}

/**
 * Registers an event listener.
 * @param {string} evt Event name
 * @param {function} fn Listener
 * @param {*} [ctx] Listener context
 * @returns {util.EventEmitter} `this`
 */
EventEmitter.prototype.on = function on(evt, fn, ctx) {
    (this._listeners[evt] || (this._listeners[evt] = [])).push({
        fn  : fn,
        ctx : ctx || this
    });
    return this;
};

/**
 * Removes an event listener or any matching listeners if arguments are omitted.
 * @param {string} [evt] Event name. Removes all listeners if omitted.
 * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.
 * @returns {util.EventEmitter} `this`
 */
EventEmitter.prototype.off = function off(evt, fn) {
    if (evt === undefined)
        this._listeners = {};
    else {
        if (fn === undefined)
            this._listeners[evt] = [];
        else {
            var listeners = this._listeners[evt];
            for (var i = 0; i < listeners.length;)
                if (listeners[i].fn === fn)
                    listeners.splice(i, 1);
                else
                    ++i;
        }
    }
    return this;
};

/**
 * Emits an event by calling its listeners with the specified arguments.
 * @param {string} evt Event name
 * @param {...*} args Arguments
 * @returns {util.EventEmitter} `this`
 */
EventEmitter.prototype.emit = function emit(evt) {
    var listeners = this._listeners[evt];
    if (listeners) {
        var args = [],
            i = 1;
        for (; i < arguments.length;)
            args.push(arguments[i++]);
        for (i = 0; i < listeners.length;)
            listeners[i].fn.apply(listeners[i++].ctx, args);
    }
    return this;
};

},{}],12:[function(require,module,exports){
"use strict";

module.exports = factory(factory);

/**
 * Reads / writes floats / doubles from / to buffers.
 * @name util.float
 * @namespace
 */

/**
 * Writes a 32 bit float to a buffer using little endian byte order.
 * @name util.float.writeFloatLE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Writes a 32 bit float to a buffer using big endian byte order.
 * @name util.float.writeFloatBE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Reads a 32 bit float from a buffer using little endian byte order.
 * @name util.float.readFloatLE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Reads a 32 bit float from a buffer using big endian byte order.
 * @name util.float.readFloatBE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Writes a 64 bit double to a buffer using little endian byte order.
 * @name util.float.writeDoubleLE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Writes a 64 bit double to a buffer using big endian byte order.
 * @name util.float.writeDoubleBE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Reads a 64 bit double from a buffer using little endian byte order.
 * @name util.float.readDoubleLE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Reads a 64 bit double from a buffer using big endian byte order.
 * @name util.float.readDoubleBE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

// Factory function for the purpose of node-based testing in modified global environments
function factory(exports) {

    // float: typed array
    if (typeof Float32Array !== "undefined") (function() {

        var f32 = new Float32Array([ -0 ]),
            f8b = new Uint8Array(f32.buffer),
            le  = f8b[3] === 128;

        function writeFloat_f32_cpy(val, buf, pos) {
            f32[0] = val;
            buf[pos    ] = f8b[0];
            buf[pos + 1] = f8b[1];
            buf[pos + 2] = f8b[2];
            buf[pos + 3] = f8b[3];
        }

        function writeFloat_f32_rev(val, buf, pos) {
            f32[0] = val;
            buf[pos    ] = f8b[3];
            buf[pos + 1] = f8b[2];
            buf[pos + 2] = f8b[1];
            buf[pos + 3] = f8b[0];
        }

        /* istanbul ignore next */
        exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;
        /* istanbul ignore next */
        exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;

        function readFloat_f32_cpy(buf, pos) {
            f8b[0] = buf[pos    ];
            f8b[1] = buf[pos + 1];
            f8b[2] = buf[pos + 2];
            f8b[3] = buf[pos + 3];
            return f32[0];
        }

        function readFloat_f32_rev(buf, pos) {
            f8b[3] = buf[pos    ];
            f8b[2] = buf[pos + 1];
            f8b[1] = buf[pos + 2];
            f8b[0] = buf[pos + 3];
            return f32[0];
        }

        /* istanbul ignore next */
        exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;
        /* istanbul ignore next */
        exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy;

    // float: ieee754
    })(); else (function() {

        function writeFloat_ieee754(writeUint, val, buf, pos) {
            var sign = val < 0 ? 1 : 0;
            if (sign)
                val = -val;
            if (val === 0)
                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos);
            else if (isNaN(val))
                writeUint(2143289344, buf, pos);
            else if (val > 3.4028234663852886e+38) // +-Infinity
                writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);
            else if (val < 1.1754943508222875e-38) // denormal
                writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);
            else {
                var exponent = Math.floor(Math.log(val) / Math.LN2),
                    mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;
                writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);
            }
        }

        exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);
        exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);

        function readFloat_ieee754(readUint, buf, pos) {
            var uint = readUint(buf, pos),
                sign = (uint >> 31) * 2 + 1,
                exponent = uint >>> 23 & 255,
                mantissa = uint & 8388607;
            return exponent === 255
                ? mantissa
                ? NaN
                : sign * Infinity
                : exponent === 0 // denormal
                ? sign * 1.401298464324817e-45 * mantissa
                : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);
        }

        exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);
        exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);

    })();

    // double: typed array
    if (typeof Float64Array !== "undefined") (function() {

        var f64 = new Float64Array([-0]),
            f8b = new Uint8Array(f64.buffer),
            le  = f8b[7] === 128;

        function writeDouble_f64_cpy(val, buf, pos) {
            f64[0] = val;
            buf[pos    ] = f8b[0];
            buf[pos + 1] = f8b[1];
            buf[pos + 2] = f8b[2];
            buf[pos + 3] = f8b[3];
            buf[pos + 4] = f8b[4];
            buf[pos + 5] = f8b[5];
            buf[pos + 6] = f8b[6];
            buf[pos + 7] = f8b[7];
        }

        function writeDouble_f64_rev(val, buf, pos) {
            f64[0] = val;
            buf[pos    ] = f8b[7];
            buf[pos + 1] = f8b[6];
            buf[pos + 2] = f8b[5];
            buf[pos + 3] = f8b[4];
            buf[pos + 4] = f8b[3];
            buf[pos + 5] = f8b[2];
            buf[pos + 6] = f8b[1];
            buf[pos + 7] = f8b[0];
        }

        /* istanbul ignore next */
        exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;
        /* istanbul ignore next */
        exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;

        function readDouble_f64_cpy(buf, pos) {
            f8b[0] = buf[pos    ];
            f8b[1] = buf[pos + 1];
            f8b[2] = buf[pos + 2];
            f8b[3] = buf[pos + 3];
            f8b[4] = buf[pos + 4];
            f8b[5] = buf[pos + 5];
            f8b[6] = buf[pos + 6];
            f8b[7] = buf[pos + 7];
            return f64[0];
        }

        function readDouble_f64_rev(buf, pos) {
            f8b[7] = buf[pos    ];
            f8b[6] = buf[pos + 1];
            f8b[5] = buf[pos + 2];
            f8b[4] = buf[pos + 3];
            f8b[3] = buf[pos + 4];
            f8b[2] = buf[pos + 5];
            f8b[1] = buf[pos + 6];
            f8b[0] = buf[pos + 7];
            return f64[0];
        }

        /* istanbul ignore next */
        exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;
        /* istanbul ignore next */
        exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy;

    // double: ieee754
    })(); else (function() {

        function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {
            var sign = val < 0 ? 1 : 0;
            if (sign)
                val = -val;
            if (val === 0) {
                writeUint(0, buf, pos + off0);
                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos + off1);
            } else if (isNaN(val)) {
                writeUint(0, buf, pos + off0);
                writeUint(2146959360, buf, pos + off1);
            } else if (val > 1.7976931348623157e+308) { // +-Infinity
                writeUint(0, buf, pos + off0);
                writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);
            } else {
                var mantissa;
                if (val < 2.2250738585072014e-308) { // denormal
                    mantissa = val / 5e-324;
                    writeUint(mantissa >>> 0, buf, pos + off0);
                    writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);
                } else {
                    var exponent = Math.floor(Math.log(val) / Math.LN2);
                    if (exponent === 1024)
                        exponent = 1023;
                    mantissa = val * Math.pow(2, -exponent);
                    writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);
                    writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);
                }
            }
        }

        exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);
        exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);

        function readDouble_ieee754(readUint, off0, off1, buf, pos) {
            var lo = readUint(buf, pos + off0),
                hi = readUint(buf, pos + off1);
            var sign = (hi >> 31) * 2 + 1,
                exponent = hi >>> 20 & 2047,
                mantissa = 4294967296 * (hi & 1048575) + lo;
            return exponent === 2047
                ? mantissa
                ? NaN
                : sign * Infinity
                : exponent === 0 // denormal
                ? sign * 5e-324 * mantissa
                : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);
        }

        exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);
        exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);

    })();

    return exports;
}

// uint helpers

function writeUintLE(val, buf, pos) {
    buf[pos    ] =  val        & 255;
    buf[pos + 1] =  val >>> 8  & 255;
    buf[pos + 2] =  val >>> 16 & 255;
    buf[pos + 3] =  val >>> 24;
}

function writeUintBE(val, buf, pos) {
    buf[pos    ] =  val >>> 24;
    buf[pos + 1] =  val >>> 16 & 255;
    buf[pos + 2] =  val >>> 8  & 255;
    buf[pos + 3] =  val        & 255;
}

function readUintLE(buf, pos) {
    return (buf[pos    ]
          | buf[pos + 1] << 8
          | buf[pos + 2] << 16
          | buf[pos + 3] << 24) >>> 0;
}

function readUintBE(buf, pos) {
    return (buf[pos    ] << 24
          | buf[pos + 1] << 16
          | buf[pos + 2] << 8
          | buf[pos + 3]) >>> 0;
}

},{}],13:[function(require,module,exports){
"use strict";
module.exports = inquire;

/**
 * Requires a module only if available.
 * @memberof util
 * @param {string} moduleName Module to require
 * @returns {?Object} Required module if available and not empty, otherwise `null`
 */
function inquire(moduleName) {
    try {
        var mod = eval("quire".replace(/^/,"re"))(moduleName); // eslint-disable-line no-eval
        if (mod && (mod.length || Object.keys(mod).length))
            return mod;
    } catch (e) {} // eslint-disable-line no-empty
    return null;
}

},{}],14:[function(require,module,exports){
"use strict";
module.exports = pool;

/**
 * An allocator as used by {@link util.pool}.
 * @typedef PoolAllocator
 * @type {function}
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */

/**
 * A slicer as used by {@link util.pool}.
 * @typedef PoolSlicer
 * @type {function}
 * @param {number} start Start offset
 * @param {number} end End offset
 * @returns {Uint8Array} Buffer slice
 * @this {Uint8Array}
 */

/**
 * A general purpose buffer pool.
 * @memberof util
 * @function
 * @param {PoolAllocator} alloc Allocator
 * @param {PoolSlicer} slice Slicer
 * @param {number} [size=8192] Slab size
 * @returns {PoolAllocator} Pooled allocator
 */
function pool(alloc, slice, size) {
    var SIZE   = size || 8192;
    var MAX    = SIZE >>> 1;
    var slab   = null;
    var offset = SIZE;
    return function pool_alloc(size) {
        if (size < 1 || size > MAX)
            return alloc(size);
        if (offset + size > SIZE) {
            slab = alloc(SIZE);
            offset = 0;
        }
        var buf = slice.call(slab, offset, offset += size);
        if (offset & 7) // align to 32 bit
            offset = (offset | 7) + 1;
        return buf;
    };
}

},{}],15:[function(require,module,exports){
"use strict";

/**
 * A minimal UTF8 implementation for number arrays.
 * @memberof util
 * @namespace
 */
var utf8 = exports;

/**
 * Calculates the UTF8 byte length of a string.
 * @param {string} string String
 * @returns {number} Byte length
 */
utf8.length = function utf8_length(string) {
    var len = 0,
        c = 0;
    for (var i = 0; i < string.length; ++i) {
        c = string.charCodeAt(i);
        if (c < 128)
            len += 1;
        else if (c < 2048)
            len += 2;
        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {
            ++i;
            len += 4;
        } else
            len += 3;
    }
    return len;
};

/**
 * Reads UTF8 bytes as a string.
 * @param {Uint8Array} buffer Source buffer
 * @param {number} start Source start
 * @param {number} end Source end
 * @returns {string} String read
 */
utf8.read = function utf8_read(buffer, start, end) {
    var len = end - start;
    if (len < 1)
        return "";
    var parts = null,
        chunk = [],
        i = 0, // char offset
        t;     // temporary
    while (start < end) {
        t = buffer[start++];
        if (t < 128)
            chunk[i++] = t;
        else if (t > 191 && t < 224)
            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;
        else if (t > 239 && t < 365) {
            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;
            chunk[i++] = 0xD800 + (t >> 10);
            chunk[i++] = 0xDC00 + (t & 1023);
        } else
            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;
        if (i > 8191) {
            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
            i = 0;
        }
    }
    if (parts) {
        if (i)
            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
        return parts.join("");
    }
    return String.fromCharCode.apply(String, chunk.slice(0, i));
};

/**
 * Writes a string as UTF8 bytes.
 * @param {string} string Source string
 * @param {Uint8Array} buffer Destination buffer
 * @param {number} offset Destination offset
 * @returns {number} Bytes written
 */
utf8.write = function utf8_write(string, buffer, offset) {
    var start = offset,
        c1, // character 1
        c2; // character 2
    for (var i = 0; i < string.length; ++i) {
        c1 = string.charCodeAt(i);
        if (c1 < 128) {
            buffer[offset++] = c1;
        } else if (c1 < 2048) {
            buffer[offset++] = c1 >> 6       | 192;
            buffer[offset++] = c1       & 63 | 128;
        } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {
            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);
            ++i;
            buffer[offset++] = c1 >> 18      | 240;
            buffer[offset++] = c1 >> 12 & 63 | 128;
            buffer[offset++] = c1 >> 6  & 63 | 128;
            buffer[offset++] = c1       & 63 | 128;
        } else {
            buffer[offset++] = c1 >> 12      | 224;
            buffer[offset++] = c1 >> 6  & 63 | 128;
            buffer[offset++] = c1       & 63 | 128;
        }
    }
    return offset - start;
};

},{}],16:[function(require,module,exports){
// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.

const Buffer = require('safe-buffer').Buffer

module.exports = function base (ALPHABET) {
  if (ALPHABET.length >= 255) throw new TypeError('Alphabet too long')

  const BASE_MAP = new Uint8Array(256)
  BASE_MAP.fill(255)

  for (let i = 0; i < ALPHABET.length; i++) {
    const x = ALPHABET.charAt(i)
    const xc = x.charCodeAt(0)

    if (BASE_MAP[xc] !== 255) throw new TypeError(x + ' is ambiguous')
    BASE_MAP[xc] = i
  }

  const BASE = ALPHABET.length
  const LEADER = ALPHABET.charAt(0)
  const FACTOR = Math.log(BASE) / Math.log(256) // log(BASE) / log(256), rounded up
  const iFACTOR = Math.log(256) / Math.log(BASE) // log(256) / log(BASE), rounded up

  function encode (source) {
    if (!Buffer.isBuffer(source)) throw new TypeError('Expected Buffer')
    if (source.length === 0) return ''

    // Skip & count leading zeroes.
    let zeroes = 0
    let length = 0
    let pbegin = 0
    const pend = source.length

    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++
      zeroes++
    }

    // Allocate enough space in big-endian base58 representation.
    const size = ((pend - pbegin) * iFACTOR + 1) >>> 0
    const b58 = new Uint8Array(size)

    // Process the bytes.
    while (pbegin !== pend) {
      let carry = source[pbegin]

      // Apply "b58 = b58 * 256 + ch".
      let i = 0
      for (let it = size - 1; (carry !== 0 || i < length) && (it !== -1); it--, i++) {
        carry += (256 * b58[it]) >>> 0
        b58[it] = (carry % BASE) >>> 0
        carry = (carry / BASE) >>> 0
      }

      if (carry !== 0) throw new Error('Non-zero carry')
      length = i
      pbegin++
    }

    // Skip leading zeroes in base58 result.
    let it = size - length
    while (it !== size && b58[it] === 0) {
      it++
    }

    // Translate the result into a string.
    let str = LEADER.repeat(zeroes)
    for (; it < size; ++it) str += ALPHABET.charAt(b58[it])

    return str
  }

  function decodeUnsafe (source) {
    if (typeof source !== 'string') throw new TypeError('Expected String')
    if (source.length === 0) return Buffer.alloc(0)

    let psz = 0

    // Skip leading spaces.
    if (source[psz] === ' ') return

    // Skip and count leading '1's.
    let zeroes = 0
    let length = 0
    while (source[psz] === LEADER) {
      zeroes++
      psz++
    }

    // Allocate enough space in big-endian base256 representation.
    const size = (((source.length - psz) * FACTOR) + 1) >>> 0 // log(58) / log(256), rounded up.
    const b256 = new Uint8Array(size)

    // Process the characters.
    while (source[psz]) {
      // Decode character
      let carry = BASE_MAP[source.charCodeAt(psz)]

      // Invalid character
      if (carry === 255) return

      let i = 0
      for (let it = size - 1; (carry !== 0 || i < length) && (it !== -1); it--, i++) {
        carry += (BASE * b256[it]) >>> 0
        b256[it] = (carry % 256) >>> 0
        carry = (carry / 256) >>> 0
      }

      if (carry !== 0) throw new Error('Non-zero carry')
      length = i
      psz++
    }

    // Skip trailing spaces.
    if (source[psz] === ' ') return

    // Skip leading zeroes in b256.
    let it = size - length
    while (it !== size && b256[it] === 0) {
      it++
    }

    const vch = Buffer.allocUnsafe(zeroes + (size - it))
    vch.fill(0x00, 0, zeroes)

    let j = zeroes
    while (it !== size) {
      vch[j++] = b256[it++]
    }

    return vch
  }

  function decode (string) {
    const buffer = decodeUnsafe(string)
    if (buffer) return buffer

    throw new Error('Non-base' + BASE + ' character')
  }

  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}

},{"safe-buffer":57}],17:[function(require,module,exports){
'use strict'

exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  for (var i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(
      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)
    ))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}

},{}],18:[function(require,module,exports){

},{}],19:[function(require,module,exports){
arguments[4][18][0].apply(exports,arguments)
},{"dup":18}],20:[function(require,module,exports){
var basex = require('base-x')
var ALPHABET = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'

module.exports = basex(ALPHABET)

},{"base-x":16}],21:[function(require,module,exports){
/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */
/* eslint-disable no-proto */

'use strict'

var base64 = require('base64-js')
var ieee754 = require('ieee754')

exports.Buffer = Buffer
exports.SlowBuffer = SlowBuffer
exports.INSPECT_MAX_BYTES = 50

var K_MAX_LENGTH = 0x7fffffff
exports.kMaxLength = K_MAX_LENGTH

/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
 *               implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * We report that the browser does not support typed arrays if the are not subclassable
 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
 * for __proto__ and has a buggy typed array implementation.
 */
Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport()

if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
    typeof console.error === 'function') {
  console.error(
    'This browser lacks typed array (Uint8Array) support which is required by ' +
    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
  )
}

function typedArraySupport () {
  // Can typed array instances can be augmented?
  try {
    var arr = new Uint8Array(1)
    arr.__proto__ = { __proto__: Uint8Array.prototype, foo: function () { return 42 } }
    return arr.foo() === 42
  } catch (e) {
    return false
  }
}

Object.defineProperty(Buffer.prototype, 'parent', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.buffer
  }
})

Object.defineProperty(Buffer.prototype, 'offset', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.byteOffset
  }
})

function createBuffer (length) {
  if (length > K_MAX_LENGTH) {
    throw new RangeError('The value "' + length + '" is invalid for option "size"')
  }
  // Return an augmented `Uint8Array` instance
  var buf = new Uint8Array(length)
  buf.__proto__ = Buffer.prototype
  return buf
}

/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */

function Buffer (arg, encodingOrOffset, length) {
  // Common case.
  if (typeof arg === 'number') {
    if (typeof encodingOrOffset === 'string') {
      throw new TypeError(
        'The "string" argument must be of type string. Received type number'
      )
    }
    return allocUnsafe(arg)
  }
  return from(arg, encodingOrOffset, length)
}

// Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97
if (typeof Symbol !== 'undefined' && Symbol.species != null &&
    Buffer[Symbol.species] === Buffer) {
  Object.defineProperty(Buffer, Symbol.species, {
    value: null,
    configurable: true,
    enumerable: false,
    writable: false
  })
}

Buffer.poolSize = 8192 // not used by this implementation

function from (value, encodingOrOffset, length) {
  if (typeof value === 'string') {
    return fromString(value, encodingOrOffset)
  }

  if (ArrayBuffer.isView(value)) {
    return fromArrayLike(value)
  }

  if (value == null) {
    throw TypeError(
      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
      'or Array-like Object. Received type ' + (typeof value)
    )
  }

  if (isInstance(value, ArrayBuffer) ||
      (value && isInstance(value.buffer, ArrayBuffer))) {
    return fromArrayBuffer(value, encodingOrOffset, length)
  }

  if (typeof value === 'number') {
    throw new TypeError(
      'The "value" argument must not be of type number. Received type number'
    )
  }

  var valueOf = value.valueOf && value.valueOf()
  if (valueOf != null && valueOf !== value) {
    return Buffer.from(valueOf, encodingOrOffset, length)
  }

  var b = fromObject(value)
  if (b) return b

  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
      typeof value[Symbol.toPrimitive] === 'function') {
    return Buffer.from(
      value[Symbol.toPrimitive]('string'), encodingOrOffset, length
    )
  }

  throw new TypeError(
    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
    'or Array-like Object. Received type ' + (typeof value)
  )
}

/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/
Buffer.from = function (value, encodingOrOffset, length) {
  return from(value, encodingOrOffset, length)
}

// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
// https://github.com/feross/buffer/pull/148
Buffer.prototype.__proto__ = Uint8Array.prototype
Buffer.__proto__ = Uint8Array

function assertSize (size) {
  if (typeof size !== 'number') {
    throw new TypeError('"size" argument must be of type number')
  } else if (size < 0) {
    throw new RangeError('The value "' + size + '" is invalid for option "size"')
  }
}

function alloc (size, fill, encoding) {
  assertSize(size)
  if (size <= 0) {
    return createBuffer(size)
  }
  if (fill !== undefined) {
    // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpretted as a start offset.
    return typeof encoding === 'string'
      ? createBuffer(size).fill(fill, encoding)
      : createBuffer(size).fill(fill)
  }
  return createBuffer(size)
}

/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/
Buffer.alloc = function (size, fill, encoding) {
  return alloc(size, fill, encoding)
}

function allocUnsafe (size) {
  assertSize(size)
  return createBuffer(size < 0 ? 0 : checked(size) | 0)
}

/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */
Buffer.allocUnsafe = function (size) {
  return allocUnsafe(size)
}
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */
Buffer.allocUnsafeSlow = function (size) {
  return allocUnsafe(size)
}

function fromString (string, encoding) {
  if (typeof encoding !== 'string' || encoding === '') {
    encoding = 'utf8'
  }

  if (!Buffer.isEncoding(encoding)) {
    throw new TypeError('Unknown encoding: ' + encoding)
  }

  var length = byteLength(string, encoding) | 0
  var buf = createBuffer(length)

  var actual = buf.write(string, encoding)

  if (actual !== length) {
    // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    buf = buf.slice(0, actual)
  }

  return buf
}

function fromArrayLike (array) {
  var length = array.length < 0 ? 0 : checked(array.length) | 0
  var buf = createBuffer(length)
  for (var i = 0; i < length; i += 1) {
    buf[i] = array[i] & 255
  }
  return buf
}

function fromArrayBuffer (array, byteOffset, length) {
  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('"offset" is outside of buffer bounds')
  }

  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('"length" is outside of buffer bounds')
  }

  var buf
  if (byteOffset === undefined && length === undefined) {
    buf = new Uint8Array(array)
  } else if (length === undefined) {
    buf = new Uint8Array(array, byteOffset)
  } else {
    buf = new Uint8Array(array, byteOffset, length)
  }

  // Return an augmented `Uint8Array` instance
  buf.__proto__ = Buffer.prototype
  return buf
}

function fromObject (obj) {
  if (Buffer.isBuffer(obj)) {
    var len = checked(obj.length) | 0
    var buf = createBuffer(len)

    if (buf.length === 0) {
      return buf
    }

    obj.copy(buf, 0, 0, len)
    return buf
  }

  if (obj.length !== undefined) {
    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
      return createBuffer(0)
    }
    return fromArrayLike(obj)
  }

  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
    return fromArrayLike(obj.data)
  }
}

function checked (length) {
  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
  // length is NaN (which is otherwise coerced to zero.)
  if (length >= K_MAX_LENGTH) {
    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
  }
  return length | 0
}

function SlowBuffer (length) {
  if (+length != length) { // eslint-disable-line eqeqeq
    length = 0
  }
  return Buffer.alloc(+length)
}

Buffer.isBuffer = function isBuffer (b) {
  return b != null && b._isBuffer === true &&
    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
}

Buffer.compare = function compare (a, b) {
  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)
  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)
  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
    throw new TypeError(
      'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
    )
  }

  if (a === b) return 0

  var x = a.length
  var y = b.length

  for (var i = 0, len = Math.min(x, y); i < len; ++i) {
    if (a[i] !== b[i]) {
      x = a[i]
      y = b[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

Buffer.isEncoding = function isEncoding (encoding) {
  switch (String(encoding).toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'latin1':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
      return true
    default:
      return false
  }
}

Buffer.concat = function concat (list, length) {
  if (!Array.isArray(list)) {
    throw new TypeError('"list" argument must be an Array of Buffers')
  }

  if (list.length === 0) {
    return Buffer.alloc(0)
  }

  var i
  if (length === undefined) {
    length = 0
    for (i = 0; i < list.length; ++i) {
      length += list[i].length
    }
  }

  var buffer = Buffer.allocUnsafe(length)
  var pos = 0
  for (i = 0; i < list.length; ++i) {
    var buf = list[i]
    if (isInstance(buf, Uint8Array)) {
      buf = Buffer.from(buf)
    }
    if (!Buffer.isBuffer(buf)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }
    buf.copy(buffer, pos)
    pos += buf.length
  }
  return buffer
}

function byteLength (string, encoding) {
  if (Buffer.isBuffer(string)) {
    return string.length
  }
  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
    return string.byteLength
  }
  if (typeof string !== 'string') {
    throw new TypeError(
      'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
      'Received type ' + typeof string
    )
  }

  var len = string.length
  var mustMatch = (arguments.length > 2 && arguments[2] === true)
  if (!mustMatch && len === 0) return 0

  // Use a for loop to avoid recursion
  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'ascii':
      case 'latin1':
      case 'binary':
        return len
      case 'utf8':
      case 'utf-8':
        return utf8ToBytes(string).length
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return len * 2
      case 'hex':
        return len >>> 1
      case 'base64':
        return base64ToBytes(string).length
      default:
        if (loweredCase) {
          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
        }
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}
Buffer.byteLength = byteLength

function slowToString (encoding, start, end) {
  var loweredCase = false

  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
  // property of a typed array.

  // This behaves neither like String nor Uint8Array in that we set start/end
  // to their upper/lower bounds if the value passed is out of range.
  // undefined is handled specially as per ECMA-262 6th Edition,
  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
  if (start === undefined || start < 0) {
    start = 0
  }
  // Return early if start > this.length. Done here to prevent potential uint32
  // coercion fail below.
  if (start > this.length) {
    return ''
  }

  if (end === undefined || end > this.length) {
    end = this.length
  }

  if (end <= 0) {
    return ''
  }

  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.
  end >>>= 0
  start >>>= 0

  if (end <= start) {
    return ''
  }

  if (!encoding) encoding = 'utf8'

  while (true) {
    switch (encoding) {
      case 'hex':
        return hexSlice(this, start, end)

      case 'utf8':
      case 'utf-8':
        return utf8Slice(this, start, end)

      case 'ascii':
        return asciiSlice(this, start, end)

      case 'latin1':
      case 'binary':
        return latin1Slice(this, start, end)

      case 'base64':
        return base64Slice(this, start, end)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return utf16leSlice(this, start, end)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = (encoding + '').toLowerCase()
        loweredCase = true
    }
  }
}

// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
// reliably in a browserify context because there could be multiple different
// copies of the 'buffer' package in use. This method works even for Buffer
// instances that were created from another copy of the `buffer` package.
// See: https://github.com/feross/buffer/issues/154
Buffer.prototype._isBuffer = true

function swap (b, n, m) {
  var i = b[n]
  b[n] = b[m]
  b[m] = i
}

Buffer.prototype.swap16 = function swap16 () {
  var len = this.length
  if (len % 2 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 16-bits')
  }
  for (var i = 0; i < len; i += 2) {
    swap(this, i, i + 1)
  }
  return this
}

Buffer.prototype.swap32 = function swap32 () {
  var len = this.length
  if (len % 4 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 32-bits')
  }
  for (var i = 0; i < len; i += 4) {
    swap(this, i, i + 3)
    swap(this, i + 1, i + 2)
  }
  return this
}

Buffer.prototype.swap64 = function swap64 () {
  var len = this.length
  if (len % 8 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 64-bits')
  }
  for (var i = 0; i < len; i += 8) {
    swap(this, i, i + 7)
    swap(this, i + 1, i + 6)
    swap(this, i + 2, i + 5)
    swap(this, i + 3, i + 4)
  }
  return this
}

Buffer.prototype.toString = function toString () {
  var length = this.length
  if (length === 0) return ''
  if (arguments.length === 0) return utf8Slice(this, 0, length)
  return slowToString.apply(this, arguments)
}

Buffer.prototype.toLocaleString = Buffer.prototype.toString

Buffer.prototype.equals = function equals (b) {
  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
  if (this === b) return true
  return Buffer.compare(this, b) === 0
}

Buffer.prototype.inspect = function inspect () {
  var str = ''
  var max = exports.INSPECT_MAX_BYTES
  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()
  if (this.length > max) str += ' ... '
  return '<Buffer ' + str + '>'
}

Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
  if (isInstance(target, Uint8Array)) {
    target = Buffer.from(target, target.offset, target.byteLength)
  }
  if (!Buffer.isBuffer(target)) {
    throw new TypeError(
      'The "target" argument must be one of type Buffer or Uint8Array. ' +
      'Received type ' + (typeof target)
    )
  }

  if (start === undefined) {
    start = 0
  }
  if (end === undefined) {
    end = target ? target.length : 0
  }
  if (thisStart === undefined) {
    thisStart = 0
  }
  if (thisEnd === undefined) {
    thisEnd = this.length
  }

  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
    throw new RangeError('out of range index')
  }

  if (thisStart >= thisEnd && start >= end) {
    return 0
  }
  if (thisStart >= thisEnd) {
    return -1
  }
  if (start >= end) {
    return 1
  }

  start >>>= 0
  end >>>= 0
  thisStart >>>= 0
  thisEnd >>>= 0

  if (this === target) return 0

  var x = thisEnd - thisStart
  var y = end - start
  var len = Math.min(x, y)

  var thisCopy = this.slice(thisStart, thisEnd)
  var targetCopy = target.slice(start, end)

  for (var i = 0; i < len; ++i) {
    if (thisCopy[i] !== targetCopy[i]) {
      x = thisCopy[i]
      y = targetCopy[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
  // Empty buffer means no match
  if (buffer.length === 0) return -1

  // Normalize byteOffset
  if (typeof byteOffset === 'string') {
    encoding = byteOffset
    byteOffset = 0
  } else if (byteOffset > 0x7fffffff) {
    byteOffset = 0x7fffffff
  } else if (byteOffset < -0x80000000) {
    byteOffset = -0x80000000
  }
  byteOffset = +byteOffset // Coerce to Number.
  if (numberIsNaN(byteOffset)) {
    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : (buffer.length - 1)
  }

  // Normalize byteOffset: negative offsets start from the end of the buffer
  if (byteOffset < 0) byteOffset = buffer.length + byteOffset
  if (byteOffset >= buffer.length) {
    if (dir) return -1
    else byteOffset = buffer.length - 1
  } else if (byteOffset < 0) {
    if (dir) byteOffset = 0
    else return -1
  }

  // Normalize val
  if (typeof val === 'string') {
    val = Buffer.from(val, encoding)
  }

  // Finally, search either indexOf (if dir is true) or lastIndexOf
  if (Buffer.isBuffer(val)) {
    // Special case: looking for empty string/buffer always fails
    if (val.length === 0) {
      return -1
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
  } else if (typeof val === 'number') {
    val = val & 0xFF // Search for a byte value [0-255]
    if (typeof Uint8Array.prototype.indexOf === 'function') {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
      } else {
        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
      }
    }
    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)
  }

  throw new TypeError('val must be string, number or Buffer')
}

function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
  var indexSize = 1
  var arrLength = arr.length
  var valLength = val.length

  if (encoding !== undefined) {
    encoding = String(encoding).toLowerCase()
    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
        encoding === 'utf16le' || encoding === 'utf-16le') {
      if (arr.length < 2 || val.length < 2) {
        return -1
      }
      indexSize = 2
      arrLength /= 2
      valLength /= 2
      byteOffset /= 2
    }
  }

  function read (buf, i) {
    if (indexSize === 1) {
      return buf[i]
    } else {
      return buf.readUInt16BE(i * indexSize)
    }
  }

  var i
  if (dir) {
    var foundIndex = -1
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1) foundIndex = i
        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
      } else {
        if (foundIndex !== -1) i -= i - foundIndex
        foundIndex = -1
      }
    }
  } else {
    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength
    for (i = byteOffset; i >= 0; i--) {
      var found = true
      for (var j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false
          break
        }
      }
      if (found) return i
    }
  }

  return -1
}

Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
  return this.indexOf(val, byteOffset, encoding) !== -1
}

Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
}

Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
}

function hexWrite (buf, string, offset, length) {
  offset = Number(offset) || 0
  var remaining = buf.length - offset
  if (!length) {
    length = remaining
  } else {
    length = Number(length)
    if (length > remaining) {
      length = remaining
    }
  }

  var strLen = string.length

  if (length > strLen / 2) {
    length = strLen / 2
  }
  for (var i = 0; i < length; ++i) {
    var parsed = parseInt(string.substr(i * 2, 2), 16)
    if (numberIsNaN(parsed)) return i
    buf[offset + i] = parsed
  }
  return i
}

function utf8Write (buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
}

function asciiWrite (buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length)
}

function latin1Write (buf, string, offset, length) {
  return asciiWrite(buf, string, offset, length)
}

function base64Write (buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length)
}

function ucs2Write (buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
}

Buffer.prototype.write = function write (string, offset, length, encoding) {
  // Buffer#write(string)
  if (offset === undefined) {
    encoding = 'utf8'
    length = this.length
    offset = 0
  // Buffer#write(string, encoding)
  } else if (length === undefined && typeof offset === 'string') {
    encoding = offset
    length = this.length
    offset = 0
  // Buffer#write(string, offset[, length][, encoding])
  } else if (isFinite(offset)) {
    offset = offset >>> 0
    if (isFinite(length)) {
      length = length >>> 0
      if (encoding === undefined) encoding = 'utf8'
    } else {
      encoding = length
      length = undefined
    }
  } else {
    throw new Error(
      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
    )
  }

  var remaining = this.length - offset
  if (length === undefined || length > remaining) length = remaining

  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
    throw new RangeError('Attempt to write outside buffer bounds')
  }

  if (!encoding) encoding = 'utf8'

  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'hex':
        return hexWrite(this, string, offset, length)

      case 'utf8':
      case 'utf-8':
        return utf8Write(this, string, offset, length)

      case 'ascii':
        return asciiWrite(this, string, offset, length)

      case 'latin1':
      case 'binary':
        return latin1Write(this, string, offset, length)

      case 'base64':
        // Warning: maxLength not taken into account in base64Write
        return base64Write(this, string, offset, length)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return ucs2Write(this, string, offset, length)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}

Buffer.prototype.toJSON = function toJSON () {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this._arr || this, 0)
  }
}

function base64Slice (buf, start, end) {
  if (start === 0 && end === buf.length) {
    return base64.fromByteArray(buf)
  } else {
    return base64.fromByteArray(buf.slice(start, end))
  }
}

function utf8Slice (buf, start, end) {
  end = Math.min(buf.length, end)
  var res = []

  var i = start
  while (i < end) {
    var firstByte = buf[i]
    var codePoint = null
    var bytesPerSequence = (firstByte > 0xEF) ? 4
      : (firstByte > 0xDF) ? 3
        : (firstByte > 0xBF) ? 2
          : 1

    if (i + bytesPerSequence <= end) {
      var secondByte, thirdByte, fourthByte, tempCodePoint

      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 0x80) {
            codePoint = firstByte
          }
          break
        case 2:
          secondByte = buf[i + 1]
          if ((secondByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)
            if (tempCodePoint > 0x7F) {
              codePoint = tempCodePoint
            }
          }
          break
        case 3:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)
            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
              codePoint = tempCodePoint
            }
          }
          break
        case 4:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          fourthByte = buf[i + 3]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)
            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
              codePoint = tempCodePoint
            }
          }
      }
    }

    if (codePoint === null) {
      // we did not generate a valid codePoint so insert a
      // replacement char (U+FFFD) and advance only 1 byte
      codePoint = 0xFFFD
      bytesPerSequence = 1
    } else if (codePoint > 0xFFFF) {
      // encode to utf16 (surrogate pair dance)
      codePoint -= 0x10000
      res.push(codePoint >>> 10 & 0x3FF | 0xD800)
      codePoint = 0xDC00 | codePoint & 0x3FF
    }

    res.push(codePoint)
    i += bytesPerSequence
  }

  return decodeCodePointsArray(res)
}

// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
var MAX_ARGUMENTS_LENGTH = 0x1000

function decodeCodePointsArray (codePoints) {
  var len = codePoints.length
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
  }

  // Decode in chunks to avoid "call stack size exceeded".
  var res = ''
  var i = 0
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    )
  }
  return res
}

function asciiSlice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 0x7F)
  }
  return ret
}

function latin1Slice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i])
  }
  return ret
}

function hexSlice (buf, start, end) {
  var len = buf.length

  if (!start || start < 0) start = 0
  if (!end || end < 0 || end > len) end = len

  var out = ''
  for (var i = start; i < end; ++i) {
    out += toHex(buf[i])
  }
  return out
}

function utf16leSlice (buf, start, end) {
  var bytes = buf.slice(start, end)
  var res = ''
  for (var i = 0; i < bytes.length; i += 2) {
    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))
  }
  return res
}

Buffer.prototype.slice = function slice (start, end) {
  var len = this.length
  start = ~~start
  end = end === undefined ? len : ~~end

  if (start < 0) {
    start += len
    if (start < 0) start = 0
  } else if (start > len) {
    start = len
  }

  if (end < 0) {
    end += len
    if (end < 0) end = 0
  } else if (end > len) {
    end = len
  }

  if (end < start) end = start

  var newBuf = this.subarray(start, end)
  // Return an augmented `Uint8Array` instance
  newBuf.__proto__ = Buffer.prototype
  return newBuf
}

/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */
function checkOffset (offset, ext, length) {
  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
}

Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }

  return val
}

Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    checkOffset(offset, byteLength, this.length)
  }

  var val = this[offset + --byteLength]
  var mul = 1
  while (byteLength > 0 && (mul *= 0x100)) {
    val += this[offset + --byteLength] * mul
  }

  return val
}

Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  return this[offset]
}

Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return this[offset] | (this[offset + 1] << 8)
}

Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return (this[offset] << 8) | this[offset + 1]
}

Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return ((this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16)) +
      (this[offset + 3] * 0x1000000)
}

Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] * 0x1000000) +
    ((this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    this[offset + 3])
}

Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var i = byteLength
  var mul = 1
  var val = this[offset + --i]
  while (i > 0 && (mul *= 0x100)) {
    val += this[offset + --i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  if (!(this[offset] & 0x80)) return (this[offset])
  return ((0xff - this[offset] + 1) * -1)
}

Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset] | (this[offset + 1] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset + 1] | (this[offset] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset]) |
    (this[offset + 1] << 8) |
    (this[offset + 2] << 16) |
    (this[offset + 3] << 24)
}

Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] << 24) |
    (this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    (this[offset + 3])
}

Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, true, 23, 4)
}

Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, false, 23, 4)
}

Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, true, 52, 8)
}

Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, false, 52, 8)
}

function checkInt (buf, value, offset, ext, max, min) {
  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
}

Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var mul = 1
  var i = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var i = byteLength - 1
  var mul = 1
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset + 3] = (value >>> 24)
  this[offset + 2] = (value >>> 16)
  this[offset + 1] = (value >>> 8)
  this[offset] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = 0
  var mul = 1
  var sub = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = byteLength - 1
  var mul = 1
  var sub = 0
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)
  if (value < 0) value = 0xff + value + 1
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  this[offset + 2] = (value >>> 16)
  this[offset + 3] = (value >>> 24)
  return offset + 4
}

Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (value < 0) value = 0xffffffff + value + 1
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

function checkIEEE754 (buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
  if (offset < 0) throw new RangeError('Index out of range')
}

function writeFloat (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)
  }
  ieee754.write(buf, value, offset, littleEndian, 23, 4)
  return offset + 4
}

Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
  return writeFloat(this, value, offset, true, noAssert)
}

Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
  return writeFloat(this, value, offset, false, noAssert)
}

function writeDouble (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)
  }
  ieee754.write(buf, value, offset, littleEndian, 52, 8)
  return offset + 8
}

Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
  return writeDouble(this, value, offset, true, noAssert)
}

Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
  return writeDouble(this, value, offset, false, noAssert)
}

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy (target, targetStart, start, end) {
  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
  if (!start) start = 0
  if (!end && end !== 0) end = this.length
  if (targetStart >= target.length) targetStart = target.length
  if (!targetStart) targetStart = 0
  if (end > 0 && end < start) end = start

  // Copy 0 bytes; we're done
  if (end === start) return 0
  if (target.length === 0 || this.length === 0) return 0

  // Fatal error conditions
  if (targetStart < 0) {
    throw new RangeError('targetStart out of bounds')
  }
  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
  if (end < 0) throw new RangeError('sourceEnd out of bounds')

  // Are we oob?
  if (end > this.length) end = this.length
  if (target.length - targetStart < end - start) {
    end = target.length - targetStart + start
  }

  var len = end - start

  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
    // Use built-in when available, missing from IE11
    this.copyWithin(targetStart, start, end)
  } else if (this === target && start < targetStart && targetStart < end) {
    // descending copy from end
    for (var i = len - 1; i >= 0; --i) {
      target[i + targetStart] = this[i + start]
    }
  } else {
    Uint8Array.prototype.set.call(
      target,
      this.subarray(start, end),
      targetStart
    )
  }

  return len
}

// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill (val, start, end, encoding) {
  // Handle string cases:
  if (typeof val === 'string') {
    if (typeof start === 'string') {
      encoding = start
      start = 0
      end = this.length
    } else if (typeof end === 'string') {
      encoding = end
      end = this.length
    }
    if (encoding !== undefined && typeof encoding !== 'string') {
      throw new TypeError('encoding must be a string')
    }
    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }
    if (val.length === 1) {
      var code = val.charCodeAt(0)
      if ((encoding === 'utf8' && code < 128) ||
          encoding === 'latin1') {
        // Fast path: If `val` fits into a single byte, use that numeric value.
        val = code
      }
    }
  } else if (typeof val === 'number') {
    val = val & 255
  }

  // Invalid ranges are not set to a default, so can range check early.
  if (start < 0 || this.length < start || this.length < end) {
    throw new RangeError('Out of range index')
  }

  if (end <= start) {
    return this
  }

  start = start >>> 0
  end = end === undefined ? this.length : end >>> 0

  if (!val) val = 0

  var i
  if (typeof val === 'number') {
    for (i = start; i < end; ++i) {
      this[i] = val
    }
  } else {
    var bytes = Buffer.isBuffer(val)
      ? val
      : Buffer.from(val, encoding)
    var len = bytes.length
    if (len === 0) {
      throw new TypeError('The value "' + val +
        '" is invalid for argument "value"')
    }
    for (i = 0; i < end - start; ++i) {
      this[i + start] = bytes[i % len]
    }
  }

  return this
}

// HELPER FUNCTIONS
// ================

var INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g

function base64clean (str) {
  // Node takes equal signs as end of the Base64 encoding
  str = str.split('=')[0]
  // Node strips out invalid characters like \n and \t from the string, base64-js does not
  str = str.trim().replace(INVALID_BASE64_RE, '')
  // Node converts strings with length < 2 to ''
  if (str.length < 2) return ''
  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
  while (str.length % 4 !== 0) {
    str = str + '='
  }
  return str
}

function toHex (n) {
  if (n < 16) return '0' + n.toString(16)
  return n.toString(16)
}

function utf8ToBytes (string, units) {
  units = units || Infinity
  var codePoint
  var length = string.length
  var leadSurrogate = null
  var bytes = []

  for (var i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i)

    // is surrogate component
    if (codePoint > 0xD7FF && codePoint < 0xE000) {
      // last char was a lead
      if (!leadSurrogate) {
        // no lead yet
        if (codePoint > 0xDBFF) {
          // unexpected trail
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        } else if (i + 1 === length) {
          // unpaired lead
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        }

        // valid lead
        leadSurrogate = codePoint

        continue
      }

      // 2 leads in a row
      if (codePoint < 0xDC00) {
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
        leadSurrogate = codePoint
        continue
      }

      // valid surrogate pair
      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000
    } else if (leadSurrogate) {
      // valid bmp char, but last char was a lead
      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
    }

    leadSurrogate = null

    // encode utf8
    if (codePoint < 0x80) {
      if ((units -= 1) < 0) break
      bytes.push(codePoint)
    } else if (codePoint < 0x800) {
      if ((units -= 2) < 0) break
      bytes.push(
        codePoint >> 0x6 | 0xC0,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x10000) {
      if ((units -= 3) < 0) break
      bytes.push(
        codePoint >> 0xC | 0xE0,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x110000) {
      if ((units -= 4) < 0) break
      bytes.push(
        codePoint >> 0x12 | 0xF0,
        codePoint >> 0xC & 0x3F | 0x80,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else {
      throw new Error('Invalid code point')
    }
  }

  return bytes
}

function asciiToBytes (str) {
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF)
  }
  return byteArray
}

function utf16leToBytes (str, units) {
  var c, hi, lo
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0) break

    c = str.charCodeAt(i)
    hi = c >> 8
    lo = c % 256
    byteArray.push(lo)
    byteArray.push(hi)
  }

  return byteArray
}

function base64ToBytes (str) {
  return base64.toByteArray(base64clean(str))
}

function blitBuffer (src, dst, offset, length) {
  for (var i = 0; i < length; ++i) {
    if ((i + offset >= dst.length) || (i >= src.length)) break
    dst[i + offset] = src[i]
  }
  return i
}

// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
// the `instanceof` check but they should be treated as of that type.
// See: https://github.com/feross/buffer/issues/166
function isInstance (obj, type) {
  return obj instanceof type ||
    (obj != null && obj.constructor != null && obj.constructor.name != null &&
      obj.constructor.name === type.name)
}
function numberIsNaN (obj) {
  // For IE11 support
  return obj !== obj // eslint-disable-line no-self-compare
}

},{"base64-js":17,"ieee754":38}],22:[function(require,module,exports){
require(".").check("es5");
},{".":23}],23:[function(require,module,exports){
require("./lib/definitions");
module.exports = require("./lib");

},{"./lib":26,"./lib/definitions":25}],24:[function(require,module,exports){
var CapabilityDetector = function () {
    this.tests = {};
    this.cache = {};
};
CapabilityDetector.prototype = {
    constructor: CapabilityDetector,
    define: function (name, test) {
        if (typeof (name) != "string" || !(test instanceof Function))
            throw new Error("Invalid capability definition.");
        if (this.tests[name])
            throw new Error('Duplicated capability definition by "' + name + '".');
        this.tests[name] = test;
    },
    check: function (name) {
        if (!this.test(name))
            throw new Error('The current environment does not support "' + name + '", therefore we cannot continue.');
    },
    test: function (name) {
        if (this.cache[name] !== undefined)
            return this.cache[name];
        if (!this.tests[name])
            throw new Error('Unknown capability with name "' + name + '".');
        var test = this.tests[name];
        this.cache[name] = !!test();
        return this.cache[name];
    }
};

module.exports = CapabilityDetector;
},{}],25:[function(require,module,exports){
var capability = require("."),
    define = capability.define,
    test = capability.test;

define("strict mode", function () {
    return (this === undefined);
});

define("arguments.callee.caller", function () {
    try {
        return (function () {
                return arguments.callee.caller;
            })() === arguments.callee;
    } catch (strictModeIsEnforced) {
        return false;
    }
});

define("es5", function () {
    return test("Array.prototype.forEach") &&
        test("Array.prototype.map") &&
        test("Function.prototype.bind") &&
        test("Object.create") &&
        test("Object.defineProperties") &&
        test("Object.defineProperty") &&
        test("Object.prototype.hasOwnProperty");
});

define("Array.prototype.forEach", function () {
    return Array.prototype.forEach;
});

define("Array.prototype.map", function () {
    return Array.prototype.map;
});

define("Function.prototype.bind", function () {
    return Function.prototype.bind;
});

define("Object.create", function () {
    return Object.create;
});

define("Object.defineProperties", function () {
    return Object.defineProperties;
});

define("Object.defineProperty", function () {
    return Object.defineProperty;
});

define("Object.prototype.hasOwnProperty", function () {
    return Object.prototype.hasOwnProperty;
});

define("Error.captureStackTrace", function () {
    return Error.captureStackTrace;
});

define("Error.prototype.stack", function () {
    try {
        throw new Error();
    }
    catch (e) {
        return e.stack || e.stacktrace;
    }
});
},{".":26}],26:[function(require,module,exports){
var CapabilityDetector = require("./CapabilityDetector");

var detector = new CapabilityDetector();

var capability = function (name) {
    return detector.test(name);
};
capability.define = function (name, test) {
    detector.define(name, test);
};
capability.check = function (name) {
    detector.check(name);
};
capability.test = capability;

module.exports = capability;
},{"./CapabilityDetector":24}],27:[function(require,module,exports){
/*!
 * depd
 * Copyright(c) 2015 Douglas Christopher Wilson
 * MIT Licensed
 */

'use strict'

/**
 * Module exports.
 * @public
 */

module.exports = depd

/**
 * Create deprecate for namespace in caller.
 */

function depd (namespace) {
  if (!namespace) {
    throw new TypeError('argument namespace is required')
  }

  function deprecate (message) {
    // no-op in browser
  }

  deprecate._file = undefined
  deprecate._ignored = true
  deprecate._namespace = namespace
  deprecate._traced = false
  deprecate._warned = Object.create(null)

  deprecate.function = wrapfunction
  deprecate.property = wrapproperty

  return deprecate
}

/**
 * Return a wrapped function in a deprecation message.
 *
 * This is a no-op version of the wrapper, which does nothing but call
 * validation.
 */

function wrapfunction (fn, message) {
  if (typeof fn !== 'function') {
    throw new TypeError('argument fn must be a function')
  }

  return fn
}

/**
 * Wrap property in a deprecation message.
 *
 * This is a no-op version of the wrapper, which does nothing but call
 * validation.
 */

function wrapproperty (obj, prop, message) {
  if (!obj || (typeof obj !== 'object' && typeof obj !== 'function')) {
    throw new TypeError('argument obj must be object')
  }

  var descriptor = Object.getOwnPropertyDescriptor(obj, prop)

  if (!descriptor) {
    throw new TypeError('must call property on owner object')
  }

  if (!descriptor.configurable) {
    throw new TypeError('property must be configurable')
  }
}

},{}],28:[function(require,module,exports){
module.exports = require("./lib");
},{"./lib":29}],29:[function(require,module,exports){
require("capability/es5");

var capability = require("capability");

var polyfill;
if (capability("Error.captureStackTrace"))
    polyfill = require("./v8");
else if (capability("Error.prototype.stack"))
    polyfill = require("./non-v8/index");
else
    polyfill = require("./unsupported");

module.exports = polyfill();
},{"./non-v8/index":33,"./unsupported":35,"./v8":36,"capability":23,"capability/es5":22}],30:[function(require,module,exports){
var Class = require("o3").Class,
    abstractMethod = require("o3").abstractMethod;

var Frame = Class(Object, {
    prototype: {
        init: Class.prototype.merge,
        frameString: undefined,
        toString: function () {
            return this.frameString;
        },
        functionValue: undefined,
        getThis: abstractMethod,
        getTypeName: abstractMethod,
        getFunction: function () {
            return this.functionValue;
        },
        getFunctionName: abstractMethod,
        getMethodName: abstractMethod,
        getFileName: abstractMethod,
        getLineNumber: abstractMethod,
        getColumnNumber: abstractMethod,
        getEvalOrigin: abstractMethod,
        isTopLevel: abstractMethod,
        isEval: abstractMethod,
        isNative: abstractMethod,
        isConstructor: abstractMethod
    }
});

module.exports = Frame;
},{"o3":41}],31:[function(require,module,exports){
var Class = require("o3").Class,
    Frame = require("./Frame"),
    cache = require("u3").cache;

var FrameStringParser = Class(Object, {
    prototype: {
        stackParser: null,
        frameParser: null,
        locationParsers: null,
        constructor: function (options) {
            Class.prototype.merge.call(this, options);
        },
        getFrames: function (frameStrings, functionValues) {
            var frames = [];
            for (var index = 0, length = frameStrings.length; index < length; ++index)
                frames[index] = this.getFrame(frameStrings[index], functionValues[index]);
            return frames;
        },
        getFrame: function (frameString, functionValue) {
            var config = {
                frameString: frameString,
                functionValue: functionValue
            };
            return new Frame(config);
        }
    }
});

module.exports = {
    getClass: cache(function () {
        return FrameStringParser;
    }),
    getInstance: cache(function () {
        var FrameStringParser = this.getClass();
        var instance = new FrameStringParser();
        return instance;
    })
};
},{"./Frame":30,"o3":41,"u3":63}],32:[function(require,module,exports){
var Class = require("o3").Class,
    abstractMethod = require("o3").abstractMethod,
    eachCombination = require("u3").eachCombination,
    cache = require("u3").cache,
    capability = require("capability");

var AbstractFrameStringSource = Class(Object, {
    prototype: {
        captureFrameStrings: function (frameShifts) {
            var error = this.createError();
            frameShifts.unshift(this.captureFrameStrings);
            frameShifts.unshift(this.createError);
            var capturedFrameStrings = this.getFrameStrings(error);

            var frameStrings = capturedFrameStrings.slice(frameShifts.length),
                functionValues = [];

            if (capability("arguments.callee.caller")) {
                var capturedFunctionValues = [
                    this.createError,
                    this.captureFrameStrings
                ];
                try {
                    var aCaller = arguments.callee;
                    while (aCaller = aCaller.caller)
                        capturedFunctionValues.push(aCaller);
                }
                catch (useStrictError) {
                }
                functionValues = capturedFunctionValues.slice(frameShifts.length);
            }
            return {
                frameStrings: frameStrings,
                functionValues: functionValues
            };
        },
        getFrameStrings: function (error) {
            var message = error.message || "";
            var name = error.name || "";
            var stackString = this.getStackString(error);
            if (stackString === undefined)
                return;
            var stackStringChunks = stackString.split("\n");
            var fromPosition = 0;
            var toPosition = stackStringChunks.length;
            if (this.hasHeader)
                fromPosition += name.split("\n").length + message.split("\n").length - 1;
            if (this.hasFooter)
                toPosition -= 1;
            return stackStringChunks.slice(fromPosition, toPosition);
        },
        createError: abstractMethod,
        getStackString: abstractMethod,
        hasHeader: undefined,
        hasFooter: undefined
    }
});

var FrameStringSourceCalibrator = Class(Object, {
    prototype: {
        calibrateClass: function (FrameStringSource) {
            return this.calibrateMethods(FrameStringSource) && this.calibrateEnvelope(FrameStringSource);
        },
        calibrateMethods: function (FrameStringSource) {
            try {
                eachCombination([[
                    function (message) {
                        return new Error(message);
                    },
                    function (message) {
                        try {
                            throw new Error(message);
                        }
                        catch (error) {
                            return error;
                        }
                    }
                ], [
                    function (error) {
                        return error.stack;
                    },
                    function (error) {
                        return error.stacktrace;
                    }
                ]], function (createError, getStackString) {
                    if (getStackString(createError()))
                        throw {
                            getStackString: getStackString,
                            createError: createError
                        };
                });
            } catch (workingImplementation) {
                Class.merge.call(FrameStringSource, {
                    prototype: workingImplementation
                });
                return true;
            }
            return false;
        },
        calibrateEnvelope: function (FrameStringSource) {
            var getStackString = FrameStringSource.prototype.getStackString;
            var createError = FrameStringSource.prototype.createError;
            var calibratorStackString = getStackString(createError("marker"));
            var calibratorFrameStrings = calibratorStackString.split("\n");
            Class.merge.call(FrameStringSource, {
                prototype: {
                    hasHeader: /marker/.test(calibratorFrameStrings[0]),
                    hasFooter: calibratorFrameStrings[calibratorFrameStrings.length - 1] === ""
                }
            });
            return true;
        }
    }
});

module.exports = {
    getClass: cache(function () {
        var FrameStringSource;
        if (FrameStringSource)
            return FrameStringSource;
        FrameStringSource = Class(AbstractFrameStringSource, {});
        var calibrator = new FrameStringSourceCalibrator();
        if (!calibrator.calibrateClass(FrameStringSource))
            throw new Error("Cannot read Error.prototype.stack in this environment.");
        return FrameStringSource;
    }),
    getInstance: cache(function () {
        var FrameStringSource = this.getClass();
        var instance = new FrameStringSource();
        return instance;
    })
};
},{"capability":23,"o3":41,"u3":63}],33:[function(require,module,exports){
var FrameStringSource = require("./FrameStringSource"),
    FrameStringParser = require("./FrameStringParser"),
    cache = require("u3").cache,
    prepareStackTrace = require("../prepareStackTrace");

module.exports = function () {

    Error.captureStackTrace = function captureStackTrace(throwable, terminator) {
        var warnings;
        var frameShifts = [
            captureStackTrace
        ];
        if (terminator) {
            // additional frames can come here if arguments.callee.caller is supported
            // otherwise it is hard to identify the terminator
            frameShifts.push(terminator);
        }
        var captured = FrameStringSource.getInstance().captureFrameStrings(frameShifts);
        Object.defineProperties(throwable, {
            stack: {
                configurable: true,
                get: cache(function () {
                    var frames = FrameStringParser.getInstance().getFrames(captured.frameStrings, captured.functionValues);
                    return (Error.prepareStackTrace || prepareStackTrace)(throwable, frames, warnings);
                })
            },
            cachedStack: {
                configurable: true,
                writable: true,
                enumerable: false,
                value: true
            }
        });
    };

    Error.getStackTrace = function (throwable) {
        if (throwable.cachedStack)
            return throwable.stack;
        var frameStrings = FrameStringSource.getInstance().getFrameStrings(throwable),
            frames = [],
            warnings;
        if (frameStrings)
            frames = FrameStringParser.getInstance().getFrames(frameStrings, []);
        else
            warnings = [
                "The stack is not readable by unthrown errors in this environment."
            ];
        var stack = (Error.prepareStackTrace || prepareStackTrace)(throwable, frames, warnings);
        if (frameStrings)
            try {
                Object.defineProperties(throwable, {
                    stack: {
                        configurable: true,
                        writable: true,
                        enumerable: false,
                        value: stack
                    },
                    cachedStack: {
                        configurable: true,
                        writable: true,
                        enumerable: false,
                        value: true
                    }
                });
            } catch (nonConfigurableError) {
            }
        return stack;
    };

    return {
        prepareStackTrace: prepareStackTrace
    };
};
},{"../prepareStackTrace":34,"./FrameStringParser":31,"./FrameStringSource":32,"u3":63}],34:[function(require,module,exports){
var prepareStackTrace = function (throwable, frames, warnings) {
    var string = "";
    string += throwable.name || "Error";
    string += ": " + (throwable.message || "");
    if (warnings instanceof Array)
        for (var warningIndex in warnings) {
            var warning = warnings[warningIndex];
            string += "\n   # " + warning;
        }
    for (var frameIndex in frames) {
        var frame = frames[frameIndex];
        string += "\n   at " + frame.toString();
    }
    return string;
};

module.exports = prepareStackTrace;
},{}],35:[function(require,module,exports){
var cache = require("u3").cache,
    prepareStackTrace = require("./prepareStackTrace");

module.exports = function () {

    Error.captureStackTrace = function (throwable, terminator) {
        Object.defineProperties(throwable, {
            stack: {
                configurable: true,
                get: cache(function () {
                    return (Error.prepareStackTrace || prepareStackTrace)(throwable, []);
                })
            },
            cachedStack: {
                configurable: true,
                writable: true,
                enumerable: false,
                value: true
            }
        });
    };

    Error.getStackTrace = function (throwable) {
        if (throwable.cachedStack)
            return throwable.stack;
        var stack = (Error.prepareStackTrace || prepareStackTrace)(throwable, []);
        try {
            Object.defineProperties(throwable, {
                stack: {
                    configurable: true,
                    writable: true,
                    enumerable: false,
                    value: stack
                },
                cachedStack: {
                    configurable: true,
                    writable: true,
                    enumerable: false,
                    value: true
                }
            });
        } catch (nonConfigurableError) {
        }
        return stack;
    };

    return {
        prepareStackTrace: prepareStackTrace
    };
};
},{"./prepareStackTrace":34,"u3":63}],36:[function(require,module,exports){
var prepareStackTrace = require("./prepareStackTrace");

module.exports = function () {
    Error.getStackTrace = function (throwable) {
        return throwable.stack;
    };

    return {
        prepareStackTrace: prepareStackTrace
    };
};
},{"./prepareStackTrace":34}],37:[function(require,module,exports){
/*!
 * http-errors
 * Copyright(c) 2014 Jonathan Ong
 * Copyright(c) 2016 Douglas Christopher Wilson
 * MIT Licensed
 */

'use strict'

/**
 * Module dependencies.
 * @private
 */

var deprecate = require('depd')('http-errors')
var setPrototypeOf = require('setprototypeof')
var statuses = require('statuses')
var inherits = require('inherits')
var toIdentifier = require('toidentifier')

/**
 * Module exports.
 * @public
 */

module.exports = createError
module.exports.HttpError = createHttpErrorConstructor()

// Populate exports for all constructors
populateConstructorExports(module.exports, statuses.codes, module.exports.HttpError)

/**
 * Get the code class of a status code.
 * @private
 */

function codeClass (status) {
  return Number(String(status).charAt(0) + '00')
}

/**
 * Create a new HTTP Error.
 *
 * @returns {Error}
 * @public
 */

function createError () {
  // so much arity going on ~_~
  var err
  var msg
  var status = 500
  var props = {}
  for (var i = 0; i < arguments.length; i++) {
    var arg = arguments[i]
    if (arg instanceof Error) {
      err = arg
      status = err.status || err.statusCode || status
      continue
    }
    switch (typeof arg) {
      case 'string':
        msg = arg
        break
      case 'number':
        status = arg
        if (i !== 0) {
          deprecate('non-first-argument status code; replace with createError(' + arg + ', ...)')
        }
        break
      case 'object':
        props = arg
        break
    }
  }

  if (typeof status === 'number' && (status < 400 || status >= 600)) {
    deprecate('non-error status code; use only 4xx or 5xx status codes')
  }

  if (typeof status !== 'number' ||
    (!statuses[status] && (status < 400 || status >= 600))) {
    status = 500
  }

  // constructor
  var HttpError = createError[status] || createError[codeClass(status)]

  if (!err) {
    // create error
    err = HttpError
      ? new HttpError(msg)
      : new Error(msg || statuses[status])
    Error.captureStackTrace(err, createError)
  }

  if (!HttpError || !(err instanceof HttpError) || err.status !== status) {
    // add properties to generic error
    err.expose = status < 500
    err.status = err.statusCode = status
  }

  for (var key in props) {
    if (key !== 'status' && key !== 'statusCode') {
      err[key] = props[key]
    }
  }

  return err
}

/**
 * Create HTTP error abstract base class.
 * @private
 */

function createHttpErrorConstructor () {
  function HttpError () {
    throw new TypeError('cannot construct abstract class')
  }

  inherits(HttpError, Error)

  return HttpError
}

/**
 * Create a constructor for a client error.
 * @private
 */

function createClientErrorConstructor (HttpError, name, code) {
  var className = name.match(/Error$/) ? name : name + 'Error'

  function ClientError (message) {
    // create the error object
    var msg = message != null ? message : statuses[code]
    var err = new Error(msg)

    // capture a stack trace to the construction point
    Error.captureStackTrace(err, ClientError)

    // adjust the [[Prototype]]
    setPrototypeOf(err, ClientError.prototype)

    // redefine the error message
    Object.defineProperty(err, 'message', {
      enumerable: true,
      configurable: true,
      value: msg,
      writable: true
    })

    // redefine the error name
    Object.defineProperty(err, 'name', {
      enumerable: false,
      configurable: true,
      value: className,
      writable: true
    })

    return err
  }

  inherits(ClientError, HttpError)
  nameFunc(ClientError, className)

  ClientError.prototype.status = code
  ClientError.prototype.statusCode = code
  ClientError.prototype.expose = true

  return ClientError
}

/**
 * Create a constructor for a server error.
 * @private
 */

function createServerErrorConstructor (HttpError, name, code) {
  var className = name.match(/Error$/) ? name : name + 'Error'

  function ServerError (message) {
    // create the error object
    var msg = message != null ? message : statuses[code]
    var err = new Error(msg)

    // capture a stack trace to the construction point
    Error.captureStackTrace(err, ServerError)

    // adjust the [[Prototype]]
    setPrototypeOf(err, ServerError.prototype)

    // redefine the error message
    Object.defineProperty(err, 'message', {
      enumerable: true,
      configurable: true,
      value: msg,
      writable: true
    })

    // redefine the error name
    Object.defineProperty(err, 'name', {
      enumerable: false,
      configurable: true,
      value: className,
      writable: true
    })

    return err
  }

  inherits(ServerError, HttpError)
  nameFunc(ServerError, className)

  ServerError.prototype.status = code
  ServerError.prototype.statusCode = code
  ServerError.prototype.expose = false

  return ServerError
}

/**
 * Set the name of a function, if possible.
 * @private
 */

function nameFunc (func, name) {
  var desc = Object.getOwnPropertyDescriptor(func, 'name')

  if (desc && desc.configurable) {
    desc.value = name
    Object.defineProperty(func, 'name', desc)
  }
}

/**
 * Populate the exports object with constructors for every error class.
 * @private
 */

function populateConstructorExports (exports, codes, HttpError) {
  codes.forEach(function forEachCode (code) {
    var CodeError
    var name = toIdentifier(statuses[code])

    switch (codeClass(code)) {
      case 400:
        CodeError = createClientErrorConstructor(HttpError, name, code)
        break
      case 500:
        CodeError = createServerErrorConstructor(HttpError, name, code)
        break
    }

    if (CodeError) {
      // export the constructor
      exports[code] = CodeError
      exports[name] = CodeError
    }
  })

  // backwards-compatibility
  exports["I'mateapot"] = deprecate.function(exports.ImATeapot,
    '"I\'mateapot"; use "ImATeapot" instead')
}

},{"depd":27,"inherits":39,"setprototypeof":58,"statuses":60,"toidentifier":61}],38:[function(require,module,exports){
exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}

},{}],39:[function(require,module,exports){
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    ctor.prototype = Object.create(superCtor.prototype, {
      constructor: {
        value: ctor,
        enumerable: false,
        writable: true,
        configurable: true
      }
    });
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    var TempCtor = function () {}
    TempCtor.prototype = superCtor.prototype
    ctor.prototype = new TempCtor()
    ctor.prototype.constructor = ctor
  }
}

},{}],40:[function(require,module,exports){
(function (process,global){
/**
 * [js-sha256]{@link https://github.com/emn178/js-sha256}
 *
 * @version 0.9.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2014-2017
 * @license MIT
 */
/*jslint bitwise: true */
(function () {
  'use strict';

  var ERROR = 'input is invalid type';
  var WINDOW = typeof window === 'object';
  var root = WINDOW ? window : {};
  if (root.JS_SHA256_NO_WINDOW) {
    WINDOW = false;
  }
  var WEB_WORKER = !WINDOW && typeof self === 'object';
  var NODE_JS = !root.JS_SHA256_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
  if (NODE_JS) {
    root = global;
  } else if (WEB_WORKER) {
    root = self;
  }
  var COMMON_JS = !root.JS_SHA256_NO_COMMON_JS && typeof module === 'object' && module.exports;
  var AMD = typeof define === 'function' && define.amd;
  var ARRAY_BUFFER = !root.JS_SHA256_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
  var HEX_CHARS = '0123456789abcdef'.split('');
  var EXTRA = [-2147483648, 8388608, 32768, 128];
  var SHIFT = [24, 16, 8, 0];
  var K = [
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
  ];
  var OUTPUT_TYPES = ['hex', 'array', 'digest', 'arrayBuffer'];

  var blocks = [];

  if (root.JS_SHA256_NO_NODE_JS || !Array.isArray) {
    Array.isArray = function (obj) {
      return Object.prototype.toString.call(obj) === '[object Array]';
    };
  }

  if (ARRAY_BUFFER && (root.JS_SHA256_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView)) {
    ArrayBuffer.isView = function (obj) {
      return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
    };
  }

  var createOutputMethod = function (outputType, is224) {
    return function (message) {
      return new Sha256(is224, true).update(message)[outputType]();
    };
  };

  var createMethod = function (is224) {
    var method = createOutputMethod('hex', is224);
    if (NODE_JS) {
      method = nodeWrap(method, is224);
    }
    method.create = function () {
      return new Sha256(is224);
    };
    method.update = function (message) {
      return method.create().update(message);
    };
    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
      var type = OUTPUT_TYPES[i];
      method[type] = createOutputMethod(type, is224);
    }
    return method;
  };

  var nodeWrap = function (method, is224) {
    var crypto = eval("require('crypto')");
    var Buffer = eval("require('buffer').Buffer");
    var algorithm = is224 ? 'sha224' : 'sha256';
    var nodeMethod = function (message) {
      if (typeof message === 'string') {
        return crypto.createHash(algorithm).update(message, 'utf8').digest('hex');
      } else {
        if (message === null || message === undefined) {
          throw new Error(ERROR);
        } else if (message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        }
      }
      if (Array.isArray(message) || ArrayBuffer.isView(message) ||
        message.constructor === Buffer) {
        return crypto.createHash(algorithm).update(new Buffer(message)).digest('hex');
      } else {
        return method(message);
      }
    };
    return nodeMethod;
  };

  var createHmacOutputMethod = function (outputType, is224) {
    return function (key, message) {
      return new HmacSha256(key, is224, true).update(message)[outputType]();
    };
  };

  var createHmacMethod = function (is224) {
    var method = createHmacOutputMethod('hex', is224);
    method.create = function (key) {
      return new HmacSha256(key, is224);
    };
    method.update = function (key, message) {
      return method.create(key).update(message);
    };
    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
      var type = OUTPUT_TYPES[i];
      method[type] = createHmacOutputMethod(type, is224);
    }
    return method;
  };

  function Sha256(is224, sharedMemory) {
    if (sharedMemory) {
      blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] =
        blocks[4] = blocks[5] = blocks[6] = blocks[7] =
        blocks[8] = blocks[9] = blocks[10] = blocks[11] =
        blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      this.blocks = blocks;
    } else {
      this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
    }

    if (is224) {
      this.h0 = 0xc1059ed8;
      this.h1 = 0x367cd507;
      this.h2 = 0x3070dd17;
      this.h3 = 0xf70e5939;
      this.h4 = 0xffc00b31;
      this.h5 = 0x68581511;
      this.h6 = 0x64f98fa7;
      this.h7 = 0xbefa4fa4;
    } else { // 256
      this.h0 = 0x6a09e667;
      this.h1 = 0xbb67ae85;
      this.h2 = 0x3c6ef372;
      this.h3 = 0xa54ff53a;
      this.h4 = 0x510e527f;
      this.h5 = 0x9b05688c;
      this.h6 = 0x1f83d9ab;
      this.h7 = 0x5be0cd19;
    }

    this.block = this.start = this.bytes = this.hBytes = 0;
    this.finalized = this.hashed = false;
    this.first = true;
    this.is224 = is224;
  }

  Sha256.prototype.update = function (message) {
    if (this.finalized) {
      return;
    }
    var notString, type = typeof message;
    if (type !== 'string') {
      if (type === 'object') {
        if (message === null) {
          throw new Error(ERROR);
        } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        } else if (!Array.isArray(message)) {
          if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
            throw new Error(ERROR);
          }
        }
      } else {
        throw new Error(ERROR);
      }
      notString = true;
    }
    var code, index = 0, i, length = message.length, blocks = this.blocks;

    while (index < length) {
      if (this.hashed) {
        this.hashed = false;
        blocks[0] = this.block;
        blocks[16] = blocks[1] = blocks[2] = blocks[3] =
          blocks[4] = blocks[5] = blocks[6] = blocks[7] =
          blocks[8] = blocks[9] = blocks[10] = blocks[11] =
          blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      }

      if (notString) {
        for (i = this.start; index < length && i < 64; ++index) {
          blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
        }
      } else {
        for (i = this.start; index < length && i < 64; ++index) {
          code = message.charCodeAt(index);
          if (code < 0x80) {
            blocks[i >> 2] |= code << SHIFT[i++ & 3];
          } else if (code < 0x800) {
            blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
          } else if (code < 0xd800 || code >= 0xe000) {
            blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
          } else {
            code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
            blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
          }
        }
      }

      this.lastByteIndex = i;
      this.bytes += i - this.start;
      if (i >= 64) {
        this.block = blocks[16];
        this.start = i - 64;
        this.hash();
        this.hashed = true;
      } else {
        this.start = i;
      }
    }
    if (this.bytes > 4294967295) {
      this.hBytes += this.bytes / 4294967296 << 0;
      this.bytes = this.bytes % 4294967296;
    }
    return this;
  };

  Sha256.prototype.finalize = function () {
    if (this.finalized) {
      return;
    }
    this.finalized = true;
    var blocks = this.blocks, i = this.lastByteIndex;
    blocks[16] = this.block;
    blocks[i >> 2] |= EXTRA[i & 3];
    this.block = blocks[16];
    if (i >= 56) {
      if (!this.hashed) {
        this.hash();
      }
      blocks[0] = this.block;
      blocks[16] = blocks[1] = blocks[2] = blocks[3] =
        blocks[4] = blocks[5] = blocks[6] = blocks[7] =
        blocks[8] = blocks[9] = blocks[10] = blocks[11] =
        blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    }
    blocks[14] = this.hBytes << 3 | this.bytes >>> 29;
    blocks[15] = this.bytes << 3;
    this.hash();
  };

  Sha256.prototype.hash = function () {
    var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f = this.h5, g = this.h6,
      h = this.h7, blocks = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;

    for (j = 16; j < 64; ++j) {
      // rightrotate
      t1 = blocks[j - 15];
      s0 = ((t1 >>> 7) | (t1 << 25)) ^ ((t1 >>> 18) | (t1 << 14)) ^ (t1 >>> 3);
      t1 = blocks[j - 2];
      s1 = ((t1 >>> 17) | (t1 << 15)) ^ ((t1 >>> 19) | (t1 << 13)) ^ (t1 >>> 10);
      blocks[j] = blocks[j - 16] + s0 + blocks[j - 7] + s1 << 0;
    }

    bc = b & c;
    for (j = 0; j < 64; j += 4) {
      if (this.first) {
        if (this.is224) {
          ab = 300032;
          t1 = blocks[0] - 1413257819;
          h = t1 - 150054599 << 0;
          d = t1 + 24177077 << 0;
        } else {
          ab = 704751109;
          t1 = blocks[0] - 210244248;
          h = t1 - 1521486534 << 0;
          d = t1 + 143694565 << 0;
        }
        this.first = false;
      } else {
        s0 = ((a >>> 2) | (a << 30)) ^ ((a >>> 13) | (a << 19)) ^ ((a >>> 22) | (a << 10));
        s1 = ((e >>> 6) | (e << 26)) ^ ((e >>> 11) | (e << 21)) ^ ((e >>> 25) | (e << 7));
        ab = a & b;
        maj = ab ^ (a & c) ^ bc;
        ch = (e & f) ^ (~e & g);
        t1 = h + s1 + ch + K[j] + blocks[j];
        t2 = s0 + maj;
        h = d + t1 << 0;
        d = t1 + t2 << 0;
      }
      s0 = ((d >>> 2) | (d << 30)) ^ ((d >>> 13) | (d << 19)) ^ ((d >>> 22) | (d << 10));
      s1 = ((h >>> 6) | (h << 26)) ^ ((h >>> 11) | (h << 21)) ^ ((h >>> 25) | (h << 7));
      da = d & a;
      maj = da ^ (d & b) ^ ab;
      ch = (h & e) ^ (~h & f);
      t1 = g + s1 + ch + K[j + 1] + blocks[j + 1];
      t2 = s0 + maj;
      g = c + t1 << 0;
      c = t1 + t2 << 0;
      s0 = ((c >>> 2) | (c << 30)) ^ ((c >>> 13) | (c << 19)) ^ ((c >>> 22) | (c << 10));
      s1 = ((g >>> 6) | (g << 26)) ^ ((g >>> 11) | (g << 21)) ^ ((g >>> 25) | (g << 7));
      cd = c & d;
      maj = cd ^ (c & a) ^ da;
      ch = (g & h) ^ (~g & e);
      t1 = f + s1 + ch + K[j + 2] + blocks[j + 2];
      t2 = s0 + maj;
      f = b + t1 << 0;
      b = t1 + t2 << 0;
      s0 = ((b >>> 2) | (b << 30)) ^ ((b >>> 13) | (b << 19)) ^ ((b >>> 22) | (b << 10));
      s1 = ((f >>> 6) | (f << 26)) ^ ((f >>> 11) | (f << 21)) ^ ((f >>> 25) | (f << 7));
      bc = b & c;
      maj = bc ^ (b & d) ^ cd;
      ch = (f & g) ^ (~f & h);
      t1 = e + s1 + ch + K[j + 3] + blocks[j + 3];
      t2 = s0 + maj;
      e = a + t1 << 0;
      a = t1 + t2 << 0;
    }

    this.h0 = this.h0 + a << 0;
    this.h1 = this.h1 + b << 0;
    this.h2 = this.h2 + c << 0;
    this.h3 = this.h3 + d << 0;
    this.h4 = this.h4 + e << 0;
    this.h5 = this.h5 + f << 0;
    this.h6 = this.h6 + g << 0;
    this.h7 = this.h7 + h << 0;
  };

  Sha256.prototype.hex = function () {
    this.finalize();

    var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5,
      h6 = this.h6, h7 = this.h7;

    var hex = HEX_CHARS[(h0 >> 28) & 0x0F] + HEX_CHARS[(h0 >> 24) & 0x0F] +
      HEX_CHARS[(h0 >> 20) & 0x0F] + HEX_CHARS[(h0 >> 16) & 0x0F] +
      HEX_CHARS[(h0 >> 12) & 0x0F] + HEX_CHARS[(h0 >> 8) & 0x0F] +
      HEX_CHARS[(h0 >> 4) & 0x0F] + HEX_CHARS[h0 & 0x0F] +
      HEX_CHARS[(h1 >> 28) & 0x0F] + HEX_CHARS[(h1 >> 24) & 0x0F] +
      HEX_CHARS[(h1 >> 20) & 0x0F] + HEX_CHARS[(h1 >> 16) & 0x0F] +
      HEX_CHARS[(h1 >> 12) & 0x0F] + HEX_CHARS[(h1 >> 8) & 0x0F] +
      HEX_CHARS[(h1 >> 4) & 0x0F] + HEX_CHARS[h1 & 0x0F] +
      HEX_CHARS[(h2 >> 28) & 0x0F] + HEX_CHARS[(h2 >> 24) & 0x0F] +
      HEX_CHARS[(h2 >> 20) & 0x0F] + HEX_CHARS[(h2 >> 16) & 0x0F] +
      HEX_CHARS[(h2 >> 12) & 0x0F] + HEX_CHARS[(h2 >> 8) & 0x0F] +
      HEX_CHARS[(h2 >> 4) & 0x0F] + HEX_CHARS[h2 & 0x0F] +
      HEX_CHARS[(h3 >> 28) & 0x0F] + HEX_CHARS[(h3 >> 24) & 0x0F] +
      HEX_CHARS[(h3 >> 20) & 0x0F] + HEX_CHARS[(h3 >> 16) & 0x0F] +
      HEX_CHARS[(h3 >> 12) & 0x0F] + HEX_CHARS[(h3 >> 8) & 0x0F] +
      HEX_CHARS[(h3 >> 4) & 0x0F] + HEX_CHARS[h3 & 0x0F] +
      HEX_CHARS[(h4 >> 28) & 0x0F] + HEX_CHARS[(h4 >> 24) & 0x0F] +
      HEX_CHARS[(h4 >> 20) & 0x0F] + HEX_CHARS[(h4 >> 16) & 0x0F] +
      HEX_CHARS[(h4 >> 12) & 0x0F] + HEX_CHARS[(h4 >> 8) & 0x0F] +
      HEX_CHARS[(h4 >> 4) & 0x0F] + HEX_CHARS[h4 & 0x0F] +
      HEX_CHARS[(h5 >> 28) & 0x0F] + HEX_CHARS[(h5 >> 24) & 0x0F] +
      HEX_CHARS[(h5 >> 20) & 0x0F] + HEX_CHARS[(h5 >> 16) & 0x0F] +
      HEX_CHARS[(h5 >> 12) & 0x0F] + HEX_CHARS[(h5 >> 8) & 0x0F] +
      HEX_CHARS[(h5 >> 4) & 0x0F] + HEX_CHARS[h5 & 0x0F] +
      HEX_CHARS[(h6 >> 28) & 0x0F] + HEX_CHARS[(h6 >> 24) & 0x0F] +
      HEX_CHARS[(h6 >> 20) & 0x0F] + HEX_CHARS[(h6 >> 16) & 0x0F] +
      HEX_CHARS[(h6 >> 12) & 0x0F] + HEX_CHARS[(h6 >> 8) & 0x0F] +
      HEX_CHARS[(h6 >> 4) & 0x0F] + HEX_CHARS[h6 & 0x0F];
    if (!this.is224) {
      hex += HEX_CHARS[(h7 >> 28) & 0x0F] + HEX_CHARS[(h7 >> 24) & 0x0F] +
        HEX_CHARS[(h7 >> 20) & 0x0F] + HEX_CHARS[(h7 >> 16) & 0x0F] +
        HEX_CHARS[(h7 >> 12) & 0x0F] + HEX_CHARS[(h7 >> 8) & 0x0F] +
        HEX_CHARS[(h7 >> 4) & 0x0F] + HEX_CHARS[h7 & 0x0F];
    }
    return hex;
  };

  Sha256.prototype.toString = Sha256.prototype.hex;

  Sha256.prototype.digest = function () {
    this.finalize();

    var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5,
      h6 = this.h6, h7 = this.h7;

    var arr = [
      (h0 >> 24) & 0xFF, (h0 >> 16) & 0xFF, (h0 >> 8) & 0xFF, h0 & 0xFF,
      (h1 >> 24) & 0xFF, (h1 >> 16) & 0xFF, (h1 >> 8) & 0xFF, h1 & 0xFF,
      (h2 >> 24) & 0xFF, (h2 >> 16) & 0xFF, (h2 >> 8) & 0xFF, h2 & 0xFF,
      (h3 >> 24) & 0xFF, (h3 >> 16) & 0xFF, (h3 >> 8) & 0xFF, h3 & 0xFF,
      (h4 >> 24) & 0xFF, (h4 >> 16) & 0xFF, (h4 >> 8) & 0xFF, h4 & 0xFF,
      (h5 >> 24) & 0xFF, (h5 >> 16) & 0xFF, (h5 >> 8) & 0xFF, h5 & 0xFF,
      (h6 >> 24) & 0xFF, (h6 >> 16) & 0xFF, (h6 >> 8) & 0xFF, h6 & 0xFF
    ];
    if (!this.is224) {
      arr.push((h7 >> 24) & 0xFF, (h7 >> 16) & 0xFF, (h7 >> 8) & 0xFF, h7 & 0xFF);
    }
    return arr;
  };

  Sha256.prototype.array = Sha256.prototype.digest;

  Sha256.prototype.arrayBuffer = function () {
    this.finalize();

    var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
    var dataView = new DataView(buffer);
    dataView.setUint32(0, this.h0);
    dataView.setUint32(4, this.h1);
    dataView.setUint32(8, this.h2);
    dataView.setUint32(12, this.h3);
    dataView.setUint32(16, this.h4);
    dataView.setUint32(20, this.h5);
    dataView.setUint32(24, this.h6);
    if (!this.is224) {
      dataView.setUint32(28, this.h7);
    }
    return buffer;
  };

  function HmacSha256(key, is224, sharedMemory) {
    var i, type = typeof key;
    if (type === 'string') {
      var bytes = [], length = key.length, index = 0, code;
      for (i = 0; i < length; ++i) {
        code = key.charCodeAt(i);
        if (code < 0x80) {
          bytes[index++] = code;
        } else if (code < 0x800) {
          bytes[index++] = (0xc0 | (code >> 6));
          bytes[index++] = (0x80 | (code & 0x3f));
        } else if (code < 0xd800 || code >= 0xe000) {
          bytes[index++] = (0xe0 | (code >> 12));
          bytes[index++] = (0x80 | ((code >> 6) & 0x3f));
          bytes[index++] = (0x80 | (code & 0x3f));
        } else {
          code = 0x10000 + (((code & 0x3ff) << 10) | (key.charCodeAt(++i) & 0x3ff));
          bytes[index++] = (0xf0 | (code >> 18));
          bytes[index++] = (0x80 | ((code >> 12) & 0x3f));
          bytes[index++] = (0x80 | ((code >> 6) & 0x3f));
          bytes[index++] = (0x80 | (code & 0x3f));
        }
      }
      key = bytes;
    } else {
      if (type === 'object') {
        if (key === null) {
          throw new Error(ERROR);
        } else if (ARRAY_BUFFER && key.constructor === ArrayBuffer) {
          key = new Uint8Array(key);
        } else if (!Array.isArray(key)) {
          if (!ARRAY_BUFFER || !ArrayBuffer.isView(key)) {
            throw new Error(ERROR);
          }
        }
      } else {
        throw new Error(ERROR);
      }
    }

    if (key.length > 64) {
      key = (new Sha256(is224, true)).update(key).array();
    }

    var oKeyPad = [], iKeyPad = [];
    for (i = 0; i < 64; ++i) {
      var b = key[i] || 0;
      oKeyPad[i] = 0x5c ^ b;
      iKeyPad[i] = 0x36 ^ b;
    }

    Sha256.call(this, is224, sharedMemory);

    this.update(iKeyPad);
    this.oKeyPad = oKeyPad;
    this.inner = true;
    this.sharedMemory = sharedMemory;
  }
  HmacSha256.prototype = new Sha256();

  HmacSha256.prototype.finalize = function () {
    Sha256.prototype.finalize.call(this);
    if (this.inner) {
      this.inner = false;
      var innerHash = this.array();
      Sha256.call(this, this.is224, this.sharedMemory);
      this.update(this.oKeyPad);
      this.update(innerHash);
      Sha256.prototype.finalize.call(this);
    }
  };

  var exports = createMethod();
  exports.sha256 = exports;
  exports.sha224 = createMethod(true);
  exports.sha256.hmac = createHmacMethod();
  exports.sha224.hmac = createHmacMethod(true);

  if (COMMON_JS) {
    module.exports = exports;
  } else {
    root.sha256 = exports.sha256;
    root.sha224 = exports.sha224;
    if (AMD) {
      define(function () {
        return exports;
      });
    }
  }
})();

}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":45}],41:[function(require,module,exports){
require("capability/es5");

module.exports = require("./lib");
},{"./lib":44,"capability/es5":22}],42:[function(require,module,exports){
var Class = function () {
    var options = Object.create({
        Source: Object,
        config: {},
        buildArgs: []
    });

    function checkOption(option) {
        var key = "config";
        if (option instanceof Function)
            key = "Source";
        else if (option instanceof Array)
            key = "buildArgs";
        else if (option instanceof Object)
            key = "config";
        else
            throw new Error("Invalid configuration option.");
        if (options.hasOwnProperty(key))
            throw new Error("Duplicated configuration option: " + key + ".");
        options[key] = option;
    }

    for (var index = 0, length = arguments.length; index < length; ++index)
        checkOption(arguments[index]);

    var Source = options.Source,
        config = options.config,
        buildArgs = options.buildArgs;

    return (Source.extend || Class.extend).call(Source, config, buildArgs);
};

Class.factory = function () {
    var Source = this;
    return function () {
        var instance = this;
        if (instance.build instanceof Function)
            instance.build.apply(instance, arguments);
        if (instance.init instanceof Function)
            instance.init.apply(instance, arguments);
    };
};

Class.extend = function (config, buildArgs) {
    var Source = this;
    if (!config)
        config = {};
    var Subject;
    if ((config.prototype instanceof Object) && config.prototype.constructor !== Object)
        Subject = config.prototype.constructor;
    else if (config.factory instanceof Function)
        Subject = config.factory.call(Source);
    Subject = (Source.clone || Class.clone).call(Source, Subject, buildArgs);
    (Subject.merge || Class.merge).call(Subject, config);
    return Subject;
};

Class.prototype.extend = function (config, buildArgs) {
    var subject = this;
    var instance = (subject.clone || Class.prototype.clone).apply(subject, buildArgs);
    (instance.merge || Class.prototype.merge).call(instance, config);
    return instance;
};

Class.clone = function (Subject, buildArgs) {
    var Source = this;
    if (!(Subject instanceof Function))
        Subject = (Source.factory || Class.factory).call(Source);
    Subject.prototype = (Source.prototype.clone || Class.prototype.clone).apply(Source.prototype, buildArgs || []);
    Subject.prototype.constructor = Subject;
    for (var staticProperty in Source)
        if (staticProperty !== "prototype")
            Subject[staticProperty] = Source[staticProperty];
    return Subject;
};

Class.prototype.clone = function () {
    var subject = this;
    var instance = Object.create(subject);
    if (instance.build instanceof Function)
        instance.build.apply(instance, arguments);
    return instance;
};

Class.merge = function (config) {
    var Subject = this;
    for (var staticProperty in config)
        if (staticProperty !== "prototype")
            Subject[staticProperty] = config[staticProperty];
    if (config.prototype instanceof Object)
        (Subject.prototype.merge || Class.prototype.merge).call(Subject.prototype, config.prototype);
    return Subject;
};

Class.prototype.merge = function (config) {
    var subject = this;
    for (var property in config)
        if (property !== "constructor")
            subject[property] = config[property];
    return subject;
};

Class.absorb = function (config) {
    var Subject = this;
    for (var staticProperty in config)
        if (staticProperty !== "prototype" && (Subject[staticProperty] === undefined || Subject[staticProperty] === Function.prototype[staticProperty]))
            Subject[staticProperty] = config[staticProperty];
    if (config.prototype instanceof Object)
        (Subject.prototype.absorb || Class.prototype.absorb).call(Subject.prototype, config.prototype);
    return Subject;
};

Class.prototype.absorb = function (config) {
    var subject = this;
    for (var property in config)
        if (property !== "constructor" && (subject[property] === undefined || subject[property] === Object.prototype[property]))
            subject[property] = config[property];
    return subject;
};

Class.getAncestor = function () {
    var Source = this;
    if (Source !== Source.prototype.constructor)
        return Source.prototype.constructor;
};

Class.newInstance = function () {
    var Subject = this;
    var instance = Object.create(this.prototype);
    Subject.apply(instance, arguments);
    return instance;
};

module.exports = Class;
},{}],43:[function(require,module,exports){
module.exports = function () {
    throw new Error("Not implemented.");
};
},{}],44:[function(require,module,exports){
module.exports = {
    Class: require("./Class"),
    abstractMethod: require("./abstractMethod")
};
},{"./Class":42,"./abstractMethod":43}],45:[function(require,module,exports){
// shim for using process in browser
var process = module.exports = {};

// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
(function () {
    try {
        if (typeof setTimeout === 'function') {
            cachedSetTimeout = setTimeout;
        } else {
            cachedSetTimeout = defaultSetTimout;
        }
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === 'function') {
            cachedClearTimeout = clearTimeout;
        } else {
            cachedClearTimeout = defaultClearTimeout;
        }
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
} ())
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }

}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }

}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}

process.nextTick = function (fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
};

// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues
process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) { return [] }

process.binding = function (name) {
    throw new Error('process.binding is not supported');
};

process.cwd = function () { return '/' };
process.chdir = function (dir) {
    throw new Error('process.chdir is not supported');
};
process.umask = function() { return 0; };

},{}],46:[function(require,module,exports){
// minimal library entry point.

"use strict";
module.exports = require("./src/index-minimal");

},{"./src/index-minimal":47}],47:[function(require,module,exports){
"use strict";
var protobuf = exports;

/**
 * Build type, one of `"full"`, `"light"` or `"minimal"`.
 * @name build
 * @type {string}
 * @const
 */
protobuf.build = "minimal";

// Serialization
protobuf.Writer       = require("./writer");
protobuf.BufferWriter = require("./writer_buffer");
protobuf.Reader       = require("./reader");
protobuf.BufferReader = require("./reader_buffer");

// Utility
protobuf.util         = require("./util/minimal");
protobuf.rpc          = require("./rpc");
protobuf.roots        = require("./roots");
protobuf.configure    = configure;

/* istanbul ignore next */
/**
 * Reconfigures the library according to the environment.
 * @returns {undefined}
 */
function configure() {
    protobuf.Reader._configure(protobuf.BufferReader);
    protobuf.util._configure();
}

// Set up buffer utility according to the environment
protobuf.Writer._configure(protobuf.BufferWriter);
configure();

},{"./reader":48,"./reader_buffer":49,"./roots":50,"./rpc":51,"./util/minimal":54,"./writer":55,"./writer_buffer":56}],48:[function(require,module,exports){
"use strict";
module.exports = Reader;

var util      = require("./util/minimal");

var BufferReader; // cyclic

var LongBits  = util.LongBits,
    utf8      = util.utf8;

/* istanbul ignore next */
function indexOutOfRange(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader(buffer);
        throw Error("illegal buffer");
    };

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader.create = util.Buffer
    ? function create_buffer_setup(buffer) {
        return (Reader.create = function create_buffer(buffer) {
            return util.Buffer.isBuffer(buffer)
                ? new BufferReader(buffer)
                /* istanbul ignore next */
                : create_array(buffer);
        })(buffer);
    }
    /* istanbul ignore next */
    : create_array;

Reader.prototype._slice = util.Array.prototype.subarray || /* istanbul ignore next */ util.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 8);

    return new LongBits(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader._configure = function(BufferReader_) {
    BufferReader = BufferReader_;

    var fn = util.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util.merge(Reader.prototype, {

        int64: function read_int64() {
            return readLongVarint.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64.call(this)[fn](false);
        }

    });
};

},{"./util/minimal":54}],49:[function(require,module,exports){
"use strict";
module.exports = BufferReader;

// extends Reader
var Reader = require("./reader");
(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;

var util = require("./util/minimal");

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader(buffer) {
    Reader.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

/* istanbul ignore else */
if (util.Buffer)
    BufferReader.prototype._slice = util.Buffer.prototype.slice;

/**
 * @override
 */
BufferReader.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

},{"./reader":48,"./util/minimal":54}],50:[function(require,module,exports){
"use strict";
module.exports = {};

/**
 * Named roots.
 * This is where pbjs stores generated structures (the option `-r, --root` specifies a name).
 * Can also be used manually to make roots available accross modules.
 * @name roots
 * @type {Object.<string,Root>}
 * @example
 * // pbjs -r myroot -o compiled.js ...
 *
 * // in another module:
 * require("./compiled.js");
 *
 * // in any subsequent module:
 * var root = protobuf.roots["myroot"];
 */

},{}],51:[function(require,module,exports){
"use strict";

/**
 * Streaming RPC helpers.
 * @namespace
 */
var rpc = exports;

/**
 * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.
 * @typedef RPCImpl
 * @type {function}
 * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called
 * @param {Uint8Array} requestData Request data
 * @param {RPCImplCallback} callback Callback function
 * @returns {undefined}
 * @example
 * function rpcImpl(method, requestData, callback) {
 *     if (protobuf.util.lcFirst(method.name) !== "myMethod") // compatible with static code
 *         throw Error("no such method");
 *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {
 *         callback(err, responseData);
 *     });
 * }
 */

/**
 * Node-style callback as used by {@link RPCImpl}.
 * @typedef RPCImplCallback
 * @type {function}
 * @param {Error|null} error Error, if any, otherwise `null`
 * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error
 * @returns {undefined}
 */

rpc.Service = require("./rpc/service");

},{"./rpc/service":52}],52:[function(require,module,exports){
"use strict";
module.exports = Service;

var util = require("../util/minimal");

// Extends EventEmitter
(Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;

/**
 * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.
 *
 * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.
 * @typedef rpc.ServiceMethodCallback
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {Error|null} error Error, if any
 * @param {TRes} [response] Response message
 * @returns {undefined}
 */

/**
 * A service method part of a {@link rpc.Service} as created by {@link Service.create}.
 * @typedef rpc.ServiceMethod
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message
 * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`
 */

/**
 * Constructs a new RPC service instance.
 * @classdesc An RPC service as returned by {@link Service#create}.
 * @exports rpc.Service
 * @extends util.EventEmitter
 * @constructor
 * @param {RPCImpl} rpcImpl RPC implementation
 * @param {boolean} [requestDelimited=false] Whether requests are length-delimited
 * @param {boolean} [responseDelimited=false] Whether responses are length-delimited
 */
function Service(rpcImpl, requestDelimited, responseDelimited) {

    if (typeof rpcImpl !== "function")
        throw TypeError("rpcImpl must be a function");

    util.EventEmitter.call(this);

    /**
     * RPC implementation. Becomes `null` once the service is ended.
     * @type {RPCImpl|null}
     */
    this.rpcImpl = rpcImpl;

    /**
     * Whether requests are length-delimited.
     * @type {boolean}
     */
    this.requestDelimited = Boolean(requestDelimited);

    /**
     * Whether responses are length-delimited.
     * @type {boolean}
     */
    this.responseDelimited = Boolean(responseDelimited);
}

/**
 * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.
 * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method
 * @param {Constructor<TReq>} requestCtor Request constructor
 * @param {Constructor<TRes>} responseCtor Response constructor
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback
 * @returns {undefined}
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 */
Service.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {

    if (!request)
        throw TypeError("request must be specified");

    var self = this;
    if (!callback)
        return util.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);

    if (!self.rpcImpl) {
        setTimeout(function() { callback(Error("already ended")); }, 0);
        return undefined;
    }

    try {
        return self.rpcImpl(
            method,
            requestCtor[self.requestDelimited ? "encodeDelimited" : "encode"](request).finish(),
            function rpcCallback(err, response) {

                if (err) {
                    self.emit("error", err, method);
                    return callback(err);
                }

                if (response === null) {
                    self.end(/* endedByRPC */ true);
                    return undefined;
                }

                if (!(response instanceof responseCtor)) {
                    try {
                        response = responseCtor[self.responseDelimited ? "decodeDelimited" : "decode"](response);
                    } catch (err) {
                        self.emit("error", err, method);
                        return callback(err);
                    }
                }

                self.emit("data", response, method);
                return callback(null, response);
            }
        );
    } catch (err) {
        self.emit("error", err, method);
        setTimeout(function() { callback(err); }, 0);
        return undefined;
    }
};

/**
 * Ends this service and emits the `end` event.
 * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.
 * @returns {rpc.Service} `this`
 */
Service.prototype.end = function end(endedByRPC) {
    if (this.rpcImpl) {
        if (!endedByRPC) // signal end to rpcImpl
            this.rpcImpl(null, null, null);
        this.rpcImpl = null;
        this.emit("end").off();
    }
    return this;
};

},{"../util/minimal":54}],53:[function(require,module,exports){
"use strict";
module.exports = LongBits;

var util = require("../util/minimal");

/**
 * Constructs new long bits.
 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
 * @memberof util
 * @constructor
 * @param {number} lo Low 32 bits, unsigned
 * @param {number} hi High 32 bits, unsigned
 */
function LongBits(lo, hi) {

    // note that the casts below are theoretically unnecessary as of today, but older statically
    // generated converter code might still call the ctor with signed 32bits. kept for compat.

    /**
     * Low bits.
     * @type {number}
     */
    this.lo = lo >>> 0;

    /**
     * High bits.
     * @type {number}
     */
    this.hi = hi >>> 0;
}

/**
 * Zero bits.
 * @memberof util.LongBits
 * @type {util.LongBits}
 */
var zero = LongBits.zero = new LongBits(0, 0);

zero.toNumber = function() { return 0; };
zero.zzEncode = zero.zzDecode = function() { return this; };
zero.length = function() { return 1; };

/**
 * Zero hash.
 * @memberof util.LongBits
 * @type {string}
 */
var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

/**
 * Constructs new long bits from the specified number.
 * @param {number} value Value
 * @returns {util.LongBits} Instance
 */
LongBits.fromNumber = function fromNumber(value) {
    if (value === 0)
        return zero;
    var sign = value < 0;
    if (sign)
        value = -value;
    var lo = value >>> 0,
        hi = (value - lo) / 4294967296 >>> 0;
    if (sign) {
        hi = ~hi >>> 0;
        lo = ~lo >>> 0;
        if (++lo > 4294967295) {
            lo = 0;
            if (++hi > 4294967295)
                hi = 0;
        }
    }
    return new LongBits(lo, hi);
};

/**
 * Constructs new long bits from a number, long or string.
 * @param {Long|number|string} value Value
 * @returns {util.LongBits} Instance
 */
LongBits.from = function from(value) {
    if (typeof value === "number")
        return LongBits.fromNumber(value);
    if (util.isString(value)) {
        /* istanbul ignore else */
        if (util.Long)
            value = util.Long.fromString(value);
        else
            return LongBits.fromNumber(parseInt(value, 10));
    }
    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
};

/**
 * Converts this long bits to a possibly unsafe JavaScript number.
 * @param {boolean} [unsigned=false] Whether unsigned or not
 * @returns {number} Possibly unsafe number
 */
LongBits.prototype.toNumber = function toNumber(unsigned) {
    if (!unsigned && this.hi >>> 31) {
        var lo = ~this.lo + 1 >>> 0,
            hi = ~this.hi     >>> 0;
        if (!lo)
            hi = hi + 1 >>> 0;
        return -(lo + hi * 4294967296);
    }
    return this.lo + this.hi * 4294967296;
};

/**
 * Converts this long bits to a long.
 * @param {boolean} [unsigned=false] Whether unsigned or not
 * @returns {Long} Long
 */
LongBits.prototype.toLong = function toLong(unsigned) {
    return util.Long
        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
        /* istanbul ignore next */
        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
};

var charCodeAt = String.prototype.charCodeAt;

/**
 * Constructs new long bits from the specified 8 characters long hash.
 * @param {string} hash Hash
 * @returns {util.LongBits} Bits
 */
LongBits.fromHash = function fromHash(hash) {
    if (hash === zeroHash)
        return zero;
    return new LongBits(
        ( charCodeAt.call(hash, 0)
        | charCodeAt.call(hash, 1) << 8
        | charCodeAt.call(hash, 2) << 16
        | charCodeAt.call(hash, 3) << 24) >>> 0
    ,
        ( charCodeAt.call(hash, 4)
        | charCodeAt.call(hash, 5) << 8
        | charCodeAt.call(hash, 6) << 16
        | charCodeAt.call(hash, 7) << 24) >>> 0
    );
};

/**
 * Converts this long bits to a 8 characters long hash.
 * @returns {string} Hash
 */
LongBits.prototype.toHash = function toHash() {
    return String.fromCharCode(
        this.lo        & 255,
        this.lo >>> 8  & 255,
        this.lo >>> 16 & 255,
        this.lo >>> 24      ,
        this.hi        & 255,
        this.hi >>> 8  & 255,
        this.hi >>> 16 & 255,
        this.hi >>> 24
    );
};

/**
 * Zig-zag encodes this long bits.
 * @returns {util.LongBits} `this`
 */
LongBits.prototype.zzEncode = function zzEncode() {
    var mask =   this.hi >> 31;
    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
    return this;
};

/**
 * Zig-zag decodes this long bits.
 * @returns {util.LongBits} `this`
 */
LongBits.prototype.zzDecode = function zzDecode() {
    var mask = -(this.lo & 1);
    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
    return this;
};

/**
 * Calculates the length of this longbits when encoded as a varint.
 * @returns {number} Length
 */
LongBits.prototype.length = function length() {
    var part0 =  this.lo,
        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
        part2 =  this.hi >>> 24;
    return part2 === 0
         ? part1 === 0
           ? part0 < 16384
             ? part0 < 128 ? 1 : 2
             : part0 < 2097152 ? 3 : 4
           : part1 < 16384
             ? part1 < 128 ? 5 : 6
             : part1 < 2097152 ? 7 : 8
         : part2 < 128 ? 9 : 10;
};

},{"../util/minimal":54}],54:[function(require,module,exports){
(function (global){
"use strict";
var util = exports;

// used to return a Promise where callback is omitted
util.asPromise = require("@protobufjs/aspromise");

// converts to / from base64 encoded strings
util.base64 = require("@protobufjs/base64");

// base class of rpc.Service
util.EventEmitter = require("@protobufjs/eventemitter");

// float handling accross browsers
util.float = require("@protobufjs/float");

// requires modules optionally and hides the call from bundlers
util.inquire = require("@protobufjs/inquire");

// converts to / from utf8 encoded strings
util.utf8 = require("@protobufjs/utf8");

// provides a node-like buffer pool in the browser
util.pool = require("@protobufjs/pool");

// utility to work with the low and high bits of a 64 bit value
util.LongBits = require("./longbits");

// global object reference
util.global = typeof window !== "undefined" && window
           || typeof global !== "undefined" && global
           || typeof self   !== "undefined" && self
           || this; // eslint-disable-line no-invalid-this

/**
 * An immuable empty array.
 * @memberof util
 * @type {Array.<*>}
 * @const
 */
util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

/**
 * An immutable empty object.
 * @type {Object}
 * @const
 */
util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

/**
 * Whether running within node or not.
 * @memberof util
 * @type {boolean}
 * @const
 */
util.isNode = Boolean(util.global.process && util.global.process.versions && util.global.process.versions.node);

/**
 * Tests if the specified value is an integer.
 * @function
 * @param {*} value Value to test
 * @returns {boolean} `true` if the value is an integer
 */
util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
};

/**
 * Tests if the specified value is a string.
 * @param {*} value Value to test
 * @returns {boolean} `true` if the value is a string
 */
util.isString = function isString(value) {
    return typeof value === "string" || value instanceof String;
};

/**
 * Tests if the specified value is a non-null object.
 * @param {*} value Value to test
 * @returns {boolean} `true` if the value is a non-null object
 */
util.isObject = function isObject(value) {
    return value && typeof value === "object";
};

/**
 * Checks if a property on a message is considered to be present.
 * This is an alias of {@link util.isSet}.
 * @function
 * @param {Object} obj Plain object or message instance
 * @param {string} prop Property name
 * @returns {boolean} `true` if considered to be present, otherwise `false`
 */
util.isset =

/**
 * Checks if a property on a message is considered to be present.
 * @param {Object} obj Plain object or message instance
 * @param {string} prop Property name
 * @returns {boolean} `true` if considered to be present, otherwise `false`
 */
util.isSet = function isSet(obj, prop) {
    var value = obj[prop];
    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
    return false;
};

/**
 * Any compatible Buffer instance.
 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
 * @interface Buffer
 * @extends Uint8Array
 */

/**
 * Node's Buffer class if available.
 * @type {Constructor<Buffer>}
 */
util.Buffer = (function() {
    try {
        var Buffer = util.inquire("buffer").Buffer;
        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
    } catch (e) {
        /* istanbul ignore next */
        return null;
    }
})();

// Internal alias of or polyfull for Buffer.from.
util._Buffer_from = null;

// Internal alias of or polyfill for Buffer.allocUnsafe.
util._Buffer_allocUnsafe = null;

/**
 * Creates a new buffer of whatever type supported by the environment.
 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
 * @returns {Uint8Array|Buffer} Buffer
 */
util.newBuffer = function newBuffer(sizeOrArray) {
    /* istanbul ignore next */
    return typeof sizeOrArray === "number"
        ? util.Buffer
            ? util._Buffer_allocUnsafe(sizeOrArray)
            : new util.Array(sizeOrArray)
        : util.Buffer
            ? util._Buffer_from(sizeOrArray)
            : typeof Uint8Array === "undefined"
                ? sizeOrArray
                : new Uint8Array(sizeOrArray);
};

/**
 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
 * @type {Constructor<Uint8Array>}
 */
util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

/**
 * Any compatible Long instance.
 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
 * @interface Long
 * @property {number} low Low bits
 * @property {number} high High bits
 * @property {boolean} unsigned Whether unsigned or not
 */

/**
 * Long.js's Long class if available.
 * @type {Constructor<Long>}
 */
util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
         || /* istanbul ignore next */ util.global.Long
         || util.inquire("long");

/**
 * Regular expression used to verify 2 bit (`bool`) map keys.
 * @type {RegExp}
 * @const
 */
util.key2Re = /^true|false|0|1$/;

/**
 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
 * @type {RegExp}
 * @const
 */
util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

/**
 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
 * @type {RegExp}
 * @const
 */
util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

/**
 * Converts a number or long to an 8 characters long hash string.
 * @param {Long|number} value Value to convert
 * @returns {string} Hash
 */
util.longToHash = function longToHash(value) {
    return value
        ? util.LongBits.from(value).toHash()
        : util.LongBits.zeroHash;
};

/**
 * Converts an 8 characters long hash string to a long or number.
 * @param {string} hash Hash
 * @param {boolean} [unsigned=false] Whether unsigned or not
 * @returns {Long|number} Original value
 */
util.longFromHash = function longFromHash(hash, unsigned) {
    var bits = util.LongBits.fromHash(hash);
    if (util.Long)
        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
    return bits.toNumber(Boolean(unsigned));
};

/**
 * Merges the properties of the source object into the destination object.
 * @memberof util
 * @param {Object.<string,*>} dst Destination object
 * @param {Object.<string,*>} src Source object
 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
 * @returns {Object.<string,*>} Destination object
 */
function merge(dst, src, ifNotSet) { // used by converters
    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
        if (dst[keys[i]] === undefined || !ifNotSet)
            dst[keys[i]] = src[keys[i]];
    return dst;
}

util.merge = merge;

/**
 * Converts the first character of a string to lower case.
 * @param {string} str String to convert
 * @returns {string} Converted string
 */
util.lcFirst = function lcFirst(str) {
    return str.charAt(0).toLowerCase() + str.substring(1);
};

/**
 * Creates a custom error constructor.
 * @memberof util
 * @param {string} name Error name
 * @returns {Constructor<Error>} Custom error constructor
 */
function newError(name) {

    function CustomError(message, properties) {

        if (!(this instanceof CustomError))
            return new CustomError(message, properties);

        // Error.call(this, message);
        // ^ just returns a new error instance because the ctor can be called as a function

        Object.defineProperty(this, "message", { get: function() { return message; } });

        /* istanbul ignore next */
        if (Error.captureStackTrace) // node
            Error.captureStackTrace(this, CustomError);
        else
            Object.defineProperty(this, "stack", { value: (new Error()).stack || "" });

        if (properties)
            merge(this, properties);
    }

    (CustomError.prototype = Object.create(Error.prototype)).constructor = CustomError;

    Object.defineProperty(CustomError.prototype, "name", { get: function() { return name; } });

    CustomError.prototype.toString = function toString() {
        return this.name + ": " + this.message;
    };

    return CustomError;
}

util.newError = newError;

/**
 * Constructs a new protocol error.
 * @classdesc Error subclass indicating a protocol specifc error.
 * @memberof util
 * @extends Error
 * @template T extends Message<T>
 * @constructor
 * @param {string} message Error message
 * @param {Object.<string,*>} [properties] Additional properties
 * @example
 * try {
 *     MyMessage.decode(someBuffer); // throws if required fields are missing
 * } catch (e) {
 *     if (e instanceof ProtocolError && e.instance)
 *         console.log("decoded so far: " + JSON.stringify(e.instance));
 * }
 */
util.ProtocolError = newError("ProtocolError");

/**
 * So far decoded message instance.
 * @name util.ProtocolError#instance
 * @type {Message<T>}
 */

/**
 * A OneOf getter as returned by {@link util.oneOfGetter}.
 * @typedef OneOfGetter
 * @type {function}
 * @returns {string|undefined} Set field name, if any
 */

/**
 * Builds a getter for a oneof's present field name.
 * @param {string[]} fieldNames Field names
 * @returns {OneOfGetter} Unbound getter
 */
util.oneOfGetter = function getOneOf(fieldNames) {
    var fieldMap = {};
    for (var i = 0; i < fieldNames.length; ++i)
        fieldMap[fieldNames[i]] = 1;

    /**
     * @returns {string|undefined} Set field name, if any
     * @this Object
     * @ignore
     */
    return function() { // eslint-disable-line consistent-return
        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
                return keys[i];
    };
};

/**
 * A OneOf setter as returned by {@link util.oneOfSetter}.
 * @typedef OneOfSetter
 * @type {function}
 * @param {string|undefined} value Field name
 * @returns {undefined}
 */

/**
 * Builds a setter for a oneof's present field name.
 * @param {string[]} fieldNames Field names
 * @returns {OneOfSetter} Unbound setter
 */
util.oneOfSetter = function setOneOf(fieldNames) {

    /**
     * @param {string} name Field name
     * @returns {undefined}
     * @this Object
     * @ignore
     */
    return function(name) {
        for (var i = 0; i < fieldNames.length; ++i)
            if (fieldNames[i] !== name)
                delete this[fieldNames[i]];
    };
};

/**
 * Default conversion options used for {@link Message#toJSON} implementations.
 *
 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
 *
 * - Longs become strings
 * - Enums become string keys
 * - Bytes become base64 encoded strings
 * - (Sub-)Messages become plain objects
 * - Maps become plain objects with all string keys
 * - Repeated fields become arrays
 * - NaN and Infinity for float and double fields become strings
 *
 * @type {IConversionOptions}
 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
 */
util.toJSONOptions = {
    longs: String,
    enums: String,
    bytes: String,
    json: true
};

// Sets up buffer utility according to the environment (called in index-minimal)
util._configure = function() {
    var Buffer = util.Buffer;
    /* istanbul ignore if */
    if (!Buffer) {
        util._Buffer_from = util._Buffer_allocUnsafe = null;
        return;
    }
    // because node 4.x buffers are incompatible & immutable
    // see: https://github.com/dcodeIO/protobuf.js/pull/665
    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
        /* istanbul ignore next */
        function Buffer_from(value, encoding) {
            return new Buffer(value, encoding);
        };
    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
        /* istanbul ignore next */
        function Buffer_allocUnsafe(size) {
            return new Buffer(size);
        };
};

}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"./longbits":53,"@protobufjs/aspromise":9,"@protobufjs/base64":10,"@protobufjs/eventemitter":11,"@protobufjs/float":12,"@protobufjs/inquire":13,"@protobufjs/pool":14,"@protobufjs/utf8":15}],55:[function(require,module,exports){
"use strict";
module.exports = Writer;

var util      = require("./util/minimal");

var BufferWriter; // cyclic

var LongBits  = util.LongBits,
    base64    = util.base64,
    utf8      = util.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op(noop, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer.create = util.Buffer
    ? function create_buffer_setup() {
        return (Writer.create = function create_buffer() {
            return new BufferWriter();
        })();
    }
    /* istanbul ignore next */
    : function create_array() {
        return new Writer();
    };

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer.alloc = function alloc(size) {
    return new util.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util.Array !== Array)
    Writer.alloc = util.pool(Writer.alloc, util.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op(fn, len, val);
    this.len += len;
    return this;
};

function writeByte(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp.prototype = Object.create(Op.prototype);
VarintOp.prototype.fn = writeVarint32;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits.from(value);
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer.prototype.int64 = Writer.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits.from(value).zzEncode();
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.bool = function write_bool(value) {
    return this._push(writeByte, 1, value ? 1 : 0);
};

function writeFixed32(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.sfixed32 = Writer.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits.from(value);
    return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer.prototype.sfixed64 = Writer.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.float = function write_float(value) {
    return this._push(util.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.double = function write_double(value) {
    return this._push(util.float.writeDoubleLE, 8, value);
};

var writeBytes = util.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte, 1, 0);
    if (util.isString(value)) {
        var buf = Writer.alloc(len = base64.length(value));
        base64.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer.prototype.string = function write_string(value) {
    var len = utf8.length(value);
    return len
        ? this.uint32(len)._push(utf8.write, len, value)
        : this._push(writeByte, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer.prototype.fork = function fork() {
    this.states = new State(this);
    this.head = this.tail = new Op(noop, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op(noop, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer._configure = function(BufferWriter_) {
    BufferWriter = BufferWriter_;
};

},{"./util/minimal":54}],56:[function(require,module,exports){
"use strict";
module.exports = BufferWriter;

// extends Writer
var Writer = require("./writer");
(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;

var util = require("./util/minimal");

var Buffer = util.Buffer;

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter() {
    Writer.call(this);
}

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Buffer} Buffer
 */
BufferWriter.alloc = function alloc_buffer(size) {
    return (BufferWriter.alloc = util._Buffer_allocUnsafe)(size);
};

var writeBytesBuffer = Buffer && Buffer.prototype instanceof Uint8Array && Buffer.prototype.set.name === "set"
    ? function writeBytesBuffer_set(val, buf, pos) {
        buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
                           // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytesBuffer_copy(val, buf, pos) {
        if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
        else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
    };

/**
 * @override
 */
BufferWriter.prototype.bytes = function write_bytes_buffer(value) {
    if (util.isString(value))
        value = util._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util.utf8.write(val, buf, pos);
    else
        buf.utf8Write(val, pos);
}

/**
 * @override
 */
BufferWriter.prototype.string = function write_string_buffer(value) {
    var len = Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer, len, value);
    return this;
};

/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

},{"./util/minimal":54,"./writer":55}],57:[function(require,module,exports){
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},{"buffer":21}],58:[function(require,module,exports){
module.exports = Object.setPrototypeOf || ({__proto__:[]} instanceof Array ? setProtoOf : mixinProperties);

function setProtoOf(obj, proto) {
	obj.__proto__ = proto;
	return obj;
}

function mixinProperties(obj, proto) {
	for (var prop in proto) {
		if (!obj.hasOwnProperty(prop)) {
			obj[prop] = proto[prop];
		}
	}
	return obj;
}

},{}],59:[function(require,module,exports){
module.exports={
  "100": "Continue",
  "101": "Switching Protocols",
  "102": "Processing",
  "103": "Early Hints",
  "200": "OK",
  "201": "Created",
  "202": "Accepted",
  "203": "Non-Authoritative Information",
  "204": "No Content",
  "205": "Reset Content",
  "206": "Partial Content",
  "207": "Multi-Status",
  "208": "Already Reported",
  "226": "IM Used",
  "300": "Multiple Choices",
  "301": "Moved Permanently",
  "302": "Found",
  "303": "See Other",
  "304": "Not Modified",
  "305": "Use Proxy",
  "306": "(Unused)",
  "307": "Temporary Redirect",
  "308": "Permanent Redirect",
  "400": "Bad Request",
  "401": "Unauthorized",
  "402": "Payment Required",
  "403": "Forbidden",
  "404": "Not Found",
  "405": "Method Not Allowed",
  "406": "Not Acceptable",
  "407": "Proxy Authentication Required",
  "408": "Request Timeout",
  "409": "Conflict",
  "410": "Gone",
  "411": "Length Required",
  "412": "Precondition Failed",
  "413": "Payload Too Large",
  "414": "URI Too Long",
  "415": "Unsupported Media Type",
  "416": "Range Not Satisfiable",
  "417": "Expectation Failed",
  "418": "I'm a teapot",
  "421": "Misdirected Request",
  "422": "Unprocessable Entity",
  "423": "Locked",
  "424": "Failed Dependency",
  "425": "Unordered Collection",
  "426": "Upgrade Required",
  "428": "Precondition Required",
  "429": "Too Many Requests",
  "431": "Request Header Fields Too Large",
  "451": "Unavailable For Legal Reasons",
  "500": "Internal Server Error",
  "501": "Not Implemented",
  "502": "Bad Gateway",
  "503": "Service Unavailable",
  "504": "Gateway Timeout",
  "505": "HTTP Version Not Supported",
  "506": "Variant Also Negotiates",
  "507": "Insufficient Storage",
  "508": "Loop Detected",
  "509": "Bandwidth Limit Exceeded",
  "510": "Not Extended",
  "511": "Network Authentication Required"
}

},{}],60:[function(require,module,exports){
/*!
 * statuses
 * Copyright(c) 2014 Jonathan Ong
 * Copyright(c) 2016 Douglas Christopher Wilson
 * MIT Licensed
 */

'use strict'

/**
 * Module dependencies.
 * @private
 */

var codes = require('./codes.json')

/**
 * Module exports.
 * @public
 */

module.exports = status

// status code to message map
status.STATUS_CODES = codes

// array of status codes
status.codes = populateStatusesMap(status, codes)

// status codes for redirects
status.redirect = {
  300: true,
  301: true,
  302: true,
  303: true,
  305: true,
  307: true,
  308: true
}

// status codes for empty bodies
status.empty = {
  204: true,
  205: true,
  304: true
}

// status codes for when you should retry the request
status.retry = {
  502: true,
  503: true,
  504: true
}

/**
 * Populate the statuses map for given codes.
 * @private
 */

function populateStatusesMap (statuses, codes) {
  var arr = []

  Object.keys(codes).forEach(function forEachCode (code) {
    var message = codes[code]
    var status = Number(code)

    // Populate properties
    statuses[status] = message
    statuses[message] = status
    statuses[message.toLowerCase()] = status

    // Add to array
    arr.push(status)
  })

  return arr
}

/**
 * Get the status code.
 *
 * Given a number, this will throw if it is not a known status
 * code, otherwise the code will be returned. Given a string,
 * the string will be parsed for a number and return the code
 * if valid, otherwise will lookup the code assuming this is
 * the status message.
 *
 * @param {string|number} code
 * @returns {number}
 * @public
 */

function status (code) {
  if (typeof code === 'number') {
    if (!status[code]) throw new Error('invalid status code: ' + code)
    return code
  }

  if (typeof code !== 'string') {
    throw new TypeError('code must be a number or string')
  }

  // '403'
  var n = parseInt(code, 10)
  if (!isNaN(n)) {
    if (!status[n]) throw new Error('invalid status code: ' + n)
    return n
  }

  n = status[code.toLowerCase()]
  if (!n) throw new Error('invalid status message: "' + code + '"')
  return n
}

},{"./codes.json":59}],61:[function(require,module,exports){
/*!
 * toidentifier
 * Copyright(c) 2016 Douglas Christopher Wilson
 * MIT Licensed
 */

/**
 * Module exports.
 * @public
 */

module.exports = toIdentifier

/**
 * Trasform the given string into a JavaScript identifier
 *
 * @param {string} str
 * @returns {string}
 * @public
 */

function toIdentifier (str) {
  return str
    .split(' ')
    .map(function (token) {
      return token.slice(0, 1).toUpperCase() + token.slice(1)
    })
    .join('')
    .replace(/[^ _0-9a-z]/gi, '')
}

},{}],62:[function(require,module,exports){
(function(nacl) {
'use strict';

// Ported in 2014 by Dmitry Chestnykh and Devi Mandiri.
// Public domain.
//
// Implementation derived from TweetNaCl version 20140427.
// See for details: http://tweetnacl.cr.yp.to/

var gf = function(init) {
  var i, r = new Float64Array(16);
  if (init) for (i = 0; i < init.length; i++) r[i] = init[i];
  return r;
};

//  Pluggable, initialized in high-level API below.
var randombytes = function(/* x, n */) { throw new Error('no PRNG'); };

var _0 = new Uint8Array(16);
var _9 = new Uint8Array(32); _9[0] = 9;

var gf0 = gf(),
    gf1 = gf([1]),
    _121665 = gf([0xdb41, 1]),
    D = gf([0x78a3, 0x1359, 0x4dca, 0x75eb, 0xd8ab, 0x4141, 0x0a4d, 0x0070, 0xe898, 0x7779, 0x4079, 0x8cc7, 0xfe73, 0x2b6f, 0x6cee, 0x5203]),
    D2 = gf([0xf159, 0x26b2, 0x9b94, 0xebd6, 0xb156, 0x8283, 0x149a, 0x00e0, 0xd130, 0xeef3, 0x80f2, 0x198e, 0xfce7, 0x56df, 0xd9dc, 0x2406]),
    X = gf([0xd51a, 0x8f25, 0x2d60, 0xc956, 0xa7b2, 0x9525, 0xc760, 0x692c, 0xdc5c, 0xfdd6, 0xe231, 0xc0a4, 0x53fe, 0xcd6e, 0x36d3, 0x2169]),
    Y = gf([0x6658, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666]),
    I = gf([0xa0b0, 0x4a0e, 0x1b27, 0xc4ee, 0xe478, 0xad2f, 0x1806, 0x2f43, 0xd7a7, 0x3dfb, 0x0099, 0x2b4d, 0xdf0b, 0x4fc1, 0x2480, 0x2b83]);

function ts64(x, i, h, l) {
  x[i]   = (h >> 24) & 0xff;
  x[i+1] = (h >> 16) & 0xff;
  x[i+2] = (h >>  8) & 0xff;
  x[i+3] = h & 0xff;
  x[i+4] = (l >> 24)  & 0xff;
  x[i+5] = (l >> 16)  & 0xff;
  x[i+6] = (l >>  8)  & 0xff;
  x[i+7] = l & 0xff;
}

function vn(x, xi, y, yi, n) {
  var i,d = 0;
  for (i = 0; i < n; i++) d |= x[xi+i]^y[yi+i];
  return (1 & ((d - 1) >>> 8)) - 1;
}

function crypto_verify_16(x, xi, y, yi) {
  return vn(x,xi,y,yi,16);
}

function crypto_verify_32(x, xi, y, yi) {
  return vn(x,xi,y,yi,32);
}

function core_salsa20(o, p, k, c) {
  var j0  = c[ 0] & 0xff | (c[ 1] & 0xff)<<8 | (c[ 2] & 0xff)<<16 | (c[ 3] & 0xff)<<24,
      j1  = k[ 0] & 0xff | (k[ 1] & 0xff)<<8 | (k[ 2] & 0xff)<<16 | (k[ 3] & 0xff)<<24,
      j2  = k[ 4] & 0xff | (k[ 5] & 0xff)<<8 | (k[ 6] & 0xff)<<16 | (k[ 7] & 0xff)<<24,
      j3  = k[ 8] & 0xff | (k[ 9] & 0xff)<<8 | (k[10] & 0xff)<<16 | (k[11] & 0xff)<<24,
      j4  = k[12] & 0xff | (k[13] & 0xff)<<8 | (k[14] & 0xff)<<16 | (k[15] & 0xff)<<24,
      j5  = c[ 4] & 0xff | (c[ 5] & 0xff)<<8 | (c[ 6] & 0xff)<<16 | (c[ 7] & 0xff)<<24,
      j6  = p[ 0] & 0xff | (p[ 1] & 0xff)<<8 | (p[ 2] & 0xff)<<16 | (p[ 3] & 0xff)<<24,
      j7  = p[ 4] & 0xff | (p[ 5] & 0xff)<<8 | (p[ 6] & 0xff)<<16 | (p[ 7] & 0xff)<<24,
      j8  = p[ 8] & 0xff | (p[ 9] & 0xff)<<8 | (p[10] & 0xff)<<16 | (p[11] & 0xff)<<24,
      j9  = p[12] & 0xff | (p[13] & 0xff)<<8 | (p[14] & 0xff)<<16 | (p[15] & 0xff)<<24,
      j10 = c[ 8] & 0xff | (c[ 9] & 0xff)<<8 | (c[10] & 0xff)<<16 | (c[11] & 0xff)<<24,
      j11 = k[16] & 0xff | (k[17] & 0xff)<<8 | (k[18] & 0xff)<<16 | (k[19] & 0xff)<<24,
      j12 = k[20] & 0xff | (k[21] & 0xff)<<8 | (k[22] & 0xff)<<16 | (k[23] & 0xff)<<24,
      j13 = k[24] & 0xff | (k[25] & 0xff)<<8 | (k[26] & 0xff)<<16 | (k[27] & 0xff)<<24,
      j14 = k[28] & 0xff | (k[29] & 0xff)<<8 | (k[30] & 0xff)<<16 | (k[31] & 0xff)<<24,
      j15 = c[12] & 0xff | (c[13] & 0xff)<<8 | (c[14] & 0xff)<<16 | (c[15] & 0xff)<<24;

  var x0 = j0, x1 = j1, x2 = j2, x3 = j3, x4 = j4, x5 = j5, x6 = j6, x7 = j7,
      x8 = j8, x9 = j9, x10 = j10, x11 = j11, x12 = j12, x13 = j13, x14 = j14,
      x15 = j15, u;

  for (var i = 0; i < 20; i += 2) {
    u = x0 + x12 | 0;
    x4 ^= u<<7 | u>>>(32-7);
    u = x4 + x0 | 0;
    x8 ^= u<<9 | u>>>(32-9);
    u = x8 + x4 | 0;
    x12 ^= u<<13 | u>>>(32-13);
    u = x12 + x8 | 0;
    x0 ^= u<<18 | u>>>(32-18);

    u = x5 + x1 | 0;
    x9 ^= u<<7 | u>>>(32-7);
    u = x9 + x5 | 0;
    x13 ^= u<<9 | u>>>(32-9);
    u = x13 + x9 | 0;
    x1 ^= u<<13 | u>>>(32-13);
    u = x1 + x13 | 0;
    x5 ^= u<<18 | u>>>(32-18);

    u = x10 + x6 | 0;
    x14 ^= u<<7 | u>>>(32-7);
    u = x14 + x10 | 0;
    x2 ^= u<<9 | u>>>(32-9);
    u = x2 + x14 | 0;
    x6 ^= u<<13 | u>>>(32-13);
    u = x6 + x2 | 0;
    x10 ^= u<<18 | u>>>(32-18);

    u = x15 + x11 | 0;
    x3 ^= u<<7 | u>>>(32-7);
    u = x3 + x15 | 0;
    x7 ^= u<<9 | u>>>(32-9);
    u = x7 + x3 | 0;
    x11 ^= u<<13 | u>>>(32-13);
    u = x11 + x7 | 0;
    x15 ^= u<<18 | u>>>(32-18);

    u = x0 + x3 | 0;
    x1 ^= u<<7 | u>>>(32-7);
    u = x1 + x0 | 0;
    x2 ^= u<<9 | u>>>(32-9);
    u = x2 + x1 | 0;
    x3 ^= u<<13 | u>>>(32-13);
    u = x3 + x2 | 0;
    x0 ^= u<<18 | u>>>(32-18);

    u = x5 + x4 | 0;
    x6 ^= u<<7 | u>>>(32-7);
    u = x6 + x5 | 0;
    x7 ^= u<<9 | u>>>(32-9);
    u = x7 + x6 | 0;
    x4 ^= u<<13 | u>>>(32-13);
    u = x4 + x7 | 0;
    x5 ^= u<<18 | u>>>(32-18);

    u = x10 + x9 | 0;
    x11 ^= u<<7 | u>>>(32-7);
    u = x11 + x10 | 0;
    x8 ^= u<<9 | u>>>(32-9);
    u = x8 + x11 | 0;
    x9 ^= u<<13 | u>>>(32-13);
    u = x9 + x8 | 0;
    x10 ^= u<<18 | u>>>(32-18);

    u = x15 + x14 | 0;
    x12 ^= u<<7 | u>>>(32-7);
    u = x12 + x15 | 0;
    x13 ^= u<<9 | u>>>(32-9);
    u = x13 + x12 | 0;
    x14 ^= u<<13 | u>>>(32-13);
    u = x14 + x13 | 0;
    x15 ^= u<<18 | u>>>(32-18);
  }
   x0 =  x0 +  j0 | 0;
   x1 =  x1 +  j1 | 0;
   x2 =  x2 +  j2 | 0;
   x3 =  x3 +  j3 | 0;
   x4 =  x4 +  j4 | 0;
   x5 =  x5 +  j5 | 0;
   x6 =  x6 +  j6 | 0;
   x7 =  x7 +  j7 | 0;
   x8 =  x8 +  j8 | 0;
   x9 =  x9 +  j9 | 0;
  x10 = x10 + j10 | 0;
  x11 = x11 + j11 | 0;
  x12 = x12 + j12 | 0;
  x13 = x13 + j13 | 0;
  x14 = x14 + j14 | 0;
  x15 = x15 + j15 | 0;

  o[ 0] = x0 >>>  0 & 0xff;
  o[ 1] = x0 >>>  8 & 0xff;
  o[ 2] = x0 >>> 16 & 0xff;
  o[ 3] = x0 >>> 24 & 0xff;

  o[ 4] = x1 >>>  0 & 0xff;
  o[ 5] = x1 >>>  8 & 0xff;
  o[ 6] = x1 >>> 16 & 0xff;
  o[ 7] = x1 >>> 24 & 0xff;

  o[ 8] = x2 >>>  0 & 0xff;
  o[ 9] = x2 >>>  8 & 0xff;
  o[10] = x2 >>> 16 & 0xff;
  o[11] = x2 >>> 24 & 0xff;

  o[12] = x3 >>>  0 & 0xff;
  o[13] = x3 >>>  8 & 0xff;
  o[14] = x3 >>> 16 & 0xff;
  o[15] = x3 >>> 24 & 0xff;

  o[16] = x4 >>>  0 & 0xff;
  o[17] = x4 >>>  8 & 0xff;
  o[18] = x4 >>> 16 & 0xff;
  o[19] = x4 >>> 24 & 0xff;

  o[20] = x5 >>>  0 & 0xff;
  o[21] = x5 >>>  8 & 0xff;
  o[22] = x5 >>> 16 & 0xff;
  o[23] = x5 >>> 24 & 0xff;

  o[24] = x6 >>>  0 & 0xff;
  o[25] = x6 >>>  8 & 0xff;
  o[26] = x6 >>> 16 & 0xff;
  o[27] = x6 >>> 24 & 0xff;

  o[28] = x7 >>>  0 & 0xff;
  o[29] = x7 >>>  8 & 0xff;
  o[30] = x7 >>> 16 & 0xff;
  o[31] = x7 >>> 24 & 0xff;

  o[32] = x8 >>>  0 & 0xff;
  o[33] = x8 >>>  8 & 0xff;
  o[34] = x8 >>> 16 & 0xff;
  o[35] = x8 >>> 24 & 0xff;

  o[36] = x9 >>>  0 & 0xff;
  o[37] = x9 >>>  8 & 0xff;
  o[38] = x9 >>> 16 & 0xff;
  o[39] = x9 >>> 24 & 0xff;

  o[40] = x10 >>>  0 & 0xff;
  o[41] = x10 >>>  8 & 0xff;
  o[42] = x10 >>> 16 & 0xff;
  o[43] = x10 >>> 24 & 0xff;

  o[44] = x11 >>>  0 & 0xff;
  o[45] = x11 >>>  8 & 0xff;
  o[46] = x11 >>> 16 & 0xff;
  o[47] = x11 >>> 24 & 0xff;

  o[48] = x12 >>>  0 & 0xff;
  o[49] = x12 >>>  8 & 0xff;
  o[50] = x12 >>> 16 & 0xff;
  o[51] = x12 >>> 24 & 0xff;

  o[52] = x13 >>>  0 & 0xff;
  o[53] = x13 >>>  8 & 0xff;
  o[54] = x13 >>> 16 & 0xff;
  o[55] = x13 >>> 24 & 0xff;

  o[56] = x14 >>>  0 & 0xff;
  o[57] = x14 >>>  8 & 0xff;
  o[58] = x14 >>> 16 & 0xff;
  o[59] = x14 >>> 24 & 0xff;

  o[60] = x15 >>>  0 & 0xff;
  o[61] = x15 >>>  8 & 0xff;
  o[62] = x15 >>> 16 & 0xff;
  o[63] = x15 >>> 24 & 0xff;
}

function core_hsalsa20(o,p,k,c) {
  var j0  = c[ 0] & 0xff | (c[ 1] & 0xff)<<8 | (c[ 2] & 0xff)<<16 | (c[ 3] & 0xff)<<24,
      j1  = k[ 0] & 0xff | (k[ 1] & 0xff)<<8 | (k[ 2] & 0xff)<<16 | (k[ 3] & 0xff)<<24,
      j2  = k[ 4] & 0xff | (k[ 5] & 0xff)<<8 | (k[ 6] & 0xff)<<16 | (k[ 7] & 0xff)<<24,
      j3  = k[ 8] & 0xff | (k[ 9] & 0xff)<<8 | (k[10] & 0xff)<<16 | (k[11] & 0xff)<<24,
      j4  = k[12] & 0xff | (k[13] & 0xff)<<8 | (k[14] & 0xff)<<16 | (k[15] & 0xff)<<24,
      j5  = c[ 4] & 0xff | (c[ 5] & 0xff)<<8 | (c[ 6] & 0xff)<<16 | (c[ 7] & 0xff)<<24,
      j6  = p[ 0] & 0xff | (p[ 1] & 0xff)<<8 | (p[ 2] & 0xff)<<16 | (p[ 3] & 0xff)<<24,
      j7  = p[ 4] & 0xff | (p[ 5] & 0xff)<<8 | (p[ 6] & 0xff)<<16 | (p[ 7] & 0xff)<<24,
      j8  = p[ 8] & 0xff | (p[ 9] & 0xff)<<8 | (p[10] & 0xff)<<16 | (p[11] & 0xff)<<24,
      j9  = p[12] & 0xff | (p[13] & 0xff)<<8 | (p[14] & 0xff)<<16 | (p[15] & 0xff)<<24,
      j10 = c[ 8] & 0xff | (c[ 9] & 0xff)<<8 | (c[10] & 0xff)<<16 | (c[11] & 0xff)<<24,
      j11 = k[16] & 0xff | (k[17] & 0xff)<<8 | (k[18] & 0xff)<<16 | (k[19] & 0xff)<<24,
      j12 = k[20] & 0xff | (k[21] & 0xff)<<8 | (k[22] & 0xff)<<16 | (k[23] & 0xff)<<24,
      j13 = k[24] & 0xff | (k[25] & 0xff)<<8 | (k[26] & 0xff)<<16 | (k[27] & 0xff)<<24,
      j14 = k[28] & 0xff | (k[29] & 0xff)<<8 | (k[30] & 0xff)<<16 | (k[31] & 0xff)<<24,
      j15 = c[12] & 0xff | (c[13] & 0xff)<<8 | (c[14] & 0xff)<<16 | (c[15] & 0xff)<<24;

  var x0 = j0, x1 = j1, x2 = j2, x3 = j3, x4 = j4, x5 = j5, x6 = j6, x7 = j7,
      x8 = j8, x9 = j9, x10 = j10, x11 = j11, x12 = j12, x13 = j13, x14 = j14,
      x15 = j15, u;

  for (var i = 0; i < 20; i += 2) {
    u = x0 + x12 | 0;
    x4 ^= u<<7 | u>>>(32-7);
    u = x4 + x0 | 0;
    x8 ^= u<<9 | u>>>(32-9);
    u = x8 + x4 | 0;
    x12 ^= u<<13 | u>>>(32-13);
    u = x12 + x8 | 0;
    x0 ^= u<<18 | u>>>(32-18);

    u = x5 + x1 | 0;
    x9 ^= u<<7 | u>>>(32-7);
    u = x9 + x5 | 0;
    x13 ^= u<<9 | u>>>(32-9);
    u = x13 + x9 | 0;
    x1 ^= u<<13 | u>>>(32-13);
    u = x1 + x13 | 0;
    x5 ^= u<<18 | u>>>(32-18);

    u = x10 + x6 | 0;
    x14 ^= u<<7 | u>>>(32-7);
    u = x14 + x10 | 0;
    x2 ^= u<<9 | u>>>(32-9);
    u = x2 + x14 | 0;
    x6 ^= u<<13 | u>>>(32-13);
    u = x6 + x2 | 0;
    x10 ^= u<<18 | u>>>(32-18);

    u = x15 + x11 | 0;
    x3 ^= u<<7 | u>>>(32-7);
    u = x3 + x15 | 0;
    x7 ^= u<<9 | u>>>(32-9);
    u = x7 + x3 | 0;
    x11 ^= u<<13 | u>>>(32-13);
    u = x11 + x7 | 0;
    x15 ^= u<<18 | u>>>(32-18);

    u = x0 + x3 | 0;
    x1 ^= u<<7 | u>>>(32-7);
    u = x1 + x0 | 0;
    x2 ^= u<<9 | u>>>(32-9);
    u = x2 + x1 | 0;
    x3 ^= u<<13 | u>>>(32-13);
    u = x3 + x2 | 0;
    x0 ^= u<<18 | u>>>(32-18);

    u = x5 + x4 | 0;
    x6 ^= u<<7 | u>>>(32-7);
    u = x6 + x5 | 0;
    x7 ^= u<<9 | u>>>(32-9);
    u = x7 + x6 | 0;
    x4 ^= u<<13 | u>>>(32-13);
    u = x4 + x7 | 0;
    x5 ^= u<<18 | u>>>(32-18);

    u = x10 + x9 | 0;
    x11 ^= u<<7 | u>>>(32-7);
    u = x11 + x10 | 0;
    x8 ^= u<<9 | u>>>(32-9);
    u = x8 + x11 | 0;
    x9 ^= u<<13 | u>>>(32-13);
    u = x9 + x8 | 0;
    x10 ^= u<<18 | u>>>(32-18);

    u = x15 + x14 | 0;
    x12 ^= u<<7 | u>>>(32-7);
    u = x12 + x15 | 0;
    x13 ^= u<<9 | u>>>(32-9);
    u = x13 + x12 | 0;
    x14 ^= u<<13 | u>>>(32-13);
    u = x14 + x13 | 0;
    x15 ^= u<<18 | u>>>(32-18);
  }

  o[ 0] = x0 >>>  0 & 0xff;
  o[ 1] = x0 >>>  8 & 0xff;
  o[ 2] = x0 >>> 16 & 0xff;
  o[ 3] = x0 >>> 24 & 0xff;

  o[ 4] = x5 >>>  0 & 0xff;
  o[ 5] = x5 >>>  8 & 0xff;
  o[ 6] = x5 >>> 16 & 0xff;
  o[ 7] = x5 >>> 24 & 0xff;

  o[ 8] = x10 >>>  0 & 0xff;
  o[ 9] = x10 >>>  8 & 0xff;
  o[10] = x10 >>> 16 & 0xff;
  o[11] = x10 >>> 24 & 0xff;

  o[12] = x15 >>>  0 & 0xff;
  o[13] = x15 >>>  8 & 0xff;
  o[14] = x15 >>> 16 & 0xff;
  o[15] = x15 >>> 24 & 0xff;

  o[16] = x6 >>>  0 & 0xff;
  o[17] = x6 >>>  8 & 0xff;
  o[18] = x6 >>> 16 & 0xff;
  o[19] = x6 >>> 24 & 0xff;

  o[20] = x7 >>>  0 & 0xff;
  o[21] = x7 >>>  8 & 0xff;
  o[22] = x7 >>> 16 & 0xff;
  o[23] = x7 >>> 24 & 0xff;

  o[24] = x8 >>>  0 & 0xff;
  o[25] = x8 >>>  8 & 0xff;
  o[26] = x8 >>> 16 & 0xff;
  o[27] = x8 >>> 24 & 0xff;

  o[28] = x9 >>>  0 & 0xff;
  o[29] = x9 >>>  8 & 0xff;
  o[30] = x9 >>> 16 & 0xff;
  o[31] = x9 >>> 24 & 0xff;
}

function crypto_core_salsa20(out,inp,k,c) {
  core_salsa20(out,inp,k,c);
}

function crypto_core_hsalsa20(out,inp,k,c) {
  core_hsalsa20(out,inp,k,c);
}

var sigma = new Uint8Array([101, 120, 112, 97, 110, 100, 32, 51, 50, 45, 98, 121, 116, 101, 32, 107]);
            // "expand 32-byte k"

function crypto_stream_salsa20_xor(c,cpos,m,mpos,b,n,k) {
  var z = new Uint8Array(16), x = new Uint8Array(64);
  var u, i;
  for (i = 0; i < 16; i++) z[i] = 0;
  for (i = 0; i < 8; i++) z[i] = n[i];
  while (b >= 64) {
    crypto_core_salsa20(x,z,k,sigma);
    for (i = 0; i < 64; i++) c[cpos+i] = m[mpos+i] ^ x[i];
    u = 1;
    for (i = 8; i < 16; i++) {
      u = u + (z[i] & 0xff) | 0;
      z[i] = u & 0xff;
      u >>>= 8;
    }
    b -= 64;
    cpos += 64;
    mpos += 64;
  }
  if (b > 0) {
    crypto_core_salsa20(x,z,k,sigma);
    for (i = 0; i < b; i++) c[cpos+i] = m[mpos+i] ^ x[i];
  }
  return 0;
}

function crypto_stream_salsa20(c,cpos,b,n,k) {
  var z = new Uint8Array(16), x = new Uint8Array(64);
  var u, i;
  for (i = 0; i < 16; i++) z[i] = 0;
  for (i = 0; i < 8; i++) z[i] = n[i];
  while (b >= 64) {
    crypto_core_salsa20(x,z,k,sigma);
    for (i = 0; i < 64; i++) c[cpos+i] = x[i];
    u = 1;
    for (i = 8; i < 16; i++) {
      u = u + (z[i] & 0xff) | 0;
      z[i] = u & 0xff;
      u >>>= 8;
    }
    b -= 64;
    cpos += 64;
  }
  if (b > 0) {
    crypto_core_salsa20(x,z,k,sigma);
    for (i = 0; i < b; i++) c[cpos+i] = x[i];
  }
  return 0;
}

function crypto_stream(c,cpos,d,n,k) {
  var s = new Uint8Array(32);
  crypto_core_hsalsa20(s,n,k,sigma);
  var sn = new Uint8Array(8);
  for (var i = 0; i < 8; i++) sn[i] = n[i+16];
  return crypto_stream_salsa20(c,cpos,d,sn,s);
}

function crypto_stream_xor(c,cpos,m,mpos,d,n,k) {
  var s = new Uint8Array(32);
  crypto_core_hsalsa20(s,n,k,sigma);
  var sn = new Uint8Array(8);
  for (var i = 0; i < 8; i++) sn[i] = n[i+16];
  return crypto_stream_salsa20_xor(c,cpos,m,mpos,d,sn,s);
}

/*
* Port of Andrew Moon's Poly1305-donna-16. Public domain.
* https://github.com/floodyberry/poly1305-donna
*/

var poly1305 = function(key) {
  this.buffer = new Uint8Array(16);
  this.r = new Uint16Array(10);
  this.h = new Uint16Array(10);
  this.pad = new Uint16Array(8);
  this.leftover = 0;
  this.fin = 0;

  var t0, t1, t2, t3, t4, t5, t6, t7;

  t0 = key[ 0] & 0xff | (key[ 1] & 0xff) << 8; this.r[0] = ( t0                     ) & 0x1fff;
  t1 = key[ 2] & 0xff | (key[ 3] & 0xff) << 8; this.r[1] = ((t0 >>> 13) | (t1 <<  3)) & 0x1fff;
  t2 = key[ 4] & 0xff | (key[ 5] & 0xff) << 8; this.r[2] = ((t1 >>> 10) | (t2 <<  6)) & 0x1f03;
  t3 = key[ 6] & 0xff | (key[ 7] & 0xff) << 8; this.r[3] = ((t2 >>>  7) | (t3 <<  9)) & 0x1fff;
  t4 = key[ 8] & 0xff | (key[ 9] & 0xff) << 8; this.r[4] = ((t3 >>>  4) | (t4 << 12)) & 0x00ff;
  this.r[5] = ((t4 >>>  1)) & 0x1ffe;
  t5 = key[10] & 0xff | (key[11] & 0xff) << 8; this.r[6] = ((t4 >>> 14) | (t5 <<  2)) & 0x1fff;
  t6 = key[12] & 0xff | (key[13] & 0xff) << 8; this.r[7] = ((t5 >>> 11) | (t6 <<  5)) & 0x1f81;
  t7 = key[14] & 0xff | (key[15] & 0xff) << 8; this.r[8] = ((t6 >>>  8) | (t7 <<  8)) & 0x1fff;
  this.r[9] = ((t7 >>>  5)) & 0x007f;

  this.pad[0] = key[16] & 0xff | (key[17] & 0xff) << 8;
  this.pad[1] = key[18] & 0xff | (key[19] & 0xff) << 8;
  this.pad[2] = key[20] & 0xff | (key[21] & 0xff) << 8;
  this.pad[3] = key[22] & 0xff | (key[23] & 0xff) << 8;
  this.pad[4] = key[24] & 0xff | (key[25] & 0xff) << 8;
  this.pad[5] = key[26] & 0xff | (key[27] & 0xff) << 8;
  this.pad[6] = key[28] & 0xff | (key[29] & 0xff) << 8;
  this.pad[7] = key[30] & 0xff | (key[31] & 0xff) << 8;
};

poly1305.prototype.blocks = function(m, mpos, bytes) {
  var hibit = this.fin ? 0 : (1 << 11);
  var t0, t1, t2, t3, t4, t5, t6, t7, c;
  var d0, d1, d2, d3, d4, d5, d6, d7, d8, d9;

  var h0 = this.h[0],
      h1 = this.h[1],
      h2 = this.h[2],
      h3 = this.h[3],
      h4 = this.h[4],
      h5 = this.h[5],
      h6 = this.h[6],
      h7 = this.h[7],
      h8 = this.h[8],
      h9 = this.h[9];

  var r0 = this.r[0],
      r1 = this.r[1],
      r2 = this.r[2],
      r3 = this.r[3],
      r4 = this.r[4],
      r5 = this.r[5],
      r6 = this.r[6],
      r7 = this.r[7],
      r8 = this.r[8],
      r9 = this.r[9];

  while (bytes >= 16) {
    t0 = m[mpos+ 0] & 0xff | (m[mpos+ 1] & 0xff) << 8; h0 += ( t0                     ) & 0x1fff;
    t1 = m[mpos+ 2] & 0xff | (m[mpos+ 3] & 0xff) << 8; h1 += ((t0 >>> 13) | (t1 <<  3)) & 0x1fff;
    t2 = m[mpos+ 4] & 0xff | (m[mpos+ 5] & 0xff) << 8; h2 += ((t1 >>> 10) | (t2 <<  6)) & 0x1fff;
    t3 = m[mpos+ 6] & 0xff | (m[mpos+ 7] & 0xff) << 8; h3 += ((t2 >>>  7) | (t3 <<  9)) & 0x1fff;
    t4 = m[mpos+ 8] & 0xff | (m[mpos+ 9] & 0xff) << 8; h4 += ((t3 >>>  4) | (t4 << 12)) & 0x1fff;
    h5 += ((t4 >>>  1)) & 0x1fff;
    t5 = m[mpos+10] & 0xff | (m[mpos+11] & 0xff) << 8; h6 += ((t4 >>> 14) | (t5 <<  2)) & 0x1fff;
    t6 = m[mpos+12] & 0xff | (m[mpos+13] & 0xff) << 8; h7 += ((t5 >>> 11) | (t6 <<  5)) & 0x1fff;
    t7 = m[mpos+14] & 0xff | (m[mpos+15] & 0xff) << 8; h8 += ((t6 >>>  8) | (t7 <<  8)) & 0x1fff;
    h9 += ((t7 >>> 5)) | hibit;

    c = 0;

    d0 = c;
    d0 += h0 * r0;
    d0 += h1 * (5 * r9);
    d0 += h2 * (5 * r8);
    d0 += h3 * (5 * r7);
    d0 += h4 * (5 * r6);
    c = (d0 >>> 13); d0 &= 0x1fff;
    d0 += h5 * (5 * r5);
    d0 += h6 * (5 * r4);
    d0 += h7 * (5 * r3);
    d0 += h8 * (5 * r2);
    d0 += h9 * (5 * r1);
    c += (d0 >>> 13); d0 &= 0x1fff;

    d1 = c;
    d1 += h0 * r1;
    d1 += h1 * r0;
    d1 += h2 * (5 * r9);
    d1 += h3 * (5 * r8);
    d1 += h4 * (5 * r7);
    c = (d1 >>> 13); d1 &= 0x1fff;
    d1 += h5 * (5 * r6);
    d1 += h6 * (5 * r5);
    d1 += h7 * (5 * r4);
    d1 += h8 * (5 * r3);
    d1 += h9 * (5 * r2);
    c += (d1 >>> 13); d1 &= 0x1fff;

    d2 = c;
    d2 += h0 * r2;
    d2 += h1 * r1;
    d2 += h2 * r0;
    d2 += h3 * (5 * r9);
    d2 += h4 * (5 * r8);
    c = (d2 >>> 13); d2 &= 0x1fff;
    d2 += h5 * (5 * r7);
    d2 += h6 * (5 * r6);
    d2 += h7 * (5 * r5);
    d2 += h8 * (5 * r4);
    d2 += h9 * (5 * r3);
    c += (d2 >>> 13); d2 &= 0x1fff;

    d3 = c;
    d3 += h0 * r3;
    d3 += h1 * r2;
    d3 += h2 * r1;
    d3 += h3 * r0;
    d3 += h4 * (5 * r9);
    c = (d3 >>> 13); d3 &= 0x1fff;
    d3 += h5 * (5 * r8);
    d3 += h6 * (5 * r7);
    d3 += h7 * (5 * r6);
    d3 += h8 * (5 * r5);
    d3 += h9 * (5 * r4);
    c += (d3 >>> 13); d3 &= 0x1fff;

    d4 = c;
    d4 += h0 * r4;
    d4 += h1 * r3;
    d4 += h2 * r2;
    d4 += h3 * r1;
    d4 += h4 * r0;
    c = (d4 >>> 13); d4 &= 0x1fff;
    d4 += h5 * (5 * r9);
    d4 += h6 * (5 * r8);
    d4 += h7 * (5 * r7);
    d4 += h8 * (5 * r6);
    d4 += h9 * (5 * r5);
    c += (d4 >>> 13); d4 &= 0x1fff;

    d5 = c;
    d5 += h0 * r5;
    d5 += h1 * r4;
    d5 += h2 * r3;
    d5 += h3 * r2;
    d5 += h4 * r1;
    c = (d5 >>> 13); d5 &= 0x1fff;
    d5 += h5 * r0;
    d5 += h6 * (5 * r9);
    d5 += h7 * (5 * r8);
    d5 += h8 * (5 * r7);
    d5 += h9 * (5 * r6);
    c += (d5 >>> 13); d5 &= 0x1fff;

    d6 = c;
    d6 += h0 * r6;
    d6 += h1 * r5;
    d6 += h2 * r4;
    d6 += h3 * r3;
    d6 += h4 * r2;
    c = (d6 >>> 13); d6 &= 0x1fff;
    d6 += h5 * r1;
    d6 += h6 * r0;
    d6 += h7 * (5 * r9);
    d6 += h8 * (5 * r8);
    d6 += h9 * (5 * r7);
    c += (d6 >>> 13); d6 &= 0x1fff;

    d7 = c;
    d7 += h0 * r7;
    d7 += h1 * r6;
    d7 += h2 * r5;
    d7 += h3 * r4;
    d7 += h4 * r3;
    c = (d7 >>> 13); d7 &= 0x1fff;
    d7 += h5 * r2;
    d7 += h6 * r1;
    d7 += h7 * r0;
    d7 += h8 * (5 * r9);
    d7 += h9 * (5 * r8);
    c += (d7 >>> 13); d7 &= 0x1fff;

    d8 = c;
    d8 += h0 * r8;
    d8 += h1 * r7;
    d8 += h2 * r6;
    d8 += h3 * r5;
    d8 += h4 * r4;
    c = (d8 >>> 13); d8 &= 0x1fff;
    d8 += h5 * r3;
    d8 += h6 * r2;
    d8 += h7 * r1;
    d8 += h8 * r0;
    d8 += h9 * (5 * r9);
    c += (d8 >>> 13); d8 &= 0x1fff;

    d9 = c;
    d9 += h0 * r9;
    d9 += h1 * r8;
    d9 += h2 * r7;
    d9 += h3 * r6;
    d9 += h4 * r5;
    c = (d9 >>> 13); d9 &= 0x1fff;
    d9 += h5 * r4;
    d9 += h6 * r3;
    d9 += h7 * r2;
    d9 += h8 * r1;
    d9 += h9 * r0;
    c += (d9 >>> 13); d9 &= 0x1fff;

    c = (((c << 2) + c)) | 0;
    c = (c + d0) | 0;
    d0 = c & 0x1fff;
    c = (c >>> 13);
    d1 += c;

    h0 = d0;
    h1 = d1;
    h2 = d2;
    h3 = d3;
    h4 = d4;
    h5 = d5;
    h6 = d6;
    h7 = d7;
    h8 = d8;
    h9 = d9;

    mpos += 16;
    bytes -= 16;
  }
  this.h[0] = h0;
  this.h[1] = h1;
  this.h[2] = h2;
  this.h[3] = h3;
  this.h[4] = h4;
  this.h[5] = h5;
  this.h[6] = h6;
  this.h[7] = h7;
  this.h[8] = h8;
  this.h[9] = h9;
};

poly1305.prototype.finish = function(mac, macpos) {
  var g = new Uint16Array(10);
  var c, mask, f, i;

  if (this.leftover) {
    i = this.leftover;
    this.buffer[i++] = 1;
    for (; i < 16; i++) this.buffer[i] = 0;
    this.fin = 1;
    this.blocks(this.buffer, 0, 16);
  }

  c = this.h[1] >>> 13;
  this.h[1] &= 0x1fff;
  for (i = 2; i < 10; i++) {
    this.h[i] += c;
    c = this.h[i] >>> 13;
    this.h[i] &= 0x1fff;
  }
  this.h[0] += (c * 5);
  c = this.h[0] >>> 13;
  this.h[0] &= 0x1fff;
  this.h[1] += c;
  c = this.h[1] >>> 13;
  this.h[1] &= 0x1fff;
  this.h[2] += c;

  g[0] = this.h[0] + 5;
  c = g[0] >>> 13;
  g[0] &= 0x1fff;
  for (i = 1; i < 10; i++) {
    g[i] = this.h[i] + c;
    c = g[i] >>> 13;
    g[i] &= 0x1fff;
  }
  g[9] -= (1 << 13);

  mask = (c ^ 1) - 1;
  for (i = 0; i < 10; i++) g[i] &= mask;
  mask = ~mask;
  for (i = 0; i < 10; i++) this.h[i] = (this.h[i] & mask) | g[i];

  this.h[0] = ((this.h[0]       ) | (this.h[1] << 13)                    ) & 0xffff;
  this.h[1] = ((this.h[1] >>>  3) | (this.h[2] << 10)                    ) & 0xffff;
  this.h[2] = ((this.h[2] >>>  6) | (this.h[3] <<  7)                    ) & 0xffff;
  this.h[3] = ((this.h[3] >>>  9) | (this.h[4] <<  4)                    ) & 0xffff;
  this.h[4] = ((this.h[4] >>> 12) | (this.h[5] <<  1) | (this.h[6] << 14)) & 0xffff;
  this.h[5] = ((this.h[6] >>>  2) | (this.h[7] << 11)                    ) & 0xffff;
  this.h[6] = ((this.h[7] >>>  5) | (this.h[8] <<  8)                    ) & 0xffff;
  this.h[7] = ((this.h[8] >>>  8) | (this.h[9] <<  5)                    ) & 0xffff;

  f = this.h[0] + this.pad[0];
  this.h[0] = f & 0xffff;
  for (i = 1; i < 8; i++) {
    f = (((this.h[i] + this.pad[i]) | 0) + (f >>> 16)) | 0;
    this.h[i] = f & 0xffff;
  }

  mac[macpos+ 0] = (this.h[0] >>> 0) & 0xff;
  mac[macpos+ 1] = (this.h[0] >>> 8) & 0xff;
  mac[macpos+ 2] = (this.h[1] >>> 0) & 0xff;
  mac[macpos+ 3] = (this.h[1] >>> 8) & 0xff;
  mac[macpos+ 4] = (this.h[2] >>> 0) & 0xff;
  mac[macpos+ 5] = (this.h[2] >>> 8) & 0xff;
  mac[macpos+ 6] = (this.h[3] >>> 0) & 0xff;
  mac[macpos+ 7] = (this.h[3] >>> 8) & 0xff;
  mac[macpos+ 8] = (this.h[4] >>> 0) & 0xff;
  mac[macpos+ 9] = (this.h[4] >>> 8) & 0xff;
  mac[macpos+10] = (this.h[5] >>> 0) & 0xff;
  mac[macpos+11] = (this.h[5] >>> 8) & 0xff;
  mac[macpos+12] = (this.h[6] >>> 0) & 0xff;
  mac[macpos+13] = (this.h[6] >>> 8) & 0xff;
  mac[macpos+14] = (this.h[7] >>> 0) & 0xff;
  mac[macpos+15] = (this.h[7] >>> 8) & 0xff;
};

poly1305.prototype.update = function(m, mpos, bytes) {
  var i, want;

  if (this.leftover) {
    want = (16 - this.leftover);
    if (want > bytes)
      want = bytes;
    for (i = 0; i < want; i++)
      this.buffer[this.leftover + i] = m[mpos+i];
    bytes -= want;
    mpos += want;
    this.leftover += want;
    if (this.leftover < 16)
      return;
    this.blocks(this.buffer, 0, 16);
    this.leftover = 0;
  }

  if (bytes >= 16) {
    want = bytes - (bytes % 16);
    this.blocks(m, mpos, want);
    mpos += want;
    bytes -= want;
  }

  if (bytes) {
    for (i = 0; i < bytes; i++)
      this.buffer[this.leftover + i] = m[mpos+i];
    this.leftover += bytes;
  }
};

function crypto_onetimeauth(out, outpos, m, mpos, n, k) {
  var s = new poly1305(k);
  s.update(m, mpos, n);
  s.finish(out, outpos);
  return 0;
}

function crypto_onetimeauth_verify(h, hpos, m, mpos, n, k) {
  var x = new Uint8Array(16);
  crypto_onetimeauth(x,0,m,mpos,n,k);
  return crypto_verify_16(h,hpos,x,0);
}

function crypto_secretbox(c,m,d,n,k) {
  var i;
  if (d < 32) return -1;
  crypto_stream_xor(c,0,m,0,d,n,k);
  crypto_onetimeauth(c, 16, c, 32, d - 32, c);
  for (i = 0; i < 16; i++) c[i] = 0;
  return 0;
}

function crypto_secretbox_open(m,c,d,n,k) {
  var i;
  var x = new Uint8Array(32);
  if (d < 32) return -1;
  crypto_stream(x,0,32,n,k);
  if (crypto_onetimeauth_verify(c, 16,c, 32,d - 32,x) !== 0) return -1;
  crypto_stream_xor(m,0,c,0,d,n,k);
  for (i = 0; i < 32; i++) m[i] = 0;
  return 0;
}

function set25519(r, a) {
  var i;
  for (i = 0; i < 16; i++) r[i] = a[i]|0;
}

function car25519(o) {
  var i, v, c = 1;
  for (i = 0; i < 16; i++) {
    v = o[i] + c + 65535;
    c = Math.floor(v / 65536);
    o[i] = v - c * 65536;
  }
  o[0] += c-1 + 37 * (c-1);
}

function sel25519(p, q, b) {
  var t, c = ~(b-1);
  for (var i = 0; i < 16; i++) {
    t = c & (p[i] ^ q[i]);
    p[i] ^= t;
    q[i] ^= t;
  }
}

function pack25519(o, n) {
  var i, j, b;
  var m = gf(), t = gf();
  for (i = 0; i < 16; i++) t[i] = n[i];
  car25519(t);
  car25519(t);
  car25519(t);
  for (j = 0; j < 2; j++) {
    m[0] = t[0] - 0xffed;
    for (i = 1; i < 15; i++) {
      m[i] = t[i] - 0xffff - ((m[i-1]>>16) & 1);
      m[i-1] &= 0xffff;
    }
    m[15] = t[15] - 0x7fff - ((m[14]>>16) & 1);
    b = (m[15]>>16) & 1;
    m[14] &= 0xffff;
    sel25519(t, m, 1-b);
  }
  for (i = 0; i < 16; i++) {
    o[2*i] = t[i] & 0xff;
    o[2*i+1] = t[i]>>8;
  }
}

function neq25519(a, b) {
  var c = new Uint8Array(32), d = new Uint8Array(32);
  pack25519(c, a);
  pack25519(d, b);
  return crypto_verify_32(c, 0, d, 0);
}

function par25519(a) {
  var d = new Uint8Array(32);
  pack25519(d, a);
  return d[0] & 1;
}

function unpack25519(o, n) {
  var i;
  for (i = 0; i < 16; i++) o[i] = n[2*i] + (n[2*i+1] << 8);
  o[15] &= 0x7fff;
}

function A(o, a, b) {
  for (var i = 0; i < 16; i++) o[i] = a[i] + b[i];
}

function Z(o, a, b) {
  for (var i = 0; i < 16; i++) o[i] = a[i] - b[i];
}

function M(o, a, b) {
  var v, c,
     t0 = 0,  t1 = 0,  t2 = 0,  t3 = 0,  t4 = 0,  t5 = 0,  t6 = 0,  t7 = 0,
     t8 = 0,  t9 = 0, t10 = 0, t11 = 0, t12 = 0, t13 = 0, t14 = 0, t15 = 0,
    t16 = 0, t17 = 0, t18 = 0, t19 = 0, t20 = 0, t21 = 0, t22 = 0, t23 = 0,
    t24 = 0, t25 = 0, t26 = 0, t27 = 0, t28 = 0, t29 = 0, t30 = 0,
    b0 = b[0],
    b1 = b[1],
    b2 = b[2],
    b3 = b[3],
    b4 = b[4],
    b5 = b[5],
    b6 = b[6],
    b7 = b[7],
    b8 = b[8],
    b9 = b[9],
    b10 = b[10],
    b11 = b[11],
    b12 = b[12],
    b13 = b[13],
    b14 = b[14],
    b15 = b[15];

  v = a[0];
  t0 += v * b0;
  t1 += v * b1;
  t2 += v * b2;
  t3 += v * b3;
  t4 += v * b4;
  t5 += v * b5;
  t6 += v * b6;
  t7 += v * b7;
  t8 += v * b8;
  t9 += v * b9;
  t10 += v * b10;
  t11 += v * b11;
  t12 += v * b12;
  t13 += v * b13;
  t14 += v * b14;
  t15 += v * b15;
  v = a[1];
  t1 += v * b0;
  t2 += v * b1;
  t3 += v * b2;
  t4 += v * b3;
  t5 += v * b4;
  t6 += v * b5;
  t7 += v * b6;
  t8 += v * b7;
  t9 += v * b8;
  t10 += v * b9;
  t11 += v * b10;
  t12 += v * b11;
  t13 += v * b12;
  t14 += v * b13;
  t15 += v * b14;
  t16 += v * b15;
  v = a[2];
  t2 += v * b0;
  t3 += v * b1;
  t4 += v * b2;
  t5 += v * b3;
  t6 += v * b4;
  t7 += v * b5;
  t8 += v * b6;
  t9 += v * b7;
  t10 += v * b8;
  t11 += v * b9;
  t12 += v * b10;
  t13 += v * b11;
  t14 += v * b12;
  t15 += v * b13;
  t16 += v * b14;
  t17 += v * b15;
  v = a[3];
  t3 += v * b0;
  t4 += v * b1;
  t5 += v * b2;
  t6 += v * b3;
  t7 += v * b4;
  t8 += v * b5;
  t9 += v * b6;
  t10 += v * b7;
  t11 += v * b8;
  t12 += v * b9;
  t13 += v * b10;
  t14 += v * b11;
  t15 += v * b12;
  t16 += v * b13;
  t17 += v * b14;
  t18 += v * b15;
  v = a[4];
  t4 += v * b0;
  t5 += v * b1;
  t6 += v * b2;
  t7 += v * b3;
  t8 += v * b4;
  t9 += v * b5;
  t10 += v * b6;
  t11 += v * b7;
  t12 += v * b8;
  t13 += v * b9;
  t14 += v * b10;
  t15 += v * b11;
  t16 += v * b12;
  t17 += v * b13;
  t18 += v * b14;
  t19 += v * b15;
  v = a[5];
  t5 += v * b0;
  t6 += v * b1;
  t7 += v * b2;
  t8 += v * b3;
  t9 += v * b4;
  t10 += v * b5;
  t11 += v * b6;
  t12 += v * b7;
  t13 += v * b8;
  t14 += v * b9;
  t15 += v * b10;
  t16 += v * b11;
  t17 += v * b12;
  t18 += v * b13;
  t19 += v * b14;
  t20 += v * b15;
  v = a[6];
  t6 += v * b0;
  t7 += v * b1;
  t8 += v * b2;
  t9 += v * b3;
  t10 += v * b4;
  t11 += v * b5;
  t12 += v * b6;
  t13 += v * b7;
  t14 += v * b8;
  t15 += v * b9;
  t16 += v * b10;
  t17 += v * b11;
  t18 += v * b12;
  t19 += v * b13;
  t20 += v * b14;
  t21 += v * b15;
  v = a[7];
  t7 += v * b0;
  t8 += v * b1;
  t9 += v * b2;
  t10 += v * b3;
  t11 += v * b4;
  t12 += v * b5;
  t13 += v * b6;
  t14 += v * b7;
  t15 += v * b8;
  t16 += v * b9;
  t17 += v * b10;
  t18 += v * b11;
  t19 += v * b12;
  t20 += v * b13;
  t21 += v * b14;
  t22 += v * b15;
  v = a[8];
  t8 += v * b0;
  t9 += v * b1;
  t10 += v * b2;
  t11 += v * b3;
  t12 += v * b4;
  t13 += v * b5;
  t14 += v * b6;
  t15 += v * b7;
  t16 += v * b8;
  t17 += v * b9;
  t18 += v * b10;
  t19 += v * b11;
  t20 += v * b12;
  t21 += v * b13;
  t22 += v * b14;
  t23 += v * b15;
  v = a[9];
  t9 += v * b0;
  t10 += v * b1;
  t11 += v * b2;
  t12 += v * b3;
  t13 += v * b4;
  t14 += v * b5;
  t15 += v * b6;
  t16 += v * b7;
  t17 += v * b8;
  t18 += v * b9;
  t19 += v * b10;
  t20 += v * b11;
  t21 += v * b12;
  t22 += v * b13;
  t23 += v * b14;
  t24 += v * b15;
  v = a[10];
  t10 += v * b0;
  t11 += v * b1;
  t12 += v * b2;
  t13 += v * b3;
  t14 += v * b4;
  t15 += v * b5;
  t16 += v * b6;
  t17 += v * b7;
  t18 += v * b8;
  t19 += v * b9;
  t20 += v * b10;
  t21 += v * b11;
  t22 += v * b12;
  t23 += v * b13;
  t24 += v * b14;
  t25 += v * b15;
  v = a[11];
  t11 += v * b0;
  t12 += v * b1;
  t13 += v * b2;
  t14 += v * b3;
  t15 += v * b4;
  t16 += v * b5;
  t17 += v * b6;
  t18 += v * b7;
  t19 += v * b8;
  t20 += v * b9;
  t21 += v * b10;
  t22 += v * b11;
  t23 += v * b12;
  t24 += v * b13;
  t25 += v * b14;
  t26 += v * b15;
  v = a[12];
  t12 += v * b0;
  t13 += v * b1;
  t14 += v * b2;
  t15 += v * b3;
  t16 += v * b4;
  t17 += v * b5;
  t18 += v * b6;
  t19 += v * b7;
  t20 += v * b8;
  t21 += v * b9;
  t22 += v * b10;
  t23 += v * b11;
  t24 += v * b12;
  t25 += v * b13;
  t26 += v * b14;
  t27 += v * b15;
  v = a[13];
  t13 += v * b0;
  t14 += v * b1;
  t15 += v * b2;
  t16 += v * b3;
  t17 += v * b4;
  t18 += v * b5;
  t19 += v * b6;
  t20 += v * b7;
  t21 += v * b8;
  t22 += v * b9;
  t23 += v * b10;
  t24 += v * b11;
  t25 += v * b12;
  t26 += v * b13;
  t27 += v * b14;
  t28 += v * b15;
  v = a[14];
  t14 += v * b0;
  t15 += v * b1;
  t16 += v * b2;
  t17 += v * b3;
  t18 += v * b4;
  t19 += v * b5;
  t20 += v * b6;
  t21 += v * b7;
  t22 += v * b8;
  t23 += v * b9;
  t24 += v * b10;
  t25 += v * b11;
  t26 += v * b12;
  t27 += v * b13;
  t28 += v * b14;
  t29 += v * b15;
  v = a[15];
  t15 += v * b0;
  t16 += v * b1;
  t17 += v * b2;
  t18 += v * b3;
  t19 += v * b4;
  t20 += v * b5;
  t21 += v * b6;
  t22 += v * b7;
  t23 += v * b8;
  t24 += v * b9;
  t25 += v * b10;
  t26 += v * b11;
  t27 += v * b12;
  t28 += v * b13;
  t29 += v * b14;
  t30 += v * b15;

  t0  += 38 * t16;
  t1  += 38 * t17;
  t2  += 38 * t18;
  t3  += 38 * t19;
  t4  += 38 * t20;
  t5  += 38 * t21;
  t6  += 38 * t22;
  t7  += 38 * t23;
  t8  += 38 * t24;
  t9  += 38 * t25;
  t10 += 38 * t26;
  t11 += 38 * t27;
  t12 += 38 * t28;
  t13 += 38 * t29;
  t14 += 38 * t30;
  // t15 left as is

  // first car
  c = 1;
  v =  t0 + c + 65535; c = Math.floor(v / 65536);  t0 = v - c * 65536;
  v =  t1 + c + 65535; c = Math.floor(v / 65536);  t1 = v - c * 65536;
  v =  t2 + c + 65535; c = Math.floor(v / 65536);  t2 = v - c * 65536;
  v =  t3 + c + 65535; c = Math.floor(v / 65536);  t3 = v - c * 65536;
  v =  t4 + c + 65535; c = Math.floor(v / 65536);  t4 = v - c * 65536;
  v =  t5 + c + 65535; c = Math.floor(v / 65536);  t5 = v - c * 65536;
  v =  t6 + c + 65535; c = Math.floor(v / 65536);  t6 = v - c * 65536;
  v =  t7 + c + 65535; c = Math.floor(v / 65536);  t7 = v - c * 65536;
  v =  t8 + c + 65535; c = Math.floor(v / 65536);  t8 = v - c * 65536;
  v =  t9 + c + 65535; c = Math.floor(v / 65536);  t9 = v - c * 65536;
  v = t10 + c + 65535; c = Math.floor(v / 65536); t10 = v - c * 65536;
  v = t11 + c + 65535; c = Math.floor(v / 65536); t11 = v - c * 65536;
  v = t12 + c + 65535; c = Math.floor(v / 65536); t12 = v - c * 65536;
  v = t13 + c + 65535; c = Math.floor(v / 65536); t13 = v - c * 65536;
  v = t14 + c + 65535; c = Math.floor(v / 65536); t14 = v - c * 65536;
  v = t15 + c + 65535; c = Math.floor(v / 65536); t15 = v - c * 65536;
  t0 += c-1 + 37 * (c-1);

  // second car
  c = 1;
  v =  t0 + c + 65535; c = Math.floor(v / 65536);  t0 = v - c * 65536;
  v =  t1 + c + 65535; c = Math.floor(v / 65536);  t1 = v - c * 65536;
  v =  t2 + c + 65535; c = Math.floor(v / 65536);  t2 = v - c * 65536;
  v =  t3 + c + 65535; c = Math.floor(v / 65536);  t3 = v - c * 65536;
  v =  t4 + c + 65535; c = Math.floor(v / 65536);  t4 = v - c * 65536;
  v =  t5 + c + 65535; c = Math.floor(v / 65536);  t5 = v - c * 65536;
  v =  t6 + c + 65535; c = Math.floor(v / 65536);  t6 = v - c * 65536;
  v =  t7 + c + 65535; c = Math.floor(v / 65536);  t7 = v - c * 65536;
  v =  t8 + c + 65535; c = Math.floor(v / 65536);  t8 = v - c * 65536;
  v =  t9 + c + 65535; c = Math.floor(v / 65536);  t9 = v - c * 65536;
  v = t10 + c + 65535; c = Math.floor(v / 65536); t10 = v - c * 65536;
  v = t11 + c + 65535; c = Math.floor(v / 65536); t11 = v - c * 65536;
  v = t12 + c + 65535; c = Math.floor(v / 65536); t12 = v - c * 65536;
  v = t13 + c + 65535; c = Math.floor(v / 65536); t13 = v - c * 65536;
  v = t14 + c + 65535; c = Math.floor(v / 65536); t14 = v - c * 65536;
  v = t15 + c + 65535; c = Math.floor(v / 65536); t15 = v - c * 65536;
  t0 += c-1 + 37 * (c-1);

  o[ 0] = t0;
  o[ 1] = t1;
  o[ 2] = t2;
  o[ 3] = t3;
  o[ 4] = t4;
  o[ 5] = t5;
  o[ 6] = t6;
  o[ 7] = t7;
  o[ 8] = t8;
  o[ 9] = t9;
  o[10] = t10;
  o[11] = t11;
  o[12] = t12;
  o[13] = t13;
  o[14] = t14;
  o[15] = t15;
}

function S(o, a) {
  M(o, a, a);
}

function inv25519(o, i) {
  var c = gf();
  var a;
  for (a = 0; a < 16; a++) c[a] = i[a];
  for (a = 253; a >= 0; a--) {
    S(c, c);
    if(a !== 2 && a !== 4) M(c, c, i);
  }
  for (a = 0; a < 16; a++) o[a] = c[a];
}

function pow2523(o, i) {
  var c = gf();
  var a;
  for (a = 0; a < 16; a++) c[a] = i[a];
  for (a = 250; a >= 0; a--) {
      S(c, c);
      if(a !== 1) M(c, c, i);
  }
  for (a = 0; a < 16; a++) o[a] = c[a];
}

function crypto_scalarmult(q, n, p) {
  var z = new Uint8Array(32);
  var x = new Float64Array(80), r, i;
  var a = gf(), b = gf(), c = gf(),
      d = gf(), e = gf(), f = gf();
  for (i = 0; i < 31; i++) z[i] = n[i];
  z[31]=(n[31]&127)|64;
  z[0]&=248;
  unpack25519(x,p);
  for (i = 0; i < 16; i++) {
    b[i]=x[i];
    d[i]=a[i]=c[i]=0;
  }
  a[0]=d[0]=1;
  for (i=254; i>=0; --i) {
    r=(z[i>>>3]>>>(i&7))&1;
    sel25519(a,b,r);
    sel25519(c,d,r);
    A(e,a,c);
    Z(a,a,c);
    A(c,b,d);
    Z(b,b,d);
    S(d,e);
    S(f,a);
    M(a,c,a);
    M(c,b,e);
    A(e,a,c);
    Z(a,a,c);
    S(b,a);
    Z(c,d,f);
    M(a,c,_121665);
    A(a,a,d);
    M(c,c,a);
    M(a,d,f);
    M(d,b,x);
    S(b,e);
    sel25519(a,b,r);
    sel25519(c,d,r);
  }
  for (i = 0; i < 16; i++) {
    x[i+16]=a[i];
    x[i+32]=c[i];
    x[i+48]=b[i];
    x[i+64]=d[i];
  }
  var x32 = x.subarray(32);
  var x16 = x.subarray(16);
  inv25519(x32,x32);
  M(x16,x16,x32);
  pack25519(q,x16);
  return 0;
}

function crypto_scalarmult_base(q, n) {
  return crypto_scalarmult(q, n, _9);
}

function crypto_box_keypair(y, x) {
  randombytes(x, 32);
  return crypto_scalarmult_base(y, x);
}

function crypto_box_beforenm(k, y, x) {
  var s = new Uint8Array(32);
  crypto_scalarmult(s, x, y);
  return crypto_core_hsalsa20(k, _0, s, sigma);
}

var crypto_box_afternm = crypto_secretbox;
var crypto_box_open_afternm = crypto_secretbox_open;

function crypto_box(c, m, d, n, y, x) {
  var k = new Uint8Array(32);
  crypto_box_beforenm(k, y, x);
  return crypto_box_afternm(c, m, d, n, k);
}

function crypto_box_open(m, c, d, n, y, x) {
  var k = new Uint8Array(32);
  crypto_box_beforenm(k, y, x);
  return crypto_box_open_afternm(m, c, d, n, k);
}

var K = [
  0x428a2f98, 0xd728ae22, 0x71374491, 0x23ef65cd,
  0xb5c0fbcf, 0xec4d3b2f, 0xe9b5dba5, 0x8189dbbc,
  0x3956c25b, 0xf348b538, 0x59f111f1, 0xb605d019,
  0x923f82a4, 0xaf194f9b, 0xab1c5ed5, 0xda6d8118,
  0xd807aa98, 0xa3030242, 0x12835b01, 0x45706fbe,
  0x243185be, 0x4ee4b28c, 0x550c7dc3, 0xd5ffb4e2,
  0x72be5d74, 0xf27b896f, 0x80deb1fe, 0x3b1696b1,
  0x9bdc06a7, 0x25c71235, 0xc19bf174, 0xcf692694,
  0xe49b69c1, 0x9ef14ad2, 0xefbe4786, 0x384f25e3,
  0x0fc19dc6, 0x8b8cd5b5, 0x240ca1cc, 0x77ac9c65,
  0x2de92c6f, 0x592b0275, 0x4a7484aa, 0x6ea6e483,
  0x5cb0a9dc, 0xbd41fbd4, 0x76f988da, 0x831153b5,
  0x983e5152, 0xee66dfab, 0xa831c66d, 0x2db43210,
  0xb00327c8, 0x98fb213f, 0xbf597fc7, 0xbeef0ee4,
  0xc6e00bf3, 0x3da88fc2, 0xd5a79147, 0x930aa725,
  0x06ca6351, 0xe003826f, 0x14292967, 0x0a0e6e70,
  0x27b70a85, 0x46d22ffc, 0x2e1b2138, 0x5c26c926,
  0x4d2c6dfc, 0x5ac42aed, 0x53380d13, 0x9d95b3df,
  0x650a7354, 0x8baf63de, 0x766a0abb, 0x3c77b2a8,
  0x81c2c92e, 0x47edaee6, 0x92722c85, 0x1482353b,
  0xa2bfe8a1, 0x4cf10364, 0xa81a664b, 0xbc423001,
  0xc24b8b70, 0xd0f89791, 0xc76c51a3, 0x0654be30,
  0xd192e819, 0xd6ef5218, 0xd6990624, 0x5565a910,
  0xf40e3585, 0x5771202a, 0x106aa070, 0x32bbd1b8,
  0x19a4c116, 0xb8d2d0c8, 0x1e376c08, 0x5141ab53,
  0x2748774c, 0xdf8eeb99, 0x34b0bcb5, 0xe19b48a8,
  0x391c0cb3, 0xc5c95a63, 0x4ed8aa4a, 0xe3418acb,
  0x5b9cca4f, 0x7763e373, 0x682e6ff3, 0xd6b2b8a3,
  0x748f82ee, 0x5defb2fc, 0x78a5636f, 0x43172f60,
  0x84c87814, 0xa1f0ab72, 0x8cc70208, 0x1a6439ec,
  0x90befffa, 0x23631e28, 0xa4506ceb, 0xde82bde9,
  0xbef9a3f7, 0xb2c67915, 0xc67178f2, 0xe372532b,
  0xca273ece, 0xea26619c, 0xd186b8c7, 0x21c0c207,
  0xeada7dd6, 0xcde0eb1e, 0xf57d4f7f, 0xee6ed178,
  0x06f067aa, 0x72176fba, 0x0a637dc5, 0xa2c898a6,
  0x113f9804, 0xbef90dae, 0x1b710b35, 0x131c471b,
  0x28db77f5, 0x23047d84, 0x32caab7b, 0x40c72493,
  0x3c9ebe0a, 0x15c9bebc, 0x431d67c4, 0x9c100d4c,
  0x4cc5d4be, 0xcb3e42b6, 0x597f299c, 0xfc657e2a,
  0x5fcb6fab, 0x3ad6faec, 0x6c44198c, 0x4a475817
];

function crypto_hashblocks_hl(hh, hl, m, n) {
  var wh = new Int32Array(16), wl = new Int32Array(16),
      bh0, bh1, bh2, bh3, bh4, bh5, bh6, bh7,
      bl0, bl1, bl2, bl3, bl4, bl5, bl6, bl7,
      th, tl, i, j, h, l, a, b, c, d;

  var ah0 = hh[0],
      ah1 = hh[1],
      ah2 = hh[2],
      ah3 = hh[3],
      ah4 = hh[4],
      ah5 = hh[5],
      ah6 = hh[6],
      ah7 = hh[7],

      al0 = hl[0],
      al1 = hl[1],
      al2 = hl[2],
      al3 = hl[3],
      al4 = hl[4],
      al5 = hl[5],
      al6 = hl[6],
      al7 = hl[7];

  var pos = 0;
  while (n >= 128) {
    for (i = 0; i < 16; i++) {
      j = 8 * i + pos;
      wh[i] = (m[j+0] << 24) | (m[j+1] << 16) | (m[j+2] << 8) | m[j+3];
      wl[i] = (m[j+4] << 24) | (m[j+5] << 16) | (m[j+6] << 8) | m[j+7];
    }
    for (i = 0; i < 80; i++) {
      bh0 = ah0;
      bh1 = ah1;
      bh2 = ah2;
      bh3 = ah3;
      bh4 = ah4;
      bh5 = ah5;
      bh6 = ah6;
      bh7 = ah7;

      bl0 = al0;
      bl1 = al1;
      bl2 = al2;
      bl3 = al3;
      bl4 = al4;
      bl5 = al5;
      bl6 = al6;
      bl7 = al7;

      // add
      h = ah7;
      l = al7;

      a = l & 0xffff; b = l >>> 16;
      c = h & 0xffff; d = h >>> 16;

      // Sigma1
      h = ((ah4 >>> 14) | (al4 << (32-14))) ^ ((ah4 >>> 18) | (al4 << (32-18))) ^ ((al4 >>> (41-32)) | (ah4 << (32-(41-32))));
      l = ((al4 >>> 14) | (ah4 << (32-14))) ^ ((al4 >>> 18) | (ah4 << (32-18))) ^ ((ah4 >>> (41-32)) | (al4 << (32-(41-32))));

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      // Ch
      h = (ah4 & ah5) ^ (~ah4 & ah6);
      l = (al4 & al5) ^ (~al4 & al6);

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      // K
      h = K[i*2];
      l = K[i*2+1];

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      // w
      h = wh[i%16];
      l = wl[i%16];

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      b += a >>> 16;
      c += b >>> 16;
      d += c >>> 16;

      th = c & 0xffff | d << 16;
      tl = a & 0xffff | b << 16;

      // add
      h = th;
      l = tl;

      a = l & 0xffff; b = l >>> 16;
      c = h & 0xffff; d = h >>> 16;

      // Sigma0
      h = ((ah0 >>> 28) | (al0 << (32-28))) ^ ((al0 >>> (34-32)) | (ah0 << (32-(34-32)))) ^ ((al0 >>> (39-32)) | (ah0 << (32-(39-32))));
      l = ((al0 >>> 28) | (ah0 << (32-28))) ^ ((ah0 >>> (34-32)) | (al0 << (32-(34-32)))) ^ ((ah0 >>> (39-32)) | (al0 << (32-(39-32))));

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      // Maj
      h = (ah0 & ah1) ^ (ah0 & ah2) ^ (ah1 & ah2);
      l = (al0 & al1) ^ (al0 & al2) ^ (al1 & al2);

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      b += a >>> 16;
      c += b >>> 16;
      d += c >>> 16;

      bh7 = (c & 0xffff) | (d << 16);
      bl7 = (a & 0xffff) | (b << 16);

      // add
      h = bh3;
      l = bl3;

      a = l & 0xffff; b = l >>> 16;
      c = h & 0xffff; d = h >>> 16;

      h = th;
      l = tl;

      a += l & 0xffff; b += l >>> 16;
      c += h & 0xffff; d += h >>> 16;

      b += a >>> 16;
      c += b >>> 16;
      d += c >>> 16;

      bh3 = (c & 0xffff) | (d << 16);
      bl3 = (a & 0xffff) | (b << 16);

      ah1 = bh0;
      ah2 = bh1;
      ah3 = bh2;
      ah4 = bh3;
      ah5 = bh4;
      ah6 = bh5;
      ah7 = bh6;
      ah0 = bh7;

      al1 = bl0;
      al2 = bl1;
      al3 = bl2;
      al4 = bl3;
      al5 = bl4;
      al6 = bl5;
      al7 = bl6;
      al0 = bl7;

      if (i%16 === 15) {
        for (j = 0; j < 16; j++) {
          // add
          h = wh[j];
          l = wl[j];

          a = l & 0xffff; b = l >>> 16;
          c = h & 0xffff; d = h >>> 16;

          h = wh[(j+9)%16];
          l = wl[(j+9)%16];

          a += l & 0xffff; b += l >>> 16;
          c += h & 0xffff; d += h >>> 16;

          // sigma0
          th = wh[(j+1)%16];
          tl = wl[(j+1)%16];
          h = ((th >>> 1) | (tl << (32-1))) ^ ((th >>> 8) | (tl << (32-8))) ^ (th >>> 7);
          l = ((tl >>> 1) | (th << (32-1))) ^ ((tl >>> 8) | (th << (32-8))) ^ ((tl >>> 7) | (th << (32-7)));

          a += l & 0xffff; b += l >>> 16;
          c += h & 0xffff; d += h >>> 16;

          // sigma1
          th = wh[(j+14)%16];
          tl = wl[(j+14)%16];
          h = ((th >>> 19) | (tl << (32-19))) ^ ((tl >>> (61-32)) | (th << (32-(61-32)))) ^ (th >>> 6);
          l = ((tl >>> 19) | (th << (32-19))) ^ ((th >>> (61-32)) | (tl << (32-(61-32)))) ^ ((tl >>> 6) | (th << (32-6)));

          a += l & 0xffff; b += l >>> 16;
          c += h & 0xffff; d += h >>> 16;

          b += a >>> 16;
          c += b >>> 16;
          d += c >>> 16;

          wh[j] = (c & 0xffff) | (d << 16);
          wl[j] = (a & 0xffff) | (b << 16);
        }
      }
    }

    // add
    h = ah0;
    l = al0;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[0];
    l = hl[0];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[0] = ah0 = (c & 0xffff) | (d << 16);
    hl[0] = al0 = (a & 0xffff) | (b << 16);

    h = ah1;
    l = al1;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[1];
    l = hl[1];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[1] = ah1 = (c & 0xffff) | (d << 16);
    hl[1] = al1 = (a & 0xffff) | (b << 16);

    h = ah2;
    l = al2;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[2];
    l = hl[2];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[2] = ah2 = (c & 0xffff) | (d << 16);
    hl[2] = al2 = (a & 0xffff) | (b << 16);

    h = ah3;
    l = al3;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[3];
    l = hl[3];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[3] = ah3 = (c & 0xffff) | (d << 16);
    hl[3] = al3 = (a & 0xffff) | (b << 16);

    h = ah4;
    l = al4;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[4];
    l = hl[4];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[4] = ah4 = (c & 0xffff) | (d << 16);
    hl[4] = al4 = (a & 0xffff) | (b << 16);

    h = ah5;
    l = al5;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[5];
    l = hl[5];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[5] = ah5 = (c & 0xffff) | (d << 16);
    hl[5] = al5 = (a & 0xffff) | (b << 16);

    h = ah6;
    l = al6;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[6];
    l = hl[6];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[6] = ah6 = (c & 0xffff) | (d << 16);
    hl[6] = al6 = (a & 0xffff) | (b << 16);

    h = ah7;
    l = al7;

    a = l & 0xffff; b = l >>> 16;
    c = h & 0xffff; d = h >>> 16;

    h = hh[7];
    l = hl[7];

    a += l & 0xffff; b += l >>> 16;
    c += h & 0xffff; d += h >>> 16;

    b += a >>> 16;
    c += b >>> 16;
    d += c >>> 16;

    hh[7] = ah7 = (c & 0xffff) | (d << 16);
    hl[7] = al7 = (a & 0xffff) | (b << 16);

    pos += 128;
    n -= 128;
  }

  return n;
}

function crypto_hash(out, m, n) {
  var hh = new Int32Array(8),
      hl = new Int32Array(8),
      x = new Uint8Array(256),
      i, b = n;

  hh[0] = 0x6a09e667;
  hh[1] = 0xbb67ae85;
  hh[2] = 0x3c6ef372;
  hh[3] = 0xa54ff53a;
  hh[4] = 0x510e527f;
  hh[5] = 0x9b05688c;
  hh[6] = 0x1f83d9ab;
  hh[7] = 0x5be0cd19;

  hl[0] = 0xf3bcc908;
  hl[1] = 0x84caa73b;
  hl[2] = 0xfe94f82b;
  hl[3] = 0x5f1d36f1;
  hl[4] = 0xade682d1;
  hl[5] = 0x2b3e6c1f;
  hl[6] = 0xfb41bd6b;
  hl[7] = 0x137e2179;

  crypto_hashblocks_hl(hh, hl, m, n);
  n %= 128;

  for (i = 0; i < n; i++) x[i] = m[b-n+i];
  x[n] = 128;

  n = 256-128*(n<112?1:0);
  x[n-9] = 0;
  ts64(x, n-8,  (b / 0x20000000) | 0, b << 3);
  crypto_hashblocks_hl(hh, hl, x, n);

  for (i = 0; i < 8; i++) ts64(out, 8*i, hh[i], hl[i]);

  return 0;
}

function add(p, q) {
  var a = gf(), b = gf(), c = gf(),
      d = gf(), e = gf(), f = gf(),
      g = gf(), h = gf(), t = gf();

  Z(a, p[1], p[0]);
  Z(t, q[1], q[0]);
  M(a, a, t);
  A(b, p[0], p[1]);
  A(t, q[0], q[1]);
  M(b, b, t);
  M(c, p[3], q[3]);
  M(c, c, D2);
  M(d, p[2], q[2]);
  A(d, d, d);
  Z(e, b, a);
  Z(f, d, c);
  A(g, d, c);
  A(h, b, a);

  M(p[0], e, f);
  M(p[1], h, g);
  M(p[2], g, f);
  M(p[3], e, h);
}

function cswap(p, q, b) {
  var i;
  for (i = 0; i < 4; i++) {
    sel25519(p[i], q[i], b);
  }
}

function pack(r, p) {
  var tx = gf(), ty = gf(), zi = gf();
  inv25519(zi, p[2]);
  M(tx, p[0], zi);
  M(ty, p[1], zi);
  pack25519(r, ty);
  r[31] ^= par25519(tx) << 7;
}

function scalarmult(p, q, s) {
  var b, i;
  set25519(p[0], gf0);
  set25519(p[1], gf1);
  set25519(p[2], gf1);
  set25519(p[3], gf0);
  for (i = 255; i >= 0; --i) {
    b = (s[(i/8)|0] >> (i&7)) & 1;
    cswap(p, q, b);
    add(q, p);
    add(p, p);
    cswap(p, q, b);
  }
}

function scalarbase(p, s) {
  var q = [gf(), gf(), gf(), gf()];
  set25519(q[0], X);
  set25519(q[1], Y);
  set25519(q[2], gf1);
  M(q[3], X, Y);
  scalarmult(p, q, s);
}

function crypto_sign_keypair(pk, sk, seeded) {
  var d = new Uint8Array(64);
  var p = [gf(), gf(), gf(), gf()];
  var i;

  if (!seeded) randombytes(sk, 32);
  crypto_hash(d, sk, 32);
  d[0] &= 248;
  d[31] &= 127;
  d[31] |= 64;

  scalarbase(p, d);
  pack(pk, p);

  for (i = 0; i < 32; i++) sk[i+32] = pk[i];
  return 0;
}

var L = new Float64Array([0xed, 0xd3, 0xf5, 0x5c, 0x1a, 0x63, 0x12, 0x58, 0xd6, 0x9c, 0xf7, 0xa2, 0xde, 0xf9, 0xde, 0x14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x10]);

function modL(r, x) {
  var carry, i, j, k;
  for (i = 63; i >= 32; --i) {
    carry = 0;
    for (j = i - 32, k = i - 12; j < k; ++j) {
      x[j] += carry - 16 * x[i] * L[j - (i - 32)];
      carry = (x[j] + 128) >> 8;
      x[j] -= carry * 256;
    }
    x[j] += carry;
    x[i] = 0;
  }
  carry = 0;
  for (j = 0; j < 32; j++) {
    x[j] += carry - (x[31] >> 4) * L[j];
    carry = x[j] >> 8;
    x[j] &= 255;
  }
  for (j = 0; j < 32; j++) x[j] -= carry * L[j];
  for (i = 0; i < 32; i++) {
    x[i+1] += x[i] >> 8;
    r[i] = x[i] & 255;
  }
}

function reduce(r) {
  var x = new Float64Array(64), i;
  for (i = 0; i < 64; i++) x[i] = r[i];
  for (i = 0; i < 64; i++) r[i] = 0;
  modL(r, x);
}

// Note: difference from C - smlen returned, not passed as argument.
function crypto_sign(sm, m, n, sk) {
  var d = new Uint8Array(64), h = new Uint8Array(64), r = new Uint8Array(64);
  var i, j, x = new Float64Array(64);
  var p = [gf(), gf(), gf(), gf()];

  crypto_hash(d, sk, 32);
  d[0] &= 248;
  d[31] &= 127;
  d[31] |= 64;

  var smlen = n + 64;
  for (i = 0; i < n; i++) sm[64 + i] = m[i];
  for (i = 0; i < 32; i++) sm[32 + i] = d[32 + i];

  crypto_hash(r, sm.subarray(32), n+32);
  reduce(r);
  scalarbase(p, r);
  pack(sm, p);

  for (i = 32; i < 64; i++) sm[i] = sk[i];
  crypto_hash(h, sm, n + 64);
  reduce(h);

  for (i = 0; i < 64; i++) x[i] = 0;
  for (i = 0; i < 32; i++) x[i] = r[i];
  for (i = 0; i < 32; i++) {
    for (j = 0; j < 32; j++) {
      x[i+j] += h[i] * d[j];
    }
  }

  modL(sm.subarray(32), x);
  return smlen;
}

function unpackneg(r, p) {
  var t = gf(), chk = gf(), num = gf(),
      den = gf(), den2 = gf(), den4 = gf(),
      den6 = gf();

  set25519(r[2], gf1);
  unpack25519(r[1], p);
  S(num, r[1]);
  M(den, num, D);
  Z(num, num, r[2]);
  A(den, r[2], den);

  S(den2, den);
  S(den4, den2);
  M(den6, den4, den2);
  M(t, den6, num);
  M(t, t, den);

  pow2523(t, t);
  M(t, t, num);
  M(t, t, den);
  M(t, t, den);
  M(r[0], t, den);

  S(chk, r[0]);
  M(chk, chk, den);
  if (neq25519(chk, num)) M(r[0], r[0], I);

  S(chk, r[0]);
  M(chk, chk, den);
  if (neq25519(chk, num)) return -1;

  if (par25519(r[0]) === (p[31]>>7)) Z(r[0], gf0, r[0]);

  M(r[3], r[0], r[1]);
  return 0;
}

function crypto_sign_open(m, sm, n, pk) {
  var i, mlen;
  var t = new Uint8Array(32), h = new Uint8Array(64);
  var p = [gf(), gf(), gf(), gf()],
      q = [gf(), gf(), gf(), gf()];

  mlen = -1;
  if (n < 64) return -1;

  if (unpackneg(q, pk)) return -1;

  for (i = 0; i < n; i++) m[i] = sm[i];
  for (i = 0; i < 32; i++) m[i+32] = pk[i];
  crypto_hash(h, m, n);
  reduce(h);
  scalarmult(p, q, h);

  scalarbase(q, sm.subarray(32));
  add(p, q);
  pack(t, p);

  n -= 64;
  if (crypto_verify_32(sm, 0, t, 0)) {
    for (i = 0; i < n; i++) m[i] = 0;
    return -1;
  }

  for (i = 0; i < n; i++) m[i] = sm[i + 64];
  mlen = n;
  return mlen;
}

var crypto_secretbox_KEYBYTES = 32,
    crypto_secretbox_NONCEBYTES = 24,
    crypto_secretbox_ZEROBYTES = 32,
    crypto_secretbox_BOXZEROBYTES = 16,
    crypto_scalarmult_BYTES = 32,
    crypto_scalarmult_SCALARBYTES = 32,
    crypto_box_PUBLICKEYBYTES = 32,
    crypto_box_SECRETKEYBYTES = 32,
    crypto_box_BEFORENMBYTES = 32,
    crypto_box_NONCEBYTES = crypto_secretbox_NONCEBYTES,
    crypto_box_ZEROBYTES = crypto_secretbox_ZEROBYTES,
    crypto_box_BOXZEROBYTES = crypto_secretbox_BOXZEROBYTES,
    crypto_sign_BYTES = 64,
    crypto_sign_PUBLICKEYBYTES = 32,
    crypto_sign_SECRETKEYBYTES = 64,
    crypto_sign_SEEDBYTES = 32,
    crypto_hash_BYTES = 64;

nacl.lowlevel = {
  crypto_core_hsalsa20: crypto_core_hsalsa20,
  crypto_stream_xor: crypto_stream_xor,
  crypto_stream: crypto_stream,
  crypto_stream_salsa20_xor: crypto_stream_salsa20_xor,
  crypto_stream_salsa20: crypto_stream_salsa20,
  crypto_onetimeauth: crypto_onetimeauth,
  crypto_onetimeauth_verify: crypto_onetimeauth_verify,
  crypto_verify_16: crypto_verify_16,
  crypto_verify_32: crypto_verify_32,
  crypto_secretbox: crypto_secretbox,
  crypto_secretbox_open: crypto_secretbox_open,
  crypto_scalarmult: crypto_scalarmult,
  crypto_scalarmult_base: crypto_scalarmult_base,
  crypto_box_beforenm: crypto_box_beforenm,
  crypto_box_afternm: crypto_box_afternm,
  crypto_box: crypto_box,
  crypto_box_open: crypto_box_open,
  crypto_box_keypair: crypto_box_keypair,
  crypto_hash: crypto_hash,
  crypto_sign: crypto_sign,
  crypto_sign_keypair: crypto_sign_keypair,
  crypto_sign_open: crypto_sign_open,

  crypto_secretbox_KEYBYTES: crypto_secretbox_KEYBYTES,
  crypto_secretbox_NONCEBYTES: crypto_secretbox_NONCEBYTES,
  crypto_secretbox_ZEROBYTES: crypto_secretbox_ZEROBYTES,
  crypto_secretbox_BOXZEROBYTES: crypto_secretbox_BOXZEROBYTES,
  crypto_scalarmult_BYTES: crypto_scalarmult_BYTES,
  crypto_scalarmult_SCALARBYTES: crypto_scalarmult_SCALARBYTES,
  crypto_box_PUBLICKEYBYTES: crypto_box_PUBLICKEYBYTES,
  crypto_box_SECRETKEYBYTES: crypto_box_SECRETKEYBYTES,
  crypto_box_BEFORENMBYTES: crypto_box_BEFORENMBYTES,
  crypto_box_NONCEBYTES: crypto_box_NONCEBYTES,
  crypto_box_ZEROBYTES: crypto_box_ZEROBYTES,
  crypto_box_BOXZEROBYTES: crypto_box_BOXZEROBYTES,
  crypto_sign_BYTES: crypto_sign_BYTES,
  crypto_sign_PUBLICKEYBYTES: crypto_sign_PUBLICKEYBYTES,
  crypto_sign_SECRETKEYBYTES: crypto_sign_SECRETKEYBYTES,
  crypto_sign_SEEDBYTES: crypto_sign_SEEDBYTES,
  crypto_hash_BYTES: crypto_hash_BYTES
};

/* High-level API */

function checkLengths(k, n) {
  if (k.length !== crypto_secretbox_KEYBYTES) throw new Error('bad key size');
  if (n.length !== crypto_secretbox_NONCEBYTES) throw new Error('bad nonce size');
}

function checkBoxLengths(pk, sk) {
  if (pk.length !== crypto_box_PUBLICKEYBYTES) throw new Error('bad public key size');
  if (sk.length !== crypto_box_SECRETKEYBYTES) throw new Error('bad secret key size');
}

function checkArrayTypes() {
  for (var i = 0; i < arguments.length; i++) {
    if (!(arguments[i] instanceof Uint8Array))
      throw new TypeError('unexpected type, use Uint8Array');
  }
}

function cleanup(arr) {
  for (var i = 0; i < arr.length; i++) arr[i] = 0;
}

nacl.randomBytes = function(n) {
  var b = new Uint8Array(n);
  randombytes(b, n);
  return b;
};

nacl.secretbox = function(msg, nonce, key) {
  checkArrayTypes(msg, nonce, key);
  checkLengths(key, nonce);
  var m = new Uint8Array(crypto_secretbox_ZEROBYTES + msg.length);
  var c = new Uint8Array(m.length);
  for (var i = 0; i < msg.length; i++) m[i+crypto_secretbox_ZEROBYTES] = msg[i];
  crypto_secretbox(c, m, m.length, nonce, key);
  return c.subarray(crypto_secretbox_BOXZEROBYTES);
};

nacl.secretbox.open = function(box, nonce, key) {
  checkArrayTypes(box, nonce, key);
  checkLengths(key, nonce);
  var c = new Uint8Array(crypto_secretbox_BOXZEROBYTES + box.length);
  var m = new Uint8Array(c.length);
  for (var i = 0; i < box.length; i++) c[i+crypto_secretbox_BOXZEROBYTES] = box[i];
  if (c.length < 32) return null;
  if (crypto_secretbox_open(m, c, c.length, nonce, key) !== 0) return null;
  return m.subarray(crypto_secretbox_ZEROBYTES);
};

nacl.secretbox.keyLength = crypto_secretbox_KEYBYTES;
nacl.secretbox.nonceLength = crypto_secretbox_NONCEBYTES;
nacl.secretbox.overheadLength = crypto_secretbox_BOXZEROBYTES;

nacl.scalarMult = function(n, p) {
  checkArrayTypes(n, p);
  if (n.length !== crypto_scalarmult_SCALARBYTES) throw new Error('bad n size');
  if (p.length !== crypto_scalarmult_BYTES) throw new Error('bad p size');
  var q = new Uint8Array(crypto_scalarmult_BYTES);
  crypto_scalarmult(q, n, p);
  return q;
};

nacl.scalarMult.base = function(n) {
  checkArrayTypes(n);
  if (n.length !== crypto_scalarmult_SCALARBYTES) throw new Error('bad n size');
  var q = new Uint8Array(crypto_scalarmult_BYTES);
  crypto_scalarmult_base(q, n);
  return q;
};

nacl.scalarMult.scalarLength = crypto_scalarmult_SCALARBYTES;
nacl.scalarMult.groupElementLength = crypto_scalarmult_BYTES;

nacl.box = function(msg, nonce, publicKey, secretKey) {
  var k = nacl.box.before(publicKey, secretKey);
  return nacl.secretbox(msg, nonce, k);
};

nacl.box.before = function(publicKey, secretKey) {
  checkArrayTypes(publicKey, secretKey);
  checkBoxLengths(publicKey, secretKey);
  var k = new Uint8Array(crypto_box_BEFORENMBYTES);
  crypto_box_beforenm(k, publicKey, secretKey);
  return k;
};

nacl.box.after = nacl.secretbox;

nacl.box.open = function(msg, nonce, publicKey, secretKey) {
  var k = nacl.box.before(publicKey, secretKey);
  return nacl.secretbox.open(msg, nonce, k);
};

nacl.box.open.after = nacl.secretbox.open;

nacl.box.keyPair = function() {
  var pk = new Uint8Array(crypto_box_PUBLICKEYBYTES);
  var sk = new Uint8Array(crypto_box_SECRETKEYBYTES);
  crypto_box_keypair(pk, sk);
  return {publicKey: pk, secretKey: sk};
};

nacl.box.keyPair.fromSecretKey = function(secretKey) {
  checkArrayTypes(secretKey);
  if (secretKey.length !== crypto_box_SECRETKEYBYTES)
    throw new Error('bad secret key size');
  var pk = new Uint8Array(crypto_box_PUBLICKEYBYTES);
  crypto_scalarmult_base(pk, secretKey);
  return {publicKey: pk, secretKey: new Uint8Array(secretKey)};
};

nacl.box.publicKeyLength = crypto_box_PUBLICKEYBYTES;
nacl.box.secretKeyLength = crypto_box_SECRETKEYBYTES;
nacl.box.sharedKeyLength = crypto_box_BEFORENMBYTES;
nacl.box.nonceLength = crypto_box_NONCEBYTES;
nacl.box.overheadLength = nacl.secretbox.overheadLength;

nacl.sign = function(msg, secretKey) {
  checkArrayTypes(msg, secretKey);
  if (secretKey.length !== crypto_sign_SECRETKEYBYTES)
    throw new Error('bad secret key size');
  var signedMsg = new Uint8Array(crypto_sign_BYTES+msg.length);
  crypto_sign(signedMsg, msg, msg.length, secretKey);
  return signedMsg;
};

nacl.sign.open = function(signedMsg, publicKey) {
  checkArrayTypes(signedMsg, publicKey);
  if (publicKey.length !== crypto_sign_PUBLICKEYBYTES)
    throw new Error('bad public key size');
  var tmp = new Uint8Array(signedMsg.length);
  var mlen = crypto_sign_open(tmp, signedMsg, signedMsg.length, publicKey);
  if (mlen < 0) return null;
  var m = new Uint8Array(mlen);
  for (var i = 0; i < m.length; i++) m[i] = tmp[i];
  return m;
};

nacl.sign.detached = function(msg, secretKey) {
  var signedMsg = nacl.sign(msg, secretKey);
  var sig = new Uint8Array(crypto_sign_BYTES);
  for (var i = 0; i < sig.length; i++) sig[i] = signedMsg[i];
  return sig;
};

nacl.sign.detached.verify = function(msg, sig, publicKey) {
  checkArrayTypes(msg, sig, publicKey);
  if (sig.length !== crypto_sign_BYTES)
    throw new Error('bad signature size');
  if (publicKey.length !== crypto_sign_PUBLICKEYBYTES)
    throw new Error('bad public key size');
  var sm = new Uint8Array(crypto_sign_BYTES + msg.length);
  var m = new Uint8Array(crypto_sign_BYTES + msg.length);
  var i;
  for (i = 0; i < crypto_sign_BYTES; i++) sm[i] = sig[i];
  for (i = 0; i < msg.length; i++) sm[i+crypto_sign_BYTES] = msg[i];
  return (crypto_sign_open(m, sm, sm.length, publicKey) >= 0);
};

nacl.sign.keyPair = function() {
  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);
  var sk = new Uint8Array(crypto_sign_SECRETKEYBYTES);
  crypto_sign_keypair(pk, sk);
  return {publicKey: pk, secretKey: sk};
};

nacl.sign.keyPair.fromSecretKey = function(secretKey) {
  checkArrayTypes(secretKey);
  if (secretKey.length !== crypto_sign_SECRETKEYBYTES)
    throw new Error('bad secret key size');
  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);
  for (var i = 0; i < pk.length; i++) pk[i] = secretKey[32+i];
  return {publicKey: pk, secretKey: new Uint8Array(secretKey)};
};

nacl.sign.keyPair.fromSeed = function(seed) {
  checkArrayTypes(seed);
  if (seed.length !== crypto_sign_SEEDBYTES)
    throw new Error('bad seed size');
  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);
  var sk = new Uint8Array(crypto_sign_SECRETKEYBYTES);
  for (var i = 0; i < 32; i++) sk[i] = seed[i];
  crypto_sign_keypair(pk, sk, true);
  return {publicKey: pk, secretKey: sk};
};

nacl.sign.publicKeyLength = crypto_sign_PUBLICKEYBYTES;
nacl.sign.secretKeyLength = crypto_sign_SECRETKEYBYTES;
nacl.sign.seedLength = crypto_sign_SEEDBYTES;
nacl.sign.signatureLength = crypto_sign_BYTES;

nacl.hash = function(msg) {
  checkArrayTypes(msg);
  var h = new Uint8Array(crypto_hash_BYTES);
  crypto_hash(h, msg, msg.length);
  return h;
};

nacl.hash.hashLength = crypto_hash_BYTES;

nacl.verify = function(x, y) {
  checkArrayTypes(x, y);
  // Zero length arguments are considered not equal.
  if (x.length === 0 || y.length === 0) return false;
  if (x.length !== y.length) return false;
  return (vn(x, 0, y, 0, x.length) === 0) ? true : false;
};

nacl.setPRNG = function(fn) {
  randombytes = fn;
};

(function() {
  // Initialize PRNG if environment provides CSPRNG.
  // If not, methods calling randombytes will throw.
  var crypto = typeof self !== 'undefined' ? (self.crypto || self.msCrypto) : null;
  if (crypto && crypto.getRandomValues) {
    // Browsers.
    var QUOTA = 65536;
    nacl.setPRNG(function(x, n) {
      var i, v = new Uint8Array(n);
      for (i = 0; i < n; i += QUOTA) {
        crypto.getRandomValues(v.subarray(i, i + Math.min(n - i, QUOTA)));
      }
      for (i = 0; i < n; i++) x[i] = v[i];
      cleanup(v);
    });
  } else if (typeof require !== 'undefined') {
    // Node.js.
    crypto = require('crypto');
    if (crypto && crypto.randomBytes) {
      nacl.setPRNG(function(x, n) {
        var i, v = crypto.randomBytes(n);
        for (i = 0; i < n; i++) x[i] = v[i];
        cleanup(v);
      });
    }
  }
})();

})(typeof module !== 'undefined' && module.exports ? module.exports : (self.nacl = self.nacl || {}));

},{"crypto":18}],63:[function(require,module,exports){
arguments[4][28][0].apply(exports,arguments)
},{"./lib":66,"dup":28}],64:[function(require,module,exports){
var cache = function (fn) {
    var called = false,
        store;

    if (!(fn instanceof Function)) {
        called = true;
        store = fn;
        delete(fn);
    }

    return function () {
        if (!called) {
            called = true;
            store = fn.apply(this, arguments);
            delete(fn);
        }
        return store;
    };
};

module.exports = cache;
},{}],65:[function(require,module,exports){
module.exports = function eachCombination(alternativesByDimension, callback, combination) {
    if (!combination)
        combination = [];
    if (combination.length < alternativesByDimension.length) {
        var alternatives = alternativesByDimension[combination.length];
        for (var index in alternatives) {
            combination[combination.length] = alternatives[index];
            eachCombination(alternativesByDimension, callback, combination);
            --combination.length;
        }
    }
    else
        callback.apply(null, combination);
};
},{}],66:[function(require,module,exports){
module.exports = {
    cache: require("./cache"),
    eachCombination: require("./eachCombination")
};
},{"./cache":64,"./eachCombination":65}],67:[function(require,module,exports){
/*eslint-disable block-scoped-var, id-length, no-control-regex, no-magic-numbers, no-prototype-builtins, no-redeclare, no-shadow, no-var, sort-vars*/
"use strict";

var $protobuf = require("protobufjs/minimal");

// Common aliases
var $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;

// Exported root namespace
var $root = $protobuf.roots["default"] || ($protobuf.roots["default"] = {});

$root.CreateAccountTransaction = (function() {

    /**
     * Properties of a CreateAccountTransaction.
     * @exports ICreateAccountTransaction
     * @interface ICreateAccountTransaction
     * @property {number|Long|null} [nonce] CreateAccountTransaction nonce
     * @property {string|null} [originator] CreateAccountTransaction originator
     * @property {string|null} [newAccountId] CreateAccountTransaction newAccountId
     * @property {number|Long|null} [amount] CreateAccountTransaction amount
     * @property {Uint8Array|null} [publicKey] CreateAccountTransaction publicKey
     */

    /**
     * Constructs a new CreateAccountTransaction.
     * @exports CreateAccountTransaction
     * @classdesc Represents a CreateAccountTransaction.
     * @implements ICreateAccountTransaction
     * @constructor
     * @param {ICreateAccountTransaction=} [properties] Properties to set
     */
    function CreateAccountTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * CreateAccountTransaction nonce.
     * @member {number|Long} nonce
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * CreateAccountTransaction originator.
     * @member {string} originator
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.originator = "";

    /**
     * CreateAccountTransaction newAccountId.
     * @member {string} newAccountId
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.newAccountId = "";

    /**
     * CreateAccountTransaction amount.
     * @member {number|Long} amount
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * CreateAccountTransaction publicKey.
     * @member {Uint8Array} publicKey
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.publicKey = $util.newBuffer([]);

    /**
     * Creates a new CreateAccountTransaction instance using the specified properties.
     * @function create
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction=} [properties] Properties to set
     * @returns {CreateAccountTransaction} CreateAccountTransaction instance
     */
    CreateAccountTransaction.create = function create(properties) {
        return new CreateAccountTransaction(properties);
    };

    /**
     * Encodes the specified CreateAccountTransaction message. Does not implicitly {@link CreateAccountTransaction.verify|verify} messages.
     * @function encode
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction} message CreateAccountTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    CreateAccountTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.newAccountId);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 4, wireType 0 =*/32).uint64(message.amount);
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            writer.uint32(/* id 5, wireType 2 =*/42).bytes(message.publicKey);
        return writer;
    };

    /**
     * Encodes the specified CreateAccountTransaction message, length delimited. Does not implicitly {@link CreateAccountTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction} message CreateAccountTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    CreateAccountTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a CreateAccountTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof CreateAccountTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    CreateAccountTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.CreateAccountTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.newAccountId = reader.string();
                break;
            case 4:
                message.amount = reader.uint64();
                break;
            case 5:
                message.publicKey = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a CreateAccountTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof CreateAccountTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    CreateAccountTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a CreateAccountTransaction message.
     * @function verify
     * @memberof CreateAccountTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    CreateAccountTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            if (!$util.isString(message.newAccountId))
                return "newAccountId: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            if (!(message.publicKey && typeof message.publicKey.length === "number" || $util.isString(message.publicKey)))
                return "publicKey: buffer expected";
        return null;
    };

    /**
     * Creates a CreateAccountTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof CreateAccountTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     */
    CreateAccountTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.CreateAccountTransaction)
            return object;
        var message = new $root.CreateAccountTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.newAccountId != null)
            message.newAccountId = String(object.newAccountId);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        if (object.publicKey != null)
            if (typeof object.publicKey === "string")
                $util.base64.decode(object.publicKey, message.publicKey = $util.newBuffer($util.base64.length(object.publicKey)), 0);
            else if (object.publicKey.length)
                message.publicKey = object.publicKey;
        return message;
    };

    /**
     * Creates a plain object from a CreateAccountTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof CreateAccountTransaction
     * @static
     * @param {CreateAccountTransaction} message CreateAccountTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    CreateAccountTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.newAccountId = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
            if (options.bytes === String)
                object.publicKey = "";
            else {
                object.publicKey = [];
                if (options.bytes !== Array)
                    object.publicKey = $util.newBuffer(object.publicKey);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            object.newAccountId = message.newAccountId;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            object.publicKey = options.bytes === String ? $util.base64.encode(message.publicKey, 0, message.publicKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.publicKey) : message.publicKey;
        return object;
    };

    /**
     * Converts this CreateAccountTransaction to JSON.
     * @function toJSON
     * @memberof CreateAccountTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    CreateAccountTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return CreateAccountTransaction;
})();

$root.DeployContractTransaction = (function() {

    /**
     * Properties of a DeployContractTransaction.
     * @exports IDeployContractTransaction
     * @interface IDeployContractTransaction
     * @property {number|Long|null} [nonce] DeployContractTransaction nonce
     * @property {string|null} [contractId] DeployContractTransaction contractId
     * @property {Uint8Array|null} [wasmByteArray] DeployContractTransaction wasmByteArray
     */

    /**
     * Constructs a new DeployContractTransaction.
     * @exports DeployContractTransaction
     * @classdesc Represents a DeployContractTransaction.
     * @implements IDeployContractTransaction
     * @constructor
     * @param {IDeployContractTransaction=} [properties] Properties to set
     */
    function DeployContractTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * DeployContractTransaction nonce.
     * @member {number|Long} nonce
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * DeployContractTransaction contractId.
     * @member {string} contractId
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.contractId = "";

    /**
     * DeployContractTransaction wasmByteArray.
     * @member {Uint8Array} wasmByteArray
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.wasmByteArray = $util.newBuffer([]);

    /**
     * Creates a new DeployContractTransaction instance using the specified properties.
     * @function create
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction=} [properties] Properties to set
     * @returns {DeployContractTransaction} DeployContractTransaction instance
     */
    DeployContractTransaction.create = function create(properties) {
        return new DeployContractTransaction(properties);
    };

    /**
     * Encodes the specified DeployContractTransaction message. Does not implicitly {@link DeployContractTransaction.verify|verify} messages.
     * @function encode
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction} message DeployContractTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeployContractTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.contractId);
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.wasmByteArray);
        return writer;
    };

    /**
     * Encodes the specified DeployContractTransaction message, length delimited. Does not implicitly {@link DeployContractTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction} message DeployContractTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeployContractTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a DeployContractTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof DeployContractTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {DeployContractTransaction} DeployContractTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeployContractTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.DeployContractTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.contractId = reader.string();
                break;
            case 3:
                message.wasmByteArray = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a DeployContractTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof DeployContractTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {DeployContractTransaction} DeployContractTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeployContractTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a DeployContractTransaction message.
     * @function verify
     * @memberof DeployContractTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    DeployContractTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            if (!$util.isString(message.contractId))
                return "contractId: string expected";
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            if (!(message.wasmByteArray && typeof message.wasmByteArray.length === "number" || $util.isString(message.wasmByteArray)))
                return "wasmByteArray: buffer expected";
        return null;
    };

    /**
     * Creates a DeployContractTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof DeployContractTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {DeployContractTransaction} DeployContractTransaction
     */
    DeployContractTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.DeployContractTransaction)
            return object;
        var message = new $root.DeployContractTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.contractId != null)
            message.contractId = String(object.contractId);
        if (object.wasmByteArray != null)
            if (typeof object.wasmByteArray === "string")
                $util.base64.decode(object.wasmByteArray, message.wasmByteArray = $util.newBuffer($util.base64.length(object.wasmByteArray)), 0);
            else if (object.wasmByteArray.length)
                message.wasmByteArray = object.wasmByteArray;
        return message;
    };

    /**
     * Creates a plain object from a DeployContractTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof DeployContractTransaction
     * @static
     * @param {DeployContractTransaction} message DeployContractTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    DeployContractTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.contractId = "";
            if (options.bytes === String)
                object.wasmByteArray = "";
            else {
                object.wasmByteArray = [];
                if (options.bytes !== Array)
                    object.wasmByteArray = $util.newBuffer(object.wasmByteArray);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            object.contractId = message.contractId;
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            object.wasmByteArray = options.bytes === String ? $util.base64.encode(message.wasmByteArray, 0, message.wasmByteArray.length) : options.bytes === Array ? Array.prototype.slice.call(message.wasmByteArray) : message.wasmByteArray;
        return object;
    };

    /**
     * Converts this DeployContractTransaction to JSON.
     * @function toJSON
     * @memberof DeployContractTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    DeployContractTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return DeployContractTransaction;
})();

$root.FunctionCallTransaction = (function() {

    /**
     * Properties of a FunctionCallTransaction.
     * @exports IFunctionCallTransaction
     * @interface IFunctionCallTransaction
     * @property {number|Long|null} [nonce] FunctionCallTransaction nonce
     * @property {string|null} [originator] FunctionCallTransaction originator
     * @property {string|null} [contractId] FunctionCallTransaction contractId
     * @property {Uint8Array|null} [methodName] FunctionCallTransaction methodName
     * @property {Uint8Array|null} [args] FunctionCallTransaction args
     * @property {number|Long|null} [amount] FunctionCallTransaction amount
     */

    /**
     * Constructs a new FunctionCallTransaction.
     * @exports FunctionCallTransaction
     * @classdesc Represents a FunctionCallTransaction.
     * @implements IFunctionCallTransaction
     * @constructor
     * @param {IFunctionCallTransaction=} [properties] Properties to set
     */
    function FunctionCallTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * FunctionCallTransaction nonce.
     * @member {number|Long} nonce
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * FunctionCallTransaction originator.
     * @member {string} originator
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.originator = "";

    /**
     * FunctionCallTransaction contractId.
     * @member {string} contractId
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.contractId = "";

    /**
     * FunctionCallTransaction methodName.
     * @member {Uint8Array} methodName
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.methodName = $util.newBuffer([]);

    /**
     * FunctionCallTransaction args.
     * @member {Uint8Array} args
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.args = $util.newBuffer([]);

    /**
     * FunctionCallTransaction amount.
     * @member {number|Long} amount
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * Creates a new FunctionCallTransaction instance using the specified properties.
     * @function create
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction=} [properties] Properties to set
     * @returns {FunctionCallTransaction} FunctionCallTransaction instance
     */
    FunctionCallTransaction.create = function create(properties) {
        return new FunctionCallTransaction(properties);
    };

    /**
     * Encodes the specified FunctionCallTransaction message. Does not implicitly {@link FunctionCallTransaction.verify|verify} messages.
     * @function encode
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction} message FunctionCallTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    FunctionCallTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.contractId);
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            writer.uint32(/* id 4, wireType 2 =*/34).bytes(message.methodName);
        if (message.args != null && message.hasOwnProperty("args"))
            writer.uint32(/* id 5, wireType 2 =*/42).bytes(message.args);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 6, wireType 0 =*/48).uint64(message.amount);
        return writer;
    };

    /**
     * Encodes the specified FunctionCallTransaction message, length delimited. Does not implicitly {@link FunctionCallTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction} message FunctionCallTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    FunctionCallTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a FunctionCallTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof FunctionCallTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    FunctionCallTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.FunctionCallTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.contractId = reader.string();
                break;
            case 4:
                message.methodName = reader.bytes();
                break;
            case 5:
                message.args = reader.bytes();
                break;
            case 6:
                message.amount = reader.uint64();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a FunctionCallTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof FunctionCallTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    FunctionCallTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a FunctionCallTransaction message.
     * @function verify
     * @memberof FunctionCallTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    FunctionCallTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            if (!$util.isString(message.contractId))
                return "contractId: string expected";
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            if (!(message.methodName && typeof message.methodName.length === "number" || $util.isString(message.methodName)))
                return "methodName: buffer expected";
        if (message.args != null && message.hasOwnProperty("args"))
            if (!(message.args && typeof message.args.length === "number" || $util.isString(message.args)))
                return "args: buffer expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        return null;
    };

    /**
     * Creates a FunctionCallTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof FunctionCallTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     */
    FunctionCallTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.FunctionCallTransaction)
            return object;
        var message = new $root.FunctionCallTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.contractId != null)
            message.contractId = String(object.contractId);
        if (object.methodName != null)
            if (typeof object.methodName === "string")
                $util.base64.decode(object.methodName, message.methodName = $util.newBuffer($util.base64.length(object.methodName)), 0);
            else if (object.methodName.length)
                message.methodName = object.methodName;
        if (object.args != null)
            if (typeof object.args === "string")
                $util.base64.decode(object.args, message.args = $util.newBuffer($util.base64.length(object.args)), 0);
            else if (object.args.length)
                message.args = object.args;
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        return message;
    };

    /**
     * Creates a plain object from a FunctionCallTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof FunctionCallTransaction
     * @static
     * @param {FunctionCallTransaction} message FunctionCallTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    FunctionCallTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.contractId = "";
            if (options.bytes === String)
                object.methodName = "";
            else {
                object.methodName = [];
                if (options.bytes !== Array)
                    object.methodName = $util.newBuffer(object.methodName);
            }
            if (options.bytes === String)
                object.args = "";
            else {
                object.args = [];
                if (options.bytes !== Array)
                    object.args = $util.newBuffer(object.args);
            }
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            object.contractId = message.contractId;
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            object.methodName = options.bytes === String ? $util.base64.encode(message.methodName, 0, message.methodName.length) : options.bytes === Array ? Array.prototype.slice.call(message.methodName) : message.methodName;
        if (message.args != null && message.hasOwnProperty("args"))
            object.args = options.bytes === String ? $util.base64.encode(message.args, 0, message.args.length) : options.bytes === Array ? Array.prototype.slice.call(message.args) : message.args;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        return object;
    };

    /**
     * Converts this FunctionCallTransaction to JSON.
     * @function toJSON
     * @memberof FunctionCallTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    FunctionCallTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return FunctionCallTransaction;
})();

$root.SendMoneyTransaction = (function() {

    /**
     * Properties of a SendMoneyTransaction.
     * @exports ISendMoneyTransaction
     * @interface ISendMoneyTransaction
     * @property {number|Long|null} [nonce] SendMoneyTransaction nonce
     * @property {string|null} [originator] SendMoneyTransaction originator
     * @property {string|null} [receiver] SendMoneyTransaction receiver
     * @property {number|Long|null} [amount] SendMoneyTransaction amount
     */

    /**
     * Constructs a new SendMoneyTransaction.
     * @exports SendMoneyTransaction
     * @classdesc Represents a SendMoneyTransaction.
     * @implements ISendMoneyTransaction
     * @constructor
     * @param {ISendMoneyTransaction=} [properties] Properties to set
     */
    function SendMoneyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SendMoneyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * SendMoneyTransaction originator.
     * @member {string} originator
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.originator = "";

    /**
     * SendMoneyTransaction receiver.
     * @member {string} receiver
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.receiver = "";

    /**
     * SendMoneyTransaction amount.
     * @member {number|Long} amount
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * Creates a new SendMoneyTransaction instance using the specified properties.
     * @function create
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction=} [properties] Properties to set
     * @returns {SendMoneyTransaction} SendMoneyTransaction instance
     */
    SendMoneyTransaction.create = function create(properties) {
        return new SendMoneyTransaction(properties);
    };

    /**
     * Encodes the specified SendMoneyTransaction message. Does not implicitly {@link SendMoneyTransaction.verify|verify} messages.
     * @function encode
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction} message SendMoneyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SendMoneyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.receiver);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 4, wireType 0 =*/32).uint64(message.amount);
        return writer;
    };

    /**
     * Encodes the specified SendMoneyTransaction message, length delimited. Does not implicitly {@link SendMoneyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction} message SendMoneyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SendMoneyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SendMoneyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SendMoneyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SendMoneyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SendMoneyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.receiver = reader.string();
                break;
            case 4:
                message.amount = reader.uint64();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SendMoneyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SendMoneyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SendMoneyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SendMoneyTransaction message.
     * @function verify
     * @memberof SendMoneyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SendMoneyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            if (!$util.isString(message.receiver))
                return "receiver: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        return null;
    };

    /**
     * Creates a SendMoneyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SendMoneyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     */
    SendMoneyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SendMoneyTransaction)
            return object;
        var message = new $root.SendMoneyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.receiver != null)
            message.receiver = String(object.receiver);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        return message;
    };

    /**
     * Creates a plain object from a SendMoneyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SendMoneyTransaction
     * @static
     * @param {SendMoneyTransaction} message SendMoneyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SendMoneyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.receiver = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            object.receiver = message.receiver;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        return object;
    };

    /**
     * Converts this SendMoneyTransaction to JSON.
     * @function toJSON
     * @memberof SendMoneyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SendMoneyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SendMoneyTransaction;
})();

$root.StakeTransaction = (function() {

    /**
     * Properties of a StakeTransaction.
     * @exports IStakeTransaction
     * @interface IStakeTransaction
     * @property {number|Long|null} [nonce] StakeTransaction nonce
     * @property {string|null} [originator] StakeTransaction originator
     * @property {number|Long|null} [amount] StakeTransaction amount
     * @property {string|null} [publicKey] StakeTransaction publicKey
     * @property {string|null} [blsPublicKey] StakeTransaction blsPublicKey
     */

    /**
     * Constructs a new StakeTransaction.
     * @exports StakeTransaction
     * @classdesc Represents a StakeTransaction.
     * @implements IStakeTransaction
     * @constructor
     * @param {IStakeTransaction=} [properties] Properties to set
     */
    function StakeTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * StakeTransaction nonce.
     * @member {number|Long} nonce
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * StakeTransaction originator.
     * @member {string} originator
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.originator = "";

    /**
     * StakeTransaction amount.
     * @member {number|Long} amount
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * StakeTransaction publicKey.
     * @member {string} publicKey
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.publicKey = "";

    /**
     * StakeTransaction blsPublicKey.
     * @member {string} blsPublicKey
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.blsPublicKey = "";

    /**
     * Creates a new StakeTransaction instance using the specified properties.
     * @function create
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction=} [properties] Properties to set
     * @returns {StakeTransaction} StakeTransaction instance
     */
    StakeTransaction.create = function create(properties) {
        return new StakeTransaction(properties);
    };

    /**
     * Encodes the specified StakeTransaction message. Does not implicitly {@link StakeTransaction.verify|verify} messages.
     * @function encode
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction} message StakeTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    StakeTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 3, wireType 0 =*/24).uint64(message.amount);
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            writer.uint32(/* id 4, wireType 2 =*/34).string(message.publicKey);
        if (message.blsPublicKey != null && message.hasOwnProperty("blsPublicKey"))
            writer.uint32(/* id 5, wireType 2 =*/42).string(message.blsPublicKey);
        return writer;
    };

    /**
     * Encodes the specified StakeTransaction message, length delimited. Does not implicitly {@link StakeTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction} message StakeTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    StakeTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a StakeTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof StakeTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {StakeTransaction} StakeTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    StakeTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.StakeTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.amount = reader.uint64();
                break;
            case 4:
                message.publicKey = reader.string();
                break;
            case 5:
                message.blsPublicKey = reader.string();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a StakeTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof StakeTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {StakeTransaction} StakeTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    StakeTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a StakeTransaction message.
     * @function verify
     * @memberof StakeTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    StakeTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            if (!$util.isString(message.publicKey))
                return "publicKey: string expected";
        if (message.blsPublicKey != null && message.hasOwnProperty("blsPublicKey"))
            if (!$util.isString(message.blsPublicKey))
                return "blsPublicKey: string expected";
        return null;
    };

    /**
     * Creates a StakeTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof StakeTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {StakeTransaction} StakeTransaction
     */
    StakeTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.StakeTransaction)
            return object;
        var message = new $root.StakeTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        if (object.publicKey != null)
            message.publicKey = String(object.publicKey);
        if (object.blsPublicKey != null)
            message.blsPublicKey = String(object.blsPublicKey);
        return message;
    };

    /**
     * Creates a plain object from a StakeTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof StakeTransaction
     * @static
     * @param {StakeTransaction} message StakeTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    StakeTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
            object.publicKey = "";
            object.blsPublicKey = "";
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            object.publicKey = message.publicKey;
        if (message.blsPublicKey != null && message.hasOwnProperty("blsPublicKey"))
            object.blsPublicKey = message.blsPublicKey;
        return object;
    };

    /**
     * Converts this StakeTransaction to JSON.
     * @function toJSON
     * @memberof StakeTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    StakeTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return StakeTransaction;
})();

$root.SwapKeyTransaction = (function() {

    /**
     * Properties of a SwapKeyTransaction.
     * @exports ISwapKeyTransaction
     * @interface ISwapKeyTransaction
     * @property {number|Long|null} [nonce] SwapKeyTransaction nonce
     * @property {string|null} [originator] SwapKeyTransaction originator
     * @property {Uint8Array|null} [curKey] SwapKeyTransaction curKey
     * @property {Uint8Array|null} [newKey] SwapKeyTransaction newKey
     */

    /**
     * Constructs a new SwapKeyTransaction.
     * @exports SwapKeyTransaction
     * @classdesc Represents a SwapKeyTransaction.
     * @implements ISwapKeyTransaction
     * @constructor
     * @param {ISwapKeyTransaction=} [properties] Properties to set
     */
    function SwapKeyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SwapKeyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * SwapKeyTransaction originator.
     * @member {string} originator
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.originator = "";

    /**
     * SwapKeyTransaction curKey.
     * @member {Uint8Array} curKey
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.curKey = $util.newBuffer([]);

    /**
     * SwapKeyTransaction newKey.
     * @member {Uint8Array} newKey
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.newKey = $util.newBuffer([]);

    /**
     * Creates a new SwapKeyTransaction instance using the specified properties.
     * @function create
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction=} [properties] Properties to set
     * @returns {SwapKeyTransaction} SwapKeyTransaction instance
     */
    SwapKeyTransaction.create = function create(properties) {
        return new SwapKeyTransaction(properties);
    };

    /**
     * Encodes the specified SwapKeyTransaction message. Does not implicitly {@link SwapKeyTransaction.verify|verify} messages.
     * @function encode
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction} message SwapKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SwapKeyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.curKey);
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            writer.uint32(/* id 4, wireType 2 =*/34).bytes(message.newKey);
        return writer;
    };

    /**
     * Encodes the specified SwapKeyTransaction message, length delimited. Does not implicitly {@link SwapKeyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction} message SwapKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SwapKeyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SwapKeyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SwapKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SwapKeyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SwapKeyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.curKey = reader.bytes();
                break;
            case 4:
                message.newKey = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SwapKeyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SwapKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SwapKeyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SwapKeyTransaction message.
     * @function verify
     * @memberof SwapKeyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SwapKeyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            if (!(message.curKey && typeof message.curKey.length === "number" || $util.isString(message.curKey)))
                return "curKey: buffer expected";
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            if (!(message.newKey && typeof message.newKey.length === "number" || $util.isString(message.newKey)))
                return "newKey: buffer expected";
        return null;
    };

    /**
     * Creates a SwapKeyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SwapKeyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     */
    SwapKeyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SwapKeyTransaction)
            return object;
        var message = new $root.SwapKeyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.curKey != null)
            if (typeof object.curKey === "string")
                $util.base64.decode(object.curKey, message.curKey = $util.newBuffer($util.base64.length(object.curKey)), 0);
            else if (object.curKey.length)
                message.curKey = object.curKey;
        if (object.newKey != null)
            if (typeof object.newKey === "string")
                $util.base64.decode(object.newKey, message.newKey = $util.newBuffer($util.base64.length(object.newKey)), 0);
            else if (object.newKey.length)
                message.newKey = object.newKey;
        return message;
    };

    /**
     * Creates a plain object from a SwapKeyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SwapKeyTransaction
     * @static
     * @param {SwapKeyTransaction} message SwapKeyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SwapKeyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if (options.bytes === String)
                object.curKey = "";
            else {
                object.curKey = [];
                if (options.bytes !== Array)
                    object.curKey = $util.newBuffer(object.curKey);
            }
            if (options.bytes === String)
                object.newKey = "";
            else {
                object.newKey = [];
                if (options.bytes !== Array)
                    object.newKey = $util.newBuffer(object.newKey);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            object.curKey = options.bytes === String ? $util.base64.encode(message.curKey, 0, message.curKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.curKey) : message.curKey;
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            object.newKey = options.bytes === String ? $util.base64.encode(message.newKey, 0, message.newKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.newKey) : message.newKey;
        return object;
    };

    /**
     * Converts this SwapKeyTransaction to JSON.
     * @function toJSON
     * @memberof SwapKeyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SwapKeyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SwapKeyTransaction;
})();

$root.AddKeyTransaction = (function() {

    /**
     * Properties of an AddKeyTransaction.
     * @exports IAddKeyTransaction
     * @interface IAddKeyTransaction
     * @property {number|Long|null} [nonce] AddKeyTransaction nonce
     * @property {string|null} [originator] AddKeyTransaction originator
     * @property {Uint8Array|null} [newKey] AddKeyTransaction newKey
     * @property {IAccessKey|null} [accessKey] AddKeyTransaction accessKey
     */

    /**
     * Constructs a new AddKeyTransaction.
     * @exports AddKeyTransaction
     * @classdesc Represents an AddKeyTransaction.
     * @implements IAddKeyTransaction
     * @constructor
     * @param {IAddKeyTransaction=} [properties] Properties to set
     */
    function AddKeyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * AddKeyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof AddKeyTransaction
     * @instance
     */
    AddKeyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * AddKeyTransaction originator.
     * @member {string} originator
     * @memberof AddKeyTransaction
     * @instance
     */
    AddKeyTransaction.prototype.originator = "";

    /**
     * AddKeyTransaction newKey.
     * @member {Uint8Array} newKey
     * @memberof AddKeyTransaction
     * @instance
     */
    AddKeyTransaction.prototype.newKey = $util.newBuffer([]);

    /**
     * AddKeyTransaction accessKey.
     * @member {IAccessKey|null|undefined} accessKey
     * @memberof AddKeyTransaction
     * @instance
     */
    AddKeyTransaction.prototype.accessKey = null;

    /**
     * Creates a new AddKeyTransaction instance using the specified properties.
     * @function create
     * @memberof AddKeyTransaction
     * @static
     * @param {IAddKeyTransaction=} [properties] Properties to set
     * @returns {AddKeyTransaction} AddKeyTransaction instance
     */
    AddKeyTransaction.create = function create(properties) {
        return new AddKeyTransaction(properties);
    };

    /**
     * Encodes the specified AddKeyTransaction message. Does not implicitly {@link AddKeyTransaction.verify|verify} messages.
     * @function encode
     * @memberof AddKeyTransaction
     * @static
     * @param {IAddKeyTransaction} message AddKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    AddKeyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.newKey);
        if (message.accessKey != null && message.hasOwnProperty("accessKey"))
            $root.AccessKey.encode(message.accessKey, writer.uint32(/* id 4, wireType 2 =*/34).fork()).ldelim();
        return writer;
    };

    /**
     * Encodes the specified AddKeyTransaction message, length delimited. Does not implicitly {@link AddKeyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof AddKeyTransaction
     * @static
     * @param {IAddKeyTransaction} message AddKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    AddKeyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes an AddKeyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof AddKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {AddKeyTransaction} AddKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    AddKeyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.AddKeyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.newKey = reader.bytes();
                break;
            case 4:
                message.accessKey = $root.AccessKey.decode(reader, reader.uint32());
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes an AddKeyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof AddKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {AddKeyTransaction} AddKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    AddKeyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies an AddKeyTransaction message.
     * @function verify
     * @memberof AddKeyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    AddKeyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            if (!(message.newKey && typeof message.newKey.length === "number" || $util.isString(message.newKey)))
                return "newKey: buffer expected";
        if (message.accessKey != null && message.hasOwnProperty("accessKey")) {
            var error = $root.AccessKey.verify(message.accessKey);
            if (error)
                return "accessKey." + error;
        }
        return null;
    };

    /**
     * Creates an AddKeyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof AddKeyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {AddKeyTransaction} AddKeyTransaction
     */
    AddKeyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.AddKeyTransaction)
            return object;
        var message = new $root.AddKeyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.newKey != null)
            if (typeof object.newKey === "string")
                $util.base64.decode(object.newKey, message.newKey = $util.newBuffer($util.base64.length(object.newKey)), 0);
            else if (object.newKey.length)
                message.newKey = object.newKey;
        if (object.accessKey != null) {
            if (typeof object.accessKey !== "object")
                throw TypeError(".AddKeyTransaction.accessKey: object expected");
            message.accessKey = $root.AccessKey.fromObject(object.accessKey);
        }
        return message;
    };

    /**
     * Creates a plain object from an AddKeyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof AddKeyTransaction
     * @static
     * @param {AddKeyTransaction} message AddKeyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    AddKeyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if (options.bytes === String)
                object.newKey = "";
            else {
                object.newKey = [];
                if (options.bytes !== Array)
                    object.newKey = $util.newBuffer(object.newKey);
            }
            object.accessKey = null;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            object.newKey = options.bytes === String ? $util.base64.encode(message.newKey, 0, message.newKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.newKey) : message.newKey;
        if (message.accessKey != null && message.hasOwnProperty("accessKey"))
            object.accessKey = $root.AccessKey.toObject(message.accessKey, options);
        return object;
    };

    /**
     * Converts this AddKeyTransaction to JSON.
     * @function toJSON
     * @memberof AddKeyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    AddKeyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return AddKeyTransaction;
})();

$root.DeleteKeyTransaction = (function() {

    /**
     * Properties of a DeleteKeyTransaction.
     * @exports IDeleteKeyTransaction
     * @interface IDeleteKeyTransaction
     * @property {number|Long|null} [nonce] DeleteKeyTransaction nonce
     * @property {string|null} [originator] DeleteKeyTransaction originator
     * @property {Uint8Array|null} [curKey] DeleteKeyTransaction curKey
     */

    /**
     * Constructs a new DeleteKeyTransaction.
     * @exports DeleteKeyTransaction
     * @classdesc Represents a DeleteKeyTransaction.
     * @implements IDeleteKeyTransaction
     * @constructor
     * @param {IDeleteKeyTransaction=} [properties] Properties to set
     */
    function DeleteKeyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * DeleteKeyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof DeleteKeyTransaction
     * @instance
     */
    DeleteKeyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * DeleteKeyTransaction originator.
     * @member {string} originator
     * @memberof DeleteKeyTransaction
     * @instance
     */
    DeleteKeyTransaction.prototype.originator = "";

    /**
     * DeleteKeyTransaction curKey.
     * @member {Uint8Array} curKey
     * @memberof DeleteKeyTransaction
     * @instance
     */
    DeleteKeyTransaction.prototype.curKey = $util.newBuffer([]);

    /**
     * Creates a new DeleteKeyTransaction instance using the specified properties.
     * @function create
     * @memberof DeleteKeyTransaction
     * @static
     * @param {IDeleteKeyTransaction=} [properties] Properties to set
     * @returns {DeleteKeyTransaction} DeleteKeyTransaction instance
     */
    DeleteKeyTransaction.create = function create(properties) {
        return new DeleteKeyTransaction(properties);
    };

    /**
     * Encodes the specified DeleteKeyTransaction message. Does not implicitly {@link DeleteKeyTransaction.verify|verify} messages.
     * @function encode
     * @memberof DeleteKeyTransaction
     * @static
     * @param {IDeleteKeyTransaction} message DeleteKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeleteKeyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.curKey);
        return writer;
    };

    /**
     * Encodes the specified DeleteKeyTransaction message, length delimited. Does not implicitly {@link DeleteKeyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof DeleteKeyTransaction
     * @static
     * @param {IDeleteKeyTransaction} message DeleteKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeleteKeyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a DeleteKeyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof DeleteKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {DeleteKeyTransaction} DeleteKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeleteKeyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.DeleteKeyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.curKey = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a DeleteKeyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof DeleteKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {DeleteKeyTransaction} DeleteKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeleteKeyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a DeleteKeyTransaction message.
     * @function verify
     * @memberof DeleteKeyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    DeleteKeyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            if (!(message.curKey && typeof message.curKey.length === "number" || $util.isString(message.curKey)))
                return "curKey: buffer expected";
        return null;
    };

    /**
     * Creates a DeleteKeyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof DeleteKeyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {DeleteKeyTransaction} DeleteKeyTransaction
     */
    DeleteKeyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.DeleteKeyTransaction)
            return object;
        var message = new $root.DeleteKeyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.curKey != null)
            if (typeof object.curKey === "string")
                $util.base64.decode(object.curKey, message.curKey = $util.newBuffer($util.base64.length(object.curKey)), 0);
            else if (object.curKey.length)
                message.curKey = object.curKey;
        return message;
    };

    /**
     * Creates a plain object from a DeleteKeyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof DeleteKeyTransaction
     * @static
     * @param {DeleteKeyTransaction} message DeleteKeyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    DeleteKeyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if (options.bytes === String)
                object.curKey = "";
            else {
                object.curKey = [];
                if (options.bytes !== Array)
                    object.curKey = $util.newBuffer(object.curKey);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            object.curKey = options.bytes === String ? $util.base64.encode(message.curKey, 0, message.curKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.curKey) : message.curKey;
        return object;
    };

    /**
     * Converts this DeleteKeyTransaction to JSON.
     * @function toJSON
     * @memberof DeleteKeyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    DeleteKeyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return DeleteKeyTransaction;
})();

$root.SignedTransaction = (function() {

    /**
     * Properties of a SignedTransaction.
     * @exports ISignedTransaction
     * @interface ISignedTransaction
     * @property {Uint8Array|null} [signature] SignedTransaction signature
     * @property {google.protobuf.IBytesValue|null} [publicKey] SignedTransaction publicKey
     * @property {ICreateAccountTransaction|null} [createAccount] SignedTransaction createAccount
     * @property {IDeployContractTransaction|null} [deployContract] SignedTransaction deployContract
     * @property {IFunctionCallTransaction|null} [functionCall] SignedTransaction functionCall
     * @property {ISendMoneyTransaction|null} [sendMoney] SignedTransaction sendMoney
     * @property {IStakeTransaction|null} [stake] SignedTransaction stake
     * @property {ISwapKeyTransaction|null} [swapKey] SignedTransaction swapKey
     * @property {IAddKeyTransaction|null} [addKey] SignedTransaction addKey
     * @property {IDeleteKeyTransaction|null} [deleteKey] SignedTransaction deleteKey
     */

    /**
     * Constructs a new SignedTransaction.
     * @exports SignedTransaction
     * @classdesc Represents a SignedTransaction.
     * @implements ISignedTransaction
     * @constructor
     * @param {ISignedTransaction=} [properties] Properties to set
     */
    function SignedTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SignedTransaction signature.
     * @member {Uint8Array} signature
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.signature = $util.newBuffer([]);

    /**
     * SignedTransaction publicKey.
     * @member {google.protobuf.IBytesValue|null|undefined} publicKey
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.publicKey = null;

    /**
     * SignedTransaction createAccount.
     * @member {ICreateAccountTransaction|null|undefined} createAccount
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.createAccount = null;

    /**
     * SignedTransaction deployContract.
     * @member {IDeployContractTransaction|null|undefined} deployContract
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.deployContract = null;

    /**
     * SignedTransaction functionCall.
     * @member {IFunctionCallTransaction|null|undefined} functionCall
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.functionCall = null;

    /**
     * SignedTransaction sendMoney.
     * @member {ISendMoneyTransaction|null|undefined} sendMoney
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.sendMoney = null;

    /**
     * SignedTransaction stake.
     * @member {IStakeTransaction|null|undefined} stake
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.stake = null;

    /**
     * SignedTransaction swapKey.
     * @member {ISwapKeyTransaction|null|undefined} swapKey
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.swapKey = null;

    /**
     * SignedTransaction addKey.
     * @member {IAddKeyTransaction|null|undefined} addKey
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.addKey = null;

    /**
     * SignedTransaction deleteKey.
     * @member {IDeleteKeyTransaction|null|undefined} deleteKey
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.deleteKey = null;

    // OneOf field names bound to virtual getters and setters
    var $oneOfFields;

    /**
     * SignedTransaction body.
     * @member {"createAccount"|"deployContract"|"functionCall"|"sendMoney"|"stake"|"swapKey"|"addKey"|"deleteKey"|undefined} body
     * @memberof SignedTransaction
     * @instance
     */
    Object.defineProperty(SignedTransaction.prototype, "body", {
        get: $util.oneOfGetter($oneOfFields = ["createAccount", "deployContract", "functionCall", "sendMoney", "stake", "swapKey", "addKey", "deleteKey"]),
        set: $util.oneOfSetter($oneOfFields)
    });

    /**
     * Creates a new SignedTransaction instance using the specified properties.
     * @function create
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction=} [properties] Properties to set
     * @returns {SignedTransaction} SignedTransaction instance
     */
    SignedTransaction.create = function create(properties) {
        return new SignedTransaction(properties);
    };

    /**
     * Encodes the specified SignedTransaction message. Does not implicitly {@link SignedTransaction.verify|verify} messages.
     * @function encode
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction} message SignedTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SignedTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.signature != null && message.hasOwnProperty("signature"))
            writer.uint32(/* id 1, wireType 2 =*/10).bytes(message.signature);
        if (message.createAccount != null && message.hasOwnProperty("createAccount"))
            $root.CreateAccountTransaction.encode(message.createAccount, writer.uint32(/* id 2, wireType 2 =*/18).fork()).ldelim();
        if (message.deployContract != null && message.hasOwnProperty("deployContract"))
            $root.DeployContractTransaction.encode(message.deployContract, writer.uint32(/* id 3, wireType 2 =*/26).fork()).ldelim();
        if (message.functionCall != null && message.hasOwnProperty("functionCall"))
            $root.FunctionCallTransaction.encode(message.functionCall, writer.uint32(/* id 4, wireType 2 =*/34).fork()).ldelim();
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney"))
            $root.SendMoneyTransaction.encode(message.sendMoney, writer.uint32(/* id 5, wireType 2 =*/42).fork()).ldelim();
        if (message.stake != null && message.hasOwnProperty("stake"))
            $root.StakeTransaction.encode(message.stake, writer.uint32(/* id 6, wireType 2 =*/50).fork()).ldelim();
        if (message.swapKey != null && message.hasOwnProperty("swapKey"))
            $root.SwapKeyTransaction.encode(message.swapKey, writer.uint32(/* id 7, wireType 2 =*/58).fork()).ldelim();
        if (message.addKey != null && message.hasOwnProperty("addKey"))
            $root.AddKeyTransaction.encode(message.addKey, writer.uint32(/* id 8, wireType 2 =*/66).fork()).ldelim();
        if (message.deleteKey != null && message.hasOwnProperty("deleteKey"))
            $root.DeleteKeyTransaction.encode(message.deleteKey, writer.uint32(/* id 9, wireType 2 =*/74).fork()).ldelim();
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            $root.google.protobuf.BytesValue.encode(message.publicKey, writer.uint32(/* id 10, wireType 2 =*/82).fork()).ldelim();
        return writer;
    };

    /**
     * Encodes the specified SignedTransaction message, length delimited. Does not implicitly {@link SignedTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction} message SignedTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SignedTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SignedTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SignedTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SignedTransaction} SignedTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SignedTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SignedTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.signature = reader.bytes();
                break;
            case 10:
                message.publicKey = $root.google.protobuf.BytesValue.decode(reader, reader.uint32());
                break;
            case 2:
                message.createAccount = $root.CreateAccountTransaction.decode(reader, reader.uint32());
                break;
            case 3:
                message.deployContract = $root.DeployContractTransaction.decode(reader, reader.uint32());
                break;
            case 4:
                message.functionCall = $root.FunctionCallTransaction.decode(reader, reader.uint32());
                break;
            case 5:
                message.sendMoney = $root.SendMoneyTransaction.decode(reader, reader.uint32());
                break;
            case 6:
                message.stake = $root.StakeTransaction.decode(reader, reader.uint32());
                break;
            case 7:
                message.swapKey = $root.SwapKeyTransaction.decode(reader, reader.uint32());
                break;
            case 8:
                message.addKey = $root.AddKeyTransaction.decode(reader, reader.uint32());
                break;
            case 9:
                message.deleteKey = $root.DeleteKeyTransaction.decode(reader, reader.uint32());
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SignedTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SignedTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SignedTransaction} SignedTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SignedTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SignedTransaction message.
     * @function verify
     * @memberof SignedTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SignedTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        var properties = {};
        if (message.signature != null && message.hasOwnProperty("signature"))
            if (!(message.signature && typeof message.signature.length === "number" || $util.isString(message.signature)))
                return "signature: buffer expected";
        if (message.publicKey != null && message.hasOwnProperty("publicKey")) {
            var error = $root.google.protobuf.BytesValue.verify(message.publicKey);
            if (error)
                return "publicKey." + error;
        }
        if (message.createAccount != null && message.hasOwnProperty("createAccount")) {
            properties.body = 1;
            {
                var error = $root.CreateAccountTransaction.verify(message.createAccount);
                if (error)
                    return "createAccount." + error;
            }
        }
        if (message.deployContract != null && message.hasOwnProperty("deployContract")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.DeployContractTransaction.verify(message.deployContract);
                if (error)
                    return "deployContract." + error;
            }
        }
        if (message.functionCall != null && message.hasOwnProperty("functionCall")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.FunctionCallTransaction.verify(message.functionCall);
                if (error)
                    return "functionCall." + error;
            }
        }
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.SendMoneyTransaction.verify(message.sendMoney);
                if (error)
                    return "sendMoney." + error;
            }
        }
        if (message.stake != null && message.hasOwnProperty("stake")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.StakeTransaction.verify(message.stake);
                if (error)
                    return "stake." + error;
            }
        }
        if (message.swapKey != null && message.hasOwnProperty("swapKey")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.SwapKeyTransaction.verify(message.swapKey);
                if (error)
                    return "swapKey." + error;
            }
        }
        if (message.addKey != null && message.hasOwnProperty("addKey")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.AddKeyTransaction.verify(message.addKey);
                if (error)
                    return "addKey." + error;
            }
        }
        if (message.deleteKey != null && message.hasOwnProperty("deleteKey")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.DeleteKeyTransaction.verify(message.deleteKey);
                if (error)
                    return "deleteKey." + error;
            }
        }
        return null;
    };

    /**
     * Creates a SignedTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SignedTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SignedTransaction} SignedTransaction
     */
    SignedTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SignedTransaction)
            return object;
        var message = new $root.SignedTransaction();
        if (object.signature != null)
            if (typeof object.signature === "string")
                $util.base64.decode(object.signature, message.signature = $util.newBuffer($util.base64.length(object.signature)), 0);
            else if (object.signature.length)
                message.signature = object.signature;
        if (object.publicKey != null) {
            if (typeof object.publicKey !== "object")
                throw TypeError(".SignedTransaction.publicKey: object expected");
            message.publicKey = $root.google.protobuf.BytesValue.fromObject(object.publicKey);
        }
        if (object.createAccount != null) {
            if (typeof object.createAccount !== "object")
                throw TypeError(".SignedTransaction.createAccount: object expected");
            message.createAccount = $root.CreateAccountTransaction.fromObject(object.createAccount);
        }
        if (object.deployContract != null) {
            if (typeof object.deployContract !== "object")
                throw TypeError(".SignedTransaction.deployContract: object expected");
            message.deployContract = $root.DeployContractTransaction.fromObject(object.deployContract);
        }
        if (object.functionCall != null) {
            if (typeof object.functionCall !== "object")
                throw TypeError(".SignedTransaction.functionCall: object expected");
            message.functionCall = $root.FunctionCallTransaction.fromObject(object.functionCall);
        }
        if (object.sendMoney != null) {
            if (typeof object.sendMoney !== "object")
                throw TypeError(".SignedTransaction.sendMoney: object expected");
            message.sendMoney = $root.SendMoneyTransaction.fromObject(object.sendMoney);
        }
        if (object.stake != null) {
            if (typeof object.stake !== "object")
                throw TypeError(".SignedTransaction.stake: object expected");
            message.stake = $root.StakeTransaction.fromObject(object.stake);
        }
        if (object.swapKey != null) {
            if (typeof object.swapKey !== "object")
                throw TypeError(".SignedTransaction.swapKey: object expected");
            message.swapKey = $root.SwapKeyTransaction.fromObject(object.swapKey);
        }
        if (object.addKey != null) {
            if (typeof object.addKey !== "object")
                throw TypeError(".SignedTransaction.addKey: object expected");
            message.addKey = $root.AddKeyTransaction.fromObject(object.addKey);
        }
        if (object.deleteKey != null) {
            if (typeof object.deleteKey !== "object")
                throw TypeError(".SignedTransaction.deleteKey: object expected");
            message.deleteKey = $root.DeleteKeyTransaction.fromObject(object.deleteKey);
        }
        return message;
    };

    /**
     * Creates a plain object from a SignedTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SignedTransaction
     * @static
     * @param {SignedTransaction} message SignedTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SignedTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if (options.bytes === String)
                object.signature = "";
            else {
                object.signature = [];
                if (options.bytes !== Array)
                    object.signature = $util.newBuffer(object.signature);
            }
            object.publicKey = null;
        }
        if (message.signature != null && message.hasOwnProperty("signature"))
            object.signature = options.bytes === String ? $util.base64.encode(message.signature, 0, message.signature.length) : options.bytes === Array ? Array.prototype.slice.call(message.signature) : message.signature;
        if (message.createAccount != null && message.hasOwnProperty("createAccount")) {
            object.createAccount = $root.CreateAccountTransaction.toObject(message.createAccount, options);
            if (options.oneofs)
                object.body = "createAccount";
        }
        if (message.deployContract != null && message.hasOwnProperty("deployContract")) {
            object.deployContract = $root.DeployContractTransaction.toObject(message.deployContract, options);
            if (options.oneofs)
                object.body = "deployContract";
        }
        if (message.functionCall != null && message.hasOwnProperty("functionCall")) {
            object.functionCall = $root.FunctionCallTransaction.toObject(message.functionCall, options);
            if (options.oneofs)
                object.body = "functionCall";
        }
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney")) {
            object.sendMoney = $root.SendMoneyTransaction.toObject(message.sendMoney, options);
            if (options.oneofs)
                object.body = "sendMoney";
        }
        if (message.stake != null && message.hasOwnProperty("stake")) {
            object.stake = $root.StakeTransaction.toObject(message.stake, options);
            if (options.oneofs)
                object.body = "stake";
        }
        if (message.swapKey != null && message.hasOwnProperty("swapKey")) {
            object.swapKey = $root.SwapKeyTransaction.toObject(message.swapKey, options);
            if (options.oneofs)
                object.body = "swapKey";
        }
        if (message.addKey != null && message.hasOwnProperty("addKey")) {
            object.addKey = $root.AddKeyTransaction.toObject(message.addKey, options);
            if (options.oneofs)
                object.body = "addKey";
        }
        if (message.deleteKey != null && message.hasOwnProperty("deleteKey")) {
            object.deleteKey = $root.DeleteKeyTransaction.toObject(message.deleteKey, options);
            if (options.oneofs)
                object.body = "deleteKey";
        }
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            object.publicKey = $root.google.protobuf.BytesValue.toObject(message.publicKey, options);
        return object;
    };

    /**
     * Converts this SignedTransaction to JSON.
     * @function toJSON
     * @memberof SignedTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SignedTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SignedTransaction;
})();

$root.google = (function() {

    /**
     * Namespace google.
     * @exports google
     * @namespace
     */
    var google = {};

    google.protobuf = (function() {

        /**
         * Namespace protobuf.
         * @memberof google
         * @namespace
         */
        var protobuf = {};

        protobuf.DoubleValue = (function() {

            /**
             * Properties of a DoubleValue.
             * @memberof google.protobuf
             * @interface IDoubleValue
             * @property {number|null} [value] DoubleValue value
             */

            /**
             * Constructs a new DoubleValue.
             * @memberof google.protobuf
             * @classdesc Represents a DoubleValue.
             * @implements IDoubleValue
             * @constructor
             * @param {google.protobuf.IDoubleValue=} [properties] Properties to set
             */
            function DoubleValue(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * DoubleValue value.
             * @member {number} value
             * @memberof google.protobuf.DoubleValue
             * @instance
             */
            DoubleValue.prototype.value = 0;

            /**
             * Creates a new DoubleValue instance using the specified properties.
             * @function create
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {google.protobuf.IDoubleValue=} [properties] Properties to set
             * @returns {google.protobuf.DoubleValue} DoubleValue instance
             */
            DoubleValue.create = function create(properties) {
                return new DoubleValue(properties);
            };

            /**
             * Encodes the specified DoubleValue message. Does not implicitly {@link google.protobuf.DoubleValue.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {google.protobuf.IDoubleValue} message DoubleValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            DoubleValue.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 1 =*/9).double(message.value);
                return writer;
            };

            /**
             * Encodes the specified DoubleValue message, length delimited. Does not implicitly {@link google.protobuf.DoubleValue.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {google.protobuf.IDoubleValue} message DoubleValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            DoubleValue.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a DoubleValue message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.DoubleValue} DoubleValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            DoubleValue.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.DoubleValue();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.double();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a DoubleValue message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.DoubleValue} DoubleValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            DoubleValue.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a DoubleValue message.
             * @function verify
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            DoubleValue.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (typeof message.value !== "number")
                        return "value: number expected";
                return null;
            };

            /**
             * Creates a DoubleValue message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.DoubleValue} DoubleValue
             */
            DoubleValue.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.DoubleValue)
                    return object;
                var message = new $root.google.protobuf.DoubleValue();
                if (object.value != null)
                    message.value = Number(object.value);
                return message;
            };

            /**
             * Creates a plain object from a DoubleValue message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.DoubleValue
             * @static
             * @param {google.protobuf.DoubleValue} message DoubleValue
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            DoubleValue.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = options.json && !isFinite(message.value) ? String(message.value) : message.value;
                return object;
            };

            /**
             * Converts this DoubleValue to JSON.
             * @function toJSON
             * @memberof google.protobuf.DoubleValue
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            DoubleValue.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return DoubleValue;
        })();

        protobuf.FloatValue = (function() {

            /**
             * Properties of a FloatValue.
             * @memberof google.protobuf
             * @interface IFloatValue
             * @property {number|null} [value] FloatValue value
             */

            /**
             * Constructs a new FloatValue.
             * @memberof google.protobuf
             * @classdesc Represents a FloatValue.
             * @implements IFloatValue
             * @constructor
             * @param {google.protobuf.IFloatValue=} [properties] Properties to set
             */
            function FloatValue(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * FloatValue value.
             * @member {number} value
             * @memberof google.protobuf.FloatValue
             * @instance
             */
            FloatValue.prototype.value = 0;

            /**
             * Creates a new FloatValue instance using the specified properties.
             * @function create
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {google.protobuf.IFloatValue=} [properties] Properties to set
             * @returns {google.protobuf.FloatValue} FloatValue instance
             */
            FloatValue.create = function create(properties) {
                return new FloatValue(properties);
            };

            /**
             * Encodes the specified FloatValue message. Does not implicitly {@link google.protobuf.FloatValue.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {google.protobuf.IFloatValue} message FloatValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            FloatValue.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 5 =*/13).float(message.value);
                return writer;
            };

            /**
             * Encodes the specified FloatValue message, length delimited. Does not implicitly {@link google.protobuf.FloatValue.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {google.protobuf.IFloatValue} message FloatValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            FloatValue.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a FloatValue message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.FloatValue} FloatValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            FloatValue.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.FloatValue();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.float();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a FloatValue message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.FloatValue} FloatValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            FloatValue.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a FloatValue message.
             * @function verify
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            FloatValue.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (typeof message.value !== "number")
                        return "value: number expected";
                return null;
            };

            /**
             * Creates a FloatValue message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.FloatValue} FloatValue
             */
            FloatValue.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.FloatValue)
                    return object;
                var message = new $root.google.protobuf.FloatValue();
                if (object.value != null)
                    message.value = Number(object.value);
                return message;
            };

            /**
             * Creates a plain object from a FloatValue message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.FloatValue
             * @static
             * @param {google.protobuf.FloatValue} message FloatValue
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            FloatValue.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = options.json && !isFinite(message.value) ? String(message.value) : message.value;
                return object;
            };

            /**
             * Converts this FloatValue to JSON.
             * @function toJSON
             * @memberof google.protobuf.FloatValue
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            FloatValue.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return FloatValue;
        })();

        protobuf.Int64Value = (function() {

            /**
             * Properties of an Int64Value.
             * @memberof google.protobuf
             * @interface IInt64Value
             * @property {number|Long|null} [value] Int64Value value
             */

            /**
             * Constructs a new Int64Value.
             * @memberof google.protobuf
             * @classdesc Represents an Int64Value.
             * @implements IInt64Value
             * @constructor
             * @param {google.protobuf.IInt64Value=} [properties] Properties to set
             */
            function Int64Value(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * Int64Value value.
             * @member {number|Long} value
             * @memberof google.protobuf.Int64Value
             * @instance
             */
            Int64Value.prototype.value = $util.Long ? $util.Long.fromBits(0,0,false) : 0;

            /**
             * Creates a new Int64Value instance using the specified properties.
             * @function create
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {google.protobuf.IInt64Value=} [properties] Properties to set
             * @returns {google.protobuf.Int64Value} Int64Value instance
             */
            Int64Value.create = function create(properties) {
                return new Int64Value(properties);
            };

            /**
             * Encodes the specified Int64Value message. Does not implicitly {@link google.protobuf.Int64Value.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {google.protobuf.IInt64Value} message Int64Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            Int64Value.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 0 =*/8).int64(message.value);
                return writer;
            };

            /**
             * Encodes the specified Int64Value message, length delimited. Does not implicitly {@link google.protobuf.Int64Value.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {google.protobuf.IInt64Value} message Int64Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            Int64Value.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes an Int64Value message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.Int64Value} Int64Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            Int64Value.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.Int64Value();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.int64();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes an Int64Value message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.Int64Value} Int64Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            Int64Value.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies an Int64Value message.
             * @function verify
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            Int64Value.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!$util.isInteger(message.value) && !(message.value && $util.isInteger(message.value.low) && $util.isInteger(message.value.high)))
                        return "value: integer|Long expected";
                return null;
            };

            /**
             * Creates an Int64Value message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.Int64Value} Int64Value
             */
            Int64Value.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.Int64Value)
                    return object;
                var message = new $root.google.protobuf.Int64Value();
                if (object.value != null)
                    if ($util.Long)
                        (message.value = $util.Long.fromValue(object.value)).unsigned = false;
                    else if (typeof object.value === "string")
                        message.value = parseInt(object.value, 10);
                    else if (typeof object.value === "number")
                        message.value = object.value;
                    else if (typeof object.value === "object")
                        message.value = new $util.LongBits(object.value.low >>> 0, object.value.high >>> 0).toNumber();
                return message;
            };

            /**
             * Creates a plain object from an Int64Value message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.Int64Value
             * @static
             * @param {google.protobuf.Int64Value} message Int64Value
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            Int64Value.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    if ($util.Long) {
                        var long = new $util.Long(0, 0, false);
                        object.value = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
                    } else
                        object.value = options.longs === String ? "0" : 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    if (typeof message.value === "number")
                        object.value = options.longs === String ? String(message.value) : message.value;
                    else
                        object.value = options.longs === String ? $util.Long.prototype.toString.call(message.value) : options.longs === Number ? new $util.LongBits(message.value.low >>> 0, message.value.high >>> 0).toNumber() : message.value;
                return object;
            };

            /**
             * Converts this Int64Value to JSON.
             * @function toJSON
             * @memberof google.protobuf.Int64Value
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            Int64Value.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return Int64Value;
        })();

        protobuf.UInt64Value = (function() {

            /**
             * Properties of a UInt64Value.
             * @memberof google.protobuf
             * @interface IUInt64Value
             * @property {number|Long|null} [value] UInt64Value value
             */

            /**
             * Constructs a new UInt64Value.
             * @memberof google.protobuf
             * @classdesc Represents a UInt64Value.
             * @implements IUInt64Value
             * @constructor
             * @param {google.protobuf.IUInt64Value=} [properties] Properties to set
             */
            function UInt64Value(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * UInt64Value value.
             * @member {number|Long} value
             * @memberof google.protobuf.UInt64Value
             * @instance
             */
            UInt64Value.prototype.value = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

            /**
             * Creates a new UInt64Value instance using the specified properties.
             * @function create
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {google.protobuf.IUInt64Value=} [properties] Properties to set
             * @returns {google.protobuf.UInt64Value} UInt64Value instance
             */
            UInt64Value.create = function create(properties) {
                return new UInt64Value(properties);
            };

            /**
             * Encodes the specified UInt64Value message. Does not implicitly {@link google.protobuf.UInt64Value.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {google.protobuf.IUInt64Value} message UInt64Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            UInt64Value.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.value);
                return writer;
            };

            /**
             * Encodes the specified UInt64Value message, length delimited. Does not implicitly {@link google.protobuf.UInt64Value.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {google.protobuf.IUInt64Value} message UInt64Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            UInt64Value.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a UInt64Value message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.UInt64Value} UInt64Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            UInt64Value.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.UInt64Value();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.uint64();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a UInt64Value message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.UInt64Value} UInt64Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            UInt64Value.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a UInt64Value message.
             * @function verify
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            UInt64Value.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!$util.isInteger(message.value) && !(message.value && $util.isInteger(message.value.low) && $util.isInteger(message.value.high)))
                        return "value: integer|Long expected";
                return null;
            };

            /**
             * Creates a UInt64Value message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.UInt64Value} UInt64Value
             */
            UInt64Value.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.UInt64Value)
                    return object;
                var message = new $root.google.protobuf.UInt64Value();
                if (object.value != null)
                    if ($util.Long)
                        (message.value = $util.Long.fromValue(object.value)).unsigned = true;
                    else if (typeof object.value === "string")
                        message.value = parseInt(object.value, 10);
                    else if (typeof object.value === "number")
                        message.value = object.value;
                    else if (typeof object.value === "object")
                        message.value = new $util.LongBits(object.value.low >>> 0, object.value.high >>> 0).toNumber(true);
                return message;
            };

            /**
             * Creates a plain object from a UInt64Value message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.UInt64Value
             * @static
             * @param {google.protobuf.UInt64Value} message UInt64Value
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            UInt64Value.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    if ($util.Long) {
                        var long = new $util.Long(0, 0, true);
                        object.value = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
                    } else
                        object.value = options.longs === String ? "0" : 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    if (typeof message.value === "number")
                        object.value = options.longs === String ? String(message.value) : message.value;
                    else
                        object.value = options.longs === String ? $util.Long.prototype.toString.call(message.value) : options.longs === Number ? new $util.LongBits(message.value.low >>> 0, message.value.high >>> 0).toNumber(true) : message.value;
                return object;
            };

            /**
             * Converts this UInt64Value to JSON.
             * @function toJSON
             * @memberof google.protobuf.UInt64Value
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            UInt64Value.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return UInt64Value;
        })();

        protobuf.Int32Value = (function() {

            /**
             * Properties of an Int32Value.
             * @memberof google.protobuf
             * @interface IInt32Value
             * @property {number|null} [value] Int32Value value
             */

            /**
             * Constructs a new Int32Value.
             * @memberof google.protobuf
             * @classdesc Represents an Int32Value.
             * @implements IInt32Value
             * @constructor
             * @param {google.protobuf.IInt32Value=} [properties] Properties to set
             */
            function Int32Value(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * Int32Value value.
             * @member {number} value
             * @memberof google.protobuf.Int32Value
             * @instance
             */
            Int32Value.prototype.value = 0;

            /**
             * Creates a new Int32Value instance using the specified properties.
             * @function create
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {google.protobuf.IInt32Value=} [properties] Properties to set
             * @returns {google.protobuf.Int32Value} Int32Value instance
             */
            Int32Value.create = function create(properties) {
                return new Int32Value(properties);
            };

            /**
             * Encodes the specified Int32Value message. Does not implicitly {@link google.protobuf.Int32Value.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {google.protobuf.IInt32Value} message Int32Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            Int32Value.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 0 =*/8).int32(message.value);
                return writer;
            };

            /**
             * Encodes the specified Int32Value message, length delimited. Does not implicitly {@link google.protobuf.Int32Value.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {google.protobuf.IInt32Value} message Int32Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            Int32Value.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes an Int32Value message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.Int32Value} Int32Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            Int32Value.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.Int32Value();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.int32();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes an Int32Value message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.Int32Value} Int32Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            Int32Value.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies an Int32Value message.
             * @function verify
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            Int32Value.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!$util.isInteger(message.value))
                        return "value: integer expected";
                return null;
            };

            /**
             * Creates an Int32Value message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.Int32Value} Int32Value
             */
            Int32Value.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.Int32Value)
                    return object;
                var message = new $root.google.protobuf.Int32Value();
                if (object.value != null)
                    message.value = object.value | 0;
                return message;
            };

            /**
             * Creates a plain object from an Int32Value message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.Int32Value
             * @static
             * @param {google.protobuf.Int32Value} message Int32Value
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            Int32Value.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = message.value;
                return object;
            };

            /**
             * Converts this Int32Value to JSON.
             * @function toJSON
             * @memberof google.protobuf.Int32Value
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            Int32Value.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return Int32Value;
        })();

        protobuf.UInt32Value = (function() {

            /**
             * Properties of a UInt32Value.
             * @memberof google.protobuf
             * @interface IUInt32Value
             * @property {number|null} [value] UInt32Value value
             */

            /**
             * Constructs a new UInt32Value.
             * @memberof google.protobuf
             * @classdesc Represents a UInt32Value.
             * @implements IUInt32Value
             * @constructor
             * @param {google.protobuf.IUInt32Value=} [properties] Properties to set
             */
            function UInt32Value(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * UInt32Value value.
             * @member {number} value
             * @memberof google.protobuf.UInt32Value
             * @instance
             */
            UInt32Value.prototype.value = 0;

            /**
             * Creates a new UInt32Value instance using the specified properties.
             * @function create
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {google.protobuf.IUInt32Value=} [properties] Properties to set
             * @returns {google.protobuf.UInt32Value} UInt32Value instance
             */
            UInt32Value.create = function create(properties) {
                return new UInt32Value(properties);
            };

            /**
             * Encodes the specified UInt32Value message. Does not implicitly {@link google.protobuf.UInt32Value.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {google.protobuf.IUInt32Value} message UInt32Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            UInt32Value.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 0 =*/8).uint32(message.value);
                return writer;
            };

            /**
             * Encodes the specified UInt32Value message, length delimited. Does not implicitly {@link google.protobuf.UInt32Value.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {google.protobuf.IUInt32Value} message UInt32Value message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            UInt32Value.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a UInt32Value message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.UInt32Value} UInt32Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            UInt32Value.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.UInt32Value();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.uint32();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a UInt32Value message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.UInt32Value} UInt32Value
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            UInt32Value.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a UInt32Value message.
             * @function verify
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            UInt32Value.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!$util.isInteger(message.value))
                        return "value: integer expected";
                return null;
            };

            /**
             * Creates a UInt32Value message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.UInt32Value} UInt32Value
             */
            UInt32Value.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.UInt32Value)
                    return object;
                var message = new $root.google.protobuf.UInt32Value();
                if (object.value != null)
                    message.value = object.value >>> 0;
                return message;
            };

            /**
             * Creates a plain object from a UInt32Value message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.UInt32Value
             * @static
             * @param {google.protobuf.UInt32Value} message UInt32Value
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            UInt32Value.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = 0;
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = message.value;
                return object;
            };

            /**
             * Converts this UInt32Value to JSON.
             * @function toJSON
             * @memberof google.protobuf.UInt32Value
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            UInt32Value.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return UInt32Value;
        })();

        protobuf.BoolValue = (function() {

            /**
             * Properties of a BoolValue.
             * @memberof google.protobuf
             * @interface IBoolValue
             * @property {boolean|null} [value] BoolValue value
             */

            /**
             * Constructs a new BoolValue.
             * @memberof google.protobuf
             * @classdesc Represents a BoolValue.
             * @implements IBoolValue
             * @constructor
             * @param {google.protobuf.IBoolValue=} [properties] Properties to set
             */
            function BoolValue(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * BoolValue value.
             * @member {boolean} value
             * @memberof google.protobuf.BoolValue
             * @instance
             */
            BoolValue.prototype.value = false;

            /**
             * Creates a new BoolValue instance using the specified properties.
             * @function create
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {google.protobuf.IBoolValue=} [properties] Properties to set
             * @returns {google.protobuf.BoolValue} BoolValue instance
             */
            BoolValue.create = function create(properties) {
                return new BoolValue(properties);
            };

            /**
             * Encodes the specified BoolValue message. Does not implicitly {@link google.protobuf.BoolValue.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {google.protobuf.IBoolValue} message BoolValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            BoolValue.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 0 =*/8).bool(message.value);
                return writer;
            };

            /**
             * Encodes the specified BoolValue message, length delimited. Does not implicitly {@link google.protobuf.BoolValue.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {google.protobuf.IBoolValue} message BoolValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            BoolValue.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a BoolValue message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.BoolValue} BoolValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            BoolValue.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.BoolValue();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.bool();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a BoolValue message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.BoolValue} BoolValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            BoolValue.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a BoolValue message.
             * @function verify
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            BoolValue.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (typeof message.value !== "boolean")
                        return "value: boolean expected";
                return null;
            };

            /**
             * Creates a BoolValue message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.BoolValue} BoolValue
             */
            BoolValue.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.BoolValue)
                    return object;
                var message = new $root.google.protobuf.BoolValue();
                if (object.value != null)
                    message.value = Boolean(object.value);
                return message;
            };

            /**
             * Creates a plain object from a BoolValue message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.BoolValue
             * @static
             * @param {google.protobuf.BoolValue} message BoolValue
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            BoolValue.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = false;
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = message.value;
                return object;
            };

            /**
             * Converts this BoolValue to JSON.
             * @function toJSON
             * @memberof google.protobuf.BoolValue
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            BoolValue.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return BoolValue;
        })();

        protobuf.StringValue = (function() {

            /**
             * Properties of a StringValue.
             * @memberof google.protobuf
             * @interface IStringValue
             * @property {string|null} [value] StringValue value
             */

            /**
             * Constructs a new StringValue.
             * @memberof google.protobuf
             * @classdesc Represents a StringValue.
             * @implements IStringValue
             * @constructor
             * @param {google.protobuf.IStringValue=} [properties] Properties to set
             */
            function StringValue(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * StringValue value.
             * @member {string} value
             * @memberof google.protobuf.StringValue
             * @instance
             */
            StringValue.prototype.value = "";

            /**
             * Creates a new StringValue instance using the specified properties.
             * @function create
             * @memberof google.protobuf.StringValue
             * @static
             * @param {google.protobuf.IStringValue=} [properties] Properties to set
             * @returns {google.protobuf.StringValue} StringValue instance
             */
            StringValue.create = function create(properties) {
                return new StringValue(properties);
            };

            /**
             * Encodes the specified StringValue message. Does not implicitly {@link google.protobuf.StringValue.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.StringValue
             * @static
             * @param {google.protobuf.IStringValue} message StringValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            StringValue.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 2 =*/10).string(message.value);
                return writer;
            };

            /**
             * Encodes the specified StringValue message, length delimited. Does not implicitly {@link google.protobuf.StringValue.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.StringValue
             * @static
             * @param {google.protobuf.IStringValue} message StringValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            StringValue.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a StringValue message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.StringValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.StringValue} StringValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            StringValue.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.StringValue();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.string();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a StringValue message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.StringValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.StringValue} StringValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            StringValue.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a StringValue message.
             * @function verify
             * @memberof google.protobuf.StringValue
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            StringValue.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!$util.isString(message.value))
                        return "value: string expected";
                return null;
            };

            /**
             * Creates a StringValue message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.StringValue
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.StringValue} StringValue
             */
            StringValue.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.StringValue)
                    return object;
                var message = new $root.google.protobuf.StringValue();
                if (object.value != null)
                    message.value = String(object.value);
                return message;
            };

            /**
             * Creates a plain object from a StringValue message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.StringValue
             * @static
             * @param {google.protobuf.StringValue} message StringValue
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            StringValue.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    object.value = "";
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = message.value;
                return object;
            };

            /**
             * Converts this StringValue to JSON.
             * @function toJSON
             * @memberof google.protobuf.StringValue
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            StringValue.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return StringValue;
        })();

        protobuf.BytesValue = (function() {

            /**
             * Properties of a BytesValue.
             * @memberof google.protobuf
             * @interface IBytesValue
             * @property {Uint8Array|null} [value] BytesValue value
             */

            /**
             * Constructs a new BytesValue.
             * @memberof google.protobuf
             * @classdesc Represents a BytesValue.
             * @implements IBytesValue
             * @constructor
             * @param {google.protobuf.IBytesValue=} [properties] Properties to set
             */
            function BytesValue(properties) {
                if (properties)
                    for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                        if (properties[keys[i]] != null)
                            this[keys[i]] = properties[keys[i]];
            }

            /**
             * BytesValue value.
             * @member {Uint8Array} value
             * @memberof google.protobuf.BytesValue
             * @instance
             */
            BytesValue.prototype.value = $util.newBuffer([]);

            /**
             * Creates a new BytesValue instance using the specified properties.
             * @function create
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {google.protobuf.IBytesValue=} [properties] Properties to set
             * @returns {google.protobuf.BytesValue} BytesValue instance
             */
            BytesValue.create = function create(properties) {
                return new BytesValue(properties);
            };

            /**
             * Encodes the specified BytesValue message. Does not implicitly {@link google.protobuf.BytesValue.verify|verify} messages.
             * @function encode
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {google.protobuf.IBytesValue} message BytesValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            BytesValue.encode = function encode(message, writer) {
                if (!writer)
                    writer = $Writer.create();
                if (message.value != null && message.hasOwnProperty("value"))
                    writer.uint32(/* id 1, wireType 2 =*/10).bytes(message.value);
                return writer;
            };

            /**
             * Encodes the specified BytesValue message, length delimited. Does not implicitly {@link google.protobuf.BytesValue.verify|verify} messages.
             * @function encodeDelimited
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {google.protobuf.IBytesValue} message BytesValue message or plain object to encode
             * @param {$protobuf.Writer} [writer] Writer to encode to
             * @returns {$protobuf.Writer} Writer
             */
            BytesValue.encodeDelimited = function encodeDelimited(message, writer) {
                return this.encode(message, writer).ldelim();
            };

            /**
             * Decodes a BytesValue message from the specified reader or buffer.
             * @function decode
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @param {number} [length] Message length if known beforehand
             * @returns {google.protobuf.BytesValue} BytesValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            BytesValue.decode = function decode(reader, length) {
                if (!(reader instanceof $Reader))
                    reader = $Reader.create(reader);
                var end = length === undefined ? reader.len : reader.pos + length, message = new $root.google.protobuf.BytesValue();
                while (reader.pos < end) {
                    var tag = reader.uint32();
                    switch (tag >>> 3) {
                    case 1:
                        message.value = reader.bytes();
                        break;
                    default:
                        reader.skipType(tag & 7);
                        break;
                    }
                }
                return message;
            };

            /**
             * Decodes a BytesValue message from the specified reader or buffer, length delimited.
             * @function decodeDelimited
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
             * @returns {google.protobuf.BytesValue} BytesValue
             * @throws {Error} If the payload is not a reader or valid buffer
             * @throws {$protobuf.util.ProtocolError} If required fields are missing
             */
            BytesValue.decodeDelimited = function decodeDelimited(reader) {
                if (!(reader instanceof $Reader))
                    reader = new $Reader(reader);
                return this.decode(reader, reader.uint32());
            };

            /**
             * Verifies a BytesValue message.
             * @function verify
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {Object.<string,*>} message Plain object to verify
             * @returns {string|null} `null` if valid, otherwise the reason why it is not
             */
            BytesValue.verify = function verify(message) {
                if (typeof message !== "object" || message === null)
                    return "object expected";
                if (message.value != null && message.hasOwnProperty("value"))
                    if (!(message.value && typeof message.value.length === "number" || $util.isString(message.value)))
                        return "value: buffer expected";
                return null;
            };

            /**
             * Creates a BytesValue message from a plain object. Also converts values to their respective internal types.
             * @function fromObject
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {Object.<string,*>} object Plain object
             * @returns {google.protobuf.BytesValue} BytesValue
             */
            BytesValue.fromObject = function fromObject(object) {
                if (object instanceof $root.google.protobuf.BytesValue)
                    return object;
                var message = new $root.google.protobuf.BytesValue();
                if (object.value != null)
                    if (typeof object.value === "string")
                        $util.base64.decode(object.value, message.value = $util.newBuffer($util.base64.length(object.value)), 0);
                    else if (object.value.length)
                        message.value = object.value;
                return message;
            };

            /**
             * Creates a plain object from a BytesValue message. Also converts values to other types if specified.
             * @function toObject
             * @memberof google.protobuf.BytesValue
             * @static
             * @param {google.protobuf.BytesValue} message BytesValue
             * @param {$protobuf.IConversionOptions} [options] Conversion options
             * @returns {Object.<string,*>} Plain object
             */
            BytesValue.toObject = function toObject(message, options) {
                if (!options)
                    options = {};
                var object = {};
                if (options.defaults)
                    if (options.bytes === String)
                        object.value = "";
                    else {
                        object.value = [];
                        if (options.bytes !== Array)
                            object.value = $util.newBuffer(object.value);
                    }
                if (message.value != null && message.hasOwnProperty("value"))
                    object.value = options.bytes === String ? $util.base64.encode(message.value, 0, message.value.length) : options.bytes === Array ? Array.prototype.slice.call(message.value) : message.value;
                return object;
            };

            /**
             * Converts this BytesValue to JSON.
             * @function toJSON
             * @memberof google.protobuf.BytesValue
             * @instance
             * @returns {Object.<string,*>} JSON object
             */
            BytesValue.prototype.toJSON = function toJSON() {
                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
            };

            return BytesValue;
        })();

        return protobuf;
    })();

    return google;
})();

$root.AccessKey = (function() {

    /**
     * Properties of an AccessKey.
     * @exports IAccessKey
     * @interface IAccessKey
     * @property {number|Long|null} [amount] AccessKey amount
     * @property {google.protobuf.IStringValue|null} [balanceOwner] AccessKey balanceOwner
     * @property {google.protobuf.IStringValue|null} [contractId] AccessKey contractId
     * @property {google.protobuf.IBytesValue|null} [methodName] AccessKey methodName
     */

    /**
     * Constructs a new AccessKey.
     * @exports AccessKey
     * @classdesc Represents an AccessKey.
     * @implements IAccessKey
     * @constructor
     * @param {IAccessKey=} [properties] Properties to set
     */
    function AccessKey(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * AccessKey amount.
     * @member {number|Long} amount
     * @memberof AccessKey
     * @instance
     */
    AccessKey.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * AccessKey balanceOwner.
     * @member {google.protobuf.IStringValue|null|undefined} balanceOwner
     * @memberof AccessKey
     * @instance
     */
    AccessKey.prototype.balanceOwner = null;

    /**
     * AccessKey contractId.
     * @member {google.protobuf.IStringValue|null|undefined} contractId
     * @memberof AccessKey
     * @instance
     */
    AccessKey.prototype.contractId = null;

    /**
     * AccessKey methodName.
     * @member {google.protobuf.IBytesValue|null|undefined} methodName
     * @memberof AccessKey
     * @instance
     */
    AccessKey.prototype.methodName = null;

    /**
     * Creates a new AccessKey instance using the specified properties.
     * @function create
     * @memberof AccessKey
     * @static
     * @param {IAccessKey=} [properties] Properties to set
     * @returns {AccessKey} AccessKey instance
     */
    AccessKey.create = function create(properties) {
        return new AccessKey(properties);
    };

    /**
     * Encodes the specified AccessKey message. Does not implicitly {@link AccessKey.verify|verify} messages.
     * @function encode
     * @memberof AccessKey
     * @static
     * @param {IAccessKey} message AccessKey message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    AccessKey.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.amount);
        if (message.balanceOwner != null && message.hasOwnProperty("balanceOwner"))
            $root.google.protobuf.StringValue.encode(message.balanceOwner, writer.uint32(/* id 2, wireType 2 =*/18).fork()).ldelim();
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            $root.google.protobuf.StringValue.encode(message.contractId, writer.uint32(/* id 3, wireType 2 =*/26).fork()).ldelim();
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            $root.google.protobuf.BytesValue.encode(message.methodName, writer.uint32(/* id 4, wireType 2 =*/34).fork()).ldelim();
        return writer;
    };

    /**
     * Encodes the specified AccessKey message, length delimited. Does not implicitly {@link AccessKey.verify|verify} messages.
     * @function encodeDelimited
     * @memberof AccessKey
     * @static
     * @param {IAccessKey} message AccessKey message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    AccessKey.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes an AccessKey message from the specified reader or buffer.
     * @function decode
     * @memberof AccessKey
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {AccessKey} AccessKey
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    AccessKey.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.AccessKey();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.amount = reader.uint64();
                break;
            case 2:
                message.balanceOwner = $root.google.protobuf.StringValue.decode(reader, reader.uint32());
                break;
            case 3:
                message.contractId = $root.google.protobuf.StringValue.decode(reader, reader.uint32());
                break;
            case 4:
                message.methodName = $root.google.protobuf.BytesValue.decode(reader, reader.uint32());
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes an AccessKey message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof AccessKey
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {AccessKey} AccessKey
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    AccessKey.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies an AccessKey message.
     * @function verify
     * @memberof AccessKey
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    AccessKey.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        if (message.balanceOwner != null && message.hasOwnProperty("balanceOwner")) {
            var error = $root.google.protobuf.StringValue.verify(message.balanceOwner);
            if (error)
                return "balanceOwner." + error;
        }
        if (message.contractId != null && message.hasOwnProperty("contractId")) {
            var error = $root.google.protobuf.StringValue.verify(message.contractId);
            if (error)
                return "contractId." + error;
        }
        if (message.methodName != null && message.hasOwnProperty("methodName")) {
            var error = $root.google.protobuf.BytesValue.verify(message.methodName);
            if (error)
                return "methodName." + error;
        }
        return null;
    };

    /**
     * Creates an AccessKey message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof AccessKey
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {AccessKey} AccessKey
     */
    AccessKey.fromObject = function fromObject(object) {
        if (object instanceof $root.AccessKey)
            return object;
        var message = new $root.AccessKey();
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        if (object.balanceOwner != null) {
            if (typeof object.balanceOwner !== "object")
                throw TypeError(".AccessKey.balanceOwner: object expected");
            message.balanceOwner = $root.google.protobuf.StringValue.fromObject(object.balanceOwner);
        }
        if (object.contractId != null) {
            if (typeof object.contractId !== "object")
                throw TypeError(".AccessKey.contractId: object expected");
            message.contractId = $root.google.protobuf.StringValue.fromObject(object.contractId);
        }
        if (object.methodName != null) {
            if (typeof object.methodName !== "object")
                throw TypeError(".AccessKey.methodName: object expected");
            message.methodName = $root.google.protobuf.BytesValue.fromObject(object.methodName);
        }
        return message;
    };

    /**
     * Creates a plain object from an AccessKey message. Also converts values to other types if specified.
     * @function toObject
     * @memberof AccessKey
     * @static
     * @param {AccessKey} message AccessKey
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    AccessKey.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
            object.balanceOwner = null;
            object.contractId = null;
            object.methodName = null;
        }
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        if (message.balanceOwner != null && message.hasOwnProperty("balanceOwner"))
            object.balanceOwner = $root.google.protobuf.StringValue.toObject(message.balanceOwner, options);
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            object.contractId = $root.google.protobuf.StringValue.toObject(message.contractId, options);
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            object.methodName = $root.google.protobuf.BytesValue.toObject(message.methodName, options);
        return object;
    };

    /**
     * Converts this AccessKey to JSON.
     * @function toJSON
     * @memberof AccessKey
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    AccessKey.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return AccessKey;
})();

module.exports = $root;

},{"protobufjs/minimal":46}],68:[function(require,module,exports){
const KeyPair = require('./key_pair');

/**
 * Utility functions for dealing with account information. 
 */
class AccountInfo {
    constructor(accountId, keyPair, networkId) {
        this.accountId = accountId;
        this.keyPair = keyPair;
        this.networkId = networkId;
    }

    /**
     * Reconstruct account info object from json.
     * @param {Object} json 
     */
    static fromJson(json) {
        if (!json.public_key || !json.secret_key || !json.account_id || !json.network_id) {
            throw 'Invalid account info format. Please ensure it contains public_key, secret_key, and account_id".';
        }
        return new AccountInfo(json.account_id, new KeyPair(json.public_key, json.secret_key), json.network_id);
    }

    /**
     * Convert to standard json format.
     */
    toJSON() {
        return {
            account_id: this.accountId,
            public_key: this.keyPair.getPublicKey(),
            secret_key: this.keyPair.getSecretKey(),
            network_id: this.networkId
        };
    }

    /**
     * Utility function to download account info as a standard file.
     */
    downloadAsFile() {
        const fileName = this.keyFileName;
        const text = JSON.stringify(this.toJSON());
      
        var element = document.createElement('a');
        element.setAttribute('href', 'data:text/plain;charset=utf-8,' + encodeURIComponent(text));
        element.setAttribute('download', fileName);
      
        element.style.display = 'none';
        document.body.appendChild(element);
      
        element.click();
      
        document.body.removeChild(element);
    }

    get keyFileName() {
        return this.networkId + '_' + this.accountId;
    }
}

module.exports = AccountInfo;

},{"./key_pair":71}],69:[function(require,module,exports){
/**
 * Stores keys in the browser local storage. This allows to retain keys between
 * browser sessions. Local storage likes to work with strings so we store public and private key separately.
 */
const KeyPair = require('./key_pair');
const AccountInfo = require('./account_info');

const LOCAL_STORAGE_SECRET_KEY_SUFFIX = '_secretkey';
const LOCAL_STORAGE_PUBLIC_KEY_SUFFIX = '_publickey';

class BrowserLocalStorageKeystore {
    constructor(networkId = 'unknown', localStorage = window.localStorage) {
        this.networkId = networkId;
        this.localStorage = localStorage;
    }

    static storageKeyForPublicKey(accountId) {
        return accountId + '_' + this.networkId + LOCAL_STORAGE_PUBLIC_KEY_SUFFIX;
    }

    static storageKeyForSecretKey(accountId) {
        return accountId + '_' + this.networkId + LOCAL_STORAGE_SECRET_KEY_SUFFIX;
    }

    /**
     * Save the key in local storage. 
     * @param {string} accountId 
     * @param {KeyPair} key 
     */
    async setKey(accountId, key) {
        this.localStorage.setItem(
            BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
        this.localStorage.setItem(
            BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
    }

    async setKeyFromJson(json) {
        const accountInfo =  AccountInfo.fromJson(json);
        if (this.networkId != accountInfo.networkId) {
            throw new Error('Setting key for a wrong network');
        }
        this.setKey(accountInfo.accountId, accountInfo.keyPair);
    }

    /**
     * Get the key from local storage and return as KeyPair object.
     * @param {string} accountId 
     */
    async getKey(accountId) {
        const publicKey = this.localStorage.getItem(
            BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId));
        const secretKey = this.localStorage.getItem(
            BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId));
        if (!publicKey || !secretKey) {
            return null;
        }
        return new KeyPair(publicKey, secretKey);
    }

    static getAccounts() {
        return Object.keys(this.localStorage).map(function(key) {
            if (key.endsWith('_public')) {
                return key.substr(0, key.length() - 7);
            }
        });
    }
}

module.exports = BrowserLocalStorageKeystore;
},{"./account_info":68,"./key_pair":71}],70:[function(require,module,exports){
/**
 * Simple in-memory keystore for testing purposes.
 */
class InMemoryKeyStore {
    constructor(networkId) {
        this.networkId = networkId;
        this.keys = {};
    }

    async setKey(accountId, key) {
        this.keys[accountId + '_' + this.networkId] = key;
    }

    async getKey(accountId) {
        return this.keys[accountId  + '_' + this.networkId];
    }

    async clear() {
        this.keys = {};
    }
}

module.exports = InMemoryKeyStore;
},{}],71:[function(require,module,exports){
(function (Buffer){

const bs58 = require('bs58');
const nacl = require('tweetnacl');

/**
 * This class provides key pair functionality (generating key pairs, encoding key pairs).
 */
class KeyPair {
    /**
     * Construct an instance of key pair given a public key and secret key. It's generally assumed that these
     * are encoded in bs58.
     * @param {string} publicKey 
     * @param {string} secretKey 
     */
    constructor(publicKey, secretKey) {
        this.publicKey = publicKey;
        this.secretKey = secretKey;
    }

    /**
     * Get the public key.
     */
    getPublicKey() {
        return this.publicKey;
    }

    /**
     * Get the secret key.
     * @example
     *  // Passing existing key into a function to store in local storage
     *  async setKey(accountId, key) {
     *      window.localStorage.setItem(
     *          BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
     *      window.localStorage.setItem(
     *          BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
     *  }
     */
    getSecretKey() {
        return this.secretKey;
    }

    /**
     * Generate a new keypair from a random seed
     * @example
     * const keyWithRandomSeed = KeyPair.fromRandomSeed();
     * keyWithRandomSeed.getPublicKey()
     * // returns [PUBLIC_KEY]
     * 
     * keyWithRandomSeed.getSecretKey()
     * // returns [SECRET_KEY]
     */
    static fromRandomSeed() {
        let newKeypair = nacl.sign.keyPair();
        const result = new KeyPair(
            KeyPair.encodeBufferInBs58(newKeypair.publicKey),
            KeyPair.encodeBufferInBs58(newKeypair.secretKey));
        return result;
    }

    /**
     * Encode a buffer as string using bs58
     * @param {Buffer} buffer 
     * @example
     * KeyPair.encodeBufferInBs58(key.publicKey)
     */
    static encodeBufferInBs58(buffer) {
        const bytes = Buffer.from(buffer);
        const encodedValue = bs58.encode(bytes);
        return encodedValue;
    }
}
module.exports = KeyPair;

}).call(this,require("buffer").Buffer)
},{"bs58":20,"buffer":21,"tweetnacl":62}],72:[function(require,module,exports){
/**
 * Simple signer that acquires a key from its single keystore and signs transactions.
 */
const bs58 = require('bs58');
const nacl = require('tweetnacl');
const { sha256 } = require('js-sha256');
const { google } = require('../protos');

class SimpleKeyStoreSigner {
    constructor(keyStore) {
        this.keyStore = keyStore;
    }

    /**
     * Signs a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        return this.signHash(new Uint8Array(sha256.array(buffer)), originator);
    }

    async signHash(hash, originator) {
        const encodedKey = await this.keyStore.getKey(originator);
        if (!encodedKey) {
            throw new Error(`Cannot find key for originator ${originator}`);
        }
        const key = bs58.decode(encodedKey.getSecretKey());
        const signature = [...nacl.sign.detached(Uint8Array.from(hash), key)];
        return {
            signature,
            publicKey: google.protobuf.BytesValue.create({
                value: bs58.decode(encodedKey.getPublicKey()),
            }),
        };
    }
}

module.exports = SimpleKeyStoreSigner;

},{"../protos":67,"bs58":20,"js-sha256":40,"tweetnacl":62}],73:[function(require,module,exports){
/**
 * Access Key based signer that uses Wallet to authorize app on the account and receive the access key.
 */

const KeyPair = require('./signing/key_pair');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');

const LOGIN_WALLET_URL_SUFFIX = '/login_v2/';
const LOCAL_STORAGE_KEY_SUFFIX = '_wallet_access_key';

/**
 * Access Key based signer that uses Wallet to authorize app on the account and receive the access key.
 * @example
 * // if importing WalletAccessKey directly
 * const walletAccount = new WalletAccessKey(contractName, walletBaseUrl)
 * // if importing in all of nearLib and calling from variable
 * const walletAccount = new nearlib.WalletAccessKey(contractName, walletBaseUrl)
 * // To access this signer globally
 * window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl);
 * // To provide custom signer where the keys would be stored
 * window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl, customSigner);
 */
class WalletAccessKey {
    constructor(appKeyPrefix, walletBaseUrl = 'https://wallet.nearprotocol.com', signer = null) {
        this._walletBaseUrl = walletBaseUrl;
        this._authDataKey = appKeyPrefix + LOCAL_STORAGE_KEY_SUFFIX;
        this._signer = signer || (new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore()));

        this._authData = JSON.parse(window.localStorage.getItem(this._authDataKey) || '{}');

        if (!this.isSignedIn()) {
            this._tryInitFromUrl();
        }
    }

    /**
     * Returns true, if this WalletAccount is authorized with the wallet.
     * @example
     * walletAccount.isSignedIn();
     */
    isSignedIn() {
        return !!this._authData.accountId;
    }

    /**
     * Returns authorized Account ID.
     * @example
     * walletAccount.getAccountId();
     */
    getAccountId() {
        return this._authData.accountId || '';
    }

    /**
     * Redirects current page to the wallet authentication page.
     * @param {string} contractId contract ID of the application
     * @param {string} title name of the application
     * @param {string} successUrl url to redirect on success
     * @param {string} failureUrl url to redirect on failure
     */
    requestSignIn(contractId, title, successUrl, failureUrl) {
        this._authData.key = KeyPair.fromRandomSeed();
        const currentUrl = new URL(window.location.href);
        let newUrl = new URL(this._walletBaseUrl + LOGIN_WALLET_URL_SUFFIX);
        newUrl.searchParams.set('title', title);
        newUrl.searchParams.set('contract_id', contractId);
        newUrl.searchParams.set('public_key', this._authData.key.getPublicKey());
        newUrl.searchParams.set('success_url', successUrl || currentUrl.href);
        newUrl.searchParams.set('failure_url', failureUrl || currentUrl.href);
        newUrl.searchParams.set('app_url', currentUrl.origin);
        window.location.replace(newUrl.toString());
    }
    /**
     * Sign out from the current account
     * @example
     * walletAccount.signOut();
     */
    signOut() {
        if (this._authData.accountId) {
            this._signer.keyStore.setKey(this.getAccountId(), null).catch(console.error);
            this._authData = {};
            window.localStorage.removeItem(this._authDataKey);
        }
    }

    _saveAuthData() {
        window.localStorage.setItem(this._authDataKey, JSON.stringify(this._authData));
    }

    _tryInitFromUrl() {
        if (this._authData.key) {
            let currentUrl = new URL(window.location.href);
            let publicKey = currentUrl.searchParams.get('public_key') || '';
            let accountId = currentUrl.searchParams.get('account_id') || '';
            if (accountId && publicKey === this._authData.key.getPublicKey()) {
                this._signer.keyStore.setKey(accountId, this._authData.key);
                this._authData = {
                    accountId,
                    publicKey,
                };
                this._saveAuthData();
            }
        }
    }

    /**
     * Sign a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        if (!this.isSignedIn() || originator !== this.getAccountId()) {
            throw 'Unauthorized account_id ' + originator;
        }
        return await this._signer.signBuffer(buffer, originator);
    }

}

module.exports = WalletAccessKey;

},{"./signing/browser_local_storage_key_store":69,"./signing/key_pair":71,"./signing/simple_key_store_signer":72}],74:[function(require,module,exports){
(function (Buffer){
/**
 * Wallet based account and signer that uses external wallet through the iframe to sign transactions.
 */

const { sha256 } = require('js-sha256');
const { FunctionCallTransaction } = require('./protos');

const EMBED_WALLET_URL_SUFFIX = '/embed/';
const LOGIN_WALLET_URL_SUFFIX = '/login/';
const RANDOM_ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
const REQUEST_ID_LENGTH = 32;

const LOCAL_STORAGE_KEY_SUFFIX = '_wallet_auth_key';

/**
 * Wallet based account and signer that uses external wallet through the iframe to sign transactions.
 * @example 
 * // if importing WalletAccount directly
 * const walletAccount = new WalletAccount(contractName, walletBaseUrl)
 * // if importing in all of nearLib and calling from variable 
 * const walletAccount = new nearlib.WalletAccount(contractName, walletBaseUrl)
 * // To access wallet globally use:
 * window.walletAccount = new nearlib.WalletAccount(config.contractName, walletBaseUrl);
 */
class WalletAccount {

    constructor(appKeyPrefix, walletBaseUrl = 'https://wallet.nearprotocol.com') {
        this._walletBaseUrl = walletBaseUrl;
        this._authDataKey = appKeyPrefix + LOCAL_STORAGE_KEY_SUFFIX;

        this._initHtmlElements();
        this._signatureRequests = {};
        this._authData = JSON.parse(window.localStorage.getItem(this._authDataKey) || '{}');

        if (!this.isSignedIn()) {
            this._tryInitFromUrl();
        }
    }

    /**
     * Returns true, if this WalletAccount is authorized with the wallet.
     * @example
     * walletAccount.isSignedIn();
     */
    isSignedIn() {
        return !!this._authData.accountId;
    }

    /**
     * Returns authorized Account ID.
     * @example 
     * walletAccount.getAccountId();
     */
    getAccountId() {
        return this._authData.accountId || '';
    }

    /**
     * Redirects current page to the wallet authentication page.
     * @param {string} contract_id contract ID of the application
     * @param {string} title name of the application
     * @param {string} success_url url to redirect on success
     * @param {string} failure_url url to redirect on failure
     * @example
     *   walletAccount.requestSignIn(
     *     myContractId,
     *     title,
     *     onSuccessHref,
     *     onFailureHref);
     */
    requestSignIn(contract_id, title, success_url, failure_url) {
        const currentUrl = new URL(window.location.href);
        let newUrl = new URL(this._walletBaseUrl + LOGIN_WALLET_URL_SUFFIX);
        newUrl.searchParams.set('title', title);
        newUrl.searchParams.set('contract_id', contract_id);
        newUrl.searchParams.set('success_url', success_url || currentUrl.href);
        newUrl.searchParams.set('failure_url', failure_url || currentUrl.href);
        newUrl.searchParams.set('app_url', currentUrl.origin);
        window.location.replace(newUrl.toString());
    }
    /**
     * Sign out from the current account
     * @example
     * walletAccount.signOut();
     */
    signOut() {
        this._authData = {};
        window.localStorage.removeItem(this._authDataKey);
    }

    _tryInitFromUrl() {
        let currentUrl = new URL(window.location.href);
        let authToken = currentUrl.searchParams.get('auth_token') || '';
        let accountId = currentUrl.searchParams.get('account_id') || '';
        if (!!authToken && !!accountId) {
            this._authData = {
                authToken,
                accountId,
            };
            window.localStorage.setItem(this._authDataKey, JSON.stringify(this._authData));
        }
    }

    _initHtmlElements() {
        // Wallet iframe
        const iframe = document.createElement('iframe');
        iframe.style = 'display: none;';
        iframe.src = this._walletBaseUrl + EMBED_WALLET_URL_SUFFIX;
        document.body.appendChild(iframe);
        this._walletWindow = iframe.contentWindow;

        // Message Event
        window.addEventListener('message', this.receiveMessage.bind(this), false);
    }

    receiveMessage(event) {
        if (!this._walletBaseUrl.startsWith(event.origin)) {
            // Only processing wallet messages.
            console.log('Wallet account ignoring message from ' + event.origin);
            return;
        }
        let data;
        try {
            data = JSON.parse(event.data);
        } catch (e) {
            console.error('Can\'t parse the result', event.data, e);
            return;
        }
        const request_id = data.request_id || '';
        if (!(request_id in this._signatureRequests)) {
            console.error('Request ID' + request_id + ' was not found');
            return;
        }
        let signatureRequest = this._signatureRequests[request_id];
        delete this._signatureRequests[request_id];

        if (data.success) {
            signatureRequest.resolve(data.result);
        } else {
            signatureRequest.reject(data.error);
        }
    }

    _randomRequestId() {
        var result = '';

        for (var i = 0; i < REQUEST_ID_LENGTH; i++) {
            result += RANDOM_ALPHABET.charAt(Math.floor(Math.random() * RANDOM_ALPHABET.length));
        }

        return result;
    }

    _remoteSign(hash, methodName, args) {
        // TODO(#482): Add timeout.
        return new Promise((resolve, reject) => {
            const request_id = this._randomRequestId();
            this._signatureRequests[request_id] = {
                request_id,
                resolve,
                reject,
            };
            this._walletWindow.postMessage(JSON.stringify({
                action: 'sign_transaction',
                token: this._authData.authToken,
                method_name: methodName,
                args: args || {},
                hash,
                request_id,
            }), this._walletBaseUrl);
        });
    }

    /**
     * Sign a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        if (!this.isSignedIn() || originator !== this.getAccountId()) {
            throw 'Unauthorized account_id ' + originator;
        }
        const body = FunctionCallTransaction.decode(buffer);
        let methodName = Buffer.from(body.methodName).toString();
        let args = JSON.parse(Buffer.from(body.args).toString());
        let signature = await this._remoteSign(sha256.array(buffer), methodName, args);
        return {
            signature,
        };
    }

}

module.exports = WalletAccount;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"buffer":21,"js-sha256":40}]},{},[2]);

'''
'''--- nearlib/dist/nearlib.min.js ---
(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
(function (Buffer){
const bs58=require("bs58"),{google:google,AccessKey:AccessKey,AddKeyTransaction:AddKeyTransaction,CreateAccountTransaction:CreateAccountTransaction,SignedTransaction:SignedTransaction}=require("./protos"),KeyPair=require("./signing/key_pair");class Account{constructor(e){this.nearClient=e}async createAccount(e,n,t,a){const c=await this.nearClient.getNonce(a);n=bs58.decode(n);const r=CreateAccountTransaction.create({nonce:c,originator:a,newAccountId:e,publicKey:n});0!==t&&(r.amount=t);const i=CreateAccountTransaction.encode(r).finish(),o=await this.nearClient.signer.signBuffer(i,a),s=SignedTransaction.create({createAccount:r,signature:o.signature,publicKey:o.publicKey});return this.nearClient.submitTransaction(s)}async addAccessKey(e,n,t,a,c,r){const i=await this.nearClient.getNonce(e);n=bs58.decode(n);const o=AccessKey.create({});t&&(o.contractId=google.protobuf.StringValue.create({value:t})),a&&(o.methodName=google.protobuf.BytesValue.create({value:new Uint8Array(Buffer.from(a))})),c&&(o.balanceOwner=google.protobuf.StringValue.create({value:c})),r>0&&(o.amount=r);const s=AddKeyTransaction.create({nonce:i,originator:e,newKey:n,accessKey:o}),u=AddKeyTransaction.encode(s).finish(),g=await this.nearClient.signer.signBuffer(u,e),d=SignedTransaction.create({addKey:s,signature:g.signature,publicKey:g.publicKey});return this.nearClient.submitTransaction(d)}async createAccountWithRandomKey(e,n,t){const a=KeyPair.fromRandomSeed(),c=await this.createAccount(e,a.getPublicKey(),n,t);return{key:a,...c}}async viewAccount(e){return await this.nearClient.viewAccount(e)}}module.exports=Account;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"./signing/key_pair":71,"bs58":20,"buffer":21}],2:[function(require,module,exports){
(function (Buffer){
require("error-polyfill"),window.nearlib=require("./index"),window.nearlib.dev=require("./dev"),window.Buffer=Buffer;

}).call(this,require("buffer").Buffer)
},{"./dev":4,"./index":3,"buffer":21,"error-polyfill":28}],3:[function(require,module,exports){
const Near=require("./near"),NearClient=require("./nearclient"),Account=require("./account"),SimpleKeyStoreSigner=require("./signing/simple_key_store_signer"),InMemoryKeyStore=require("./signing/in_memory_key_store"),BrowserLocalStorageKeystore=require("./signing/browser_local_storage_key_store"),LocalNodeConnection=require("./local_node_connection"),KeyPair=require("./signing/key_pair"),WalletAccount=require("./wallet-account"),dev=require("./dev"),AccountInfo=require("./signing/account_info"),WalletAccessKey=require("./wallet-access-key");module.exports={Near:Near,NearClient:NearClient,Account:Account,SimpleKeyStoreSigner:SimpleKeyStoreSigner,InMemoryKeyStore:InMemoryKeyStore,BrowserLocalStorageKeystore:BrowserLocalStorageKeystore,LocalNodeConnection:LocalNodeConnection,KeyPair:KeyPair,WalletAccount:WalletAccount,dev:dev,AccountInfo:AccountInfo,WalletAccessKey:WalletAccessKey};

},{"./account":1,"./dev":4,"./local_node_connection":6,"./near":7,"./nearclient":8,"./signing/account_info":68,"./signing/browser_local_storage_key_store":69,"./signing/in_memory_key_store":70,"./signing/key_pair":71,"./signing/simple_key_store_signer":72,"./wallet-access-key":73,"./wallet-account":74}],4:[function(require,module,exports){
const Near=require("./near"),NearClient=require("./nearclient"),Account=require("./account"),SimpleKeyStoreSigner=require("./signing/simple_key_store_signer"),BrowserLocalStorageKeystore=require("./signing/browser_local_storage_key_store"),LocalNodeConnection=require("./local_node_connection"),KeyPair=require("./signing/key_pair"),sendJson=require("./internal/send-json"),storageAccountIdKey="dev_near_user",devKey=new KeyPair("22skMptHjFWNyuEWY22ftn2AbLPSYpmYwGJRGwpNHbTV","2wyRcSwSuHtRVmkMCGjPwnzZmQLeXLzLLyED1NDMt4BjnKgQL6tF85yBx6Jr26D2dUNeC716RBoTxntVHsegogYw"),devAccountName="alice.near",localNodeUrl="http://localhost:3030";function getCookie(e){var t=document.cookie.match("(^|;) ?"+e+"=([^;]*)(;|$)");return t?t[2]:null}module.exports={getConfig:async function(){return JSON.parse(decodeURIComponent(getCookie("fiddleConfig")))||{}},connect:async function(e={}){this.options=Object.assign({deps:{}},e),this.deps=this.options.deps,this.options.useDevAccount&&(this.options.accountId="alice.near",this.options.key=devKey),this.options.helperUrl=this.options.helperUrl||this.options.baseUrl,this.deps.createAccount||(this.options.helperUrl?this.deps.createAccount=this.createAccountWithContractHelper.bind(this):this.deps.createAccount=this.createAccountWithLocalNodeConnection.bind(this)),this.options.networkId=this.options.networkId||"localhost",this.options.nodeUrl=this.options.nodeUrl||(await this.getConfig()).nodeUrl||localNodeUrl,this.deps.keyStore=this.deps.keyStore||new BrowserLocalStorageKeystore(this.options.networkId),this.deps.storage=this.deps.storage||window.localStorage;const t=new NearClient(new SimpleKeyStoreSigner(this.deps.keyStore),new LocalNodeConnection(this.options.nodeUrl));return this.near=new Near(t),this.options.accountId&&this.options.key&&this.deps.keyStore.setKey(this.options.accountId,this.options.key),this.options.accountId||await this.getOrCreateDevUser(),this.near},getOrCreateDevUser:async function(){let e=this.deps.storage.getItem("dev_near_user");const t=await this.deps.keyStore.getKey(e);if(e&&t){const t=new Account(this.near.nearClient);try{return await t.viewAccount(e),e}catch(e){console.log("Error looking up temp account",e)}}else e="devuser"+Date.now();const o=KeyPair.fromRandomSeed(),n=this.deps.createAccount?this.deps.createAccount:async(e,t)=>this.createAccountWithContractHelper(await this.getConfig(),e,t);return await n.bind(this,e,o.getPublicKey())(),this.deps.keyStore.setKey(e,o),this.deps.storage.setItem("dev_near_user",e),e},get myAccountId(){return this.deps.storage.getItem("dev_near_user")},createAccountWithLocalNodeConnection:async function(e,t){const o=new Account(this.near.nearClient);this.deps.keyStore.setKey("alice.near",devKey);const n=await o.createAccount(e,t,1,"alice.near");await this.near.waitForTransactionResult(n)},createAccountWithContractHelper:async function(e,t){return await sendJson("POST",`${this.options.helperUrl}/account`,{newAccountId:e,newAccountPublicKey:t})}};

},{"./account":1,"./internal/send-json":5,"./local_node_connection":6,"./near":7,"./nearclient":8,"./signing/browser_local_storage_key_store":69,"./signing/key_pair":71,"./signing/simple_key_store_signer":72}],5:[function(require,module,exports){
let fetch="undefined"==typeof window||"nodejs"==window.name?require("node-fetch"):window.fetch;const createError=require("http-errors");module.exports=async function(t,e,o){const r=await fetch(e,{method:t,body:"GET"!=t?JSON.stringify(o):void 0,headers:{"Content-type":"application/json; charset=utf-8"}});if(!r.ok)throw createError(r.status,await r.text());return 204===r.status?null:await r.json()};

},{"http-errors":37,"node-fetch":19}],6:[function(require,module,exports){
const sendJson=require("./internal/send-json");class LocalNodeConnection{constructor(n){this.baseUrl=n}async request(n,e){return await sendJson("POST",`${this.baseUrl}/${n}`,e)}}module.exports=LocalNodeConnection;

},{"./internal/send-json":5}],7:[function(require,module,exports){
(function (Buffer){
const createError=require("http-errors"),NearClient=require("./nearclient"),BrowserLocalStorageKeystore=require("./signing/browser_local_storage_key_store"),SimpleKeyStoreSigner=require("./signing/simple_key_store_signer"),LocalNodeConnection=require("./local_node_connection"),{DeployContractTransaction:DeployContractTransaction,FunctionCallTransaction:FunctionCallTransaction,SignedTransaction:SignedTransaction}=require("./protos"),MAX_STATUS_POLL_ATTEMPTS=10,STATUS_POLL_PERIOD_MS=2e3;class Near{constructor(t){this.nearClient=t}static createDefaultConfig(t="http://localhost:3030"){return new Near(new NearClient(new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore),new LocalNodeConnection(t)))}async callViewFunction(t,n,e){return this.nearClient.callViewFunction(t,n,e)}async scheduleFunctionCall(t,n,e,a,r){r||(r={}),a=new Uint8Array(Buffer.from(a)),r=new Uint8Array(Buffer.from(JSON.stringify(r)));const o=await this.nearClient.getNonce(n),i=FunctionCallTransaction.create({nonce:o,originator:n,contractId:e,methodName:a,args:r});0!==t&&(i.amount=t);const s=FunctionCallTransaction.encode(i).finish(),c=await this.nearClient.signer.signBuffer(s,n),l=SignedTransaction.create({functionCall:i,signature:c.signature,publicKey:c.publicKey});return await this.nearClient.submitTransaction(l)}async deployContract(t,n){const e=await this.nearClient.getNonce(t),a=DeployContractTransaction.create({nonce:e,contractId:t,wasmByteArray:n}),r=DeployContractTransaction.encode(a).finish(),o=await this.nearClient.signer.signBuffer(r,t),i=SignedTransaction.create({deployContract:a,signature:o.signature,publicKey:o.publicKey});return await this.nearClient.submitTransaction(i)}async getTransactionStatus(t){return this.nearClient.getTransactionStatus(t)}async waitForTransactionResult(t,n={}){const e=t.hasOwnProperty("hash")?t.hash:t,a=n.contractAccountId||"unknown contract";let r,o=[];for(let t=0;t<MAX_STATUS_POLL_ATTEMPTS;t++){let t;for(await sleep(STATUS_POLL_PERIOD_MS),r=await this.getTransactionStatus(e),t=0;t<o.length&&o[t]==r.logs[t];t++);for(t!=o.length&&console.warn("new logs:",r.logs,"iconsistent with already displayed logs:",o);t<r.logs.length;++t){const n=r.logs[t];console.log(`[${a}]: ${n}`),o.push(n)}if("Completed"==r.status)return r.value&&(r.lastResult=JSON.parse(Buffer.from(r.value,"base64").toString())),r;if("Failed"==r.status){const t=r.logs.find(t=>t.startsWith("ABORT:"))||"",n=Buffer.from(e).toString("base64");throw createError(400,`Transaction ${n} on ${a} failed. ${t}`)}}throw createError(408,`Exceeded ${MAX_STATUS_POLL_ATTEMPTS} status check attempts `+`for transaction ${e} on ${a} with status: ${r.status}`)}async loadContract(t,n){let e={},a=this;return n.viewMethods.forEach(n=>{e[n]=async function(e){return e=e||{},a.callViewFunction(t,n,e)}}),n.changeMethods.forEach(r=>{e[r]=async function(e){e=e||{};const o=await a.scheduleFunctionCall(0,n.sender,t,r,e);return a.waitForTransactionResult(o.hash,{contractAccountId:t})}}),e}}function sleep(t){return new Promise(function(n){setTimeout(n,t)})}module.exports=Near;

}).call(this,require("buffer").Buffer)
},{"./local_node_connection":6,"./nearclient":8,"./protos":67,"./signing/browser_local_storage_key_store":69,"./signing/simple_key_store_signer":72,"buffer":21,"http-errors":37}],8:[function(require,module,exports){
(function (Buffer){
const{SignedTransaction:SignedTransaction}=require("./protos");function _arrayBufferToBase64(e){return Buffer.from(e).toString("base64")}function _base64ToBuffer(e){return new Buffer.from(e,"base64")}class NearClient{constructor(e,t){this.signer=e,this.nearConnection=t}async viewAccount(e){const t=await this.jsonRpcRequest("abci_query",[`account/${e}`,"","0",!1]);return JSON.parse(_base64ToBuffer(t.response.value).toString())}async submitTransaction(e){const t=[_arrayBufferToBase64(SignedTransaction.encode(e).finish())],r=await this.jsonRpcRequest("broadcast_tx_async",t);return r.hash=Buffer.from(r.hash,"hex"),r}async callViewFunction(e,t,r){r||(r={});const n=Buffer.from(JSON.stringify(r)).toString("hex"),s=(await this.jsonRpcRequest("abci_query",[`call/${e}/${t}`,n,"0",!1])).response;let o=[];if(void 0!==s.log&&s.log.length>0&&(o=s.log.split("\n")),o.forEach(t=>{console.log(`[${e}]: ${t}`)}),0!=(s.code||0))throw Error(s.info);return JSON.parse(_base64ToBuffer(s.value).toString())}async getTransactionStatus(e){const t=_arrayBufferToBase64(e),r=await this.jsonRpcRequest("tx",[t,!1]),n={0:"Completed",1:"Failed",2:"Started"}[r.tx_result.code||0]||"Unknown";let s=[];return void 0!==r.tx_result&&void 0!==r.tx_result.log&&r.tx_result.log.length>0&&(s=r.tx_result.log.split("\n")),{logs:s,status:n,value:r.tx_result.data}}async getNonce(e){return(await this.viewAccount(e)).nonce+1}async jsonRpcRequest(e,t){const r={jsonrpc:"2.0",method:e,params:t,id:Date.now().toString()},n=await this.nearConnection.request("",r);if(n.error)throw Error(`Error calling ${e} with ${t}: ${n.error.message}.\nFull response: ${JSON.stringify(n)}`);return n.result}async request(e,t){return this.nearConnection.request(e,t)}}module.exports=NearClient;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"buffer":21}],9:[function(require,module,exports){
"use strict";function asPromise(e,n){for(var r=new Array(arguments.length-1),t=0,l=2,o=!0;l<arguments.length;)r[t++]=arguments[l++];return new Promise(function(l,a){r[t]=function(e){if(o)if(o=!1,e)a(e);else{for(var n=new Array(arguments.length-1),r=0;r<n.length;)n[r++]=arguments[r];l.apply(null,n)}};try{e.apply(n||null,r)}catch(e){o&&(o=!1,a(e))}})}module.exports=asPromise;

},{}],10:[function(require,module,exports){
"use strict";var base64=exports;base64.length=function(r){var a=r.length;if(!a)return 0;for(var e=0;--a%4>1&&"="===r.charAt(a);)++e;return Math.ceil(3*r.length)/4-e};for(var b64=new Array(64),s64=new Array(123),i=0;i<64;)s64[b64[i]=i<26?i+65:i<52?i+71:i<62?i-4:i-59|43]=i++;base64.encode=function(r,a,e){for(var i,n=null,t=[],o=0,s=0;a<e;){var c=r[a++];switch(s){case 0:t[o++]=b64[c>>2],i=(3&c)<<4,s=1;break;case 1:t[o++]=b64[i|c>>4],i=(15&c)<<2,s=2;break;case 2:t[o++]=b64[i|c>>6],t[o++]=b64[63&c],s=0}o>8191&&((n||(n=[])).push(String.fromCharCode.apply(String,t)),o=0)}return s&&(t[o++]=b64[i],t[o++]=61,1===s&&(t[o++]=61)),n?(o&&n.push(String.fromCharCode.apply(String,t.slice(0,o))),n.join("")):String.fromCharCode.apply(String,t.slice(0,o))};var invalidEncoding="invalid encoding";base64.decode=function(r,a,e){for(var i,n=e,t=0,o=0;o<r.length;){var s=r.charCodeAt(o++);if(61===s&&t>1)break;if(void 0===(s=s64[s]))throw Error(invalidEncoding);switch(t){case 0:i=s,t=1;break;case 1:a[e++]=i<<2|(48&s)>>4,i=s,t=2;break;case 2:a[e++]=(15&i)<<4|(60&s)>>2,i=s,t=3;break;case 3:a[e++]=(3&i)<<6|s,t=0}}if(1===t)throw Error(invalidEncoding);return e-n},base64.test=function(r){return/^(?:[A-Za-z0-9+\/]{4})*(?:[A-Za-z0-9+\/]{2}==|[A-Za-z0-9+\/]{3}=)?$/.test(r)};

},{}],11:[function(require,module,exports){
"use strict";function EventEmitter(){this._listeners={}}module.exports=EventEmitter,EventEmitter.prototype.on=function(t,e,i){return(this._listeners[t]||(this._listeners[t]=[])).push({fn:e,ctx:i||this}),this},EventEmitter.prototype.off=function(t,e){if(void 0===t)this._listeners={};else if(void 0===e)this._listeners[t]=[];else for(var i=this._listeners[t],s=0;s<i.length;)i[s].fn===e?i.splice(s,1):++s;return this},EventEmitter.prototype.emit=function(t){var e=this._listeners[t];if(e){for(var i=[],s=1;s<arguments.length;)i.push(arguments[s++]);for(s=0;s<e.length;)e[s].fn.apply(e[s++].ctx,i)}return this};

},{}],12:[function(require,module,exports){
"use strict";function factory(n){return"undefined"!=typeof Float32Array?function(){var t=new Float32Array([-0]),e=new Uint8Array(t.buffer),r=128===e[3];function i(n,r,i){t[0]=n,r[i]=e[0],r[i+1]=e[1],r[i+2]=e[2],r[i+3]=e[3]}function a(n,r,i){t[0]=n,r[i]=e[3],r[i+1]=e[2],r[i+2]=e[1],r[i+3]=e[0]}function o(n,r){return e[0]=n[r],e[1]=n[r+1],e[2]=n[r+2],e[3]=n[r+3],t[0]}function u(n,r){return e[3]=n[r],e[2]=n[r+1],e[1]=n[r+2],e[0]=n[r+3],t[0]}n.writeFloatLE=r?i:a,n.writeFloatBE=r?a:i,n.readFloatLE=r?o:u,n.readFloatBE=r?u:o}():function(){function t(n,t,e,r){var i=t<0?1:0;if(i&&(t=-t),0===t)n(1/t>0?0:2147483648,e,r);else if(isNaN(t))n(2143289344,e,r);else if(t>3.4028234663852886e38)n((i<<31|2139095040)>>>0,e,r);else if(t<1.1754943508222875e-38)n((i<<31|Math.round(t/1.401298464324817e-45))>>>0,e,r);else{var a=Math.floor(Math.log(t)/Math.LN2);n((i<<31|a+127<<23|8388607&Math.round(t*Math.pow(2,-a)*8388608))>>>0,e,r)}}function e(n,t,e){var r=n(t,e),i=2*(r>>31)+1,a=r>>>23&255,o=8388607&r;return 255===a?o?NaN:i*(1/0):0===a?1.401298464324817e-45*i*o:i*Math.pow(2,a-150)*(o+8388608)}n.writeFloatLE=t.bind(null,writeUintLE),n.writeFloatBE=t.bind(null,writeUintBE),n.readFloatLE=e.bind(null,readUintLE),n.readFloatBE=e.bind(null,readUintBE)}(),"undefined"!=typeof Float64Array?function(){var t=new Float64Array([-0]),e=new Uint8Array(t.buffer),r=128===e[7];function i(n,r,i){t[0]=n,r[i]=e[0],r[i+1]=e[1],r[i+2]=e[2],r[i+3]=e[3],r[i+4]=e[4],r[i+5]=e[5],r[i+6]=e[6],r[i+7]=e[7]}function a(n,r,i){t[0]=n,r[i]=e[7],r[i+1]=e[6],r[i+2]=e[5],r[i+3]=e[4],r[i+4]=e[3],r[i+5]=e[2],r[i+6]=e[1],r[i+7]=e[0]}function o(n,r){return e[0]=n[r],e[1]=n[r+1],e[2]=n[r+2],e[3]=n[r+3],e[4]=n[r+4],e[5]=n[r+5],e[6]=n[r+6],e[7]=n[r+7],t[0]}function u(n,r){return e[7]=n[r],e[6]=n[r+1],e[5]=n[r+2],e[4]=n[r+3],e[3]=n[r+4],e[2]=n[r+5],e[1]=n[r+6],e[0]=n[r+7],t[0]}n.writeDoubleLE=r?i:a,n.writeDoubleBE=r?a:i,n.readDoubleLE=r?o:u,n.readDoubleBE=r?u:o}():function(){function t(n,t,e,r,i,a){var o=r<0?1:0;if(o&&(r=-r),0===r)n(0,i,a+t),n(1/r>0?0:2147483648,i,a+e);else if(isNaN(r))n(0,i,a+t),n(2146959360,i,a+e);else if(r>1.7976931348623157e308)n(0,i,a+t),n((o<<31|2146435072)>>>0,i,a+e);else{var u;if(r<2.2250738585072014e-308)n((u=r/5e-324)>>>0,i,a+t),n((o<<31|u/4294967296)>>>0,i,a+e);else{var l=Math.floor(Math.log(r)/Math.LN2);1024===l&&(l=1023),n(4503599627370496*(u=r*Math.pow(2,-l))>>>0,i,a+t),n((o<<31|l+1023<<20|1048576*u&1048575)>>>0,i,a+e)}}}function e(n,t,e,r,i){var a=n(r,i+t),o=n(r,i+e),u=2*(o>>31)+1,l=o>>>20&2047,f=4294967296*(1048575&o)+a;return 2047===l?f?NaN:u*(1/0):0===l?5e-324*u*f:u*Math.pow(2,l-1075)*(f+4503599627370496)}n.writeDoubleLE=t.bind(null,writeUintLE,0,4),n.writeDoubleBE=t.bind(null,writeUintBE,4,0),n.readDoubleLE=e.bind(null,readUintLE,0,4),n.readDoubleBE=e.bind(null,readUintBE,4,0)}(),n}function writeUintLE(n,t,e){t[e]=255&n,t[e+1]=n>>>8&255,t[e+2]=n>>>16&255,t[e+3]=n>>>24}function writeUintBE(n,t,e){t[e]=n>>>24,t[e+1]=n>>>16&255,t[e+2]=n>>>8&255,t[e+3]=255&n}function readUintLE(n,t){return(n[t]|n[t+1]<<8|n[t+2]<<16|n[t+3]<<24)>>>0}function readUintBE(n,t){return(n[t]<<24|n[t+1]<<16|n[t+2]<<8|n[t+3])>>>0}module.exports=factory(factory);

},{}],13:[function(require,module,exports){
"use strict";function inquire(moduleName){try{var mod=eval("quire".replace(/^/,"re"))(moduleName);if(mod&&(mod.length||Object.keys(mod).length))return mod}catch(e){}return null}module.exports=inquire;

},{}],14:[function(require,module,exports){
"use strict";function pool(r,n,o){var t=o||8192,u=t>>>1,l=null,e=t;return function(o){if(o<1||o>u)return r(o);e+o>t&&(l=r(t),e=0);var c=n.call(l,e,e+=o);return 7&e&&(e=1+(7|e)),c}}module.exports=pool;

},{}],15:[function(require,module,exports){
"use strict";var utf8=exports;utf8.length=function(r){for(var t=0,n=0,e=0;e<r.length;++e)(n=r.charCodeAt(e))<128?t+=1:n<2048?t+=2:55296==(64512&n)&&56320==(64512&r.charCodeAt(e+1))?(++e,t+=4):t+=3;return t},utf8.read=function(r,t,n){if(n-t<1)return"";for(var e,o=null,a=[],i=0;t<n;)(e=r[t++])<128?a[i++]=e:e>191&&e<224?a[i++]=(31&e)<<6|63&r[t++]:e>239&&e<365?(e=((7&e)<<18|(63&r[t++])<<12|(63&r[t++])<<6|63&r[t++])-65536,a[i++]=55296+(e>>10),a[i++]=56320+(1023&e)):a[i++]=(15&e)<<12|(63&r[t++])<<6|63&r[t++],i>8191&&((o||(o=[])).push(String.fromCharCode.apply(String,a)),i=0);return o?(i&&o.push(String.fromCharCode.apply(String,a.slice(0,i))),o.join("")):String.fromCharCode.apply(String,a.slice(0,i))},utf8.write=function(r,t,n){for(var e,o,a=n,i=0;i<r.length;++i)(e=r.charCodeAt(i))<128?t[n++]=e:e<2048?(t[n++]=e>>6|192,t[n++]=63&e|128):55296==(64512&e)&&56320==(64512&(o=r.charCodeAt(i+1)))?(e=65536+((1023&e)<<10)+(1023&o),++i,t[n++]=e>>18|240,t[n++]=e>>12&63|128,t[n++]=e>>6&63|128,t[n++]=63&e|128):(t[n++]=e>>12|224,t[n++]=e>>6&63|128,t[n++]=63&e|128);return n-a};

},{}],16:[function(require,module,exports){
const Buffer=require("safe-buffer").Buffer;module.exports=function(r){if(r.length>=255)throw new TypeError("Alphabet too long");const e=new Uint8Array(256);e.fill(255);for(let t=0;t<r.length;t++){const o=r.charAt(t),n=o.charCodeAt(0);if(255!==e[n])throw new TypeError(o+" is ambiguous");e[n]=t}const t=r.length,o=r.charAt(0),n=Math.log(t)/Math.log(256),f=Math.log(256)/Math.log(t);function l(r){if("string"!=typeof r)throw new TypeError("Expected String");if(0===r.length)return Buffer.alloc(0);let f=0;if(" "===r[f])return;let l=0,c=0;for(;r[f]===o;)l++,f++;const i=(r.length-f)*n+1>>>0,a=new Uint8Array(i);for(;r[f];){let o=e[r.charCodeAt(f)];if(255===o)return;let n=0;for(let r=i-1;(0!==o||n<c)&&-1!==r;r--,n++)o+=t*a[r]>>>0,a[r]=o%256>>>0,o=o/256>>>0;if(0!==o)throw new Error("Non-zero carry");c=n,f++}if(" "===r[f])return;let h=i-c;for(;h!==i&&0===a[h];)h++;const u=Buffer.allocUnsafe(l+(i-h));u.fill(0,0,l);let s=l;for(;h!==i;)u[s++]=a[h++];return u}return{encode:function(e){if(!Buffer.isBuffer(e))throw new TypeError("Expected Buffer");if(0===e.length)return"";let n=0,l=0,c=0;const i=e.length;for(;c!==i&&0===e[c];)c++,n++;const a=(i-c)*f+1>>>0,h=new Uint8Array(a);for(;c!==i;){let r=e[c],o=0;for(let e=a-1;(0!==r||o<l)&&-1!==e;e--,o++)r+=256*h[e]>>>0,h[e]=r%t>>>0,r=r/t>>>0;if(0!==r)throw new Error("Non-zero carry");l=o,c++}let u=a-l;for(;u!==a&&0===h[u];)u++;let s=o.repeat(n);for(;u<a;++u)s+=r.charAt(h[u]);return s},decodeUnsafe:l,decode:function(r){const e=l(r);if(e)return e;throw new Error("Non-base"+t+" character")}}};

},{"safe-buffer":57}],17:[function(require,module,exports){
"use strict";exports.byteLength=byteLength,exports.toByteArray=toByteArray,exports.fromByteArray=fromByteArray;for(var lookup=[],revLookup=[],Arr="undefined"!=typeof Uint8Array?Uint8Array:Array,code="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",i=0,len=code.length;i<len;++i)lookup[i]=code[i],revLookup[code.charCodeAt(i)]=i;function getLens(o){var r=o.length;if(r%4>0)throw new Error("Invalid string. Length must be a multiple of 4");var e=o.indexOf("=");return-1===e&&(e=r),[e,e===r?0:4-e%4]}function byteLength(o){var r=getLens(o),e=r[0],t=r[1];return 3*(e+t)/4-t}function _byteLength(o,r,e){return 3*(r+e)/4-e}function toByteArray(o){for(var r,e=getLens(o),t=e[0],n=e[1],u=new Arr(_byteLength(o,t,n)),p=0,a=n>0?t-4:t,h=0;h<a;h+=4)r=revLookup[o.charCodeAt(h)]<<18|revLookup[o.charCodeAt(h+1)]<<12|revLookup[o.charCodeAt(h+2)]<<6|revLookup[o.charCodeAt(h+3)],u[p++]=r>>16&255,u[p++]=r>>8&255,u[p++]=255&r;return 2===n&&(r=revLookup[o.charCodeAt(h)]<<2|revLookup[o.charCodeAt(h+1)]>>4,u[p++]=255&r),1===n&&(r=revLookup[o.charCodeAt(h)]<<10|revLookup[o.charCodeAt(h+1)]<<4|revLookup[o.charCodeAt(h+2)]>>2,u[p++]=r>>8&255,u[p++]=255&r),u}function tripletToBase64(o){return lookup[o>>18&63]+lookup[o>>12&63]+lookup[o>>6&63]+lookup[63&o]}function encodeChunk(o,r,e){for(var t,n=[],u=r;u<e;u+=3)t=(o[u]<<16&16711680)+(o[u+1]<<8&65280)+(255&o[u+2]),n.push(tripletToBase64(t));return n.join("")}function fromByteArray(o){for(var r,e=o.length,t=e%3,n=[],u=0,p=e-t;u<p;u+=16383)n.push(encodeChunk(o,u,u+16383>p?p:u+16383));return 1===t?(r=o[e-1],n.push(lookup[r>>2]+lookup[r<<4&63]+"==")):2===t&&(r=(o[e-2]<<8)+o[e-1],n.push(lookup[r>>10]+lookup[r>>4&63]+lookup[r<<2&63]+"=")),n.join("")}revLookup["-".charCodeAt(0)]=62,revLookup["_".charCodeAt(0)]=63;

},{}],18:[function(require,module,exports){

},{}],19:[function(require,module,exports){

},{}],20:[function(require,module,exports){
var basex=require("base-x"),ALPHABET="123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz";module.exports=basex(ALPHABET);

},{"base-x":16}],21:[function(require,module,exports){
"use strict";var base64=require("base64-js"),ieee754=require("ieee754");exports.Buffer=Buffer,exports.SlowBuffer=SlowBuffer,exports.INSPECT_MAX_BYTES=50;var K_MAX_LENGTH=2147483647;function typedArraySupport(){try{var e=new Uint8Array(1);return e.__proto__={__proto__:Uint8Array.prototype,foo:function(){return 42}},42===e.foo()}catch(e){return!1}}function createBuffer(e){if(e>K_MAX_LENGTH)throw new RangeError('The value "'+e+'" is invalid for option "size"');var t=new Uint8Array(e);return t.__proto__=Buffer.prototype,t}function Buffer(e,t,r){if("number"==typeof e){if("string"==typeof t)throw new TypeError('The "string" argument must be of type string. Received type number');return allocUnsafe(e)}return from(e,t,r)}function from(e,t,r){if("string"==typeof e)return fromString(e,t);if(ArrayBuffer.isView(e))return fromArrayLike(e);if(null==e)throw TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "+typeof e);if(isInstance(e,ArrayBuffer)||e&&isInstance(e.buffer,ArrayBuffer))return fromArrayBuffer(e,t,r);if("number"==typeof e)throw new TypeError('The "value" argument must not be of type number. Received type number');var n=e.valueOf&&e.valueOf();if(null!=n&&n!==e)return Buffer.from(n,t,r);var f=fromObject(e);if(f)return f;if("undefined"!=typeof Symbol&&null!=Symbol.toPrimitive&&"function"==typeof e[Symbol.toPrimitive])return Buffer.from(e[Symbol.toPrimitive]("string"),t,r);throw new TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "+typeof e)}function assertSize(e){if("number"!=typeof e)throw new TypeError('"size" argument must be of type number');if(e<0)throw new RangeError('The value "'+e+'" is invalid for option "size"')}function alloc(e,t,r){return assertSize(e),e<=0?createBuffer(e):void 0!==t?"string"==typeof r?createBuffer(e).fill(t,r):createBuffer(e).fill(t):createBuffer(e)}function allocUnsafe(e){return assertSize(e),createBuffer(e<0?0:0|checked(e))}function fromString(e,t){if("string"==typeof t&&""!==t||(t="utf8"),!Buffer.isEncoding(t))throw new TypeError("Unknown encoding: "+t);var r=0|byteLength(e,t),n=createBuffer(r),f=n.write(e,t);return f!==r&&(n=n.slice(0,f)),n}function fromArrayLike(e){for(var t=e.length<0?0:0|checked(e.length),r=createBuffer(t),n=0;n<t;n+=1)r[n]=255&e[n];return r}function fromArrayBuffer(e,t,r){if(t<0||e.byteLength<t)throw new RangeError('"offset" is outside of buffer bounds');if(e.byteLength<t+(r||0))throw new RangeError('"length" is outside of buffer bounds');var n;return(n=void 0===t&&void 0===r?new Uint8Array(e):void 0===r?new Uint8Array(e,t):new Uint8Array(e,t,r)).__proto__=Buffer.prototype,n}function fromObject(e){if(Buffer.isBuffer(e)){var t=0|checked(e.length),r=createBuffer(t);return 0===r.length?r:(e.copy(r,0,0,t),r)}return void 0!==e.length?"number"!=typeof e.length||numberIsNaN(e.length)?createBuffer(0):fromArrayLike(e):"Buffer"===e.type&&Array.isArray(e.data)?fromArrayLike(e.data):void 0}function checked(e){if(e>=K_MAX_LENGTH)throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x"+K_MAX_LENGTH.toString(16)+" bytes");return 0|e}function SlowBuffer(e){return+e!=e&&(e=0),Buffer.alloc(+e)}function byteLength(e,t){if(Buffer.isBuffer(e))return e.length;if(ArrayBuffer.isView(e)||isInstance(e,ArrayBuffer))return e.byteLength;if("string"!=typeof e)throw new TypeError('The "string" argument must be one of type string, Buffer, or ArrayBuffer. Received type '+typeof e);var r=e.length,n=arguments.length>2&&!0===arguments[2];if(!n&&0===r)return 0;for(var f=!1;;)switch(t){case"ascii":case"latin1":case"binary":return r;case"utf8":case"utf-8":return utf8ToBytes(e).length;case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return 2*r;case"hex":return r>>>1;case"base64":return base64ToBytes(e).length;default:if(f)return n?-1:utf8ToBytes(e).length;t=(""+t).toLowerCase(),f=!0}}function slowToString(e,t,r){var n=!1;if((void 0===t||t<0)&&(t=0),t>this.length)return"";if((void 0===r||r>this.length)&&(r=this.length),r<=0)return"";if((r>>>=0)<=(t>>>=0))return"";for(e||(e="utf8");;)switch(e){case"hex":return hexSlice(this,t,r);case"utf8":case"utf-8":return utf8Slice(this,t,r);case"ascii":return asciiSlice(this,t,r);case"latin1":case"binary":return latin1Slice(this,t,r);case"base64":return base64Slice(this,t,r);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return utf16leSlice(this,t,r);default:if(n)throw new TypeError("Unknown encoding: "+e);e=(e+"").toLowerCase(),n=!0}}function swap(e,t,r){var n=e[t];e[t]=e[r],e[r]=n}function bidirectionalIndexOf(e,t,r,n,f){if(0===e.length)return-1;if("string"==typeof r?(n=r,r=0):r>2147483647?r=2147483647:r<-2147483648&&(r=-2147483648),numberIsNaN(r=+r)&&(r=f?0:e.length-1),r<0&&(r=e.length+r),r>=e.length){if(f)return-1;r=e.length-1}else if(r<0){if(!f)return-1;r=0}if("string"==typeof t&&(t=Buffer.from(t,n)),Buffer.isBuffer(t))return 0===t.length?-1:arrayIndexOf(e,t,r,n,f);if("number"==typeof t)return t&=255,"function"==typeof Uint8Array.prototype.indexOf?f?Uint8Array.prototype.indexOf.call(e,t,r):Uint8Array.prototype.lastIndexOf.call(e,t,r):arrayIndexOf(e,[t],r,n,f);throw new TypeError("val must be string, number or Buffer")}function arrayIndexOf(e,t,r,n,f){var i,o=1,u=e.length,s=t.length;if(void 0!==n&&("ucs2"===(n=String(n).toLowerCase())||"ucs-2"===n||"utf16le"===n||"utf-16le"===n)){if(e.length<2||t.length<2)return-1;o=2,u/=2,s/=2,r/=2}function a(e,t){return 1===o?e[t]:e.readUInt16BE(t*o)}if(f){var h=-1;for(i=r;i<u;i++)if(a(e,i)===a(t,-1===h?0:i-h)){if(-1===h&&(h=i),i-h+1===s)return h*o}else-1!==h&&(i-=i-h),h=-1}else for(r+s>u&&(r=u-s),i=r;i>=0;i--){for(var c=!0,l=0;l<s;l++)if(a(e,i+l)!==a(t,l)){c=!1;break}if(c)return i}return-1}function hexWrite(e,t,r,n){r=Number(r)||0;var f=e.length-r;n?(n=Number(n))>f&&(n=f):n=f;var i=t.length;n>i/2&&(n=i/2);for(var o=0;o<n;++o){var u=parseInt(t.substr(2*o,2),16);if(numberIsNaN(u))return o;e[r+o]=u}return o}function utf8Write(e,t,r,n){return blitBuffer(utf8ToBytes(t,e.length-r),e,r,n)}function asciiWrite(e,t,r,n){return blitBuffer(asciiToBytes(t),e,r,n)}function latin1Write(e,t,r,n){return asciiWrite(e,t,r,n)}function base64Write(e,t,r,n){return blitBuffer(base64ToBytes(t),e,r,n)}function ucs2Write(e,t,r,n){return blitBuffer(utf16leToBytes(t,e.length-r),e,r,n)}function base64Slice(e,t,r){return 0===t&&r===e.length?base64.fromByteArray(e):base64.fromByteArray(e.slice(t,r))}function utf8Slice(e,t,r){r=Math.min(e.length,r);for(var n=[],f=t;f<r;){var i,o,u,s,a=e[f],h=null,c=a>239?4:a>223?3:a>191?2:1;if(f+c<=r)switch(c){case 1:a<128&&(h=a);break;case 2:128==(192&(i=e[f+1]))&&(s=(31&a)<<6|63&i)>127&&(h=s);break;case 3:i=e[f+1],o=e[f+2],128==(192&i)&&128==(192&o)&&(s=(15&a)<<12|(63&i)<<6|63&o)>2047&&(s<55296||s>57343)&&(h=s);break;case 4:i=e[f+1],o=e[f+2],u=e[f+3],128==(192&i)&&128==(192&o)&&128==(192&u)&&(s=(15&a)<<18|(63&i)<<12|(63&o)<<6|63&u)>65535&&s<1114112&&(h=s)}null===h?(h=65533,c=1):h>65535&&(h-=65536,n.push(h>>>10&1023|55296),h=56320|1023&h),n.push(h),f+=c}return decodeCodePointsArray(n)}exports.kMaxLength=K_MAX_LENGTH,Buffer.TYPED_ARRAY_SUPPORT=typedArraySupport(),Buffer.TYPED_ARRAY_SUPPORT||"undefined"==typeof console||"function"!=typeof console.error||console.error("This browser lacks typed array (Uint8Array) support which is required by `buffer` v5.x. Use `buffer` v4.x if you require old browser support."),Object.defineProperty(Buffer.prototype,"parent",{enumerable:!0,get:function(){if(Buffer.isBuffer(this))return this.buffer}}),Object.defineProperty(Buffer.prototype,"offset",{enumerable:!0,get:function(){if(Buffer.isBuffer(this))return this.byteOffset}}),"undefined"!=typeof Symbol&&null!=Symbol.species&&Buffer[Symbol.species]===Buffer&&Object.defineProperty(Buffer,Symbol.species,{value:null,configurable:!0,enumerable:!1,writable:!1}),Buffer.poolSize=8192,Buffer.from=function(e,t,r){return from(e,t,r)},Buffer.prototype.__proto__=Uint8Array.prototype,Buffer.__proto__=Uint8Array,Buffer.alloc=function(e,t,r){return alloc(e,t,r)},Buffer.allocUnsafe=function(e){return allocUnsafe(e)},Buffer.allocUnsafeSlow=function(e){return allocUnsafe(e)},Buffer.isBuffer=function(e){return null!=e&&!0===e._isBuffer&&e!==Buffer.prototype},Buffer.compare=function(e,t){if(isInstance(e,Uint8Array)&&(e=Buffer.from(e,e.offset,e.byteLength)),isInstance(t,Uint8Array)&&(t=Buffer.from(t,t.offset,t.byteLength)),!Buffer.isBuffer(e)||!Buffer.isBuffer(t))throw new TypeError('The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array');if(e===t)return 0;for(var r=e.length,n=t.length,f=0,i=Math.min(r,n);f<i;++f)if(e[f]!==t[f]){r=e[f],n=t[f];break}return r<n?-1:n<r?1:0},Buffer.isEncoding=function(e){switch(String(e).toLowerCase()){case"hex":case"utf8":case"utf-8":case"ascii":case"latin1":case"binary":case"base64":case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return!0;default:return!1}},Buffer.concat=function(e,t){if(!Array.isArray(e))throw new TypeError('"list" argument must be an Array of Buffers');if(0===e.length)return Buffer.alloc(0);var r;if(void 0===t)for(t=0,r=0;r<e.length;++r)t+=e[r].length;var n=Buffer.allocUnsafe(t),f=0;for(r=0;r<e.length;++r){var i=e[r];if(isInstance(i,Uint8Array)&&(i=Buffer.from(i)),!Buffer.isBuffer(i))throw new TypeError('"list" argument must be an Array of Buffers');i.copy(n,f),f+=i.length}return n},Buffer.byteLength=byteLength,Buffer.prototype._isBuffer=!0,Buffer.prototype.swap16=function(){var e=this.length;if(e%2!=0)throw new RangeError("Buffer size must be a multiple of 16-bits");for(var t=0;t<e;t+=2)swap(this,t,t+1);return this},Buffer.prototype.swap32=function(){var e=this.length;if(e%4!=0)throw new RangeError("Buffer size must be a multiple of 32-bits");for(var t=0;t<e;t+=4)swap(this,t,t+3),swap(this,t+1,t+2);return this},Buffer.prototype.swap64=function(){var e=this.length;if(e%8!=0)throw new RangeError("Buffer size must be a multiple of 64-bits");for(var t=0;t<e;t+=8)swap(this,t,t+7),swap(this,t+1,t+6),swap(this,t+2,t+5),swap(this,t+3,t+4);return this},Buffer.prototype.toString=function(){var e=this.length;return 0===e?"":0===arguments.length?utf8Slice(this,0,e):slowToString.apply(this,arguments)},Buffer.prototype.toLocaleString=Buffer.prototype.toString,Buffer.prototype.equals=function(e){if(!Buffer.isBuffer(e))throw new TypeError("Argument must be a Buffer");return this===e||0===Buffer.compare(this,e)},Buffer.prototype.inspect=function(){var e="",t=exports.INSPECT_MAX_BYTES;return e=this.toString("hex",0,t).replace(/(.{2})/g,"$1 ").trim(),this.length>t&&(e+=" ... "),"<Buffer "+e+">"},Buffer.prototype.compare=function(e,t,r,n,f){if(isInstance(e,Uint8Array)&&(e=Buffer.from(e,e.offset,e.byteLength)),!Buffer.isBuffer(e))throw new TypeError('The "target" argument must be one of type Buffer or Uint8Array. Received type '+typeof e);if(void 0===t&&(t=0),void 0===r&&(r=e?e.length:0),void 0===n&&(n=0),void 0===f&&(f=this.length),t<0||r>e.length||n<0||f>this.length)throw new RangeError("out of range index");if(n>=f&&t>=r)return 0;if(n>=f)return-1;if(t>=r)return 1;if(this===e)return 0;for(var i=(f>>>=0)-(n>>>=0),o=(r>>>=0)-(t>>>=0),u=Math.min(i,o),s=this.slice(n,f),a=e.slice(t,r),h=0;h<u;++h)if(s[h]!==a[h]){i=s[h],o=a[h];break}return i<o?-1:o<i?1:0},Buffer.prototype.includes=function(e,t,r){return-1!==this.indexOf(e,t,r)},Buffer.prototype.indexOf=function(e,t,r){return bidirectionalIndexOf(this,e,t,r,!0)},Buffer.prototype.lastIndexOf=function(e,t,r){return bidirectionalIndexOf(this,e,t,r,!1)},Buffer.prototype.write=function(e,t,r,n){if(void 0===t)n="utf8",r=this.length,t=0;else if(void 0===r&&"string"==typeof t)n=t,r=this.length,t=0;else{if(!isFinite(t))throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");t>>>=0,isFinite(r)?(r>>>=0,void 0===n&&(n="utf8")):(n=r,r=void 0)}var f=this.length-t;if((void 0===r||r>f)&&(r=f),e.length>0&&(r<0||t<0)||t>this.length)throw new RangeError("Attempt to write outside buffer bounds");n||(n="utf8");for(var i=!1;;)switch(n){case"hex":return hexWrite(this,e,t,r);case"utf8":case"utf-8":return utf8Write(this,e,t,r);case"ascii":return asciiWrite(this,e,t,r);case"latin1":case"binary":return latin1Write(this,e,t,r);case"base64":return base64Write(this,e,t,r);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return ucs2Write(this,e,t,r);default:if(i)throw new TypeError("Unknown encoding: "+n);n=(""+n).toLowerCase(),i=!0}},Buffer.prototype.toJSON=function(){return{type:"Buffer",data:Array.prototype.slice.call(this._arr||this,0)}};var MAX_ARGUMENTS_LENGTH=4096;function decodeCodePointsArray(e){var t=e.length;if(t<=MAX_ARGUMENTS_LENGTH)return String.fromCharCode.apply(String,e);for(var r="",n=0;n<t;)r+=String.fromCharCode.apply(String,e.slice(n,n+=MAX_ARGUMENTS_LENGTH));return r}function asciiSlice(e,t,r){var n="";r=Math.min(e.length,r);for(var f=t;f<r;++f)n+=String.fromCharCode(127&e[f]);return n}function latin1Slice(e,t,r){var n="";r=Math.min(e.length,r);for(var f=t;f<r;++f)n+=String.fromCharCode(e[f]);return n}function hexSlice(e,t,r){var n=e.length;(!t||t<0)&&(t=0),(!r||r<0||r>n)&&(r=n);for(var f="",i=t;i<r;++i)f+=toHex(e[i]);return f}function utf16leSlice(e,t,r){for(var n=e.slice(t,r),f="",i=0;i<n.length;i+=2)f+=String.fromCharCode(n[i]+256*n[i+1]);return f}function checkOffset(e,t,r){if(e%1!=0||e<0)throw new RangeError("offset is not uint");if(e+t>r)throw new RangeError("Trying to access beyond buffer length")}function checkInt(e,t,r,n,f,i){if(!Buffer.isBuffer(e))throw new TypeError('"buffer" argument must be a Buffer instance');if(t>f||t<i)throw new RangeError('"value" argument is out of bounds');if(r+n>e.length)throw new RangeError("Index out of range")}function checkIEEE754(e,t,r,n,f,i){if(r+n>e.length)throw new RangeError("Index out of range");if(r<0)throw new RangeError("Index out of range")}function writeFloat(e,t,r,n,f){return t=+t,r>>>=0,f||checkIEEE754(e,t,r,4,3.4028234663852886e38,-3.4028234663852886e38),ieee754.write(e,t,r,n,23,4),r+4}function writeDouble(e,t,r,n,f){return t=+t,r>>>=0,f||checkIEEE754(e,t,r,8,1.7976931348623157e308,-1.7976931348623157e308),ieee754.write(e,t,r,n,52,8),r+8}Buffer.prototype.slice=function(e,t){var r=this.length;(e=~~e)<0?(e+=r)<0&&(e=0):e>r&&(e=r),(t=void 0===t?r:~~t)<0?(t+=r)<0&&(t=0):t>r&&(t=r),t<e&&(t=e);var n=this.subarray(e,t);return n.__proto__=Buffer.prototype,n},Buffer.prototype.readUIntLE=function(e,t,r){e>>>=0,t>>>=0,r||checkOffset(e,t,this.length);for(var n=this[e],f=1,i=0;++i<t&&(f*=256);)n+=this[e+i]*f;return n},Buffer.prototype.readUIntBE=function(e,t,r){e>>>=0,t>>>=0,r||checkOffset(e,t,this.length);for(var n=this[e+--t],f=1;t>0&&(f*=256);)n+=this[e+--t]*f;return n},Buffer.prototype.readUInt8=function(e,t){return e>>>=0,t||checkOffset(e,1,this.length),this[e]},Buffer.prototype.readUInt16LE=function(e,t){return e>>>=0,t||checkOffset(e,2,this.length),this[e]|this[e+1]<<8},Buffer.prototype.readUInt16BE=function(e,t){return e>>>=0,t||checkOffset(e,2,this.length),this[e]<<8|this[e+1]},Buffer.prototype.readUInt32LE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),(this[e]|this[e+1]<<8|this[e+2]<<16)+16777216*this[e+3]},Buffer.prototype.readUInt32BE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),16777216*this[e]+(this[e+1]<<16|this[e+2]<<8|this[e+3])},Buffer.prototype.readIntLE=function(e,t,r){e>>>=0,t>>>=0,r||checkOffset(e,t,this.length);for(var n=this[e],f=1,i=0;++i<t&&(f*=256);)n+=this[e+i]*f;return n>=(f*=128)&&(n-=Math.pow(2,8*t)),n},Buffer.prototype.readIntBE=function(e,t,r){e>>>=0,t>>>=0,r||checkOffset(e,t,this.length);for(var n=t,f=1,i=this[e+--n];n>0&&(f*=256);)i+=this[e+--n]*f;return i>=(f*=128)&&(i-=Math.pow(2,8*t)),i},Buffer.prototype.readInt8=function(e,t){return e>>>=0,t||checkOffset(e,1,this.length),128&this[e]?-1*(255-this[e]+1):this[e]},Buffer.prototype.readInt16LE=function(e,t){e>>>=0,t||checkOffset(e,2,this.length);var r=this[e]|this[e+1]<<8;return 32768&r?4294901760|r:r},Buffer.prototype.readInt16BE=function(e,t){e>>>=0,t||checkOffset(e,2,this.length);var r=this[e+1]|this[e]<<8;return 32768&r?4294901760|r:r},Buffer.prototype.readInt32LE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),this[e]|this[e+1]<<8|this[e+2]<<16|this[e+3]<<24},Buffer.prototype.readInt32BE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),this[e]<<24|this[e+1]<<16|this[e+2]<<8|this[e+3]},Buffer.prototype.readFloatLE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),ieee754.read(this,e,!0,23,4)},Buffer.prototype.readFloatBE=function(e,t){return e>>>=0,t||checkOffset(e,4,this.length),ieee754.read(this,e,!1,23,4)},Buffer.prototype.readDoubleLE=function(e,t){return e>>>=0,t||checkOffset(e,8,this.length),ieee754.read(this,e,!0,52,8)},Buffer.prototype.readDoubleBE=function(e,t){return e>>>=0,t||checkOffset(e,8,this.length),ieee754.read(this,e,!1,52,8)},Buffer.prototype.writeUIntLE=function(e,t,r,n){(e=+e,t>>>=0,r>>>=0,n)||checkInt(this,e,t,r,Math.pow(2,8*r)-1,0);var f=1,i=0;for(this[t]=255&e;++i<r&&(f*=256);)this[t+i]=e/f&255;return t+r},Buffer.prototype.writeUIntBE=function(e,t,r,n){(e=+e,t>>>=0,r>>>=0,n)||checkInt(this,e,t,r,Math.pow(2,8*r)-1,0);var f=r-1,i=1;for(this[t+f]=255&e;--f>=0&&(i*=256);)this[t+f]=e/i&255;return t+r},Buffer.prototype.writeUInt8=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,1,255,0),this[t]=255&e,t+1},Buffer.prototype.writeUInt16LE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,2,65535,0),this[t]=255&e,this[t+1]=e>>>8,t+2},Buffer.prototype.writeUInt16BE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,2,65535,0),this[t]=e>>>8,this[t+1]=255&e,t+2},Buffer.prototype.writeUInt32LE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,4,4294967295,0),this[t+3]=e>>>24,this[t+2]=e>>>16,this[t+1]=e>>>8,this[t]=255&e,t+4},Buffer.prototype.writeUInt32BE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,4,4294967295,0),this[t]=e>>>24,this[t+1]=e>>>16,this[t+2]=e>>>8,this[t+3]=255&e,t+4},Buffer.prototype.writeIntLE=function(e,t,r,n){if(e=+e,t>>>=0,!n){var f=Math.pow(2,8*r-1);checkInt(this,e,t,r,f-1,-f)}var i=0,o=1,u=0;for(this[t]=255&e;++i<r&&(o*=256);)e<0&&0===u&&0!==this[t+i-1]&&(u=1),this[t+i]=(e/o>>0)-u&255;return t+r},Buffer.prototype.writeIntBE=function(e,t,r,n){if(e=+e,t>>>=0,!n){var f=Math.pow(2,8*r-1);checkInt(this,e,t,r,f-1,-f)}var i=r-1,o=1,u=0;for(this[t+i]=255&e;--i>=0&&(o*=256);)e<0&&0===u&&0!==this[t+i+1]&&(u=1),this[t+i]=(e/o>>0)-u&255;return t+r},Buffer.prototype.writeInt8=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,1,127,-128),e<0&&(e=255+e+1),this[t]=255&e,t+1},Buffer.prototype.writeInt16LE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,2,32767,-32768),this[t]=255&e,this[t+1]=e>>>8,t+2},Buffer.prototype.writeInt16BE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,2,32767,-32768),this[t]=e>>>8,this[t+1]=255&e,t+2},Buffer.prototype.writeInt32LE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,4,2147483647,-2147483648),this[t]=255&e,this[t+1]=e>>>8,this[t+2]=e>>>16,this[t+3]=e>>>24,t+4},Buffer.prototype.writeInt32BE=function(e,t,r){return e=+e,t>>>=0,r||checkInt(this,e,t,4,2147483647,-2147483648),e<0&&(e=4294967295+e+1),this[t]=e>>>24,this[t+1]=e>>>16,this[t+2]=e>>>8,this[t+3]=255&e,t+4},Buffer.prototype.writeFloatLE=function(e,t,r){return writeFloat(this,e,t,!0,r)},Buffer.prototype.writeFloatBE=function(e,t,r){return writeFloat(this,e,t,!1,r)},Buffer.prototype.writeDoubleLE=function(e,t,r){return writeDouble(this,e,t,!0,r)},Buffer.prototype.writeDoubleBE=function(e,t,r){return writeDouble(this,e,t,!1,r)},Buffer.prototype.copy=function(e,t,r,n){if(!Buffer.isBuffer(e))throw new TypeError("argument should be a Buffer");if(r||(r=0),n||0===n||(n=this.length),t>=e.length&&(t=e.length),t||(t=0),n>0&&n<r&&(n=r),n===r)return 0;if(0===e.length||0===this.length)return 0;if(t<0)throw new RangeError("targetStart out of bounds");if(r<0||r>=this.length)throw new RangeError("Index out of range");if(n<0)throw new RangeError("sourceEnd out of bounds");n>this.length&&(n=this.length),e.length-t<n-r&&(n=e.length-t+r);var f=n-r;if(this===e&&"function"==typeof Uint8Array.prototype.copyWithin)this.copyWithin(t,r,n);else if(this===e&&r<t&&t<n)for(var i=f-1;i>=0;--i)e[i+t]=this[i+r];else Uint8Array.prototype.set.call(e,this.subarray(r,n),t);return f},Buffer.prototype.fill=function(e,t,r,n){if("string"==typeof e){if("string"==typeof t?(n=t,t=0,r=this.length):"string"==typeof r&&(n=r,r=this.length),void 0!==n&&"string"!=typeof n)throw new TypeError("encoding must be a string");if("string"==typeof n&&!Buffer.isEncoding(n))throw new TypeError("Unknown encoding: "+n);if(1===e.length){var f=e.charCodeAt(0);("utf8"===n&&f<128||"latin1"===n)&&(e=f)}}else"number"==typeof e&&(e&=255);if(t<0||this.length<t||this.length<r)throw new RangeError("Out of range index");if(r<=t)return this;var i;if(t>>>=0,r=void 0===r?this.length:r>>>0,e||(e=0),"number"==typeof e)for(i=t;i<r;++i)this[i]=e;else{var o=Buffer.isBuffer(e)?e:Buffer.from(e,n),u=o.length;if(0===u)throw new TypeError('The value "'+e+'" is invalid for argument "value"');for(i=0;i<r-t;++i)this[i+t]=o[i%u]}return this};var INVALID_BASE64_RE=/[^+\/0-9A-Za-z-_]/g;function base64clean(e){if((e=(e=e.split("=")[0]).trim().replace(INVALID_BASE64_RE,"")).length<2)return"";for(;e.length%4!=0;)e+="=";return e}function toHex(e){return e<16?"0"+e.toString(16):e.toString(16)}function utf8ToBytes(e,t){var r;t=t||1/0;for(var n=e.length,f=null,i=[],o=0;o<n;++o){if((r=e.charCodeAt(o))>55295&&r<57344){if(!f){if(r>56319){(t-=3)>-1&&i.push(239,191,189);continue}if(o+1===n){(t-=3)>-1&&i.push(239,191,189);continue}f=r;continue}if(r<56320){(t-=3)>-1&&i.push(239,191,189),f=r;continue}r=65536+(f-55296<<10|r-56320)}else f&&(t-=3)>-1&&i.push(239,191,189);if(f=null,r<128){if((t-=1)<0)break;i.push(r)}else if(r<2048){if((t-=2)<0)break;i.push(r>>6|192,63&r|128)}else if(r<65536){if((t-=3)<0)break;i.push(r>>12|224,r>>6&63|128,63&r|128)}else{if(!(r<1114112))throw new Error("Invalid code point");if((t-=4)<0)break;i.push(r>>18|240,r>>12&63|128,r>>6&63|128,63&r|128)}}return i}function asciiToBytes(e){for(var t=[],r=0;r<e.length;++r)t.push(255&e.charCodeAt(r));return t}function utf16leToBytes(e,t){for(var r,n,f,i=[],o=0;o<e.length&&!((t-=2)<0);++o)n=(r=e.charCodeAt(o))>>8,f=r%256,i.push(f),i.push(n);return i}function base64ToBytes(e){return base64.toByteArray(base64clean(e))}function blitBuffer(e,t,r,n){for(var f=0;f<n&&!(f+r>=t.length||f>=e.length);++f)t[f+r]=e[f];return f}function isInstance(e,t){return e instanceof t||null!=e&&null!=e.constructor&&null!=e.constructor.name&&e.constructor.name===t.name}function numberIsNaN(e){return e!=e}

},{"base64-js":17,"ieee754":38}],22:[function(require,module,exports){
require(".").check("es5");

},{".":23}],23:[function(require,module,exports){
require("./lib/definitions"),module.exports=require("./lib");

},{"./lib":26,"./lib/definitions":25}],24:[function(require,module,exports){
var CapabilityDetector=function(){this.tests={},this.cache={}};CapabilityDetector.prototype={constructor:CapabilityDetector,define:function(t,i){if("string"!=typeof t||!(i instanceof Function))throw new Error("Invalid capability definition.");if(this.tests[t])throw new Error('Duplicated capability definition by "'+t+'".');this.tests[t]=i},check:function(t){if(!this.test(t))throw new Error('The current environment does not support "'+t+'", therefore we cannot continue.')},test:function(t){if(void 0!==this.cache[t])return this.cache[t];if(!this.tests[t])throw new Error('Unknown capability with name "'+t+'".');var i=this.tests[t];return this.cache[t]=!!i(),this.cache[t]}},module.exports=CapabilityDetector;

},{}],25:[function(require,module,exports){
var capability=require("."),define=capability.define,test=capability.test;define("strict mode",function(){return void 0===this}),define("arguments.callee.caller",function(){try{return function(){return arguments.callee.caller}()===arguments.callee}catch(e){return!1}}),define("es5",function(){return test("Array.prototype.forEach")&&test("Array.prototype.map")&&test("Function.prototype.bind")&&test("Object.create")&&test("Object.defineProperties")&&test("Object.defineProperty")&&test("Object.prototype.hasOwnProperty")}),define("Array.prototype.forEach",function(){return Array.prototype.forEach}),define("Array.prototype.map",function(){return Array.prototype.map}),define("Function.prototype.bind",function(){return Function.prototype.bind}),define("Object.create",function(){return Object.create}),define("Object.defineProperties",function(){return Object.defineProperties}),define("Object.defineProperty",function(){return Object.defineProperty}),define("Object.prototype.hasOwnProperty",function(){return Object.prototype.hasOwnProperty}),define("Error.captureStackTrace",function(){return Error.captureStackTrace}),define("Error.prototype.stack",function(){try{throw new Error}catch(e){return e.stack||e.stacktrace}});

},{".":26}],26:[function(require,module,exports){
var CapabilityDetector=require("./CapabilityDetector"),detector=new CapabilityDetector,capability=function(t){return detector.test(t)};capability.define=function(t,e){detector.define(t,e)},capability.check=function(t){detector.check(t)},capability.test=capability,module.exports=capability;

},{"./CapabilityDetector":24}],27:[function(require,module,exports){
"use strict";function depd(r){if(!r)throw new TypeError("argument namespace is required");function e(r){}return e._file=void 0,e._ignored=!0,e._namespace=r,e._traced=!1,e._warned=Object.create(null),e.function=wrapfunction,e.property=wrapproperty,e}function wrapfunction(r,e){if("function"!=typeof r)throw new TypeError("argument fn must be a function");return r}function wrapproperty(r,e,t){if(!r||"object"!=typeof r&&"function"!=typeof r)throw new TypeError("argument obj must be object");var o=Object.getOwnPropertyDescriptor(r,e);if(!o)throw new TypeError("must call property on owner object");if(!o.configurable)throw new TypeError("property must be configurable")}module.exports=depd;

},{}],28:[function(require,module,exports){
module.exports=require("./lib");

},{"./lib":29}],29:[function(require,module,exports){
require("capability/es5");var polyfill,capability=require("capability");polyfill=capability("Error.captureStackTrace")?require("./v8"):capability("Error.prototype.stack")?require("./non-v8/index"):require("./unsupported"),module.exports=polyfill();

},{"./non-v8/index":33,"./unsupported":35,"./v8":36,"capability":23,"capability/es5":22}],30:[function(require,module,exports){
var Class=require("o3").Class,abstractMethod=require("o3").abstractMethod,Frame=Class(Object,{prototype:{init:Class.prototype.merge,frameString:void 0,toString:function(){return this.frameString},functionValue:void 0,getThis:abstractMethod,getTypeName:abstractMethod,getFunction:function(){return this.functionValue},getFunctionName:abstractMethod,getMethodName:abstractMethod,getFileName:abstractMethod,getLineNumber:abstractMethod,getColumnNumber:abstractMethod,getEvalOrigin:abstractMethod,isTopLevel:abstractMethod,isEval:abstractMethod,isNative:abstractMethod,isConstructor:abstractMethod}});module.exports=Frame;

},{"o3":41}],31:[function(require,module,exports){
var Class=require("o3").Class,Frame=require("./Frame"),cache=require("u3").cache,FrameStringParser=Class(Object,{prototype:{stackParser:null,frameParser:null,locationParsers:null,constructor:function(e){Class.prototype.merge.call(this,e)},getFrames:function(e,r){for(var t=[],a=0,n=e.length;a<n;++a)t[a]=this.getFrame(e[a],r[a]);return t},getFrame:function(e,r){return new Frame({frameString:e,functionValue:r})}}});module.exports={getClass:cache(function(){return FrameStringParser}),getInstance:cache(function(){return new(this.getClass())})};

},{"./Frame":30,"o3":41,"u3":63}],32:[function(require,module,exports){
var Class=require("o3").Class,abstractMethod=require("o3").abstractMethod,eachCombination=require("u3").eachCombination,cache=require("u3").cache,capability=require("capability"),AbstractFrameStringSource=Class(Object,{prototype:{captureFrameStrings:function(r){var t=this.createError();r.unshift(this.captureFrameStrings),r.unshift(this.createError);var e=this.getFrameStrings(t).slice(r.length),a=[];if(capability("arguments.callee.caller")){var n=[this.createError,this.captureFrameStrings];try{for(var i=arguments.callee;i=i.caller;)n.push(i)}catch(r){}a=n.slice(r.length)}return{frameStrings:e,functionValues:a}},getFrameStrings:function(r){var t=r.message||"",e=r.name||"",a=this.getStackString(r);if(void 0!==a){var n=a.split("\n"),i=0,c=n.length;return this.hasHeader&&(i+=e.split("\n").length+t.split("\n").length-1),this.hasFooter&&(c-=1),n.slice(i,c)}},createError:abstractMethod,getStackString:abstractMethod,hasHeader:void 0,hasFooter:void 0}}),FrameStringSourceCalibrator=Class(Object,{prototype:{calibrateClass:function(r){return this.calibrateMethods(r)&&this.calibrateEnvelope(r)},calibrateMethods:function(r){try{eachCombination([[function(r){return new Error(r)},function(r){try{throw new Error(r)}catch(r){return r}}],[function(r){return r.stack},function(r){return r.stacktrace}]],function(r,t){if(t(r()))throw{getStackString:t,createError:r}})}catch(t){return Class.merge.call(r,{prototype:t}),!0}return!1},calibrateEnvelope:function(r){var t=(0,r.prototype.getStackString)((0,r.prototype.createError)("marker")).split("\n");return Class.merge.call(r,{prototype:{hasHeader:/marker/.test(t[0]),hasFooter:""===t[t.length-1]}}),!0}}});module.exports={getClass:cache(function(){var r;if(r)return r;if(r=Class(AbstractFrameStringSource,{}),!(new FrameStringSourceCalibrator).calibrateClass(r))throw new Error("Cannot read Error.prototype.stack in this environment.");return r}),getInstance:cache(function(){return new(this.getClass())})};

},{"capability":23,"o3":41,"u3":63}],33:[function(require,module,exports){
var FrameStringSource=require("./FrameStringSource"),FrameStringParser=require("./FrameStringParser"),cache=require("u3").cache,prepareStackTrace=require("../prepareStackTrace");module.exports=function(){return Error.captureStackTrace=function r(e,a){var t=[r];a&&t.push(a);var c=FrameStringSource.getInstance().captureFrameStrings(t);Object.defineProperties(e,{stack:{configurable:!0,get:cache(function(){var r=FrameStringParser.getInstance().getFrames(c.frameStrings,c.functionValues);return(Error.prepareStackTrace||prepareStackTrace)(e,r,void 0)})},cachedStack:{configurable:!0,writable:!0,enumerable:!1,value:!0}})},Error.getStackTrace=function(r){if(r.cachedStack)return r.stack;var e,a=FrameStringSource.getInstance().getFrameStrings(r),t=[];a?t=FrameStringParser.getInstance().getFrames(a,[]):e=["The stack is not readable by unthrown errors in this environment."];var c=(Error.prepareStackTrace||prepareStackTrace)(r,t,e);if(a)try{Object.defineProperties(r,{stack:{configurable:!0,writable:!0,enumerable:!1,value:c},cachedStack:{configurable:!0,writable:!0,enumerable:!1,value:!0}})}catch(r){}return c},{prepareStackTrace:prepareStackTrace}};

},{"../prepareStackTrace":34,"./FrameStringParser":31,"./FrameStringSource":32,"u3":63}],34:[function(require,module,exports){
var prepareStackTrace=function(r,a,e){var n="";if(n+=r.name||"Error",n+=": "+(r.message||""),e instanceof Array)for(var t in e){n+="\n   # "+e[t]}for(var o in a){n+="\n   at "+a[o].toString()}return n};module.exports=prepareStackTrace;

},{}],35:[function(require,module,exports){
var cache=require("u3").cache,prepareStackTrace=require("./prepareStackTrace");module.exports=function(){return Error.captureStackTrace=function(e,r){Object.defineProperties(e,{stack:{configurable:!0,get:cache(function(){return(Error.prepareStackTrace||prepareStackTrace)(e,[])})},cachedStack:{configurable:!0,writable:!0,enumerable:!1,value:!0}})},Error.getStackTrace=function(e){if(e.cachedStack)return e.stack;var r=(Error.prepareStackTrace||prepareStackTrace)(e,[]);try{Object.defineProperties(e,{stack:{configurable:!0,writable:!0,enumerable:!1,value:r},cachedStack:{configurable:!0,writable:!0,enumerable:!1,value:!0}})}catch(e){}return r},{prepareStackTrace:prepareStackTrace}};

},{"./prepareStackTrace":34,"u3":63}],36:[function(require,module,exports){
var prepareStackTrace=require("./prepareStackTrace");module.exports=function(){return Error.getStackTrace=function(r){return r.stack},{prepareStackTrace:prepareStackTrace}};

},{"./prepareStackTrace":34}],37:[function(require,module,exports){
"use strict";var deprecate=require("depd")("http-errors"),setPrototypeOf=require("setprototypeof"),statuses=require("statuses"),inherits=require("inherits"),toIdentifier=require("toidentifier");function codeClass(r){return Number(String(r).charAt(0)+"00")}function createError(){for(var r,e,t=500,o={},a=0;a<arguments.length;a++){var s=arguments[a];if(s instanceof Error)t=(r=s).status||r.statusCode||t;else switch(typeof s){case"string":e=s;break;case"number":t=s,0!==a&&deprecate("non-first-argument status code; replace with createError("+s+", ...)");break;case"object":o=s}}"number"==typeof t&&(t<400||t>=600)&&deprecate("non-error status code; use only 4xx or 5xx status codes"),("number"!=typeof t||!statuses[t]&&(t<400||t>=600))&&(t=500);var n=createError[t]||createError[codeClass(t)];for(var u in r||(r=n?new n(e):new Error(e||statuses[t]),Error.captureStackTrace(r,createError)),n&&r instanceof n&&r.status===t||(r.expose=t<500,r.status=r.statusCode=t),o)"status"!==u&&"statusCode"!==u&&(r[u]=o[u]);return r}function createHttpErrorConstructor(){function r(){throw new TypeError("cannot construct abstract class")}return inherits(r,Error),r}function createClientErrorConstructor(r,e,t){var o=e.match(/Error$/)?e:e+"Error";function a(r){var e=null!=r?r:statuses[t],s=new Error(e);return Error.captureStackTrace(s,a),setPrototypeOf(s,a.prototype),Object.defineProperty(s,"message",{enumerable:!0,configurable:!0,value:e,writable:!0}),Object.defineProperty(s,"name",{enumerable:!1,configurable:!0,value:o,writable:!0}),s}return inherits(a,r),nameFunc(a,o),a.prototype.status=t,a.prototype.statusCode=t,a.prototype.expose=!0,a}function createServerErrorConstructor(r,e,t){var o=e.match(/Error$/)?e:e+"Error";function a(r){var e=null!=r?r:statuses[t],s=new Error(e);return Error.captureStackTrace(s,a),setPrototypeOf(s,a.prototype),Object.defineProperty(s,"message",{enumerable:!0,configurable:!0,value:e,writable:!0}),Object.defineProperty(s,"name",{enumerable:!1,configurable:!0,value:o,writable:!0}),s}return inherits(a,r),nameFunc(a,o),a.prototype.status=t,a.prototype.statusCode=t,a.prototype.expose=!1,a}function nameFunc(r,e){var t=Object.getOwnPropertyDescriptor(r,"name");t&&t.configurable&&(t.value=e,Object.defineProperty(r,"name",t))}function populateConstructorExports(r,e,t){e.forEach(function(e){var o,a=toIdentifier(statuses[e]);switch(codeClass(e)){case 400:o=createClientErrorConstructor(t,a,e);break;case 500:o=createServerErrorConstructor(t,a,e)}o&&(r[e]=o,r[a]=o)}),r["I'mateapot"]=deprecate.function(r.ImATeapot,'"I\'mateapot"; use "ImATeapot" instead')}module.exports=createError,module.exports.HttpError=createHttpErrorConstructor(),populateConstructorExports(module.exports,statuses.codes,module.exports.HttpError);

},{"depd":27,"inherits":39,"setprototypeof":58,"statuses":60,"toidentifier":61}],38:[function(require,module,exports){
exports.read=function(a,o,t,r,h){var M,p,w=8*h-r-1,f=(1<<w)-1,e=f>>1,i=-7,N=t?h-1:0,n=t?-1:1,s=a[o+N];for(N+=n,M=s&(1<<-i)-1,s>>=-i,i+=w;i>0;M=256*M+a[o+N],N+=n,i-=8);for(p=M&(1<<-i)-1,M>>=-i,i+=r;i>0;p=256*p+a[o+N],N+=n,i-=8);if(0===M)M=1-e;else{if(M===f)return p?NaN:1/0*(s?-1:1);p+=Math.pow(2,r),M-=e}return(s?-1:1)*p*Math.pow(2,M-r)},exports.write=function(a,o,t,r,h,M){var p,w,f,e=8*M-h-1,i=(1<<e)-1,N=i>>1,n=23===h?Math.pow(2,-24)-Math.pow(2,-77):0,s=r?0:M-1,u=r?1:-1,l=o<0||0===o&&1/o<0?1:0;for(o=Math.abs(o),isNaN(o)||o===1/0?(w=isNaN(o)?1:0,p=i):(p=Math.floor(Math.log(o)/Math.LN2),o*(f=Math.pow(2,-p))<1&&(p--,f*=2),(o+=p+N>=1?n/f:n*Math.pow(2,1-N))*f>=2&&(p++,f/=2),p+N>=i?(w=0,p=i):p+N>=1?(w=(o*f-1)*Math.pow(2,h),p+=N):(w=o*Math.pow(2,N-1)*Math.pow(2,h),p=0));h>=8;a[t+s]=255&w,s+=u,w/=256,h-=8);for(p=p<<h|w,e+=h;e>0;a[t+s]=255&p,s+=u,p/=256,e-=8);a[t+s-u]|=128*l};

},{}],39:[function(require,module,exports){
"function"==typeof Object.create?module.exports=function(t,e){t.super_=e,t.prototype=Object.create(e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}})}:module.exports=function(t,e){t.super_=e;var o=function(){};o.prototype=e.prototype,t.prototype=new o,t.prototype.constructor=t};

},{}],40:[function(require,module,exports){
(function (process,global){
!function(){"use strict";var ERROR="input is invalid type",WINDOW="object"==typeof window,root=WINDOW?window:{};root.JS_SHA256_NO_WINDOW&&(WINDOW=!1);var WEB_WORKER=!WINDOW&&"object"==typeof self,NODE_JS=!root.JS_SHA256_NO_NODE_JS&&"object"==typeof process&&process.versions&&process.versions.node;NODE_JS?root=global:WEB_WORKER&&(root=self);var COMMON_JS=!root.JS_SHA256_NO_COMMON_JS&&"object"==typeof module&&module.exports,AMD="function"==typeof define&&define.amd,ARRAY_BUFFER=!root.JS_SHA256_NO_ARRAY_BUFFER&&"undefined"!=typeof ArrayBuffer,HEX_CHARS="0123456789abcdef".split(""),EXTRA=[-2147483648,8388608,32768,128],SHIFT=[24,16,8,0],K=[1116352408,1899447441,3049323471,3921009573,961987163,1508970993,2453635748,2870763221,3624381080,310598401,607225278,1426881987,1925078388,2162078206,2614888103,3248222580,3835390401,4022224774,264347078,604807628,770255983,1249150122,1555081692,1996064986,2554220882,2821834349,2952996808,3210313671,3336571891,3584528711,113926993,338241895,666307205,773529912,1294757372,1396182291,1695183700,1986661051,2177026350,2456956037,2730485921,2820302411,3259730800,3345764771,3516065817,3600352804,4094571909,275423344,430227734,506948616,659060556,883997877,958139571,1322822218,1537002063,1747873779,1955562222,2024104815,2227730452,2361852424,2428436474,2756734187,3204031479,3329325298],OUTPUT_TYPES=["hex","array","digest","arrayBuffer"],blocks=[];!root.JS_SHA256_NO_NODE_JS&&Array.isArray||(Array.isArray=function(t){return"[object Array]"===Object.prototype.toString.call(t)}),!ARRAY_BUFFER||!root.JS_SHA256_NO_ARRAY_BUFFER_IS_VIEW&&ArrayBuffer.isView||(ArrayBuffer.isView=function(t){return"object"==typeof t&&t.buffer&&t.buffer.constructor===ArrayBuffer});var createOutputMethod=function(t,h){return function(r){return new Sha256(h,!0).update(r)[t]()}},createMethod=function(t){var h=createOutputMethod("hex",t);NODE_JS&&(h=nodeWrap(h,t)),h.create=function(){return new Sha256(t)},h.update=function(t){return h.create().update(t)};for(var r=0;r<OUTPUT_TYPES.length;++r){var e=OUTPUT_TYPES[r];h[e]=createOutputMethod(e,t)}return h},nodeWrap=function(method,is224){var crypto=eval("require('crypto')"),Buffer=eval("require('buffer').Buffer"),algorithm=is224?"sha224":"sha256",nodeMethod=function(t){if("string"==typeof t)return crypto.createHash(algorithm).update(t,"utf8").digest("hex");if(null==t)throw new Error(ERROR);return t.constructor===ArrayBuffer&&(t=new Uint8Array(t)),Array.isArray(t)||ArrayBuffer.isView(t)||t.constructor===Buffer?crypto.createHash(algorithm).update(new Buffer(t)).digest("hex"):method(t)};return nodeMethod},createHmacOutputMethod=function(t,h){return function(r,e){return new HmacSha256(r,h,!0).update(e)[t]()}},createHmacMethod=function(t){var h=createHmacOutputMethod("hex",t);h.create=function(h){return new HmacSha256(h,t)},h.update=function(t,r){return h.create(t).update(r)};for(var r=0;r<OUTPUT_TYPES.length;++r){var e=OUTPUT_TYPES[r];h[e]=createHmacOutputMethod(e,t)}return h};function Sha256(t,h){h?(blocks[0]=blocks[16]=blocks[1]=blocks[2]=blocks[3]=blocks[4]=blocks[5]=blocks[6]=blocks[7]=blocks[8]=blocks[9]=blocks[10]=blocks[11]=blocks[12]=blocks[13]=blocks[14]=blocks[15]=0,this.blocks=blocks):this.blocks=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],t?(this.h0=3238371032,this.h1=914150663,this.h2=812702999,this.h3=4144912697,this.h4=4290775857,this.h5=1750603025,this.h6=1694076839,this.h7=3204075428):(this.h0=1779033703,this.h1=3144134277,this.h2=1013904242,this.h3=2773480762,this.h4=1359893119,this.h5=2600822924,this.h6=528734635,this.h7=1541459225),this.block=this.start=this.bytes=this.hBytes=0,this.finalized=this.hashed=!1,this.first=!0,this.is224=t}function HmacSha256(t,h,r){var e,s=typeof t;if("string"===s){var i,o=[],a=t.length,H=0;for(e=0;e<a;++e)(i=t.charCodeAt(e))<128?o[H++]=i:i<2048?(o[H++]=192|i>>6,o[H++]=128|63&i):i<55296||i>=57344?(o[H++]=224|i>>12,o[H++]=128|i>>6&63,o[H++]=128|63&i):(i=65536+((1023&i)<<10|1023&t.charCodeAt(++e)),o[H++]=240|i>>18,o[H++]=128|i>>12&63,o[H++]=128|i>>6&63,o[H++]=128|63&i);t=o}else{if("object"!==s)throw new Error(ERROR);if(null===t)throw new Error(ERROR);if(ARRAY_BUFFER&&t.constructor===ArrayBuffer)t=new Uint8Array(t);else if(!(Array.isArray(t)||ARRAY_BUFFER&&ArrayBuffer.isView(t)))throw new Error(ERROR)}t.length>64&&(t=new Sha256(h,!0).update(t).array());var n=[],S=[];for(e=0;e<64;++e){var c=t[e]||0;n[e]=92^c,S[e]=54^c}Sha256.call(this,h,r),this.update(S),this.oKeyPad=n,this.inner=!0,this.sharedMemory=r}Sha256.prototype.update=function(t){if(!this.finalized){var h,r=typeof t;if("string"!==r){if("object"!==r)throw new Error(ERROR);if(null===t)throw new Error(ERROR);if(ARRAY_BUFFER&&t.constructor===ArrayBuffer)t=new Uint8Array(t);else if(!(Array.isArray(t)||ARRAY_BUFFER&&ArrayBuffer.isView(t)))throw new Error(ERROR);h=!0}for(var e,s,i=0,o=t.length,a=this.blocks;i<o;){if(this.hashed&&(this.hashed=!1,a[0]=this.block,a[16]=a[1]=a[2]=a[3]=a[4]=a[5]=a[6]=a[7]=a[8]=a[9]=a[10]=a[11]=a[12]=a[13]=a[14]=a[15]=0),h)for(s=this.start;i<o&&s<64;++i)a[s>>2]|=t[i]<<SHIFT[3&s++];else for(s=this.start;i<o&&s<64;++i)(e=t.charCodeAt(i))<128?a[s>>2]|=e<<SHIFT[3&s++]:e<2048?(a[s>>2]|=(192|e>>6)<<SHIFT[3&s++],a[s>>2]|=(128|63&e)<<SHIFT[3&s++]):e<55296||e>=57344?(a[s>>2]|=(224|e>>12)<<SHIFT[3&s++],a[s>>2]|=(128|e>>6&63)<<SHIFT[3&s++],a[s>>2]|=(128|63&e)<<SHIFT[3&s++]):(e=65536+((1023&e)<<10|1023&t.charCodeAt(++i)),a[s>>2]|=(240|e>>18)<<SHIFT[3&s++],a[s>>2]|=(128|e>>12&63)<<SHIFT[3&s++],a[s>>2]|=(128|e>>6&63)<<SHIFT[3&s++],a[s>>2]|=(128|63&e)<<SHIFT[3&s++]);this.lastByteIndex=s,this.bytes+=s-this.start,s>=64?(this.block=a[16],this.start=s-64,this.hash(),this.hashed=!0):this.start=s}return this.bytes>4294967295&&(this.hBytes+=this.bytes/4294967296<<0,this.bytes=this.bytes%4294967296),this}},Sha256.prototype.finalize=function(){if(!this.finalized){this.finalized=!0;var t=this.blocks,h=this.lastByteIndex;t[16]=this.block,t[h>>2]|=EXTRA[3&h],this.block=t[16],h>=56&&(this.hashed||this.hash(),t[0]=this.block,t[16]=t[1]=t[2]=t[3]=t[4]=t[5]=t[6]=t[7]=t[8]=t[9]=t[10]=t[11]=t[12]=t[13]=t[14]=t[15]=0),t[14]=this.hBytes<<3|this.bytes>>>29,t[15]=this.bytes<<3,this.hash()}},Sha256.prototype.hash=function(){var t,h,r,e,s,i,o,a,H,n=this.h0,S=this.h1,c=this.h2,f=this.h3,A=this.h4,R=this.h5,u=this.h6,_=this.h7,E=this.blocks;for(t=16;t<64;++t)h=((s=E[t-15])>>>7|s<<25)^(s>>>18|s<<14)^s>>>3,r=((s=E[t-2])>>>17|s<<15)^(s>>>19|s<<13)^s>>>10,E[t]=E[t-16]+h+E[t-7]+r<<0;for(H=S&c,t=0;t<64;t+=4)this.first?(this.is224?(i=300032,_=(s=E[0]-1413257819)-150054599<<0,f=s+24177077<<0):(i=704751109,_=(s=E[0]-210244248)-1521486534<<0,f=s+143694565<<0),this.first=!1):(h=(n>>>2|n<<30)^(n>>>13|n<<19)^(n>>>22|n<<10),e=(i=n&S)^n&c^H,_=f+(s=_+(r=(A>>>6|A<<26)^(A>>>11|A<<21)^(A>>>25|A<<7))+(A&R^~A&u)+K[t]+E[t])<<0,f=s+(h+e)<<0),h=(f>>>2|f<<30)^(f>>>13|f<<19)^(f>>>22|f<<10),e=(o=f&n)^f&S^i,u=c+(s=u+(r=(_>>>6|_<<26)^(_>>>11|_<<21)^(_>>>25|_<<7))+(_&A^~_&R)+K[t+1]+E[t+1])<<0,h=((c=s+(h+e)<<0)>>>2|c<<30)^(c>>>13|c<<19)^(c>>>22|c<<10),e=(a=c&f)^c&n^o,R=S+(s=R+(r=(u>>>6|u<<26)^(u>>>11|u<<21)^(u>>>25|u<<7))+(u&_^~u&A)+K[t+2]+E[t+2])<<0,h=((S=s+(h+e)<<0)>>>2|S<<30)^(S>>>13|S<<19)^(S>>>22|S<<10),e=(H=S&c)^S&f^a,A=n+(s=A+(r=(R>>>6|R<<26)^(R>>>11|R<<21)^(R>>>25|R<<7))+(R&u^~R&_)+K[t+3]+E[t+3])<<0,n=s+(h+e)<<0;this.h0=this.h0+n<<0,this.h1=this.h1+S<<0,this.h2=this.h2+c<<0,this.h3=this.h3+f<<0,this.h4=this.h4+A<<0,this.h5=this.h5+R<<0,this.h6=this.h6+u<<0,this.h7=this.h7+_<<0},Sha256.prototype.hex=function(){this.finalize();var t=this.h0,h=this.h1,r=this.h2,e=this.h3,s=this.h4,i=this.h5,o=this.h6,a=this.h7,H=HEX_CHARS[t>>28&15]+HEX_CHARS[t>>24&15]+HEX_CHARS[t>>20&15]+HEX_CHARS[t>>16&15]+HEX_CHARS[t>>12&15]+HEX_CHARS[t>>8&15]+HEX_CHARS[t>>4&15]+HEX_CHARS[15&t]+HEX_CHARS[h>>28&15]+HEX_CHARS[h>>24&15]+HEX_CHARS[h>>20&15]+HEX_CHARS[h>>16&15]+HEX_CHARS[h>>12&15]+HEX_CHARS[h>>8&15]+HEX_CHARS[h>>4&15]+HEX_CHARS[15&h]+HEX_CHARS[r>>28&15]+HEX_CHARS[r>>24&15]+HEX_CHARS[r>>20&15]+HEX_CHARS[r>>16&15]+HEX_CHARS[r>>12&15]+HEX_CHARS[r>>8&15]+HEX_CHARS[r>>4&15]+HEX_CHARS[15&r]+HEX_CHARS[e>>28&15]+HEX_CHARS[e>>24&15]+HEX_CHARS[e>>20&15]+HEX_CHARS[e>>16&15]+HEX_CHARS[e>>12&15]+HEX_CHARS[e>>8&15]+HEX_CHARS[e>>4&15]+HEX_CHARS[15&e]+HEX_CHARS[s>>28&15]+HEX_CHARS[s>>24&15]+HEX_CHARS[s>>20&15]+HEX_CHARS[s>>16&15]+HEX_CHARS[s>>12&15]+HEX_CHARS[s>>8&15]+HEX_CHARS[s>>4&15]+HEX_CHARS[15&s]+HEX_CHARS[i>>28&15]+HEX_CHARS[i>>24&15]+HEX_CHARS[i>>20&15]+HEX_CHARS[i>>16&15]+HEX_CHARS[i>>12&15]+HEX_CHARS[i>>8&15]+HEX_CHARS[i>>4&15]+HEX_CHARS[15&i]+HEX_CHARS[o>>28&15]+HEX_CHARS[o>>24&15]+HEX_CHARS[o>>20&15]+HEX_CHARS[o>>16&15]+HEX_CHARS[o>>12&15]+HEX_CHARS[o>>8&15]+HEX_CHARS[o>>4&15]+HEX_CHARS[15&o];return this.is224||(H+=HEX_CHARS[a>>28&15]+HEX_CHARS[a>>24&15]+HEX_CHARS[a>>20&15]+HEX_CHARS[a>>16&15]+HEX_CHARS[a>>12&15]+HEX_CHARS[a>>8&15]+HEX_CHARS[a>>4&15]+HEX_CHARS[15&a]),H},Sha256.prototype.toString=Sha256.prototype.hex,Sha256.prototype.digest=function(){this.finalize();var t=this.h0,h=this.h1,r=this.h2,e=this.h3,s=this.h4,i=this.h5,o=this.h6,a=this.h7,H=[t>>24&255,t>>16&255,t>>8&255,255&t,h>>24&255,h>>16&255,h>>8&255,255&h,r>>24&255,r>>16&255,r>>8&255,255&r,e>>24&255,e>>16&255,e>>8&255,255&e,s>>24&255,s>>16&255,s>>8&255,255&s,i>>24&255,i>>16&255,i>>8&255,255&i,o>>24&255,o>>16&255,o>>8&255,255&o];return this.is224||H.push(a>>24&255,a>>16&255,a>>8&255,255&a),H},Sha256.prototype.array=Sha256.prototype.digest,Sha256.prototype.arrayBuffer=function(){this.finalize();var t=new ArrayBuffer(this.is224?28:32),h=new DataView(t);return h.setUint32(0,this.h0),h.setUint32(4,this.h1),h.setUint32(8,this.h2),h.setUint32(12,this.h3),h.setUint32(16,this.h4),h.setUint32(20,this.h5),h.setUint32(24,this.h6),this.is224||h.setUint32(28,this.h7),t},HmacSha256.prototype=new Sha256,HmacSha256.prototype.finalize=function(){if(Sha256.prototype.finalize.call(this),this.inner){this.inner=!1;var t=this.array();Sha256.call(this,this.is224,this.sharedMemory),this.update(this.oKeyPad),this.update(t),Sha256.prototype.finalize.call(this)}};var exports=createMethod();exports.sha256=exports,exports.sha224=createMethod(!0),exports.sha256.hmac=createHmacMethod(),exports.sha224.hmac=createHmacMethod(!0),COMMON_JS?module.exports=exports:(root.sha256=exports.sha256,root.sha224=exports.sha224,AMD&&define(function(){return exports}))}();

}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":45}],41:[function(require,module,exports){
require("capability/es5"),module.exports=require("./lib");

},{"./lib":44,"capability/es5":22}],42:[function(require,module,exports){
var Class=function(){var t=Object.create({Source:Object,config:{},buildArgs:[]});function o(o){var r="config";if(o instanceof Function)r="Source";else if(o instanceof Array)r="buildArgs";else{if(!(o instanceof Object))throw new Error("Invalid configuration option.");r="config"}if(t.hasOwnProperty(r))throw new Error("Duplicated configuration option: "+r+".");t[r]=o}for(var r=0,e=arguments.length;r<e;++r)o(arguments[r]);var n=t.Source,s=t.config,i=t.buildArgs;return(n.extend||Class.extend).call(n,s,i)};Class.factory=function(){return function(){this.build instanceof Function&&this.build.apply(this,arguments),this.init instanceof Function&&this.init.apply(this,arguments)}},Class.extend=function(t,o){var r;return t||(t={}),t.prototype instanceof Object&&t.prototype.constructor!==Object?r=t.prototype.constructor:t.factory instanceof Function&&(r=t.factory.call(this)),((r=(this.clone||Class.clone).call(this,r,o)).merge||Class.merge).call(r,t),r},Class.prototype.extend=function(t,o){var r=(this.clone||Class.prototype.clone).apply(this,o);return(r.merge||Class.prototype.merge).call(r,t),r},Class.clone=function(t,o){for(var r in t instanceof Function||(t=(this.factory||Class.factory).call(this)),t.prototype=(this.prototype.clone||Class.prototype.clone).apply(this.prototype,o||[]),t.prototype.constructor=t,this)"prototype"!==r&&(t[r]=this[r]);return t},Class.prototype.clone=function(){var t=Object.create(this);return t.build instanceof Function&&t.build.apply(t,arguments),t},Class.merge=function(t){for(var o in t)"prototype"!==o&&(this[o]=t[o]);return t.prototype instanceof Object&&(this.prototype.merge||Class.prototype.merge).call(this.prototype,t.prototype),this},Class.prototype.merge=function(t){for(var o in t)"constructor"!==o&&(this[o]=t[o]);return this},Class.absorb=function(t){for(var o in t)"prototype"===o||void 0!==this[o]&&this[o]!==Function.prototype[o]||(this[o]=t[o]);return t.prototype instanceof Object&&(this.prototype.absorb||Class.prototype.absorb).call(this.prototype,t.prototype),this},Class.prototype.absorb=function(t){for(var o in t)"constructor"===o||void 0!==this[o]&&this[o]!==Object.prototype[o]||(this[o]=t[o]);return this},Class.getAncestor=function(){if(this!==this.prototype.constructor)return this.prototype.constructor},Class.newInstance=function(){var t=Object.create(this.prototype);return this.apply(t,arguments),t},module.exports=Class;

},{}],43:[function(require,module,exports){
module.exports=function(){throw new Error("Not implemented.")};

},{}],44:[function(require,module,exports){
module.exports={Class:require("./Class"),abstractMethod:require("./abstractMethod")};

},{"./Class":42,"./abstractMethod":43}],45:[function(require,module,exports){
var cachedSetTimeout,cachedClearTimeout,process=module.exports={};function defaultSetTimout(){throw new Error("setTimeout has not been defined")}function defaultClearTimeout(){throw new Error("clearTimeout has not been defined")}function runTimeout(e){if(cachedSetTimeout===setTimeout)return setTimeout(e,0);if((cachedSetTimeout===defaultSetTimout||!cachedSetTimeout)&&setTimeout)return cachedSetTimeout=setTimeout,setTimeout(e,0);try{return cachedSetTimeout(e,0)}catch(t){try{return cachedSetTimeout.call(null,e,0)}catch(t){return cachedSetTimeout.call(this,e,0)}}}function runClearTimeout(e){if(cachedClearTimeout===clearTimeout)return clearTimeout(e);if((cachedClearTimeout===defaultClearTimeout||!cachedClearTimeout)&&clearTimeout)return cachedClearTimeout=clearTimeout,clearTimeout(e);try{return cachedClearTimeout(e)}catch(t){try{return cachedClearTimeout.call(null,e)}catch(t){return cachedClearTimeout.call(this,e)}}}!function(){try{cachedSetTimeout="function"==typeof setTimeout?setTimeout:defaultSetTimout}catch(e){cachedSetTimeout=defaultSetTimout}try{cachedClearTimeout="function"==typeof clearTimeout?clearTimeout:defaultClearTimeout}catch(e){cachedClearTimeout=defaultClearTimeout}}();var currentQueue,queue=[],draining=!1,queueIndex=-1;function cleanUpNextTick(){draining&&currentQueue&&(draining=!1,currentQueue.length?queue=currentQueue.concat(queue):queueIndex=-1,queue.length&&drainQueue())}function drainQueue(){if(!draining){var e=runTimeout(cleanUpNextTick);draining=!0;for(var t=queue.length;t;){for(currentQueue=queue,queue=[];++queueIndex<t;)currentQueue&&currentQueue[queueIndex].run();queueIndex=-1,t=queue.length}currentQueue=null,draining=!1,runClearTimeout(e)}}function Item(e,t){this.fun=e,this.array=t}function noop(){}process.nextTick=function(e){var t=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)t[r-1]=arguments[r];queue.push(new Item(e,t)),1!==queue.length||draining||runTimeout(drainQueue)},Item.prototype.run=function(){this.fun.apply(null,this.array)},process.title="browser",process.browser=!0,process.env={},process.argv=[],process.version="",process.versions={},process.on=noop,process.addListener=noop,process.once=noop,process.off=noop,process.removeListener=noop,process.removeAllListeners=noop,process.emit=noop,process.prependListener=noop,process.prependOnceListener=noop,process.listeners=function(e){return[]},process.binding=function(e){throw new Error("process.binding is not supported")},process.cwd=function(){return"/"},process.chdir=function(e){throw new Error("process.chdir is not supported")},process.umask=function(){return 0};

},{}],46:[function(require,module,exports){
"use strict";module.exports=require("./src/index-minimal");

},{"./src/index-minimal":47}],47:[function(require,module,exports){
"use strict";var protobuf=exports;function configure(){protobuf.Reader._configure(protobuf.BufferReader),protobuf.util._configure()}protobuf.build="minimal",protobuf.Writer=require("./writer"),protobuf.BufferWriter=require("./writer_buffer"),protobuf.Reader=require("./reader"),protobuf.BufferReader=require("./reader_buffer"),protobuf.util=require("./util/minimal"),protobuf.rpc=require("./rpc"),protobuf.roots=require("./roots"),protobuf.configure=configure,protobuf.Writer._configure(protobuf.BufferWriter),configure();

},{"./reader":48,"./reader_buffer":49,"./roots":50,"./rpc":51,"./util/minimal":54,"./writer":55,"./writer_buffer":56}],48:[function(require,module,exports){
"use strict";module.exports=Reader;var BufferReader,util=require("./util/minimal"),LongBits=util.LongBits,utf8=util.utf8;function indexOutOfRange(t,i){return RangeError("index out of range: "+t.pos+" + "+(i||1)+" > "+t.len)}function Reader(t){this.buf=t,this.pos=0,this.len=t.length}var create_array="undefined"!=typeof Uint8Array?function(t){if(t instanceof Uint8Array||Array.isArray(t))return new Reader(t);throw Error("illegal buffer")}:function(t){if(Array.isArray(t))return new Reader(t);throw Error("illegal buffer")};function readLongVarint(){var t=new LongBits(0,0),i=0;if(!(this.len-this.pos>4)){for(;i<3;++i){if(this.pos>=this.len)throw indexOutOfRange(this);if(t.lo=(t.lo|(127&this.buf[this.pos])<<7*i)>>>0,this.buf[this.pos++]<128)return t}return t.lo=(t.lo|(127&this.buf[this.pos++])<<7*i)>>>0,t}for(;i<4;++i)if(t.lo=(t.lo|(127&this.buf[this.pos])<<7*i)>>>0,this.buf[this.pos++]<128)return t;if(t.lo=(t.lo|(127&this.buf[this.pos])<<28)>>>0,t.hi=(t.hi|(127&this.buf[this.pos])>>4)>>>0,this.buf[this.pos++]<128)return t;if(i=0,this.len-this.pos>4){for(;i<5;++i)if(t.hi=(t.hi|(127&this.buf[this.pos])<<7*i+3)>>>0,this.buf[this.pos++]<128)return t}else for(;i<5;++i){if(this.pos>=this.len)throw indexOutOfRange(this);if(t.hi=(t.hi|(127&this.buf[this.pos])<<7*i+3)>>>0,this.buf[this.pos++]<128)return t}throw Error("invalid varint encoding")}function readFixed32_end(t,i){return(t[i-4]|t[i-3]<<8|t[i-2]<<16|t[i-1]<<24)>>>0}function readFixed64(){if(this.pos+8>this.len)throw indexOutOfRange(this,8);return new LongBits(readFixed32_end(this.buf,this.pos+=4),readFixed32_end(this.buf,this.pos+=4))}Reader.create=util.Buffer?function(t){return(Reader.create=function(t){return util.Buffer.isBuffer(t)?new BufferReader(t):create_array(t)})(t)}:create_array,Reader.prototype._slice=util.Array.prototype.subarray||util.Array.prototype.slice,Reader.prototype.uint32=function(){var t=4294967295;return function(){if(t=(127&this.buf[this.pos])>>>0,this.buf[this.pos++]<128)return t;if(t=(t|(127&this.buf[this.pos])<<7)>>>0,this.buf[this.pos++]<128)return t;if(t=(t|(127&this.buf[this.pos])<<14)>>>0,this.buf[this.pos++]<128)return t;if(t=(t|(127&this.buf[this.pos])<<21)>>>0,this.buf[this.pos++]<128)return t;if(t=(t|(15&this.buf[this.pos])<<28)>>>0,this.buf[this.pos++]<128)return t;if((this.pos+=5)>this.len)throw this.pos=this.len,indexOutOfRange(this,10);return t}}(),Reader.prototype.int32=function(){return 0|this.uint32()},Reader.prototype.sint32=function(){var t=this.uint32();return t>>>1^-(1&t)|0},Reader.prototype.bool=function(){return 0!==this.uint32()},Reader.prototype.fixed32=function(){if(this.pos+4>this.len)throw indexOutOfRange(this,4);return readFixed32_end(this.buf,this.pos+=4)},Reader.prototype.sfixed32=function(){if(this.pos+4>this.len)throw indexOutOfRange(this,4);return 0|readFixed32_end(this.buf,this.pos+=4)},Reader.prototype.float=function(){if(this.pos+4>this.len)throw indexOutOfRange(this,4);var t=util.float.readFloatLE(this.buf,this.pos);return this.pos+=4,t},Reader.prototype.double=function(){if(this.pos+8>this.len)throw indexOutOfRange(this,4);var t=util.float.readDoubleLE(this.buf,this.pos);return this.pos+=8,t},Reader.prototype.bytes=function(){var t=this.uint32(),i=this.pos,e=this.pos+t;if(e>this.len)throw indexOutOfRange(this,t);return this.pos+=t,Array.isArray(this.buf)?this.buf.slice(i,e):i===e?new this.buf.constructor(0):this._slice.call(this.buf,i,e)},Reader.prototype.string=function(){var t=this.bytes();return utf8.read(t,0,t.length)},Reader.prototype.skip=function(t){if("number"==typeof t){if(this.pos+t>this.len)throw indexOutOfRange(this,t);this.pos+=t}else do{if(this.pos>=this.len)throw indexOutOfRange(this)}while(128&this.buf[this.pos++]);return this},Reader.prototype.skipType=function(t){switch(t){case 0:this.skip();break;case 1:this.skip(8);break;case 2:this.skip(this.uint32());break;case 3:for(;4!=(t=7&this.uint32());)this.skipType(t);break;case 5:this.skip(4);break;default:throw Error("invalid wire type "+t+" at offset "+this.pos)}return this},Reader._configure=function(t){BufferReader=t;var i=util.Long?"toLong":"toNumber";util.merge(Reader.prototype,{int64:function(){return readLongVarint.call(this)[i](!1)},uint64:function(){return readLongVarint.call(this)[i](!0)},sint64:function(){return readLongVarint.call(this).zzDecode()[i](!1)},fixed64:function(){return readFixed64.call(this)[i](!0)},sfixed64:function(){return readFixed64.call(this)[i](!1)}})};

},{"./util/minimal":54}],49:[function(require,module,exports){
"use strict";module.exports=BufferReader;var Reader=require("./reader");(BufferReader.prototype=Object.create(Reader.prototype)).constructor=BufferReader;var util=require("./util/minimal");function BufferReader(e){Reader.call(this,e)}util.Buffer&&(BufferReader.prototype._slice=util.Buffer.prototype.slice),BufferReader.prototype.string=function(){var e=this.uint32();return this.buf.utf8Slice(this.pos,this.pos=Math.min(this.pos+e,this.len))};

},{"./reader":48,"./util/minimal":54}],50:[function(require,module,exports){
"use strict";module.exports={};

},{}],51:[function(require,module,exports){
"use strict";var rpc=exports;rpc.Service=require("./rpc/service");

},{"./rpc/service":52}],52:[function(require,module,exports){
"use strict";module.exports=Service;var util=require("../util/minimal");function Service(e,t,r){if("function"!=typeof e)throw TypeError("rpcImpl must be a function");util.EventEmitter.call(this),this.rpcImpl=e,this.requestDelimited=Boolean(t),this.responseDelimited=Boolean(r)}(Service.prototype=Object.create(util.EventEmitter.prototype)).constructor=Service,Service.prototype.rpcCall=function e(t,r,i,n,o){if(!n)throw TypeError("request must be specified");var l=this;if(!o)return util.asPromise(e,l,t,r,i,n);if(l.rpcImpl)try{return l.rpcImpl(t,r[l.requestDelimited?"encodeDelimited":"encode"](n).finish(),function(e,r){if(e)return l.emit("error",e,t),o(e);if(null!==r){if(!(r instanceof i))try{r=i[l.responseDelimited?"decodeDelimited":"decode"](r)}catch(e){return l.emit("error",e,t),o(e)}return l.emit("data",r,t),o(null,r)}l.end(!0)})}catch(e){return l.emit("error",e,t),void setTimeout(function(){o(e)},0)}else setTimeout(function(){o(Error("already ended"))},0)},Service.prototype.end=function(e){return this.rpcImpl&&(e||this.rpcImpl(null,null,null),this.rpcImpl=null,this.emit("end").off()),this};

},{"../util/minimal":54}],53:[function(require,module,exports){
"use strict";module.exports=LongBits;var util=require("../util/minimal");function LongBits(t,o){this.lo=t>>>0,this.hi=o>>>0}var zero=LongBits.zero=new LongBits(0,0);zero.toNumber=function(){return 0},zero.zzEncode=zero.zzDecode=function(){return this},zero.length=function(){return 1};var zeroHash=LongBits.zeroHash="\0\0\0\0\0\0\0\0";LongBits.fromNumber=function(t){if(0===t)return zero;var o=t<0;o&&(t=-t);var i=t>>>0,r=(t-i)/4294967296>>>0;return o&&(r=~r>>>0,i=~i>>>0,++i>4294967295&&(i=0,++r>4294967295&&(r=0))),new LongBits(i,r)},LongBits.from=function(t){if("number"==typeof t)return LongBits.fromNumber(t);if(util.isString(t)){if(!util.Long)return LongBits.fromNumber(parseInt(t,10));t=util.Long.fromString(t)}return t.low||t.high?new LongBits(t.low>>>0,t.high>>>0):zero},LongBits.prototype.toNumber=function(t){if(!t&&this.hi>>>31){var o=1+~this.lo>>>0,i=~this.hi>>>0;return o||(i=i+1>>>0),-(o+4294967296*i)}return this.lo+4294967296*this.hi},LongBits.prototype.toLong=function(t){return util.Long?new util.Long(0|this.lo,0|this.hi,Boolean(t)):{low:0|this.lo,high:0|this.hi,unsigned:Boolean(t)}};var charCodeAt=String.prototype.charCodeAt;LongBits.fromHash=function(t){return t===zeroHash?zero:new LongBits((charCodeAt.call(t,0)|charCodeAt.call(t,1)<<8|charCodeAt.call(t,2)<<16|charCodeAt.call(t,3)<<24)>>>0,(charCodeAt.call(t,4)|charCodeAt.call(t,5)<<8|charCodeAt.call(t,6)<<16|charCodeAt.call(t,7)<<24)>>>0)},LongBits.prototype.toHash=function(){return String.fromCharCode(255&this.lo,this.lo>>>8&255,this.lo>>>16&255,this.lo>>>24,255&this.hi,this.hi>>>8&255,this.hi>>>16&255,this.hi>>>24)},LongBits.prototype.zzEncode=function(){var t=this.hi>>31;return this.hi=((this.hi<<1|this.lo>>>31)^t)>>>0,this.lo=(this.lo<<1^t)>>>0,this},LongBits.prototype.zzDecode=function(){var t=-(1&this.lo);return this.lo=((this.lo>>>1|this.hi<<31)^t)>>>0,this.hi=(this.hi>>>1^t)>>>0,this},LongBits.prototype.length=function(){var t=this.lo,o=(this.lo>>>28|this.hi<<4)>>>0,i=this.hi>>>24;return 0===i?0===o?t<16384?t<128?1:2:t<2097152?3:4:o<16384?o<128?5:6:o<2097152?7:8:i<128?9:10};

},{"../util/minimal":54}],54:[function(require,module,exports){
(function (global){
"use strict";var util=exports;function merge(t,e,r){for(var i=Object.keys(e),o=0;o<i.length;++o)void 0!==t[i[o]]&&r||(t[i[o]]=e[i[o]]);return t}function newError(t){function e(t,r){if(!(this instanceof e))return new e(t,r);Object.defineProperty(this,"message",{get:function(){return t}}),Error.captureStackTrace?Error.captureStackTrace(this,e):Object.defineProperty(this,"stack",{value:(new Error).stack||""}),r&&merge(this,r)}return(e.prototype=Object.create(Error.prototype)).constructor=e,Object.defineProperty(e.prototype,"name",{get:function(){return t}}),e.prototype.toString=function(){return this.name+": "+this.message},e}util.asPromise=require("@protobufjs/aspromise"),util.base64=require("@protobufjs/base64"),util.EventEmitter=require("@protobufjs/eventemitter"),util.float=require("@protobufjs/float"),util.inquire=require("@protobufjs/inquire"),util.utf8=require("@protobufjs/utf8"),util.pool=require("@protobufjs/pool"),util.LongBits=require("./longbits"),util.global="undefined"!=typeof window&&window||"undefined"!=typeof global&&global||"undefined"!=typeof self&&self||this,util.emptyArray=Object.freeze?Object.freeze([]):[],util.emptyObject=Object.freeze?Object.freeze({}):{},util.isNode=Boolean(util.global.process&&util.global.process.versions&&util.global.process.versions.node),util.isInteger=Number.isInteger||function(t){return"number"==typeof t&&isFinite(t)&&Math.floor(t)===t},util.isString=function(t){return"string"==typeof t||t instanceof String},util.isObject=function(t){return t&&"object"==typeof t},util.isset=util.isSet=function(t,e){var r=t[e];return!(null==r||!t.hasOwnProperty(e))&&("object"!=typeof r||(Array.isArray(r)?r.length:Object.keys(r).length)>0)},util.Buffer=function(){try{var t=util.inquire("buffer").Buffer;return t.prototype.utf8Write?t:null}catch(t){return null}}(),util._Buffer_from=null,util._Buffer_allocUnsafe=null,util.newBuffer=function(t){return"number"==typeof t?util.Buffer?util._Buffer_allocUnsafe(t):new util.Array(t):util.Buffer?util._Buffer_from(t):"undefined"==typeof Uint8Array?t:new Uint8Array(t)},util.Array="undefined"!=typeof Uint8Array?Uint8Array:Array,util.Long=util.global.dcodeIO&&util.global.dcodeIO.Long||util.global.Long||util.inquire("long"),util.key2Re=/^true|false|0|1$/,util.key32Re=/^-?(?:0|[1-9][0-9]*)$/,util.key64Re=/^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/,util.longToHash=function(t){return t?util.LongBits.from(t).toHash():util.LongBits.zeroHash},util.longFromHash=function(t,e){var r=util.LongBits.fromHash(t);return util.Long?util.Long.fromBits(r.lo,r.hi,e):r.toNumber(Boolean(e))},util.merge=merge,util.lcFirst=function(t){return t.charAt(0).toLowerCase()+t.substring(1)},util.newError=newError,util.ProtocolError=newError("ProtocolError"),util.oneOfGetter=function(t){for(var e={},r=0;r<t.length;++r)e[t[r]]=1;return function(){for(var t=Object.keys(this),r=t.length-1;r>-1;--r)if(1===e[t[r]]&&void 0!==this[t[r]]&&null!==this[t[r]])return t[r]}},util.oneOfSetter=function(t){return function(e){for(var r=0;r<t.length;++r)t[r]!==e&&delete this[t[r]]}},util.toJSONOptions={longs:String,enums:String,bytes:String,json:!0},util._configure=function(){var t=util.Buffer;t?(util._Buffer_from=t.from!==Uint8Array.from&&t.from||function(e,r){return new t(e,r)},util._Buffer_allocUnsafe=t.allocUnsafe||function(e){return new t(e)}):util._Buffer_from=util._Buffer_allocUnsafe=null};

}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"./longbits":53,"@protobufjs/aspromise":9,"@protobufjs/base64":10,"@protobufjs/eventemitter":11,"@protobufjs/float":12,"@protobufjs/inquire":13,"@protobufjs/pool":14,"@protobufjs/utf8":15}],55:[function(require,module,exports){
"use strict";module.exports=Writer;var BufferWriter,util=require("./util/minimal"),LongBits=util.LongBits,base64=util.base64,utf8=util.utf8;function Op(t,i,r){this.fn=t,this.len=i,this.next=void 0,this.val=r}function noop(){}function State(t){this.head=t.head,this.tail=t.tail,this.len=t.len,this.next=t.states}function Writer(){this.len=0,this.head=new Op(noop,0,0),this.tail=this.head,this.states=null}function writeByte(t,i,r){i[r]=255&t}function writeVarint32(t,i,r){for(;t>127;)i[r++]=127&t|128,t>>>=7;i[r]=t}function VarintOp(t,i){this.len=t,this.next=void 0,this.val=i}function writeVarint64(t,i,r){for(;t.hi;)i[r++]=127&t.lo|128,t.lo=(t.lo>>>7|t.hi<<25)>>>0,t.hi>>>=7;for(;t.lo>127;)i[r++]=127&t.lo|128,t.lo=t.lo>>>7;i[r++]=t.lo}function writeFixed32(t,i,r){i[r]=255&t,i[r+1]=t>>>8&255,i[r+2]=t>>>16&255,i[r+3]=t>>>24}Writer.create=util.Buffer?function(){return(Writer.create=function(){return new BufferWriter})()}:function(){return new Writer},Writer.alloc=function(t){return new util.Array(t)},util.Array!==Array&&(Writer.alloc=util.pool(Writer.alloc,util.Array.prototype.subarray)),Writer.prototype._push=function(t,i,r){return this.tail=this.tail.next=new Op(t,i,r),this.len+=i,this},VarintOp.prototype=Object.create(Op.prototype),VarintOp.prototype.fn=writeVarint32,Writer.prototype.uint32=function(t){return this.len+=(this.tail=this.tail.next=new VarintOp((t>>>=0)<128?1:t<16384?2:t<2097152?3:t<268435456?4:5,t)).len,this},Writer.prototype.int32=function(t){return t<0?this._push(writeVarint64,10,LongBits.fromNumber(t)):this.uint32(t)},Writer.prototype.sint32=function(t){return this.uint32((t<<1^t>>31)>>>0)},Writer.prototype.uint64=function(t){var i=LongBits.from(t);return this._push(writeVarint64,i.length(),i)},Writer.prototype.int64=Writer.prototype.uint64,Writer.prototype.sint64=function(t){var i=LongBits.from(t).zzEncode();return this._push(writeVarint64,i.length(),i)},Writer.prototype.bool=function(t){return this._push(writeByte,1,t?1:0)},Writer.prototype.fixed32=function(t){return this._push(writeFixed32,4,t>>>0)},Writer.prototype.sfixed32=Writer.prototype.fixed32,Writer.prototype.fixed64=function(t){var i=LongBits.from(t);return this._push(writeFixed32,4,i.lo)._push(writeFixed32,4,i.hi)},Writer.prototype.sfixed64=Writer.prototype.fixed64,Writer.prototype.float=function(t){return this._push(util.float.writeFloatLE,4,t)},Writer.prototype.double=function(t){return this._push(util.float.writeDoubleLE,8,t)};var writeBytes=util.Array.prototype.set?function(t,i,r){i.set(t,r)}:function(t,i,r){for(var e=0;e<t.length;++e)i[r+e]=t[e]};Writer.prototype.bytes=function(t){var i=t.length>>>0;if(!i)return this._push(writeByte,1,0);if(util.isString(t)){var r=Writer.alloc(i=base64.length(t));base64.decode(t,r,0),t=r}return this.uint32(i)._push(writeBytes,i,t)},Writer.prototype.string=function(t){var i=utf8.length(t);return i?this.uint32(i)._push(utf8.write,i,t):this._push(writeByte,1,0)},Writer.prototype.fork=function(){return this.states=new State(this),this.head=this.tail=new Op(noop,0,0),this.len=0,this},Writer.prototype.reset=function(){return this.states?(this.head=this.states.head,this.tail=this.states.tail,this.len=this.states.len,this.states=this.states.next):(this.head=this.tail=new Op(noop,0,0),this.len=0),this},Writer.prototype.ldelim=function(){var t=this.head,i=this.tail,r=this.len;return this.reset().uint32(r),r&&(this.tail.next=t.next,this.tail=i,this.len+=r),this},Writer.prototype.finish=function(){for(var t=this.head.next,i=this.constructor.alloc(this.len),r=0;t;)t.fn(t.val,i,r),r+=t.len,t=t.next;return i},Writer._configure=function(t){BufferWriter=t};

},{"./util/minimal":54}],56:[function(require,module,exports){
"use strict";module.exports=BufferWriter;var Writer=require("./writer");(BufferWriter.prototype=Object.create(Writer.prototype)).constructor=BufferWriter;var util=require("./util/minimal"),Buffer=util.Buffer;function BufferWriter(){Writer.call(this)}BufferWriter.alloc=function(r){return(BufferWriter.alloc=util._Buffer_allocUnsafe)(r)};var writeBytesBuffer=Buffer&&Buffer.prototype instanceof Uint8Array&&"set"===Buffer.prototype.set.name?function(r,t,e){t.set(r,e)}:function(r,t,e){if(r.copy)r.copy(t,e,0,r.length);else for(var f=0;f<r.length;)t[e++]=r[f++]};function writeStringBuffer(r,t,e){r.length<40?util.utf8.write(r,t,e):t.utf8Write(r,e)}BufferWriter.prototype.bytes=function(r){util.isString(r)&&(r=util._Buffer_from(r,"base64"));var t=r.length>>>0;return this.uint32(t),t&&this._push(writeBytesBuffer,t,r),this},BufferWriter.prototype.string=function(r){var t=Buffer.byteLength(r);return this.uint32(t),t&&this._push(writeStringBuffer,t,r),this};

},{"./util/minimal":54,"./writer":55}],57:[function(require,module,exports){
var buffer=require("buffer"),Buffer=buffer.Buffer;function copyProps(f,r){for(var e in f)r[e]=f[e]}function SafeBuffer(f,r,e){return Buffer(f,r,e)}Buffer.from&&Buffer.alloc&&Buffer.allocUnsafe&&Buffer.allocUnsafeSlow?module.exports=buffer:(copyProps(buffer,exports),exports.Buffer=SafeBuffer),copyProps(Buffer,SafeBuffer),SafeBuffer.from=function(f,r,e){if("number"==typeof f)throw new TypeError("Argument must not be a number");return Buffer(f,r,e)},SafeBuffer.alloc=function(f,r,e){if("number"!=typeof f)throw new TypeError("Argument must be a number");var u=Buffer(f);return void 0!==r?"string"==typeof e?u.fill(r,e):u.fill(r):u.fill(0),u},SafeBuffer.allocUnsafe=function(f){if("number"!=typeof f)throw new TypeError("Argument must be a number");return Buffer(f)},SafeBuffer.allocUnsafeSlow=function(f){if("number"!=typeof f)throw new TypeError("Argument must be a number");return buffer.SlowBuffer(f)};

},{"buffer":21}],58:[function(require,module,exports){
function setProtoOf(r,o){return r.__proto__=o,r}function mixinProperties(r,o){for(var t in o)r.hasOwnProperty(t)||(r[t]=o[t]);return r}module.exports=Object.setPrototypeOf||({__proto__:[]}instanceof Array?setProtoOf:mixinProperties);

},{}],59:[function(require,module,exports){
module.exports={
  "100": "Continue",
  "101": "Switching Protocols",
  "102": "Processing",
  "103": "Early Hints",
  "200": "OK",
  "201": "Created",
  "202": "Accepted",
  "203": "Non-Authoritative Information",
  "204": "No Content",
  "205": "Reset Content",
  "206": "Partial Content",
  "207": "Multi-Status",
  "208": "Already Reported",
  "226": "IM Used",
  "300": "Multiple Choices",
  "301": "Moved Permanently",
  "302": "Found",
  "303": "See Other",
  "304": "Not Modified",
  "305": "Use Proxy",
  "306": "(Unused)",
  "307": "Temporary Redirect",
  "308": "Permanent Redirect",
  "400": "Bad Request",
  "401": "Unauthorized",
  "402": "Payment Required",
  "403": "Forbidden",
  "404": "Not Found",
  "405": "Method Not Allowed",
  "406": "Not Acceptable",
  "407": "Proxy Authentication Required",
  "408": "Request Timeout",
  "409": "Conflict",
  "410": "Gone",
  "411": "Length Required",
  "412": "Precondition Failed",
  "413": "Payload Too Large",
  "414": "URI Too Long",
  "415": "Unsupported Media Type",
  "416": "Range Not Satisfiable",
  "417": "Expectation Failed",
  "418": "I'm a teapot",
  "421": "Misdirected Request",
  "422": "Unprocessable Entity",
  "423": "Locked",
  "424": "Failed Dependency",
  "425": "Unordered Collection",
  "426": "Upgrade Required",
  "428": "Precondition Required",
  "429": "Too Many Requests",
  "431": "Request Header Fields Too Large",
  "451": "Unavailable For Legal Reasons",
  "500": "Internal Server Error",
  "501": "Not Implemented",
  "502": "Bad Gateway",
  "503": "Service Unavailable",
  "504": "Gateway Timeout",
  "505": "HTTP Version Not Supported",
  "506": "Variant Also Negotiates",
  "507": "Insufficient Storage",
  "508": "Loop Detected",
  "509": "Bandwidth Limit Exceeded",
  "510": "Not Extended",
  "511": "Network Authentication Required"
}

},{}],60:[function(require,module,exports){
"use strict";var codes=require("./codes.json");function populateStatusesMap(t,s){var r=[];return Object.keys(s).forEach(function(e){var a=s[e],u=Number(e);t[u]=a,t[a]=u,t[a.toLowerCase()]=u,r.push(u)}),r}function status(t){if("number"==typeof t){if(!status[t])throw new Error("invalid status code: "+t);return t}if("string"!=typeof t)throw new TypeError("code must be a number or string");var s=parseInt(t,10);if(!isNaN(s)){if(!status[s])throw new Error("invalid status code: "+s);return s}if(!(s=status[t.toLowerCase()]))throw new Error('invalid status message: "'+t+'"');return s}module.exports=status,status.STATUS_CODES=codes,status.codes=populateStatusesMap(status,codes),status.redirect={300:!0,301:!0,302:!0,303:!0,305:!0,307:!0,308:!0},status.empty={204:!0,205:!0,304:!0},status.retry={502:!0,503:!0,504:!0};

},{"./codes.json":59}],61:[function(require,module,exports){
function toIdentifier(e){return e.split(" ").map(function(e){return e.slice(0,1).toUpperCase()+e.slice(1)}).join("").replace(/[^ _0-9a-z]/gi,"")}module.exports=toIdentifier;

},{}],62:[function(require,module,exports){
!function(r){"use strict";var t=function(r){var t,n=new Float64Array(16);if(r)for(t=0;t<r.length;t++)n[t]=r[t];return n},n=function(){throw new Error("no PRNG")},e=new Uint8Array(16),o=new Uint8Array(32);o[0]=9;var i=t(),h=t([1]),a=t([56129,1]),f=t([30883,4953,19914,30187,55467,16705,2637,112,59544,30585,16505,36039,65139,11119,27886,20995]),s=t([61785,9906,39828,60374,45398,33411,5274,224,53552,61171,33010,6542,64743,22239,55772,9222]),u=t([54554,36645,11616,51542,42930,38181,51040,26924,56412,64982,57905,49316,21502,52590,14035,8553]),c=t([26200,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214,26214]),y=t([41136,18958,6951,50414,58488,44335,6150,12099,55207,15867,153,11085,57099,20417,9344,11139]);function l(r,t,n,e){r[t]=n>>24&255,r[t+1]=n>>16&255,r[t+2]=n>>8&255,r[t+3]=255&n,r[t+4]=e>>24&255,r[t+5]=e>>16&255,r[t+6]=e>>8&255,r[t+7]=255&e}function v(r,t,n,e,o){var i,h=0;for(i=0;i<o;i++)h|=r[t+i]^n[e+i];return(1&h-1>>>8)-1}function w(r,t,n,e){return v(r,t,n,e,16)}function p(r,t,n,e){return v(r,t,n,e,32)}function b(r,t,n,e){!function(r,t,n,e){for(var o,i=255&e[0]|(255&e[1])<<8|(255&e[2])<<16|(255&e[3])<<24,h=255&n[0]|(255&n[1])<<8|(255&n[2])<<16|(255&n[3])<<24,a=255&n[4]|(255&n[5])<<8|(255&n[6])<<16|(255&n[7])<<24,f=255&n[8]|(255&n[9])<<8|(255&n[10])<<16|(255&n[11])<<24,s=255&n[12]|(255&n[13])<<8|(255&n[14])<<16|(255&n[15])<<24,u=255&e[4]|(255&e[5])<<8|(255&e[6])<<16|(255&e[7])<<24,c=255&t[0]|(255&t[1])<<8|(255&t[2])<<16|(255&t[3])<<24,y=255&t[4]|(255&t[5])<<8|(255&t[6])<<16|(255&t[7])<<24,l=255&t[8]|(255&t[9])<<8|(255&t[10])<<16|(255&t[11])<<24,v=255&t[12]|(255&t[13])<<8|(255&t[14])<<16|(255&t[15])<<24,w=255&e[8]|(255&e[9])<<8|(255&e[10])<<16|(255&e[11])<<24,p=255&n[16]|(255&n[17])<<8|(255&n[18])<<16|(255&n[19])<<24,b=255&n[20]|(255&n[21])<<8|(255&n[22])<<16|(255&n[23])<<24,g=255&n[24]|(255&n[25])<<8|(255&n[26])<<16|(255&n[27])<<24,_=255&n[28]|(255&n[29])<<8|(255&n[30])<<16|(255&n[31])<<24,A=255&e[12]|(255&e[13])<<8|(255&e[14])<<16|(255&e[15])<<24,U=i,d=h,E=a,x=f,M=s,m=u,B=c,S=y,K=l,Y=v,k=w,T=p,L=b,z=g,R=_,P=A,N=0;N<20;N+=2)U^=(o=(L^=(o=(K^=(o=(M^=(o=U+L|0)<<7|o>>>25)+U|0)<<9|o>>>23)+M|0)<<13|o>>>19)+K|0)<<18|o>>>14,m^=(o=(d^=(o=(z^=(o=(Y^=(o=m+d|0)<<7|o>>>25)+m|0)<<9|o>>>23)+Y|0)<<13|o>>>19)+z|0)<<18|o>>>14,k^=(o=(B^=(o=(E^=(o=(R^=(o=k+B|0)<<7|o>>>25)+k|0)<<9|o>>>23)+R|0)<<13|o>>>19)+E|0)<<18|o>>>14,P^=(o=(T^=(o=(S^=(o=(x^=(o=P+T|0)<<7|o>>>25)+P|0)<<9|o>>>23)+x|0)<<13|o>>>19)+S|0)<<18|o>>>14,U^=(o=(x^=(o=(E^=(o=(d^=(o=U+x|0)<<7|o>>>25)+U|0)<<9|o>>>23)+d|0)<<13|o>>>19)+E|0)<<18|o>>>14,m^=(o=(M^=(o=(S^=(o=(B^=(o=m+M|0)<<7|o>>>25)+m|0)<<9|o>>>23)+B|0)<<13|o>>>19)+S|0)<<18|o>>>14,k^=(o=(Y^=(o=(K^=(o=(T^=(o=k+Y|0)<<7|o>>>25)+k|0)<<9|o>>>23)+T|0)<<13|o>>>19)+K|0)<<18|o>>>14,P^=(o=(R^=(o=(z^=(o=(L^=(o=P+R|0)<<7|o>>>25)+P|0)<<9|o>>>23)+L|0)<<13|o>>>19)+z|0)<<18|o>>>14;U=U+i|0,d=d+h|0,E=E+a|0,x=x+f|0,M=M+s|0,m=m+u|0,B=B+c|0,S=S+y|0,K=K+l|0,Y=Y+v|0,k=k+w|0,T=T+p|0,L=L+b|0,z=z+g|0,R=R+_|0,P=P+A|0,r[0]=U>>>0&255,r[1]=U>>>8&255,r[2]=U>>>16&255,r[3]=U>>>24&255,r[4]=d>>>0&255,r[5]=d>>>8&255,r[6]=d>>>16&255,r[7]=d>>>24&255,r[8]=E>>>0&255,r[9]=E>>>8&255,r[10]=E>>>16&255,r[11]=E>>>24&255,r[12]=x>>>0&255,r[13]=x>>>8&255,r[14]=x>>>16&255,r[15]=x>>>24&255,r[16]=M>>>0&255,r[17]=M>>>8&255,r[18]=M>>>16&255,r[19]=M>>>24&255,r[20]=m>>>0&255,r[21]=m>>>8&255,r[22]=m>>>16&255,r[23]=m>>>24&255,r[24]=B>>>0&255,r[25]=B>>>8&255,r[26]=B>>>16&255,r[27]=B>>>24&255,r[28]=S>>>0&255,r[29]=S>>>8&255,r[30]=S>>>16&255,r[31]=S>>>24&255,r[32]=K>>>0&255,r[33]=K>>>8&255,r[34]=K>>>16&255,r[35]=K>>>24&255,r[36]=Y>>>0&255,r[37]=Y>>>8&255,r[38]=Y>>>16&255,r[39]=Y>>>24&255,r[40]=k>>>0&255,r[41]=k>>>8&255,r[42]=k>>>16&255,r[43]=k>>>24&255,r[44]=T>>>0&255,r[45]=T>>>8&255,r[46]=T>>>16&255,r[47]=T>>>24&255,r[48]=L>>>0&255,r[49]=L>>>8&255,r[50]=L>>>16&255,r[51]=L>>>24&255,r[52]=z>>>0&255,r[53]=z>>>8&255,r[54]=z>>>16&255,r[55]=z>>>24&255,r[56]=R>>>0&255,r[57]=R>>>8&255,r[58]=R>>>16&255,r[59]=R>>>24&255,r[60]=P>>>0&255,r[61]=P>>>8&255,r[62]=P>>>16&255,r[63]=P>>>24&255}(r,t,n,e)}function g(r,t,n,e){!function(r,t,n,e){for(var o,i=255&e[0]|(255&e[1])<<8|(255&e[2])<<16|(255&e[3])<<24,h=255&n[0]|(255&n[1])<<8|(255&n[2])<<16|(255&n[3])<<24,a=255&n[4]|(255&n[5])<<8|(255&n[6])<<16|(255&n[7])<<24,f=255&n[8]|(255&n[9])<<8|(255&n[10])<<16|(255&n[11])<<24,s=255&n[12]|(255&n[13])<<8|(255&n[14])<<16|(255&n[15])<<24,u=255&e[4]|(255&e[5])<<8|(255&e[6])<<16|(255&e[7])<<24,c=255&t[0]|(255&t[1])<<8|(255&t[2])<<16|(255&t[3])<<24,y=255&t[4]|(255&t[5])<<8|(255&t[6])<<16|(255&t[7])<<24,l=255&t[8]|(255&t[9])<<8|(255&t[10])<<16|(255&t[11])<<24,v=255&t[12]|(255&t[13])<<8|(255&t[14])<<16|(255&t[15])<<24,w=255&e[8]|(255&e[9])<<8|(255&e[10])<<16|(255&e[11])<<24,p=255&n[16]|(255&n[17])<<8|(255&n[18])<<16|(255&n[19])<<24,b=255&n[20]|(255&n[21])<<8|(255&n[22])<<16|(255&n[23])<<24,g=255&n[24]|(255&n[25])<<8|(255&n[26])<<16|(255&n[27])<<24,_=255&n[28]|(255&n[29])<<8|(255&n[30])<<16|(255&n[31])<<24,A=255&e[12]|(255&e[13])<<8|(255&e[14])<<16|(255&e[15])<<24,U=0;U<20;U+=2)i^=(o=(b^=(o=(l^=(o=(s^=(o=i+b|0)<<7|o>>>25)+i|0)<<9|o>>>23)+s|0)<<13|o>>>19)+l|0)<<18|o>>>14,u^=(o=(h^=(o=(g^=(o=(v^=(o=u+h|0)<<7|o>>>25)+u|0)<<9|o>>>23)+v|0)<<13|o>>>19)+g|0)<<18|o>>>14,w^=(o=(c^=(o=(a^=(o=(_^=(o=w+c|0)<<7|o>>>25)+w|0)<<9|o>>>23)+_|0)<<13|o>>>19)+a|0)<<18|o>>>14,A^=(o=(p^=(o=(y^=(o=(f^=(o=A+p|0)<<7|o>>>25)+A|0)<<9|o>>>23)+f|0)<<13|o>>>19)+y|0)<<18|o>>>14,i^=(o=(f^=(o=(a^=(o=(h^=(o=i+f|0)<<7|o>>>25)+i|0)<<9|o>>>23)+h|0)<<13|o>>>19)+a|0)<<18|o>>>14,u^=(o=(s^=(o=(y^=(o=(c^=(o=u+s|0)<<7|o>>>25)+u|0)<<9|o>>>23)+c|0)<<13|o>>>19)+y|0)<<18|o>>>14,w^=(o=(v^=(o=(l^=(o=(p^=(o=w+v|0)<<7|o>>>25)+w|0)<<9|o>>>23)+p|0)<<13|o>>>19)+l|0)<<18|o>>>14,A^=(o=(_^=(o=(g^=(o=(b^=(o=A+_|0)<<7|o>>>25)+A|0)<<9|o>>>23)+b|0)<<13|o>>>19)+g|0)<<18|o>>>14;r[0]=i>>>0&255,r[1]=i>>>8&255,r[2]=i>>>16&255,r[3]=i>>>24&255,r[4]=u>>>0&255,r[5]=u>>>8&255,r[6]=u>>>16&255,r[7]=u>>>24&255,r[8]=w>>>0&255,r[9]=w>>>8&255,r[10]=w>>>16&255,r[11]=w>>>24&255,r[12]=A>>>0&255,r[13]=A>>>8&255,r[14]=A>>>16&255,r[15]=A>>>24&255,r[16]=c>>>0&255,r[17]=c>>>8&255,r[18]=c>>>16&255,r[19]=c>>>24&255,r[20]=y>>>0&255,r[21]=y>>>8&255,r[22]=y>>>16&255,r[23]=y>>>24&255,r[24]=l>>>0&255,r[25]=l>>>8&255,r[26]=l>>>16&255,r[27]=l>>>24&255,r[28]=v>>>0&255,r[29]=v>>>8&255,r[30]=v>>>16&255,r[31]=v>>>24&255}(r,t,n,e)}var _=new Uint8Array([101,120,112,97,110,100,32,51,50,45,98,121,116,101,32,107]);function A(r,t,n,e,o,i,h){var a,f,s=new Uint8Array(16),u=new Uint8Array(64);for(f=0;f<16;f++)s[f]=0;for(f=0;f<8;f++)s[f]=i[f];for(;o>=64;){for(b(u,s,h,_),f=0;f<64;f++)r[t+f]=n[e+f]^u[f];for(a=1,f=8;f<16;f++)a=a+(255&s[f])|0,s[f]=255&a,a>>>=8;o-=64,t+=64,e+=64}if(o>0)for(b(u,s,h,_),f=0;f<o;f++)r[t+f]=n[e+f]^u[f];return 0}function U(r,t,n,e,o){var i,h,a=new Uint8Array(16),f=new Uint8Array(64);for(h=0;h<16;h++)a[h]=0;for(h=0;h<8;h++)a[h]=e[h];for(;n>=64;){for(b(f,a,o,_),h=0;h<64;h++)r[t+h]=f[h];for(i=1,h=8;h<16;h++)i=i+(255&a[h])|0,a[h]=255&i,i>>>=8;n-=64,t+=64}if(n>0)for(b(f,a,o,_),h=0;h<n;h++)r[t+h]=f[h];return 0}function d(r,t,n,e,o){var i=new Uint8Array(32);g(i,e,o,_);for(var h=new Uint8Array(8),a=0;a<8;a++)h[a]=e[a+16];return U(r,t,n,h,i)}function E(r,t,n,e,o,i,h){var a=new Uint8Array(32);g(a,i,h,_);for(var f=new Uint8Array(8),s=0;s<8;s++)f[s]=i[s+16];return A(r,t,n,e,o,f,a)}var x=function(r){var t,n,e,o,i,h,a,f;this.buffer=new Uint8Array(16),this.r=new Uint16Array(10),this.h=new Uint16Array(10),this.pad=new Uint16Array(8),this.leftover=0,this.fin=0,t=255&r[0]|(255&r[1])<<8,this.r[0]=8191&t,n=255&r[2]|(255&r[3])<<8,this.r[1]=8191&(t>>>13|n<<3),e=255&r[4]|(255&r[5])<<8,this.r[2]=7939&(n>>>10|e<<6),o=255&r[6]|(255&r[7])<<8,this.r[3]=8191&(e>>>7|o<<9),i=255&r[8]|(255&r[9])<<8,this.r[4]=255&(o>>>4|i<<12),this.r[5]=i>>>1&8190,h=255&r[10]|(255&r[11])<<8,this.r[6]=8191&(i>>>14|h<<2),a=255&r[12]|(255&r[13])<<8,this.r[7]=8065&(h>>>11|a<<5),f=255&r[14]|(255&r[15])<<8,this.r[8]=8191&(a>>>8|f<<8),this.r[9]=f>>>5&127,this.pad[0]=255&r[16]|(255&r[17])<<8,this.pad[1]=255&r[18]|(255&r[19])<<8,this.pad[2]=255&r[20]|(255&r[21])<<8,this.pad[3]=255&r[22]|(255&r[23])<<8,this.pad[4]=255&r[24]|(255&r[25])<<8,this.pad[5]=255&r[26]|(255&r[27])<<8,this.pad[6]=255&r[28]|(255&r[29])<<8,this.pad[7]=255&r[30]|(255&r[31])<<8};function M(r,t,n,e,o,i){var h=new x(i);return h.update(n,e,o),h.finish(r,t),0}function m(r,t,n,e,o,i){var h=new Uint8Array(16);return M(h,0,n,e,o,i),w(r,t,h,0)}function B(r,t,n,e,o){var i;if(n<32)return-1;for(E(r,0,t,0,n,e,o),M(r,16,r,32,n-32,r),i=0;i<16;i++)r[i]=0;return 0}function S(r,t,n,e,o){var i,h=new Uint8Array(32);if(n<32)return-1;if(d(h,0,32,e,o),0!==m(t,16,t,32,n-32,h))return-1;for(E(r,0,t,0,n,e,o),i=0;i<32;i++)r[i]=0;return 0}function K(r,t){var n;for(n=0;n<16;n++)r[n]=0|t[n]}function Y(r){var t,n,e=1;for(t=0;t<16;t++)n=r[t]+e+65535,e=Math.floor(n/65536),r[t]=n-65536*e;r[0]+=e-1+37*(e-1)}function k(r,t,n){for(var e,o=~(n-1),i=0;i<16;i++)e=o&(r[i]^t[i]),r[i]^=e,t[i]^=e}function T(r,n){var e,o,i,h=t(),a=t();for(e=0;e<16;e++)a[e]=n[e];for(Y(a),Y(a),Y(a),o=0;o<2;o++){for(h[0]=a[0]-65517,e=1;e<15;e++)h[e]=a[e]-65535-(h[e-1]>>16&1),h[e-1]&=65535;h[15]=a[15]-32767-(h[14]>>16&1),i=h[15]>>16&1,h[14]&=65535,k(a,h,1-i)}for(e=0;e<16;e++)r[2*e]=255&a[e],r[2*e+1]=a[e]>>8}function L(r,t){var n=new Uint8Array(32),e=new Uint8Array(32);return T(n,r),T(e,t),p(n,0,e,0)}function z(r){var t=new Uint8Array(32);return T(t,r),1&t[0]}function R(r,t){var n;for(n=0;n<16;n++)r[n]=t[2*n]+(t[2*n+1]<<8);r[15]&=32767}function P(r,t,n){for(var e=0;e<16;e++)r[e]=t[e]+n[e]}function N(r,t,n){for(var e=0;e<16;e++)r[e]=t[e]-n[e]}function O(r,t,n){var e,o,i=0,h=0,a=0,f=0,s=0,u=0,c=0,y=0,l=0,v=0,w=0,p=0,b=0,g=0,_=0,A=0,U=0,d=0,E=0,x=0,M=0,m=0,B=0,S=0,K=0,Y=0,k=0,T=0,L=0,z=0,R=0,P=n[0],N=n[1],O=n[2],C=n[3],F=n[4],I=n[5],G=n[6],Z=n[7],q=n[8],V=n[9],X=n[10],D=n[11],j=n[12],H=n[13],J=n[14],Q=n[15];i+=(e=t[0])*P,h+=e*N,a+=e*O,f+=e*C,s+=e*F,u+=e*I,c+=e*G,y+=e*Z,l+=e*q,v+=e*V,w+=e*X,p+=e*D,b+=e*j,g+=e*H,_+=e*J,A+=e*Q,h+=(e=t[1])*P,a+=e*N,f+=e*O,s+=e*C,u+=e*F,c+=e*I,y+=e*G,l+=e*Z,v+=e*q,w+=e*V,p+=e*X,b+=e*D,g+=e*j,_+=e*H,A+=e*J,U+=e*Q,a+=(e=t[2])*P,f+=e*N,s+=e*O,u+=e*C,c+=e*F,y+=e*I,l+=e*G,v+=e*Z,w+=e*q,p+=e*V,b+=e*X,g+=e*D,_+=e*j,A+=e*H,U+=e*J,d+=e*Q,f+=(e=t[3])*P,s+=e*N,u+=e*O,c+=e*C,y+=e*F,l+=e*I,v+=e*G,w+=e*Z,p+=e*q,b+=e*V,g+=e*X,_+=e*D,A+=e*j,U+=e*H,d+=e*J,E+=e*Q,s+=(e=t[4])*P,u+=e*N,c+=e*O,y+=e*C,l+=e*F,v+=e*I,w+=e*G,p+=e*Z,b+=e*q,g+=e*V,_+=e*X,A+=e*D,U+=e*j,d+=e*H,E+=e*J,x+=e*Q,u+=(e=t[5])*P,c+=e*N,y+=e*O,l+=e*C,v+=e*F,w+=e*I,p+=e*G,b+=e*Z,g+=e*q,_+=e*V,A+=e*X,U+=e*D,d+=e*j,E+=e*H,x+=e*J,M+=e*Q,c+=(e=t[6])*P,y+=e*N,l+=e*O,v+=e*C,w+=e*F,p+=e*I,b+=e*G,g+=e*Z,_+=e*q,A+=e*V,U+=e*X,d+=e*D,E+=e*j,x+=e*H,M+=e*J,m+=e*Q,y+=(e=t[7])*P,l+=e*N,v+=e*O,w+=e*C,p+=e*F,b+=e*I,g+=e*G,_+=e*Z,A+=e*q,U+=e*V,d+=e*X,E+=e*D,x+=e*j,M+=e*H,m+=e*J,B+=e*Q,l+=(e=t[8])*P,v+=e*N,w+=e*O,p+=e*C,b+=e*F,g+=e*I,_+=e*G,A+=e*Z,U+=e*q,d+=e*V,E+=e*X,x+=e*D,M+=e*j,m+=e*H,B+=e*J,S+=e*Q,v+=(e=t[9])*P,w+=e*N,p+=e*O,b+=e*C,g+=e*F,_+=e*I,A+=e*G,U+=e*Z,d+=e*q,E+=e*V,x+=e*X,M+=e*D,m+=e*j,B+=e*H,S+=e*J,K+=e*Q,w+=(e=t[10])*P,p+=e*N,b+=e*O,g+=e*C,_+=e*F,A+=e*I,U+=e*G,d+=e*Z,E+=e*q,x+=e*V,M+=e*X,m+=e*D,B+=e*j,S+=e*H,K+=e*J,Y+=e*Q,p+=(e=t[11])*P,b+=e*N,g+=e*O,_+=e*C,A+=e*F,U+=e*I,d+=e*G,E+=e*Z,x+=e*q,M+=e*V,m+=e*X,B+=e*D,S+=e*j,K+=e*H,Y+=e*J,k+=e*Q,b+=(e=t[12])*P,g+=e*N,_+=e*O,A+=e*C,U+=e*F,d+=e*I,E+=e*G,x+=e*Z,M+=e*q,m+=e*V,B+=e*X,S+=e*D,K+=e*j,Y+=e*H,k+=e*J,T+=e*Q,g+=(e=t[13])*P,_+=e*N,A+=e*O,U+=e*C,d+=e*F,E+=e*I,x+=e*G,M+=e*Z,m+=e*q,B+=e*V,S+=e*X,K+=e*D,Y+=e*j,k+=e*H,T+=e*J,L+=e*Q,_+=(e=t[14])*P,A+=e*N,U+=e*O,d+=e*C,E+=e*F,x+=e*I,M+=e*G,m+=e*Z,B+=e*q,S+=e*V,K+=e*X,Y+=e*D,k+=e*j,T+=e*H,L+=e*J,z+=e*Q,A+=(e=t[15])*P,h+=38*(d+=e*O),a+=38*(E+=e*C),f+=38*(x+=e*F),s+=38*(M+=e*I),u+=38*(m+=e*G),c+=38*(B+=e*Z),y+=38*(S+=e*q),l+=38*(K+=e*V),v+=38*(Y+=e*X),w+=38*(k+=e*D),p+=38*(T+=e*j),b+=38*(L+=e*H),g+=38*(z+=e*J),_+=38*(R+=e*Q),i=(e=(i+=38*(U+=e*N))+(o=1)+65535)-65536*(o=Math.floor(e/65536)),h=(e=h+o+65535)-65536*(o=Math.floor(e/65536)),a=(e=a+o+65535)-65536*(o=Math.floor(e/65536)),f=(e=f+o+65535)-65536*(o=Math.floor(e/65536)),s=(e=s+o+65535)-65536*(o=Math.floor(e/65536)),u=(e=u+o+65535)-65536*(o=Math.floor(e/65536)),c=(e=c+o+65535)-65536*(o=Math.floor(e/65536)),y=(e=y+o+65535)-65536*(o=Math.floor(e/65536)),l=(e=l+o+65535)-65536*(o=Math.floor(e/65536)),v=(e=v+o+65535)-65536*(o=Math.floor(e/65536)),w=(e=w+o+65535)-65536*(o=Math.floor(e/65536)),p=(e=p+o+65535)-65536*(o=Math.floor(e/65536)),b=(e=b+o+65535)-65536*(o=Math.floor(e/65536)),g=(e=g+o+65535)-65536*(o=Math.floor(e/65536)),_=(e=_+o+65535)-65536*(o=Math.floor(e/65536)),A=(e=A+o+65535)-65536*(o=Math.floor(e/65536)),i=(e=(i+=o-1+37*(o-1))+(o=1)+65535)-65536*(o=Math.floor(e/65536)),h=(e=h+o+65535)-65536*(o=Math.floor(e/65536)),a=(e=a+o+65535)-65536*(o=Math.floor(e/65536)),f=(e=f+o+65535)-65536*(o=Math.floor(e/65536)),s=(e=s+o+65535)-65536*(o=Math.floor(e/65536)),u=(e=u+o+65535)-65536*(o=Math.floor(e/65536)),c=(e=c+o+65535)-65536*(o=Math.floor(e/65536)),y=(e=y+o+65535)-65536*(o=Math.floor(e/65536)),l=(e=l+o+65535)-65536*(o=Math.floor(e/65536)),v=(e=v+o+65535)-65536*(o=Math.floor(e/65536)),w=(e=w+o+65535)-65536*(o=Math.floor(e/65536)),p=(e=p+o+65535)-65536*(o=Math.floor(e/65536)),b=(e=b+o+65535)-65536*(o=Math.floor(e/65536)),g=(e=g+o+65535)-65536*(o=Math.floor(e/65536)),_=(e=_+o+65535)-65536*(o=Math.floor(e/65536)),A=(e=A+o+65535)-65536*(o=Math.floor(e/65536)),i+=o-1+37*(o-1),r[0]=i,r[1]=h,r[2]=a,r[3]=f,r[4]=s,r[5]=u,r[6]=c,r[7]=y,r[8]=l,r[9]=v,r[10]=w,r[11]=p,r[12]=b,r[13]=g,r[14]=_,r[15]=A}function C(r,t){O(r,t,t)}function F(r,n){var e,o=t();for(e=0;e<16;e++)o[e]=n[e];for(e=253;e>=0;e--)C(o,o),2!==e&&4!==e&&O(o,o,n);for(e=0;e<16;e++)r[e]=o[e]}function I(r,n,e){var o,i,h=new Uint8Array(32),f=new Float64Array(80),s=t(),u=t(),c=t(),y=t(),l=t(),v=t();for(i=0;i<31;i++)h[i]=n[i];for(h[31]=127&n[31]|64,h[0]&=248,R(f,e),i=0;i<16;i++)u[i]=f[i],y[i]=s[i]=c[i]=0;for(s[0]=y[0]=1,i=254;i>=0;--i)k(s,u,o=h[i>>>3]>>>(7&i)&1),k(c,y,o),P(l,s,c),N(s,s,c),P(c,u,y),N(u,u,y),C(y,l),C(v,s),O(s,c,s),O(c,u,l),P(l,s,c),N(s,s,c),C(u,s),N(c,y,v),O(s,c,a),P(s,s,y),O(c,c,s),O(s,y,v),O(y,u,f),C(u,l),k(s,u,o),k(c,y,o);for(i=0;i<16;i++)f[i+16]=s[i],f[i+32]=c[i],f[i+48]=u[i],f[i+64]=y[i];var w=f.subarray(32),p=f.subarray(16);return F(w,w),O(p,p,w),T(r,p),0}function G(r,t){return I(r,t,o)}function Z(r,t){return n(t,32),G(r,t)}function q(r,t,n){var o=new Uint8Array(32);return I(o,n,t),g(r,e,o,_)}x.prototype.blocks=function(r,t,n){for(var e,o,i,h,a,f,s,u,c,y,l,v,w,p,b,g,_,A,U,d=this.fin?0:2048,E=this.h[0],x=this.h[1],M=this.h[2],m=this.h[3],B=this.h[4],S=this.h[5],K=this.h[6],Y=this.h[7],k=this.h[8],T=this.h[9],L=this.r[0],z=this.r[1],R=this.r[2],P=this.r[3],N=this.r[4],O=this.r[5],C=this.r[6],F=this.r[7],I=this.r[8],G=this.r[9];n>=16;)y=c=0,y+=(E+=8191&(e=255&r[t+0]|(255&r[t+1])<<8))*L,y+=(x+=8191&(e>>>13|(o=255&r[t+2]|(255&r[t+3])<<8)<<3))*(5*G),y+=(M+=8191&(o>>>10|(i=255&r[t+4]|(255&r[t+5])<<8)<<6))*(5*I),y+=(m+=8191&(i>>>7|(h=255&r[t+6]|(255&r[t+7])<<8)<<9))*(5*F),c=(y+=(B+=8191&(h>>>4|(a=255&r[t+8]|(255&r[t+9])<<8)<<12))*(5*C))>>>13,y&=8191,y+=(S+=a>>>1&8191)*(5*O),y+=(K+=8191&(a>>>14|(f=255&r[t+10]|(255&r[t+11])<<8)<<2))*(5*N),y+=(Y+=8191&(f>>>11|(s=255&r[t+12]|(255&r[t+13])<<8)<<5))*(5*P),y+=(k+=8191&(s>>>8|(u=255&r[t+14]|(255&r[t+15])<<8)<<8))*(5*R),l=c+=(y+=(T+=u>>>5|d)*(5*z))>>>13,l+=E*z,l+=x*L,l+=M*(5*G),l+=m*(5*I),c=(l+=B*(5*F))>>>13,l&=8191,l+=S*(5*C),l+=K*(5*O),l+=Y*(5*N),l+=k*(5*P),c+=(l+=T*(5*R))>>>13,l&=8191,v=c,v+=E*R,v+=x*z,v+=M*L,v+=m*(5*G),c=(v+=B*(5*I))>>>13,v&=8191,v+=S*(5*F),v+=K*(5*C),v+=Y*(5*O),v+=k*(5*N),w=c+=(v+=T*(5*P))>>>13,w+=E*P,w+=x*R,w+=M*z,w+=m*L,c=(w+=B*(5*G))>>>13,w&=8191,w+=S*(5*I),w+=K*(5*F),w+=Y*(5*C),w+=k*(5*O),p=c+=(w+=T*(5*N))>>>13,p+=E*N,p+=x*P,p+=M*R,p+=m*z,c=(p+=B*L)>>>13,p&=8191,p+=S*(5*G),p+=K*(5*I),p+=Y*(5*F),p+=k*(5*C),b=c+=(p+=T*(5*O))>>>13,b+=E*O,b+=x*N,b+=M*P,b+=m*R,c=(b+=B*z)>>>13,b&=8191,b+=S*L,b+=K*(5*G),b+=Y*(5*I),b+=k*(5*F),g=c+=(b+=T*(5*C))>>>13,g+=E*C,g+=x*O,g+=M*N,g+=m*P,c=(g+=B*R)>>>13,g&=8191,g+=S*z,g+=K*L,g+=Y*(5*G),g+=k*(5*I),_=c+=(g+=T*(5*F))>>>13,_+=E*F,_+=x*C,_+=M*O,_+=m*N,c=(_+=B*P)>>>13,_&=8191,_+=S*R,_+=K*z,_+=Y*L,_+=k*(5*G),A=c+=(_+=T*(5*I))>>>13,A+=E*I,A+=x*F,A+=M*C,A+=m*O,c=(A+=B*N)>>>13,A&=8191,A+=S*P,A+=K*R,A+=Y*z,A+=k*L,U=c+=(A+=T*(5*G))>>>13,U+=E*G,U+=x*I,U+=M*F,U+=m*C,c=(U+=B*O)>>>13,U&=8191,U+=S*N,U+=K*P,U+=Y*R,U+=k*z,E=y=8191&(c=(c=((c+=(U+=T*L)>>>13)<<2)+c|0)+(y&=8191)|0),x=l+=c>>>=13,M=v&=8191,m=w&=8191,B=p&=8191,S=b&=8191,K=g&=8191,Y=_&=8191,k=A&=8191,T=U&=8191,t+=16,n-=16;this.h[0]=E,this.h[1]=x,this.h[2]=M,this.h[3]=m,this.h[4]=B,this.h[5]=S,this.h[6]=K,this.h[7]=Y,this.h[8]=k,this.h[9]=T},x.prototype.finish=function(r,t){var n,e,o,i,h=new Uint16Array(10);if(this.leftover){for(i=this.leftover,this.buffer[i++]=1;i<16;i++)this.buffer[i]=0;this.fin=1,this.blocks(this.buffer,0,16)}for(n=this.h[1]>>>13,this.h[1]&=8191,i=2;i<10;i++)this.h[i]+=n,n=this.h[i]>>>13,this.h[i]&=8191;for(this.h[0]+=5*n,n=this.h[0]>>>13,this.h[0]&=8191,this.h[1]+=n,n=this.h[1]>>>13,this.h[1]&=8191,this.h[2]+=n,h[0]=this.h[0]+5,n=h[0]>>>13,h[0]&=8191,i=1;i<10;i++)h[i]=this.h[i]+n,n=h[i]>>>13,h[i]&=8191;for(h[9]-=8192,e=(1^n)-1,i=0;i<10;i++)h[i]&=e;for(e=~e,i=0;i<10;i++)this.h[i]=this.h[i]&e|h[i];for(this.h[0]=65535&(this.h[0]|this.h[1]<<13),this.h[1]=65535&(this.h[1]>>>3|this.h[2]<<10),this.h[2]=65535&(this.h[2]>>>6|this.h[3]<<7),this.h[3]=65535&(this.h[3]>>>9|this.h[4]<<4),this.h[4]=65535&(this.h[4]>>>12|this.h[5]<<1|this.h[6]<<14),this.h[5]=65535&(this.h[6]>>>2|this.h[7]<<11),this.h[6]=65535&(this.h[7]>>>5|this.h[8]<<8),this.h[7]=65535&(this.h[8]>>>8|this.h[9]<<5),o=this.h[0]+this.pad[0],this.h[0]=65535&o,i=1;i<8;i++)o=(this.h[i]+this.pad[i]|0)+(o>>>16)|0,this.h[i]=65535&o;r[t+0]=this.h[0]>>>0&255,r[t+1]=this.h[0]>>>8&255,r[t+2]=this.h[1]>>>0&255,r[t+3]=this.h[1]>>>8&255,r[t+4]=this.h[2]>>>0&255,r[t+5]=this.h[2]>>>8&255,r[t+6]=this.h[3]>>>0&255,r[t+7]=this.h[3]>>>8&255,r[t+8]=this.h[4]>>>0&255,r[t+9]=this.h[4]>>>8&255,r[t+10]=this.h[5]>>>0&255,r[t+11]=this.h[5]>>>8&255,r[t+12]=this.h[6]>>>0&255,r[t+13]=this.h[6]>>>8&255,r[t+14]=this.h[7]>>>0&255,r[t+15]=this.h[7]>>>8&255},x.prototype.update=function(r,t,n){var e,o;if(this.leftover){for((o=16-this.leftover)>n&&(o=n),e=0;e<o;e++)this.buffer[this.leftover+e]=r[t+e];if(n-=o,t+=o,this.leftover+=o,this.leftover<16)return;this.blocks(this.buffer,0,16),this.leftover=0}if(n>=16&&(o=n-n%16,this.blocks(r,t,o),t+=o,n-=o),n){for(e=0;e<n;e++)this.buffer[this.leftover+e]=r[t+e];this.leftover+=n}};var V=B,X=S;var D=[1116352408,3609767458,1899447441,602891725,3049323471,3964484399,3921009573,2173295548,961987163,4081628472,1508970993,3053834265,2453635748,2937671579,2870763221,3664609560,3624381080,2734883394,310598401,1164996542,607225278,1323610764,1426881987,3590304994,1925078388,4068182383,2162078206,991336113,2614888103,633803317,3248222580,3479774868,3835390401,2666613458,4022224774,944711139,264347078,2341262773,604807628,2007800933,770255983,1495990901,1249150122,1856431235,1555081692,3175218132,1996064986,2198950837,2554220882,3999719339,2821834349,766784016,2952996808,2566594879,3210313671,3203337956,3336571891,1034457026,3584528711,2466948901,113926993,3758326383,338241895,168717936,666307205,1188179964,773529912,1546045734,1294757372,1522805485,1396182291,2643833823,1695183700,2343527390,1986661051,1014477480,2177026350,1206759142,2456956037,344077627,2730485921,1290863460,2820302411,3158454273,3259730800,3505952657,3345764771,106217008,3516065817,3606008344,3600352804,1432725776,4094571909,1467031594,275423344,851169720,430227734,3100823752,506948616,1363258195,659060556,3750685593,883997877,3785050280,958139571,3318307427,1322822218,3812723403,1537002063,2003034995,1747873779,3602036899,1955562222,1575990012,2024104815,1125592928,2227730452,2716904306,2361852424,442776044,2428436474,593698344,2756734187,3733110249,3204031479,2999351573,3329325298,3815920427,3391569614,3928383900,3515267271,566280711,3940187606,3454069534,4118630271,4000239992,116418474,1914138554,174292421,2731055270,289380356,3203993006,460393269,320620315,685471733,587496836,852142971,1086792851,1017036298,365543100,1126000580,2618297676,1288033470,3409855158,1501505948,4234509866,1607167915,987167468,1816402316,1246189591];function j(r,t,n,e){for(var o,i,h,a,f,s,u,c,y,l,v,w,p,b,g,_,A,U,d,E,x,M,m,B,S,K,Y=new Int32Array(16),k=new Int32Array(16),T=r[0],L=r[1],z=r[2],R=r[3],P=r[4],N=r[5],O=r[6],C=r[7],F=t[0],I=t[1],G=t[2],Z=t[3],q=t[4],V=t[5],X=t[6],j=t[7],H=0;e>=128;){for(d=0;d<16;d++)E=8*d+H,Y[d]=n[E+0]<<24|n[E+1]<<16|n[E+2]<<8|n[E+3],k[d]=n[E+4]<<24|n[E+5]<<16|n[E+6]<<8|n[E+7];for(d=0;d<80;d++)if(o=T,i=L,h=z,a=R,f=P,s=N,u=O,C,y=F,l=I,v=G,w=Z,p=q,b=V,g=X,j,m=65535&(M=j),B=M>>>16,S=65535&(x=C),K=x>>>16,m+=65535&(M=(q>>>14|P<<18)^(q>>>18|P<<14)^(P>>>9|q<<23)),B+=M>>>16,S+=65535&(x=(P>>>14|q<<18)^(P>>>18|q<<14)^(q>>>9|P<<23)),K+=x>>>16,m+=65535&(M=q&V^~q&X),B+=M>>>16,S+=65535&(x=P&N^~P&O),K+=x>>>16,x=D[2*d],m+=65535&(M=D[2*d+1]),B+=M>>>16,S+=65535&x,K+=x>>>16,x=Y[d%16],B+=(M=k[d%16])>>>16,S+=65535&x,K+=x>>>16,S+=(B+=(m+=65535&M)>>>16)>>>16,m=65535&(M=U=65535&m|B<<16),B=M>>>16,S=65535&(x=A=65535&S|(K+=S>>>16)<<16),K=x>>>16,m+=65535&(M=(F>>>28|T<<4)^(T>>>2|F<<30)^(T>>>7|F<<25)),B+=M>>>16,S+=65535&(x=(T>>>28|F<<4)^(F>>>2|T<<30)^(F>>>7|T<<25)),K+=x>>>16,B+=(M=F&I^F&G^I&G)>>>16,S+=65535&(x=T&L^T&z^L&z),K+=x>>>16,c=65535&(S+=(B+=(m+=65535&M)>>>16)>>>16)|(K+=S>>>16)<<16,_=65535&m|B<<16,m=65535&(M=w),B=M>>>16,S=65535&(x=a),K=x>>>16,B+=(M=U)>>>16,S+=65535&(x=A),K+=x>>>16,L=o,z=i,R=h,P=a=65535&(S+=(B+=(m+=65535&M)>>>16)>>>16)|(K+=S>>>16)<<16,N=f,O=s,C=u,T=c,I=y,G=l,Z=v,q=w=65535&m|B<<16,V=p,X=b,j=g,F=_,d%16==15)for(E=0;E<16;E++)x=Y[E],m=65535&(M=k[E]),B=M>>>16,S=65535&x,K=x>>>16,x=Y[(E+9)%16],m+=65535&(M=k[(E+9)%16]),B+=M>>>16,S+=65535&x,K+=x>>>16,A=Y[(E+1)%16],m+=65535&(M=((U=k[(E+1)%16])>>>1|A<<31)^(U>>>8|A<<24)^(U>>>7|A<<25)),B+=M>>>16,S+=65535&(x=(A>>>1|U<<31)^(A>>>8|U<<24)^A>>>7),K+=x>>>16,A=Y[(E+14)%16],B+=(M=((U=k[(E+14)%16])>>>19|A<<13)^(A>>>29|U<<3)^(U>>>6|A<<26))>>>16,S+=65535&(x=(A>>>19|U<<13)^(U>>>29|A<<3)^A>>>6),K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,Y[E]=65535&S|K<<16,k[E]=65535&m|B<<16;m=65535&(M=F),B=M>>>16,S=65535&(x=T),K=x>>>16,x=r[0],B+=(M=t[0])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[0]=T=65535&S|K<<16,t[0]=F=65535&m|B<<16,m=65535&(M=I),B=M>>>16,S=65535&(x=L),K=x>>>16,x=r[1],B+=(M=t[1])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[1]=L=65535&S|K<<16,t[1]=I=65535&m|B<<16,m=65535&(M=G),B=M>>>16,S=65535&(x=z),K=x>>>16,x=r[2],B+=(M=t[2])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[2]=z=65535&S|K<<16,t[2]=G=65535&m|B<<16,m=65535&(M=Z),B=M>>>16,S=65535&(x=R),K=x>>>16,x=r[3],B+=(M=t[3])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[3]=R=65535&S|K<<16,t[3]=Z=65535&m|B<<16,m=65535&(M=q),B=M>>>16,S=65535&(x=P),K=x>>>16,x=r[4],B+=(M=t[4])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[4]=P=65535&S|K<<16,t[4]=q=65535&m|B<<16,m=65535&(M=V),B=M>>>16,S=65535&(x=N),K=x>>>16,x=r[5],B+=(M=t[5])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[5]=N=65535&S|K<<16,t[5]=V=65535&m|B<<16,m=65535&(M=X),B=M>>>16,S=65535&(x=O),K=x>>>16,x=r[6],B+=(M=t[6])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[6]=O=65535&S|K<<16,t[6]=X=65535&m|B<<16,m=65535&(M=j),B=M>>>16,S=65535&(x=C),K=x>>>16,x=r[7],B+=(M=t[7])>>>16,S+=65535&x,K+=x>>>16,K+=(S+=(B+=(m+=65535&M)>>>16)>>>16)>>>16,r[7]=C=65535&S|K<<16,t[7]=j=65535&m|B<<16,H+=128,e-=128}return e}function H(r,t,n){var e,o=new Int32Array(8),i=new Int32Array(8),h=new Uint8Array(256),a=n;for(o[0]=1779033703,o[1]=3144134277,o[2]=1013904242,o[3]=2773480762,o[4]=1359893119,o[5]=2600822924,o[6]=528734635,o[7]=1541459225,i[0]=4089235720,i[1]=2227873595,i[2]=4271175723,i[3]=1595750129,i[4]=2917565137,i[5]=725511199,i[6]=4215389547,i[7]=327033209,j(o,i,t,n),n%=128,e=0;e<n;e++)h[e]=t[a-n+e];for(h[n]=128,h[(n=256-128*(n<112?1:0))-9]=0,l(h,n-8,a/536870912|0,a<<3),j(o,i,h,n),e=0;e<8;e++)l(r,8*e,o[e],i[e]);return 0}function J(r,n){var e=t(),o=t(),i=t(),h=t(),a=t(),f=t(),u=t(),c=t(),y=t();N(e,r[1],r[0]),N(y,n[1],n[0]),O(e,e,y),P(o,r[0],r[1]),P(y,n[0],n[1]),O(o,o,y),O(i,r[3],n[3]),O(i,i,s),O(h,r[2],n[2]),P(h,h,h),N(a,o,e),N(f,h,i),P(u,h,i),P(c,o,e),O(r[0],a,f),O(r[1],c,u),O(r[2],u,f),O(r[3],a,c)}function Q(r,t,n){var e;for(e=0;e<4;e++)k(r[e],t[e],n)}function W(r,n){var e=t(),o=t(),i=t();F(i,n[2]),O(e,n[0],i),O(o,n[1],i),T(r,o),r[31]^=z(e)<<7}function $(r,t,n){var e,o;for(K(r[0],i),K(r[1],h),K(r[2],h),K(r[3],i),o=255;o>=0;--o)Q(r,t,e=n[o/8|0]>>(7&o)&1),J(t,r),J(r,r),Q(r,t,e)}function rr(r,n){var e=[t(),t(),t(),t()];K(e[0],u),K(e[1],c),K(e[2],h),O(e[3],u,c),$(r,e,n)}function tr(r,e,o){var i,h=new Uint8Array(64),a=[t(),t(),t(),t()];for(o||n(e,32),H(h,e,32),h[0]&=248,h[31]&=127,h[31]|=64,rr(a,h),W(r,a),i=0;i<32;i++)e[i+32]=r[i];return 0}var nr=new Float64Array([237,211,245,92,26,99,18,88,214,156,247,162,222,249,222,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16]);function er(r,t){var n,e,o,i;for(e=63;e>=32;--e){for(n=0,o=e-32,i=e-12;o<i;++o)t[o]+=n-16*t[e]*nr[o-(e-32)],n=t[o]+128>>8,t[o]-=256*n;t[o]+=n,t[e]=0}for(n=0,o=0;o<32;o++)t[o]+=n-(t[31]>>4)*nr[o],n=t[o]>>8,t[o]&=255;for(o=0;o<32;o++)t[o]-=n*nr[o];for(e=0;e<32;e++)t[e+1]+=t[e]>>8,r[e]=255&t[e]}function or(r){var t,n=new Float64Array(64);for(t=0;t<64;t++)n[t]=r[t];for(t=0;t<64;t++)r[t]=0;er(r,n)}function ir(r,n,e,o){var i,h,a=new Uint8Array(64),f=new Uint8Array(64),s=new Uint8Array(64),u=new Float64Array(64),c=[t(),t(),t(),t()];H(a,o,32),a[0]&=248,a[31]&=127,a[31]|=64;var y=e+64;for(i=0;i<e;i++)r[64+i]=n[i];for(i=0;i<32;i++)r[32+i]=a[32+i];for(H(s,r.subarray(32),e+32),or(s),rr(c,s),W(r,c),i=32;i<64;i++)r[i]=o[i];for(H(f,r,e+64),or(f),i=0;i<64;i++)u[i]=0;for(i=0;i<32;i++)u[i]=s[i];for(i=0;i<32;i++)for(h=0;h<32;h++)u[i+h]+=f[i]*a[h];return er(r.subarray(32),u),y}function hr(r,n){var e=t(),o=t(),a=t(),s=t(),u=t(),c=t(),l=t();return K(r[2],h),R(r[1],n),C(a,r[1]),O(s,a,f),N(a,a,r[2]),P(s,r[2],s),C(u,s),C(c,u),O(l,c,u),O(e,l,a),O(e,e,s),function(r,n){var e,o=t();for(e=0;e<16;e++)o[e]=n[e];for(e=250;e>=0;e--)C(o,o),1!==e&&O(o,o,n);for(e=0;e<16;e++)r[e]=o[e]}(e,e),O(e,e,a),O(e,e,s),O(e,e,s),O(r[0],e,s),C(o,r[0]),O(o,o,s),L(o,a)&&O(r[0],r[0],y),C(o,r[0]),O(o,o,s),L(o,a)?-1:(z(r[0])===n[31]>>7&&N(r[0],i,r[0]),O(r[3],r[0],r[1]),0)}function ar(r,n,e,o){var i,h=new Uint8Array(32),a=new Uint8Array(64),f=[t(),t(),t(),t()],s=[t(),t(),t(),t()];if(-1,e<64)return-1;if(hr(s,o))return-1;for(i=0;i<e;i++)r[i]=n[i];for(i=0;i<32;i++)r[i+32]=o[i];if(H(a,r,e),or(a),$(f,s,a),rr(s,n.subarray(32)),J(f,s),W(h,f),e-=64,p(n,0,h,0)){for(i=0;i<e;i++)r[i]=0;return-1}for(i=0;i<e;i++)r[i]=n[i+64];return e}var fr=32,sr=24,ur=32,cr=32,yr=sr;function lr(r,t){if(r.length!==fr)throw new Error("bad key size");if(t.length!==sr)throw new Error("bad nonce size")}function vr(){for(var r=0;r<arguments.length;r++)if(!(arguments[r]instanceof Uint8Array))throw new TypeError("unexpected type, use Uint8Array")}function wr(r){for(var t=0;t<r.length;t++)r[t]=0}r.lowlevel={crypto_core_hsalsa20:g,crypto_stream_xor:E,crypto_stream:d,crypto_stream_salsa20_xor:A,crypto_stream_salsa20:U,crypto_onetimeauth:M,crypto_onetimeauth_verify:m,crypto_verify_16:w,crypto_verify_32:p,crypto_secretbox:B,crypto_secretbox_open:S,crypto_scalarmult:I,crypto_scalarmult_base:G,crypto_box_beforenm:q,crypto_box_afternm:V,crypto_box:function(r,t,n,e,o,i){var h=new Uint8Array(32);return q(h,o,i),V(r,t,n,e,h)},crypto_box_open:function(r,t,n,e,o,i){var h=new Uint8Array(32);return q(h,o,i),X(r,t,n,e,h)},crypto_box_keypair:Z,crypto_hash:H,crypto_sign:ir,crypto_sign_keypair:tr,crypto_sign_open:ar,crypto_secretbox_KEYBYTES:fr,crypto_secretbox_NONCEBYTES:sr,crypto_secretbox_ZEROBYTES:32,crypto_secretbox_BOXZEROBYTES:16,crypto_scalarmult_BYTES:32,crypto_scalarmult_SCALARBYTES:32,crypto_box_PUBLICKEYBYTES:ur,crypto_box_SECRETKEYBYTES:cr,crypto_box_BEFORENMBYTES:32,crypto_box_NONCEBYTES:yr,crypto_box_ZEROBYTES:32,crypto_box_BOXZEROBYTES:16,crypto_sign_BYTES:64,crypto_sign_PUBLICKEYBYTES:32,crypto_sign_SECRETKEYBYTES:64,crypto_sign_SEEDBYTES:32,crypto_hash_BYTES:64},r.randomBytes=function(r){var t=new Uint8Array(r);return n(t,r),t},r.secretbox=function(r,t,n){vr(r,t,n),lr(n,t);for(var e=new Uint8Array(32+r.length),o=new Uint8Array(e.length),i=0;i<r.length;i++)e[i+32]=r[i];return B(o,e,e.length,t,n),o.subarray(16)},r.secretbox.open=function(r,t,n){vr(r,t,n),lr(n,t);for(var e=new Uint8Array(16+r.length),o=new Uint8Array(e.length),i=0;i<r.length;i++)e[i+16]=r[i];return e.length<32?null:0!==S(o,e,e.length,t,n)?null:o.subarray(32)},r.secretbox.keyLength=fr,r.secretbox.nonceLength=sr,r.secretbox.overheadLength=16,r.scalarMult=function(r,t){if(vr(r,t),32!==r.length)throw new Error("bad n size");if(32!==t.length)throw new Error("bad p size");var n=new Uint8Array(32);return I(n,r,t),n},r.scalarMult.base=function(r){if(vr(r),32!==r.length)throw new Error("bad n size");var t=new Uint8Array(32);return G(t,r),t},r.scalarMult.scalarLength=32,r.scalarMult.groupElementLength=32,r.box=function(t,n,e,o){var i=r.box.before(e,o);return r.secretbox(t,n,i)},r.box.before=function(r,t){vr(r,t),function(r,t){if(r.length!==ur)throw new Error("bad public key size");if(t.length!==cr)throw new Error("bad secret key size")}(r,t);var n=new Uint8Array(32);return q(n,r,t),n},r.box.after=r.secretbox,r.box.open=function(t,n,e,o){var i=r.box.before(e,o);return r.secretbox.open(t,n,i)},r.box.open.after=r.secretbox.open,r.box.keyPair=function(){var r=new Uint8Array(ur),t=new Uint8Array(cr);return Z(r,t),{publicKey:r,secretKey:t}},r.box.keyPair.fromSecretKey=function(r){if(vr(r),r.length!==cr)throw new Error("bad secret key size");var t=new Uint8Array(ur);return G(t,r),{publicKey:t,secretKey:new Uint8Array(r)}},r.box.publicKeyLength=ur,r.box.secretKeyLength=cr,r.box.sharedKeyLength=32,r.box.nonceLength=yr,r.box.overheadLength=r.secretbox.overheadLength,r.sign=function(r,t){if(vr(r,t),64!==t.length)throw new Error("bad secret key size");var n=new Uint8Array(64+r.length);return ir(n,r,r.length,t),n},r.sign.open=function(r,t){if(vr(r,t),32!==t.length)throw new Error("bad public key size");var n=new Uint8Array(r.length),e=ar(n,r,r.length,t);if(e<0)return null;for(var o=new Uint8Array(e),i=0;i<o.length;i++)o[i]=n[i];return o},r.sign.detached=function(t,n){for(var e=r.sign(t,n),o=new Uint8Array(64),i=0;i<o.length;i++)o[i]=e[i];return o},r.sign.detached.verify=function(r,t,n){if(vr(r,t,n),64!==t.length)throw new Error("bad signature size");if(32!==n.length)throw new Error("bad public key size");var e,o=new Uint8Array(64+r.length),i=new Uint8Array(64+r.length);for(e=0;e<64;e++)o[e]=t[e];for(e=0;e<r.length;e++)o[e+64]=r[e];return ar(i,o,o.length,n)>=0},r.sign.keyPair=function(){var r=new Uint8Array(32),t=new Uint8Array(64);return tr(r,t),{publicKey:r,secretKey:t}},r.sign.keyPair.fromSecretKey=function(r){if(vr(r),64!==r.length)throw new Error("bad secret key size");for(var t=new Uint8Array(32),n=0;n<t.length;n++)t[n]=r[32+n];return{publicKey:t,secretKey:new Uint8Array(r)}},r.sign.keyPair.fromSeed=function(r){if(vr(r),32!==r.length)throw new Error("bad seed size");for(var t=new Uint8Array(32),n=new Uint8Array(64),e=0;e<32;e++)n[e]=r[e];return tr(t,n,!0),{publicKey:t,secretKey:n}},r.sign.publicKeyLength=32,r.sign.secretKeyLength=64,r.sign.seedLength=32,r.sign.signatureLength=64,r.hash=function(r){vr(r);var t=new Uint8Array(64);return H(t,r,r.length),t},r.hash.hashLength=64,r.verify=function(r,t){return vr(r,t),0!==r.length&&0!==t.length&&(r.length===t.length&&0===v(r,0,t,0,r.length))},r.setPRNG=function(r){n=r},function(){var t="undefined"!=typeof self?self.crypto||self.msCrypto:null;if(t&&t.getRandomValues){r.setPRNG(function(r,n){var e,o=new Uint8Array(n);for(e=0;e<n;e+=65536)t.getRandomValues(o.subarray(e,e+Math.min(n-e,65536)));for(e=0;e<n;e++)r[e]=o[e];wr(o)})}else"undefined"!=typeof require&&(t=require("crypto"))&&t.randomBytes&&r.setPRNG(function(r,n){var e,o=t.randomBytes(n);for(e=0;e<n;e++)r[e]=o[e];wr(o)})}()}("undefined"!=typeof module&&module.exports?module.exports:self.nacl=self.nacl||{});

},{"crypto":18}],63:[function(require,module,exports){
module.exports=require("./lib");

},{"./lib":66}],64:[function(require,module,exports){
var cache=function(e){var n,t=!1;return e instanceof Function||(t=!0,n=e,delete e),function(){return t||(t=!0,n=e.apply(this,arguments),delete e),n}};module.exports=cache;

},{}],65:[function(require,module,exports){
module.exports=function l(e,n,t){if(t||(t=[]),t.length<e.length){var g=e[t.length];for(var h in g)t[t.length]=g[h],l(e,n,t),--t.length}else n.apply(null,t)};

},{}],66:[function(require,module,exports){
module.exports={cache:require("./cache"),eachCombination:require("./eachCombination")};

},{"./cache":64,"./eachCombination":65}],67:[function(require,module,exports){
"use strict";var $protobuf=require("protobufjs/minimal"),$Reader=$protobuf.Reader,$Writer=$protobuf.Writer,$util=$protobuf.util,$root=$protobuf.roots.default||($protobuf.roots.default={});$root.CreateAccountTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.newAccountId="",e.prototype.amount=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.publicKey=$util.newBuffer([]),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.newAccountId&&e.hasOwnProperty("newAccountId")&&n.uint32(26).string(e.newAccountId),null!=e.amount&&e.hasOwnProperty("amount")&&n.uint32(32).uint64(e.amount),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&n.uint32(42).bytes(e.publicKey),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.CreateAccountTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.newAccountId=e.string();break;case 4:o.amount=e.uint64();break;case 5:o.publicKey=e.bytes();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.newAccountId&&e.hasOwnProperty("newAccountId")&&!$util.isString(e.newAccountId)?"newAccountId: string expected":null!=e.amount&&e.hasOwnProperty("amount")&&!($util.isInteger(e.amount)||e.amount&&$util.isInteger(e.amount.low)&&$util.isInteger(e.amount.high))?"amount: integer|Long expected":null!=e.publicKey&&e.hasOwnProperty("publicKey")&&!(e.publicKey&&"number"==typeof e.publicKey.length||$util.isString(e.publicKey))?"publicKey: buffer expected":null},e.fromObject=function(e){if(e instanceof $root.CreateAccountTransaction)return e;var n=new $root.CreateAccountTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.newAccountId&&(n.newAccountId=String(e.newAccountId)),null!=e.amount&&($util.Long?(n.amount=$util.Long.fromValue(e.amount)).unsigned=!0:"string"==typeof e.amount?n.amount=parseInt(e.amount,10):"number"==typeof e.amount?n.amount=e.amount:"object"==typeof e.amount&&(n.amount=new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0))),null!=e.publicKey&&("string"==typeof e.publicKey?$util.base64.decode(e.publicKey,n.publicKey=$util.newBuffer($util.base64.length(e.publicKey)),0):e.publicKey.length&&(n.publicKey=e.publicKey)),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;if(t.originator="",t.newAccountId="",$util.Long){o=new $util.Long(0,0,!0);t.amount=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.amount=n.longs===String?"0":0;n.bytes===String?t.publicKey="":(t.publicKey=[],n.bytes!==Array&&(t.publicKey=$util.newBuffer(t.publicKey)))}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.newAccountId&&e.hasOwnProperty("newAccountId")&&(t.newAccountId=e.newAccountId),null!=e.amount&&e.hasOwnProperty("amount")&&("number"==typeof e.amount?t.amount=n.longs===String?String(e.amount):e.amount:t.amount=n.longs===String?$util.Long.prototype.toString.call(e.amount):n.longs===Number?new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0):e.amount),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&(t.publicKey=n.bytes===String?$util.base64.encode(e.publicKey,0,e.publicKey.length):n.bytes===Array?Array.prototype.slice.call(e.publicKey):e.publicKey),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.DeployContractTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.contractId="",e.prototype.wasmByteArray=$util.newBuffer([]),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.contractId&&e.hasOwnProperty("contractId")&&n.uint32(18).string(e.contractId),null!=e.wasmByteArray&&e.hasOwnProperty("wasmByteArray")&&n.uint32(26).bytes(e.wasmByteArray),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.DeployContractTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.contractId=e.string();break;case 3:o.wasmByteArray=e.bytes();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.contractId&&e.hasOwnProperty("contractId")&&!$util.isString(e.contractId)?"contractId: string expected":null!=e.wasmByteArray&&e.hasOwnProperty("wasmByteArray")&&!(e.wasmByteArray&&"number"==typeof e.wasmByteArray.length||$util.isString(e.wasmByteArray))?"wasmByteArray: buffer expected":null},e.fromObject=function(e){if(e instanceof $root.DeployContractTransaction)return e;var n=new $root.DeployContractTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.contractId&&(n.contractId=String(e.contractId)),null!=e.wasmByteArray&&("string"==typeof e.wasmByteArray?$util.base64.decode(e.wasmByteArray,n.wasmByteArray=$util.newBuffer($util.base64.length(e.wasmByteArray)),0):e.wasmByteArray.length&&(n.wasmByteArray=e.wasmByteArray)),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;t.contractId="",n.bytes===String?t.wasmByteArray="":(t.wasmByteArray=[],n.bytes!==Array&&(t.wasmByteArray=$util.newBuffer(t.wasmByteArray)))}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.contractId&&e.hasOwnProperty("contractId")&&(t.contractId=e.contractId),null!=e.wasmByteArray&&e.hasOwnProperty("wasmByteArray")&&(t.wasmByteArray=n.bytes===String?$util.base64.encode(e.wasmByteArray,0,e.wasmByteArray.length):n.bytes===Array?Array.prototype.slice.call(e.wasmByteArray):e.wasmByteArray),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.FunctionCallTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.contractId="",e.prototype.methodName=$util.newBuffer([]),e.prototype.args=$util.newBuffer([]),e.prototype.amount=$util.Long?$util.Long.fromBits(0,0,!0):0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.contractId&&e.hasOwnProperty("contractId")&&n.uint32(26).string(e.contractId),null!=e.methodName&&e.hasOwnProperty("methodName")&&n.uint32(34).bytes(e.methodName),null!=e.args&&e.hasOwnProperty("args")&&n.uint32(42).bytes(e.args),null!=e.amount&&e.hasOwnProperty("amount")&&n.uint32(48).uint64(e.amount),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.FunctionCallTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.contractId=e.string();break;case 4:o.methodName=e.bytes();break;case 5:o.args=e.bytes();break;case 6:o.amount=e.uint64();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.contractId&&e.hasOwnProperty("contractId")&&!$util.isString(e.contractId)?"contractId: string expected":null!=e.methodName&&e.hasOwnProperty("methodName")&&!(e.methodName&&"number"==typeof e.methodName.length||$util.isString(e.methodName))?"methodName: buffer expected":null!=e.args&&e.hasOwnProperty("args")&&!(e.args&&"number"==typeof e.args.length||$util.isString(e.args))?"args: buffer expected":null!=e.amount&&e.hasOwnProperty("amount")&&!($util.isInteger(e.amount)||e.amount&&$util.isInteger(e.amount.low)&&$util.isInteger(e.amount.high))?"amount: integer|Long expected":null},e.fromObject=function(e){if(e instanceof $root.FunctionCallTransaction)return e;var n=new $root.FunctionCallTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.contractId&&(n.contractId=String(e.contractId)),null!=e.methodName&&("string"==typeof e.methodName?$util.base64.decode(e.methodName,n.methodName=$util.newBuffer($util.base64.length(e.methodName)),0):e.methodName.length&&(n.methodName=e.methodName)),null!=e.args&&("string"==typeof e.args?$util.base64.decode(e.args,n.args=$util.newBuffer($util.base64.length(e.args)),0):e.args.length&&(n.args=e.args)),null!=e.amount&&($util.Long?(n.amount=$util.Long.fromValue(e.amount)).unsigned=!0:"string"==typeof e.amount?n.amount=parseInt(e.amount,10):"number"==typeof e.amount?n.amount=e.amount:"object"==typeof e.amount&&(n.amount=new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0))),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;if(t.originator="",t.contractId="",n.bytes===String?t.methodName="":(t.methodName=[],n.bytes!==Array&&(t.methodName=$util.newBuffer(t.methodName))),n.bytes===String?t.args="":(t.args=[],n.bytes!==Array&&(t.args=$util.newBuffer(t.args))),$util.Long){o=new $util.Long(0,0,!0);t.amount=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.amount=n.longs===String?"0":0}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.contractId&&e.hasOwnProperty("contractId")&&(t.contractId=e.contractId),null!=e.methodName&&e.hasOwnProperty("methodName")&&(t.methodName=n.bytes===String?$util.base64.encode(e.methodName,0,e.methodName.length):n.bytes===Array?Array.prototype.slice.call(e.methodName):e.methodName),null!=e.args&&e.hasOwnProperty("args")&&(t.args=n.bytes===String?$util.base64.encode(e.args,0,e.args.length):n.bytes===Array?Array.prototype.slice.call(e.args):e.args),null!=e.amount&&e.hasOwnProperty("amount")&&("number"==typeof e.amount?t.amount=n.longs===String?String(e.amount):e.amount:t.amount=n.longs===String?$util.Long.prototype.toString.call(e.amount):n.longs===Number?new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0):e.amount),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.SendMoneyTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.receiver="",e.prototype.amount=$util.Long?$util.Long.fromBits(0,0,!0):0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.receiver&&e.hasOwnProperty("receiver")&&n.uint32(26).string(e.receiver),null!=e.amount&&e.hasOwnProperty("amount")&&n.uint32(32).uint64(e.amount),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.SendMoneyTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.receiver=e.string();break;case 4:o.amount=e.uint64();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.receiver&&e.hasOwnProperty("receiver")&&!$util.isString(e.receiver)?"receiver: string expected":null!=e.amount&&e.hasOwnProperty("amount")&&!($util.isInteger(e.amount)||e.amount&&$util.isInteger(e.amount.low)&&$util.isInteger(e.amount.high))?"amount: integer|Long expected":null},e.fromObject=function(e){if(e instanceof $root.SendMoneyTransaction)return e;var n=new $root.SendMoneyTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.receiver&&(n.receiver=String(e.receiver)),null!=e.amount&&($util.Long?(n.amount=$util.Long.fromValue(e.amount)).unsigned=!0:"string"==typeof e.amount?n.amount=parseInt(e.amount,10):"number"==typeof e.amount?n.amount=e.amount:"object"==typeof e.amount&&(n.amount=new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0))),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;if(t.originator="",t.receiver="",$util.Long){o=new $util.Long(0,0,!0);t.amount=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.amount=n.longs===String?"0":0}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.receiver&&e.hasOwnProperty("receiver")&&(t.receiver=e.receiver),null!=e.amount&&e.hasOwnProperty("amount")&&("number"==typeof e.amount?t.amount=n.longs===String?String(e.amount):e.amount:t.amount=n.longs===String?$util.Long.prototype.toString.call(e.amount):n.longs===Number?new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0):e.amount),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.StakeTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.amount=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.publicKey="",e.prototype.blsPublicKey="",e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.amount&&e.hasOwnProperty("amount")&&n.uint32(24).uint64(e.amount),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&n.uint32(34).string(e.publicKey),null!=e.blsPublicKey&&e.hasOwnProperty("blsPublicKey")&&n.uint32(42).string(e.blsPublicKey),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.StakeTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.amount=e.uint64();break;case 4:o.publicKey=e.string();break;case 5:o.blsPublicKey=e.string();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.amount&&e.hasOwnProperty("amount")&&!($util.isInteger(e.amount)||e.amount&&$util.isInteger(e.amount.low)&&$util.isInteger(e.amount.high))?"amount: integer|Long expected":null!=e.publicKey&&e.hasOwnProperty("publicKey")&&!$util.isString(e.publicKey)?"publicKey: string expected":null!=e.blsPublicKey&&e.hasOwnProperty("blsPublicKey")&&!$util.isString(e.blsPublicKey)?"blsPublicKey: string expected":null},e.fromObject=function(e){if(e instanceof $root.StakeTransaction)return e;var n=new $root.StakeTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.amount&&($util.Long?(n.amount=$util.Long.fromValue(e.amount)).unsigned=!0:"string"==typeof e.amount?n.amount=parseInt(e.amount,10):"number"==typeof e.amount?n.amount=e.amount:"object"==typeof e.amount&&(n.amount=new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0))),null!=e.publicKey&&(n.publicKey=String(e.publicKey)),null!=e.blsPublicKey&&(n.blsPublicKey=String(e.blsPublicKey)),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;if(t.originator="",$util.Long){o=new $util.Long(0,0,!0);t.amount=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.amount=n.longs===String?"0":0;t.publicKey="",t.blsPublicKey=""}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.amount&&e.hasOwnProperty("amount")&&("number"==typeof e.amount?t.amount=n.longs===String?String(e.amount):e.amount:t.amount=n.longs===String?$util.Long.prototype.toString.call(e.amount):n.longs===Number?new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0):e.amount),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&(t.publicKey=e.publicKey),null!=e.blsPublicKey&&e.hasOwnProperty("blsPublicKey")&&(t.blsPublicKey=e.blsPublicKey),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.SwapKeyTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.curKey=$util.newBuffer([]),e.prototype.newKey=$util.newBuffer([]),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.curKey&&e.hasOwnProperty("curKey")&&n.uint32(26).bytes(e.curKey),null!=e.newKey&&e.hasOwnProperty("newKey")&&n.uint32(34).bytes(e.newKey),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.SwapKeyTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.curKey=e.bytes();break;case 4:o.newKey=e.bytes();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.curKey&&e.hasOwnProperty("curKey")&&!(e.curKey&&"number"==typeof e.curKey.length||$util.isString(e.curKey))?"curKey: buffer expected":null!=e.newKey&&e.hasOwnProperty("newKey")&&!(e.newKey&&"number"==typeof e.newKey.length||$util.isString(e.newKey))?"newKey: buffer expected":null},e.fromObject=function(e){if(e instanceof $root.SwapKeyTransaction)return e;var n=new $root.SwapKeyTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.curKey&&("string"==typeof e.curKey?$util.base64.decode(e.curKey,n.curKey=$util.newBuffer($util.base64.length(e.curKey)),0):e.curKey.length&&(n.curKey=e.curKey)),null!=e.newKey&&("string"==typeof e.newKey?$util.base64.decode(e.newKey,n.newKey=$util.newBuffer($util.base64.length(e.newKey)),0):e.newKey.length&&(n.newKey=e.newKey)),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;t.originator="",n.bytes===String?t.curKey="":(t.curKey=[],n.bytes!==Array&&(t.curKey=$util.newBuffer(t.curKey))),n.bytes===String?t.newKey="":(t.newKey=[],n.bytes!==Array&&(t.newKey=$util.newBuffer(t.newKey)))}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.curKey&&e.hasOwnProperty("curKey")&&(t.curKey=n.bytes===String?$util.base64.encode(e.curKey,0,e.curKey.length):n.bytes===Array?Array.prototype.slice.call(e.curKey):e.curKey),null!=e.newKey&&e.hasOwnProperty("newKey")&&(t.newKey=n.bytes===String?$util.base64.encode(e.newKey,0,e.newKey.length):n.bytes===Array?Array.prototype.slice.call(e.newKey):e.newKey),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.AddKeyTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.newKey=$util.newBuffer([]),e.prototype.accessKey=null,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.newKey&&e.hasOwnProperty("newKey")&&n.uint32(26).bytes(e.newKey),null!=e.accessKey&&e.hasOwnProperty("accessKey")&&$root.AccessKey.encode(e.accessKey,n.uint32(34).fork()).ldelim(),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.AddKeyTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.newKey=e.bytes();break;case 4:o.accessKey=$root.AccessKey.decode(e,e.uint32());break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){if("object"!=typeof e||null===e)return"object expected";if(null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high)))return"nonce: integer|Long expected";if(null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator))return"originator: string expected";if(null!=e.newKey&&e.hasOwnProperty("newKey")&&!(e.newKey&&"number"==typeof e.newKey.length||$util.isString(e.newKey)))return"newKey: buffer expected";if(null!=e.accessKey&&e.hasOwnProperty("accessKey")){var n=$root.AccessKey.verify(e.accessKey);if(n)return"accessKey."+n}return null},e.fromObject=function(e){if(e instanceof $root.AddKeyTransaction)return e;var n=new $root.AddKeyTransaction;if(null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.newKey&&("string"==typeof e.newKey?$util.base64.decode(e.newKey,n.newKey=$util.newBuffer($util.base64.length(e.newKey)),0):e.newKey.length&&(n.newKey=e.newKey)),null!=e.accessKey){if("object"!=typeof e.accessKey)throw TypeError(".AddKeyTransaction.accessKey: object expected");n.accessKey=$root.AccessKey.fromObject(e.accessKey)}return n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;t.originator="",n.bytes===String?t.newKey="":(t.newKey=[],n.bytes!==Array&&(t.newKey=$util.newBuffer(t.newKey))),t.accessKey=null}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.newKey&&e.hasOwnProperty("newKey")&&(t.newKey=n.bytes===String?$util.base64.encode(e.newKey,0,e.newKey.length):n.bytes===Array?Array.prototype.slice.call(e.newKey):e.newKey),null!=e.accessKey&&e.hasOwnProperty("accessKey")&&(t.accessKey=$root.AccessKey.toObject(e.accessKey,n)),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.DeleteKeyTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.nonce=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.originator="",e.prototype.curKey=$util.newBuffer([]),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.nonce&&e.hasOwnProperty("nonce")&&n.uint32(8).uint64(e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&n.uint32(18).string(e.originator),null!=e.curKey&&e.hasOwnProperty("curKey")&&n.uint32(26).bytes(e.curKey),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.DeleteKeyTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.nonce=e.uint64();break;case 2:o.originator=e.string();break;case 3:o.curKey=e.bytes();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.nonce&&e.hasOwnProperty("nonce")&&!($util.isInteger(e.nonce)||e.nonce&&$util.isInteger(e.nonce.low)&&$util.isInteger(e.nonce.high))?"nonce: integer|Long expected":null!=e.originator&&e.hasOwnProperty("originator")&&!$util.isString(e.originator)?"originator: string expected":null!=e.curKey&&e.hasOwnProperty("curKey")&&!(e.curKey&&"number"==typeof e.curKey.length||$util.isString(e.curKey))?"curKey: buffer expected":null},e.fromObject=function(e){if(e instanceof $root.DeleteKeyTransaction)return e;var n=new $root.DeleteKeyTransaction;return null!=e.nonce&&($util.Long?(n.nonce=$util.Long.fromValue(e.nonce)).unsigned=!0:"string"==typeof e.nonce?n.nonce=parseInt(e.nonce,10):"number"==typeof e.nonce?n.nonce=e.nonce:"object"==typeof e.nonce&&(n.nonce=new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0))),null!=e.originator&&(n.originator=String(e.originator)),null!=e.curKey&&("string"==typeof e.curKey?$util.base64.decode(e.curKey,n.curKey=$util.newBuffer($util.base64.length(e.curKey)),0):e.curKey.length&&(n.curKey=e.curKey)),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.nonce=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.nonce=n.longs===String?"0":0;t.originator="",n.bytes===String?t.curKey="":(t.curKey=[],n.bytes!==Array&&(t.curKey=$util.newBuffer(t.curKey)))}return null!=e.nonce&&e.hasOwnProperty("nonce")&&("number"==typeof e.nonce?t.nonce=n.longs===String?String(e.nonce):e.nonce:t.nonce=n.longs===String?$util.Long.prototype.toString.call(e.nonce):n.longs===Number?new $util.LongBits(e.nonce.low>>>0,e.nonce.high>>>0).toNumber(!0):e.nonce),null!=e.originator&&e.hasOwnProperty("originator")&&(t.originator=e.originator),null!=e.curKey&&e.hasOwnProperty("curKey")&&(t.curKey=n.bytes===String?$util.base64.encode(e.curKey,0,e.curKey.length):n.bytes===Array?Array.prototype.slice.call(e.curKey):e.curKey),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.SignedTransaction=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}var n;return e.prototype.signature=$util.newBuffer([]),e.prototype.publicKey=null,e.prototype.createAccount=null,e.prototype.deployContract=null,e.prototype.functionCall=null,e.prototype.sendMoney=null,e.prototype.stake=null,e.prototype.swapKey=null,e.prototype.addKey=null,e.prototype.deleteKey=null,Object.defineProperty(e.prototype,"body",{get:$util.oneOfGetter(n=["createAccount","deployContract","functionCall","sendMoney","stake","swapKey","addKey","deleteKey"]),set:$util.oneOfSetter(n)}),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.signature&&e.hasOwnProperty("signature")&&n.uint32(10).bytes(e.signature),null!=e.createAccount&&e.hasOwnProperty("createAccount")&&$root.CreateAccountTransaction.encode(e.createAccount,n.uint32(18).fork()).ldelim(),null!=e.deployContract&&e.hasOwnProperty("deployContract")&&$root.DeployContractTransaction.encode(e.deployContract,n.uint32(26).fork()).ldelim(),null!=e.functionCall&&e.hasOwnProperty("functionCall")&&$root.FunctionCallTransaction.encode(e.functionCall,n.uint32(34).fork()).ldelim(),null!=e.sendMoney&&e.hasOwnProperty("sendMoney")&&$root.SendMoneyTransaction.encode(e.sendMoney,n.uint32(42).fork()).ldelim(),null!=e.stake&&e.hasOwnProperty("stake")&&$root.StakeTransaction.encode(e.stake,n.uint32(50).fork()).ldelim(),null!=e.swapKey&&e.hasOwnProperty("swapKey")&&$root.SwapKeyTransaction.encode(e.swapKey,n.uint32(58).fork()).ldelim(),null!=e.addKey&&e.hasOwnProperty("addKey")&&$root.AddKeyTransaction.encode(e.addKey,n.uint32(66).fork()).ldelim(),null!=e.deleteKey&&e.hasOwnProperty("deleteKey")&&$root.DeleteKeyTransaction.encode(e.deleteKey,n.uint32(74).fork()).ldelim(),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&$root.google.protobuf.BytesValue.encode(e.publicKey,n.uint32(82).fork()).ldelim(),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.SignedTransaction;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.signature=e.bytes();break;case 10:o.publicKey=$root.google.protobuf.BytesValue.decode(e,e.uint32());break;case 2:o.createAccount=$root.CreateAccountTransaction.decode(e,e.uint32());break;case 3:o.deployContract=$root.DeployContractTransaction.decode(e,e.uint32());break;case 4:o.functionCall=$root.FunctionCallTransaction.decode(e,e.uint32());break;case 5:o.sendMoney=$root.SendMoneyTransaction.decode(e,e.uint32());break;case 6:o.stake=$root.StakeTransaction.decode(e,e.uint32());break;case 7:o.swapKey=$root.SwapKeyTransaction.decode(e,e.uint32());break;case 8:o.addKey=$root.AddKeyTransaction.decode(e,e.uint32());break;case 9:o.deleteKey=$root.DeleteKeyTransaction.decode(e,e.uint32());break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){if("object"!=typeof e||null===e)return"object expected";var n={};if(null!=e.signature&&e.hasOwnProperty("signature")&&!(e.signature&&"number"==typeof e.signature.length||$util.isString(e.signature)))return"signature: buffer expected";if(null!=e.publicKey&&e.hasOwnProperty("publicKey")&&(t=$root.google.protobuf.BytesValue.verify(e.publicKey)))return"publicKey."+t;if(null!=e.createAccount&&e.hasOwnProperty("createAccount")&&(n.body=1,t=$root.CreateAccountTransaction.verify(e.createAccount)))return"createAccount."+t;if(null!=e.deployContract&&e.hasOwnProperty("deployContract")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.DeployContractTransaction.verify(e.deployContract))return"deployContract."+t}if(null!=e.functionCall&&e.hasOwnProperty("functionCall")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.FunctionCallTransaction.verify(e.functionCall))return"functionCall."+t}if(null!=e.sendMoney&&e.hasOwnProperty("sendMoney")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.SendMoneyTransaction.verify(e.sendMoney))return"sendMoney."+t}if(null!=e.stake&&e.hasOwnProperty("stake")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.StakeTransaction.verify(e.stake))return"stake."+t}if(null!=e.swapKey&&e.hasOwnProperty("swapKey")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.SwapKeyTransaction.verify(e.swapKey))return"swapKey."+t}if(null!=e.addKey&&e.hasOwnProperty("addKey")){if(1===n.body)return"body: multiple values";if(n.body=1,t=$root.AddKeyTransaction.verify(e.addKey))return"addKey."+t}if(null!=e.deleteKey&&e.hasOwnProperty("deleteKey")){if(1===n.body)return"body: multiple values";var t;if(n.body=1,t=$root.DeleteKeyTransaction.verify(e.deleteKey))return"deleteKey."+t}return null},e.fromObject=function(e){if(e instanceof $root.SignedTransaction)return e;var n=new $root.SignedTransaction;if(null!=e.signature&&("string"==typeof e.signature?$util.base64.decode(e.signature,n.signature=$util.newBuffer($util.base64.length(e.signature)),0):e.signature.length&&(n.signature=e.signature)),null!=e.publicKey){if("object"!=typeof e.publicKey)throw TypeError(".SignedTransaction.publicKey: object expected");n.publicKey=$root.google.protobuf.BytesValue.fromObject(e.publicKey)}if(null!=e.createAccount){if("object"!=typeof e.createAccount)throw TypeError(".SignedTransaction.createAccount: object expected");n.createAccount=$root.CreateAccountTransaction.fromObject(e.createAccount)}if(null!=e.deployContract){if("object"!=typeof e.deployContract)throw TypeError(".SignedTransaction.deployContract: object expected");n.deployContract=$root.DeployContractTransaction.fromObject(e.deployContract)}if(null!=e.functionCall){if("object"!=typeof e.functionCall)throw TypeError(".SignedTransaction.functionCall: object expected");n.functionCall=$root.FunctionCallTransaction.fromObject(e.functionCall)}if(null!=e.sendMoney){if("object"!=typeof e.sendMoney)throw TypeError(".SignedTransaction.sendMoney: object expected");n.sendMoney=$root.SendMoneyTransaction.fromObject(e.sendMoney)}if(null!=e.stake){if("object"!=typeof e.stake)throw TypeError(".SignedTransaction.stake: object expected");n.stake=$root.StakeTransaction.fromObject(e.stake)}if(null!=e.swapKey){if("object"!=typeof e.swapKey)throw TypeError(".SignedTransaction.swapKey: object expected");n.swapKey=$root.SwapKeyTransaction.fromObject(e.swapKey)}if(null!=e.addKey){if("object"!=typeof e.addKey)throw TypeError(".SignedTransaction.addKey: object expected");n.addKey=$root.AddKeyTransaction.fromObject(e.addKey)}if(null!=e.deleteKey){if("object"!=typeof e.deleteKey)throw TypeError(".SignedTransaction.deleteKey: object expected");n.deleteKey=$root.DeleteKeyTransaction.fromObject(e.deleteKey)}return n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(n.bytes===String?t.signature="":(t.signature=[],n.bytes!==Array&&(t.signature=$util.newBuffer(t.signature))),t.publicKey=null),null!=e.signature&&e.hasOwnProperty("signature")&&(t.signature=n.bytes===String?$util.base64.encode(e.signature,0,e.signature.length):n.bytes===Array?Array.prototype.slice.call(e.signature):e.signature),null!=e.createAccount&&e.hasOwnProperty("createAccount")&&(t.createAccount=$root.CreateAccountTransaction.toObject(e.createAccount,n),n.oneofs&&(t.body="createAccount")),null!=e.deployContract&&e.hasOwnProperty("deployContract")&&(t.deployContract=$root.DeployContractTransaction.toObject(e.deployContract,n),n.oneofs&&(t.body="deployContract")),null!=e.functionCall&&e.hasOwnProperty("functionCall")&&(t.functionCall=$root.FunctionCallTransaction.toObject(e.functionCall,n),n.oneofs&&(t.body="functionCall")),null!=e.sendMoney&&e.hasOwnProperty("sendMoney")&&(t.sendMoney=$root.SendMoneyTransaction.toObject(e.sendMoney,n),n.oneofs&&(t.body="sendMoney")),null!=e.stake&&e.hasOwnProperty("stake")&&(t.stake=$root.StakeTransaction.toObject(e.stake,n),n.oneofs&&(t.body="stake")),null!=e.swapKey&&e.hasOwnProperty("swapKey")&&(t.swapKey=$root.SwapKeyTransaction.toObject(e.swapKey,n),n.oneofs&&(t.body="swapKey")),null!=e.addKey&&e.hasOwnProperty("addKey")&&(t.addKey=$root.AddKeyTransaction.toObject(e.addKey,n),n.oneofs&&(t.body="addKey")),null!=e.deleteKey&&e.hasOwnProperty("deleteKey")&&(t.deleteKey=$root.DeleteKeyTransaction.toObject(e.deleteKey,n),n.oneofs&&(t.body="deleteKey")),null!=e.publicKey&&e.hasOwnProperty("publicKey")&&(t.publicKey=$root.google.protobuf.BytesValue.toObject(e.publicKey,n)),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),$root.google=function(){var e,n={};return n.protobuf=((e={}).DoubleValue=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(9).double(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.DoubleValue;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.double();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&"number"!=typeof e.value?"value: number expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.DoubleValue)return e;var n=new $root.google.protobuf.DoubleValue;return null!=e.value&&(n.value=Number(e.value)),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=0),null!=e.value&&e.hasOwnProperty("value")&&(t.value=n.json&&!isFinite(e.value)?String(e.value):e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.FloatValue=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(13).float(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.FloatValue;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.float();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&"number"!=typeof e.value?"value: number expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.FloatValue)return e;var n=new $root.google.protobuf.FloatValue;return null!=e.value&&(n.value=Number(e.value)),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=0),null!=e.value&&e.hasOwnProperty("value")&&(t.value=n.json&&!isFinite(e.value)?String(e.value):e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.Int64Value=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=$util.Long?$util.Long.fromBits(0,0,!1):0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(8).int64(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.Int64Value;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.int64();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!($util.isInteger(e.value)||e.value&&$util.isInteger(e.value.low)&&$util.isInteger(e.value.high))?"value: integer|Long expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.Int64Value)return e;var n=new $root.google.protobuf.Int64Value;return null!=e.value&&($util.Long?(n.value=$util.Long.fromValue(e.value)).unsigned=!1:"string"==typeof e.value?n.value=parseInt(e.value,10):"number"==typeof e.value?n.value=e.value:"object"==typeof e.value&&(n.value=new $util.LongBits(e.value.low>>>0,e.value.high>>>0).toNumber())),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults)if($util.Long){var o=new $util.Long(0,0,!1);t.value=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.value=n.longs===String?"0":0;return null!=e.value&&e.hasOwnProperty("value")&&("number"==typeof e.value?t.value=n.longs===String?String(e.value):e.value:t.value=n.longs===String?$util.Long.prototype.toString.call(e.value):n.longs===Number?new $util.LongBits(e.value.low>>>0,e.value.high>>>0).toNumber():e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.UInt64Value=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=$util.Long?$util.Long.fromBits(0,0,!0):0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(8).uint64(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.UInt64Value;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.uint64();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!($util.isInteger(e.value)||e.value&&$util.isInteger(e.value.low)&&$util.isInteger(e.value.high))?"value: integer|Long expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.UInt64Value)return e;var n=new $root.google.protobuf.UInt64Value;return null!=e.value&&($util.Long?(n.value=$util.Long.fromValue(e.value)).unsigned=!0:"string"==typeof e.value?n.value=parseInt(e.value,10):"number"==typeof e.value?n.value=e.value:"object"==typeof e.value&&(n.value=new $util.LongBits(e.value.low>>>0,e.value.high>>>0).toNumber(!0))),n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults)if($util.Long){var o=new $util.Long(0,0,!0);t.value=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.value=n.longs===String?"0":0;return null!=e.value&&e.hasOwnProperty("value")&&("number"==typeof e.value?t.value=n.longs===String?String(e.value):e.value:t.value=n.longs===String?$util.Long.prototype.toString.call(e.value):n.longs===Number?new $util.LongBits(e.value.low>>>0,e.value.high>>>0).toNumber(!0):e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.Int32Value=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(8).int32(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.Int32Value;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.int32();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!$util.isInteger(e.value)?"value: integer expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.Int32Value)return e;var n=new $root.google.protobuf.Int32Value;return null!=e.value&&(n.value=0|e.value),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=0),null!=e.value&&e.hasOwnProperty("value")&&(t.value=e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.UInt32Value=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=0,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(8).uint32(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.UInt32Value;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.uint32();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!$util.isInteger(e.value)?"value: integer expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.UInt32Value)return e;var n=new $root.google.protobuf.UInt32Value;return null!=e.value&&(n.value=e.value>>>0),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=0),null!=e.value&&e.hasOwnProperty("value")&&(t.value=e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.BoolValue=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=!1,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(8).bool(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.BoolValue;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.bool();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&"boolean"!=typeof e.value?"value: boolean expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.BoolValue)return e;var n=new $root.google.protobuf.BoolValue;return null!=e.value&&(n.value=Boolean(e.value)),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=!1),null!=e.value&&e.hasOwnProperty("value")&&(t.value=e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.StringValue=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value="",e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(10).string(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.StringValue;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.string();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!$util.isString(e.value)?"value: string expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.StringValue)return e;var n=new $root.google.protobuf.StringValue;return null!=e.value&&(n.value=String(e.value)),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(t.value=""),null!=e.value&&e.hasOwnProperty("value")&&(t.value=e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e.BytesValue=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.value=$util.newBuffer([]),e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.value&&e.hasOwnProperty("value")&&n.uint32(10).bytes(e.value),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.google.protobuf.BytesValue;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.value=e.bytes();break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){return"object"!=typeof e||null===e?"object expected":null!=e.value&&e.hasOwnProperty("value")&&!(e.value&&"number"==typeof e.value.length||$util.isString(e.value))?"value: buffer expected":null},e.fromObject=function(e){if(e instanceof $root.google.protobuf.BytesValue)return e;var n=new $root.google.protobuf.BytesValue;return null!=e.value&&("string"==typeof e.value?$util.base64.decode(e.value,n.value=$util.newBuffer($util.base64.length(e.value)),0):e.value.length&&(n.value=e.value)),n},e.toObject=function(e,n){n||(n={});var t={};return n.defaults&&(n.bytes===String?t.value="":(t.value=[],n.bytes!==Array&&(t.value=$util.newBuffer(t.value)))),null!=e.value&&e.hasOwnProperty("value")&&(t.value=n.bytes===String?$util.base64.encode(e.value,0,e.value.length):n.bytes===Array?Array.prototype.slice.call(e.value):e.value),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),e),n}(),$root.AccessKey=function(){function e(e){if(e)for(var n=Object.keys(e),t=0;t<n.length;++t)null!=e[n[t]]&&(this[n[t]]=e[n[t]])}return e.prototype.amount=$util.Long?$util.Long.fromBits(0,0,!0):0,e.prototype.balanceOwner=null,e.prototype.contractId=null,e.prototype.methodName=null,e.create=function(n){return new e(n)},e.encode=function(e,n){return n||(n=$Writer.create()),null!=e.amount&&e.hasOwnProperty("amount")&&n.uint32(8).uint64(e.amount),null!=e.balanceOwner&&e.hasOwnProperty("balanceOwner")&&$root.google.protobuf.StringValue.encode(e.balanceOwner,n.uint32(18).fork()).ldelim(),null!=e.contractId&&e.hasOwnProperty("contractId")&&$root.google.protobuf.StringValue.encode(e.contractId,n.uint32(26).fork()).ldelim(),null!=e.methodName&&e.hasOwnProperty("methodName")&&$root.google.protobuf.BytesValue.encode(e.methodName,n.uint32(34).fork()).ldelim(),n},e.encodeDelimited=function(e,n){return this.encode(e,n).ldelim()},e.decode=function(e,n){e instanceof $Reader||(e=$Reader.create(e));for(var t=void 0===n?e.len:e.pos+n,o=new $root.AccessKey;e.pos<t;){var r=e.uint32();switch(r>>>3){case 1:o.amount=e.uint64();break;case 2:o.balanceOwner=$root.google.protobuf.StringValue.decode(e,e.uint32());break;case 3:o.contractId=$root.google.protobuf.StringValue.decode(e,e.uint32());break;case 4:o.methodName=$root.google.protobuf.BytesValue.decode(e,e.uint32());break;default:e.skipType(7&r)}}return o},e.decodeDelimited=function(e){return e instanceof $Reader||(e=new $Reader(e)),this.decode(e,e.uint32())},e.verify=function(e){if("object"!=typeof e||null===e)return"object expected";if(null!=e.amount&&e.hasOwnProperty("amount")&&!($util.isInteger(e.amount)||e.amount&&$util.isInteger(e.amount.low)&&$util.isInteger(e.amount.high)))return"amount: integer|Long expected";var n;if(null!=e.balanceOwner&&e.hasOwnProperty("balanceOwner")&&(n=$root.google.protobuf.StringValue.verify(e.balanceOwner)))return"balanceOwner."+n;if(null!=e.contractId&&e.hasOwnProperty("contractId")&&(n=$root.google.protobuf.StringValue.verify(e.contractId)))return"contractId."+n;if(null!=e.methodName&&e.hasOwnProperty("methodName")&&(n=$root.google.protobuf.BytesValue.verify(e.methodName)))return"methodName."+n;return null},e.fromObject=function(e){if(e instanceof $root.AccessKey)return e;var n=new $root.AccessKey;if(null!=e.amount&&($util.Long?(n.amount=$util.Long.fromValue(e.amount)).unsigned=!0:"string"==typeof e.amount?n.amount=parseInt(e.amount,10):"number"==typeof e.amount?n.amount=e.amount:"object"==typeof e.amount&&(n.amount=new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0))),null!=e.balanceOwner){if("object"!=typeof e.balanceOwner)throw TypeError(".AccessKey.balanceOwner: object expected");n.balanceOwner=$root.google.protobuf.StringValue.fromObject(e.balanceOwner)}if(null!=e.contractId){if("object"!=typeof e.contractId)throw TypeError(".AccessKey.contractId: object expected");n.contractId=$root.google.protobuf.StringValue.fromObject(e.contractId)}if(null!=e.methodName){if("object"!=typeof e.methodName)throw TypeError(".AccessKey.methodName: object expected");n.methodName=$root.google.protobuf.BytesValue.fromObject(e.methodName)}return n},e.toObject=function(e,n){n||(n={});var t={};if(n.defaults){if($util.Long){var o=new $util.Long(0,0,!0);t.amount=n.longs===String?o.toString():n.longs===Number?o.toNumber():o}else t.amount=n.longs===String?"0":0;t.balanceOwner=null,t.contractId=null,t.methodName=null}return null!=e.amount&&e.hasOwnProperty("amount")&&("number"==typeof e.amount?t.amount=n.longs===String?String(e.amount):e.amount:t.amount=n.longs===String?$util.Long.prototype.toString.call(e.amount):n.longs===Number?new $util.LongBits(e.amount.low>>>0,e.amount.high>>>0).toNumber(!0):e.amount),null!=e.balanceOwner&&e.hasOwnProperty("balanceOwner")&&(t.balanceOwner=$root.google.protobuf.StringValue.toObject(e.balanceOwner,n)),null!=e.contractId&&e.hasOwnProperty("contractId")&&(t.contractId=$root.google.protobuf.StringValue.toObject(e.contractId,n)),null!=e.methodName&&e.hasOwnProperty("methodName")&&(t.methodName=$root.google.protobuf.BytesValue.toObject(e.methodName,n)),t},e.prototype.toJSON=function(){return this.constructor.toObject(this,$protobuf.util.toJSONOptions)},e}(),module.exports=$root;

},{"protobufjs/minimal":46}],68:[function(require,module,exports){
const KeyPair=require("./key_pair");class AccountInfo{constructor(e,t,n){this.accountId=e,this.keyPair=t,this.networkId=n}static fromJson(e){if(!(e.public_key&&e.secret_key&&e.account_id&&e.network_id))throw'Invalid account info format. Please ensure it contains public_key, secret_key, and account_id".';return new AccountInfo(e.account_id,new KeyPair(e.public_key,e.secret_key),e.network_id)}toJSON(){return{account_id:this.accountId,public_key:this.keyPair.getPublicKey(),secret_key:this.keyPair.getSecretKey(),network_id:this.networkId}}downloadAsFile(){const e=this.keyFileName,t=JSON.stringify(this.toJSON());var n=document.createElement("a");n.setAttribute("href","data:text/plain;charset=utf-8,"+encodeURIComponent(t)),n.setAttribute("download",e),n.style.display="none",document.body.appendChild(n),n.click(),document.body.removeChild(n)}get keyFileName(){return this.networkId+"_"+this.accountId}}module.exports=AccountInfo;

},{"./key_pair":71}],69:[function(require,module,exports){
const KeyPair=require("./key_pair"),AccountInfo=require("./account_info"),LOCAL_STORAGE_SECRET_KEY_SUFFIX="_secretkey",LOCAL_STORAGE_PUBLIC_KEY_SUFFIX="_publickey";class BrowserLocalStorageKeystore{constructor(e="unknown",t=window.localStorage){this.networkId=e,this.localStorage=t}static storageKeyForPublicKey(e){return e+"_"+this.networkId+LOCAL_STORAGE_PUBLIC_KEY_SUFFIX}static storageKeyForSecretKey(e){return e+"_"+this.networkId+LOCAL_STORAGE_SECRET_KEY_SUFFIX}async setKey(e,t){this.localStorage.setItem(BrowserLocalStorageKeystore.storageKeyForPublicKey(e),t.getPublicKey()),this.localStorage.setItem(BrowserLocalStorageKeystore.storageKeyForSecretKey(e),t.getSecretKey())}async setKeyFromJson(e){const t=AccountInfo.fromJson(e);if(this.networkId!=t.networkId)throw new Error("Setting key for a wrong network");this.setKey(t.accountId,t.keyPair)}async getKey(e){const t=this.localStorage.getItem(BrowserLocalStorageKeystore.storageKeyForPublicKey(e)),r=this.localStorage.getItem(BrowserLocalStorageKeystore.storageKeyForSecretKey(e));return t&&r?new KeyPair(t,r):null}static getAccounts(){return Object.keys(this.localStorage).map(function(e){if(e.endsWith("_public"))return e.substr(0,e.length()-7)})}}module.exports=BrowserLocalStorageKeystore;

},{"./account_info":68,"./key_pair":71}],70:[function(require,module,exports){
class InMemoryKeyStore{constructor(e){this.networkId=e,this.keys={}}async setKey(e,s){this.keys[e+"_"+this.networkId]=s}async getKey(e){return this.keys[e+"_"+this.networkId]}async clear(){this.keys={}}}module.exports=InMemoryKeyStore;

},{}],71:[function(require,module,exports){
(function (Buffer){
const bs58=require("bs58"),nacl=require("tweetnacl");class KeyPair{constructor(e,r){this.publicKey=e,this.secretKey=r}getPublicKey(){return this.publicKey}getSecretKey(){return this.secretKey}static fromRandomSeed(){let e=nacl.sign.keyPair();return new KeyPair(KeyPair.encodeBufferInBs58(e.publicKey),KeyPair.encodeBufferInBs58(e.secretKey))}static encodeBufferInBs58(e){const r=Buffer.from(e);return bs58.encode(r)}}module.exports=KeyPair;

}).call(this,require("buffer").Buffer)
},{"bs58":20,"buffer":21,"tweetnacl":62}],72:[function(require,module,exports){
const bs58=require("bs58"),nacl=require("tweetnacl"),{sha256:sha256}=require("js-sha256"),{google:google}=require("../protos");class SimpleKeyStoreSigner{constructor(e){this.keyStore=e}async signBuffer(e,r){return this.signHash(new Uint8Array(sha256.array(e)),r)}async signHash(e,r){const t=await this.keyStore.getKey(r);if(!t)throw new Error(`Cannot find key for originator ${r}`);const o=bs58.decode(t.getSecretKey());return{signature:[...nacl.sign.detached(Uint8Array.from(e),o)],publicKey:google.protobuf.BytesValue.create({value:bs58.decode(t.getPublicKey())})}}}module.exports=SimpleKeyStoreSigner;

},{"../protos":67,"bs58":20,"js-sha256":40,"tweetnacl":62}],73:[function(require,module,exports){
const KeyPair=require("./signing/key_pair"),BrowserLocalStorageKeystore=require("./signing/browser_local_storage_key_store"),SimpleKeyStoreSigner=require("./signing/simple_key_store_signer"),LOGIN_WALLET_URL_SUFFIX="/login_v2/",LOCAL_STORAGE_KEY_SUFFIX="_wallet_access_key";class WalletAccessKey{constructor(t,e="https://wallet.nearprotocol.com",a=null){this._walletBaseUrl=e,this._authDataKey=t+LOCAL_STORAGE_KEY_SUFFIX,this._signer=a||new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore),this._authData=JSON.parse(window.localStorage.getItem(this._authDataKey)||"{}"),this.isSignedIn()||this._tryInitFromUrl()}isSignedIn(){return!!this._authData.accountId}getAccountId(){return this._authData.accountId||""}requestSignIn(t,e,a,s){this._authData.key=KeyPair.fromRandomSeed();const r=new URL(window.location.href);let i=new URL(this._walletBaseUrl+LOGIN_WALLET_URL_SUFFIX);i.searchParams.set("title",e),i.searchParams.set("contract_id",t),i.searchParams.set("public_key",this._authData.key.getPublicKey()),i.searchParams.set("success_url",a||r.href),i.searchParams.set("failure_url",s||r.href),i.searchParams.set("app_url",r.origin),window.location.replace(i.toString())}signOut(){this._authData.accountId&&(this._signer.keyStore.setKey(this.getAccountId(),null).catch(console.error),this._authData={},window.localStorage.removeItem(this._authDataKey))}_saveAuthData(){window.localStorage.setItem(this._authDataKey,JSON.stringify(this._authData))}_tryInitFromUrl(){if(this._authData.key){let t=new URL(window.location.href),e=t.searchParams.get("public_key")||"",a=t.searchParams.get("account_id")||"";a&&e===this._authData.key.getPublicKey()&&(this._signer.keyStore.setKey(a,this._authData.key),this._authData={accountId:a,publicKey:e},this._saveAuthData())}}async signBuffer(t,e){if(!this.isSignedIn()||e!==this.getAccountId())throw"Unauthorized account_id "+e;return await this._signer.signBuffer(t,e)}}module.exports=WalletAccessKey;

},{"./signing/browser_local_storage_key_store":69,"./signing/key_pair":71,"./signing/simple_key_store_signer":72}],74:[function(require,module,exports){
(function (Buffer){
const{sha256:sha256}=require("js-sha256"),{FunctionCallTransaction:FunctionCallTransaction}=require("./protos"),EMBED_WALLET_URL_SUFFIX="/embed/",LOGIN_WALLET_URL_SUFFIX="/login/",RANDOM_ALPHABET="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789",REQUEST_ID_LENGTH=32,LOCAL_STORAGE_KEY_SUFFIX="_wallet_auth_key";class WalletAccount{constructor(t,e="https://wallet.nearprotocol.com"){this._walletBaseUrl=e,this._authDataKey=t+LOCAL_STORAGE_KEY_SUFFIX,this._initHtmlElements(),this._signatureRequests={},this._authData=JSON.parse(window.localStorage.getItem(this._authDataKey)||"{}"),this.isSignedIn()||this._tryInitFromUrl()}isSignedIn(){return!!this._authData.accountId}getAccountId(){return this._authData.accountId||""}requestSignIn(t,e,a,s){const r=new URL(window.location.href);let n=new URL(this._walletBaseUrl+LOGIN_WALLET_URL_SUFFIX);n.searchParams.set("title",e),n.searchParams.set("contract_id",t),n.searchParams.set("success_url",a||r.href),n.searchParams.set("failure_url",s||r.href),n.searchParams.set("app_url",r.origin),window.location.replace(n.toString())}signOut(){this._authData={},window.localStorage.removeItem(this._authDataKey)}_tryInitFromUrl(){let t=new URL(window.location.href),e=t.searchParams.get("auth_token")||"",a=t.searchParams.get("account_id")||"";e&&a&&(this._authData={authToken:e,accountId:a},window.localStorage.setItem(this._authDataKey,JSON.stringify(this._authData)))}_initHtmlElements(){const t=document.createElement("iframe");t.style="display: none;",t.src=this._walletBaseUrl+EMBED_WALLET_URL_SUFFIX,document.body.appendChild(t),this._walletWindow=t.contentWindow,window.addEventListener("message",this.receiveMessage.bind(this),!1)}receiveMessage(t){if(!this._walletBaseUrl.startsWith(t.origin))return void console.log("Wallet account ignoring message from "+t.origin);let e;try{e=JSON.parse(t.data)}catch(e){return void console.error("Can't parse the result",t.data,e)}const a=e.request_id||"";if(!(a in this._signatureRequests))return void console.error("Request ID"+a+" was not found");let s=this._signatureRequests[a];delete this._signatureRequests[a],e.success?s.resolve(e.result):s.reject(e.error)}_randomRequestId(){for(var t="",e=0;e<REQUEST_ID_LENGTH;e++)t+=RANDOM_ALPHABET.charAt(Math.floor(Math.random()*RANDOM_ALPHABET.length));return t}_remoteSign(t,e,a){return new Promise((s,r)=>{const n=this._randomRequestId();this._signatureRequests[n]={request_id:n,resolve:s,reject:r},this._walletWindow.postMessage(JSON.stringify({action:"sign_transaction",token:this._authData.authToken,method_name:e,args:a||{},hash:t,request_id:n}),this._walletBaseUrl)})}async signBuffer(t,e){if(!this.isSignedIn()||e!==this.getAccountId())throw"Unauthorized account_id "+e;const a=FunctionCallTransaction.decode(t);let s=Buffer.from(a.methodName).toString(),r=JSON.parse(Buffer.from(a.args).toString());return{signature:await this._remoteSign(sha256.array(t),s,r)}}}module.exports=WalletAccount;

}).call(this,require("buffer").Buffer)
},{"./protos":67,"buffer":21,"js-sha256":40}]},{},[2]);

'''
'''--- nearlib/index.js ---
const Near = require('./near');
const NearClient = require('./nearclient');
const Account = require('./account');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const InMemoryKeyStore = require('./signing/in_memory_key_store');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const LocalNodeConnection = require('./local_node_connection');
const KeyPair = require('./signing/key_pair');
const WalletAccount = require('./wallet-account');
const UnencryptedFileSystemKeyStore = require('./signing/unencrypted_file_system_keystore');
const dev = require('./dev');
const AccountInfo = require('./signing/account_info');
const WalletAccessKey = require('./wallet-access-key');

module.exports = { Near, NearClient, Account, SimpleKeyStoreSigner, InMemoryKeyStore, BrowserLocalStorageKeystore, LocalNodeConnection, KeyPair, WalletAccount, UnencryptedFileSystemKeyStore, dev, AccountInfo, WalletAccessKey };

'''
'''--- nearlib/internal/send-json.js ---
let fetch = (typeof window === 'undefined' || window.name == 'nodejs') ? require('node-fetch') : window.fetch;

const createError = require('http-errors');

module.exports = async function sendJson(method, url, json) {
    const response = await fetch(url, {
        method: method,
        body: method != 'GET' ? JSON.stringify(json) : undefined,
        headers: { 'Content-type': 'application/json; charset=utf-8' }
    });
    if (!response.ok) {
        throw createError(response.status, await response.text());
    }
    if (response.status === 204) {
        // No Content
        return null;
    }
    return await response.json();
};

'''
'''--- nearlib/local_node_connection.js ---
const sendJson = require('./internal/send-json');

class LocalNodeConnection {
    constructor (baseUrl) {
        this.baseUrl = baseUrl;
    }

    async request(methodName, params) {
        return await sendJson('POST', `${this.baseUrl}/${methodName}`, params);
    }
}

module.exports = LocalNodeConnection;

'''
'''--- nearlib/near.js ---
const createError = require('http-errors');

const NearClient = require('./nearclient');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');
const LocalNodeConnection = require('./local_node_connection');
const {
    DeployContractTransaction, FunctionCallTransaction, SignedTransaction
} = require('./protos');

const MAX_STATUS_POLL_ATTEMPTS = 10;
const STATUS_POLL_PERIOD_MS = 2000;

/**
 * Javascript library for interacting with near.
 */
class Near {
    /**
     * Constructs near with an instance of nearclient.
     * @constructor
     * @param {NearClient} nearClient
     * @example
     * const nearClient = new nearlib.NearClient(
     *   walletAccount, 
     *   new nearlib.LocalNodeConnection(config.nodeUrl));
     * const near = new nearlib.Near(nearClient);
     */
    constructor(nearClient) {
        this.nearClient = nearClient;
    }

    /**
     * Generate a default configuration for nearlib
     * @param {string} nodeUrl url of the near node to connect to
     * @example
     * Near.createDefaultConfig();
     */
    static createDefaultConfig(nodeUrl = 'http://localhost:3030') {
        return new Near(new NearClient(
            new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore()),
            new LocalNodeConnection(nodeUrl)
        ));
    }

    /**
     * Calls a view function. Returns the same value that the function returns.
     * @param {string} contractAccountId account id of the contract
     * @param {string} methodName method to call
     * @param {object} args arguments to pass to the method
     * @example
     * const viewFunctionResponse = await near.callViewFunction(
     *   contractAccountId, 
     *   methodName, 
     *   args);
     */
    async callViewFunction(contractAccountId, methodName, args) {
        return this.nearClient.callViewFunction(contractAccountId, methodName, args);
    }

    /**
     * Schedules an asynchronous function call. Returns a hash which can be used to
     * check the status of the transaction later.
     * @param {number} amount amount of tokens to transfer as part of the operation
     * @param {string} sender account id of the sender
     * @param {string} contractAccountId account id of the contract
     * @param {string} methodName method to call
     * @param {object} args arguments to pass to the method
     * @example
     * const scheduleResult = await near.scheduleFunctionCall(
     *     0,
     *     aliceAccountName,
     *     contractName,
     *     'setValue', // this is the function defined in a wasm file that we are calling
     *     setArgs);
     */
    async scheduleFunctionCall(amount, originator, contractId, methodName, args) {
        if (!args) {
            args = {};
        }
        methodName = new Uint8Array(Buffer.from(methodName));
        args = new Uint8Array(Buffer.from(JSON.stringify(args)));
        const nonce = await this.nearClient.getNonce(originator);
        const functionCall = FunctionCallTransaction.create({
            nonce,
            originator,
            contractId,
            methodName,
            args,
        });
        // Integers with value of 0 must be omitted
        // https://github.com/dcodeIO/protobuf.js/issues/1138
        if (amount !== 0) {
            functionCall.amount = amount;
        }

        const buffer = FunctionCallTransaction.encode(functionCall).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            originator,
        );

        const signedTransaction = SignedTransaction.create({
            functionCall,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return await this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Deploys a smart contract to the block chain
     * @param {string} contractAccountId account id of the contract
     * @param {Uint8Array} wasmArray wasm binary
     * @example
     * const response =  await nearjs.deployContract(contractName, data);
     */
    async deployContract(contractId, wasmByteArray) {
        const nonce = await this.nearClient.getNonce(contractId);

        const deployContract = DeployContractTransaction.create({
            nonce,
            contractId,
            wasmByteArray,
        });

        const buffer = DeployContractTransaction.encode(deployContract).finish();
        const signatureAndPublicKey = await this.nearClient.signer.signBuffer(
            buffer,
            contractId,
        );

        const signedTransaction = SignedTransaction.create({
            deployContract,
            signature: signatureAndPublicKey.signature,
            publicKey: signatureAndPublicKey.publicKey,
        });
        return await this.nearClient.submitTransaction(signedTransaction);
    }

    /**
     * Get a status of a single transaction identified by the transaction hash.
     * @param {string} transactionHash unique identifier of the transaction
     * @example
     * // get the result of a transaction status call
     * const result = await this.getTransactionStatus(transactionHash)
     */
    async getTransactionStatus(transactionHash) {
        return this.nearClient.getTransactionStatus(transactionHash);
    }

    /**
     * Wait until transaction is completed or failed.
     * Automatically sends logs from contract to `console.log`.
     *
     * {@link MAX_STATUS_POLL_ATTEMPTS} defines how many attempts are made.
     * {@link STATUS_POLL_PERIOD_MS} defines delay between subsequent {@link getTransactionStatus} calls.
     *
     * @param {string | object} transactionResponseOrHash hash of transaction or object returned from {@link submitTransaction}
     * @param {object} options object used to pass named parameters
     * @param {string} options.contractAccountId specifies contract ID for better logs and error messages
     * @example
     * const result = await this.waitForTransactionResult(transactionHash);
     */
    async waitForTransactionResult(transactionResponseOrHash, options = {}) {
        const transactionHash = transactionResponseOrHash.hasOwnProperty('hash') ? transactionResponseOrHash.hash : transactionResponseOrHash;
        const contractAccountId = options.contractAccountId || 'unknown contract';
        let alreadyDisplayedLogs = [];
        let result;
        for (let i = 0; i < MAX_STATUS_POLL_ATTEMPTS; i++) {
            await sleep(STATUS_POLL_PERIOD_MS);
            result = (await this.getTransactionStatus(transactionHash));
            let j;
            for (j = 0; j < alreadyDisplayedLogs.length && alreadyDisplayedLogs[j] == result.logs[j]; j++);
            if (j != alreadyDisplayedLogs.length) {
                console.warn('new logs:', result.logs, 'iconsistent with already displayed logs:', alreadyDisplayedLogs);
            }
            for (; j < result.logs.length; ++j) {
                const line = result.logs[j];
                console.log(`[${contractAccountId}]: ${line}`);
                alreadyDisplayedLogs.push(line);
            }
            if (result.status == 'Completed') {
                if (result.value) {
                    result.lastResult = JSON.parse(Buffer.from(result.value, 'base64').toString());
                }
                return result;
            }
            if (result.status == 'Failed') {
                const errorMessage = result.logs.find(it => it.startsWith('ABORT:')) || '';
                const hash = Buffer.from(transactionHash).toString('base64');
                throw createError(400, `Transaction ${hash} on ${contractAccountId} failed. ${errorMessage}`);
            }
        }
        throw createError(408, `Exceeded ${MAX_STATUS_POLL_ATTEMPTS} status check attempts ` +
            `for transaction ${transactionHash} on ${contractAccountId} with status: ${result.status}`);
    }

    /**
     * Load given contract and expose it's methods.
     *
     * Every method is taking named arguments as JS object, e.g.:
     * `{ paramName1: "val1", paramName2: 123 }`
     *
     * View method returns promise which is resolved to result when it's available.
     * State change method returns promise which is resolved when state change is succesful and rejected otherwise.
     *
     * Note that `options` param is only needed temporary while contract introspection capabilities are missing.
     *
     * @param {string} contractAccountId contract account name
     * @param {object} options object used to pass named parameters
     * @param {string} options.sender account name of user which is sending transactions
     * @param {string[]} options.viewMethods list of view methods to load (which don't change state)
     * @param {string[]} options.changeMethods list of methods to load that change state
     * @returns {object} object with methods corresponding to given contract methods.
     * @example
     * // this example would be a counter app with a contract that contains the incrementCounter and decrementCounter methods
     * window.contract = await near.loadContract(config.contractName, {
     *   viewMethods: ["getCounter"],
     *   changeMethods: ["incrementCounter", "decrementCounter"],
     *   sender: nearlib.dev.myAccountId
     * });
     */
    async loadContract(contractAccountId, options) {
        // TODO: Move this to account context to avoid options.sender
        let contract = {};
        let near = this;
        options.viewMethods.forEach((methodName) => {
            contract[methodName] = async function (args) {
                args = args || {};
                return near.callViewFunction(contractAccountId, methodName, args);
            };
        });
        options.changeMethods.forEach((methodName) => {
            contract[methodName] = async function (args) {
                args = args || {};
                const response = await near.scheduleFunctionCall(0, options.sender, contractAccountId, methodName, args);
                return near.waitForTransactionResult(response.hash, { contractAccountId });
            };
        });
        return contract;
    }
}

function sleep(time) {
    return new Promise(function (resolve) {
        setTimeout(resolve, time);
    });
}

module.exports = Near;

'''
'''--- nearlib/nearclient.js ---
const { SignedTransaction } = require('./protos');

/**
 * Client for communicating with near blockchain. 
 */

function _arrayBufferToBase64(buffer) {
    return Buffer.from(buffer).toString('base64');
}

function _base64ToBuffer(str) {
    return new Buffer.from(str, 'base64');
}

class NearClient {
    constructor(signer, nearConnection) {
        this.signer = signer;
        this.nearConnection = nearConnection;
    }

    async viewAccount(accountId) {
        const response = await this.jsonRpcRequest('abci_query', [`account/${accountId}`, '', '0', false]);
        return JSON.parse(_base64ToBuffer(response.response.value).toString());
    }

    async submitTransaction(signedTransaction) {
        const buffer = SignedTransaction.encode(signedTransaction).finish();
        const transaction = _arrayBufferToBase64(buffer);
        const params = [transaction];
        const response = await this.jsonRpcRequest('broadcast_tx_async', params);
        response.hash = Buffer.from(response.hash, 'hex');
        return response;
    }

    async callViewFunction(contractAccountId, methodName, args) {
        if (!args) {
            args = {};
        }
        const serializedArgs = Buffer.from(JSON.stringify(args)).toString('hex');
        const result = await this.jsonRpcRequest('abci_query', [`call/${contractAccountId}/${methodName}`, serializedArgs, '0', false]);
        const response = result.response;
        let logs = [];
        if (response.log !== undefined && response.log.length > 0) {
            logs = response.log.split('\n');
        }
        logs.forEach(line => {
            console.log(`[${contractAccountId}]: ${line}`);
        });
        // If error, raise exception after printing logs.
        const code = response.code || 0;
        if (code != 0) {
            throw Error(response.info);
        }
        const json = JSON.parse(_base64ToBuffer(response.value).toString());
        return json;
    }

    async getTransactionStatus(transactionHash) {
        const encodedHash = _arrayBufferToBase64(transactionHash);
        const response = await this.jsonRpcRequest('tx', [encodedHash, false]);
        // tx_result has default values: code = 0, logs: '', data: ''.
        const codes = { 0: 'Completed', 1: 'Failed', 2: 'Started' };
        const status = codes[response.tx_result.code || 0] || 'Unknown';
        let logs = [];
        if (response.tx_result !== undefined && response.tx_result.log !== undefined && response.tx_result.log.length > 0) {
            logs = response.tx_result.log.split('\n');
        }
        return { logs, status, value: response.tx_result.data };
    }

    async getNonce(accountId) {
        return (await this.viewAccount(accountId)).nonce + 1;
    }

    async jsonRpcRequest(method, params) {
        const request = {
            jsonrpc: '2.0',
            method,
            params,
            id: Date.now().toString(),
        };
        const response = await this.nearConnection.request('', request);
        if (response.error) {
            throw Error(`Error calling ${method} with ${params}: ${response.error.message}.\nFull response: ${JSON.stringify(response)}`);
        }
        return response.result;
    }

    async request(methodName, params) {
        return this.nearConnection.request(methodName, params);
    }
}

module.exports = NearClient;

'''
'''--- nearlib/package-lock.json ---
{
  "name": "nearlib",
  "version": "0.6.0",
  "lockfileVersion": 1,
  "requires": true,
  "dependencies": {
    "@babel/code-frame": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.0.0.tgz",
      "integrity": "sha512-OfC2uemaknXr87bdLUkWog7nYuliM9Ij5HUcajsVcMCpQrcLmtxRbVFTIqmcSkSeYRBFBRxs2FiUqFJDLdiebA==",
      "dev": true,
      "requires": {
        "@babel/highlight": "^7.0.0"
      }
    },
    "@babel/core": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.2.2.tgz",
      "integrity": "sha512-59vB0RWt09cAct5EIe58+NzGP4TFSD3Bz//2/ELy3ZeTeKF6VTD1AXlH8BGGbCX0PuobZBsIzO7IAI9PH67eKw==",
      "dev": true,
      "requires": {
        "@babel/code-frame": "^7.0.0",
        "@babel/generator": "^7.2.2",
        "@babel/helpers": "^7.2.0",
        "@babel/parser": "^7.2.2",
        "@babel/template": "^7.2.2",
        "@babel/traverse": "^7.2.2",
        "@babel/types": "^7.2.2",
        "convert-source-map": "^1.1.0",
        "debug": "^4.1.0",
        "json5": "^2.1.0",
        "lodash": "^4.17.10",
        "resolve": "^1.3.2",
        "semver": "^5.4.1",
        "source-map": "^0.5.0"
      },
      "dependencies": {
        "@babel/parser": {
          "version": "7.3.1",
          "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.3.1.tgz",
          "integrity": "sha512-ATz6yX/L8LEnC3dtLQnIx4ydcPxhLcoy9Vl6re00zb2w5lG6itY6Vhnr1KFRPq/FHNsgl/gh2mjNN20f9iJTTA==",
          "dev": true
        },
        "debug": {
          "version": "4.1.1",
          "resolved": "https://registry.npmjs.org/debug/-/debug-4.1.1.tgz",
          "integrity": "sha512-pYAIzeRo8J6KPEaJ0VWOh5Pzkbw/RetuzehGM7QRRX5he4fPHx2rdKMB256ehJCkX+XRQm16eZLqLNS8RSZXZw==",
          "dev": true,
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "json5": {
          "version": "2.1.0",
          "resolved": "https://registry.npmjs.org/json5/-/json5-2.1.0.tgz",
          "integrity": "sha512-8Mh9h6xViijj36g7Dxi+Y4S6hNGV96vcJZr/SrlHh1LR/pEn/8j/+qIBbs44YKl69Lrfctp4QD+AdWLTMqEZAQ==",
          "dev": true,
          "requires": {
            "minimist": "^1.2.0"
          }
        },
        "minimist": {
          "version": "1.2.0",
          "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
          "dev": true
        },
        "ms": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
          "dev": true
        },
        "resolve": {
          "version": "1.10.0",
          "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.10.0.tgz",
          "integrity": "sha512-3sUr9aq5OfSg2S9pNtPA9hL1FVEAjvfOC4leW0SNf/mpnaakz2a9femSd6LqAww2RaFctwyf1lCqnTHuF1rxDg==",
          "dev": true,
          "requires": {
            "path-parse": "^1.0.6"
          }
        }
      }
    },
    "@babel/generator": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.3.0.tgz",
      "integrity": "sha512-dZTwMvTgWfhmibq4V9X+LMf6Bgl7zAodRn9PvcPdhlzFMbvUutx74dbEv7Atz3ToeEpevYEJtAwfxq/bDCzHWg==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.3.0",
        "jsesc": "^2.5.1",
        "lodash": "^4.17.10",
        "source-map": "^0.5.0",
        "trim-right": "^1.0.1"
      },
      "dependencies": {
        "jsesc": {
          "version": "2.5.2",
          "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-2.5.2.tgz",
          "integrity": "sha512-OYu7XEzjkCQ3C5Ps3QIZsQfNpqoJyZZA99wd9aWd05NCtC5pWOkShK2mkL6HXQR6/Cy2lbNdPlZBpuQHXE63gA==",
          "dev": true
        }
      }
    },
    "@babel/helper-annotate-as-pure": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-annotate-as-pure/-/helper-annotate-as-pure-7.0.0.tgz",
      "integrity": "sha512-3UYcJUj9kvSLbLbUIfQTqzcy5VX7GRZ/CCDrnOaZorFFM01aXp1+GJwuFGV4NDDoAS+mOUyHcO6UD/RfqOks3Q==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-builder-binary-assignment-operator-visitor": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-builder-binary-assignment-operator-visitor/-/helper-builder-binary-assignment-operator-visitor-7.1.0.tgz",
      "integrity": "sha512-qNSR4jrmJ8M1VMM9tibvyRAHXQs2PmaksQF7c1CGJNipfe3D8p+wgNwgso/P2A2r2mdgBWAXljNWR0QRZAMW8w==",
      "dev": true,
      "requires": {
        "@babel/helper-explode-assignable-expression": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-builder-react-jsx": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-builder-react-jsx/-/helper-builder-react-jsx-7.3.0.tgz",
      "integrity": "sha512-MjA9KgwCuPEkQd9ncSXvSyJ5y+j2sICHyrI0M3L+6fnS4wMSNDc1ARXsbTfbb2cXHn17VisSnU/sHFTCxVxSMw==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.3.0",
        "esutils": "^2.0.0"
      }
    },
    "@babel/helper-call-delegate": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-call-delegate/-/helper-call-delegate-7.1.0.tgz",
      "integrity": "sha512-YEtYZrw3GUK6emQHKthltKNZwszBcHK58Ygcis+gVUrF4/FmTVr5CCqQNSfmvg2y+YDEANyYoaLz/SHsnusCwQ==",
      "dev": true,
      "requires": {
        "@babel/helper-hoist-variables": "^7.0.0",
        "@babel/traverse": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-create-class-features-plugin": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-create-class-features-plugin/-/helper-create-class-features-plugin-7.3.0.tgz",
      "integrity": "sha512-DUsQNS2CGLZZ7I3W3fvh0YpPDd6BuWJlDl+qmZZpABZHza2ErE3LxtEzLJFHFC1ZwtlAXvHhbFYbtM5o5B0WBw==",
      "dev": true,
      "requires": {
        "@babel/helper-function-name": "^7.1.0",
        "@babel/helper-member-expression-to-functions": "^7.0.0",
        "@babel/helper-optimise-call-expression": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-replace-supers": "^7.2.3"
      }
    },
    "@babel/helper-define-map": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-define-map/-/helper-define-map-7.1.0.tgz",
      "integrity": "sha512-yPPcW8dc3gZLN+U1mhYV91QU3n5uTbx7DUdf8NnPbjS0RMwBuHi9Xt2MUgppmNz7CJxTBWsGczTiEp1CSOTPRg==",
      "dev": true,
      "requires": {
        "@babel/helper-function-name": "^7.1.0",
        "@babel/types": "^7.0.0",
        "lodash": "^4.17.10"
      }
    },
    "@babel/helper-explode-assignable-expression": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-explode-assignable-expression/-/helper-explode-assignable-expression-7.1.0.tgz",
      "integrity": "sha512-NRQpfHrJ1msCHtKjbzs9YcMmJZOg6mQMmGRB+hbamEdG5PNpaSm95275VD92DvJKuyl0s2sFiDmMZ+EnnvufqA==",
      "dev": true,
      "requires": {
        "@babel/traverse": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-function-name": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-function-name/-/helper-function-name-7.1.0.tgz",
      "integrity": "sha512-A95XEoCpb3TO+KZzJ4S/5uW5fNe26DjBGqf1o9ucyLyCmi1dXq/B3c8iaWTfBk3VvetUxl16e8tIrd5teOCfGw==",
      "dev": true,
      "requires": {
        "@babel/helper-get-function-arity": "^7.0.0",
        "@babel/template": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-get-function-arity": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-get-function-arity/-/helper-get-function-arity-7.0.0.tgz",
      "integrity": "sha512-r2DbJeg4svYvt3HOS74U4eWKsUAMRH01Z1ds1zx8KNTPtpTL5JAsdFv8BNyOpVqdFhHkkRDIg5B4AsxmkjAlmQ==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-hoist-variables": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-hoist-variables/-/helper-hoist-variables-7.0.0.tgz",
      "integrity": "sha512-Ggv5sldXUeSKsuzLkddtyhyHe2YantsxWKNi7A+7LeD12ExRDWTRk29JCXpaHPAbMaIPZSil7n+lq78WY2VY7w==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-member-expression-to-functions": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-member-expression-to-functions/-/helper-member-expression-to-functions-7.0.0.tgz",
      "integrity": "sha512-avo+lm/QmZlv27Zsi0xEor2fKcqWG56D5ae9dzklpIaY7cQMK5N8VSpaNVPPagiqmy7LrEjK1IWdGMOqPu5csg==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-module-imports": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.0.0.tgz",
      "integrity": "sha512-aP/hlLq01DWNEiDg4Jn23i+CXxW/owM4WpDLFUbpjxe4NS3BhLVZQ5i7E0ZrxuQ/vwekIeciyamgB1UIYxxM6A==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-module-transforms": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.2.2.tgz",
      "integrity": "sha512-YRD7I6Wsv+IHuTPkAmAS4HhY0dkPobgLftHp0cRGZSdrRvmZY8rFvae/GVu3bD00qscuvK3WPHB3YdNpBXUqrA==",
      "dev": true,
      "requires": {
        "@babel/helper-module-imports": "^7.0.0",
        "@babel/helper-simple-access": "^7.1.0",
        "@babel/helper-split-export-declaration": "^7.0.0",
        "@babel/template": "^7.2.2",
        "@babel/types": "^7.2.2",
        "lodash": "^4.17.10"
      }
    },
    "@babel/helper-optimise-call-expression": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-optimise-call-expression/-/helper-optimise-call-expression-7.0.0.tgz",
      "integrity": "sha512-u8nd9NQePYNQV8iPWu/pLLYBqZBa4ZaY1YWRFMuxrid94wKI1QNt67NEZ7GAe5Kc/0LLScbim05xZFWkAdrj9g==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-plugin-utils": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.0.0.tgz",
      "integrity": "sha512-CYAOUCARwExnEixLdB6sDm2dIJ/YgEAKDM1MOeMeZu9Ld/bDgVo8aiWrXwcY7OBh+1Ea2uUcVRcxKk0GJvW7QA==",
      "dev": true
    },
    "@babel/helper-regex": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-regex/-/helper-regex-7.0.0.tgz",
      "integrity": "sha512-TR0/N0NDCcUIUEbqV6dCO+LptmmSQFQ7q70lfcEB4URsjD0E1HzicrwUH+ap6BAQ2jhCX9Q4UqZy4wilujWlkg==",
      "dev": true,
      "requires": {
        "lodash": "^4.17.10"
      }
    },
    "@babel/helper-remap-async-to-generator": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-remap-async-to-generator/-/helper-remap-async-to-generator-7.1.0.tgz",
      "integrity": "sha512-3fOK0L+Fdlg8S5al8u/hWE6vhufGSn0bN09xm2LXMy//REAF8kDCrYoOBKYmA8m5Nom+sV9LyLCwrFynA8/slg==",
      "dev": true,
      "requires": {
        "@babel/helper-annotate-as-pure": "^7.0.0",
        "@babel/helper-wrap-function": "^7.1.0",
        "@babel/template": "^7.1.0",
        "@babel/traverse": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-replace-supers": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/@babel/helper-replace-supers/-/helper-replace-supers-7.2.3.tgz",
      "integrity": "sha512-GyieIznGUfPXPWu0yLS6U55Mz67AZD9cUk0BfirOWlPrXlBcan9Gz+vHGz+cPfuoweZSnPzPIm67VtQM0OWZbA==",
      "dev": true,
      "requires": {
        "@babel/helper-member-expression-to-functions": "^7.0.0",
        "@babel/helper-optimise-call-expression": "^7.0.0",
        "@babel/traverse": "^7.2.3",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-simple-access": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-simple-access/-/helper-simple-access-7.1.0.tgz",
      "integrity": "sha512-Vk+78hNjRbsiu49zAPALxTb+JUQCz1aolpd8osOF16BGnLtseD21nbHgLPGUwrXEurZgiCOUmvs3ExTu4F5x6w==",
      "dev": true,
      "requires": {
        "@babel/template": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-split-export-declaration": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-split-export-declaration/-/helper-split-export-declaration-7.0.0.tgz",
      "integrity": "sha512-MXkOJqva62dfC0w85mEf/LucPPS/1+04nmmRMPEBUB++hiiThQ2zPtX/mEWQ3mtzCEjIJvPY8nuwxXtQeQwUag==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@babel/helper-wrap-function": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-wrap-function/-/helper-wrap-function-7.2.0.tgz",
      "integrity": "sha512-o9fP1BZLLSrYlxYEYyl2aS+Flun5gtjTIG8iln+XuEzQTs0PLagAGSXUcqruJwD5fM48jzIEggCKpIfWTcR7pQ==",
      "dev": true,
      "requires": {
        "@babel/helper-function-name": "^7.1.0",
        "@babel/template": "^7.1.0",
        "@babel/traverse": "^7.1.0",
        "@babel/types": "^7.2.0"
      }
    },
    "@babel/helpers": {
      "version": "7.3.1",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.3.1.tgz",
      "integrity": "sha512-Q82R3jKsVpUV99mgX50gOPCWwco9Ec5Iln/8Vyu4osNIOQgSrd9RFrQeUvmvddFNoLwMyOUWU+5ckioEKpDoGA==",
      "dev": true,
      "requires": {
        "@babel/template": "^7.1.2",
        "@babel/traverse": "^7.1.5",
        "@babel/types": "^7.3.0"
      }
    },
    "@babel/highlight": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/highlight/-/highlight-7.0.0.tgz",
      "integrity": "sha512-UFMC4ZeFC48Tpvj7C8UgLvtkaUuovQX+5xNWrsIoMG8o2z+XFKjKaN9iVmS84dPwVN00W4wPmqvYoZF3EGAsfw==",
      "dev": true,
      "requires": {
        "chalk": "^2.0.0",
        "esutils": "^2.0.2",
        "js-tokens": "^4.0.0"
      },
      "dependencies": {
        "js-tokens": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
          "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
          "dev": true
        }
      }
    },
    "@babel/parser": {
      "version": "7.1.3",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.1.3.tgz",
      "integrity": "sha512-gqmspPZOMW3MIRb9HlrnbZHXI1/KHTOroBwN1NcLL6pWxzqzEKGvRTq0W/PxS45OtQGbaFikSQpkS5zbnsQm2w==",
      "dev": true
    },
    "@babel/plugin-proposal-async-generator-functions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-async-generator-functions/-/plugin-proposal-async-generator-functions-7.2.0.tgz",
      "integrity": "sha512-+Dfo/SCQqrwx48ptLVGLdE39YtWRuKc/Y9I5Fy0P1DDBB9lsAHpjcEJQt+4IifuSOSTLBKJObJqMvaO1pIE8LQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-remap-async-to-generator": "^7.1.0",
        "@babel/plugin-syntax-async-generators": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-class-properties": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-class-properties/-/plugin-proposal-class-properties-7.3.0.tgz",
      "integrity": "sha512-wNHxLkEKTQ2ay0tnsam2z7fGZUi+05ziDJflEt3AZTP3oXLKHJp9HqhfroB/vdMvt3sda9fAbq7FsG8QPDrZBg==",
      "dev": true,
      "requires": {
        "@babel/helper-create-class-features-plugin": "^7.3.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-proposal-decorators": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-decorators/-/plugin-proposal-decorators-7.3.0.tgz",
      "integrity": "sha512-3W/oCUmsO43FmZIqermmq6TKaRSYhmh/vybPfVFwQWdSb8xwki38uAIvknCRzuyHRuYfCYmJzL9or1v0AffPjg==",
      "dev": true,
      "requires": {
        "@babel/helper-create-class-features-plugin": "^7.3.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-decorators": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-do-expressions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-do-expressions/-/plugin-proposal-do-expressions-7.2.0.tgz",
      "integrity": "sha512-2bWN48zQHf/W5T8XvemGQJSi8hzhIo7y4kv/RiA08UcMLQ73lkTknhlaFGf1HjCJzG8FGopgsq6pSe1C+10fPg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-do-expressions": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-export-default-from": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-export-default-from/-/plugin-proposal-export-default-from-7.2.0.tgz",
      "integrity": "sha512-NVfNe7F6nsasG1FnvcFxh2FN0l04ZNe75qTOAVOILWPam0tw9a63RtT/Dab8dPjedZa4fTQaQ83yMMywF9OSug==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-export-default-from": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-export-namespace-from": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-export-namespace-from/-/plugin-proposal-export-namespace-from-7.2.0.tgz",
      "integrity": "sha512-DZUxbHYxQ5fUFIkMEnh75ogEdBLPfL+mQUqrO2hNY2LGm+tqFnxE924+mhAcCOh/8za8AaZsWHbq6bBoS3TAzA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-export-namespace-from": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-function-bind": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-function-bind/-/plugin-proposal-function-bind-7.2.0.tgz",
      "integrity": "sha512-qOFJ/eX1Is78sywwTxDcsntLOdb5ZlHVVqUz5xznq8ldAfOVIyZzp1JE2rzHnaksZIhrqMrwIpQL/qcEprnVbw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-function-bind": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-function-sent": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-function-sent/-/plugin-proposal-function-sent-7.2.0.tgz",
      "integrity": "sha512-qQBDKRSCu1wGJi3jbngs18vrujVQA4F+OkSuIQYRhE6y19jcPzeEIGOc683mCQXDUR3BQCz8JyCupIwv+IRFmA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-wrap-function": "^7.2.0",
        "@babel/plugin-syntax-function-sent": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-json-strings": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-json-strings/-/plugin-proposal-json-strings-7.2.0.tgz",
      "integrity": "sha512-MAFV1CA/YVmYwZG0fBQyXhmj0BHCB5egZHCKWIFVv/XCxAeVGIHfos3SwDck4LvCllENIAg7xMKOG5kH0dzyUg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-json-strings": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-logical-assignment-operators": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-logical-assignment-operators/-/plugin-proposal-logical-assignment-operators-7.2.0.tgz",
      "integrity": "sha512-0w797xwdPXKk0m3Js74hDi0mCTZplIu93MOSfb1ZLd/XFe3abWypx1QknVk0J+ohnsjYpvjH4Gwfo2i3RicB6Q==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-logical-assignment-operators": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-nullish-coalescing-operator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-nullish-coalescing-operator/-/plugin-proposal-nullish-coalescing-operator-7.2.0.tgz",
      "integrity": "sha512-QXj/YjFuFJd68oDvoc1e8aqLr2wz7Kofzvp6Ekd/o7MWZl+nZ0/cpStxND+hlZ7DpRWAp7OmuyT2areZ2V3YUA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-nullish-coalescing-operator": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-numeric-separator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-numeric-separator/-/plugin-proposal-numeric-separator-7.2.0.tgz",
      "integrity": "sha512-DohMOGDrZiMKS7LthjUZNNcWl8TAf5BZDwZAH4wpm55FuJTHgfqPGdibg7rZDmont/8Yg0zA03IgT6XLeP+4sg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-numeric-separator": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-object-rest-spread": {
      "version": "7.3.1",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-object-rest-spread/-/plugin-proposal-object-rest-spread-7.3.1.tgz",
      "integrity": "sha512-Nmmv1+3LqxJu/V5jU9vJmxR/KIRWFk2qLHmbB56yRRRFhlaSuOVXscX3gUmhaKgUhzA3otOHVubbIEVYsZ0eZg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-object-rest-spread": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-optional-catch-binding": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-optional-catch-binding/-/plugin-proposal-optional-catch-binding-7.2.0.tgz",
      "integrity": "sha512-mgYj3jCcxug6KUcX4OBoOJz3CMrwRfQELPQ5560F70YQUBZB7uac9fqaWamKR1iWUzGiK2t0ygzjTScZnVz75g==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-optional-catch-binding": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-optional-chaining": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-optional-chaining/-/plugin-proposal-optional-chaining-7.2.0.tgz",
      "integrity": "sha512-ea3Q6edZC/55wEBVZAEz42v528VulyO0eir+7uky/sT4XRcdkWJcFi1aPtitTlwUzGnECWJNExWww1SStt+yWw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-optional-chaining": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-pipeline-operator": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-pipeline-operator/-/plugin-proposal-pipeline-operator-7.3.0.tgz",
      "integrity": "sha512-izEUzWAz9T1FGewqiRKG+uUFTwO4rJ/7uifPkBbOkxq/p5/pkvYpA0wGW28o8wYzUyxJSk2ERgssqqgqt09PBg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-pipeline-operator": "^7.3.0"
      }
    },
    "@babel/plugin-proposal-throw-expressions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-throw-expressions/-/plugin-proposal-throw-expressions-7.2.0.tgz",
      "integrity": "sha512-adsydM8DQF4i5DLNO4ySAU5VtHTPewOtNBV3u7F4lNMPADFF9bWQ+iDtUUe8+033cYCUz+bFlQdXQJmJOwoLpw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-throw-expressions": "^7.2.0"
      }
    },
    "@babel/plugin-proposal-unicode-property-regex": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-unicode-property-regex/-/plugin-proposal-unicode-property-regex-7.2.0.tgz",
      "integrity": "sha512-LvRVYb7kikuOtIoUeWTkOxQEV1kYvL5B6U3iWEGCzPNRus1MzJweFqORTj+0jkxozkTSYNJozPOddxmqdqsRpw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-regex": "^7.0.0",
        "regexpu-core": "^4.2.0"
      }
    },
    "@babel/plugin-syntax-async-generators": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-async-generators/-/plugin-syntax-async-generators-7.2.0.tgz",
      "integrity": "sha512-1ZrIRBv2t0GSlcwVoQ6VgSLpLgiN/FVQUzt9znxo7v2Ov4jJrs8RY8tv0wvDmFN3qIdMKWrmMMW6yZ0G19MfGg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-decorators": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-decorators/-/plugin-syntax-decorators-7.2.0.tgz",
      "integrity": "sha512-38QdqVoXdHUQfTpZo3rQwqQdWtCn5tMv4uV6r2RMfTqNBuv4ZBhz79SfaQWKTVmxHjeFv/DnXVC/+agHCklYWA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-do-expressions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-do-expressions/-/plugin-syntax-do-expressions-7.2.0.tgz",
      "integrity": "sha512-/u4rJ+XEmZkIhspVuKRS+7WLvm7Dky9j9TvGK5IgId8B3FKir9MG+nQxDZ9xLn10QMBvW58dZ6ABe2juSmARjg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-dynamic-import": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-dynamic-import/-/plugin-syntax-dynamic-import-7.2.0.tgz",
      "integrity": "sha512-mVxuJ0YroI/h/tbFTPGZR8cv6ai+STMKNBq0f8hFxsxWjl94qqhsb+wXbpNMDPU3cfR1TIsVFzU3nXyZMqyK4w==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-export-default-from": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-export-default-from/-/plugin-syntax-export-default-from-7.2.0.tgz",
      "integrity": "sha512-c7nqUnNST97BWPtoe+Ssi+fJukc9P9/JMZ71IOMNQWza2E+Psrd46N6AEvtw6pqK+gt7ChjXyrw4SPDO79f3Lw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-export-namespace-from": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-export-namespace-from/-/plugin-syntax-export-namespace-from-7.2.0.tgz",
      "integrity": "sha512-1zGA3UNch6A+A11nIzBVEaE3DDJbjfB+eLIcf0GGOh/BJr/8NxL3546MGhV/r0RhH4xADFIEso39TKCfEMlsGA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-flow": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-flow/-/plugin-syntax-flow-7.2.0.tgz",
      "integrity": "sha512-r6YMuZDWLtLlu0kqIim5o/3TNRAlWb073HwT3e2nKf9I8IIvOggPrnILYPsrrKilmn/mYEMCf/Z07w3yQJF6dg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-function-bind": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-function-bind/-/plugin-syntax-function-bind-7.2.0.tgz",
      "integrity": "sha512-/WzU1lLU2l0wDfB42Wkg6tahrmtBbiD8C4H6EGSX0M4GAjzN6JiOpq/Uh8G6GSoR6lPMvhjM0MNiV6znj6y/zg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-function-sent": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-function-sent/-/plugin-syntax-function-sent-7.2.0.tgz",
      "integrity": "sha512-2MOVuJ6IMAifp2cf0RFkHQaOvHpbBYyWCvgtF/WVqXhTd7Bgtov8iXVCadLXp2FN1BrI2EFl+JXuwXy0qr3KoQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-import-meta": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-meta/-/plugin-syntax-import-meta-7.2.0.tgz",
      "integrity": "sha512-Hq6kFSZD7+PHkmBN8bCpHR6J8QEoCuEV/B38AIQscYjgMZkGlXB7cHNFzP5jR4RCh5545yP1ujHdmO7hAgKtBA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-json-strings": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-json-strings/-/plugin-syntax-json-strings-7.2.0.tgz",
      "integrity": "sha512-5UGYnMSLRE1dqqZwug+1LISpA403HzlSfsg6P9VXU6TBjcSHeNlw4DxDx7LgpF+iKZoOG/+uzqoRHTdcUpiZNg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-jsx": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-jsx/-/plugin-syntax-jsx-7.2.0.tgz",
      "integrity": "sha512-VyN4QANJkRW6lDBmENzRszvZf3/4AXaj9YR7GwrWeeN9tEBPuXbmDYVU9bYBN0D70zCWVwUy0HWq2553VCb6Hw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-logical-assignment-operators": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-logical-assignment-operators/-/plugin-syntax-logical-assignment-operators-7.2.0.tgz",
      "integrity": "sha512-l/NKSlrnvd73/EL540t9hZhcSo4TULBrIPs9Palju8Oc/A8DXDO+xQf04whfeuZLpi8AuIvCAdpKmmubLN4EfQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-nullish-coalescing-operator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-nullish-coalescing-operator/-/plugin-syntax-nullish-coalescing-operator-7.2.0.tgz",
      "integrity": "sha512-lRCEaKE+LTxDQtgbYajI04ddt6WW0WJq57xqkAZ+s11h4YgfRHhVA/Y2VhfPzzFD4qeLHWg32DMp9HooY4Kqlg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-numeric-separator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-numeric-separator/-/plugin-syntax-numeric-separator-7.2.0.tgz",
      "integrity": "sha512-DroeVNkO/BnGpL2R7+ZNZqW+E24aR/4YWxP3Qb15d6lPU8KDzF8HlIUIRCOJRn4X77/oyW4mJY+7FHfY82NLtQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-object-rest-spread": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-object-rest-spread/-/plugin-syntax-object-rest-spread-7.2.0.tgz",
      "integrity": "sha512-t0JKGgqk2We+9may3t0xDdmneaXmyxq0xieYcKHxIsrJO64n1OiMWNUtc5gQK1PA0NpdCRrtZp4z+IUaKugrSA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-optional-catch-binding": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-catch-binding/-/plugin-syntax-optional-catch-binding-7.2.0.tgz",
      "integrity": "sha512-bDe4xKNhb0LI7IvZHiA13kff0KEfaGX/Hv4lMA9+7TEc63hMNvfKo6ZFpXhKuEp+II/q35Gc4NoMeDZyaUbj9w==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-optional-chaining": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-chaining/-/plugin-syntax-optional-chaining-7.2.0.tgz",
      "integrity": "sha512-HtGCtvp5Uq/jH/WNUPkK6b7rufnCPLLlDAFN7cmACoIjaOOiXxUt3SswU5loHqrhtqTsa/WoLQ1OQ1AGuZqaWA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-pipeline-operator": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-pipeline-operator/-/plugin-syntax-pipeline-operator-7.3.0.tgz",
      "integrity": "sha512-LAa3ZcOAyfPOUDTp0W5EiXGSAFh1vz9sD8yY7sZzWzEkZdIC404pqBP60Yfu9GJDj0ggh+UTQY6EYlIDXVr0/Q==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-syntax-throw-expressions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-throw-expressions/-/plugin-syntax-throw-expressions-7.2.0.tgz",
      "integrity": "sha512-ngwynuqu1Rx0JUS9zxSDuPgW1K8TyVZCi2hHehrL4vyjqE7RGoNHWlZsS7KQT2vw9Yjk4YLa0+KldBXTRdPLRg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-arrow-functions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-arrow-functions/-/plugin-transform-arrow-functions-7.2.0.tgz",
      "integrity": "sha512-ER77Cax1+8/8jCB9fo4Ud161OZzWN5qawi4GusDuRLcDbDG+bIGYY20zb2dfAFdTRGzrfq2xZPvF0R64EHnimg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-async-to-generator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-async-to-generator/-/plugin-transform-async-to-generator-7.2.0.tgz",
      "integrity": "sha512-CEHzg4g5UraReozI9D4fblBYABs7IM6UerAVG7EJVrTLC5keh00aEuLUT+O40+mJCEzaXkYfTCUKIyeDfMOFFQ==",
      "dev": true,
      "requires": {
        "@babel/helper-module-imports": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-remap-async-to-generator": "^7.1.0"
      }
    },
    "@babel/plugin-transform-block-scoped-functions": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-block-scoped-functions/-/plugin-transform-block-scoped-functions-7.2.0.tgz",
      "integrity": "sha512-ntQPR6q1/NKuphly49+QiQiTN0O63uOwjdD6dhIjSWBI5xlrbUFh720TIpzBhpnrLfv2tNH/BXvLIab1+BAI0w==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-block-scoping": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-block-scoping/-/plugin-transform-block-scoping-7.2.0.tgz",
      "integrity": "sha512-vDTgf19ZEV6mx35yiPJe4fS02mPQUUcBNwWQSZFXSzTSbsJFQvHt7DqyS3LK8oOWALFOsJ+8bbqBgkirZteD5Q==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "lodash": "^4.17.10"
      }
    },
    "@babel/plugin-transform-classes": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-classes/-/plugin-transform-classes-7.2.2.tgz",
      "integrity": "sha512-gEZvgTy1VtcDOaQty1l10T3jQmJKlNVxLDCs+3rCVPr6nMkODLELxViq5X9l+rfxbie3XrfrMCYYY6eX3aOcOQ==",
      "dev": true,
      "requires": {
        "@babel/helper-annotate-as-pure": "^7.0.0",
        "@babel/helper-define-map": "^7.1.0",
        "@babel/helper-function-name": "^7.1.0",
        "@babel/helper-optimise-call-expression": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-replace-supers": "^7.1.0",
        "@babel/helper-split-export-declaration": "^7.0.0",
        "globals": "^11.1.0"
      },
      "dependencies": {
        "globals": {
          "version": "11.10.0",
          "resolved": "https://registry.npmjs.org/globals/-/globals-11.10.0.tgz",
          "integrity": "sha512-0GZF1RiPKU97IHUO5TORo9w1PwrH/NBPl+fS7oMLdaTRiYmYbwK4NWoZWrAdd0/abG9R2BU+OiwyQpTpE6pdfQ==",
          "dev": true
        }
      }
    },
    "@babel/plugin-transform-computed-properties": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-computed-properties/-/plugin-transform-computed-properties-7.2.0.tgz",
      "integrity": "sha512-kP/drqTxY6Xt3NNpKiMomfgkNn4o7+vKxK2DDKcBG9sHj51vHqMBGy8wbDS/J4lMxnqs153/T3+DmCEAkC5cpA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-destructuring": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-destructuring/-/plugin-transform-destructuring-7.2.0.tgz",
      "integrity": "sha512-coVO2Ayv7g0qdDbrNiadE4bU7lvCd9H539m2gMknyVjjMdwF/iCOM7R+E8PkntoqLkltO0rk+3axhpp/0v68VQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-dotall-regex": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-dotall-regex/-/plugin-transform-dotall-regex-7.2.0.tgz",
      "integrity": "sha512-sKxnyHfizweTgKZf7XsXu/CNupKhzijptfTM+bozonIuyVrLWVUvYjE2bhuSBML8VQeMxq4Mm63Q9qvcvUcciQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-regex": "^7.0.0",
        "regexpu-core": "^4.1.3"
      }
    },
    "@babel/plugin-transform-duplicate-keys": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-duplicate-keys/-/plugin-transform-duplicate-keys-7.2.0.tgz",
      "integrity": "sha512-q+yuxW4DsTjNceUiTzK0L+AfQ0zD9rWaTLiUqHA8p0gxx7lu1EylenfzjeIWNkPy6e/0VG/Wjw9uf9LueQwLOw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-exponentiation-operator": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-exponentiation-operator/-/plugin-transform-exponentiation-operator-7.2.0.tgz",
      "integrity": "sha512-umh4hR6N7mu4Elq9GG8TOu9M0bakvlsREEC+ialrQN6ABS4oDQ69qJv1VtR3uxlKMCQMCvzk7vr17RHKcjx68A==",
      "dev": true,
      "requires": {
        "@babel/helper-builder-binary-assignment-operator-visitor": "^7.1.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-flow-strip-types": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-flow-strip-types/-/plugin-transform-flow-strip-types-7.2.3.tgz",
      "integrity": "sha512-xnt7UIk9GYZRitqCnsVMjQK1O2eKZwFB3CvvHjf5SGx6K6vr/MScCKQDnf1DxRaj501e3pXjti+inbSXX2ZUoQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-flow": "^7.2.0"
      }
    },
    "@babel/plugin-transform-for-of": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-for-of/-/plugin-transform-for-of-7.2.0.tgz",
      "integrity": "sha512-Kz7Mt0SsV2tQk6jG5bBv5phVbkd0gd27SgYD4hH1aLMJRchM0dzHaXvrWhVZ+WxAlDoAKZ7Uy3jVTW2mKXQ1WQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-function-name": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-function-name/-/plugin-transform-function-name-7.2.0.tgz",
      "integrity": "sha512-kWgksow9lHdvBC2Z4mxTsvc7YdY7w/V6B2vy9cTIPtLEE9NhwoWivaxdNM/S37elu5bqlLP/qOY906LukO9lkQ==",
      "dev": true,
      "requires": {
        "@babel/helper-function-name": "^7.1.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-literals": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-literals/-/plugin-transform-literals-7.2.0.tgz",
      "integrity": "sha512-2ThDhm4lI4oV7fVQ6pNNK+sx+c/GM5/SaML0w/r4ZB7sAneD/piDJtwdKlNckXeyGK7wlwg2E2w33C/Hh+VFCg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-modules-amd": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-amd/-/plugin-transform-modules-amd-7.2.0.tgz",
      "integrity": "sha512-mK2A8ucqz1qhrdqjS9VMIDfIvvT2thrEsIQzbaTdc5QFzhDjQv2CkJJ5f6BXIkgbmaoax3zBr2RyvV/8zeoUZw==",
      "dev": true,
      "requires": {
        "@babel/helper-module-transforms": "^7.1.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-modules-commonjs": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-commonjs/-/plugin-transform-modules-commonjs-7.2.0.tgz",
      "integrity": "sha512-V6y0uaUQrQPXUrmj+hgnks8va2L0zcZymeU7TtWEgdRLNkceafKXEduv7QzgQAE4lT+suwooG9dC7LFhdRAbVQ==",
      "dev": true,
      "requires": {
        "@babel/helper-module-transforms": "^7.1.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-simple-access": "^7.1.0"
      }
    },
    "@babel/plugin-transform-modules-systemjs": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-systemjs/-/plugin-transform-modules-systemjs-7.2.0.tgz",
      "integrity": "sha512-aYJwpAhoK9a+1+O625WIjvMY11wkB/ok0WClVwmeo3mCjcNRjt+/8gHWrB5i+00mUju0gWsBkQnPpdvQ7PImmQ==",
      "dev": true,
      "requires": {
        "@babel/helper-hoist-variables": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-modules-umd": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-umd/-/plugin-transform-modules-umd-7.2.0.tgz",
      "integrity": "sha512-BV3bw6MyUH1iIsGhXlOK6sXhmSarZjtJ/vMiD9dNmpY8QXFFQTj+6v92pcfy1iqa8DeAfJFwoxcrS/TUZda6sw==",
      "dev": true,
      "requires": {
        "@babel/helper-module-transforms": "^7.1.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-named-capturing-groups-regex": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-named-capturing-groups-regex/-/plugin-transform-named-capturing-groups-regex-7.3.0.tgz",
      "integrity": "sha512-NxIoNVhk9ZxS+9lSoAQ/LM0V2UEvARLttEHUrRDGKFaAxOYQcrkN/nLRE+BbbicCAvZPl7wMP0X60HsHE5DtQw==",
      "dev": true,
      "requires": {
        "regexp-tree": "^0.1.0"
      }
    },
    "@babel/plugin-transform-new-target": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-new-target/-/plugin-transform-new-target-7.0.0.tgz",
      "integrity": "sha512-yin069FYjah+LbqfGeTfzIBODex/e++Yfa0rH0fpfam9uTbuEeEOx5GLGr210ggOV77mVRNoeqSYqeuaqSzVSw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-object-super": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-object-super/-/plugin-transform-object-super-7.2.0.tgz",
      "integrity": "sha512-VMyhPYZISFZAqAPVkiYb7dUe2AsVi2/wCT5+wZdsNO31FojQJa9ns40hzZ6U9f50Jlq4w6qwzdBB2uwqZ00ebg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-replace-supers": "^7.1.0"
      }
    },
    "@babel/plugin-transform-parameters": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-parameters/-/plugin-transform-parameters-7.2.0.tgz",
      "integrity": "sha512-kB9+hhUidIgUoBQ0MsxMewhzr8i60nMa2KgeJKQWYrqQpqcBYtnpR+JgkadZVZoaEZ/eKu9mclFaVwhRpLNSzA==",
      "dev": true,
      "requires": {
        "@babel/helper-call-delegate": "^7.1.0",
        "@babel/helper-get-function-arity": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-react-display-name": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-display-name/-/plugin-transform-react-display-name-7.2.0.tgz",
      "integrity": "sha512-Htf/tPa5haZvRMiNSQSFifK12gtr/8vwfr+A9y69uF0QcU77AVu4K7MiHEkTxF7lQoHOL0F9ErqgfNEAKgXj7A==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-react-jsx": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx/-/plugin-transform-react-jsx-7.3.0.tgz",
      "integrity": "sha512-a/+aRb7R06WcKvQLOu4/TpjKOdvVEKRLWFpKcNuHhiREPgGRB4TQJxq07+EZLS8LFVYpfq1a5lDUnuMdcCpBKg==",
      "dev": true,
      "requires": {
        "@babel/helper-builder-react-jsx": "^7.3.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-jsx": "^7.2.0"
      }
    },
    "@babel/plugin-transform-react-jsx-self": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-self/-/plugin-transform-react-jsx-self-7.2.0.tgz",
      "integrity": "sha512-v6S5L/myicZEy+jr6ielB0OR8h+EH/1QFx/YJ7c7Ua+7lqsjj/vW6fD5FR9hB/6y7mGbfT4vAURn3xqBxsUcdg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-jsx": "^7.2.0"
      }
    },
    "@babel/plugin-transform-react-jsx-source": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-source/-/plugin-transform-react-jsx-source-7.2.0.tgz",
      "integrity": "sha512-A32OkKTp4i5U6aE88GwwcuV4HAprUgHcTq0sSafLxjr6AW0QahrCRCjxogkbbcdtpbXkuTOlgpjophCxb6sh5g==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-syntax-jsx": "^7.2.0"
      }
    },
    "@babel/plugin-transform-regenerator": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-regenerator/-/plugin-transform-regenerator-7.0.0.tgz",
      "integrity": "sha512-sj2qzsEx8KDVv1QuJc/dEfilkg3RRPvPYx/VnKLtItVQRWt1Wqf5eVCOLZm29CiGFfYYsA3VPjfizTCV0S0Dlw==",
      "dev": true,
      "requires": {
        "regenerator-transform": "^0.13.3"
      }
    },
    "@babel/plugin-transform-shorthand-properties": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-shorthand-properties/-/plugin-transform-shorthand-properties-7.2.0.tgz",
      "integrity": "sha512-QP4eUM83ha9zmYtpbnyjTLAGKQritA5XW/iG9cjtuOI8s1RuL/3V6a3DeSHfKutJQ+ayUfeZJPcnCYEQzaPQqg==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-spread": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-spread/-/plugin-transform-spread-7.2.2.tgz",
      "integrity": "sha512-KWfky/58vubwtS0hLqEnrWJjsMGaOeSBn90Ezn5Jeg9Z8KKHmELbP1yGylMlm5N6TPKeY9A2+UaSYLdxahg01w==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-sticky-regex": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-sticky-regex/-/plugin-transform-sticky-regex-7.2.0.tgz",
      "integrity": "sha512-KKYCoGaRAf+ckH8gEL3JHUaFVyNHKe3ASNsZ+AlktgHevvxGigoIttrEJb8iKN03Q7Eazlv1s6cx2B2cQ3Jabw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-regex": "^7.0.0"
      }
    },
    "@babel/plugin-transform-template-literals": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-template-literals/-/plugin-transform-template-literals-7.2.0.tgz",
      "integrity": "sha512-FkPix00J9A/XWXv4VoKJBMeSkyY9x/TqIh76wzcdfl57RJJcf8CehQ08uwfhCDNtRQYtHQKBTwKZDEyjE13Lwg==",
      "dev": true,
      "requires": {
        "@babel/helper-annotate-as-pure": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-typeof-symbol": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-typeof-symbol/-/plugin-transform-typeof-symbol-7.2.0.tgz",
      "integrity": "sha512-2LNhETWYxiYysBtrBTqL8+La0jIoQQnIScUJc74OYvUGRmkskNY4EzLCnjHBzdmb38wqtTaixpo1NctEcvMDZw==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0"
      }
    },
    "@babel/plugin-transform-unicode-regex": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-unicode-regex/-/plugin-transform-unicode-regex-7.2.0.tgz",
      "integrity": "sha512-m48Y0lMhrbXEJnVUaYly29jRXbQ3ksxPrS1Tg8t+MHqzXhtBYAvI51euOBaoAlZLPHsieY9XPVMf80a5x0cPcA==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/helper-regex": "^7.0.0",
        "regexpu-core": "^4.1.3"
      }
    },
    "@babel/preset-env": {
      "version": "7.3.1",
      "resolved": "https://registry.npmjs.org/@babel/preset-env/-/preset-env-7.3.1.tgz",
      "integrity": "sha512-FHKrD6Dxf30e8xgHQO0zJZpUPfVZg+Xwgz5/RdSWCbza9QLNk4Qbp40ctRoqDxml3O8RMzB1DU55SXeDG6PqHQ==",
      "dev": true,
      "requires": {
        "@babel/helper-module-imports": "^7.0.0",
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-proposal-async-generator-functions": "^7.2.0",
        "@babel/plugin-proposal-json-strings": "^7.2.0",
        "@babel/plugin-proposal-object-rest-spread": "^7.3.1",
        "@babel/plugin-proposal-optional-catch-binding": "^7.2.0",
        "@babel/plugin-proposal-unicode-property-regex": "^7.2.0",
        "@babel/plugin-syntax-async-generators": "^7.2.0",
        "@babel/plugin-syntax-json-strings": "^7.2.0",
        "@babel/plugin-syntax-object-rest-spread": "^7.2.0",
        "@babel/plugin-syntax-optional-catch-binding": "^7.2.0",
        "@babel/plugin-transform-arrow-functions": "^7.2.0",
        "@babel/plugin-transform-async-to-generator": "^7.2.0",
        "@babel/plugin-transform-block-scoped-functions": "^7.2.0",
        "@babel/plugin-transform-block-scoping": "^7.2.0",
        "@babel/plugin-transform-classes": "^7.2.0",
        "@babel/plugin-transform-computed-properties": "^7.2.0",
        "@babel/plugin-transform-destructuring": "^7.2.0",
        "@babel/plugin-transform-dotall-regex": "^7.2.0",
        "@babel/plugin-transform-duplicate-keys": "^7.2.0",
        "@babel/plugin-transform-exponentiation-operator": "^7.2.0",
        "@babel/plugin-transform-for-of": "^7.2.0",
        "@babel/plugin-transform-function-name": "^7.2.0",
        "@babel/plugin-transform-literals": "^7.2.0",
        "@babel/plugin-transform-modules-amd": "^7.2.0",
        "@babel/plugin-transform-modules-commonjs": "^7.2.0",
        "@babel/plugin-transform-modules-systemjs": "^7.2.0",
        "@babel/plugin-transform-modules-umd": "^7.2.0",
        "@babel/plugin-transform-named-capturing-groups-regex": "^7.3.0",
        "@babel/plugin-transform-new-target": "^7.0.0",
        "@babel/plugin-transform-object-super": "^7.2.0",
        "@babel/plugin-transform-parameters": "^7.2.0",
        "@babel/plugin-transform-regenerator": "^7.0.0",
        "@babel/plugin-transform-shorthand-properties": "^7.2.0",
        "@babel/plugin-transform-spread": "^7.2.0",
        "@babel/plugin-transform-sticky-regex": "^7.2.0",
        "@babel/plugin-transform-template-literals": "^7.2.0",
        "@babel/plugin-transform-typeof-symbol": "^7.2.0",
        "@babel/plugin-transform-unicode-regex": "^7.2.0",
        "browserslist": "^4.3.4",
        "invariant": "^2.2.2",
        "js-levenshtein": "^1.1.3",
        "semver": "^5.3.0"
      }
    },
    "@babel/preset-flow": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/preset-flow/-/preset-flow-7.0.0.tgz",
      "integrity": "sha512-bJOHrYOPqJZCkPVbG1Lot2r5OSsB+iUOaxiHdlOeB1yPWS6evswVHwvkDLZ54WTaTRIk89ds0iHmGZSnxlPejQ==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-transform-flow-strip-types": "^7.0.0"
      }
    },
    "@babel/preset-react": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/preset-react/-/preset-react-7.0.0.tgz",
      "integrity": "sha512-oayxyPS4Zj+hF6Et11BwuBkmpgT/zMxyuZgFrMeZID6Hdh3dGlk4sHCAhdBCpuCKW2ppBfl2uCCetlrUIJRY3w==",
      "dev": true,
      "requires": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/plugin-transform-react-display-name": "^7.0.0",
        "@babel/plugin-transform-react-jsx": "^7.0.0",
        "@babel/plugin-transform-react-jsx-self": "^7.0.0",
        "@babel/plugin-transform-react-jsx-source": "^7.0.0"
      }
    },
    "@babel/preset-stage-0": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/@babel/preset-stage-0/-/preset-stage-0-7.0.0.tgz",
      "integrity": "sha512-FBMd0IiARPtH5aaOFUVki6evHiJQiY0pFy7fizyRF7dtwc+el3nwpzvhb9qBNzceG1OIJModG1xpE0DDFjPXwA==",
      "dev": true
    },
    "@babel/template": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.2.2.tgz",
      "integrity": "sha512-zRL0IMM02AUDwghf5LMSSDEz7sBCO2YnNmpg3uWTZj/v1rcG2BmQUvaGU8GhU8BvfMh1k2KIAYZ7Ji9KXPUg7g==",
      "dev": true,
      "requires": {
        "@babel/code-frame": "^7.0.0",
        "@babel/parser": "^7.2.2",
        "@babel/types": "^7.2.2"
      },
      "dependencies": {
        "@babel/parser": {
          "version": "7.3.1",
          "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.3.1.tgz",
          "integrity": "sha512-ATz6yX/L8LEnC3dtLQnIx4ydcPxhLcoy9Vl6re00zb2w5lG6itY6Vhnr1KFRPq/FHNsgl/gh2mjNN20f9iJTTA==",
          "dev": true
        }
      }
    },
    "@babel/traverse": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.2.3.tgz",
      "integrity": "sha512-Z31oUD/fJvEWVR0lNZtfgvVt512ForCTNKYcJBGbPb1QZfve4WGH8Wsy7+Mev33/45fhP/hwQtvgusNdcCMgSw==",
      "dev": true,
      "requires": {
        "@babel/code-frame": "^7.0.0",
        "@babel/generator": "^7.2.2",
        "@babel/helper-function-name": "^7.1.0",
        "@babel/helper-split-export-declaration": "^7.0.0",
        "@babel/parser": "^7.2.3",
        "@babel/types": "^7.2.2",
        "debug": "^4.1.0",
        "globals": "^11.1.0",
        "lodash": "^4.17.10"
      },
      "dependencies": {
        "@babel/parser": {
          "version": "7.3.1",
          "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.3.1.tgz",
          "integrity": "sha512-ATz6yX/L8LEnC3dtLQnIx4ydcPxhLcoy9Vl6re00zb2w5lG6itY6Vhnr1KFRPq/FHNsgl/gh2mjNN20f9iJTTA==",
          "dev": true
        },
        "debug": {
          "version": "4.1.1",
          "resolved": "https://registry.npmjs.org/debug/-/debug-4.1.1.tgz",
          "integrity": "sha512-pYAIzeRo8J6KPEaJ0VWOh5Pzkbw/RetuzehGM7QRRX5he4fPHx2rdKMB256ehJCkX+XRQm16eZLqLNS8RSZXZw==",
          "dev": true,
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "globals": {
          "version": "11.10.0",
          "resolved": "https://registry.npmjs.org/globals/-/globals-11.10.0.tgz",
          "integrity": "sha512-0GZF1RiPKU97IHUO5TORo9w1PwrH/NBPl+fS7oMLdaTRiYmYbwK4NWoZWrAdd0/abG9R2BU+OiwyQpTpE6pdfQ==",
          "dev": true
        },
        "ms": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
          "dev": true
        }
      }
    },
    "@babel/types": {
      "version": "7.3.0",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.3.0.tgz",
      "integrity": "sha512-QkFPw68QqWU1/RVPyBe8SO7lXbPfjtqAxRYQKpFpaB8yMq7X2qAqfwK5LKoQufEkSmO5NQ70O6Kc3Afk03RwXw==",
      "dev": true,
      "requires": {
        "esutils": "^2.0.2",
        "lodash": "^4.17.10",
        "to-fast-properties": "^2.0.0"
      },
      "dependencies": {
        "to-fast-properties": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/to-fast-properties/-/to-fast-properties-2.0.0.tgz",
          "integrity": "sha1-3F5pjL0HkmW8c+A3doGk5Og/YW4=",
          "dev": true
        }
      }
    },
    "@cnakazawa/watch": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/@cnakazawa/watch/-/watch-1.0.3.tgz",
      "integrity": "sha512-r5160ogAvGyHsal38Kux7YYtodEKOj89RGb28ht1jh3SJb08VwRwAKKJL0bGb04Zd/3r9FL3BFIc3bBidYffCA==",
      "dev": true,
      "requires": {
        "exec-sh": "^0.3.2",
        "minimist": "^1.2.0"
      },
      "dependencies": {
        "minimist": {
          "version": "1.2.0",
          "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
          "dev": true
        }
      }
    },
    "@jest/console": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/console/-/console-24.7.1.tgz",
      "integrity": "sha512-iNhtIy2M8bXlAOULWVTUxmnelTLFneTNEkHCgPmgd+zNwy9zVddJ6oS5rZ9iwoscNdT5mMwUd0C51v/fSlzItg==",
      "dev": true,
      "requires": {
        "@jest/source-map": "^24.3.0",
        "chalk": "^2.0.1",
        "slash": "^2.0.0"
      }
    },
    "@jest/core": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/core/-/core-24.7.1.tgz",
      "integrity": "sha512-ivlZ8HX/FOASfHcb5DJpSPFps8ydfUYzLZfgFFqjkLijYysnIEOieg72YRhO4ZUB32xu40hsSMmaw+IGYeKONA==",
      "dev": true,
      "requires": {
        "@jest/console": "^24.7.1",
        "@jest/reporters": "^24.7.1",
        "@jest/test-result": "^24.7.1",
        "@jest/transform": "^24.7.1",
        "@jest/types": "^24.7.0",
        "ansi-escapes": "^3.0.0",
        "chalk": "^2.0.1",
        "exit": "^0.1.2",
        "graceful-fs": "^4.1.15",
        "jest-changed-files": "^24.7.0",
        "jest-config": "^24.7.1",
        "jest-haste-map": "^24.7.1",
        "jest-message-util": "^24.7.1",
        "jest-regex-util": "^24.3.0",
        "jest-resolve-dependencies": "^24.7.1",
        "jest-runner": "^24.7.1",
        "jest-runtime": "^24.7.1",
        "jest-snapshot": "^24.7.1",
        "jest-util": "^24.7.1",
        "jest-validate": "^24.7.0",
        "jest-watcher": "^24.7.1",
        "micromatch": "^3.1.10",
        "p-each-series": "^1.0.0",
        "pirates": "^4.0.1",
        "realpath-native": "^1.1.0",
        "rimraf": "^2.5.4",
        "strip-ansi": "^5.0.0"
      },
      "dependencies": {
        "ansi-regex": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-4.1.0.tgz",
          "integrity": "sha512-1apePfXM1UOSqw0o9IiFAovVz9M5S1Dg+4TrDwfMewQ6p/rmMueb7tWZjQ1rx4Loy1ArBggoqGpfqqdI4rondg==",
          "dev": true
        },
        "strip-ansi": {
          "version": "5.2.0",
          "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-5.2.0.tgz",
          "integrity": "sha512-DuRs1gKbBqsMKIZlrffwlug8MHkcnpjs5VPmL1PAh+mA30U0DTotfDZ0d2UUsXpPmPmMMJ6W773MaA3J+lbiWA==",
          "dev": true,
          "requires": {
            "ansi-regex": "^4.1.0"
          }
        }
      }
    },
    "@jest/environment": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/environment/-/environment-24.7.1.tgz",
      "integrity": "sha512-wmcTTYc4/KqA+U5h1zQd5FXXynfa7VGP2NfF+c6QeGJ7c+2nStgh65RQWNX62SC716dTtqheTRrZl0j+54oGHw==",
      "dev": true,
      "requires": {
        "@jest/fake-timers": "^24.7.1",
        "@jest/transform": "^24.7.1",
        "@jest/types": "^24.7.0",
        "jest-mock": "^24.7.0"
      }
    },
    "@jest/fake-timers": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/fake-timers/-/fake-timers-24.7.1.tgz",
      "integrity": "sha512-4vSQJDKfR2jScOe12L9282uiwuwQv9Lk7mgrCSZHA9evB9efB/qx8i0KJxsAKtp8fgJYBJdYY7ZU6u3F4/pyjA==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "jest-message-util": "^24.7.1",
        "jest-mock": "^24.7.0"
      }
    },
    "@jest/reporters": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/reporters/-/reporters-24.7.1.tgz",
      "integrity": "sha512-bO+WYNwHLNhrjB9EbPL4kX/mCCG4ZhhfWmO3m4FSpbgr7N83MFejayz30kKjgqr7smLyeaRFCBQMbXpUgnhAJw==",
      "dev": true,
      "requires": {
        "@jest/environment": "^24.7.1",
        "@jest/test-result": "^24.7.1",
        "@jest/transform": "^24.7.1",
        "@jest/types": "^24.7.0",
        "chalk": "^2.0.1",
        "exit": "^0.1.2",
        "glob": "^7.1.2",
        "istanbul-api": "^2.1.1",
        "istanbul-lib-coverage": "^2.0.2",
        "istanbul-lib-instrument": "^3.0.1",
        "istanbul-lib-source-maps": "^3.0.1",
        "jest-haste-map": "^24.7.1",
        "jest-resolve": "^24.7.1",
        "jest-runtime": "^24.7.1",
        "jest-util": "^24.7.1",
        "jest-worker": "^24.6.0",
        "node-notifier": "^5.2.1",
        "slash": "^2.0.0",
        "source-map": "^0.6.0",
        "string-length": "^2.0.0"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "@jest/source-map": {
      "version": "24.3.0",
      "resolved": "https://registry.npmjs.org/@jest/source-map/-/source-map-24.3.0.tgz",
      "integrity": "sha512-zALZt1t2ou8le/crCeeiRYzvdnTzaIlpOWaet45lNSqNJUnXbppUUFR4ZUAlzgDmKee4Q5P/tKXypI1RiHwgag==",
      "dev": true,
      "requires": {
        "callsites": "^3.0.0",
        "graceful-fs": "^4.1.15",
        "source-map": "^0.6.0"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "@jest/test-result": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/test-result/-/test-result-24.7.1.tgz",
      "integrity": "sha512-3U7wITxstdEc2HMfBX7Yx3JZgiNBubwDqQMh+BXmZXHa3G13YWF3p6cK+5g0hGkN3iufg/vGPl3hLxQXD74Npg==",
      "dev": true,
      "requires": {
        "@jest/console": "^24.7.1",
        "@jest/types": "^24.7.0",
        "@types/istanbul-lib-coverage": "^2.0.0"
      }
    },
    "@jest/test-sequencer": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/test-sequencer/-/test-sequencer-24.7.1.tgz",
      "integrity": "sha512-84HQkCpVZI/G1zq53gHJvSmhUer4aMYp9tTaffW28Ih5OxfCg8hGr3nTSbL1OhVDRrFZwvF+/R9gY6JRkDUpUA==",
      "dev": true,
      "requires": {
        "@jest/test-result": "^24.7.1",
        "jest-haste-map": "^24.7.1",
        "jest-runner": "^24.7.1",
        "jest-runtime": "^24.7.1"
      }
    },
    "@jest/transform": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/@jest/transform/-/transform-24.7.1.tgz",
      "integrity": "sha512-EsOUqP9ULuJ66IkZQhI5LufCHlTbi7hrcllRMUEV/tOgqBVQi93+9qEvkX0n8mYpVXQ8VjwmICeRgg58mrtIEw==",
      "dev": true,
      "requires": {
        "@babel/core": "^7.1.0",
        "@jest/types": "^24.7.0",
        "babel-plugin-istanbul": "^5.1.0",
        "chalk": "^2.0.1",
        "convert-source-map": "^1.4.0",
        "fast-json-stable-stringify": "^2.0.0",
        "graceful-fs": "^4.1.15",
        "jest-haste-map": "^24.7.1",
        "jest-regex-util": "^24.3.0",
        "jest-util": "^24.7.1",
        "micromatch": "^3.1.10",
        "realpath-native": "^1.1.0",
        "slash": "^2.0.0",
        "source-map": "^0.6.1",
        "write-file-atomic": "2.4.1"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "@jest/types": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/@jest/types/-/types-24.7.0.tgz",
      "integrity": "sha512-ipJUa2rFWiKoBqMKP63Myb6h9+iT3FHRTF2M8OR6irxWzItisa8i4dcSg14IbvmXUnBlHBlUQPYUHWyX3UPpYA==",
      "dev": true,
      "requires": {
        "@types/istanbul-lib-coverage": "^2.0.0",
        "@types/yargs": "^12.0.9"
      }
    },
    "@protobufjs/aspromise": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@protobufjs/aspromise/-/aspromise-1.1.2.tgz",
      "integrity": "sha1-m4sMxmPWaafY9vXQiToU00jzD78="
    },
    "@protobufjs/base64": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@protobufjs/base64/-/base64-1.1.2.tgz",
      "integrity": "sha512-AZkcAA5vnN/v4PDqKyMR5lx7hZttPDgClv83E//FMNhR2TMcLUhfRUBHCmSl0oi9zMgDDqRUJkSxO3wm85+XLg=="
    },
    "@protobufjs/codegen": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/@protobufjs/codegen/-/codegen-2.0.4.tgz",
      "integrity": "sha512-YyFaikqM5sH0ziFZCN3xDC7zeGaB/d0IUb9CATugHWbd1FRFwWwt4ld4OYMPWu5a3Xe01mGAULCdqhMlPl29Jg=="
    },
    "@protobufjs/eventemitter": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@protobufjs/eventemitter/-/eventemitter-1.1.0.tgz",
      "integrity": "sha1-NVy8mLr61ZePntCV85diHx0Ga3A="
    },
    "@protobufjs/fetch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@protobufjs/fetch/-/fetch-1.1.0.tgz",
      "integrity": "sha1-upn7WYYUr2VwDBYZ/wbUVLDYTEU=",
      "requires": {
        "@protobufjs/aspromise": "^1.1.1",
        "@protobufjs/inquire": "^1.1.0"
      }
    },
    "@protobufjs/float": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/@protobufjs/float/-/float-1.0.2.tgz",
      "integrity": "sha1-Xp4avctz/Ap8uLKR33jIy9l7h9E="
    },
    "@protobufjs/inquire": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@protobufjs/inquire/-/inquire-1.1.0.tgz",
      "integrity": "sha1-/yAOPnzyQp4tyvwRQIKOjMY48Ik="
    },
    "@protobufjs/path": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@protobufjs/path/-/path-1.1.2.tgz",
      "integrity": "sha1-bMKyDFya1q0NzP0hynZz2Nf79o0="
    },
    "@protobufjs/pool": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@protobufjs/pool/-/pool-1.1.0.tgz",
      "integrity": "sha1-Cf0V8tbTq/qbZbw2ZQbWrXhG/1Q="
    },
    "@protobufjs/utf8": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@protobufjs/utf8/-/utf8-1.1.0.tgz",
      "integrity": "sha1-p3c2C1s5oaLlEG+OhY8v0tBgxXA="
    },
    "@types/babel__core": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.1.1.tgz",
      "integrity": "sha512-+hjBtgcFPYyCTo0A15+nxrCVJL7aC6Acg87TXd5OW3QhHswdrOLoles+ldL2Uk8q++7yIfl4tURtztccdeeyOw==",
      "dev": true,
      "requires": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "@types/babel__generator": {
      "version": "7.0.2",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.0.2.tgz",
      "integrity": "sha512-NHcOfab3Zw4q5sEE2COkpfXjoE7o+PmqD9DQW4koUT3roNxwziUdXGnRndMat/LJNUtePwn1TlP4do3uoe3KZQ==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0"
      }
    },
    "@types/babel__template": {
      "version": "7.0.2",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.0.2.tgz",
      "integrity": "sha512-/K6zCpeW7Imzgab2bLkLEbz0+1JlFSrUMdw7KoIIu+IUdu51GWaBZpd3y1VXGVXzynvGa4DaIaxNZHiON3GXUg==",
      "dev": true,
      "requires": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "@types/babel__traverse": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.0.6.tgz",
      "integrity": "sha512-XYVgHF2sQ0YblLRMLNPB3CkFMewzFmlDsH/TneZFHUXDlABQgh88uOxuez7ZcXxayLFrqLwtDH1t+FmlFwNZxw==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.3.0"
      }
    },
    "@types/istanbul-lib-coverage": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.1.tgz",
      "integrity": "sha512-hRJD2ahnnpLgsj6KWMYSrmXkM3rm2Dl1qkx6IOFD5FnuNPXJIG5L0dhgKXCYTRMGzU4n0wImQ/xfmRc4POUFlg==",
      "dev": true
    },
    "@types/long": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/@types/long/-/long-4.0.0.tgz",
      "integrity": "sha512-1w52Nyx4Gq47uuu0EVcsHBxZFJgurQ+rTKS3qMHxR1GY2T8c2AJYd6vZoZ9q1rupaDjU0yT+Jc2XTyXkjeMA+Q=="
    },
    "@types/node": {
      "version": "10.12.18",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-10.12.18.tgz",
      "integrity": "sha512-fh+pAqt4xRzPfqA6eh3Z2y6fyZavRIumvjhaCL753+TVkGKGhpPeyrJG2JftD0T9q4GF00KjefsQ+PQNDdWQaQ=="
    },
    "@types/stack-utils": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@types/stack-utils/-/stack-utils-1.0.1.tgz",
      "integrity": "sha512-l42BggppR6zLmpfU6fq9HEa2oGPEI8yrSPL3GITjfRInppYFahObbIQOQK3UGxEnyQpltZLaPe75046NOZQikw==",
      "dev": true
    },
    "@types/yargs": {
      "version": "12.0.12",
      "resolved": "https://registry.npmjs.org/@types/yargs/-/yargs-12.0.12.tgz",
      "integrity": "sha512-SOhuU4wNBxhhTHxYaiG5NY4HBhDIDnJF60GU+2LqHAdKKer86//e4yg69aENCtQ04n0ovz+tq2YPME5t5yp4pw==",
      "dev": true
    },
    "JSONStream": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/JSONStream/-/JSONStream-1.3.5.tgz",
      "integrity": "sha512-E+iruNOY8VV9s4JEbe1aNEm6MiszPRr/UfcHMz0TQh1BXSxHK+ASV1R6W4HpjBhSeS+54PIsAMCBmwD06LLsqQ==",
      "dev": true,
      "requires": {
        "jsonparse": "^1.2.0",
        "through": ">=2.2.7 <3"
      }
    },
    "abab": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/abab/-/abab-2.0.0.tgz",
      "integrity": "sha512-sY5AXXVZv4Y1VACTtR11UJCPHHudgY5i26Qj5TypE6DKlIApbwb5uqhXcJ5UUGbvZNRh7EeIoW+LrJumBsKp7w==",
      "dev": true
    },
    "acorn": {
      "version": "5.7.3",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-5.7.3.tgz",
      "integrity": "sha512-T/zvzYRfbVojPWahDsE5evJdHb3oJoQfFbsrKM7w5Zcs++Tr257tia3BmMP8XYVjp1S9RZXQMh7gao96BlqZOw==",
      "dev": true
    },
    "acorn-dynamic-import": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/acorn-dynamic-import/-/acorn-dynamic-import-4.0.0.tgz",
      "integrity": "sha512-d3OEjQV4ROpoflsnUA8HozoIR504TFxNivYEUi6uwz0IYhBkTDXGuWlNdMtybRt3nqVx/L6XqMt0FxkXuWKZhw==",
      "dev": true
    },
    "acorn-globals": {
      "version": "4.3.2",
      "resolved": "https://registry.npmjs.org/acorn-globals/-/acorn-globals-4.3.2.tgz",
      "integrity": "sha512-BbzvZhVtZP+Bs1J1HcwrQe8ycfO0wStkSGxuul3He3GkHOIZ6eTqOkPuw9IP1X3+IkOo4wiJmwkobzXYz4wewQ==",
      "dev": true,
      "requires": {
        "acorn": "^6.0.1",
        "acorn-walk": "^6.0.1"
      },
      "dependencies": {
        "acorn": {
          "version": "6.1.1",
          "resolved": "https://registry.npmjs.org/acorn/-/acorn-6.1.1.tgz",
          "integrity": "sha512-jPTiwtOxaHNaAPg/dmrJ/beuzLRnXtB0kQPQ8JpotKJgTB6rX6c8mlf315941pyjBSaPg8NHXS9fhP4u17DpGA==",
          "dev": true
        }
      }
    },
    "acorn-jsx": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.0.1.tgz",
      "integrity": "sha512-HJ7CfNHrfJLlNTzIEUTj43LNWGkqpRLxm3YjAlcD0ACydk9XynzYsCBHxut+iqt+1aBXkx9UP/w/ZqMr13XIzg==",
      "dev": true
    },
    "acorn-node": {
      "version": "1.6.2",
      "resolved": "https://registry.npmjs.org/acorn-node/-/acorn-node-1.6.2.tgz",
      "integrity": "sha512-rIhNEZuNI8ibQcL7ANm/mGyPukIaZsRNX9psFNQURyJW0nu6k8wjSDld20z6v2mDBWqX13pIEnk9gGZJHIlEXg==",
      "dev": true,
      "requires": {
        "acorn": "^6.0.2",
        "acorn-dynamic-import": "^4.0.0",
        "acorn-walk": "^6.1.0",
        "xtend": "^4.0.1"
      },
      "dependencies": {
        "acorn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/acorn/-/acorn-6.0.5.tgz",
          "integrity": "sha512-i33Zgp3XWtmZBMNvCr4azvOFeWVw1Rk6p3hfi3LUDvIFraOMywb1kAtrbi+med14m4Xfpqm3zRZMT+c0FNE7kg==",
          "dev": true
        }
      }
    },
    "acorn-walk": {
      "version": "6.1.1",
      "resolved": "https://registry.npmjs.org/acorn-walk/-/acorn-walk-6.1.1.tgz",
      "integrity": "sha512-OtUw6JUTgxA2QoqqmrmQ7F2NYqiBPi/L2jqHyFtllhOUvXYQXf0Z1CYUinIfyT4bTCGmrA7gX9FvHA81uzCoVw==",
      "dev": true
    },
    "ajv": {
      "version": "6.10.0",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.10.0.tgz",
      "integrity": "sha512-nffhOpkymDECQyR0mnsUtoCE8RlX38G0rYP+wgLWFyZuUyuuojSSvi/+euOiQBIn63whYwYVIIH1TvE3tu4OEg==",
      "dev": true,
      "requires": {
        "fast-deep-equal": "^2.0.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      }
    },
    "ansi-escapes": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-3.2.0.tgz",
      "integrity": "sha512-cBhpre4ma+U0T1oM5fXg7Dy1Jw7zzwv7lt/GoCpr+hDQJoYnKVPLL4dCvSEFMmQurOQvSrwT7SL/DAlhBI97RQ==",
      "dev": true
    },
    "ansi-html": {
      "version": "0.0.7",
      "resolved": "https://registry.npmjs.org/ansi-html/-/ansi-html-0.0.7.tgz",
      "integrity": "sha1-gTWEAhliqenm/QOflA0S9WynhZ4=",
      "dev": true
    },
    "ansi-regex": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-2.1.1.tgz",
      "integrity": "sha1-w7M6te42DYbg5ijwRorn7yfWVN8=",
      "dev": true
    },
    "ansi-styles": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-3.2.1.tgz",
      "integrity": "sha512-VT0ZI6kZRdTh8YyJw3SMbYm/u+NqfsAxEpWO0Pf9sq8/e94WxxOpPKx9FR1FlyCtOVDNOQ+8ntlqFxiRc+r5qA==",
      "dev": true,
      "requires": {
        "color-convert": "^1.9.0"
      }
    },
    "anymatch": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-2.0.0.tgz",
      "integrity": "sha512-5teOsQWABXHHBFP9y3skS5P3d/WfWXpv3FUpy+LorMrNYaT9pI4oLMQX7jzQ2KklNpGpWHzdCXTDT2Y3XGlZBw==",
      "dev": true,
      "requires": {
        "micromatch": "^3.1.4",
        "normalize-path": "^2.1.1"
      },
      "dependencies": {
        "arr-diff": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/arr-diff/-/arr-diff-4.0.0.tgz",
          "integrity": "sha1-1kYQdP6/7HHn4VI1dhoyml3HxSA=",
          "dev": true
        },
        "array-unique": {
          "version": "0.3.2",
          "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
          "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
          "dev": true
        },
        "braces": {
          "version": "2.3.2",
          "resolved": "https://registry.npmjs.org/braces/-/braces-2.3.2.tgz",
          "integrity": "sha512-aNdbnj9P8PjdXU4ybaWLK2IF3jc/EoDYbC7AazW6to3TRsfXxscC9UXOB5iDiEQrkyIbWp2SLQda4+QAa7nc3w==",
          "dev": true,
          "requires": {
            "arr-flatten": "^1.1.0",
            "array-unique": "^0.3.2",
            "extend-shallow": "^2.0.1",
            "fill-range": "^4.0.0",
            "isobject": "^3.0.1",
            "repeat-element": "^1.1.2",
            "snapdragon": "^0.8.1",
            "snapdragon-node": "^2.0.1",
            "split-string": "^3.0.2",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "expand-brackets": {
          "version": "2.1.4",
          "resolved": "https://registry.npmjs.org/expand-brackets/-/expand-brackets-2.1.4.tgz",
          "integrity": "sha1-t3c14xXOMPa27/D4OwQVGiJEliI=",
          "dev": true,
          "requires": {
            "debug": "^2.3.3",
            "define-property": "^0.2.5",
            "extend-shallow": "^2.0.1",
            "posix-character-classes": "^0.1.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "0.2.5",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
              "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^0.1.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            },
            "is-accessor-descriptor": {
              "version": "0.1.6",
              "resolved": "http://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-0.1.6.tgz",
              "integrity": "sha1-qeEss66Nh2cn7u84Q/igiXtcmNY=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-data-descriptor": {
              "version": "0.1.4",
              "resolved": "http://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-0.1.4.tgz",
              "integrity": "sha1-C17mSDiOLIYCgueT8YVv7D8wG1Y=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-descriptor": {
              "version": "0.1.6",
              "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-0.1.6.tgz",
              "integrity": "sha512-avDYr0SB3DwO9zsMov0gKCESFYqCnE4hq/4z3TdUlukEy5t9C0YRq7HLrsN52NAcqXKaepeCD0n+B0arnVG3Hg==",
              "dev": true,
              "requires": {
                "is-accessor-descriptor": "^0.1.6",
                "is-data-descriptor": "^0.1.4",
                "kind-of": "^5.0.0"
              }
            },
            "kind-of": {
              "version": "5.1.0",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-5.1.0.tgz",
              "integrity": "sha512-NGEErnH6F2vUuXDh+OlbcKW7/wOcfdRHaZ7VWtqCztfHri/++YKmP51OdWeGPuqCOba6kk2OTe5d02VmTB80Pw==",
              "dev": true
            }
          }
        },
        "extglob": {
          "version": "2.0.4",
          "resolved": "https://registry.npmjs.org/extglob/-/extglob-2.0.4.tgz",
          "integrity": "sha512-Nmb6QXkELsuBr24CJSkilo6UHHgbekK5UiZgfE6UHD3Eb27YC6oD+bhcT+tJ6cl8dmsgdQxnWlcry8ksBIBLpw==",
          "dev": true,
          "requires": {
            "array-unique": "^0.3.2",
            "define-property": "^1.0.0",
            "expand-brackets": "^2.1.4",
            "extend-shallow": "^2.0.1",
            "fragment-cache": "^0.2.1",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "1.0.0",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
              "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^1.0.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "fill-range": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-4.0.0.tgz",
          "integrity": "sha1-1USBHUKPmOsGpj3EAtJAPDKMOPc=",
          "dev": true,
          "requires": {
            "extend-shallow": "^2.0.1",
            "is-number": "^3.0.0",
            "repeat-string": "^1.6.1",
            "to-regex-range": "^2.1.0"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          },
          "dependencies": {
            "kind-of": {
              "version": "3.2.2",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
              "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
              "dev": true,
              "requires": {
                "is-buffer": "^1.1.5"
              }
            }
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        },
        "micromatch": {
          "version": "3.1.10",
          "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-3.1.10.tgz",
          "integrity": "sha512-MWikgl9n9M3w+bpsY3He8L+w9eF9338xRl8IAO5viDizwSzziFEyUzo2xrrloB64ADbTf8uA8vRqqttDTOmccg==",
          "dev": true,
          "requires": {
            "arr-diff": "^4.0.0",
            "array-unique": "^0.3.2",
            "braces": "^2.3.1",
            "define-property": "^2.0.2",
            "extend-shallow": "^3.0.2",
            "extglob": "^2.0.4",
            "fragment-cache": "^0.2.1",
            "kind-of": "^6.0.2",
            "nanomatch": "^1.2.9",
            "object.pick": "^1.3.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.2"
          }
        }
      }
    },
    "append-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/append-buffer/-/append-buffer-1.0.2.tgz",
      "integrity": "sha1-2CIM9GYIFSXv6lBhTz3mUU36WPE=",
      "dev": true,
      "requires": {
        "buffer-equal": "^1.0.0"
      }
    },
    "append-transform": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/append-transform/-/append-transform-1.0.0.tgz",
      "integrity": "sha512-P009oYkeHyU742iSZJzZZywj4QRJdnTWffaKuJQLablCZ1uz6/cW4yaRgcDaoQ+uwOxxnt0gRUcwfsNP2ri0gw==",
      "dev": true,
      "requires": {
        "default-require-extensions": "^2.0.0"
      }
    },
    "argparse": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
      "dev": true,
      "requires": {
        "sprintf-js": "~1.0.2"
      }
    },
    "arr-diff": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/arr-diff/-/arr-diff-4.0.0.tgz",
      "integrity": "sha1-1kYQdP6/7HHn4VI1dhoyml3HxSA=",
      "dev": true
    },
    "arr-flatten": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/arr-flatten/-/arr-flatten-1.1.0.tgz",
      "integrity": "sha512-L3hKV5R/p5o81R7O02IGnwpDmkp6E982XhtbuwSe3O4qOtMMMtodicASA1Cny2U+aCXcNpml+m4dPsvsJ3jatg==",
      "dev": true
    },
    "arr-union": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/arr-union/-/arr-union-3.1.0.tgz",
      "integrity": "sha1-45sJrqne+Gao8gbiiK9jkZuuOcQ=",
      "dev": true
    },
    "array-equal": {
      "version": "1.0.0",
      "resolved": "http://registry.npmjs.org/array-equal/-/array-equal-1.0.0.tgz",
      "integrity": "sha1-jCpe8kcv2ep0KwTHenUJO6J1fJM=",
      "dev": true
    },
    "array-filter": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/array-filter/-/array-filter-0.0.1.tgz",
      "integrity": "sha1-fajPLiZijtcygDWB/SH2fKzS7uw=",
      "dev": true
    },
    "array-map": {
      "version": "0.0.0",
      "resolved": "https://registry.npmjs.org/array-map/-/array-map-0.0.0.tgz",
      "integrity": "sha1-iKK6tz0c97zVwbEYoAP2b2ZfpmI=",
      "dev": true
    },
    "array-reduce": {
      "version": "0.0.0",
      "resolved": "https://registry.npmjs.org/array-reduce/-/array-reduce-0.0.0.tgz",
      "integrity": "sha1-FziZ0//Rx9k4PkR5Ul2+J4yrXys=",
      "dev": true
    },
    "array-unique": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
      "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
      "dev": true
    },
    "asn1": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/asn1/-/asn1-0.2.4.tgz",
      "integrity": "sha512-jxwzQpLQjSmWXgwaCZE9Nz+glAG01yF1QnWgbhGwHI5A6FRIEY6IVqtHhIepHqI7/kyEyQEagBC5mBEFlIYvdg==",
      "dev": true,
      "requires": {
        "safer-buffer": "~2.1.0"
      }
    },
    "asn1.js": {
      "version": "4.10.1",
      "resolved": "https://registry.npmjs.org/asn1.js/-/asn1.js-4.10.1.tgz",
      "integrity": "sha512-p32cOF5q0Zqs9uBiONKYLm6BClCoBCM5O9JfeUSlnQLBTxYdTK+pW+nXflm8UkKd2UYlEbYz5qEi0JuZR9ckSw==",
      "dev": true,
      "requires": {
        "bn.js": "^4.0.0",
        "inherits": "^2.0.1",
        "minimalistic-assert": "^1.0.0"
      }
    },
    "assert": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/assert/-/assert-1.4.1.tgz",
      "integrity": "sha1-mZEtWRg2tab1s0XA8H7vwI/GXZE=",
      "dev": true,
      "requires": {
        "util": "0.10.3"
      },
      "dependencies": {
        "inherits": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.1.tgz",
          "integrity": "sha1-sX0I0ya0Qj5Wjv9xn5GwscvfafE=",
          "dev": true
        },
        "util": {
          "version": "0.10.3",
          "resolved": "https://registry.npmjs.org/util/-/util-0.10.3.tgz",
          "integrity": "sha1-evsa/lCAUkZInj23/g7TeTNqwPk=",
          "dev": true,
          "requires": {
            "inherits": "2.0.1"
          }
        }
      }
    },
    "assert-plus": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/assert-plus/-/assert-plus-1.0.0.tgz",
      "integrity": "sha1-8S4PPF13sLHN2RRpQuTpbB5N1SU=",
      "dev": true
    },
    "assign-symbols": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/assign-symbols/-/assign-symbols-1.0.0.tgz",
      "integrity": "sha1-WWZ/QfrdTyDMvCu5a41Pf3jsA2c=",
      "dev": true
    },
    "astral-regex": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/astral-regex/-/astral-regex-1.0.0.tgz",
      "integrity": "sha512-+Ryf6g3BKoRc7jfp7ad8tM4TtMiaWvbF/1/sQcZPkkS7ag3D5nMBCe2UfOTONtAkaG0tO0ij3C5Lwmf1EiyjHg==",
      "dev": true
    },
    "async": {
      "version": "2.6.2",
      "resolved": "https://registry.npmjs.org/async/-/async-2.6.2.tgz",
      "integrity": "sha512-H1qVYh1MYhEEFLsP97cVKqCGo7KfCyTt6uEWqsTBr9SO84oK9Uwbyd/yCW+6rKJLHksBNUVWZDAjfS+Ccx0Bbg==",
      "dev": true,
      "requires": {
        "lodash": "^4.17.11"
      }
    },
    "async-each": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/async-each/-/async-each-1.0.1.tgz",
      "integrity": "sha1-GdOGodntxufByF04iu28xW0zYC0=",
      "dev": true
    },
    "async-limiter": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/async-limiter/-/async-limiter-1.0.0.tgz",
      "integrity": "sha512-jp/uFnooOiO+L211eZOoSyzpOITMXx1rBITauYykG3BRYPu8h0UcxsPNB04RR5vo4Tyz3+ay17tR6JVf9qzYWg==",
      "dev": true
    },
    "asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha1-x57Zf380y48robyXkLzDZkdLS3k=",
      "dev": true
    },
    "atob": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/atob/-/atob-2.1.2.tgz",
      "integrity": "sha512-Wm6ukoaOGJi/73p/cl2GvLjTI5JM1k/O14isD73YML8StrH/7/lRFgmg8nICZgD3bZZvjwCGxtMOD3wWNAu8cg==",
      "dev": true
    },
    "aws-sign2": {
      "version": "0.7.0",
      "resolved": "https://registry.npmjs.org/aws-sign2/-/aws-sign2-0.7.0.tgz",
      "integrity": "sha1-tG6JCTSpWR8tL2+G1+ap8bP+dqg=",
      "dev": true
    },
    "aws4": {
      "version": "1.8.0",
      "resolved": "https://registry.npmjs.org/aws4/-/aws4-1.8.0.tgz",
      "integrity": "sha512-ReZxvNHIOv88FlT7rxcXIIC0fPt4KZqZbOlivyWtXLt8ESx84zd3kMC6iK5jVeS2qt+g7ftS7ye4fi06X5rtRQ==",
      "dev": true
    },
    "babel-jest": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/babel-jest/-/babel-jest-24.7.1.tgz",
      "integrity": "sha512-GPnLqfk8Mtt0i4OemjWkChi73A3ALs4w2/QbG64uAj8b5mmwzxc7jbJVRZt8NJkxi6FopVHog9S3xX6UJKb2qg==",
      "dev": true,
      "requires": {
        "@jest/transform": "^24.7.1",
        "@jest/types": "^24.7.0",
        "@types/babel__core": "^7.1.0",
        "babel-plugin-istanbul": "^5.1.0",
        "babel-preset-jest": "^24.6.0",
        "chalk": "^2.4.2",
        "slash": "^2.0.0"
      },
      "dependencies": {
        "chalk": {
          "version": "2.4.2",
          "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.2.tgz",
          "integrity": "sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==",
          "dev": true,
          "requires": {
            "ansi-styles": "^3.2.1",
            "escape-string-regexp": "^1.0.5",
            "supports-color": "^5.3.0"
          }
        }
      }
    },
    "babel-plugin-istanbul": {
      "version": "5.1.3",
      "resolved": "https://registry.npmjs.org/babel-plugin-istanbul/-/babel-plugin-istanbul-5.1.3.tgz",
      "integrity": "sha512-IFyehbvRRwdBlI1lDp+FaMsWNnEndEk7065IB8NhzBX+ZKLPwPodgk4I5Gobw/8SNUUzso2Dv3hbqRh88eiSCQ==",
      "dev": true,
      "requires": {
        "find-up": "^3.0.0",
        "istanbul-lib-instrument": "^3.2.0",
        "test-exclude": "^5.2.2"
      },
      "dependencies": {
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "p-limit": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.2.0.tgz",
          "integrity": "sha512-pZbTJpoUsCzV48Mc9Nh51VbwO0X9cuPFE8gYwx9BTCt9SF8/b7Zljd2fVgOxhIF/HDTKgpVzs+GPhyKfjLLFRQ==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
          "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
          "dev": true
        }
      }
    },
    "babel-plugin-jest-hoist": {
      "version": "24.6.0",
      "resolved": "https://registry.npmjs.org/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-24.6.0.tgz",
      "integrity": "sha512-3pKNH6hMt9SbOv0F3WVmy5CWQ4uogS3k0GY5XLyQHJ9EGpAT9XWkFd2ZiXXtkwFHdAHa5j7w7kfxSP5lAIwu7w==",
      "dev": true,
      "requires": {
        "@types/babel__traverse": "^7.0.6"
      }
    },
    "babel-preset-jest": {
      "version": "24.6.0",
      "resolved": "https://registry.npmjs.org/babel-preset-jest/-/babel-preset-jest-24.6.0.tgz",
      "integrity": "sha512-pdZqLEdmy1ZK5kyRUfvBb2IfTPb2BUvIJczlPspS8fWmBQslNNDBqVfh7BW5leOVJMDZKzjD8XEyABTk6gQ5yw==",
      "dev": true,
      "requires": {
        "@babel/plugin-syntax-object-rest-spread": "^7.0.0",
        "babel-plugin-jest-hoist": "^24.6.0"
      }
    },
    "babelify": {
      "version": "10.0.0",
      "resolved": "https://registry.npmjs.org/babelify/-/babelify-10.0.0.tgz",
      "integrity": "sha512-X40FaxyH7t3X+JFAKvb1H9wooWKLRCi8pg3m8poqtdZaIng+bjzp9RvKQCvRjF9isHiPkXspbbXT/zwXLtwgwg==",
      "dev": true
    },
    "bail": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/bail/-/bail-1.0.3.tgz",
      "integrity": "sha512-1X8CnjFVQ+a+KW36uBNMTU5s8+v5FzeqrP7hTG5aTb4aPreSbZJlhwPon9VKMuEVgV++JM+SQrALY3kr7eswdg==",
      "dev": true
    },
    "balanced-match": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.0.tgz",
      "integrity": "sha1-ibTRmasr7kneFk6gK4nORi1xt2c=",
      "dev": true
    },
    "base": {
      "version": "0.11.2",
      "resolved": "https://registry.npmjs.org/base/-/base-0.11.2.tgz",
      "integrity": "sha512-5T6P4xPgpp0YDFvSWwEZ4NoE3aM4QBQXDzmVbraCkFj8zHM+mba8SyqB5DbZWyR7mYHo6Y7BdQo3MoA4m0TeQg==",
      "dev": true,
      "requires": {
        "cache-base": "^1.0.1",
        "class-utils": "^0.3.5",
        "component-emitter": "^1.2.1",
        "define-property": "^1.0.0",
        "isobject": "^3.0.1",
        "mixin-deep": "^1.2.0",
        "pascalcase": "^0.1.1"
      },
      "dependencies": {
        "define-property": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
          "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^1.0.0"
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "base-x": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/base-x/-/base-x-3.0.5.tgz",
      "integrity": "sha512-C3picSgzPSLE+jW3tcBzJoGwitOtazb5B+5YmAxZm2ybmTi9LNgAtDO/jjVEBZwHoXmDBZ9m/IELj3elJVRBcA==",
      "requires": {
        "safe-buffer": "^5.0.1"
      }
    },
    "base64-js": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/base64-js/-/base64-js-1.3.0.tgz",
      "integrity": "sha512-ccav/yGvoa80BQDljCxsmmQ3Xvx60/UpBIij5QN21W3wBi/hhIC9OoO+KLpu9IJTS9j4DRVJ3aDDF9cMSoa2lw==",
      "dev": true
    },
    "bcrypt-pbkdf": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/bcrypt-pbkdf/-/bcrypt-pbkdf-1.0.2.tgz",
      "integrity": "sha1-pDAdOJtqQ/m2f/PKEaP2Y342Dp4=",
      "dev": true,
      "requires": {
        "tweetnacl": "^0.14.3"
      },
      "dependencies": {
        "tweetnacl": {
          "version": "0.14.5",
          "resolved": "https://registry.npmjs.org/tweetnacl/-/tweetnacl-0.14.5.tgz",
          "integrity": "sha1-WuaBd/GS1EViadEIr6k/+HQ/T2Q=",
          "dev": true
        }
      }
    },
    "binary-extensions": {
      "version": "1.12.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-1.12.0.tgz",
      "integrity": "sha512-DYWGk01lDcxeS/K9IHPGWfT8PsJmbXRtRd2Sx72Tnb8pcYZQFF1oSDb8hJtS1vhp212q1Rzi5dUf9+nq0o9UIg==",
      "dev": true
    },
    "bn.js": {
      "version": "4.11.8",
      "resolved": "https://registry.npmjs.org/bn.js/-/bn.js-4.11.8.tgz",
      "integrity": "sha512-ItfYfPLkWHUjckQCk8xC+LwxgK8NYcXywGigJgSwOP8Y2iyWT4f2vsZnoOXTTbo+o5yXmIUJ4gn5538SO5S3gA==",
      "dev": true
    },
    "body": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/body/-/body-5.1.0.tgz",
      "integrity": "sha1-5LoM5BCkaTYyM2dgnstOZVMSUGk=",
      "dev": true,
      "requires": {
        "continuable-cache": "^0.3.1",
        "error": "^7.0.0",
        "raw-body": "~1.1.0",
        "safe-json-parse": "~1.0.1"
      }
    },
    "brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dev": true,
      "requires": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "braces": {
      "version": "2.3.2",
      "resolved": "https://registry.npmjs.org/braces/-/braces-2.3.2.tgz",
      "integrity": "sha512-aNdbnj9P8PjdXU4ybaWLK2IF3jc/EoDYbC7AazW6to3TRsfXxscC9UXOB5iDiEQrkyIbWp2SLQda4+QAa7nc3w==",
      "dev": true,
      "requires": {
        "arr-flatten": "^1.1.0",
        "array-unique": "^0.3.2",
        "extend-shallow": "^2.0.1",
        "fill-range": "^4.0.0",
        "isobject": "^3.0.1",
        "repeat-element": "^1.1.2",
        "snapdragon": "^0.8.1",
        "snapdragon-node": "^2.0.1",
        "split-string": "^3.0.2",
        "to-regex": "^3.0.1"
      },
      "dependencies": {
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        }
      }
    },
    "brorand": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/brorand/-/brorand-1.1.0.tgz",
      "integrity": "sha1-EsJe/kCkXjwyPrhnWgoM5XsiNx8=",
      "dev": true
    },
    "browser-pack": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/browser-pack/-/browser-pack-6.1.0.tgz",
      "integrity": "sha512-erYug8XoqzU3IfcU8fUgyHqyOXqIE4tUTTQ+7mqUjQlvnXkOO6OlT9c/ZoJVHYoAaqGxr09CN53G7XIsO4KtWA==",
      "dev": true,
      "requires": {
        "JSONStream": "^1.0.3",
        "combine-source-map": "~0.8.0",
        "defined": "^1.0.0",
        "safe-buffer": "^5.1.1",
        "through2": "^2.0.0",
        "umd": "^3.0.0"
      }
    },
    "browser-process-hrtime": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/browser-process-hrtime/-/browser-process-hrtime-0.1.3.tgz",
      "integrity": "sha512-bRFnI4NnjO6cnyLmOV/7PVoDEMJChlcfN0z4s1YMBY989/SvlfMI1lgCnkFUs53e9gQF+w7qu7XdllSTiSl8Aw==",
      "dev": true
    },
    "browser-resolve": {
      "version": "1.11.3",
      "resolved": "https://registry.npmjs.org/browser-resolve/-/browser-resolve-1.11.3.tgz",
      "integrity": "sha512-exDi1BYWB/6raKHmDTCicQfTkqwN5fioMFV4j8BsfMU4R2DK/QfZfK7kOVkmWCNANf0snkBzqGqAJBao9gZMdQ==",
      "dev": true,
      "requires": {
        "resolve": "1.1.7"
      }
    },
    "browserify": {
      "version": "16.2.3",
      "resolved": "https://registry.npmjs.org/browserify/-/browserify-16.2.3.tgz",
      "integrity": "sha512-zQt/Gd1+W+IY+h/xX2NYMW4orQWhqSwyV+xsblycTtpOuB27h1fZhhNQuipJ4t79ohw4P4mMem0jp/ZkISQtjQ==",
      "dev": true,
      "requires": {
        "JSONStream": "^1.0.3",
        "assert": "^1.4.0",
        "browser-pack": "^6.0.1",
        "browser-resolve": "^1.11.0",
        "browserify-zlib": "~0.2.0",
        "buffer": "^5.0.2",
        "cached-path-relative": "^1.0.0",
        "concat-stream": "^1.6.0",
        "console-browserify": "^1.1.0",
        "constants-browserify": "~1.0.0",
        "crypto-browserify": "^3.0.0",
        "defined": "^1.0.0",
        "deps-sort": "^2.0.0",
        "domain-browser": "^1.2.0",
        "duplexer2": "~0.1.2",
        "events": "^2.0.0",
        "glob": "^7.1.0",
        "has": "^1.0.0",
        "htmlescape": "^1.1.0",
        "https-browserify": "^1.0.0",
        "inherits": "~2.0.1",
        "insert-module-globals": "^7.0.0",
        "labeled-stream-splicer": "^2.0.0",
        "mkdirp": "^0.5.0",
        "module-deps": "^6.0.0",
        "os-browserify": "~0.3.0",
        "parents": "^1.0.1",
        "path-browserify": "~0.0.0",
        "process": "~0.11.0",
        "punycode": "^1.3.2",
        "querystring-es3": "~0.2.0",
        "read-only-stream": "^2.0.0",
        "readable-stream": "^2.0.2",
        "resolve": "^1.1.4",
        "shasum": "^1.0.0",
        "shell-quote": "^1.6.1",
        "stream-browserify": "^2.0.0",
        "stream-http": "^2.0.0",
        "string_decoder": "^1.1.1",
        "subarg": "^1.0.0",
        "syntax-error": "^1.1.1",
        "through2": "^2.0.0",
        "timers-browserify": "^1.0.1",
        "tty-browserify": "0.0.1",
        "url": "~0.11.0",
        "util": "~0.10.1",
        "vm-browserify": "^1.0.0",
        "xtend": "^4.0.0"
      },
      "dependencies": {
        "punycode": {
          "version": "1.4.1",
          "resolved": "https://registry.npmjs.org/punycode/-/punycode-1.4.1.tgz",
          "integrity": "sha1-wNWmOycYgArY4esPpSachN1BhF4=",
          "dev": true
        }
      }
    },
    "browserify-aes": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/browserify-aes/-/browserify-aes-1.2.0.tgz",
      "integrity": "sha512-+7CHXqGuspUn/Sl5aO7Ea0xWGAtETPXNSAjHo48JfLdPWcMng33Xe4znFvQweqc/uzk5zSOI3H52CYnjCfb5hA==",
      "dev": true,
      "requires": {
        "buffer-xor": "^1.0.3",
        "cipher-base": "^1.0.0",
        "create-hash": "^1.1.0",
        "evp_bytestokey": "^1.0.3",
        "inherits": "^2.0.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "browserify-cipher": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/browserify-cipher/-/browserify-cipher-1.0.1.tgz",
      "integrity": "sha512-sPhkz0ARKbf4rRQt2hTpAHqn47X3llLkUGn+xEJzLjwY8LRs2p0v7ljvI5EyoRO/mexrNunNECisZs+gw2zz1w==",
      "dev": true,
      "requires": {
        "browserify-aes": "^1.0.4",
        "browserify-des": "^1.0.0",
        "evp_bytestokey": "^1.0.0"
      }
    },
    "browserify-des": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/browserify-des/-/browserify-des-1.0.2.tgz",
      "integrity": "sha512-BioO1xf3hFwz4kc6iBhI3ieDFompMhrMlnDFC4/0/vd5MokpuAc3R+LYbwTA9A5Yc9pq9UYPqffKpW2ObuwX5A==",
      "dev": true,
      "requires": {
        "cipher-base": "^1.0.1",
        "des.js": "^1.0.0",
        "inherits": "^2.0.1",
        "safe-buffer": "^5.1.2"
      }
    },
    "browserify-rsa": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/browserify-rsa/-/browserify-rsa-4.0.1.tgz",
      "integrity": "sha1-IeCr+vbyApzy+vsTNWenAdQTVSQ=",
      "dev": true,
      "requires": {
        "bn.js": "^4.1.0",
        "randombytes": "^2.0.1"
      }
    },
    "browserify-sign": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/browserify-sign/-/browserify-sign-4.0.4.tgz",
      "integrity": "sha1-qk62jl17ZYuqa/alfmMMvXqT0pg=",
      "dev": true,
      "requires": {
        "bn.js": "^4.1.1",
        "browserify-rsa": "^4.0.0",
        "create-hash": "^1.1.0",
        "create-hmac": "^1.1.2",
        "elliptic": "^6.0.0",
        "inherits": "^2.0.1",
        "parse-asn1": "^5.0.0"
      }
    },
    "browserify-zlib": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/browserify-zlib/-/browserify-zlib-0.2.0.tgz",
      "integrity": "sha512-Z942RysHXmJrhqk88FmKBVq/v5tqmSkDz7p54G/MGyjMnCFFnC79XWNbg+Vta8W6Wb2qtSZTSxIGkJrRpCFEiA==",
      "dev": true,
      "requires": {
        "pako": "~1.0.5"
      }
    },
    "browserslist": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.4.1.tgz",
      "integrity": "sha512-pEBxEXg7JwaakBXjATYw/D1YZh4QUSCX/Mnd/wnqSRPPSi1U39iDhDoKGoBUcraKdxDlrYqJxSI5nNvD+dWP2A==",
      "dev": true,
      "requires": {
        "caniuse-lite": "^1.0.30000929",
        "electron-to-chromium": "^1.3.103",
        "node-releases": "^1.1.3"
      }
    },
    "bs58": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/bs58/-/bs58-4.0.1.tgz",
      "integrity": "sha1-vhYedsNU9veIrkBx9j806MTwpCo=",
      "requires": {
        "base-x": "^3.0.2"
      }
    },
    "bser": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/bser/-/bser-2.0.0.tgz",
      "integrity": "sha1-mseNPtXZFYBP2HrLFYvHlxR6Fxk=",
      "dev": true,
      "requires": {
        "node-int64": "^0.4.0"
      }
    },
    "buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/buffer/-/buffer-5.2.1.tgz",
      "integrity": "sha512-c+Ko0loDaFfuPWiL02ls9Xd3GO3cPVmUobQ6t3rXNUk304u6hGq+8N/kFi+QEIKhzK3uwolVhLzszmfLmMLnqg==",
      "dev": true,
      "requires": {
        "base64-js": "^1.0.2",
        "ieee754": "^1.1.4"
      }
    },
    "buffer-equal": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/buffer-equal/-/buffer-equal-1.0.0.tgz",
      "integrity": "sha1-WWFrSYME1Var1GaWayLu2j7KX74=",
      "dev": true
    },
    "buffer-from": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.1.tgz",
      "integrity": "sha512-MQcXEUbCKtEo7bhqEs6560Hyd4XaovZlO/k9V3hjVUF/zwW7KBVdSK4gIt/bzwS9MbR5qob+F5jusZsb0YQK2A==",
      "dev": true
    },
    "buffer-shims": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/buffer-shims/-/buffer-shims-1.0.0.tgz",
      "integrity": "sha1-mXjOMXOIxkmth5MCjDR37wRKi1E=",
      "dev": true
    },
    "buffer-xor": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/buffer-xor/-/buffer-xor-1.0.3.tgz",
      "integrity": "sha1-JuYe0UIvtw3ULm42cp7VHYVf6Nk=",
      "dev": true
    },
    "builtin-modules": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/builtin-modules/-/builtin-modules-1.1.1.tgz",
      "integrity": "sha1-Jw8HbFpywC9bZaR9+Uxf46J4iS8=",
      "dev": true
    },
    "builtin-status-codes": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/builtin-status-codes/-/builtin-status-codes-3.0.0.tgz",
      "integrity": "sha1-hZgoeOIbmOHGZCXgPQF0eI9Wnug=",
      "dev": true
    },
    "bytes": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/bytes/-/bytes-1.0.0.tgz",
      "integrity": "sha1-NWnt6Lo0MV+rmcPpLLBMciDeH6g=",
      "dev": true
    },
    "cache-base": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/cache-base/-/cache-base-1.0.1.tgz",
      "integrity": "sha512-AKcdTnFSWATd5/GCPRxr2ChwIJ85CeyrEyjRHlKxQ56d4XJMGym0uAiKn0xbLOGOl3+yRpOTi484dVCEc5AUzQ==",
      "dev": true,
      "requires": {
        "collection-visit": "^1.0.0",
        "component-emitter": "^1.2.1",
        "get-value": "^2.0.6",
        "has-value": "^1.0.0",
        "isobject": "^3.0.1",
        "set-value": "^2.0.0",
        "to-object-path": "^0.3.0",
        "union-value": "^1.0.0",
        "unset-value": "^1.0.0"
      },
      "dependencies": {
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "cached-path-relative": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/cached-path-relative/-/cached-path-relative-1.0.2.tgz",
      "integrity": "sha512-5r2GqsoEb4qMTTN9J+WzXfjov+hjxT+j3u5K+kIVNIwAd99DLCJE9pBIMP1qVeybV6JiijL385Oz0DcYxfbOIg==",
      "dev": true
    },
    "callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true
    },
    "camelcase": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-4.1.0.tgz",
      "integrity": "sha1-1UVjW+HjPFQmScaRc+Xeas+uNN0=",
      "dev": true
    },
    "caniuse-lite": {
      "version": "1.0.30000930",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30000930.tgz",
      "integrity": "sha512-KD+pw9DderBLB8CGqBzYyFWpnrPVOEjsjargU/CvkNyg60od3cxSPTcTeMPhxJhDbkQPWvOz5BAyBzNl/St9vg==",
      "dev": true
    },
    "capability": {
      "version": "0.2.5",
      "resolved": "https://registry.npmjs.org/capability/-/capability-0.2.5.tgz",
      "integrity": "sha1-Ua2HNT8ZNv/Xfy8hx0YzpN6oiAE="
    },
    "capture-exit": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/capture-exit/-/capture-exit-2.0.0.tgz",
      "integrity": "sha512-PiT/hQmTonHhl/HFGN+Lx3JJUznrVYJ3+AQsnthneZbvW7x+f08Tk7yLJTLEOUvBTbduLeeBkxEaYXUOUrRq6g==",
      "dev": true,
      "requires": {
        "rsvp": "^4.8.4"
      }
    },
    "caseless": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/caseless/-/caseless-0.12.0.tgz",
      "integrity": "sha1-G2gcIf+EAzyCZUMJBolCDRhxUdw=",
      "dev": true
    },
    "ccount": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/ccount/-/ccount-1.0.3.tgz",
      "integrity": "sha512-Jt9tIBkRc9POUof7QA/VwWd+58fKkEEfI+/t1/eOlxKM7ZhrczNzMFefge7Ai+39y1pR/pP6cI19guHy3FSLmw==",
      "dev": true
    },
    "chalk": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.1.tgz",
      "integrity": "sha512-ObN6h1v2fTJSmUXoS3nMQ92LbDK9be4TV+6G+omQlGJFdcUX5heKi1LZ1YnRMIgwTLEj3E24bT6tYni50rlCfQ==",
      "dev": true,
      "requires": {
        "ansi-styles": "^3.2.1",
        "escape-string-regexp": "^1.0.5",
        "supports-color": "^5.3.0"
      }
    },
    "character-entities": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-1.2.2.tgz",
      "integrity": "sha512-sMoHX6/nBiy3KKfC78dnEalnpn0Az0oSNvqUWYTtYrhRI5iUIYsROU48G+E+kMFQzqXaJ8kHJZ85n7y6/PHgwQ==",
      "dev": true
    },
    "character-entities-html4": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/character-entities-html4/-/character-entities-html4-1.1.2.tgz",
      "integrity": "sha512-sIrXwyna2+5b0eB9W149izTPJk/KkJTg6mEzDGibwBUkyH1SbDa+nf515Ppdi3MaH35lW0JFJDWeq9Luzes1Iw==",
      "dev": true
    },
    "character-entities-legacy": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-1.1.2.tgz",
      "integrity": "sha512-9NB2VbXtXYWdXzqrvAHykE/f0QJxzaKIpZ5QzNZrrgQ7Iyxr2vnfS8fCBNVW9nUEZE0lo57nxKRqnzY/dKrwlA==",
      "dev": true
    },
    "character-reference-invalid": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-1.1.2.tgz",
      "integrity": "sha512-7I/xceXfKyUJmSAn/jw8ve/9DyOP7XxufNYLI9Px7CmsKgEUaZLUTax6nZxGQtaoiZCjpu6cHPj20xC/vqRReQ==",
      "dev": true
    },
    "chardet": {
      "version": "0.7.0",
      "resolved": "https://registry.npmjs.org/chardet/-/chardet-0.7.0.tgz",
      "integrity": "sha512-mT8iDcrh03qDGRRmoA2hmBJnxpllMR+0/0qlzjqZES6NdiWDcZkCNAk4rPFZ9Q85r27unkiNNg8ZOiwZXBHwcA==",
      "dev": true
    },
    "chokidar": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-2.0.4.tgz",
      "integrity": "sha512-z9n7yt9rOvIJrMhvDtDictKrkFHeihkNl6uWMmZlmL6tJtX9Cs+87oK+teBx+JIgzvbX3yZHT3eF8vpbDxHJXQ==",
      "dev": true,
      "requires": {
        "anymatch": "^2.0.0",
        "async-each": "^1.0.0",
        "braces": "^2.3.0",
        "fsevents": "^1.2.2",
        "glob-parent": "^3.1.0",
        "inherits": "^2.0.1",
        "is-binary-path": "^1.0.0",
        "is-glob": "^4.0.0",
        "lodash.debounce": "^4.0.8",
        "normalize-path": "^2.1.1",
        "path-is-absolute": "^1.0.0",
        "readdirp": "^2.0.0",
        "upath": "^1.0.5"
      },
      "dependencies": {
        "array-unique": {
          "version": "0.3.2",
          "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
          "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
          "dev": true
        },
        "braces": {
          "version": "2.3.2",
          "resolved": "https://registry.npmjs.org/braces/-/braces-2.3.2.tgz",
          "integrity": "sha512-aNdbnj9P8PjdXU4ybaWLK2IF3jc/EoDYbC7AazW6to3TRsfXxscC9UXOB5iDiEQrkyIbWp2SLQda4+QAa7nc3w==",
          "dev": true,
          "requires": {
            "arr-flatten": "^1.1.0",
            "array-unique": "^0.3.2",
            "extend-shallow": "^2.0.1",
            "fill-range": "^4.0.0",
            "isobject": "^3.0.1",
            "repeat-element": "^1.1.2",
            "snapdragon": "^0.8.1",
            "snapdragon-node": "^2.0.1",
            "split-string": "^3.0.2",
            "to-regex": "^3.0.1"
          }
        },
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        },
        "fill-range": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-4.0.0.tgz",
          "integrity": "sha1-1USBHUKPmOsGpj3EAtJAPDKMOPc=",
          "dev": true,
          "requires": {
            "extend-shallow": "^2.0.1",
            "is-number": "^3.0.0",
            "repeat-string": "^1.6.1",
            "to-regex-range": "^2.1.0"
          }
        },
        "glob-parent": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-3.1.0.tgz",
          "integrity": "sha1-nmr2KZ2NO9K9QEMIMr0RPfkGxa4=",
          "dev": true,
          "requires": {
            "is-glob": "^3.1.0",
            "path-dirname": "^1.0.0"
          },
          "dependencies": {
            "is-glob": {
              "version": "3.1.0",
              "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-3.1.0.tgz",
              "integrity": "sha1-e6WuJCF4BKxwcHuWkiVnSGzD6Eo=",
              "dev": true,
              "requires": {
                "is-extglob": "^2.1.0"
              }
            }
          }
        },
        "is-extglob": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
          "integrity": "sha1-qIwCU1eR8C7TfHahueqXc8gz+MI=",
          "dev": true
        },
        "is-glob": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.0.tgz",
          "integrity": "sha1-lSHHaEXMJhCoUgPd8ICpWML/q8A=",
          "dev": true,
          "requires": {
            "is-extglob": "^2.1.1"
          }
        },
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "chownr": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/chownr/-/chownr-1.1.1.tgz",
      "integrity": "sha512-j38EvO5+LHX84jlo6h4UzmOwi0UgW61WRyPtJz4qaadK5eY3BTS5TY/S1Stc3Uk2lIM6TPevAlULiEJwie860g==",
      "dev": true,
      "optional": true
    },
    "ci-info": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ci-info/-/ci-info-2.0.0.tgz",
      "integrity": "sha512-5tK7EtrZ0N+OLFMthtqOj4fI2Jeb88C4CAZPu25LDVUgXJ0A3Js4PMGqrn0JU1W0Mh1/Z8wZzYPxqUrXeBboCQ==",
      "dev": true
    },
    "cipher-base": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/cipher-base/-/cipher-base-1.0.4.tgz",
      "integrity": "sha512-Kkht5ye6ZGmwv40uUDZztayT2ThLQGfnj/T71N/XzeZeo3nf8foyW7zGTsPYkEya3m5f3cAypH+qe7YOrM1U2Q==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "class-utils": {
      "version": "0.3.6",
      "resolved": "https://registry.npmjs.org/class-utils/-/class-utils-0.3.6.tgz",
      "integrity": "sha512-qOhPa/Fj7s6TY8H8esGu5QNpMMQxz79h+urzrNYN6mn+9BnxlDGf5QZ+XeCDsxSjPqsSR56XOZOJmpeurnLMeg==",
      "dev": true,
      "requires": {
        "arr-union": "^3.1.0",
        "define-property": "^0.2.5",
        "isobject": "^3.0.0",
        "static-extend": "^0.1.1"
      },
      "dependencies": {
        "define-property": {
          "version": "0.2.5",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
          "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^0.1.0"
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "cli-cursor": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/cli-cursor/-/cli-cursor-2.1.0.tgz",
      "integrity": "sha1-s12sN2R5+sw+lHR9QdDQ9SOP/LU=",
      "dev": true,
      "requires": {
        "restore-cursor": "^2.0.0"
      }
    },
    "cli-table3": {
      "version": "0.5.1",
      "resolved": "https://registry.npmjs.org/cli-table3/-/cli-table3-0.5.1.tgz",
      "integrity": "sha512-7Qg2Jrep1S/+Q3EceiZtQcDPWxhAvBw+ERf1162v4sikJrvojMHFqXt8QIVha8UlH9rgU0BeWPytZ9/TzYqlUw==",
      "dev": true,
      "requires": {
        "colors": "^1.1.2",
        "object-assign": "^4.1.0",
        "string-width": "^2.1.1"
      }
    },
    "cli-width": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/cli-width/-/cli-width-2.2.0.tgz",
      "integrity": "sha1-/xnt6Kml5XkyQUewwR8PvLq+1jk=",
      "dev": true
    },
    "cliui": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/cliui/-/cliui-4.1.0.tgz",
      "integrity": "sha512-4FG+RSG9DL7uEwRUZXZn3SS34DiDPfzP0VOiEwtUWlE+AR2EIg+hSyvrIgUUfhdgR/UkAeW2QHgeP+hWrXs7jQ==",
      "dev": true,
      "requires": {
        "string-width": "^2.1.1",
        "strip-ansi": "^4.0.0",
        "wrap-ansi": "^2.0.0"
      }
    },
    "clone": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/clone/-/clone-2.1.2.tgz",
      "integrity": "sha1-G39Ln1kfHo+DZwQBYANFoCiHQ18=",
      "dev": true
    },
    "clone-buffer": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/clone-buffer/-/clone-buffer-1.0.0.tgz",
      "integrity": "sha1-4+JbIHrE5wGvch4staFnksrD3Fg=",
      "dev": true
    },
    "clone-stats": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/clone-stats/-/clone-stats-1.0.0.tgz",
      "integrity": "sha1-s3gt/4u1R04Yuba/D9/ngvh3doA=",
      "dev": true
    },
    "cloneable-readable": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/cloneable-readable/-/cloneable-readable-1.1.2.tgz",
      "integrity": "sha512-Bq6+4t+lbM8vhTs/Bef5c5AdEMtapp/iFb6+s4/Hh9MVTt8OLKH7ZOOZSCT+Ys7hsHvqv0GuMPJ1lnQJVHvxpg==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "process-nextick-args": "^2.0.0",
        "readable-stream": "^2.3.5"
      }
    },
    "co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha1-bqa989hTrlTMuOR7+gvz+QMfsYQ=",
      "dev": true
    },
    "code-point-at": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/code-point-at/-/code-point-at-1.1.0.tgz",
      "integrity": "sha1-DQcLTQQ6W+ozovGkDi7bPZpMz3c=",
      "dev": true
    },
    "collapse-white-space": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/collapse-white-space/-/collapse-white-space-1.0.4.tgz",
      "integrity": "sha512-YfQ1tAUZm561vpYD+5eyWN8+UsceQbSrqqlc/6zDY2gtAE+uZLSdkkovhnGpmCThsvKBFakq4EdY/FF93E8XIw==",
      "dev": true
    },
    "collection-visit": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/collection-visit/-/collection-visit-1.0.0.tgz",
      "integrity": "sha1-S8A3PBZLwykbTTaMgpzxqApZ3KA=",
      "dev": true,
      "requires": {
        "map-visit": "^1.0.0",
        "object-visit": "^1.0.0"
      }
    },
    "color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "dev": true,
      "requires": {
        "color-name": "1.1.3"
      }
    },
    "color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha1-p9BVi9icQveV3UIyj3QIMcpTvCU=",
      "dev": true
    },
    "colors": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/colors/-/colors-1.3.3.tgz",
      "integrity": "sha512-mmGt/1pZqYRjMxB1axhTo16/snVZ5krrKkcmMeVKxzECMMXoCgnvTPp10QgHfcbQZw8Dq2jMNG6je4JlWU0gWg==",
      "dev": true
    },
    "combine-source-map": {
      "version": "0.8.0",
      "resolved": "https://registry.npmjs.org/combine-source-map/-/combine-source-map-0.8.0.tgz",
      "integrity": "sha1-pY0N8ELBhvz4IqjoAV9UUNLXmos=",
      "dev": true,
      "requires": {
        "convert-source-map": "~1.1.0",
        "inline-source-map": "~0.6.0",
        "lodash.memoize": "~3.0.3",
        "source-map": "~0.5.3"
      },
      "dependencies": {
        "convert-source-map": {
          "version": "1.1.3",
          "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-1.1.3.tgz",
          "integrity": "sha1-SCnId+n+SbMWHzvzZziI4gRpmGA=",
          "dev": true
        }
      }
    },
    "combined-stream": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.7.tgz",
      "integrity": "sha512-brWl9y6vOB1xYPZcpZde3N9zDByXTosAeMDo4p1wzo6UMOX4vumB+TP1RZ76sfE6Md68Q0NJSrE/gbezd4Ul+w==",
      "dev": true,
      "requires": {
        "delayed-stream": "~1.0.0"
      }
    },
    "comma-separated-tokens": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-1.0.5.tgz",
      "integrity": "sha512-Cg90/fcK93n0ecgYTAz1jaA3zvnQ0ExlmKY1rdbyHqAx6BHxwoJc+J7HDu0iuQ7ixEs1qaa+WyQ6oeuBpYP1iA==",
      "dev": true,
      "requires": {
        "trim": "0.0.1"
      }
    },
    "commander": {
      "version": "2.17.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-2.17.1.tgz",
      "integrity": "sha512-wPMUt6FnH2yzG95SA6mzjQOEKUU3aLaDEmzs1ti+1E9h+CsrZghRlqEM/EJ4KscsQVG8uNN4uVreUeT8+drlgg==",
      "dev": true
    },
    "compare-versions": {
      "version": "3.4.0",
      "resolved": "https://registry.npmjs.org/compare-versions/-/compare-versions-3.4.0.tgz",
      "integrity": "sha512-tK69D7oNXXqUW3ZNo/z7NXTEz22TCF0pTE+YF9cxvaAM9XnkLo1fV621xCLrRR6aevJlKxExkss0vWqUCUpqdg==",
      "dev": true
    },
    "component-emitter": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/component-emitter/-/component-emitter-1.2.1.tgz",
      "integrity": "sha1-E3kY1teCg/ffemt8WmPhQOaUJeY=",
      "dev": true
    },
    "concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha1-2Klr13/Wjfd5OnMDajug1UBdR3s=",
      "dev": true
    },
    "concat-stream": {
      "version": "1.6.2",
      "resolved": "https://registry.npmjs.org/concat-stream/-/concat-stream-1.6.2.tgz",
      "integrity": "sha512-27HBghJxjiZtIk3Ycvn/4kbJk/1uZuJFfuPEns6LaEvpvG1f0hTea8lilrouyo9mVc2GWdcEZ8OLoGmSADlrCw==",
      "dev": true,
      "requires": {
        "buffer-from": "^1.0.0",
        "inherits": "^2.0.3",
        "readable-stream": "^2.2.2",
        "typedarray": "^0.0.6"
      }
    },
    "console-browserify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/console-browserify/-/console-browserify-1.1.0.tgz",
      "integrity": "sha1-8CQcRXMKn8YyOyBtvzjtx0HQuxA=",
      "dev": true,
      "requires": {
        "date-now": "^0.1.4"
      }
    },
    "constants-browserify": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/constants-browserify/-/constants-browserify-1.0.0.tgz",
      "integrity": "sha1-wguW2MYXdIqvHBYCF2DNJ/y4y3U=",
      "dev": true
    },
    "continuable-cache": {
      "version": "0.3.1",
      "resolved": "https://registry.npmjs.org/continuable-cache/-/continuable-cache-0.3.1.tgz",
      "integrity": "sha1-vXJ6f67XfnH/OYWskzUakSczrQ8=",
      "dev": true
    },
    "convert-source-map": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-1.6.0.tgz",
      "integrity": "sha512-eFu7XigvxdZ1ETfbgPBohgyQ/Z++C0eEhTor0qRwBw9unw+L0/6V8wkSuGgzdThkiS5lSpdptOQPD8Ak40a+7A==",
      "dev": true,
      "requires": {
        "safe-buffer": "~5.1.1"
      }
    },
    "copy-descriptor": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/copy-descriptor/-/copy-descriptor-0.1.1.tgz",
      "integrity": "sha1-Z29us8OZl8LuGsOpJP1hJHSPV40=",
      "dev": true
    },
    "core-util-is": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
      "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac=",
      "dev": true
    },
    "create-ecdh": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/create-ecdh/-/create-ecdh-4.0.3.tgz",
      "integrity": "sha512-GbEHQPMOswGpKXM9kCWVrremUcBmjteUaQ01T9rkKCPDXfUHX0IoP9LpHYo2NPFampa4e+/pFDc3jQdxrxQLaw==",
      "dev": true,
      "requires": {
        "bn.js": "^4.1.0",
        "elliptic": "^6.0.0"
      }
    },
    "create-hash": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/create-hash/-/create-hash-1.2.0.tgz",
      "integrity": "sha512-z00bCGNHDG8mHAkP7CtT1qVu+bFQUPjYq/4Iv3C3kWjTFV10zIjfSoeqXo9Asws8gwSHDGj/hl2u4OGIjapeCg==",
      "dev": true,
      "requires": {
        "cipher-base": "^1.0.1",
        "inherits": "^2.0.1",
        "md5.js": "^1.3.4",
        "ripemd160": "^2.0.1",
        "sha.js": "^2.4.0"
      }
    },
    "create-hmac": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/create-hmac/-/create-hmac-1.1.7.tgz",
      "integrity": "sha512-MJG9liiZ+ogc4TzUwuvbER1JRdgvUFSB5+VR/g5h82fGaIRWMWddtKBHi7/sVhfjQZ6SehlyhvQYrcYkaUIpLg==",
      "dev": true,
      "requires": {
        "cipher-base": "^1.0.3",
        "create-hash": "^1.1.0",
        "inherits": "^2.0.1",
        "ripemd160": "^2.0.0",
        "safe-buffer": "^5.0.1",
        "sha.js": "^2.4.8"
      }
    },
    "cross-spawn": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-5.1.0.tgz",
      "integrity": "sha1-6L0O/uWPz/b4+UUQoKVUu/ojVEk=",
      "dev": true,
      "requires": {
        "lru-cache": "^4.0.1",
        "shebang-command": "^1.2.0",
        "which": "^1.2.9"
      }
    },
    "crypto-browserify": {
      "version": "3.12.0",
      "resolved": "https://registry.npmjs.org/crypto-browserify/-/crypto-browserify-3.12.0.tgz",
      "integrity": "sha512-fz4spIh+znjO2VjL+IdhEpRJ3YN6sMzITSBijk6FK2UvTqruSQW+/cCZTSNsMiZNvUeq0CqurF+dAbyiGOY6Wg==",
      "dev": true,
      "requires": {
        "browserify-cipher": "^1.0.0",
        "browserify-sign": "^4.0.0",
        "create-ecdh": "^4.0.0",
        "create-hash": "^1.1.0",
        "create-hmac": "^1.1.0",
        "diffie-hellman": "^5.0.0",
        "inherits": "^2.0.1",
        "pbkdf2": "^3.0.3",
        "public-encrypt": "^4.0.0",
        "randombytes": "^2.0.0",
        "randomfill": "^1.0.3"
      }
    },
    "cssom": {
      "version": "0.3.6",
      "resolved": "https://registry.npmjs.org/cssom/-/cssom-0.3.6.tgz",
      "integrity": "sha512-DtUeseGk9/GBW0hl0vVPpU22iHL6YB5BUX7ml1hB+GMpo0NX5G4voX3kdWiMSEguFtcW3Vh3djqNF4aIe6ne0A==",
      "dev": true
    },
    "cssstyle": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/cssstyle/-/cssstyle-1.2.2.tgz",
      "integrity": "sha512-43wY3kl1CVQSvL7wUY1qXkxVGkStjpkDmVjiIKX8R97uhajy8Bybay78uOtqvh7Q5GK75dNPfW0geWjE6qQQow==",
      "dev": true,
      "requires": {
        "cssom": "0.3.x"
      }
    },
    "dashdash": {
      "version": "1.14.1",
      "resolved": "https://registry.npmjs.org/dashdash/-/dashdash-1.14.1.tgz",
      "integrity": "sha1-hTz6D3y+L+1d4gMmuN1YEDX24vA=",
      "dev": true,
      "requires": {
        "assert-plus": "^1.0.0"
      }
    },
    "data-urls": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/data-urls/-/data-urls-1.1.0.tgz",
      "integrity": "sha512-YTWYI9se1P55u58gL5GkQHW4P6VJBJ5iBT+B5a7i2Tjadhv52paJG0qHX4A0OR6/t52odI64KP2YvFpkDOi3eQ==",
      "dev": true,
      "requires": {
        "abab": "^2.0.0",
        "whatwg-mimetype": "^2.2.0",
        "whatwg-url": "^7.0.0"
      },
      "dependencies": {
        "whatwg-url": {
          "version": "7.0.0",
          "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-7.0.0.tgz",
          "integrity": "sha512-37GeVSIJ3kn1JgKyjiYNmSLP1yzbpb29jdmwBSgkD9h40/hyrR/OifpVUndji3tmwGgD8qpw7iQu3RSbCrBpsQ==",
          "dev": true,
          "requires": {
            "lodash.sortby": "^4.7.0",
            "tr46": "^1.0.1",
            "webidl-conversions": "^4.0.2"
          }
        }
      }
    },
    "date-now": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/date-now/-/date-now-0.1.4.tgz",
      "integrity": "sha1-6vQ5/U1ISK105cx9vvIAZyueNFs=",
      "dev": true
    },
    "de-indent": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/de-indent/-/de-indent-1.0.2.tgz",
      "integrity": "sha1-sgOOhG3DO6pXlhKNCAS0VbjB4h0=",
      "dev": true
    },
    "debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "dev": true,
      "requires": {
        "ms": "2.0.0"
      }
    },
    "decamelize": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/decamelize/-/decamelize-1.2.0.tgz",
      "integrity": "sha1-9lNNFRSCabIDUue+4m9QH5oZEpA=",
      "dev": true
    },
    "decode-uri-component": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/decode-uri-component/-/decode-uri-component-0.2.0.tgz",
      "integrity": "sha1-6zkTMzRYd1y4TNGh+uBiEGu4dUU=",
      "dev": true
    },
    "deep-is": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.3.tgz",
      "integrity": "sha1-s2nW+128E+7PUk+RsHD+7cNXzzQ=",
      "dev": true
    },
    "default-require-extensions": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/default-require-extensions/-/default-require-extensions-2.0.0.tgz",
      "integrity": "sha1-9fj7sYp9bVCyH2QfZJ67Uiz+JPc=",
      "dev": true,
      "requires": {
        "strip-bom": "^3.0.0"
      }
    },
    "define-properties": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.1.3.tgz",
      "integrity": "sha512-3MqfYKj2lLzdMSf8ZIZE/V+Zuy+BgD6f164e8K2w7dgnpKArBDerGYpM46IYYcjnkdPNMjPk9A6VFB8+3SKlXQ==",
      "dev": true,
      "requires": {
        "object-keys": "^1.0.12"
      }
    },
    "define-property": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/define-property/-/define-property-2.0.2.tgz",
      "integrity": "sha512-jwK2UV4cnPpbcG7+VRARKTZPUWowwXA8bzH5NP6ud0oeAxyYPuGZUAC7hMugpCdz4BeSZl2Dl9k66CHJ/46ZYQ==",
      "dev": true,
      "requires": {
        "is-descriptor": "^1.0.2",
        "isobject": "^3.0.1"
      },
      "dependencies": {
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "defined": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/defined/-/defined-1.0.0.tgz",
      "integrity": "sha1-yY2bzvdWdBiOEQlpFRGZ45sfppM=",
      "dev": true
    },
    "delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha1-3zrhmayt+31ECqrgsp4icrJOxhk=",
      "dev": true
    },
    "depd": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/depd/-/depd-1.1.2.tgz",
      "integrity": "sha1-m81S4UwJd2PnSbJ0xDRu0uVgtak="
    },
    "deps-sort": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/deps-sort/-/deps-sort-2.0.0.tgz",
      "integrity": "sha1-CRckkC6EZYJg65EHSMzNGvbiH7U=",
      "dev": true,
      "requires": {
        "JSONStream": "^1.0.3",
        "shasum": "^1.0.0",
        "subarg": "^1.0.0",
        "through2": "^2.0.0"
      }
    },
    "des.js": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/des.js/-/des.js-1.0.0.tgz",
      "integrity": "sha1-wHTS4qpqipoH29YfmhXCzYPsjsw=",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "minimalistic-assert": "^1.0.0"
      }
    },
    "detab": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/detab/-/detab-2.0.1.tgz",
      "integrity": "sha512-/hhdqdQc5thGrqzjyO/pz76lDZ5GSuAs6goxOaKTsvPk7HNnzAyFN5lyHgqpX4/s1i66K8qMGj+VhA9504x7DQ==",
      "dev": true,
      "requires": {
        "repeat-string": "^1.5.4"
      }
    },
    "detect-newline": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/detect-newline/-/detect-newline-2.1.0.tgz",
      "integrity": "sha1-9B8cEL5LAOh7XxPaaAdZ8sW/0+I=",
      "dev": true
    },
    "detective": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/detective/-/detective-5.1.0.tgz",
      "integrity": "sha512-TFHMqfOvxlgrfVzTEkNBSh9SvSNX/HfF4OFI2QFGCyPm02EsyILqnUeb5P6q7JZ3SFNTBL5t2sePRgrN4epUWQ==",
      "dev": true,
      "requires": {
        "acorn-node": "^1.3.0",
        "defined": "^1.0.0",
        "minimist": "^1.1.1"
      },
      "dependencies": {
        "minimist": {
          "version": "1.2.0",
          "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
          "dev": true
        }
      }
    },
    "diff-sequences": {
      "version": "24.3.0",
      "resolved": "https://registry.npmjs.org/diff-sequences/-/diff-sequences-24.3.0.tgz",
      "integrity": "sha512-xLqpez+Zj9GKSnPWS0WZw1igGocZ+uua8+y+5dDNTT934N3QuY1sp2LkHzwiaYQGz60hMq0pjAshdeXm5VUOEw==",
      "dev": true
    },
    "diffie-hellman": {
      "version": "5.0.3",
      "resolved": "https://registry.npmjs.org/diffie-hellman/-/diffie-hellman-5.0.3.tgz",
      "integrity": "sha512-kqag/Nl+f3GwyK25fhUMYj81BUOrZ9IuJsjIcDE5icNM9FJHAVm3VcUDxdLPoQtTuUylWm6ZIknYJwwaPxsUzg==",
      "dev": true,
      "requires": {
        "bn.js": "^4.1.0",
        "miller-rabin": "^4.0.0",
        "randombytes": "^2.0.0"
      }
    },
    "disparity": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/disparity/-/disparity-2.0.0.tgz",
      "integrity": "sha1-V92stHMkrl9Y0swNqIbbTOnutxg=",
      "dev": true,
      "requires": {
        "ansi-styles": "^2.0.1",
        "diff": "^1.3.2"
      },
      "dependencies": {
        "ansi-styles": {
          "version": "2.2.1",
          "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-2.2.1.tgz",
          "integrity": "sha1-tDLdM1i2NM914eRmQ2gkBTPB3b4=",
          "dev": true
        },
        "diff": {
          "version": "1.4.0",
          "resolved": "https://registry.npmjs.org/diff/-/diff-1.4.0.tgz",
          "integrity": "sha1-fyjS657nsVqX79ic5j3P2qPMur8=",
          "dev": true
        }
      }
    },
    "doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "requires": {
        "esutils": "^2.0.2"
      }
    },
    "doctrine-temporary-fork": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/doctrine-temporary-fork/-/doctrine-temporary-fork-2.0.1.tgz",
      "integrity": "sha512-+GQh3niRkKtSr7cKDo8po+NHkJZyC2Ebwvjz9fvq0ReQr9kIDS6BY9MDrzx+KbbLxvSj3vD/eUaeIoURHzEAFQ==",
      "dev": true,
      "requires": {
        "esutils": "^2.0.2"
      }
    },
    "documentation": {
      "version": "9.1.1",
      "resolved": "https://registry.npmjs.org/documentation/-/documentation-9.1.1.tgz",
      "integrity": "sha512-oSTBZXBlrJpRMXCzXdd1j8CQ+miJHTIZeEZ3oCU/NgIImKTBG3nHIPPSZRPA35cJGWN9L3uQK7eF6vS82QJlgg==",
      "dev": true,
      "requires": {
        "@babel/core": "^7.1.2",
        "@babel/generator": "^7.1.3",
        "@babel/parser": "7.1.3",
        "@babel/plugin-proposal-class-properties": "^7.1.0",
        "@babel/plugin-proposal-decorators": "^7.1.2",
        "@babel/plugin-proposal-do-expressions": "^7.0.0",
        "@babel/plugin-proposal-export-default-from": "^7.0.0",
        "@babel/plugin-proposal-export-namespace-from": "^7.0.0",
        "@babel/plugin-proposal-function-bind": "^7.0.0",
        "@babel/plugin-proposal-function-sent": "^7.1.0",
        "@babel/plugin-proposal-json-strings": "^7.0.0",
        "@babel/plugin-proposal-logical-assignment-operators": "^7.0.0",
        "@babel/plugin-proposal-nullish-coalescing-operator": "^7.0.0",
        "@babel/plugin-proposal-numeric-separator": "^7.0.0",
        "@babel/plugin-proposal-optional-chaining": "^7.0.0",
        "@babel/plugin-proposal-pipeline-operator": "^7.0.0",
        "@babel/plugin-proposal-throw-expressions": "^7.0.0",
        "@babel/plugin-syntax-dynamic-import": "^7.0.0",
        "@babel/plugin-syntax-import-meta": "^7.0.0",
        "@babel/preset-env": "^7.1.0",
        "@babel/preset-flow": "^7.0.0",
        "@babel/preset-react": "^7.0.0",
        "@babel/preset-stage-0": "^7.0.0",
        "@babel/traverse": "^7.1.4",
        "@babel/types": "^7.1.3",
        "ansi-html": "^0.0.7",
        "babelify": "^10.0.0",
        "chalk": "^2.3.0",
        "chokidar": "^2.0.4",
        "concat-stream": "^1.6.0",
        "disparity": "^2.0.0",
        "doctrine-temporary-fork": "2.0.1",
        "get-port": "^4.0.0",
        "git-url-parse": "^10.0.1",
        "github-slugger": "1.2.0",
        "glob": "^7.1.2",
        "globals-docs": "^2.4.0",
        "highlight.js": "^9.12.0",
        "js-yaml": "^3.10.0",
        "lodash": "^4.17.10",
        "mdast-util-inject": "^1.1.0",
        "micromatch": "^3.1.5",
        "mime": "^2.2.0",
        "module-deps-sortable": "5.0.0",
        "parse-filepath": "^1.0.2",
        "pify": "^4.0.0",
        "read-pkg-up": "^4.0.0",
        "remark": "^9.0.0",
        "remark-html": "^8.0.0",
        "remark-reference-links": "^4.0.1",
        "remark-toc": "^5.0.0",
        "remote-origin-url": "0.4.0",
        "resolve": "^1.8.1",
        "stream-array": "^1.1.2",
        "strip-json-comments": "^2.0.1",
        "tiny-lr": "^1.1.0",
        "unist-builder": "^1.0.2",
        "unist-util-visit": "^1.3.0",
        "vfile": "^3.0.0",
        "vfile-reporter": "^5.0.0",
        "vfile-sort": "^2.1.0",
        "vinyl": "^2.1.0",
        "vinyl-fs": "^3.0.2",
        "vue-template-compiler": "^2.5.16",
        "yargs": "^9.0.1"
      },
      "dependencies": {
        "arr-diff": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/arr-diff/-/arr-diff-4.0.0.tgz",
          "integrity": "sha1-1kYQdP6/7HHn4VI1dhoyml3HxSA=",
          "dev": true
        },
        "array-unique": {
          "version": "0.3.2",
          "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
          "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
          "dev": true
        },
        "braces": {
          "version": "2.3.2",
          "resolved": "https://registry.npmjs.org/braces/-/braces-2.3.2.tgz",
          "integrity": "sha512-aNdbnj9P8PjdXU4ybaWLK2IF3jc/EoDYbC7AazW6to3TRsfXxscC9UXOB5iDiEQrkyIbWp2SLQda4+QAa7nc3w==",
          "dev": true,
          "requires": {
            "arr-flatten": "^1.1.0",
            "array-unique": "^0.3.2",
            "extend-shallow": "^2.0.1",
            "fill-range": "^4.0.0",
            "isobject": "^3.0.1",
            "repeat-element": "^1.1.2",
            "snapdragon": "^0.8.1",
            "snapdragon-node": "^2.0.1",
            "split-string": "^3.0.2",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "cliui": {
          "version": "3.2.0",
          "resolved": "https://registry.npmjs.org/cliui/-/cliui-3.2.0.tgz",
          "integrity": "sha1-EgYBU3qRbSmUD5NNo7SNWFo5IT0=",
          "dev": true,
          "requires": {
            "string-width": "^1.0.1",
            "strip-ansi": "^3.0.1",
            "wrap-ansi": "^2.0.0"
          },
          "dependencies": {
            "string-width": {
              "version": "1.0.2",
              "resolved": "https://registry.npmjs.org/string-width/-/string-width-1.0.2.tgz",
              "integrity": "sha1-EYvfW4zcUaKn5w0hHgfisLmxB9M=",
              "dev": true,
              "requires": {
                "code-point-at": "^1.0.0",
                "is-fullwidth-code-point": "^1.0.0",
                "strip-ansi": "^3.0.0"
              }
            }
          }
        },
        "detective": {
          "version": "4.7.1",
          "resolved": "https://registry.npmjs.org/detective/-/detective-4.7.1.tgz",
          "integrity": "sha512-H6PmeeUcZloWtdt4DAkFyzFL94arpHr3NOwwmVILFiy+9Qd4JTxxXrzfyGk/lmct2qVGBwTSwSXagqu2BxmWig==",
          "dev": true,
          "requires": {
            "acorn": "^5.2.1",
            "defined": "^1.0.0"
          }
        },
        "expand-brackets": {
          "version": "2.1.4",
          "resolved": "https://registry.npmjs.org/expand-brackets/-/expand-brackets-2.1.4.tgz",
          "integrity": "sha1-t3c14xXOMPa27/D4OwQVGiJEliI=",
          "dev": true,
          "requires": {
            "debug": "^2.3.3",
            "define-property": "^0.2.5",
            "extend-shallow": "^2.0.1",
            "posix-character-classes": "^0.1.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "0.2.5",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
              "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^0.1.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            },
            "is-accessor-descriptor": {
              "version": "0.1.6",
              "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-0.1.6.tgz",
              "integrity": "sha1-qeEss66Nh2cn7u84Q/igiXtcmNY=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-data-descriptor": {
              "version": "0.1.4",
              "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-0.1.4.tgz",
              "integrity": "sha1-C17mSDiOLIYCgueT8YVv7D8wG1Y=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-descriptor": {
              "version": "0.1.6",
              "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-0.1.6.tgz",
              "integrity": "sha512-avDYr0SB3DwO9zsMov0gKCESFYqCnE4hq/4z3TdUlukEy5t9C0YRq7HLrsN52NAcqXKaepeCD0n+B0arnVG3Hg==",
              "dev": true,
              "requires": {
                "is-accessor-descriptor": "^0.1.6",
                "is-data-descriptor": "^0.1.4",
                "kind-of": "^5.0.0"
              }
            },
            "kind-of": {
              "version": "5.1.0",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-5.1.0.tgz",
              "integrity": "sha512-NGEErnH6F2vUuXDh+OlbcKW7/wOcfdRHaZ7VWtqCztfHri/++YKmP51OdWeGPuqCOba6kk2OTe5d02VmTB80Pw==",
              "dev": true
            }
          }
        },
        "extglob": {
          "version": "2.0.4",
          "resolved": "https://registry.npmjs.org/extglob/-/extglob-2.0.4.tgz",
          "integrity": "sha512-Nmb6QXkELsuBr24CJSkilo6UHHgbekK5UiZgfE6UHD3Eb27YC6oD+bhcT+tJ6cl8dmsgdQxnWlcry8ksBIBLpw==",
          "dev": true,
          "requires": {
            "array-unique": "^0.3.2",
            "define-property": "^1.0.0",
            "expand-brackets": "^2.1.4",
            "extend-shallow": "^2.0.1",
            "fragment-cache": "^0.2.1",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "1.0.0",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
              "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^1.0.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "fill-range": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-4.0.0.tgz",
          "integrity": "sha1-1USBHUKPmOsGpj3EAtJAPDKMOPc=",
          "dev": true,
          "requires": {
            "extend-shallow": "^2.0.1",
            "is-number": "^3.0.0",
            "repeat-string": "^1.6.1",
            "to-regex-range": "^2.1.0"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "is-fullwidth-code-point": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-1.0.0.tgz",
          "integrity": "sha1-754xOG8DGn8NZDr4L95QxFfvAMs=",
          "dev": true,
          "requires": {
            "number-is-nan": "^1.0.0"
          }
        },
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          },
          "dependencies": {
            "kind-of": {
              "version": "3.2.2",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
              "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
              "dev": true,
              "requires": {
                "is-buffer": "^1.1.5"
              }
            }
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        },
        "load-json-file": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/load-json-file/-/load-json-file-4.0.0.tgz",
          "integrity": "sha1-L19Fq5HjMhYjT9U62rZo607AmTs=",
          "dev": true,
          "requires": {
            "graceful-fs": "^4.1.2",
            "parse-json": "^4.0.0",
            "pify": "^3.0.0",
            "strip-bom": "^3.0.0"
          },
          "dependencies": {
            "pify": {
              "version": "3.0.0",
              "resolved": "https://registry.npmjs.org/pify/-/pify-3.0.0.tgz",
              "integrity": "sha1-5aSs0sEB/fPZpNB/DbxNtJ3SgXY=",
              "dev": true
            }
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "micromatch": {
          "version": "3.1.10",
          "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-3.1.10.tgz",
          "integrity": "sha512-MWikgl9n9M3w+bpsY3He8L+w9eF9338xRl8IAO5viDizwSzziFEyUzo2xrrloB64ADbTf8uA8vRqqttDTOmccg==",
          "dev": true,
          "requires": {
            "arr-diff": "^4.0.0",
            "array-unique": "^0.3.2",
            "braces": "^2.3.1",
            "define-property": "^2.0.2",
            "extend-shallow": "^3.0.2",
            "extglob": "^2.0.4",
            "fragment-cache": "^0.2.1",
            "kind-of": "^6.0.2",
            "nanomatch": "^1.2.9",
            "object.pick": "^1.3.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.2"
          }
        },
        "module-deps-sortable": {
          "version": "5.0.0",
          "resolved": "https://registry.npmjs.org/module-deps-sortable/-/module-deps-sortable-5.0.0.tgz",
          "integrity": "sha512-bnGGeghQmz/t/6771/KC4FmxpVm126iR6AAzzq4N6hVZQVl4+ZZBv+VF3PJmDyxXtVtgcgTSSP7NL+jq1QAHrg==",
          "dev": true,
          "requires": {
            "JSONStream": "^1.0.3",
            "browser-resolve": "^1.7.0",
            "cached-path-relative": "^1.0.0",
            "concat-stream": "~1.5.0",
            "defined": "^1.0.0",
            "detective": "^4.0.0",
            "duplexer2": "^0.1.2",
            "inherits": "^2.0.1",
            "readable-stream": "^2.0.2",
            "resolve": "^1.1.3",
            "stream-combiner2": "^1.1.1",
            "subarg": "^1.0.0",
            "through2": "^2.0.0",
            "xtend": "^4.0.0"
          },
          "dependencies": {
            "concat-stream": {
              "version": "1.5.2",
              "resolved": "https://registry.npmjs.org/concat-stream/-/concat-stream-1.5.2.tgz",
              "integrity": "sha1-cIl4Yk2FavQaWnQd790mHadSwmY=",
              "dev": true,
              "requires": {
                "inherits": "~2.0.1",
                "readable-stream": "~2.0.0",
                "typedarray": "~0.0.5"
              },
              "dependencies": {
                "readable-stream": {
                  "version": "2.0.6",
                  "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.0.6.tgz",
                  "integrity": "sha1-j5A0HmilPMySh4jaz80Rs265t44=",
                  "dev": true,
                  "requires": {
                    "core-util-is": "~1.0.0",
                    "inherits": "~2.0.1",
                    "isarray": "~1.0.0",
                    "process-nextick-args": "~1.0.6",
                    "string_decoder": "~0.10.x",
                    "util-deprecate": "~1.0.1"
                  }
                }
              }
            }
          }
        },
        "p-limit": {
          "version": "2.1.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.1.0.tgz",
          "integrity": "sha512-NhURkNcrVB+8hNfLuysU8enY5xn2KXphsHBaC2YmRNTZRc7RWusw6apSpdEj3jo4CMb6W9nrF6tTnsJsJeyu6g==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.0.0.tgz",
          "integrity": "sha512-hMp0onDKIajHfIkdRk3P4CdCmErkYAxxDtP3Wx/4nZ3aGlau2VKh3mZpcuFkH27WQkL/3WBCPOktzA9ZOAnMQQ==",
          "dev": true
        },
        "parse-json": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-4.0.0.tgz",
          "integrity": "sha1-vjX1Qlvh9/bHRxhPmKeIy5lHfuA=",
          "dev": true,
          "requires": {
            "error-ex": "^1.3.1",
            "json-parse-better-errors": "^1.0.1"
          }
        },
        "path-type": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/path-type/-/path-type-3.0.0.tgz",
          "integrity": "sha512-T2ZUsdZFHgA3u4e5PfPbjd7HDDpxPnQb5jN0SrDsjNSuVXHJqtwTnWqG0B1jZrgmJ/7lj1EmVIByWt1gxGkWvg==",
          "dev": true,
          "requires": {
            "pify": "^3.0.0"
          },
          "dependencies": {
            "pify": {
              "version": "3.0.0",
              "resolved": "https://registry.npmjs.org/pify/-/pify-3.0.0.tgz",
              "integrity": "sha1-5aSs0sEB/fPZpNB/DbxNtJ3SgXY=",
              "dev": true
            }
          }
        },
        "pify": {
          "version": "4.0.1",
          "resolved": "https://registry.npmjs.org/pify/-/pify-4.0.1.tgz",
          "integrity": "sha512-uB80kBFb/tfd68bVleG9T5GGsGPjJrLAUpR5PZIrhBnIaRTQRjqdJSsIKkOP6OAIFbj7GOrcudc5pNjZ+geV2g==",
          "dev": true
        },
        "process-nextick-args": {
          "version": "1.0.7",
          "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-1.0.7.tgz",
          "integrity": "sha1-FQ4gt1ZZCtP5EJPyWk8q2L/zC6M=",
          "dev": true
        },
        "read-pkg": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/read-pkg/-/read-pkg-3.0.0.tgz",
          "integrity": "sha1-nLxoaXj+5l0WwA4rGcI3/Pbjg4k=",
          "dev": true,
          "requires": {
            "load-json-file": "^4.0.0",
            "normalize-package-data": "^2.3.2",
            "path-type": "^3.0.0"
          }
        },
        "read-pkg-up": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/read-pkg-up/-/read-pkg-up-4.0.0.tgz",
          "integrity": "sha512-6etQSH7nJGsK0RbG/2TeDzZFa8shjQ1um+SwQQ5cwKy0dhSXdOncEhb1CPpvQG4h7FyOV6EB6YlV0yJvZQNAkA==",
          "dev": true,
          "requires": {
            "find-up": "^3.0.0",
            "read-pkg": "^3.0.0"
          }
        },
        "resolve": {
          "version": "1.10.0",
          "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.10.0.tgz",
          "integrity": "sha512-3sUr9aq5OfSg2S9pNtPA9hL1FVEAjvfOC4leW0SNf/mpnaakz2a9femSd6LqAww2RaFctwyf1lCqnTHuF1rxDg==",
          "dev": true,
          "requires": {
            "path-parse": "^1.0.6"
          }
        },
        "string_decoder": {
          "version": "0.10.31",
          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-0.10.31.tgz",
          "integrity": "sha1-YuIDvEF2bGwoyfyEMB2rHFMQ+pQ=",
          "dev": true
        },
        "strip-ansi": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-3.0.1.tgz",
          "integrity": "sha1-ajhfuIU9lS1f8F0Oiq+UJ43GPc8=",
          "dev": true,
          "requires": {
            "ansi-regex": "^2.0.0"
          }
        },
        "strip-bom": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
          "integrity": "sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM=",
          "dev": true
        },
        "yargs": {
          "version": "9.0.1",
          "resolved": "https://registry.npmjs.org/yargs/-/yargs-9.0.1.tgz",
          "integrity": "sha1-UqzCP+7Kw0BCB47njAwAf1CF20w=",
          "dev": true,
          "requires": {
            "camelcase": "^4.1.0",
            "cliui": "^3.2.0",
            "decamelize": "^1.1.1",
            "get-caller-file": "^1.0.1",
            "os-locale": "^2.0.0",
            "read-pkg-up": "^2.0.0",
            "require-directory": "^2.1.1",
            "require-main-filename": "^1.0.1",
            "set-blocking": "^2.0.0",
            "string-width": "^2.0.0",
            "which-module": "^2.0.0",
            "y18n": "^3.2.1",
            "yargs-parser": "^7.0.0"
          },
          "dependencies": {
            "find-up": {
              "version": "2.1.0",
              "resolved": "https://registry.npmjs.org/find-up/-/find-up-2.1.0.tgz",
              "integrity": "sha1-RdG35QbHF93UgndaK3eSCjwMV6c=",
              "dev": true,
              "requires": {
                "locate-path": "^2.0.0"
              }
            },
            "load-json-file": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/load-json-file/-/load-json-file-2.0.0.tgz",
              "integrity": "sha1-eUfkIUmvgNaWy/eXvKq8/h/inKg=",
              "dev": true,
              "requires": {
                "graceful-fs": "^4.1.2",
                "parse-json": "^2.2.0",
                "pify": "^2.0.0",
                "strip-bom": "^3.0.0"
              }
            },
            "locate-path": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-2.0.0.tgz",
              "integrity": "sha1-K1aLJl7slExtnA3pw9u7ygNUzY4=",
              "dev": true,
              "requires": {
                "p-locate": "^2.0.0",
                "path-exists": "^3.0.0"
              }
            },
            "p-limit": {
              "version": "1.3.0",
              "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-1.3.0.tgz",
              "integrity": "sha512-vvcXsLAJ9Dr5rQOPk7toZQZJApBl2K4J6dANSsEuh6QI41JYcsS/qhTGa9ErIUUgK3WNQoJYvylxvjqmiqEA9Q==",
              "dev": true,
              "requires": {
                "p-try": "^1.0.0"
              }
            },
            "p-locate": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-2.0.0.tgz",
              "integrity": "sha1-IKAQOyIqcMj9OcwuWAaA893l7EM=",
              "dev": true,
              "requires": {
                "p-limit": "^1.1.0"
              }
            },
            "p-try": {
              "version": "1.0.0",
              "resolved": "https://registry.npmjs.org/p-try/-/p-try-1.0.0.tgz",
              "integrity": "sha1-y8ec26+P1CKOE/Yh8rGiN8GyB7M=",
              "dev": true
            },
            "parse-json": {
              "version": "2.2.0",
              "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-2.2.0.tgz",
              "integrity": "sha1-9ID0BDTvgHQfhGkJn43qGPVaTck=",
              "dev": true,
              "requires": {
                "error-ex": "^1.2.0"
              }
            },
            "path-type": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/path-type/-/path-type-2.0.0.tgz",
              "integrity": "sha1-8BLMuEFbcJb8LaoQVMPXI4lZTHM=",
              "dev": true,
              "requires": {
                "pify": "^2.0.0"
              }
            },
            "pify": {
              "version": "2.3.0",
              "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
              "integrity": "sha1-7RQaasBDqEnqWISY59yosVMw6Qw=",
              "dev": true
            },
            "read-pkg": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/read-pkg/-/read-pkg-2.0.0.tgz",
              "integrity": "sha1-jvHAYjxqbbDcZxPEv6xGMysjaPg=",
              "dev": true,
              "requires": {
                "load-json-file": "^2.0.0",
                "normalize-package-data": "^2.3.2",
                "path-type": "^2.0.0"
              }
            },
            "read-pkg-up": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/read-pkg-up/-/read-pkg-up-2.0.0.tgz",
              "integrity": "sha1-a3KoBImE4MQeeVEP1en6mbO1Sb4=",
              "dev": true,
              "requires": {
                "find-up": "^2.0.0",
                "read-pkg": "^2.0.0"
              }
            }
          }
        },
        "yargs-parser": {
          "version": "7.0.0",
          "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-7.0.0.tgz",
          "integrity": "sha1-jQrELxbqVd69MyyvTEA4s+P139k=",
          "dev": true,
          "requires": {
            "camelcase": "^4.1.0"
          }
        }
      }
    },
    "domain-browser": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/domain-browser/-/domain-browser-1.2.0.tgz",
      "integrity": "sha512-jnjyiM6eRyZl2H+W8Q/zLMA481hzi0eszAaBUzIVnmYVDBbnLxVNnfu1HgEBvCbL+71FrxMl3E6lpKH7Ge3OXA==",
      "dev": true
    },
    "domexception": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/domexception/-/domexception-1.0.1.tgz",
      "integrity": "sha512-raigMkn7CJNNo6Ihro1fzG7wr3fHuYVytzquZKX5n0yizGsTcYgzdIUwj1X9pK0VvjeihV+XiclP+DjwbsSKug==",
      "dev": true,
      "requires": {
        "webidl-conversions": "^4.0.2"
      }
    },
    "duplexer2": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/duplexer2/-/duplexer2-0.1.4.tgz",
      "integrity": "sha1-ixLauHjA1p4+eJEFFmKjL8a93ME=",
      "dev": true,
      "requires": {
        "readable-stream": "^2.0.2"
      }
    },
    "duplexify": {
      "version": "3.6.1",
      "resolved": "https://registry.npmjs.org/duplexify/-/duplexify-3.6.1.tgz",
      "integrity": "sha512-vM58DwdnKmty+FSPzT14K9JXb90H+j5emaR4KYbr2KTIz00WHGbWOe5ghQTx233ZCLZtrGDALzKwcjEtSt35mA==",
      "dev": true,
      "requires": {
        "end-of-stream": "^1.0.0",
        "inherits": "^2.0.1",
        "readable-stream": "^2.0.0",
        "stream-shift": "^1.0.0"
      }
    },
    "ecc-jsbn": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/ecc-jsbn/-/ecc-jsbn-0.1.2.tgz",
      "integrity": "sha1-OoOpBOVDUyh4dMVkt1SThoSamMk=",
      "dev": true,
      "requires": {
        "jsbn": "~0.1.0",
        "safer-buffer": "^2.1.0"
      }
    },
    "electron-to-chromium": {
      "version": "1.3.106",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.3.106.tgz",
      "integrity": "sha512-eXX45p4q9CRxG0G8D3ZBZYSdN3DnrcZfrFvt6VUr1u7aKITEtRY/xwWzJ/UZcWXa7DMqPu/pYwuZ6Nm+bl0GmA==",
      "dev": true
    },
    "elliptic": {
      "version": "6.4.1",
      "resolved": "https://registry.npmjs.org/elliptic/-/elliptic-6.4.1.tgz",
      "integrity": "sha512-BsXLz5sqX8OHcsh7CqBMztyXARmGQ3LWPtGjJi6DiJHq5C/qvi9P3OqgswKSDftbu8+IoI/QDTAm2fFnQ9SZSQ==",
      "dev": true,
      "requires": {
        "bn.js": "^4.4.0",
        "brorand": "^1.0.1",
        "hash.js": "^1.0.0",
        "hmac-drbg": "^1.0.0",
        "inherits": "^2.0.1",
        "minimalistic-assert": "^1.0.0",
        "minimalistic-crypto-utils": "^1.0.0"
      }
    },
    "emoji-regex": {
      "version": "6.1.1",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-6.1.1.tgz",
      "integrity": "sha1-xs0OwbBkLio8Z6ETfvxeeW2k+I4=",
      "dev": true
    },
    "end-of-stream": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/end-of-stream/-/end-of-stream-1.4.1.tgz",
      "integrity": "sha512-1MkrZNvWTKCaigbn+W15elq2BB/L22nqrSY5DKlo3X6+vclJm8Bb5djXJBmEX6fS3+zCh/F4VBK5Z2KxJt4s2Q==",
      "dev": true,
      "requires": {
        "once": "^1.4.0"
      }
    },
    "error": {
      "version": "7.0.2",
      "resolved": "https://registry.npmjs.org/error/-/error-7.0.2.tgz",
      "integrity": "sha1-pfdf/02ZJhJt2sDqXcOOaJFTywI=",
      "dev": true,
      "requires": {
        "string-template": "~0.2.1",
        "xtend": "~4.0.0"
      }
    },
    "error-ex": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/error-ex/-/error-ex-1.3.2.tgz",
      "integrity": "sha512-7dFHNmqeFSEt2ZBsCriorKnn3Z2pj+fd9kmI6QoWw4//DL+icEBfc0U7qJCisqrTsKTjw4fNFy2pW9OqStD84g==",
      "dev": true,
      "requires": {
        "is-arrayish": "^0.2.1"
      }
    },
    "error-polyfill": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/error-polyfill/-/error-polyfill-0.1.2.tgz",
      "integrity": "sha512-8uhnXlJuhFkmIfhw2tAHtWQGpXcw5rrc0dhuY3bhn8tBHvh6l0oL9VJvR2suqx9eltglKKhVPv8luPQy+UxLTA==",
      "requires": {
        "capability": "^0.2.5",
        "o3": "^1.0.3",
        "u3": "^0.1.0"
      }
    },
    "es-abstract": {
      "version": "1.13.0",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.13.0.tgz",
      "integrity": "sha512-vDZfg/ykNxQVwup/8E1BZhVzFfBxs9NqMzGcvIJrqg5k2/5Za2bWo40dK2J1pgLngZ7c+Shh8lwYtLGyrwPutg==",
      "dev": true,
      "requires": {
        "es-to-primitive": "^1.2.0",
        "function-bind": "^1.1.1",
        "has": "^1.0.3",
        "is-callable": "^1.1.4",
        "is-regex": "^1.0.4",
        "object-keys": "^1.0.12"
      }
    },
    "es-to-primitive": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.2.0.tgz",
      "integrity": "sha512-qZryBOJjV//LaxLTV6UC//WewneB3LcXOL9NP++ozKVXsIIIpm/2c13UDiD9Jp2eThsecw9m3jPqDwTyobcdbg==",
      "dev": true,
      "requires": {
        "is-callable": "^1.1.4",
        "is-date-object": "^1.0.1",
        "is-symbol": "^1.0.2"
      }
    },
    "escape-string-regexp": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-1.0.5.tgz",
      "integrity": "sha1-G2HAViGQqN/2rjuyzwIAyhMLhtQ=",
      "dev": true
    },
    "escodegen": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/escodegen/-/escodegen-1.11.1.tgz",
      "integrity": "sha512-JwiqFD9KdGVVpeuRa68yU3zZnBEOcPs0nKW7wZzXky8Z7tffdYUHbe11bPCV5jYlK6DVdKLWLm0f5I/QlL0Kmw==",
      "dev": true,
      "requires": {
        "esprima": "^3.1.3",
        "estraverse": "^4.2.0",
        "esutils": "^2.0.2",
        "optionator": "^0.8.1",
        "source-map": "~0.6.1"
      },
      "dependencies": {
        "esprima": {
          "version": "3.1.3",
          "resolved": "https://registry.npmjs.org/esprima/-/esprima-3.1.3.tgz",
          "integrity": "sha1-/cpRzuYTOJXjyI1TXOSdv/YqRjM=",
          "dev": true
        },
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true,
          "optional": true
        }
      }
    },
    "eslint": {
      "version": "5.14.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-5.14.1.tgz",
      "integrity": "sha512-CyUMbmsjxedx8B0mr79mNOqetvkbij/zrXnFeK2zc3pGRn3/tibjiNAv/3UxFEyfMDjh+ZqTrJrEGBFiGfD5Og==",
      "dev": true,
      "requires": {
        "@babel/code-frame": "^7.0.0",
        "ajv": "^6.9.1",
        "chalk": "^2.1.0",
        "cross-spawn": "^6.0.5",
        "debug": "^4.0.1",
        "doctrine": "^3.0.0",
        "eslint-scope": "^4.0.0",
        "eslint-utils": "^1.3.1",
        "eslint-visitor-keys": "^1.0.0",
        "espree": "^5.0.1",
        "esquery": "^1.0.1",
        "esutils": "^2.0.2",
        "file-entry-cache": "^5.0.1",
        "functional-red-black-tree": "^1.0.1",
        "glob": "^7.1.2",
        "globals": "^11.7.0",
        "ignore": "^4.0.6",
        "import-fresh": "^3.0.0",
        "imurmurhash": "^0.1.4",
        "inquirer": "^6.2.2",
        "js-yaml": "^3.12.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.3.0",
        "lodash": "^4.17.11",
        "minimatch": "^3.0.4",
        "mkdirp": "^0.5.1",
        "natural-compare": "^1.4.0",
        "optionator": "^0.8.2",
        "path-is-inside": "^1.0.2",
        "progress": "^2.0.0",
        "regexpp": "^2.0.1",
        "semver": "^5.5.1",
        "strip-ansi": "^4.0.0",
        "strip-json-comments": "^2.0.1",
        "table": "^5.2.3",
        "text-table": "^0.2.0"
      },
      "dependencies": {
        "ajv": {
          "version": "6.9.2",
          "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.9.2.tgz",
          "integrity": "sha512-4UFy0/LgDo7Oa/+wOAlj44tp9K78u38E5/359eSrqEp1Z5PdVfimCcs7SluXMP755RUQu6d2b4AvF0R1C9RZjg==",
          "dev": true,
          "requires": {
            "fast-deep-equal": "^2.0.1",
            "fast-json-stable-stringify": "^2.0.0",
            "json-schema-traverse": "^0.4.1",
            "uri-js": "^4.2.2"
          }
        },
        "cross-spawn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-6.0.5.tgz",
          "integrity": "sha512-eTVLrBSt7fjbDygz805pMnstIs2VTBNkRm0qxZd+M7A5XDdxVRWO5MxGBXZhjY4cqLYLdtrGqRf8mBPmzwSpWQ==",
          "dev": true,
          "requires": {
            "nice-try": "^1.0.4",
            "path-key": "^2.0.1",
            "semver": "^5.5.0",
            "shebang-command": "^1.2.0",
            "which": "^1.2.9"
          }
        },
        "debug": {
          "version": "4.1.1",
          "resolved": "https://registry.npmjs.org/debug/-/debug-4.1.1.tgz",
          "integrity": "sha512-pYAIzeRo8J6KPEaJ0VWOh5Pzkbw/RetuzehGM7QRRX5he4fPHx2rdKMB256ehJCkX+XRQm16eZLqLNS8RSZXZw==",
          "dev": true,
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "globals": {
          "version": "11.11.0",
          "resolved": "https://registry.npmjs.org/globals/-/globals-11.11.0.tgz",
          "integrity": "sha512-WHq43gS+6ufNOEqlrDBxVEbb8ntfXrfAUU2ZOpCxrBdGKW3gyv8mCxAfIBD0DroPKGrJ2eSsXsLtY9MPntsyTw==",
          "dev": true
        },
        "ms": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
          "dev": true
        }
      }
    },
    "eslint-scope": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-4.0.0.tgz",
      "integrity": "sha512-1G6UTDi7Jc1ELFwnR58HV4fK9OQK4S6N985f166xqXxpjU6plxFISJa2Ba9KCQuFa8RCnj/lSFJbHo7UFDBnUA==",
      "dev": true,
      "requires": {
        "esrecurse": "^4.1.0",
        "estraverse": "^4.1.1"
      }
    },
    "eslint-utils": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/eslint-utils/-/eslint-utils-1.3.1.tgz",
      "integrity": "sha512-Z7YjnIldX+2XMcjr7ZkgEsOj/bREONV60qYeB/bjMAqqqZ4zxKyWX+BOUkdmRmA9riiIPVvo5x86m5elviOk0Q==",
      "dev": true
    },
    "eslint-visitor-keys": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-1.0.0.tgz",
      "integrity": "sha512-qzm/XxIbxm/FHyH341ZrbnMUpe+5Bocte9xkmFMzPMjRaZMcXww+MpBptFvtU+79L362nqiLhekCxCxDPaUMBQ==",
      "dev": true
    },
    "espree": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-5.0.1.tgz",
      "integrity": "sha512-qWAZcWh4XE/RwzLJejfcofscgMc9CamR6Tn1+XRXNzrvUSSbiAjGOI/fggztjIi7y9VLPqnICMIPiGyr8JaZ0A==",
      "dev": true,
      "requires": {
        "acorn": "^6.0.7",
        "acorn-jsx": "^5.0.0",
        "eslint-visitor-keys": "^1.0.0"
      },
      "dependencies": {
        "acorn": {
          "version": "6.1.0",
          "resolved": "https://registry.npmjs.org/acorn/-/acorn-6.1.0.tgz",
          "integrity": "sha512-MW/FjM+IvU9CgBzjO3UIPCE2pyEwUsoFl+VGdczOPEdxfGFjuKny/gN54mOuX7Qxmb9Rg9MCn2oKiSUeW+pjrw==",
          "dev": true
        }
      }
    },
    "esprima": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
      "dev": true
    },
    "esquery": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.0.1.tgz",
      "integrity": "sha512-SmiyZ5zIWH9VM+SRUReLS5Q8a7GxtRdxEBVZpm98rJM7Sb+A9DVCndXfkeFUd3byderg+EbDkfnevfCwynWaNA==",
      "dev": true,
      "requires": {
        "estraverse": "^4.0.0"
      }
    },
    "esrecurse": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.2.1.tgz",
      "integrity": "sha512-64RBB++fIOAXPw3P9cy89qfMlvZEXZkqqJkjqqXIvzP5ezRZjW+lPWjw35UX/3EhUPFYbg5ER4JYgDw4007/DQ==",
      "dev": true,
      "requires": {
        "estraverse": "^4.1.0"
      }
    },
    "estraverse": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-4.2.0.tgz",
      "integrity": "sha1-De4/7TH81GlhjOc0IJn8GvoL2xM=",
      "dev": true
    },
    "esutils": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.2.tgz",
      "integrity": "sha1-Cr9PHKpbyx96nYrMbepPqqBLrJs=",
      "dev": true
    },
    "events": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/events/-/events-2.1.0.tgz",
      "integrity": "sha512-3Zmiobend8P9DjmKAty0Era4jV8oJ0yGYe2nJJAxgymF9+N8F2m0hhZiMoWtcfepExzNKZumFU3ksdQbInGWCg==",
      "dev": true
    },
    "evp_bytestokey": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/evp_bytestokey/-/evp_bytestokey-1.0.3.tgz",
      "integrity": "sha512-/f2Go4TognH/KvCISP7OUsHn85hT9nUkxxA9BEWxFn+Oj9o8ZNLm/40hdlgSLyuOimsrTKLUMEorQexp/aPQeA==",
      "dev": true,
      "requires": {
        "md5.js": "^1.3.4",
        "safe-buffer": "^5.1.1"
      }
    },
    "exec-sh": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/exec-sh/-/exec-sh-0.3.2.tgz",
      "integrity": "sha512-9sLAvzhI5nc8TpuQUh4ahMdCrWT00wPWz7j47/emR5+2qEfoZP5zzUXvx+vdx+H6ohhnsYC31iX04QLYJK8zTg==",
      "dev": true
    },
    "execa": {
      "version": "0.7.0",
      "resolved": "https://registry.npmjs.org/execa/-/execa-0.7.0.tgz",
      "integrity": "sha1-lEvs00zEHuMqY6n68nrVpl/Fl3c=",
      "dev": true,
      "requires": {
        "cross-spawn": "^5.0.1",
        "get-stream": "^3.0.0",
        "is-stream": "^1.1.0",
        "npm-run-path": "^2.0.0",
        "p-finally": "^1.0.0",
        "signal-exit": "^3.0.0",
        "strip-eof": "^1.0.0"
      }
    },
    "exit": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/exit/-/exit-0.1.2.tgz",
      "integrity": "sha1-BjJjj42HfMghB9MKD/8aF8uhzQw=",
      "dev": true
    },
    "expand-brackets": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/expand-brackets/-/expand-brackets-2.1.4.tgz",
      "integrity": "sha1-t3c14xXOMPa27/D4OwQVGiJEliI=",
      "dev": true,
      "requires": {
        "debug": "^2.3.3",
        "define-property": "^0.2.5",
        "extend-shallow": "^2.0.1",
        "posix-character-classes": "^0.1.0",
        "regex-not": "^1.0.0",
        "snapdragon": "^0.8.1",
        "to-regex": "^3.0.1"
      },
      "dependencies": {
        "define-property": {
          "version": "0.2.5",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
          "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^0.1.0"
          }
        },
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        }
      }
    },
    "expect": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/expect/-/expect-24.7.1.tgz",
      "integrity": "sha512-mGfvMTPduksV3xoI0xur56pQsg2vJjNf5+a+bXOjqCkiCBbmCayrBbHS/75y9K430cfqyocPr2ZjiNiRx4SRKw==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "ansi-styles": "^3.2.0",
        "jest-get-type": "^24.3.0",
        "jest-matcher-utils": "^24.7.0",
        "jest-message-util": "^24.7.1",
        "jest-regex-util": "^24.3.0"
      }
    },
    "extend": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
      "dev": true
    },
    "extend-shallow": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-3.0.2.tgz",
      "integrity": "sha1-Jqcarwc7OfshJxcnRhMcJwQCjbg=",
      "dev": true,
      "requires": {
        "assign-symbols": "^1.0.0",
        "is-extendable": "^1.0.1"
      },
      "dependencies": {
        "is-extendable": {
          "version": "1.0.1",
          "resolved": "https://registry.npmjs.org/is-extendable/-/is-extendable-1.0.1.tgz",
          "integrity": "sha512-arnXMxT1hhoKo9k1LZdmlNyJdDDfy2v0fXjFlmok4+i8ul/6WlbVge9bhM74OpNPQPMGUToDtz+KXa1PneJxOA==",
          "dev": true,
          "requires": {
            "is-plain-object": "^2.0.4"
          }
        }
      }
    },
    "external-editor": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/external-editor/-/external-editor-3.0.3.tgz",
      "integrity": "sha512-bn71H9+qWoOQKyZDo25mOMVpSmXROAsTJVVVYzrrtol3d4y+AsKjf4Iwl2Q+IuT0kFSQ1qo166UuIwqYq7mGnA==",
      "dev": true,
      "requires": {
        "chardet": "^0.7.0",
        "iconv-lite": "^0.4.24",
        "tmp": "^0.0.33"
      }
    },
    "extglob": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/extglob/-/extglob-2.0.4.tgz",
      "integrity": "sha512-Nmb6QXkELsuBr24CJSkilo6UHHgbekK5UiZgfE6UHD3Eb27YC6oD+bhcT+tJ6cl8dmsgdQxnWlcry8ksBIBLpw==",
      "dev": true,
      "requires": {
        "array-unique": "^0.3.2",
        "define-property": "^1.0.0",
        "expand-brackets": "^2.1.4",
        "extend-shallow": "^2.0.1",
        "fragment-cache": "^0.2.1",
        "regex-not": "^1.0.0",
        "snapdragon": "^0.8.1",
        "to-regex": "^3.0.1"
      },
      "dependencies": {
        "define-property": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
          "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^1.0.0"
          }
        },
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "extsprintf": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/extsprintf/-/extsprintf-1.3.0.tgz",
      "integrity": "sha1-lpGEQOMEGnpBT4xS48V06zw+HgU=",
      "dev": true
    },
    "fast-deep-equal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-2.0.1.tgz",
      "integrity": "sha1-ewUhjd+WZ79/Nwv3/bLLFf3Qqkk=",
      "dev": true
    },
    "fast-json-stable-stringify": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.0.0.tgz",
      "integrity": "sha1-1RQsDK7msRifh9OnYREGT4bIu/I=",
      "dev": true
    },
    "fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha1-PYpcZog6FqMMqGQ+hR8Zuqd5eRc=",
      "dev": true
    },
    "faye-websocket": {
      "version": "0.10.0",
      "resolved": "https://registry.npmjs.org/faye-websocket/-/faye-websocket-0.10.0.tgz",
      "integrity": "sha1-TkkvjQTftviQA1B/btvy1QHnxvQ=",
      "dev": true,
      "requires": {
        "websocket-driver": ">=0.5.1"
      }
    },
    "fb-watchman": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/fb-watchman/-/fb-watchman-2.0.0.tgz",
      "integrity": "sha1-VOmr99+i8mzZsWNsWIwa/AXeXVg=",
      "dev": true,
      "requires": {
        "bser": "^2.0.0"
      }
    },
    "figures": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/figures/-/figures-2.0.0.tgz",
      "integrity": "sha1-OrGi0qYsi/tDGgyUy3l6L84nyWI=",
      "dev": true,
      "requires": {
        "escape-string-regexp": "^1.0.5"
      }
    },
    "file-entry-cache": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-5.0.1.tgz",
      "integrity": "sha512-bCg29ictuBaKUwwArK4ouCaqDgLZcysCFLmM/Yn/FDoqndh/9vNuQfXRDvTuXKLxfD/JtZQGKFT8MGcJBK644g==",
      "dev": true,
      "requires": {
        "flat-cache": "^2.0.1"
      }
    },
    "fileset": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/fileset/-/fileset-2.0.3.tgz",
      "integrity": "sha1-jnVIqW08wjJ+5eZ0FocjozO7oqA=",
      "dev": true,
      "requires": {
        "glob": "^7.0.3",
        "minimatch": "^3.0.3"
      }
    },
    "fill-range": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-4.0.0.tgz",
      "integrity": "sha1-1USBHUKPmOsGpj3EAtJAPDKMOPc=",
      "dev": true,
      "requires": {
        "extend-shallow": "^2.0.1",
        "is-number": "^3.0.0",
        "repeat-string": "^1.6.1",
        "to-regex-range": "^2.1.0"
      },
      "dependencies": {
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        }
      }
    },
    "find-up": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-2.1.0.tgz",
      "integrity": "sha1-RdG35QbHF93UgndaK3eSCjwMV6c=",
      "dev": true,
      "requires": {
        "locate-path": "^2.0.0"
      }
    },
    "flat-cache": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-2.0.1.tgz",
      "integrity": "sha512-LoQe6yDuUMDzQAEH8sgmh4Md6oZnc/7PjtwjNFSzveXqSHt6ka9fPBuso7IGf9Rz4uqnSnWiFH2B/zj24a5ReA==",
      "dev": true,
      "requires": {
        "flatted": "^2.0.0",
        "rimraf": "2.6.3",
        "write": "1.0.3"
      },
      "dependencies": {
        "rimraf": {
          "version": "2.6.3",
          "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-2.6.3.tgz",
          "integrity": "sha512-mwqeW5XsA2qAejG46gYdENaxXjx9onRNCfn7L0duuP4hCuTIi/QO7PDK07KJfp1d+izWPrzEJDcSqBa0OZQriA==",
          "dev": true,
          "requires": {
            "glob": "^7.1.3"
          }
        }
      }
    },
    "flatted": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-2.0.0.tgz",
      "integrity": "sha512-R+H8IZclI8AAkSBRQJLVOsxwAoHd6WC40b4QTNWIjzAa6BXOBfQcM587MXDTVPeYaopFNWHUFLx7eNmHDSxMWg==",
      "dev": true
    },
    "flush-write-stream": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/flush-write-stream/-/flush-write-stream-1.0.3.tgz",
      "integrity": "sha512-calZMC10u0FMUqoiunI2AiGIIUtUIvifNwkHhNupZH4cbNnW1Itkoh/Nf5HFYmDrwWPjrUxpkZT0KhuCq0jmGw==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "readable-stream": "^2.0.4"
      }
    },
    "for-in": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/for-in/-/for-in-1.0.2.tgz",
      "integrity": "sha1-gQaNKVqBQuwKxybG4iAMMPttXoA=",
      "dev": true
    },
    "forever-agent": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/forever-agent/-/forever-agent-0.6.1.tgz",
      "integrity": "sha1-+8cfDEGt6zf5bFd60e1C2P2sypE=",
      "dev": true
    },
    "form-data": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-2.3.3.tgz",
      "integrity": "sha512-1lLKB2Mu3aGP1Q/2eCOx0fNbRMe7XdwktwOruhfqqd0rIJWwN4Dh+E3hrPSlDCXnSR7UtZ1N38rVXm+6+MEhJQ==",
      "dev": true,
      "requires": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.6",
        "mime-types": "^2.1.12"
      }
    },
    "fragment-cache": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/fragment-cache/-/fragment-cache-0.2.1.tgz",
      "integrity": "sha1-QpD60n8T6Jvn8zeZxrxaCr//DRk=",
      "dev": true,
      "requires": {
        "map-cache": "^0.2.2"
      }
    },
    "fs-minipass": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/fs-minipass/-/fs-minipass-1.2.5.tgz",
      "integrity": "sha512-JhBl0skXjUPCFH7x6x61gQxrKyXsxB5gcgePLZCwfyCGGsTISMoIeObbrvVeP6Xmyaudw4TT43qV2Gz+iyd2oQ==",
      "dev": true,
      "optional": true,
      "requires": {
        "minipass": "^2.2.1"
      }
    },
    "fs-mkdirp-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs-mkdirp-stream/-/fs-mkdirp-stream-1.0.0.tgz",
      "integrity": "sha1-C3gV/DIBxqaeFNuYzgmMFpNSWes=",
      "dev": true,
      "requires": {
        "graceful-fs": "^4.1.11",
        "through2": "^2.0.3"
      }
    },
    "fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha1-FQStJSMVjKpA20onh8sBQRmU6k8=",
      "dev": true
    },
    "fsevents": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-1.2.4.tgz",
      "integrity": "sha512-z8H8/diyk76B7q5wg+Ud0+CqzcAF3mBBI/bA5ne5zrRUUIvNkJY//D3BqyH571KuAC4Nr7Rw7CjWX4r0y9DvNg==",
      "dev": true,
      "optional": true,
      "requires": {
        "nan": "^2.9.2",
        "node-pre-gyp": "^0.10.0"
      },
      "dependencies": {
        "abbrev": {
          "version": "1.1.1",
          "resolved": "",
          "integrity": "sha512-nne9/IiQ/hzIhY6pdDnbBtz7DjPTKrY00P/zvPSm5pOFkl6xuGrGnXn/VtTNNfNtAfZ9/1RtehkszU9qcTii0Q==",
          "dev": true,
          "optional": true
        },
        "ansi-regex": {
          "version": "2.1.1",
          "resolved": "",
          "integrity": "sha1-w7M6te42DYbg5ijwRorn7yfWVN8=",
          "dev": true,
          "optional": true
        },
        "aproba": {
          "version": "1.2.0",
          "resolved": "",
          "integrity": "sha512-Y9J6ZjXtoYh8RnXVCMOU/ttDmk1aBjunq9vO0ta5x85WDQiQfUF9sIPBITdbiiIVcBo03Hi3jMxigBtsddlXRw==",
          "dev": true,
          "optional": true
        },
        "are-we-there-yet": {
          "version": "1.1.4",
          "resolved": "",
          "integrity": "sha1-u13KOCu5TwXhUZQ3PRb9O6HKEQ0=",
          "dev": true,
          "optional": true,
          "requires": {
            "delegates": "^1.0.0",
            "readable-stream": "^2.0.6"
          }
        },
        "balanced-match": {
          "version": "1.0.0",
          "resolved": "",
          "integrity": "sha1-ibTRmasr7kneFk6gK4nORi1xt2c=",
          "dev": true,
          "optional": true
        },
        "brace-expansion": {
          "version": "1.1.11",
          "resolved": "",
          "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
          "dev": true,
          "optional": true,
          "requires": {
            "balanced-match": "^1.0.0",
            "concat-map": "0.0.1"
          }
        },
        "code-point-at": {
          "version": "1.1.0",
          "resolved": "",
          "integrity": "sha1-DQcLTQQ6W+ozovGkDi7bPZpMz3c=",
          "dev": true,
          "optional": true
        },
        "concat-map": {
          "version": "0.0.1",
          "resolved": "",
          "integrity": "sha1-2Klr13/Wjfd5OnMDajug1UBdR3s=",
          "dev": true,
          "optional": true
        },
        "console-control-strings": {
          "version": "1.1.0",
          "resolved": "",
          "integrity": "sha1-PXz0Rk22RG6mRL9LOVB/mFEAjo4=",
          "dev": true,
          "optional": true
        },
        "core-util-is": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-tf1UIgqivFq1eqtxQMlAdUUDwac=",
          "dev": true,
          "optional": true
        },
        "debug": {
          "version": "2.6.9",
          "resolved": "",
          "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
          "dev": true,
          "optional": true,
          "requires": {
            "ms": "2.0.0"
          }
        },
        "deep-extend": {
          "version": "0.5.1",
          "resolved": "",
          "integrity": "sha512-N8vBdOa+DF7zkRrDCsaOXoCs/E2fJfx9B9MrKnnSiHNh4ws7eSys6YQE4KvT1cecKmOASYQBhbKjeuDD9lT81w==",
          "dev": true,
          "optional": true
        },
        "delegates": {
          "version": "1.0.0",
          "resolved": "",
          "integrity": "sha1-hMbhWbgZBP3KWaDvRM2HDTElD5o=",
          "dev": true,
          "optional": true
        },
        "detect-libc": {
          "version": "1.0.3",
          "resolved": "",
          "integrity": "sha1-+hN8S9aY7fVc1c0CrFWfkaTEups=",
          "dev": true,
          "optional": true
        },
        "fs.realpath": {
          "version": "1.0.0",
          "resolved": "",
          "integrity": "sha1-FQStJSMVjKpA20onh8sBQRmU6k8=",
          "dev": true,
          "optional": true
        },
        "gauge": {
          "version": "2.7.4",
          "resolved": "",
          "integrity": "sha1-LANAXHU4w51+s3sxcCLjJfsBi/c=",
          "dev": true,
          "optional": true,
          "requires": {
            "aproba": "^1.0.3",
            "console-control-strings": "^1.0.0",
            "has-unicode": "^2.0.0",
            "object-assign": "^4.1.0",
            "signal-exit": "^3.0.0",
            "string-width": "^1.0.1",
            "strip-ansi": "^3.0.1",
            "wide-align": "^1.1.0"
          }
        },
        "glob": {
          "version": "7.1.2",
          "resolved": "",
          "integrity": "sha512-MJTUg1kjuLeQCJ+ccE4Vpa6kKVXkPYJ2mOCQyUuKLcLQsdrMCpBPUi8qVE6+YuaJkozeA9NusTAw3hLr8Xe5EQ==",
          "dev": true,
          "optional": true,
          "requires": {
            "fs.realpath": "^1.0.0",
            "inflight": "^1.0.4",
            "inherits": "2",
            "minimatch": "^3.0.4",
            "once": "^1.3.0",
            "path-is-absolute": "^1.0.0"
          }
        },
        "has-unicode": {
          "version": "2.0.1",
          "resolved": "",
          "integrity": "sha1-4Ob+aijPUROIVeCG0Wkedx3iqLk=",
          "dev": true,
          "optional": true
        },
        "iconv-lite": {
          "version": "0.4.21",
          "resolved": "",
          "integrity": "sha512-En5V9za5mBt2oUA03WGD3TwDv0MKAruqsuxstbMUZaj9W9k/m1CV/9py3l0L5kw9Bln8fdHQmzHSYtvpvTLpKw==",
          "dev": true,
          "optional": true,
          "requires": {
            "safer-buffer": "^2.1.0"
          }
        },
        "ignore-walk": {
          "version": "3.0.1",
          "resolved": "",
          "integrity": "sha512-DTVlMx3IYPe0/JJcYP7Gxg7ttZZu3IInhuEhbchuqneY9wWe5Ojy2mXLBaQFUQmo0AW2r3qG7m1mg86js+gnlQ==",
          "dev": true,
          "optional": true,
          "requires": {
            "minimatch": "^3.0.4"
          }
        },
        "inflight": {
          "version": "1.0.6",
          "resolved": "",
          "integrity": "sha1-Sb1jMdfQLQwJvJEKEHW6gWW1bfk=",
          "dev": true,
          "optional": true,
          "requires": {
            "once": "^1.3.0",
            "wrappy": "1"
          }
        },
        "inherits": {
          "version": "2.0.3",
          "resolved": "",
          "integrity": "sha1-Yzwsg+PaQqUC9SRmAiSA9CCCYd4=",
          "dev": true,
          "optional": true
        },
        "ini": {
          "version": "1.3.5",
          "resolved": "",
          "integrity": "sha512-RZY5huIKCMRWDUqZlEi72f/lmXKMvuszcMBduliQ3nnWbx9X/ZBQO7DijMEYS9EhHBb2qacRUMtC7svLwe0lcw==",
          "dev": true,
          "optional": true
        },
        "is-fullwidth-code-point": {
          "version": "1.0.0",
          "resolved": "",
          "integrity": "sha1-754xOG8DGn8NZDr4L95QxFfvAMs=",
          "dev": true,
          "optional": true,
          "requires": {
            "number-is-nan": "^1.0.0"
          }
        },
        "isarray": {
          "version": "1.0.0",
          "resolved": "",
          "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE=",
          "dev": true,
          "optional": true
        },
        "minimatch": {
          "version": "3.0.4",
          "resolved": "",
          "integrity": "sha512-yJHVQEhyqPLUTgt9B83PXu6W3rx4MvvHvSUvToogpwoGDOUQ+yDrR0HRot+yOCdCO7u4hX3pWft6kWBBcqh0UA==",
          "dev": true,
          "optional": true,
          "requires": {
            "brace-expansion": "^1.1.7"
          }
        },
        "minimist": {
          "version": "0.0.8",
          "resolved": "",
          "integrity": "sha1-hX/Kv8M5fSYluCKCYuhqp6ARsF0=",
          "dev": true,
          "optional": true
        },
        "mkdirp": {
          "version": "0.5.1",
          "resolved": "",
          "integrity": "sha1-MAV0OOrGz3+MR2fzhkjWaX11yQM=",
          "dev": true,
          "optional": true,
          "requires": {
            "minimist": "0.0.8"
          }
        },
        "ms": {
          "version": "2.0.0",
          "resolved": "",
          "integrity": "sha1-VgiurfwAvmwpAd9fmGF4jeDVl8g=",
          "dev": true,
          "optional": true
        },
        "needle": {
          "version": "2.2.0",
          "resolved": "",
          "integrity": "sha512-eFagy6c+TYayorXw/qtAdSvaUpEbBsDwDyxYFgLZ0lTojfH7K+OdBqAF7TAFwDokJaGpubpSGG0wO3iC0XPi8w==",
          "dev": true,
          "optional": true,
          "requires": {
            "debug": "^2.1.2",
            "iconv-lite": "^0.4.4",
            "sax": "^1.2.4"
          }
        },
        "node-pre-gyp": {
          "version": "0.10.0",
          "resolved": false,
          "integrity": "sha512-G7kEonQLRbcA/mOoFoxvlMrw6Q6dPf92+t/l0DFSMuSlDoWaI9JWIyPwK0jyE1bph//CUEL65/Fz1m2vJbmjQQ==",
          "dev": true,
          "optional": true,
          "requires": {
            "detect-libc": "^1.0.2",
            "mkdirp": "^0.5.1",
            "needle": "^2.2.0",
            "nopt": "^4.0.1",
            "npm-packlist": "^1.1.6",
            "npmlog": "^4.0.2",
            "rc": "^1.1.7",
            "rimraf": "^2.6.1",
            "semver": "^5.3.0",
            "tar": "^4"
          }
        },
        "nopt": {
          "version": "4.0.1",
          "resolved": "",
          "integrity": "sha1-0NRoWv1UFRk8jHUFYC0NF81kR00=",
          "dev": true,
          "optional": true,
          "requires": {
            "abbrev": "1",
            "osenv": "^0.1.4"
          }
        },
        "npm-bundled": {
          "version": "1.0.3",
          "resolved": "",
          "integrity": "sha512-ByQ3oJ/5ETLyglU2+8dBObvhfWXX8dtPZDMePCahptliFX2iIuhyEszyFk401PZUNQH20vvdW5MLjJxkwU80Ow==",
          "dev": true,
          "optional": true
        },
        "npm-packlist": {
          "version": "1.1.10",
          "resolved": "",
          "integrity": "sha512-AQC0Dyhzn4EiYEfIUjCdMl0JJ61I2ER9ukf/sLxJUcZHfo+VyEfz2rMJgLZSS1v30OxPQe1cN0LZA1xbcaVfWA==",
          "dev": true,
          "optional": true,
          "requires": {
            "ignore-walk": "^3.0.1",
            "npm-bundled": "^1.0.1"
          }
        },
        "npmlog": {
          "version": "4.1.2",
          "resolved": "",
          "integrity": "sha512-2uUqazuKlTaSI/dC8AzicUck7+IrEaOnN/e0jd3Xtt1KcGpwx30v50mL7oPyr/h9bL3E4aZccVwpwP+5W9Vjkg==",
          "dev": true,
          "optional": true,
          "requires": {
            "are-we-there-yet": "~1.1.2",
            "console-control-strings": "~1.1.0",
            "gauge": "~2.7.3",
            "set-blocking": "~2.0.0"
          }
        },
        "number-is-nan": {
          "version": "1.0.1",
          "resolved": "",
          "integrity": "sha1-CXtgK1NCKlIsGvuHkDGDNpQaAR0=",
          "dev": true,
          "optional": true
        },
        "object-assign": {
          "version": "4.1.1",
          "resolved": "",
          "integrity": "sha1-IQmtx5ZYh8/AXLvUQsrIv7s2CGM=",
          "dev": true,
          "optional": true
        },
        "once": {
          "version": "1.4.0",
          "resolved": "",
          "integrity": "sha1-WDsap3WWHUsROsF9nFC6753Xa9E=",
          "dev": true,
          "optional": true,
          "requires": {
            "wrappy": "1"
          }
        },
        "os-homedir": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-/7xJiDNuDoM94MFox+8VISGqf7M=",
          "dev": true,
          "optional": true
        },
        "os-tmpdir": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-u+Z0BseaqFxc/sdm/lc0VV36EnQ=",
          "dev": true,
          "optional": true
        },
        "osenv": {
          "version": "0.1.5",
          "resolved": "",
          "integrity": "sha512-0CWcCECdMVc2Rw3U5w9ZjqX6ga6ubk1xDVKxtBQPK7wis/0F2r9T6k4ydGYhecl7YUBxBVxhL5oisPsNxAPe2g==",
          "dev": true,
          "optional": true,
          "requires": {
            "os-homedir": "^1.0.0",
            "os-tmpdir": "^1.0.0"
          }
        },
        "path-is-absolute": {
          "version": "1.0.1",
          "resolved": "",
          "integrity": "sha1-F0uSaHNVNP+8es5r9TpanhtcX18=",
          "dev": true,
          "optional": true
        },
        "process-nextick-args": {
          "version": "2.0.0",
          "resolved": "",
          "integrity": "sha512-MtEC1TqN0EU5nephaJ4rAtThHtC86dNN9qCuEhtshvpVBkAW5ZO7BASN9REnF9eoXGcRub+pFuKEpOHE+HbEMw==",
          "dev": true,
          "optional": true
        },
        "rc": {
          "version": "1.2.7",
          "resolved": "",
          "integrity": "sha512-LdLD8xD4zzLsAT5xyushXDNscEjB7+2ulnl8+r1pnESlYtlJtVSoCMBGr30eDRJ3+2Gq89jK9P9e4tCEH1+ywA==",
          "dev": true,
          "optional": true,
          "requires": {
            "deep-extend": "^0.5.1",
            "ini": "~1.3.0",
            "minimist": "^1.2.0",
            "strip-json-comments": "~2.0.1"
          },
          "dependencies": {
            "minimist": {
              "version": "1.2.0",
              "resolved": "",
              "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
              "dev": true,
              "optional": true
            }
          }
        },
        "readable-stream": {
          "version": "2.3.6",
          "resolved": "",
          "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
          "dev": true,
          "optional": true,
          "requires": {
            "core-util-is": "~1.0.0",
            "inherits": "~2.0.3",
            "isarray": "~1.0.0",
            "process-nextick-args": "~2.0.0",
            "safe-buffer": "~5.1.1",
            "string_decoder": "~1.1.1",
            "util-deprecate": "~1.0.1"
          }
        },
        "rimraf": {
          "version": "2.6.2",
          "resolved": "",
          "integrity": "sha512-lreewLK/BlghmxtfH36YYVg1i8IAce4TI7oao75I1g245+6BctqTVQiBP3YUJ9C6DQOXJmkYR9X9fCLtCOJc5w==",
          "dev": true,
          "optional": true,
          "requires": {
            "glob": "^7.0.5"
          }
        },
        "safe-buffer": {
          "version": "5.1.1",
          "resolved": "",
          "integrity": "sha512-kKvNJn6Mm93gAczWVJg7wH+wGYWNrDHdWvpUmHyEsgCtIwwo3bqPtV4tR5tuPaUhTOo/kvhVwd8XwwOllGYkbg==",
          "dev": true,
          "optional": true
        },
        "safer-buffer": {
          "version": "2.1.2",
          "resolved": "",
          "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==",
          "dev": true,
          "optional": true
        },
        "sax": {
          "version": "1.2.4",
          "resolved": "",
          "integrity": "sha512-NqVDv9TpANUjFm0N8uM5GxL36UgKi9/atZw+x7YFnQ8ckwFGKrl4xX4yWtrey3UJm5nP1kUbnYgLopqWNSRhWw==",
          "dev": true,
          "optional": true
        },
        "semver": {
          "version": "5.5.0",
          "resolved": "",
          "integrity": "sha512-4SJ3dm0WAwWy/NVeioZh5AntkdJoWKxHxcmyP622fOkgHa4z3R0TdBJICINyaSDE6uNwVc8gZr+ZinwZAH4xIA==",
          "dev": true,
          "optional": true
        },
        "set-blocking": {
          "version": "2.0.0",
          "resolved": "",
          "integrity": "sha1-BF+XgtARrppoA93TgrJDkrPYkPc=",
          "dev": true,
          "optional": true
        },
        "signal-exit": {
          "version": "3.0.2",
          "resolved": "",
          "integrity": "sha1-tf3AjxKH6hF4Yo5BXiUTK3NkbG0=",
          "dev": true,
          "optional": true
        },
        "string-width": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-EYvfW4zcUaKn5w0hHgfisLmxB9M=",
          "dev": true,
          "optional": true,
          "requires": {
            "code-point-at": "^1.0.0",
            "is-fullwidth-code-point": "^1.0.0",
            "strip-ansi": "^3.0.0"
          }
        },
        "string_decoder": {
          "version": "1.1.1",
          "resolved": "",
          "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
          "dev": true,
          "optional": true,
          "requires": {
            "safe-buffer": "~5.1.0"
          }
        },
        "strip-ansi": {
          "version": "3.0.1",
          "resolved": "",
          "integrity": "sha1-ajhfuIU9lS1f8F0Oiq+UJ43GPc8=",
          "dev": true,
          "optional": true,
          "requires": {
            "ansi-regex": "^2.0.0"
          }
        },
        "strip-json-comments": {
          "version": "2.0.1",
          "resolved": "",
          "integrity": "sha1-PFMZQukIwml8DsNEhYwobHygpgo=",
          "dev": true,
          "optional": true
        },
        "util-deprecate": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-RQ1Nyfpw3nMnYvvS1KKJgUGaDM8=",
          "dev": true,
          "optional": true
        },
        "wide-align": {
          "version": "1.1.2",
          "resolved": "",
          "integrity": "sha512-ijDLlyQ7s6x1JgCLur53osjm/UXUYD9+0PbYKrBsYisYXzCxN+HC3mYDNy/dWdmf3AwqwU3CXwDCvsNgGK1S0w==",
          "dev": true,
          "optional": true,
          "requires": {
            "string-width": "^1.0.2"
          }
        },
        "wrappy": {
          "version": "1.0.2",
          "resolved": "",
          "integrity": "sha1-tSQ9jz7BqjXxNkYFvA0QNuMKtp8=",
          "dev": true,
          "optional": true
        }
      }
    },
    "function-bind": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.1.tgz",
      "integrity": "sha512-yIovAzMX49sF8Yl58fSCWJ5svSLuaibPxXQJFLmBObTuCr0Mf1KiPopGM9NiFjiYBCbfaa2Fh6breQ6ANVTI0A==",
      "dev": true
    },
    "functional-red-black-tree": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/functional-red-black-tree/-/functional-red-black-tree-1.0.1.tgz",
      "integrity": "sha1-GwqzvVU7Kg1jmdKcDj6gslIHgyc=",
      "dev": true
    },
    "get-assigned-identifiers": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/get-assigned-identifiers/-/get-assigned-identifiers-1.2.0.tgz",
      "integrity": "sha512-mBBwmeGTrxEMO4pMaaf/uUEFHnYtwr8FTe8Y/mer4rcV/bye0qGm6pw1bGZFGStxC5O76c5ZAVBGnqHmOaJpdQ==",
      "dev": true
    },
    "get-caller-file": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/get-caller-file/-/get-caller-file-1.0.3.tgz",
      "integrity": "sha512-3t6rVToeoZfYSGd8YoLFR2DJkiQrIiUrGcjvFX2mDw3bn6k2OtwHN0TNCLbBO+w8qTvimhDkv+LSscbJY1vE6w==",
      "dev": true
    },
    "get-port": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/get-port/-/get-port-4.1.0.tgz",
      "integrity": "sha512-4/fqAYrzrzOiqDrdeZRKXGdTGgbkfTEumGlNQPeP6Jy8w0PzN9mzeNQ3XgHaTNie8pQ3hOUkrwlZt2Fzk5H9mA==",
      "dev": true
    },
    "get-stream": {
      "version": "3.0.0",
      "resolved": "http://registry.npmjs.org/get-stream/-/get-stream-3.0.0.tgz",
      "integrity": "sha1-jpQ9E1jcN1VQVOy+LtsFqhdO3hQ=",
      "dev": true
    },
    "get-value": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/get-value/-/get-value-2.0.6.tgz",
      "integrity": "sha1-3BXKHGcjh8p2vTesCjlbogQqLCg=",
      "dev": true
    },
    "getpass": {
      "version": "0.1.7",
      "resolved": "https://registry.npmjs.org/getpass/-/getpass-0.1.7.tgz",
      "integrity": "sha1-Xv+OPmhNVprkyysSgmBOi6YhSfo=",
      "dev": true,
      "requires": {
        "assert-plus": "^1.0.0"
      }
    },
    "git-up": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/git-up/-/git-up-2.1.0.tgz",
      "integrity": "sha512-MJgwfcSd9qxgDyEYpRU/CDxNpUadrK80JHuEQDG4Urn0m7tpSOgCBrtiSIa9S9KH8Tbuo/TN8SSQmJBvsw1HkA==",
      "dev": true,
      "requires": {
        "is-ssh": "^1.3.0",
        "parse-url": "^3.0.2"
      }
    },
    "git-url-parse": {
      "version": "10.1.0",
      "resolved": "https://registry.npmjs.org/git-url-parse/-/git-url-parse-10.1.0.tgz",
      "integrity": "sha512-goZOORAtFjU1iG+4zZgWq+N7It09PqS3Xsy43ZwhP5unDD0tTSmXTpqULHodMdJXGejm3COwXIhIRT6Z8DYVZQ==",
      "dev": true,
      "requires": {
        "git-up": "^2.0.0"
      }
    },
    "github-slugger": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/github-slugger/-/github-slugger-1.2.0.tgz",
      "integrity": "sha512-wIaa75k1vZhyPm9yWrD08A5Xnx/V+RmzGrpjQuLemGKSb77Qukiaei58Bogrl/LZSADDfPzKJX8jhLs4CRTl7Q==",
      "dev": true,
      "requires": {
        "emoji-regex": ">=6.0.0 <=6.1.1"
      }
    },
    "glob": {
      "version": "7.1.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.3.tgz",
      "integrity": "sha512-vcfuiIxogLV4DlGBHIUOwI0IbrJ8HWPc4MU7HzviGeNho/UJDfi6B5p3sHeWIQ0KGIU0Jpxi5ZHxemQfLkkAwQ==",
      "dev": true,
      "requires": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.0.4",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      }
    },
    "glob-stream": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/glob-stream/-/glob-stream-6.1.0.tgz",
      "integrity": "sha1-cEXJlBOz65SIjYOrRtC0BMx73eQ=",
      "dev": true,
      "requires": {
        "extend": "^3.0.0",
        "glob": "^7.1.1",
        "glob-parent": "^3.1.0",
        "is-negated-glob": "^1.0.0",
        "ordered-read-streams": "^1.0.0",
        "pumpify": "^1.3.5",
        "readable-stream": "^2.1.5",
        "remove-trailing-separator": "^1.0.1",
        "to-absolute-glob": "^2.0.0",
        "unique-stream": "^2.0.2"
      },
      "dependencies": {
        "glob-parent": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-3.1.0.tgz",
          "integrity": "sha1-nmr2KZ2NO9K9QEMIMr0RPfkGxa4=",
          "dev": true,
          "requires": {
            "is-glob": "^3.1.0",
            "path-dirname": "^1.0.0"
          }
        },
        "is-extglob": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
          "integrity": "sha1-qIwCU1eR8C7TfHahueqXc8gz+MI=",
          "dev": true
        },
        "is-glob": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-3.1.0.tgz",
          "integrity": "sha1-e6WuJCF4BKxwcHuWkiVnSGzD6Eo=",
          "dev": true,
          "requires": {
            "is-extglob": "^2.1.0"
          }
        }
      }
    },
    "globals-docs": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/globals-docs/-/globals-docs-2.4.0.tgz",
      "integrity": "sha512-B69mWcqCmT3jNYmSxRxxOXWfzu3Go8NQXPfl2o0qPd1EEFhwW0dFUg9ztTu915zPQzqwIhWAlw6hmfIcCK4kkQ==",
      "dev": true
    },
    "graceful-fs": {
      "version": "4.1.15",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.1.15.tgz",
      "integrity": "sha512-6uHUhOPEBgQ24HM+r6b/QwWfZq+yiFcipKFrOFiBEnWdy5sdzYoi+pJeQaPI5qOLRFqWmAXUPQNsielzdLoecA==",
      "dev": true
    },
    "growly": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/growly/-/growly-1.3.0.tgz",
      "integrity": "sha1-8QdIy+dq+WS3yWyTxrzCivEgwIE=",
      "dev": true
    },
    "handlebars": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/handlebars/-/handlebars-4.1.2.tgz",
      "integrity": "sha512-nvfrjqvt9xQ8Z/w0ijewdD/vvWDTOweBUm96NTr66Wfvo1mJenBLwcYmPs3TIBP5ruzYGD7Hx/DaM9RmhroGPw==",
      "dev": true,
      "requires": {
        "neo-async": "^2.6.0",
        "optimist": "^0.6.1",
        "source-map": "^0.6.1",
        "uglify-js": "^3.1.4"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "har-schema": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/har-schema/-/har-schema-2.0.0.tgz",
      "integrity": "sha1-qUwiJOvKwEeCoNkDVSHyRzW37JI=",
      "dev": true
    },
    "har-validator": {
      "version": "5.1.3",
      "resolved": "https://registry.npmjs.org/har-validator/-/har-validator-5.1.3.tgz",
      "integrity": "sha512-sNvOCzEQNr/qrvJgc3UG/kD4QtlHycrzwS+6mfTrrSq97BvaYcPZZI1ZSqGSPR73Cxn4LKTD4PttRwfU7jWq5g==",
      "dev": true,
      "requires": {
        "ajv": "^6.5.5",
        "har-schema": "^2.0.0"
      }
    },
    "has": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/has/-/has-1.0.3.tgz",
      "integrity": "sha512-f2dvO0VU6Oej7RkWJGrehjbzMAjFp5/VKPp5tTpWIV4JHHZK1/BxbFRtf/siA2SWTe09caDmVtYYzWEIbBS4zw==",
      "dev": true,
      "requires": {
        "function-bind": "^1.1.1"
      }
    },
    "has-flag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
      "integrity": "sha1-tdRU3CGZriJWmfNGfloH87lVuv0=",
      "dev": true
    },
    "has-symbols": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.0.0.tgz",
      "integrity": "sha1-uhqPGvKg/DllD1yFA2dwQSIGO0Q=",
      "dev": true
    },
    "has-value": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/has-value/-/has-value-1.0.0.tgz",
      "integrity": "sha1-GLKB2lhbHFxR3vJMkw7SmgvmsXc=",
      "dev": true,
      "requires": {
        "get-value": "^2.0.6",
        "has-values": "^1.0.0",
        "isobject": "^3.0.0"
      },
      "dependencies": {
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "has-values": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/has-values/-/has-values-1.0.0.tgz",
      "integrity": "sha1-lbC2P+whRmGab+V/51Yo1aOe/k8=",
      "dev": true,
      "requires": {
        "is-number": "^3.0.0",
        "kind-of": "^4.0.0"
      },
      "dependencies": {
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          },
          "dependencies": {
            "kind-of": {
              "version": "3.2.2",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
              "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
              "dev": true,
              "requires": {
                "is-buffer": "^1.1.5"
              }
            }
          }
        },
        "kind-of": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-4.0.0.tgz",
          "integrity": "sha1-IIE989cSkosgc3hpGkUGb65y3Vc=",
          "dev": true,
          "requires": {
            "is-buffer": "^1.1.5"
          }
        }
      }
    },
    "hash-base": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/hash-base/-/hash-base-3.0.4.tgz",
      "integrity": "sha1-X8hoaEfs1zSZQDMZprCj8/auSRg=",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "hash.js": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/hash.js/-/hash.js-1.1.7.tgz",
      "integrity": "sha512-taOaskGt4z4SOANNseOviYDvjEJinIkRgmp7LbKP2YTTmVxWBl87s/uzK9r+44BclBSp2X7K1hqeNfz9JbBeXA==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.3",
        "minimalistic-assert": "^1.0.1"
      }
    },
    "hast-util-is-element": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/hast-util-is-element/-/hast-util-is-element-1.0.2.tgz",
      "integrity": "sha512-4MEtyofNi3ZunPFrp9NpTQdNPN24xvLX3M+Lr/RGgPX6TLi+wR4/DqeoyQ7lwWcfUp4aevdt4RR0r7ZQPFbHxw==",
      "dev": true
    },
    "hast-util-sanitize": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/hast-util-sanitize/-/hast-util-sanitize-1.3.0.tgz",
      "integrity": "sha512-rQeetoD08jHmDOUYN6h9vTuE0hQN4wymhtkQZ6whHtcjaLpjw5RYAbcdxx9cMgMWERDsSs79UpqHuBLlUHKeOw==",
      "dev": true,
      "requires": {
        "xtend": "^4.0.1"
      }
    },
    "hast-util-to-html": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/hast-util-to-html/-/hast-util-to-html-4.0.1.tgz",
      "integrity": "sha512-2emzwyf0xEsc4TBIPmDJmBttIw8R4SXAJiJZoiRR/s47ODYWgOqNoDbf2SJAbMbfNdFWMiCSOrI3OVnX6Qq2Mg==",
      "dev": true,
      "requires": {
        "ccount": "^1.0.0",
        "comma-separated-tokens": "^1.0.1",
        "hast-util-is-element": "^1.0.0",
        "hast-util-whitespace": "^1.0.0",
        "html-void-elements": "^1.0.0",
        "property-information": "^4.0.0",
        "space-separated-tokens": "^1.0.0",
        "stringify-entities": "^1.0.1",
        "unist-util-is": "^2.0.0",
        "xtend": "^4.0.1"
      }
    },
    "hast-util-whitespace": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/hast-util-whitespace/-/hast-util-whitespace-1.0.2.tgz",
      "integrity": "sha512-4JT8B0HKPHBMFZdDQzexjxwhKx9TrpV/+uelvmqlPu8RqqDrnNIEHDtDZCmgE+4YmcFAtKVPLmnY3dQGRaN53A==",
      "dev": true
    },
    "he": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/he/-/he-1.2.0.tgz",
      "integrity": "sha512-F/1DnUGPopORZi0ni+CvrCgHQ5FyEAHRLSApuYWMmrbSwoN2Mn/7k+Gl38gJnR7yyDZk6WLXwiGod1JOWNDKGw==",
      "dev": true
    },
    "highlight.js": {
      "version": "9.13.1",
      "resolved": "https://registry.npmjs.org/highlight.js/-/highlight.js-9.13.1.tgz",
      "integrity": "sha512-Sc28JNQNDzaH6PORtRLMvif9RSn1mYuOoX3omVjnb0+HbpPygU2ALBI0R/wsiqCb4/fcp07Gdo8g+fhtFrQl6A==",
      "dev": true
    },
    "hmac-drbg": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/hmac-drbg/-/hmac-drbg-1.0.1.tgz",
      "integrity": "sha1-0nRXAQJabHdabFRXk+1QL8DGSaE=",
      "dev": true,
      "requires": {
        "hash.js": "^1.0.3",
        "minimalistic-assert": "^1.0.0",
        "minimalistic-crypto-utils": "^1.0.1"
      }
    },
    "hosted-git-info": {
      "version": "2.7.1",
      "resolved": "https://registry.npmjs.org/hosted-git-info/-/hosted-git-info-2.7.1.tgz",
      "integrity": "sha512-7T/BxH19zbcCTa8XkMlbK5lTo1WtgkFi3GvdWEyNuc4Vex7/9Dqbnpsf4JMydcfj9HCg4zUWFTL3Za6lapg5/w==",
      "dev": true
    },
    "html-encoding-sniffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/html-encoding-sniffer/-/html-encoding-sniffer-1.0.2.tgz",
      "integrity": "sha512-71lZziiDnsuabfdYiUeWdCVyKuqwWi23L8YeIgV9jSSZHCtb6wB1BKWooH7L3tn4/FuZJMVWyNaIDr4RGmaSYw==",
      "dev": true,
      "requires": {
        "whatwg-encoding": "^1.0.1"
      }
    },
    "html-void-elements": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/html-void-elements/-/html-void-elements-1.0.3.tgz",
      "integrity": "sha512-SaGhCDPXJVNrQyKMtKy24q6IMdXg5FCPN3z+xizxw9l+oXQw5fOoaj/ERU5KqWhSYhXtW5bWthlDbTDLBhJQrA==",
      "dev": true
    },
    "htmlescape": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/htmlescape/-/htmlescape-1.1.1.tgz",
      "integrity": "sha1-OgPtwiFLyjtmQko+eVk0lQnLA1E=",
      "dev": true
    },
    "http-errors": {
      "version": "1.7.1",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-1.7.1.tgz",
      "integrity": "sha512-jWEUgtZWGSMba9I1N3gc1HmvpBUaNC9vDdA46yScAdp+C5rdEuKWUBLWTQpW9FwSWSbYYs++b6SDCxf9UEJzfw==",
      "requires": {
        "depd": "~1.1.2",
        "inherits": "2.0.3",
        "setprototypeof": "1.1.0",
        "statuses": ">= 1.5.0 < 2",
        "toidentifier": "1.0.0"
      }
    },
    "http-parser-js": {
      "version": "0.5.0",
      "resolved": "https://registry.npmjs.org/http-parser-js/-/http-parser-js-0.5.0.tgz",
      "integrity": "sha512-cZdEF7r4gfRIq7ezX9J0T+kQmJNOub71dWbgAXVHDct80TKP4MCETtZQ31xyv38UwgzkWPYF/Xc0ge55dW9Z9w==",
      "dev": true
    },
    "http-signature": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/http-signature/-/http-signature-1.2.0.tgz",
      "integrity": "sha1-muzZJRFHcvPZW2WmCruPfBj7rOE=",
      "dev": true,
      "requires": {
        "assert-plus": "^1.0.0",
        "jsprim": "^1.2.2",
        "sshpk": "^1.7.0"
      }
    },
    "https-browserify": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/https-browserify/-/https-browserify-1.0.0.tgz",
      "integrity": "sha1-7AbBDgo0wPL68Zn3/X/Hj//QPHM=",
      "dev": true
    },
    "iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "dev": true,
      "requires": {
        "safer-buffer": ">= 2.1.2 < 3"
      }
    },
    "ieee754": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/ieee754/-/ieee754-1.1.12.tgz",
      "integrity": "sha512-GguP+DRY+pJ3soyIiGPTvdiVXjZ+DbXOxGpXn3eMvNW4x4irjqXm4wHKscC+TfxSJ0yw/S1F24tqdMNsMZTiLA==",
      "dev": true
    },
    "ignore": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-4.0.6.tgz",
      "integrity": "sha512-cyFDKrqc/YdcWFniJhzI42+AzS+gNwmUzOSFcRCQYwySuBBBy/KjuxWLZ/FHEH6Moq1NizMOBWyTcv8O4OZIMg==",
      "dev": true
    },
    "import-fresh": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.0.0.tgz",
      "integrity": "sha512-pOnA9tfM3Uwics+SaBLCNyZZZbK+4PTu0OPZtLlMIrv17EdBoC15S9Kn8ckJ9TZTyKb3ywNE5y1yeDxxGA7nTQ==",
      "dev": true,
      "requires": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "dependencies": {
        "resolve-from": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
          "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
          "dev": true
        }
      }
    },
    "import-local": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/import-local/-/import-local-2.0.0.tgz",
      "integrity": "sha512-b6s04m3O+s3CGSbqDIyP4R6aAwAeYlVq9+WUWep6iHa8ETRf9yei1U48C5MmfJmV9AiLYYBKPMq/W+/WRpQmCQ==",
      "dev": true,
      "requires": {
        "pkg-dir": "^3.0.0",
        "resolve-cwd": "^2.0.0"
      }
    },
    "imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha1-khi5srkoojixPcT7a21XbyMUU+o=",
      "dev": true
    },
    "inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha1-Sb1jMdfQLQwJvJEKEHW6gWW1bfk=",
      "dev": true,
      "requires": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "inherits": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.3.tgz",
      "integrity": "sha1-Yzwsg+PaQqUC9SRmAiSA9CCCYd4="
    },
    "ini": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/ini/-/ini-1.3.5.tgz",
      "integrity": "sha512-RZY5huIKCMRWDUqZlEi72f/lmXKMvuszcMBduliQ3nnWbx9X/ZBQO7DijMEYS9EhHBb2qacRUMtC7svLwe0lcw==",
      "dev": true
    },
    "inline-source-map": {
      "version": "0.6.2",
      "resolved": "https://registry.npmjs.org/inline-source-map/-/inline-source-map-0.6.2.tgz",
      "integrity": "sha1-+Tk0ccGKedFyT4Y/o4tYY3Ct4qU=",
      "dev": true,
      "requires": {
        "source-map": "~0.5.3"
      }
    },
    "inquirer": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/inquirer/-/inquirer-6.2.2.tgz",
      "integrity": "sha512-Z2rREiXA6cHRR9KBOarR3WuLlFzlIfAEIiB45ll5SSadMg7WqOh1MKEjjndfuH5ewXdixWCxqnVfGOQzPeiztA==",
      "dev": true,
      "requires": {
        "ansi-escapes": "^3.2.0",
        "chalk": "^2.4.2",
        "cli-cursor": "^2.1.0",
        "cli-width": "^2.0.0",
        "external-editor": "^3.0.3",
        "figures": "^2.0.0",
        "lodash": "^4.17.11",
        "mute-stream": "0.0.7",
        "run-async": "^2.2.0",
        "rxjs": "^6.4.0",
        "string-width": "^2.1.0",
        "strip-ansi": "^5.0.0",
        "through": "^2.3.6"
      },
      "dependencies": {
        "ansi-escapes": {
          "version": "3.2.0",
          "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-3.2.0.tgz",
          "integrity": "sha512-cBhpre4ma+U0T1oM5fXg7Dy1Jw7zzwv7lt/GoCpr+hDQJoYnKVPLL4dCvSEFMmQurOQvSrwT7SL/DAlhBI97RQ==",
          "dev": true
        },
        "ansi-regex": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-4.0.0.tgz",
          "integrity": "sha512-iB5Dda8t/UqpPI/IjsejXu5jOGDrzn41wJyljwPH65VCIbk6+1BzFIMJGFwTNrYXT1CrD+B4l19U7awiQ8rk7w==",
          "dev": true
        },
        "chalk": {
          "version": "2.4.2",
          "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.2.tgz",
          "integrity": "sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==",
          "dev": true,
          "requires": {
            "ansi-styles": "^3.2.1",
            "escape-string-regexp": "^1.0.5",
            "supports-color": "^5.3.0"
          }
        },
        "strip-ansi": {
          "version": "5.0.0",
          "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-5.0.0.tgz",
          "integrity": "sha512-Uu7gQyZI7J7gn5qLn1Np3G9vcYGTVqB+lFTytnDJv83dd8T22aGH451P3jueT2/QemInJDfxHB5Tde5OzgG1Ow==",
          "dev": true,
          "requires": {
            "ansi-regex": "^4.0.0"
          }
        }
      }
    },
    "insert-module-globals": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/insert-module-globals/-/insert-module-globals-7.2.0.tgz",
      "integrity": "sha512-VE6NlW+WGn2/AeOMd496AHFYmE7eLKkUY6Ty31k4og5vmA3Fjuwe9v6ifH6Xx/Hz27QvdoMoviw1/pqWRB09Sw==",
      "dev": true,
      "requires": {
        "JSONStream": "^1.0.3",
        "acorn-node": "^1.5.2",
        "combine-source-map": "^0.8.0",
        "concat-stream": "^1.6.1",
        "is-buffer": "^1.1.0",
        "path-is-absolute": "^1.0.1",
        "process": "~0.11.0",
        "through2": "^2.0.0",
        "undeclared-identifiers": "^1.1.2",
        "xtend": "^4.0.0"
      }
    },
    "invariant": {
      "version": "2.2.4",
      "resolved": "https://registry.npmjs.org/invariant/-/invariant-2.2.4.tgz",
      "integrity": "sha512-phJfQVBuaJM5raOpJjSfkiD6BpbCE4Ns//LaXl6wGYtUBY83nWS6Rf9tXm2e8VaK60JEjYldbPif/A2B1C2gNA==",
      "dev": true,
      "requires": {
        "loose-envify": "^1.0.0"
      }
    },
    "invert-kv": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/invert-kv/-/invert-kv-1.0.0.tgz",
      "integrity": "sha1-EEqOSqym09jNFXqO+L+rLXo//bY=",
      "dev": true
    },
    "is-absolute": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-absolute/-/is-absolute-1.0.0.tgz",
      "integrity": "sha512-dOWoqflvcydARa360Gvv18DZ/gRuHKi2NU/wU5X1ZFzdYfH29nkiNZsF3mp4OJ3H4yo9Mx8A/uAGNzpzPN3yBA==",
      "dev": true,
      "requires": {
        "is-relative": "^1.0.0",
        "is-windows": "^1.0.1"
      }
    },
    "is-accessor-descriptor": {
      "version": "0.1.6",
      "resolved": "http://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-0.1.6.tgz",
      "integrity": "sha1-qeEss66Nh2cn7u84Q/igiXtcmNY=",
      "dev": true,
      "requires": {
        "kind-of": "^3.0.2"
      }
    },
    "is-alphabetical": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-1.0.2.tgz",
      "integrity": "sha512-V0xN4BYezDHcBSKb1QHUFMlR4as/XEuCZBzMJUU4n7+Cbt33SmUnSol+pnXFvLxSHNq2CemUXNdaXV6Flg7+xg==",
      "dev": true
    },
    "is-alphanumeric": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-alphanumeric/-/is-alphanumeric-1.0.0.tgz",
      "integrity": "sha1-Spzvcdr0wAHB2B1j0UDPU/1oifQ=",
      "dev": true
    },
    "is-alphanumerical": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-1.0.2.tgz",
      "integrity": "sha512-pyfU/0kHdISIgslFfZN9nfY1Gk3MquQgUm1mJTjdkEPpkAKNWuBTSqFwewOpR7N351VkErCiyV71zX7mlQQqsg==",
      "dev": true,
      "requires": {
        "is-alphabetical": "^1.0.0",
        "is-decimal": "^1.0.0"
      }
    },
    "is-arrayish": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.2.1.tgz",
      "integrity": "sha1-d8mYQFJ6qOyxqLppe4BkWnqSap0=",
      "dev": true
    },
    "is-binary-path": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-1.0.1.tgz",
      "integrity": "sha1-dfFmQrSA8YenEcgUFh/TpKdlWJg=",
      "dev": true,
      "requires": {
        "binary-extensions": "^1.0.0"
      }
    },
    "is-buffer": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/is-buffer/-/is-buffer-1.1.6.tgz",
      "integrity": "sha512-NcdALwpXkTm5Zvvbk7owOUSvVvBKDgKP5/ewfXEznmQFfs4ZRmanOeKBTjRVjka3QFoN6XJ+9F3USqfHqTaU5w==",
      "dev": true
    },
    "is-builtin-module": {
      "version": "1.0.0",
      "resolved": "http://registry.npmjs.org/is-builtin-module/-/is-builtin-module-1.0.0.tgz",
      "integrity": "sha1-VAVy0096wxGfj3bDDLwbHgN6/74=",
      "dev": true,
      "requires": {
        "builtin-modules": "^1.0.0"
      }
    },
    "is-callable": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.1.4.tgz",
      "integrity": "sha512-r5p9sxJjYnArLjObpjA4xu5EKI3CuKHkJXMhT7kwbpUyIFD1n5PMAsoPvWnvtZiNz7LjkYDRZhd7FlI0eMijEA==",
      "dev": true
    },
    "is-ci": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-ci/-/is-ci-2.0.0.tgz",
      "integrity": "sha512-YfJT7rkpQB0updsdHLGWrvhBJfcfzNNawYDNIyQXJz0IViGf75O8EBPKSdvw2rF+LGCsX4FZ8tcr3b19LcZq4w==",
      "dev": true,
      "requires": {
        "ci-info": "^2.0.0"
      }
    },
    "is-data-descriptor": {
      "version": "0.1.4",
      "resolved": "http://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-0.1.4.tgz",
      "integrity": "sha1-C17mSDiOLIYCgueT8YVv7D8wG1Y=",
      "dev": true,
      "requires": {
        "kind-of": "^3.0.2"
      }
    },
    "is-date-object": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.0.1.tgz",
      "integrity": "sha1-mqIOtq7rv/d/vTPnTKAbM1gdOhY=",
      "dev": true
    },
    "is-decimal": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-1.0.2.tgz",
      "integrity": "sha512-TRzl7mOCchnhchN+f3ICUCzYvL9ul7R+TYOsZ8xia++knyZAJfv/uA1FvQXsAnYIl1T3B2X5E/J7Wb1QXiIBXg==",
      "dev": true
    },
    "is-descriptor": {
      "version": "0.1.6",
      "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-0.1.6.tgz",
      "integrity": "sha512-avDYr0SB3DwO9zsMov0gKCESFYqCnE4hq/4z3TdUlukEy5t9C0YRq7HLrsN52NAcqXKaepeCD0n+B0arnVG3Hg==",
      "dev": true,
      "requires": {
        "is-accessor-descriptor": "^0.1.6",
        "is-data-descriptor": "^0.1.4",
        "kind-of": "^5.0.0"
      },
      "dependencies": {
        "kind-of": {
          "version": "5.1.0",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-5.1.0.tgz",
          "integrity": "sha512-NGEErnH6F2vUuXDh+OlbcKW7/wOcfdRHaZ7VWtqCztfHri/++YKmP51OdWeGPuqCOba6kk2OTe5d02VmTB80Pw==",
          "dev": true
        }
      }
    },
    "is-extendable": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/is-extendable/-/is-extendable-0.1.1.tgz",
      "integrity": "sha1-YrEQ4omkcUGOPsNqYX1HLjAd/Ik=",
      "dev": true
    },
    "is-fullwidth-code-point": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-2.0.0.tgz",
      "integrity": "sha1-o7MKXE8ZkYMWeqq5O+764937ZU8=",
      "dev": true
    },
    "is-generator-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-fn/-/is-generator-fn-2.1.0.tgz",
      "integrity": "sha512-cTIB4yPYL/Grw0EaSzASzg6bBy9gqCofvWN8okThAYIxKJZC+udlRAmGbM0XLeniEJSs8uEgHPGuHSe1XsOLSQ==",
      "dev": true
    },
    "is-hexadecimal": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-1.0.2.tgz",
      "integrity": "sha512-but/G3sapV3MNyqiDBLrOi4x8uCIw0RY3o/Vb5GT0sMFHrVV7731wFSVy41T5FO1og7G0gXLJh0MkgPRouko/A==",
      "dev": true
    },
    "is-negated-glob": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-negated-glob/-/is-negated-glob-1.0.0.tgz",
      "integrity": "sha1-aRC8pdqMleeEtXUbl2z1oQ/uNtI=",
      "dev": true
    },
    "is-number": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
      "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
      "dev": true,
      "requires": {
        "kind-of": "^3.0.2"
      }
    },
    "is-plain-obj": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-1.1.0.tgz",
      "integrity": "sha1-caUMhCnfync8kqOQpKA7OfzVHT4=",
      "dev": true
    },
    "is-plain-object": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/is-plain-object/-/is-plain-object-2.0.4.tgz",
      "integrity": "sha512-h5PpgXkWitc38BBMYawTYMWJHFZJVnBquFE57xFpjB8pJFiF6gZ+bU+WyI/yqXiFR5mdLsgYNaPe8uao6Uv9Og==",
      "dev": true,
      "requires": {
        "isobject": "^3.0.1"
      },
      "dependencies": {
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "is-promise": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-promise/-/is-promise-2.1.0.tgz",
      "integrity": "sha1-eaKp7OfwlugPNtKy87wWwf9L8/o=",
      "dev": true
    },
    "is-regex": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.0.4.tgz",
      "integrity": "sha1-VRdIm1RwkbCTDglWVM7SXul+lJE=",
      "dev": true,
      "requires": {
        "has": "^1.0.1"
      }
    },
    "is-relative": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-relative/-/is-relative-1.0.0.tgz",
      "integrity": "sha512-Kw/ReK0iqwKeu0MITLFuj0jbPAmEiOsIwyIXvvbfa6QfmN9pkD1M+8pdk7Rl/dTKbH34/XBFMbgD4iMJhLQbGA==",
      "dev": true,
      "requires": {
        "is-unc-path": "^1.0.0"
      }
    },
    "is-ssh": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/is-ssh/-/is-ssh-1.3.1.tgz",
      "integrity": "sha512-0eRIASHZt1E68/ixClI8bp2YK2wmBPVWEismTs6M+M099jKgrzl/3E976zIbImSIob48N2/XGe9y7ZiYdImSlg==",
      "dev": true,
      "requires": {
        "protocols": "^1.1.0"
      }
    },
    "is-stream": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-stream/-/is-stream-1.1.0.tgz",
      "integrity": "sha1-EtSj3U5o4Lec6428hBc66A2RykQ=",
      "dev": true
    },
    "is-symbol": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.0.2.tgz",
      "integrity": "sha512-HS8bZ9ox60yCJLH9snBpIwv9pYUAkcuLhSA1oero1UB5y9aiQpRA8y2ex945AOtCZL1lJDeIk3G5LthswI46Lw==",
      "dev": true,
      "requires": {
        "has-symbols": "^1.0.0"
      }
    },
    "is-typedarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-typedarray/-/is-typedarray-1.0.0.tgz",
      "integrity": "sha1-5HnICFjfDBsR3dppQPlgEfzaSpo=",
      "dev": true
    },
    "is-unc-path": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-unc-path/-/is-unc-path-1.0.0.tgz",
      "integrity": "sha512-mrGpVd0fs7WWLfVsStvgF6iEJnbjDFZh9/emhRDcGWTduTfNHd9CHeUwH3gYIjdbwo4On6hunkztwOaAw0yllQ==",
      "dev": true,
      "requires": {
        "unc-path-regex": "^0.1.2"
      }
    },
    "is-utf8": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/is-utf8/-/is-utf8-0.2.1.tgz",
      "integrity": "sha1-Sw2hRCEE0bM2NA6AeX6GXPOffXI=",
      "dev": true
    },
    "is-valid-glob": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/is-valid-glob/-/is-valid-glob-1.0.0.tgz",
      "integrity": "sha1-Kb8+/3Ab4tTTFdusw5vDn+j2Aao=",
      "dev": true
    },
    "is-whitespace-character": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-whitespace-character/-/is-whitespace-character-1.0.2.tgz",
      "integrity": "sha512-SzM+T5GKUCtLhlHFKt2SDAX2RFzfS6joT91F2/WSi9LxgFdsnhfPK/UIA+JhRR2xuyLdrCys2PiFDrtn1fU5hQ==",
      "dev": true
    },
    "is-windows": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-windows/-/is-windows-1.0.2.tgz",
      "integrity": "sha512-eXK1UInq2bPmjyX6e3VHIzMLobc4J94i4AWn+Hpq3OU5KkrRC96OAcR3PRJ/pGu6m8TRnBHP9dkXQVsT/COVIA==",
      "dev": true
    },
    "is-word-character": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-word-character/-/is-word-character-1.0.2.tgz",
      "integrity": "sha512-T3FlsX8rCHAH8e7RE7PfOPZVFQlcV3XRF9eOOBQ1uf70OxO7CjjSOjeImMPCADBdYWcStAbVbYvJ1m2D3tb+EA==",
      "dev": true
    },
    "is-wsl": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-wsl/-/is-wsl-1.1.0.tgz",
      "integrity": "sha1-HxbkqiKwTRM2tmGIpmrzxgDDpm0=",
      "dev": true
    },
    "isarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
      "integrity": "sha1-u5NdSFgsuhaMBoNJV6VKPgcSTxE=",
      "dev": true
    },
    "isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha1-6PvzdNxVb/iUehDcsFctYz8s+hA=",
      "dev": true
    },
    "isobject": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
      "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
      "dev": true
    },
    "isstream": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/isstream/-/isstream-0.1.2.tgz",
      "integrity": "sha1-R+Y/evVa+m+S4VAOaQ64uFKcCZo=",
      "dev": true
    },
    "istanbul-api": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/istanbul-api/-/istanbul-api-2.1.5.tgz",
      "integrity": "sha512-meYk1BwDp59Pfse1TvPrkKYgVqAufbdBLEVoqvu/hLLKSaQ054ZTksbNepyc223tMnWdm6AdK2URIJJRqdP87g==",
      "dev": true,
      "requires": {
        "async": "^2.6.1",
        "compare-versions": "^3.2.1",
        "fileset": "^2.0.3",
        "istanbul-lib-coverage": "^2.0.4",
        "istanbul-lib-hook": "^2.0.6",
        "istanbul-lib-instrument": "^3.2.0",
        "istanbul-lib-report": "^2.0.7",
        "istanbul-lib-source-maps": "^3.0.5",
        "istanbul-reports": "^2.2.3",
        "js-yaml": "^3.13.0",
        "make-dir": "^2.1.0",
        "minimatch": "^3.0.4",
        "once": "^1.4.0"
      }
    },
    "istanbul-lib-coverage": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.4.tgz",
      "integrity": "sha512-LXTBICkMARVgo579kWDm8SqfB6nvSDKNqIOBEjmJRnL04JvoMHCYGWaMddQnseJYtkEuEvO/sIcOxPLk9gERug==",
      "dev": true
    },
    "istanbul-lib-hook": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/istanbul-lib-hook/-/istanbul-lib-hook-2.0.6.tgz",
      "integrity": "sha512-829DKONApZ7UCiPXcOYWSgkFXa4+vNYoNOt3F+4uDJLKL1OotAoVwvThoEj1i8jmOj7odbYcR3rnaHu+QroaXg==",
      "dev": true,
      "requires": {
        "append-transform": "^1.0.0"
      }
    },
    "istanbul-lib-instrument": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-3.2.0.tgz",
      "integrity": "sha512-06IM3xShbNW4NgZv5AP4QH0oHqf1/ivFo8eFys0ZjPXHGldHJQWb3riYOKXqmOqfxXBfxu4B+g/iuhOPZH0RJg==",
      "dev": true,
      "requires": {
        "@babel/generator": "^7.0.0",
        "@babel/parser": "^7.0.0",
        "@babel/template": "^7.0.0",
        "@babel/traverse": "^7.0.0",
        "@babel/types": "^7.0.0",
        "istanbul-lib-coverage": "^2.0.4",
        "semver": "^6.0.0"
      },
      "dependencies": {
        "semver": {
          "version": "6.0.0",
          "resolved": "https://registry.npmjs.org/semver/-/semver-6.0.0.tgz",
          "integrity": "sha512-0UewU+9rFapKFnlbirLi3byoOuhrSsli/z/ihNnvM24vgF+8sNBiI1LZPBSH9wJKUwaUbw+s3hToDLCXkrghrQ==",
          "dev": true
        }
      }
    },
    "istanbul-lib-report": {
      "version": "2.0.7",
      "resolved": "https://registry.npmjs.org/istanbul-lib-report/-/istanbul-lib-report-2.0.7.tgz",
      "integrity": "sha512-wLH6beJBFbRBLiTlMOBxmb85cnVM1Vyl36N48e4e/aTKSM3WbOx7zbVIH1SQ537fhhsPbX0/C5JB4qsmyRXXyA==",
      "dev": true,
      "requires": {
        "istanbul-lib-coverage": "^2.0.4",
        "make-dir": "^2.1.0",
        "supports-color": "^6.0.0"
      },
      "dependencies": {
        "supports-color": {
          "version": "6.1.0",
          "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-6.1.0.tgz",
          "integrity": "sha512-qe1jfm1Mg7Nq/NSh6XE24gPXROEVsWHxC1LIx//XNlD9iw7YZQGjZNjYN7xGaEG6iKdA8EtNFW6R0gjnVXp+wQ==",
          "dev": true,
          "requires": {
            "has-flag": "^3.0.0"
          }
        }
      }
    },
    "istanbul-lib-source-maps": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/istanbul-lib-source-maps/-/istanbul-lib-source-maps-3.0.5.tgz",
      "integrity": "sha512-eDhZ7r6r1d1zQPVZehLc3D0K14vRba/eBYkz3rw16DLOrrTzve9RmnkcwrrkWVgO1FL3EK5knujVe5S8QHE9xw==",
      "dev": true,
      "requires": {
        "debug": "^4.1.1",
        "istanbul-lib-coverage": "^2.0.4",
        "make-dir": "^2.1.0",
        "rimraf": "^2.6.2",
        "source-map": "^0.6.1"
      },
      "dependencies": {
        "debug": {
          "version": "4.1.1",
          "resolved": "https://registry.npmjs.org/debug/-/debug-4.1.1.tgz",
          "integrity": "sha512-pYAIzeRo8J6KPEaJ0VWOh5Pzkbw/RetuzehGM7QRRX5he4fPHx2rdKMB256ehJCkX+XRQm16eZLqLNS8RSZXZw==",
          "dev": true,
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "ms": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
          "dev": true
        },
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "istanbul-reports": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/istanbul-reports/-/istanbul-reports-2.2.3.tgz",
      "integrity": "sha512-T6EbPuc8Cb620LWAYyZ4D8SSn06dY9i1+IgUX2lTH8gbwflMc9Obd33zHTyNX653ybjpamAHS9toKS3E6cGhTw==",
      "dev": true,
      "requires": {
        "handlebars": "^4.1.0"
      }
    },
    "jest": {
      "version": "24.1.0",
      "resolved": "https://registry.npmjs.org/jest/-/jest-24.1.0.tgz",
      "integrity": "sha512-+q91L65kypqklvlRFfXfdzUKyngQLOcwGhXQaLmVHv+d09LkNXuBuGxlofTFW42XMzu3giIcChchTsCNUjQ78A==",
      "dev": true,
      "requires": {
        "import-local": "^2.0.0",
        "jest-cli": "^24.1.0"
      },
      "dependencies": {
        "camelcase": {
          "version": "5.3.1",
          "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
          "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
          "dev": true
        },
        "cross-spawn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-6.0.5.tgz",
          "integrity": "sha512-eTVLrBSt7fjbDygz805pMnstIs2VTBNkRm0qxZd+M7A5XDdxVRWO5MxGBXZhjY4cqLYLdtrGqRf8mBPmzwSpWQ==",
          "dev": true,
          "requires": {
            "nice-try": "^1.0.4",
            "path-key": "^2.0.1",
            "semver": "^5.5.0",
            "shebang-command": "^1.2.0",
            "which": "^1.2.9"
          }
        },
        "execa": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/execa/-/execa-1.0.0.tgz",
          "integrity": "sha512-adbxcyWV46qiHyvSp50TKt05tB4tK3HcmF7/nxfAdhnox83seTDbwnaqKO4sXRy7roHAIFqJP/Rw/AuEbX61LA==",
          "dev": true,
          "requires": {
            "cross-spawn": "^6.0.0",
            "get-stream": "^4.0.0",
            "is-stream": "^1.1.0",
            "npm-run-path": "^2.0.0",
            "p-finally": "^1.0.0",
            "signal-exit": "^3.0.0",
            "strip-eof": "^1.0.0"
          }
        },
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "get-stream": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-4.1.0.tgz",
          "integrity": "sha512-GMat4EJ5161kIy2HevLlr4luNjBgvmj413KaQA7jt4V8B4RDsfpHk7WQ9GVqfYyyx8OS/L66Kox+rJRNklLK7w==",
          "dev": true,
          "requires": {
            "pump": "^3.0.0"
          }
        },
        "invert-kv": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/invert-kv/-/invert-kv-2.0.0.tgz",
          "integrity": "sha512-wPVv/y/QQ/Uiirj/vh3oP+1Ww+AWehmi1g5fFWGPF6IpCBCDVrhgHRMvrLfdYcwDh3QJbGXDW4JAuzxElLSqKA==",
          "dev": true
        },
        "jest-cli": {
          "version": "24.7.1",
          "resolved": "https://registry.npmjs.org/jest-cli/-/jest-cli-24.7.1.tgz",
          "integrity": "sha512-32OBoSCVPzcTslGFl6yVCMzB2SqX3IrWwZCY5mZYkb0D2WsogmU3eV2o8z7+gRQa4o4sZPX/k7GU+II7CxM6WQ==",
          "dev": true,
          "requires": {
            "@jest/core": "^24.7.1",
            "@jest/test-result": "^24.7.1",
            "@jest/types": "^24.7.0",
            "chalk": "^2.0.1",
            "exit": "^0.1.2",
            "import-local": "^2.0.0",
            "is-ci": "^2.0.0",
            "jest-config": "^24.7.1",
            "jest-util": "^24.7.1",
            "jest-validate": "^24.7.0",
            "prompts": "^2.0.1",
            "realpath-native": "^1.1.0",
            "yargs": "^12.0.2"
          },
          "dependencies": {
            "exit": {
              "version": "0.1.2",
              "resolved": "https://registry.npmjs.org/exit/-/exit-0.1.2.tgz",
              "integrity": "sha1-BjJjj42HfMghB9MKD/8aF8uhzQw=",
              "dev": true
            },
            "is-ci": {
              "version": "2.0.0",
              "resolved": "https://registry.npmjs.org/is-ci/-/is-ci-2.0.0.tgz",
              "integrity": "sha512-YfJT7rkpQB0updsdHLGWrvhBJfcfzNNawYDNIyQXJz0IViGf75O8EBPKSdvw2rF+LGCsX4FZ8tcr3b19LcZq4w==",
              "dev": true,
              "requires": {
                "ci-info": "^2.0.0"
              }
            },
            "jest-config": {
              "version": "24.7.1",
              "resolved": "https://registry.npmjs.org/jest-config/-/jest-config-24.7.1.tgz",
              "integrity": "sha512-8FlJNLI+X+MU37j7j8RE4DnJkvAghXmBWdArVzypW6WxfGuxiL/CCkzBg0gHtXhD2rxla3IMOSUAHylSKYJ83g==",
              "dev": true,
              "requires": {
                "@babel/core": "^7.1.0",
                "@jest/test-sequencer": "^24.7.1",
                "@jest/types": "^24.7.0",
                "babel-jest": "^24.7.1",
                "chalk": "^2.0.1",
                "glob": "^7.1.1",
                "jest-environment-jsdom": "^24.7.1",
                "jest-environment-node": "^24.7.1",
                "jest-get-type": "^24.3.0",
                "jest-jasmine2": "^24.7.1",
                "jest-regex-util": "^24.3.0",
                "jest-resolve": "^24.7.1",
                "jest-util": "^24.7.1",
                "jest-validate": "^24.7.0",
                "micromatch": "^3.1.10",
                "pretty-format": "^24.7.0",
                "realpath-native": "^1.1.0"
              }
            },
            "jest-util": {
              "version": "24.7.1",
              "resolved": "https://registry.npmjs.org/jest-util/-/jest-util-24.7.1.tgz",
              "integrity": "sha512-/KilOue2n2rZ5AnEBYoxOXkeTu6vi7cjgQ8MXEkih0oeAXT6JkS3fr7/j8+engCjciOU1Nq5loMSKe0A1oeX0A==",
              "dev": true,
              "requires": {
                "@jest/console": "^24.7.1",
                "@jest/fake-timers": "^24.7.1",
                "@jest/source-map": "^24.3.0",
                "@jest/test-result": "^24.7.1",
                "@jest/types": "^24.7.0",
                "callsites": "^3.0.0",
                "chalk": "^2.0.1",
                "graceful-fs": "^4.1.15",
                "is-ci": "^2.0.0",
                "mkdirp": "^0.5.1",
                "slash": "^2.0.0",
                "source-map": "^0.6.0"
              }
            },
            "jest-validate": {
              "version": "24.7.0",
              "resolved": "https://registry.npmjs.org/jest-validate/-/jest-validate-24.7.0.tgz",
              "integrity": "sha512-cgai/gts9B2chz1rqVdmLhzYxQbgQurh1PEQSvSgPZ8KGa1AqXsqC45W5wKEwzxKrWqypuQrQxnF4+G9VejJJA==",
              "dev": true,
              "requires": {
                "@jest/types": "^24.7.0",
                "camelcase": "^5.0.0",
                "chalk": "^2.0.1",
                "jest-get-type": "^24.3.0",
                "leven": "^2.1.0",
                "pretty-format": "^24.7.0"
              }
            },
            "prompts": {
              "version": "2.0.4",
              "resolved": "https://registry.npmjs.org/prompts/-/prompts-2.0.4.tgz",
              "integrity": "sha512-HTzM3UWp/99A0gk51gAegwo1QRYA7xjcZufMNe33rCclFszUYAuHe1fIN/3ZmiHeGPkUsNaRyQm1hHOfM0PKxA==",
              "dev": true,
              "requires": {
                "kleur": "^3.0.2",
                "sisteransi": "^1.0.0"
              }
            },
            "realpath-native": {
              "version": "1.1.0",
              "resolved": "https://registry.npmjs.org/realpath-native/-/realpath-native-1.1.0.tgz",
              "integrity": "sha512-wlgPA6cCIIg9gKz0fgAPjnzh4yR/LnXovwuo9hvyGvx3h8nX4+/iLZplfUWasXpqD8BdnGnP5njOFjkUwPzvjA==",
              "dev": true,
              "requires": {
                "util.promisify": "^1.0.0"
              }
            },
            "yargs": {
              "version": "12.0.5",
              "resolved": "https://registry.npmjs.org/yargs/-/yargs-12.0.5.tgz",
              "integrity": "sha512-Lhz8TLaYnxq/2ObqHDql8dX8CJi97oHxrjUcYtzKbbykPtVW9WB+poxI+NM2UIzsMgNCZTIf0AQwsjK5yMAqZw==",
              "dev": true,
              "requires": {
                "cliui": "^4.0.0",
                "decamelize": "^1.2.0",
                "find-up": "^3.0.0",
                "get-caller-file": "^1.0.1",
                "os-locale": "^3.0.0",
                "require-directory": "^2.1.1",
                "require-main-filename": "^1.0.1",
                "set-blocking": "^2.0.0",
                "string-width": "^2.0.0",
                "which-module": "^2.0.0",
                "y18n": "^3.2.1 || ^4.0.0",
                "yargs-parser": "^11.1.1"
              }
            }
          }
        },
        "lcid": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/lcid/-/lcid-2.0.0.tgz",
          "integrity": "sha512-avPEb8P8EGnwXKClwsNUgryVjllcRqtMYa49NTsbQagYuT1DcXnl1915oxWjoyGrXR6zH/Y0Zc96xWsPcoDKeA==",
          "dev": true,
          "requires": {
            "invert-kv": "^2.0.0"
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "mem": {
          "version": "4.3.0",
          "resolved": "https://registry.npmjs.org/mem/-/mem-4.3.0.tgz",
          "integrity": "sha512-qX2bG48pTqYRVmDB37rn/6PT7LcR8T7oAX3bf99u1Tt1nzxYfxkgqDwUwolPlXweM0XzBOBFzSx4kfp7KP1s/w==",
          "dev": true,
          "requires": {
            "map-age-cleaner": "^0.1.1",
            "mimic-fn": "^2.0.0",
            "p-is-promise": "^2.0.0"
          }
        },
        "mimic-fn": {
          "version": "2.1.0",
          "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
          "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
          "dev": true
        },
        "os-locale": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/os-locale/-/os-locale-3.1.0.tgz",
          "integrity": "sha512-Z8l3R4wYWM40/52Z+S265okfFj8Kt2cC2MKY+xNi3kFs+XGI7WXu/I309QQQYbRW4ijiZ+yxs9pqEhJh0DqW3Q==",
          "dev": true,
          "requires": {
            "execa": "^1.0.0",
            "lcid": "^2.0.0",
            "mem": "^4.0.0"
          }
        },
        "p-limit": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.2.0.tgz",
          "integrity": "sha512-pZbTJpoUsCzV48Mc9Nh51VbwO0X9cuPFE8gYwx9BTCt9SF8/b7Zljd2fVgOxhIF/HDTKgpVzs+GPhyKfjLLFRQ==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
          "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
          "dev": true
        },
        "pump": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.0.tgz",
          "integrity": "sha512-LwZy+p3SFs1Pytd/jYct4wpv49HiYCqd9Rlc5ZVdk0V+8Yzv6jR5Blk3TRmPL1ft69TxP0IMZGJ+WPFU2BFhww==",
          "dev": true,
          "requires": {
            "end-of-stream": "^1.1.0",
            "once": "^1.3.1"
          }
        },
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "jest-changed-files": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-changed-files/-/jest-changed-files-24.7.0.tgz",
      "integrity": "sha512-33BgewurnwSfJrW7T5/ZAXGE44o7swLslwh8aUckzq2e17/2Os1V0QU506ZNik3hjs8MgnEMKNkcud442NCDTw==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "execa": "^1.0.0",
        "throat": "^4.0.0"
      },
      "dependencies": {
        "cross-spawn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-6.0.5.tgz",
          "integrity": "sha512-eTVLrBSt7fjbDygz805pMnstIs2VTBNkRm0qxZd+M7A5XDdxVRWO5MxGBXZhjY4cqLYLdtrGqRf8mBPmzwSpWQ==",
          "dev": true,
          "requires": {
            "nice-try": "^1.0.4",
            "path-key": "^2.0.1",
            "semver": "^5.5.0",
            "shebang-command": "^1.2.0",
            "which": "^1.2.9"
          }
        },
        "execa": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/execa/-/execa-1.0.0.tgz",
          "integrity": "sha512-adbxcyWV46qiHyvSp50TKt05tB4tK3HcmF7/nxfAdhnox83seTDbwnaqKO4sXRy7roHAIFqJP/Rw/AuEbX61LA==",
          "dev": true,
          "requires": {
            "cross-spawn": "^6.0.0",
            "get-stream": "^4.0.0",
            "is-stream": "^1.1.0",
            "npm-run-path": "^2.0.0",
            "p-finally": "^1.0.0",
            "signal-exit": "^3.0.0",
            "strip-eof": "^1.0.0"
          }
        },
        "get-stream": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-4.1.0.tgz",
          "integrity": "sha512-GMat4EJ5161kIy2HevLlr4luNjBgvmj413KaQA7jt4V8B4RDsfpHk7WQ9GVqfYyyx8OS/L66Kox+rJRNklLK7w==",
          "dev": true,
          "requires": {
            "pump": "^3.0.0"
          }
        },
        "pump": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.0.tgz",
          "integrity": "sha512-LwZy+p3SFs1Pytd/jYct4wpv49HiYCqd9Rlc5ZVdk0V+8Yzv6jR5Blk3TRmPL1ft69TxP0IMZGJ+WPFU2BFhww==",
          "dev": true,
          "requires": {
            "end-of-stream": "^1.1.0",
            "once": "^1.3.1"
          }
        }
      }
    },
    "jest-config": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-config/-/jest-config-24.7.1.tgz",
      "integrity": "sha512-8FlJNLI+X+MU37j7j8RE4DnJkvAghXmBWdArVzypW6WxfGuxiL/CCkzBg0gHtXhD2rxla3IMOSUAHylSKYJ83g==",
      "dev": true,
      "requires": {
        "@babel/core": "^7.1.0",
        "@jest/test-sequencer": "^24.7.1",
        "@jest/types": "^24.7.0",
        "babel-jest": "^24.7.1",
        "chalk": "^2.0.1",
        "glob": "^7.1.1",
        "jest-environment-jsdom": "^24.7.1",
        "jest-environment-node": "^24.7.1",
        "jest-get-type": "^24.3.0",
        "jest-jasmine2": "^24.7.1",
        "jest-regex-util": "^24.3.0",
        "jest-resolve": "^24.7.1",
        "jest-util": "^24.7.1",
        "jest-validate": "^24.7.0",
        "micromatch": "^3.1.10",
        "pretty-format": "^24.7.0",
        "realpath-native": "^1.1.0"
      }
    },
    "jest-diff": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-diff/-/jest-diff-24.7.0.tgz",
      "integrity": "sha512-ULQZ5B1lWpH70O4xsANC4tf4Ko6RrpwhE3PtG6ERjMg1TiYTC2Wp4IntJVGro6a8HG9luYHhhmF4grF0Pltckg==",
      "dev": true,
      "requires": {
        "chalk": "^2.0.1",
        "diff-sequences": "^24.3.0",
        "jest-get-type": "^24.3.0",
        "pretty-format": "^24.7.0"
      }
    },
    "jest-docblock": {
      "version": "24.3.0",
      "resolved": "https://registry.npmjs.org/jest-docblock/-/jest-docblock-24.3.0.tgz",
      "integrity": "sha512-nlANmF9Yq1dufhFlKG9rasfQlrY7wINJbo3q01tu56Jv5eBU5jirylhF2O5ZBnLxzOVBGRDz/9NAwNyBtG4Nyg==",
      "dev": true,
      "requires": {
        "detect-newline": "^2.1.0"
      }
    },
    "jest-each": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-each/-/jest-each-24.7.1.tgz",
      "integrity": "sha512-4fsS8fEfLa3lfnI1Jw6NxjhyRTgfpuOVTeUZZFyVYqeTa4hPhr2YkToUhouuLTrL2eMGOfpbdMyRx0GQ/VooKA==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "chalk": "^2.0.1",
        "jest-get-type": "^24.3.0",
        "jest-util": "^24.7.1",
        "pretty-format": "^24.7.0"
      }
    },
    "jest-environment-jsdom": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-environment-jsdom/-/jest-environment-jsdom-24.7.1.tgz",
      "integrity": "sha512-Gnhb+RqE2JuQGb3kJsLF8vfqjt3PHKSstq4Xc8ic+ax7QKo4Z0RWGucU3YV+DwKR3T9SYc+3YCUQEJs8r7+Jxg==",
      "dev": true,
      "requires": {
        "@jest/environment": "^24.7.1",
        "@jest/fake-timers": "^24.7.1",
        "@jest/types": "^24.7.0",
        "jest-mock": "^24.7.0",
        "jest-util": "^24.7.1",
        "jsdom": "^11.5.1"
      }
    },
    "jest-environment-node": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-environment-node/-/jest-environment-node-24.7.1.tgz",
      "integrity": "sha512-GJJQt1p9/C6aj6yNZMvovZuxTUd+BEJprETdvTKSb4kHcw4mFj8777USQV0FJoJ4V3djpOwA5eWyPwfq//PFBA==",
      "dev": true,
      "requires": {
        "@jest/environment": "^24.7.1",
        "@jest/fake-timers": "^24.7.1",
        "@jest/types": "^24.7.0",
        "jest-mock": "^24.7.0",
        "jest-util": "^24.7.1"
      }
    },
    "jest-get-type": {
      "version": "24.3.0",
      "resolved": "https://registry.npmjs.org/jest-get-type/-/jest-get-type-24.3.0.tgz",
      "integrity": "sha512-HYF6pry72YUlVcvUx3sEpMRwXEWGEPlJ0bSPVnB3b3n++j4phUEoSPcS6GC0pPJ9rpyPSe4cb5muFo6D39cXow==",
      "dev": true
    },
    "jest-haste-map": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-haste-map/-/jest-haste-map-24.7.1.tgz",
      "integrity": "sha512-g0tWkzjpHD2qa03mTKhlydbmmYiA2KdcJe762SbfFo/7NIMgBWAA0XqQlApPwkWOF7Cxoi/gUqL0i6DIoLpMBw==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "anymatch": "^2.0.0",
        "fb-watchman": "^2.0.0",
        "fsevents": "^1.2.7",
        "graceful-fs": "^4.1.15",
        "invariant": "^2.2.4",
        "jest-serializer": "^24.4.0",
        "jest-util": "^24.7.1",
        "jest-worker": "^24.6.0",
        "micromatch": "^3.1.10",
        "sane": "^4.0.3",
        "walker": "^1.0.7"
      },
      "dependencies": {
        "fsevents": {
          "version": "1.2.9",
          "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-1.2.9.tgz",
          "integrity": "sha512-oeyj2H3EjjonWcFjD5NvZNE9Rqe4UW+nQBU2HNeKw0koVLEFIhtyETyAakeAM3de7Z/SW5kcA+fZUait9EApnw==",
          "dev": true,
          "optional": true,
          "requires": {
            "nan": "^2.12.1",
            "node-pre-gyp": "^0.12.0"
          },
          "dependencies": {
            "abbrev": {
              "version": "1.1.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "ansi-regex": {
              "version": "2.1.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "aproba": {
              "version": "1.2.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "are-we-there-yet": {
              "version": "1.1.5",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "delegates": "^1.0.0",
                "readable-stream": "^2.0.6"
              }
            },
            "balanced-match": {
              "version": "1.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "brace-expansion": {
              "version": "1.1.11",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "balanced-match": "^1.0.0",
                "concat-map": "0.0.1"
              }
            },
            "chownr": {
              "version": "1.1.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "code-point-at": {
              "version": "1.1.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "concat-map": {
              "version": "0.0.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "console-control-strings": {
              "version": "1.1.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "core-util-is": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "debug": {
              "version": "4.1.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "ms": "^2.1.1"
              }
            },
            "deep-extend": {
              "version": "0.6.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "delegates": {
              "version": "1.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "detect-libc": {
              "version": "1.0.3",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "fs-minipass": {
              "version": "1.2.5",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "minipass": "^2.2.1"
              }
            },
            "fs.realpath": {
              "version": "1.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "gauge": {
              "version": "2.7.4",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "aproba": "^1.0.3",
                "console-control-strings": "^1.0.0",
                "has-unicode": "^2.0.0",
                "object-assign": "^4.1.0",
                "signal-exit": "^3.0.0",
                "string-width": "^1.0.1",
                "strip-ansi": "^3.0.1",
                "wide-align": "^1.1.0"
              }
            },
            "glob": {
              "version": "7.1.3",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "fs.realpath": "^1.0.0",
                "inflight": "^1.0.4",
                "inherits": "2",
                "minimatch": "^3.0.4",
                "once": "^1.3.0",
                "path-is-absolute": "^1.0.0"
              }
            },
            "has-unicode": {
              "version": "2.0.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "iconv-lite": {
              "version": "0.4.24",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "safer-buffer": ">= 2.1.2 < 3"
              }
            },
            "ignore-walk": {
              "version": "3.0.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "minimatch": "^3.0.4"
              }
            },
            "inflight": {
              "version": "1.0.6",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "once": "^1.3.0",
                "wrappy": "1"
              }
            },
            "inherits": {
              "version": "2.0.3",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "ini": {
              "version": "1.3.5",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "is-fullwidth-code-point": {
              "version": "1.0.0",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "number-is-nan": "^1.0.0"
              }
            },
            "isarray": {
              "version": "1.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "minimatch": {
              "version": "3.0.4",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "brace-expansion": "^1.1.7"
              }
            },
            "minimist": {
              "version": "0.0.8",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "minipass": {
              "version": "2.3.5",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "safe-buffer": "^5.1.2",
                "yallist": "^3.0.0"
              }
            },
            "minizlib": {
              "version": "1.2.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "minipass": "^2.2.1"
              }
            },
            "mkdirp": {
              "version": "0.5.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "minimist": "0.0.8"
              }
            },
            "ms": {
              "version": "2.1.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "needle": {
              "version": "2.3.0",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "debug": "^4.1.0",
                "iconv-lite": "^0.4.4",
                "sax": "^1.2.4"
              }
            },
            "node-pre-gyp": {
              "version": "0.12.0",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "detect-libc": "^1.0.2",
                "mkdirp": "^0.5.1",
                "needle": "^2.2.1",
                "nopt": "^4.0.1",
                "npm-packlist": "^1.1.6",
                "npmlog": "^4.0.2",
                "rc": "^1.2.7",
                "rimraf": "^2.6.1",
                "semver": "^5.3.0",
                "tar": "^4"
              }
            },
            "nopt": {
              "version": "4.0.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "abbrev": "1",
                "osenv": "^0.1.4"
              }
            },
            "npm-bundled": {
              "version": "1.0.6",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "npm-packlist": {
              "version": "1.4.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "ignore-walk": "^3.0.1",
                "npm-bundled": "^1.0.1"
              }
            },
            "npmlog": {
              "version": "4.1.2",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "are-we-there-yet": "~1.1.2",
                "console-control-strings": "~1.1.0",
                "gauge": "~2.7.3",
                "set-blocking": "~2.0.0"
              }
            },
            "number-is-nan": {
              "version": "1.0.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "object-assign": {
              "version": "4.1.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "once": {
              "version": "1.4.0",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "wrappy": "1"
              }
            },
            "os-homedir": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "os-tmpdir": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "osenv": {
              "version": "0.1.5",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "os-homedir": "^1.0.0",
                "os-tmpdir": "^1.0.0"
              }
            },
            "path-is-absolute": {
              "version": "1.0.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "process-nextick-args": {
              "version": "2.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "rc": {
              "version": "1.2.8",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "deep-extend": "^0.6.0",
                "ini": "~1.3.0",
                "minimist": "^1.2.0",
                "strip-json-comments": "~2.0.1"
              },
              "dependencies": {
                "minimist": {
                  "version": "1.2.0",
                  "bundled": true,
                  "dev": true,
                  "optional": true
                }
              }
            },
            "readable-stream": {
              "version": "2.3.6",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "core-util-is": "~1.0.0",
                "inherits": "~2.0.3",
                "isarray": "~1.0.0",
                "process-nextick-args": "~2.0.0",
                "safe-buffer": "~5.1.1",
                "string_decoder": "~1.1.1",
                "util-deprecate": "~1.0.1"
              }
            },
            "rimraf": {
              "version": "2.6.3",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "glob": "^7.1.3"
              }
            },
            "safe-buffer": {
              "version": "5.1.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "safer-buffer": {
              "version": "2.1.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "sax": {
              "version": "1.2.4",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "semver": {
              "version": "5.7.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "set-blocking": {
              "version": "2.0.0",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "signal-exit": {
              "version": "3.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "string-width": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "code-point-at": "^1.0.0",
                "is-fullwidth-code-point": "^1.0.0",
                "strip-ansi": "^3.0.0"
              }
            },
            "string_decoder": {
              "version": "1.1.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "safe-buffer": "~5.1.0"
              }
            },
            "strip-ansi": {
              "version": "3.0.1",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "ansi-regex": "^2.0.0"
              }
            },
            "strip-json-comments": {
              "version": "2.0.1",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "tar": {
              "version": "4.4.8",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "chownr": "^1.1.1",
                "fs-minipass": "^1.2.5",
                "minipass": "^2.3.4",
                "minizlib": "^1.1.1",
                "mkdirp": "^0.5.0",
                "safe-buffer": "^5.1.2",
                "yallist": "^3.0.2"
              }
            },
            "util-deprecate": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "wide-align": {
              "version": "1.1.3",
              "bundled": true,
              "dev": true,
              "optional": true,
              "requires": {
                "string-width": "^1.0.2 || 2"
              }
            },
            "wrappy": {
              "version": "1.0.2",
              "bundled": true,
              "dev": true,
              "optional": true
            },
            "yallist": {
              "version": "3.0.3",
              "bundled": true,
              "dev": true,
              "optional": true
            }
          }
        }
      }
    },
    "jest-jasmine2": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-jasmine2/-/jest-jasmine2-24.7.1.tgz",
      "integrity": "sha512-Y/9AOJDV1XS44wNwCaThq4Pw3gBPiOv/s6NcbOAkVRRUEPu+36L2xoPsqQXsDrxoBerqeyslpn2TpCI8Zr6J2w==",
      "dev": true,
      "requires": {
        "@babel/traverse": "^7.1.0",
        "@jest/environment": "^24.7.1",
        "@jest/test-result": "^24.7.1",
        "@jest/types": "^24.7.0",
        "chalk": "^2.0.1",
        "co": "^4.6.0",
        "expect": "^24.7.1",
        "is-generator-fn": "^2.0.0",
        "jest-each": "^24.7.1",
        "jest-matcher-utils": "^24.7.0",
        "jest-message-util": "^24.7.1",
        "jest-runtime": "^24.7.1",
        "jest-snapshot": "^24.7.1",
        "jest-util": "^24.7.1",
        "pretty-format": "^24.7.0",
        "throat": "^4.0.0"
      }
    },
    "jest-leak-detector": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-leak-detector/-/jest-leak-detector-24.7.0.tgz",
      "integrity": "sha512-zV0qHKZGXtmPVVzT99CVEcHE9XDf+8LwiE0Ob7jjezERiGVljmqKFWpV2IkG+rkFIEUHFEkMiICu7wnoPM/RoQ==",
      "dev": true,
      "requires": {
        "pretty-format": "^24.7.0"
      }
    },
    "jest-matcher-utils": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-matcher-utils/-/jest-matcher-utils-24.7.0.tgz",
      "integrity": "sha512-158ieSgk3LNXeUhbVJYRXyTPSCqNgVXOp/GT7O94mYd3pk/8+odKTyR1JLtNOQSPzNi8NFYVONtvSWA/e1RDXg==",
      "dev": true,
      "requires": {
        "chalk": "^2.0.1",
        "jest-diff": "^24.7.0",
        "jest-get-type": "^24.3.0",
        "pretty-format": "^24.7.0"
      }
    },
    "jest-message-util": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-message-util/-/jest-message-util-24.7.1.tgz",
      "integrity": "sha512-dk0gqVtyqezCHbcbk60CdIf+8UHgD+lmRHifeH3JRcnAqh4nEyPytSc9/L1+cQyxC+ceaeP696N4ATe7L+omcg==",
      "dev": true,
      "requires": {
        "@babel/code-frame": "^7.0.0",
        "@jest/test-result": "^24.7.1",
        "@jest/types": "^24.7.0",
        "@types/stack-utils": "^1.0.1",
        "chalk": "^2.0.1",
        "micromatch": "^3.1.10",
        "slash": "^2.0.0",
        "stack-utils": "^1.0.1"
      }
    },
    "jest-mock": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-mock/-/jest-mock-24.7.0.tgz",
      "integrity": "sha512-6taW4B4WUcEiT2V9BbOmwyGuwuAFT2G8yghF7nyNW1/2gq5+6aTqSPcS9lS6ArvEkX55vbPAS/Jarx5LSm4Fng==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0"
      }
    },
    "jest-pnp-resolver": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/jest-pnp-resolver/-/jest-pnp-resolver-1.2.1.tgz",
      "integrity": "sha512-pgFw2tm54fzgYvc/OHrnysABEObZCUNFnhjoRjaVOCN8NYc032/gVjPaHD4Aq6ApkSieWtfKAFQtmDKAmhupnQ==",
      "dev": true
    },
    "jest-regex-util": {
      "version": "24.3.0",
      "resolved": "https://registry.npmjs.org/jest-regex-util/-/jest-regex-util-24.3.0.tgz",
      "integrity": "sha512-tXQR1NEOyGlfylyEjg1ImtScwMq8Oh3iJbGTjN7p0J23EuVX1MA8rwU69K4sLbCmwzgCUbVkm0FkSF9TdzOhtg==",
      "dev": true
    },
    "jest-resolve": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-resolve/-/jest-resolve-24.7.1.tgz",
      "integrity": "sha512-Bgrc+/UUZpGJ4323sQyj85hV9d+ANyPNu6XfRDUcyFNX1QrZpSoM0kE4Mb2vZMAYTJZsBFzYe8X1UaOkOELSbw==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "browser-resolve": "^1.11.3",
        "chalk": "^2.0.1",
        "jest-pnp-resolver": "^1.2.1",
        "realpath-native": "^1.1.0"
      }
    },
    "jest-resolve-dependencies": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-resolve-dependencies/-/jest-resolve-dependencies-24.7.1.tgz",
      "integrity": "sha512-2Eyh5LJB2liNzfk4eo7bD1ZyBbqEJIyyrFtZG555cSWW9xVHxII2NuOkSl1yUYTAYCAmM2f2aIT5A7HzNmubyg==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "jest-regex-util": "^24.3.0",
        "jest-snapshot": "^24.7.1"
      }
    },
    "jest-runner": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-runner/-/jest-runner-24.7.1.tgz",
      "integrity": "sha512-aNFc9liWU/xt+G9pobdKZ4qTeG/wnJrJna3VqunziDNsWT3EBpmxXZRBMKCsNMyfy+A/XHiV+tsMLufdsNdgCw==",
      "dev": true,
      "requires": {
        "@jest/console": "^24.7.1",
        "@jest/environment": "^24.7.1",
        "@jest/test-result": "^24.7.1",
        "@jest/types": "^24.7.0",
        "chalk": "^2.4.2",
        "exit": "^0.1.2",
        "graceful-fs": "^4.1.15",
        "jest-config": "^24.7.1",
        "jest-docblock": "^24.3.0",
        "jest-haste-map": "^24.7.1",
        "jest-jasmine2": "^24.7.1",
        "jest-leak-detector": "^24.7.0",
        "jest-message-util": "^24.7.1",
        "jest-resolve": "^24.7.1",
        "jest-runtime": "^24.7.1",
        "jest-util": "^24.7.1",
        "jest-worker": "^24.6.0",
        "source-map-support": "^0.5.6",
        "throat": "^4.0.0"
      },
      "dependencies": {
        "chalk": {
          "version": "2.4.2",
          "resolved": "https://registry.npmjs.org/chalk/-/chalk-2.4.2.tgz",
          "integrity": "sha512-Mti+f9lpJNcwF4tWV8/OrTTtF1gZi+f8FqlyAdouralcFWFQWF2+NgCHShjkCb+IFBLq9buZwE1xckQU4peSuQ==",
          "dev": true,
          "requires": {
            "ansi-styles": "^3.2.1",
            "escape-string-regexp": "^1.0.5",
            "supports-color": "^5.3.0"
          }
        }
      }
    },
    "jest-runtime": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-runtime/-/jest-runtime-24.7.1.tgz",
      "integrity": "sha512-0VAbyBy7tll3R+82IPJpf6QZkokzXPIS71aDeqh+WzPRXRCNz6StQ45otFariPdJ4FmXpDiArdhZrzNAC3sj6A==",
      "dev": true,
      "requires": {
        "@jest/console": "^24.7.1",
        "@jest/environment": "^24.7.1",
        "@jest/source-map": "^24.3.0",
        "@jest/transform": "^24.7.1",
        "@jest/types": "^24.7.0",
        "@types/yargs": "^12.0.2",
        "chalk": "^2.0.1",
        "exit": "^0.1.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.1.15",
        "jest-config": "^24.7.1",
        "jest-haste-map": "^24.7.1",
        "jest-message-util": "^24.7.1",
        "jest-mock": "^24.7.0",
        "jest-regex-util": "^24.3.0",
        "jest-resolve": "^24.7.1",
        "jest-snapshot": "^24.7.1",
        "jest-util": "^24.7.1",
        "jest-validate": "^24.7.0",
        "realpath-native": "^1.1.0",
        "slash": "^2.0.0",
        "strip-bom": "^3.0.0",
        "yargs": "^12.0.2"
      }
    },
    "jest-serializer": {
      "version": "24.4.0",
      "resolved": "https://registry.npmjs.org/jest-serializer/-/jest-serializer-24.4.0.tgz",
      "integrity": "sha512-k//0DtglVstc1fv+GY/VHDIjrtNjdYvYjMlbLUed4kxrE92sIUewOi5Hj3vrpB8CXfkJntRPDRjCrCvUhBdL8Q==",
      "dev": true
    },
    "jest-snapshot": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-snapshot/-/jest-snapshot-24.7.1.tgz",
      "integrity": "sha512-8Xk5O4p+JsZZn4RCNUS3pxA+ORKpEKepE+a5ejIKrId9CwrVN0NY+vkqEkXqlstA5NMBkNahXkR/4qEBy0t5yA==",
      "dev": true,
      "requires": {
        "@babel/types": "^7.0.0",
        "@jest/types": "^24.7.0",
        "chalk": "^2.0.1",
        "expect": "^24.7.1",
        "jest-diff": "^24.7.0",
        "jest-matcher-utils": "^24.7.0",
        "jest-message-util": "^24.7.1",
        "jest-resolve": "^24.7.1",
        "mkdirp": "^0.5.1",
        "natural-compare": "^1.4.0",
        "pretty-format": "^24.7.0",
        "semver": "^5.5.0"
      }
    },
    "jest-util": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-util/-/jest-util-24.7.1.tgz",
      "integrity": "sha512-/KilOue2n2rZ5AnEBYoxOXkeTu6vi7cjgQ8MXEkih0oeAXT6JkS3fr7/j8+engCjciOU1Nq5loMSKe0A1oeX0A==",
      "dev": true,
      "requires": {
        "@jest/console": "^24.7.1",
        "@jest/fake-timers": "^24.7.1",
        "@jest/source-map": "^24.3.0",
        "@jest/test-result": "^24.7.1",
        "@jest/types": "^24.7.0",
        "callsites": "^3.0.0",
        "chalk": "^2.0.1",
        "graceful-fs": "^4.1.15",
        "is-ci": "^2.0.0",
        "mkdirp": "^0.5.1",
        "slash": "^2.0.0",
        "source-map": "^0.6.0"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "jest-validate": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/jest-validate/-/jest-validate-24.7.0.tgz",
      "integrity": "sha512-cgai/gts9B2chz1rqVdmLhzYxQbgQurh1PEQSvSgPZ8KGa1AqXsqC45W5wKEwzxKrWqypuQrQxnF4+G9VejJJA==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "camelcase": "^5.0.0",
        "chalk": "^2.0.1",
        "jest-get-type": "^24.3.0",
        "leven": "^2.1.0",
        "pretty-format": "^24.7.0"
      },
      "dependencies": {
        "camelcase": {
          "version": "5.3.1",
          "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
          "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
          "dev": true
        }
      }
    },
    "jest-watcher": {
      "version": "24.7.1",
      "resolved": "https://registry.npmjs.org/jest-watcher/-/jest-watcher-24.7.1.tgz",
      "integrity": "sha512-Wd6TepHLRHVKLNPacEsBwlp9raeBIO+01xrN24Dek4ggTS8HHnOzYSFnvp+6MtkkJ3KfMzy220KTi95e2rRkrw==",
      "dev": true,
      "requires": {
        "@jest/test-result": "^24.7.1",
        "@jest/types": "^24.7.0",
        "@types/yargs": "^12.0.9",
        "ansi-escapes": "^3.0.0",
        "chalk": "^2.0.1",
        "jest-util": "^24.7.1",
        "string-length": "^2.0.0"
      }
    },
    "jest-worker": {
      "version": "24.6.0",
      "resolved": "https://registry.npmjs.org/jest-worker/-/jest-worker-24.6.0.tgz",
      "integrity": "sha512-jDwgW5W9qGNvpI1tNnvajh0a5IE/PuGLFmHk6aR/BZFz8tSgGw17GsDPXAJ6p91IvYDjOw8GpFbvvZGAK+DPQQ==",
      "dev": true,
      "requires": {
        "merge-stream": "^1.0.1",
        "supports-color": "^6.1.0"
      },
      "dependencies": {
        "supports-color": {
          "version": "6.1.0",
          "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-6.1.0.tgz",
          "integrity": "sha512-qe1jfm1Mg7Nq/NSh6XE24gPXROEVsWHxC1LIx//XNlD9iw7YZQGjZNjYN7xGaEG6iKdA8EtNFW6R0gjnVXp+wQ==",
          "dev": true,
          "requires": {
            "has-flag": "^3.0.0"
          }
        }
      }
    },
    "js-levenshtein": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/js-levenshtein/-/js-levenshtein-1.1.6.tgz",
      "integrity": "sha512-X2BB11YZtrRqY4EnQcLX5Rh373zbK4alC1FW7D7MBhL2gtcC17cTnr6DmfHZeS0s2rTHjUTMMHfG7gO8SSdw+g==",
      "dev": true
    },
    "js-sha256": {
      "version": "0.9.0",
      "resolved": "https://registry.npmjs.org/js-sha256/-/js-sha256-0.9.0.tgz",
      "integrity": "sha512-sga3MHh9sgQN2+pJ9VYZ+1LPwXOxuBJBA5nrR5/ofPfuiJBE2hnjsaN8se8JznOmGLN2p49Pe5U/ttafcs/apA=="
    },
    "js-tokens": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-3.0.2.tgz",
      "integrity": "sha1-mGbfOVECEw449/mWvOtlRDIJwls=",
      "dev": true
    },
    "js-yaml": {
      "version": "3.13.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.13.1.tgz",
      "integrity": "sha512-YfbcO7jXDdyj0DGxYVSlSeQNHbD7XPWvrVWeVUujrQEoZzWJIRrCPoyk6kL6IAjAG2IolMK4T0hNUe0HOUs5Jw==",
      "dev": true,
      "requires": {
        "argparse": "^1.0.7",
        "esprima": "^4.0.0"
      }
    },
    "jsbn": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/jsbn/-/jsbn-0.1.1.tgz",
      "integrity": "sha1-peZUwuWi3rXyAdls77yoDA7y9RM=",
      "dev": true
    },
    "jsdom": {
      "version": "11.12.0",
      "resolved": "https://registry.npmjs.org/jsdom/-/jsdom-11.12.0.tgz",
      "integrity": "sha512-y8Px43oyiBM13Zc1z780FrfNLJCXTL40EWlty/LXUtcjykRBNgLlCjWXpfSPBl2iv+N7koQN+dvqszHZgT/Fjw==",
      "dev": true,
      "requires": {
        "abab": "^2.0.0",
        "acorn": "^5.5.3",
        "acorn-globals": "^4.1.0",
        "array-equal": "^1.0.0",
        "cssom": ">= 0.3.2 < 0.4.0",
        "cssstyle": "^1.0.0",
        "data-urls": "^1.0.0",
        "domexception": "^1.0.1",
        "escodegen": "^1.9.1",
        "html-encoding-sniffer": "^1.0.2",
        "left-pad": "^1.3.0",
        "nwsapi": "^2.0.7",
        "parse5": "4.0.0",
        "pn": "^1.1.0",
        "request": "^2.87.0",
        "request-promise-native": "^1.0.5",
        "sax": "^1.2.4",
        "symbol-tree": "^3.2.2",
        "tough-cookie": "^2.3.4",
        "w3c-hr-time": "^1.0.1",
        "webidl-conversions": "^4.0.2",
        "whatwg-encoding": "^1.0.3",
        "whatwg-mimetype": "^2.1.0",
        "whatwg-url": "^6.4.1",
        "ws": "^5.2.0",
        "xml-name-validator": "^3.0.0"
      }
    },
    "json-parse-better-errors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json-parse-better-errors/-/json-parse-better-errors-1.0.2.tgz",
      "integrity": "sha512-mrqyZKfX5EhL7hvqcV6WG1yYjnjeuYDzDhhcAAUrq8Po85NBQBJP+ZDUT75qZQ98IkUoBqdkExkukOU7Ts2wrw==",
      "dev": true
    },
    "json-schema": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/json-schema/-/json-schema-0.2.3.tgz",
      "integrity": "sha1-tIDIkuWaLwWVTOcnvT8qTogvnhM=",
      "dev": true
    },
    "json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true
    },
    "json-stable-stringify": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify/-/json-stable-stringify-0.0.1.tgz",
      "integrity": "sha1-YRwj6BTbN1Un34URk9tZ3Sryf0U=",
      "dev": true,
      "requires": {
        "jsonify": "~0.0.0"
      }
    },
    "json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha1-nbe1lJatPzz+8wp1FC0tkwrXJlE=",
      "dev": true
    },
    "json-stringify-safe": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/json-stringify-safe/-/json-stringify-safe-5.0.1.tgz",
      "integrity": "sha1-Epai1Y/UXxmg9s4B1lcB4sc1tus=",
      "dev": true
    },
    "jsonify": {
      "version": "0.0.0",
      "resolved": "https://registry.npmjs.org/jsonify/-/jsonify-0.0.0.tgz",
      "integrity": "sha1-LHS27kHZPKUbe1qu6PUDYx0lKnM=",
      "dev": true
    },
    "jsonparse": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/jsonparse/-/jsonparse-1.3.1.tgz",
      "integrity": "sha1-P02uSpH6wxX3EGL4UhzCOfE2YoA=",
      "dev": true
    },
    "jsprim": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/jsprim/-/jsprim-1.4.1.tgz",
      "integrity": "sha1-MT5mvB5cwG5Di8G3SZwuXFastqI=",
      "dev": true,
      "requires": {
        "assert-plus": "1.0.0",
        "extsprintf": "1.3.0",
        "json-schema": "0.2.3",
        "verror": "1.10.0"
      }
    },
    "kind-of": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
      "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
      "dev": true,
      "requires": {
        "is-buffer": "^1.1.5"
      }
    },
    "kleur": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/kleur/-/kleur-3.0.3.tgz",
      "integrity": "sha512-eTIzlVOSUR+JxdDFepEYcBMtZ9Qqdef+rnzWdRZuMbOywu5tO2w2N7rqjoANZ5k9vywhL6Br1VRjUIgTQx4E8w==",
      "dev": true
    },
    "labeled-stream-splicer": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/labeled-stream-splicer/-/labeled-stream-splicer-2.0.1.tgz",
      "integrity": "sha512-MC94mHZRvJ3LfykJlTUipBqenZz1pacOZEMhhQ8dMGcDHs0SBE5GbsavUXV7YtP3icBW17W0Zy1I0lfASmo9Pg==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "isarray": "^2.0.4",
        "stream-splicer": "^2.0.0"
      },
      "dependencies": {
        "isarray": {
          "version": "2.0.4",
          "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.4.tgz",
          "integrity": "sha512-GMxXOiUirWg1xTKRipM0Ek07rX+ubx4nNVElTJdNLYmNO/2YrDkgJGw9CljXn+r4EWiDQg/8lsRdHyg2PJuUaA==",
          "dev": true
        }
      }
    },
    "lazystream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/lazystream/-/lazystream-1.0.0.tgz",
      "integrity": "sha1-9plf4PggOS9hOWvolGJAe7dxaOQ=",
      "dev": true,
      "requires": {
        "readable-stream": "^2.0.5"
      }
    },
    "lcid": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/lcid/-/lcid-1.0.0.tgz",
      "integrity": "sha1-MIrMr6C8SDo4Z7S28rlQYlHRuDU=",
      "dev": true,
      "requires": {
        "invert-kv": "^1.0.0"
      }
    },
    "lead": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/lead/-/lead-1.0.0.tgz",
      "integrity": "sha1-bxT5mje+Op3XhPVJVpDlkDRm7kI=",
      "dev": true,
      "requires": {
        "flush-write-stream": "^1.0.2"
      }
    },
    "left-pad": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/left-pad/-/left-pad-1.3.0.tgz",
      "integrity": "sha512-XI5MPzVNApjAyhQzphX8BkmKsKUxD4LdyK24iZeQGinBN9yTQT3bFlCBy/aVx2HrNcqQGsdot8ghrjyrvMCoEA==",
      "dev": true
    },
    "leven": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/leven/-/leven-2.1.0.tgz",
      "integrity": "sha1-wuep93IJTe6dNCAq6KzORoeHVYA=",
      "dev": true
    },
    "levn": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.3.0.tgz",
      "integrity": "sha1-OwmSTt+fCDwEkP3UwLxEIeBHZO4=",
      "dev": true,
      "requires": {
        "prelude-ls": "~1.1.2",
        "type-check": "~0.3.2"
      }
    },
    "livereload-js": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/livereload-js/-/livereload-js-2.4.0.tgz",
      "integrity": "sha512-XPQH8Z2GDP/Hwz2PCDrh2mth4yFejwA1OZ/81Ti3LgKyhDcEjsSsqFWZojHG0va/duGd+WyosY7eXLDoOyqcPw==",
      "dev": true
    },
    "load-json-file": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/load-json-file/-/load-json-file-4.0.0.tgz",
      "integrity": "sha1-L19Fq5HjMhYjT9U62rZo607AmTs=",
      "dev": true,
      "requires": {
        "graceful-fs": "^4.1.2",
        "parse-json": "^4.0.0",
        "pify": "^3.0.0",
        "strip-bom": "^3.0.0"
      }
    },
    "locate-path": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-2.0.0.tgz",
      "integrity": "sha1-K1aLJl7slExtnA3pw9u7ygNUzY4=",
      "dev": true,
      "requires": {
        "p-locate": "^2.0.0",
        "path-exists": "^3.0.0"
      }
    },
    "lodash": {
      "version": "4.17.11",
      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.11.tgz",
      "integrity": "sha512-cQKh8igo5QUhZ7lg38DYWAxMvjSAKG0A8wGSVimP07SIUEK2UO+arSRKbRZWtelMtN5V0Hkwh5ryOto/SshYIg==",
      "dev": true
    },
    "lodash.debounce": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/lodash.debounce/-/lodash.debounce-4.0.8.tgz",
      "integrity": "sha1-gteb/zCmfEAF/9XiUVMArZyk168=",
      "dev": true
    },
    "lodash.memoize": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/lodash.memoize/-/lodash.memoize-3.0.4.tgz",
      "integrity": "sha1-LcvSwofLwKVcxCMovQxzYVDVPj8=",
      "dev": true
    },
    "lodash.sortby": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/lodash.sortby/-/lodash.sortby-4.7.0.tgz",
      "integrity": "sha1-7dFMgk4sycHgsKG0K7UhBRakJDg=",
      "dev": true
    },
    "long": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/long/-/long-4.0.0.tgz",
      "integrity": "sha512-XsP+KhQif4bjX1kbuSiySJFNAehNxgLb6hPRGJ9QsUr8ajHkuXGdrHmFUTUUXhDwVX2R5bY4JNZEwbUiMhV+MA=="
    },
    "longest-streak": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/longest-streak/-/longest-streak-2.0.2.tgz",
      "integrity": "sha512-TmYTeEYxiAmSVdpbnQDXGtvYOIRsCMg89CVZzwzc2o7GFL1CjoiRPjH5ec0NFAVlAx3fVof9dX/t6KKRAo2OWA==",
      "dev": true
    },
    "loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "dev": true,
      "requires": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      }
    },
    "lru-cache": {
      "version": "4.1.5",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-4.1.5.tgz",
      "integrity": "sha512-sWZlbEP2OsHNkXrMl5GYk/jKk70MBng6UU4YI/qGDYbgf6YbP4EvmqISbXCoJiRKs+1bSpFHVgQxvJ17F2li5g==",
      "dev": true,
      "requires": {
        "pseudomap": "^1.0.2",
        "yallist": "^2.1.2"
      }
    },
    "make-dir": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-2.1.0.tgz",
      "integrity": "sha512-LS9X+dc8KLxXCb8dni79fLIIUA5VyZoyjSMCwTluaXA0o27cCK0bhXkpgw+sTXVpPy/lSO57ilRixqk0vDmtRA==",
      "dev": true,
      "requires": {
        "pify": "^4.0.1",
        "semver": "^5.6.0"
      },
      "dependencies": {
        "pify": {
          "version": "4.0.1",
          "resolved": "https://registry.npmjs.org/pify/-/pify-4.0.1.tgz",
          "integrity": "sha512-uB80kBFb/tfd68bVleG9T5GGsGPjJrLAUpR5PZIrhBnIaRTQRjqdJSsIKkOP6OAIFbj7GOrcudc5pNjZ+geV2g==",
          "dev": true
        }
      }
    },
    "makeerror": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/makeerror/-/makeerror-1.0.11.tgz",
      "integrity": "sha1-4BpckQnyr3lmDk6LlYd5AYT1qWw=",
      "dev": true,
      "requires": {
        "tmpl": "1.0.x"
      }
    },
    "map-age-cleaner": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/map-age-cleaner/-/map-age-cleaner-0.1.3.tgz",
      "integrity": "sha512-bJzx6nMoP6PDLPBFmg7+xRKeFZvFboMrGlxmNj9ClvX53KrmvM5bXFXEWjbz4cz1AFn+jWJ9z/DJSz7hrs0w3w==",
      "dev": true,
      "requires": {
        "p-defer": "^1.0.0"
      }
    },
    "map-cache": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/map-cache/-/map-cache-0.2.2.tgz",
      "integrity": "sha1-wyq9C9ZSXZsFFkW7TyasXcmKDb8=",
      "dev": true
    },
    "map-visit": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/map-visit/-/map-visit-1.0.0.tgz",
      "integrity": "sha1-7Nyo8TFE5mDxtb1B8S80edmN+48=",
      "dev": true,
      "requires": {
        "object-visit": "^1.0.0"
      }
    },
    "markdown-escapes": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/markdown-escapes/-/markdown-escapes-1.0.2.tgz",
      "integrity": "sha512-lbRZ2mE3Q9RtLjxZBZ9+IMl68DKIXaVAhwvwn9pmjnPLS0h/6kyBMgNhqi1xFJ/2yv6cSyv0jbiZavZv93JkkA==",
      "dev": true
    },
    "markdown-table": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/markdown-table/-/markdown-table-1.1.2.tgz",
      "integrity": "sha512-NcWuJFHDA8V3wkDgR/j4+gZx+YQwstPgfQDV8ndUeWWzta3dnDTBxpVzqS9lkmJAuV5YX35lmyojl6HO5JXAgw==",
      "dev": true
    },
    "md5.js": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/md5.js/-/md5.js-1.3.5.tgz",
      "integrity": "sha512-xitP+WxNPcTTOgnTJcrhM0xvdPepipPSf3I8EIpGKeFLjt3PlJLIDG3u8EX53ZIubkb+5U2+3rELYpEhHhzdkg==",
      "dev": true,
      "requires": {
        "hash-base": "^3.0.0",
        "inherits": "^2.0.1",
        "safe-buffer": "^5.1.2"
      }
    },
    "mdast-util-compact": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-compact/-/mdast-util-compact-1.0.2.tgz",
      "integrity": "sha512-d2WS98JSDVbpSsBfVvD9TaDMlqPRz7ohM/11G0rp5jOBb5q96RJ6YLszQ/09AAixyzh23FeIpCGqfaamEADtWg==",
      "dev": true,
      "requires": {
        "unist-util-visit": "^1.1.0"
      }
    },
    "mdast-util-definitions": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/mdast-util-definitions/-/mdast-util-definitions-1.2.3.tgz",
      "integrity": "sha512-P6wpRO8YVQ1iv30maMc93NLh7COvufglBE8/ldcOyYmk5EbfF0YeqlLgtqP/FOBU501Kqar1x5wYWwB3Nga74g==",
      "dev": true,
      "requires": {
        "unist-util-visit": "^1.0.0"
      }
    },
    "mdast-util-inject": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-inject/-/mdast-util-inject-1.1.0.tgz",
      "integrity": "sha1-2wa4tYW+lZotzS+H9HK6m3VvNnU=",
      "dev": true,
      "requires": {
        "mdast-util-to-string": "^1.0.0"
      }
    },
    "mdast-util-to-hast": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/mdast-util-to-hast/-/mdast-util-to-hast-3.0.4.tgz",
      "integrity": "sha512-/eIbly2YmyVgpJNo+bFLLMCI1XgolO/Ffowhf+pHDq3X4/V6FntC9sGQCDLM147eTS+uSXv5dRzJyFn+o0tazA==",
      "dev": true,
      "requires": {
        "collapse-white-space": "^1.0.0",
        "detab": "^2.0.0",
        "mdast-util-definitions": "^1.2.0",
        "mdurl": "^1.0.1",
        "trim": "0.0.1",
        "trim-lines": "^1.0.0",
        "unist-builder": "^1.0.1",
        "unist-util-generated": "^1.1.0",
        "unist-util-position": "^3.0.0",
        "unist-util-visit": "^1.1.0",
        "xtend": "^4.0.1"
      }
    },
    "mdast-util-to-string": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/mdast-util-to-string/-/mdast-util-to-string-1.0.5.tgz",
      "integrity": "sha512-2qLt/DEOo5F6nc2VFScQiHPzQ0XXcabquRJxKMhKte8nt42o08HUxNDPk7tt0YPxnWjAT11I1SYi0X0iPnfI5A==",
      "dev": true
    },
    "mdast-util-toc": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-toc/-/mdast-util-toc-3.0.1.tgz",
      "integrity": "sha512-Z8lKq6sQr/vDNIcUkIWzPwKo5JQIzlDLouZuzIMVajOdUAyjnkA+s98RhjVpFt7SiuJzase9oh6Iw7n4zhVNDQ==",
      "dev": true,
      "requires": {
        "github-slugger": "^1.1.1",
        "mdast-util-to-string": "^1.0.2",
        "unist-util-visit": "^1.1.0"
      }
    },
    "mdurl": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/mdurl/-/mdurl-1.0.1.tgz",
      "integrity": "sha1-/oWy7HWlkDfyrf7BAP1sYBdhFS4=",
      "dev": true
    },
    "mem": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/mem/-/mem-1.1.0.tgz",
      "integrity": "sha1-Xt1StIXKHZAP5kiVUFOZoN+kX3Y=",
      "dev": true,
      "requires": {
        "mimic-fn": "^1.0.0"
      }
    },
    "merge-stream": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/merge-stream/-/merge-stream-1.0.1.tgz",
      "integrity": "sha1-QEEgLVCKNCugAXQAjfDCUbjBNeE=",
      "dev": true,
      "requires": {
        "readable-stream": "^2.0.1"
      }
    },
    "micromatch": {
      "version": "3.1.10",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-3.1.10.tgz",
      "integrity": "sha512-MWikgl9n9M3w+bpsY3He8L+w9eF9338xRl8IAO5viDizwSzziFEyUzo2xrrloB64ADbTf8uA8vRqqttDTOmccg==",
      "dev": true,
      "requires": {
        "arr-diff": "^4.0.0",
        "array-unique": "^0.3.2",
        "braces": "^2.3.1",
        "define-property": "^2.0.2",
        "extend-shallow": "^3.0.2",
        "extglob": "^2.0.4",
        "fragment-cache": "^0.2.1",
        "kind-of": "^6.0.2",
        "nanomatch": "^1.2.9",
        "object.pick": "^1.3.0",
        "regex-not": "^1.0.0",
        "snapdragon": "^0.8.1",
        "to-regex": "^3.0.2"
      },
      "dependencies": {
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "miller-rabin": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/miller-rabin/-/miller-rabin-4.0.1.tgz",
      "integrity": "sha512-115fLhvZVqWwHPbClyntxEVfVDfl9DLLTuJvq3g2O/Oxi8AiNouAHvDSzHS0viUJc+V5vm3eq91Xwqn9dp4jRA==",
      "dev": true,
      "requires": {
        "bn.js": "^4.0.0",
        "brorand": "^1.0.1"
      }
    },
    "mime": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/mime/-/mime-2.4.0.tgz",
      "integrity": "sha512-ikBcWwyqXQSHKtciCcctu9YfPbFYZ4+gbHEmE0Q8jzcTYQg5dHCr3g2wwAZjPoJfQVXZq6KXAjpXOTf5/cjT7w==",
      "dev": true
    },
    "mime-db": {
      "version": "1.40.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.40.0.tgz",
      "integrity": "sha512-jYdeOMPy9vnxEqFRRo6ZvTZ8d9oPb+k18PKoYNYUe2stVEBPPwsln/qWzdbmaIvnhZ9v2P+CuecK+fpUfsV2mA==",
      "dev": true
    },
    "mime-types": {
      "version": "2.1.24",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.24.tgz",
      "integrity": "sha512-WaFHS3MCl5fapm3oLxU4eYDw77IQM2ACcxQ9RIxfaC3ooc6PFuBMGZZsYpvoXS5D5QTWPieo1jjLdAm3TBP3cQ==",
      "dev": true,
      "requires": {
        "mime-db": "1.40.0"
      }
    },
    "mimic-fn": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-1.2.0.tgz",
      "integrity": "sha512-jf84uxzwiuiIVKiOLpfYk7N46TSy8ubTonmneY9vrpHNAnp0QBt2BxWV9dO3/j+BoVAb+a5G6YDPW3M5HOdMWQ==",
      "dev": true
    },
    "minimalistic-assert": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/minimalistic-assert/-/minimalistic-assert-1.0.1.tgz",
      "integrity": "sha512-UtJcAD4yEaGtjPezWuO9wC4nwUnVH/8/Im3yEHQP4b67cXlD/Qr9hdITCU1xDbSEXg2XKNaP8jsReV7vQd00/A==",
      "dev": true
    },
    "minimalistic-crypto-utils": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/minimalistic-crypto-utils/-/minimalistic-crypto-utils-1.0.1.tgz",
      "integrity": "sha1-9sAMHAsIIkblxNmd+4x8CDsrWCo=",
      "dev": true
    },
    "minimatch": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.0.4.tgz",
      "integrity": "sha512-yJHVQEhyqPLUTgt9B83PXu6W3rx4MvvHvSUvToogpwoGDOUQ+yDrR0HRot+yOCdCO7u4hX3pWft6kWBBcqh0UA==",
      "dev": true,
      "requires": {
        "brace-expansion": "^1.1.7"
      }
    },
    "minimist": {
      "version": "0.0.8",
      "resolved": "http://registry.npmjs.org/minimist/-/minimist-0.0.8.tgz",
      "integrity": "sha1-hX/Kv8M5fSYluCKCYuhqp6ARsF0=",
      "dev": true
    },
    "minipass": {
      "version": "2.3.5",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-2.3.5.tgz",
      "integrity": "sha512-Gi1W4k059gyRbyVUZQ4mEqLm0YIUiGYfvxhF6SIlk3ui1WVxMTGfGdQ2SInh3PDrRTVvPKgULkpJtT4RH10+VA==",
      "dev": true,
      "optional": true,
      "requires": {
        "safe-buffer": "^5.1.2",
        "yallist": "^3.0.0"
      },
      "dependencies": {
        "yallist": {
          "version": "3.0.3",
          "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.0.3.tgz",
          "integrity": "sha512-S+Zk8DEWE6oKpV+vI3qWkaK+jSbIK86pCwe2IF/xwIpQ8jEuxpw9NyaGjmp9+BoJv5FV2piqCDcoCtStppiq2A==",
          "dev": true,
          "optional": true
        }
      }
    },
    "minizlib": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/minizlib/-/minizlib-1.2.1.tgz",
      "integrity": "sha512-7+4oTUOWKg7AuL3vloEWekXY2/D20cevzsrNT2kGWm+39J9hGTCBv8VI5Pm5lXZ/o3/mdR4f8rflAPhnQb8mPA==",
      "dev": true,
      "optional": true,
      "requires": {
        "minipass": "^2.2.1"
      }
    },
    "mixin-deep": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/mixin-deep/-/mixin-deep-1.3.1.tgz",
      "integrity": "sha512-8ZItLHeEgaqEvd5lYBXfm4EZSFCX29Jb9K+lAHhDKzReKBQKj3R+7NOF6tjqYi9t4oI8VUfaWITJQm86wnXGNQ==",
      "dev": true,
      "requires": {
        "for-in": "^1.0.2",
        "is-extendable": "^1.0.1"
      },
      "dependencies": {
        "is-extendable": {
          "version": "1.0.1",
          "resolved": "https://registry.npmjs.org/is-extendable/-/is-extendable-1.0.1.tgz",
          "integrity": "sha512-arnXMxT1hhoKo9k1LZdmlNyJdDDfy2v0fXjFlmok4+i8ul/6WlbVge9bhM74OpNPQPMGUToDtz+KXa1PneJxOA==",
          "dev": true,
          "requires": {
            "is-plain-object": "^2.0.4"
          }
        }
      }
    },
    "mkdirp": {
      "version": "0.5.1",
      "resolved": "http://registry.npmjs.org/mkdirp/-/mkdirp-0.5.1.tgz",
      "integrity": "sha1-MAV0OOrGz3+MR2fzhkjWaX11yQM=",
      "dev": true,
      "requires": {
        "minimist": "0.0.8"
      }
    },
    "module-deps": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/module-deps/-/module-deps-6.2.0.tgz",
      "integrity": "sha512-hKPmO06so6bL/ZvqVNVqdTVO8UAYsi3tQWlCa+z9KuWhoN4KDQtb5hcqQQv58qYiDE21wIvnttZEPiDgEbpwbA==",
      "dev": true,
      "requires": {
        "JSONStream": "^1.0.3",
        "browser-resolve": "^1.7.0",
        "cached-path-relative": "^1.0.0",
        "concat-stream": "~1.6.0",
        "defined": "^1.0.0",
        "detective": "^5.0.2",
        "duplexer2": "^0.1.2",
        "inherits": "^2.0.1",
        "parents": "^1.0.0",
        "readable-stream": "^2.0.2",
        "resolve": "^1.4.0",
        "stream-combiner2": "^1.1.1",
        "subarg": "^1.0.0",
        "through2": "^2.0.0",
        "xtend": "^4.0.0"
      },
      "dependencies": {
        "resolve": {
          "version": "1.9.0",
          "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.9.0.tgz",
          "integrity": "sha512-TZNye00tI67lwYvzxCxHGjwTNlUV70io54/Ed4j6PscB8xVfuBJpRenI/o6dVk0cY0PYTY27AgCoGGxRnYuItQ==",
          "dev": true,
          "requires": {
            "path-parse": "^1.0.6"
          }
        }
      }
    },
    "ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha1-VgiurfwAvmwpAd9fmGF4jeDVl8g=",
      "dev": true
    },
    "mute-stream": {
      "version": "0.0.7",
      "resolved": "https://registry.npmjs.org/mute-stream/-/mute-stream-0.0.7.tgz",
      "integrity": "sha1-MHXOk7whuPq0PhvE2n6BFe0ee6s=",
      "dev": true
    },
    "nan": {
      "version": "2.12.1",
      "resolved": "https://registry.npmjs.org/nan/-/nan-2.12.1.tgz",
      "integrity": "sha512-JY7V6lRkStKcKTvHO5NVSQRv+RV+FIL5pvDoLiAtSL9pKlC5x9PKQcZDsq7m4FO4d57mkhC6Z+QhAh3Jdk5JFw==",
      "dev": true,
      "optional": true
    },
    "nanomatch": {
      "version": "1.2.13",
      "resolved": "https://registry.npmjs.org/nanomatch/-/nanomatch-1.2.13.tgz",
      "integrity": "sha512-fpoe2T0RbHwBTBUOftAfBPaDEi06ufaUai0mE6Yn1kacc3SnTErfb/h+X94VXzI64rKFHYImXSvdwGGCmwOqCA==",
      "dev": true,
      "requires": {
        "arr-diff": "^4.0.0",
        "array-unique": "^0.3.2",
        "define-property": "^2.0.2",
        "extend-shallow": "^3.0.2",
        "fragment-cache": "^0.2.1",
        "is-windows": "^1.0.2",
        "kind-of": "^6.0.2",
        "object.pick": "^1.3.0",
        "regex-not": "^1.0.0",
        "snapdragon": "^0.8.1",
        "to-regex": "^3.0.1"
      },
      "dependencies": {
        "arr-diff": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/arr-diff/-/arr-diff-4.0.0.tgz",
          "integrity": "sha1-1kYQdP6/7HHn4VI1dhoyml3HxSA=",
          "dev": true
        },
        "array-unique": {
          "version": "0.3.2",
          "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
          "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha1-Sr6/7tdUHywnrPspvbvRXI1bpPc=",
      "dev": true
    },
    "neo-async": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/neo-async/-/neo-async-2.6.0.tgz",
      "integrity": "sha512-MFh0d/Wa7vkKO3Y3LlacqAEeHK0mckVqzDieUKTT+KGxi+zIpeVsFxymkIiRpbpDziHc290Xr9A1O4Om7otoRA==",
      "dev": true
    },
    "nice-try": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/nice-try/-/nice-try-1.0.5.tgz",
      "integrity": "sha512-1nh45deeb5olNY7eX82BkPO7SSxR5SSYJiPTrTdFUVYwAl8CKMA5N9PjTYkHiRjisVcxcQ1HXdLhx2qxxJzLNQ==",
      "dev": true
    },
    "node-fetch": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/node-fetch/-/node-fetch-2.3.0.tgz",
      "integrity": "sha512-MOd8pV3fxENbryESLgVIeaGKrdl+uaYhCSSVkjeOb/31/njTpcis5aWfdqgNlHIrKOLRbMnfPINPOML2CIFeXA=="
    },
    "node-int64": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/node-int64/-/node-int64-0.4.0.tgz",
      "integrity": "sha1-h6kGXNs1XTGC2PlM4RGIuCXGijs=",
      "dev": true
    },
    "node-modules-regexp": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/node-modules-regexp/-/node-modules-regexp-1.0.0.tgz",
      "integrity": "sha1-jZ2+KJZKSsVxLpExZCEHxx6Q7EA=",
      "dev": true
    },
    "node-notifier": {
      "version": "5.4.0",
      "resolved": "https://registry.npmjs.org/node-notifier/-/node-notifier-5.4.0.tgz",
      "integrity": "sha512-SUDEb+o71XR5lXSTyivXd9J7fCloE3SyP4lSgt3lU2oSANiox+SxlNRGPjDKrwU1YN3ix2KN/VGGCg0t01rttQ==",
      "dev": true,
      "requires": {
        "growly": "^1.3.0",
        "is-wsl": "^1.1.0",
        "semver": "^5.5.0",
        "shellwords": "^0.1.1",
        "which": "^1.3.0"
      }
    },
    "node-releases": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-1.1.3.tgz",
      "integrity": "sha512-6VrvH7z6jqqNFY200kdB6HdzkgM96Oaj9v3dqGfgp6mF+cHmU4wyQKZ2/WPDRVoR0Jz9KqbamaBN0ZhdUaysUQ==",
      "dev": true,
      "requires": {
        "semver": "^5.3.0"
      }
    },
    "normalize-package-data": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/normalize-package-data/-/normalize-package-data-2.4.0.tgz",
      "integrity": "sha512-9jjUFbTPfEy3R/ad/2oNbKtW9Hgovl5O1FvFWKkKblNXoN/Oou6+9+KKohPK13Yc3/TyunyWhJp6gvRNR/PPAw==",
      "dev": true,
      "requires": {
        "hosted-git-info": "^2.1.4",
        "is-builtin-module": "^1.0.0",
        "semver": "2 || 3 || 4 || 5",
        "validate-npm-package-license": "^3.0.1"
      }
    },
    "normalize-path": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-2.1.1.tgz",
      "integrity": "sha1-GrKLVW4Zg2Oowab35vogE3/mrtk=",
      "dev": true,
      "requires": {
        "remove-trailing-separator": "^1.0.1"
      }
    },
    "normalize-url": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/normalize-url/-/normalize-url-1.9.1.tgz",
      "integrity": "sha1-LMDWazHqIwNkWENuNiDYWVTGbDw=",
      "dev": true,
      "requires": {
        "object-assign": "^4.0.1",
        "prepend-http": "^1.0.0",
        "query-string": "^4.1.0",
        "sort-keys": "^1.0.0"
      }
    },
    "now-and-later": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/now-and-later/-/now-and-later-2.0.0.tgz",
      "integrity": "sha1-vGHLtFbXnLMiB85HygUTb/Ln1u4=",
      "dev": true,
      "requires": {
        "once": "^1.3.2"
      }
    },
    "npm-run-path": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/npm-run-path/-/npm-run-path-2.0.2.tgz",
      "integrity": "sha1-NakjLfo11wZ7TLLd8jV7GHFTbF8=",
      "dev": true,
      "requires": {
        "path-key": "^2.0.0"
      }
    },
    "number-is-nan": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/number-is-nan/-/number-is-nan-1.0.1.tgz",
      "integrity": "sha1-CXtgK1NCKlIsGvuHkDGDNpQaAR0=",
      "dev": true
    },
    "nwsapi": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/nwsapi/-/nwsapi-2.1.4.tgz",
      "integrity": "sha512-iGfd9Y6SFdTNldEy2L0GUhcarIutFmk+MPWIn9dmj8NMIup03G08uUF2KGbbmv/Ux4RT0VZJoP/sVbWA6d/VIw==",
      "dev": true
    },
    "o3": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/o3/-/o3-1.0.3.tgz",
      "integrity": "sha1-GSzod6iC36Z1HwQSqGX6+y2h2sA=",
      "requires": {
        "capability": "^0.2.5"
      }
    },
    "oauth-sign": {
      "version": "0.9.0",
      "resolved": "https://registry.npmjs.org/oauth-sign/-/oauth-sign-0.9.0.tgz",
      "integrity": "sha512-fexhUFFPTGV8ybAtSIGbV6gOkSv8UtRbDBnAyLQw4QPKkgNlsH2ByPGtMUqdWkos6YCRmAqViwgZrJc/mRDzZQ==",
      "dev": true
    },
    "object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha1-IQmtx5ZYh8/AXLvUQsrIv7s2CGM=",
      "dev": true
    },
    "object-copy": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/object-copy/-/object-copy-0.1.0.tgz",
      "integrity": "sha1-fn2Fi3gb18mRpBupde04EnVOmYw=",
      "dev": true,
      "requires": {
        "copy-descriptor": "^0.1.0",
        "define-property": "^0.2.5",
        "kind-of": "^3.0.3"
      },
      "dependencies": {
        "define-property": {
          "version": "0.2.5",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
          "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^0.1.0"
          }
        }
      }
    },
    "object-keys": {
      "version": "1.0.12",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.0.12.tgz",
      "integrity": "sha512-FTMyFUm2wBcGHnH2eXmz7tC6IwlqQZ6mVZ+6dm6vZ4IQIHjs6FdNsQBuKGPuUUUY6NfJw2PshC08Tn6LzLDOag==",
      "dev": true
    },
    "object-visit": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/object-visit/-/object-visit-1.0.1.tgz",
      "integrity": "sha1-95xEk68MU3e1n+OdOV5BBC3QRbs=",
      "dev": true,
      "requires": {
        "isobject": "^3.0.0"
      },
      "dependencies": {
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "object.assign": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.0.tgz",
      "integrity": "sha512-exHJeq6kBKj58mqGyTQ9DFvrZC/eR6OwxzoM9YRoGBqrXYonaFyGiFMuc9VZrXf7DarreEwMpurG3dd+CNyW5w==",
      "dev": true,
      "requires": {
        "define-properties": "^1.1.2",
        "function-bind": "^1.1.1",
        "has-symbols": "^1.0.0",
        "object-keys": "^1.0.11"
      }
    },
    "object.getownpropertydescriptors": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/object.getownpropertydescriptors/-/object.getownpropertydescriptors-2.0.3.tgz",
      "integrity": "sha1-h1jIRvW0B62rDyNuCYbxSwUcqhY=",
      "dev": true,
      "requires": {
        "define-properties": "^1.1.2",
        "es-abstract": "^1.5.1"
      }
    },
    "object.pick": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/object.pick/-/object.pick-1.3.0.tgz",
      "integrity": "sha1-h6EKxMFpS9Lhy/U1kaZhQftd10c=",
      "dev": true,
      "requires": {
        "isobject": "^3.0.1"
      },
      "dependencies": {
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha1-WDsap3WWHUsROsF9nFC6753Xa9E=",
      "dev": true,
      "requires": {
        "wrappy": "1"
      }
    },
    "onetime": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/onetime/-/onetime-2.0.1.tgz",
      "integrity": "sha1-BnQoIw/WdEOyeUsiu6UotoZ5YtQ=",
      "dev": true,
      "requires": {
        "mimic-fn": "^1.0.0"
      }
    },
    "optimist": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/optimist/-/optimist-0.6.1.tgz",
      "integrity": "sha1-2j6nRob6IaGaERwybpDrFaAZZoY=",
      "dev": true,
      "requires": {
        "minimist": "~0.0.1",
        "wordwrap": "~0.0.2"
      }
    },
    "optionator": {
      "version": "0.8.2",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.8.2.tgz",
      "integrity": "sha1-NkxeQJ0/TWMB1sC0wFu6UBgK62Q=",
      "dev": true,
      "requires": {
        "deep-is": "~0.1.3",
        "fast-levenshtein": "~2.0.4",
        "levn": "~0.3.0",
        "prelude-ls": "~1.1.2",
        "type-check": "~0.3.2",
        "wordwrap": "~1.0.0"
      },
      "dependencies": {
        "wordwrap": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/wordwrap/-/wordwrap-1.0.0.tgz",
          "integrity": "sha1-J1hIEIkUVqQXHI0CJkQa3pDLyus=",
          "dev": true
        }
      }
    },
    "ordered-read-streams": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/ordered-read-streams/-/ordered-read-streams-1.0.1.tgz",
      "integrity": "sha1-d8DLN8QVJdZBZtmQ/61+xqDhNj4=",
      "dev": true,
      "requires": {
        "readable-stream": "^2.0.1"
      }
    },
    "os-browserify": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/os-browserify/-/os-browserify-0.3.0.tgz",
      "integrity": "sha1-hUNzx/XCMVkU/Jv8a9gjj92h7Cc=",
      "dev": true
    },
    "os-locale": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/os-locale/-/os-locale-2.1.0.tgz",
      "integrity": "sha512-3sslG3zJbEYcaC4YVAvDorjGxc7tv6KVATnLPZONiljsUncvihe9BQoVCEs0RZ1kmf4Hk9OBqlZfJZWI4GanKA==",
      "dev": true,
      "requires": {
        "execa": "^0.7.0",
        "lcid": "^1.0.0",
        "mem": "^1.1.0"
      }
    },
    "os-tmpdir": {
      "version": "1.0.2",
      "resolved": "http://registry.npmjs.org/os-tmpdir/-/os-tmpdir-1.0.2.tgz",
      "integrity": "sha1-u+Z0BseaqFxc/sdm/lc0VV36EnQ=",
      "dev": true
    },
    "p-defer": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-defer/-/p-defer-1.0.0.tgz",
      "integrity": "sha1-n26xgvbJqozXQwBKfU+WsZaw+ww=",
      "dev": true
    },
    "p-each-series": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-each-series/-/p-each-series-1.0.0.tgz",
      "integrity": "sha1-kw89Et0fUOdDRFeiLNbwSsatf3E=",
      "dev": true,
      "requires": {
        "p-reduce": "^1.0.0"
      }
    },
    "p-finally": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-finally/-/p-finally-1.0.0.tgz",
      "integrity": "sha1-P7z7FbiZpEEjs0ttzBi3JDNqLK4=",
      "dev": true
    },
    "p-is-promise": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/p-is-promise/-/p-is-promise-2.1.0.tgz",
      "integrity": "sha512-Y3W0wlRPK8ZMRbNq97l4M5otioeA5lm1z7bkNkxCka8HSPjR0xRWmpCmc9utiaLP9Jb1eD8BgeIxTW4AIF45Pg==",
      "dev": true
    },
    "p-limit": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-1.3.0.tgz",
      "integrity": "sha512-vvcXsLAJ9Dr5rQOPk7toZQZJApBl2K4J6dANSsEuh6QI41JYcsS/qhTGa9ErIUUgK3WNQoJYvylxvjqmiqEA9Q==",
      "dev": true,
      "requires": {
        "p-try": "^1.0.0"
      }
    },
    "p-locate": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-2.0.0.tgz",
      "integrity": "sha1-IKAQOyIqcMj9OcwuWAaA893l7EM=",
      "dev": true,
      "requires": {
        "p-limit": "^1.1.0"
      }
    },
    "p-reduce": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-reduce/-/p-reduce-1.0.0.tgz",
      "integrity": "sha1-GMKw3ZNqRpClKfgjH1ig/bakffo=",
      "dev": true
    },
    "p-try": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-try/-/p-try-1.0.0.tgz",
      "integrity": "sha1-y8ec26+P1CKOE/Yh8rGiN8GyB7M=",
      "dev": true
    },
    "pako": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/pako/-/pako-1.0.8.tgz",
      "integrity": "sha512-6i0HVbUfcKaTv+EG8ZTr75az7GFXcLYk9UyLEg7Notv/Ma+z/UG3TCoz6GiNeOrn1E/e63I0X/Hpw18jHOTUnA==",
      "dev": true
    },
    "parent-module": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.0.tgz",
      "integrity": "sha512-8Mf5juOMmiE4FcmzYc4IaiS9L3+9paz2KOiXzkRviCP6aDmN49Hz6EMWz0lGNp9pX80GvvAuLADtyGfW/Em3TA==",
      "dev": true,
      "requires": {
        "callsites": "^3.0.0"
      },
      "dependencies": {
        "callsites": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.0.0.tgz",
          "integrity": "sha512-tWnkwu9YEq2uzlBDI4RcLn8jrFvF9AOi8PxDNU3hZZjJcjkcRAq3vCI+vZcg1SuxISDYe86k9VZFwAxDiJGoAw==",
          "dev": true
        }
      }
    },
    "parents": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parents/-/parents-1.0.1.tgz",
      "integrity": "sha1-/t1NK/GTp3dF/nHjcdc8MwfZx1E=",
      "dev": true,
      "requires": {
        "path-platform": "~0.11.15"
      }
    },
    "parse-asn1": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/parse-asn1/-/parse-asn1-5.1.1.tgz",
      "integrity": "sha512-KPx7flKXg775zZpnp9SxJlz00gTd4BmJ2yJufSc44gMCRrRQ7NSzAcSJQfifuOLgW6bEi+ftrALtsgALeB2Adw==",
      "dev": true,
      "requires": {
        "asn1.js": "^4.0.0",
        "browserify-aes": "^1.0.0",
        "create-hash": "^1.1.0",
        "evp_bytestokey": "^1.0.0",
        "pbkdf2": "^3.0.3"
      }
    },
    "parse-entities": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-1.2.0.tgz",
      "integrity": "sha512-XXtDdOPLSB0sHecbEapQi6/58U/ODj/KWfIXmmMCJF/eRn8laX6LZbOyioMoETOOJoWRW8/qTSl5VQkUIfKM5g==",
      "dev": true,
      "requires": {
        "character-entities": "^1.0.0",
        "character-entities-legacy": "^1.0.0",
        "character-reference-invalid": "^1.0.0",
        "is-alphanumerical": "^1.0.0",
        "is-decimal": "^1.0.0",
        "is-hexadecimal": "^1.0.0"
      }
    },
    "parse-filepath": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/parse-filepath/-/parse-filepath-1.0.2.tgz",
      "integrity": "sha1-pjISf1Oq89FYdvWHLz/6x2PWyJE=",
      "dev": true,
      "requires": {
        "is-absolute": "^1.0.0",
        "map-cache": "^0.2.0",
        "path-root": "^0.1.1"
      }
    },
    "parse-git-config": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/parse-git-config/-/parse-git-config-0.2.0.tgz",
      "integrity": "sha1-Jygz/dFf6hRvt10zbSNrljtv9wY=",
      "dev": true,
      "requires": {
        "ini": "^1.3.3"
      }
    },
    "parse-json": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-4.0.0.tgz",
      "integrity": "sha1-vjX1Qlvh9/bHRxhPmKeIy5lHfuA=",
      "dev": true,
      "requires": {
        "error-ex": "^1.3.1",
        "json-parse-better-errors": "^1.0.1"
      }
    },
    "parse-path": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/parse-path/-/parse-path-3.0.4.tgz",
      "integrity": "sha512-wP70vtwv2DyrM2YoA7ZHVv4zIXa4P7dGgHlj+VwyXNDduLLVJ7NMY1zsFxjUUJ3DAwJLupGb1H5gMDDiNlJaxw==",
      "dev": true,
      "requires": {
        "is-ssh": "^1.3.0",
        "protocols": "^1.4.0"
      }
    },
    "parse-url": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/parse-url/-/parse-url-3.0.2.tgz",
      "integrity": "sha1-YCeHpwY6eV1yuGcxl1BecvYGEL4=",
      "dev": true,
      "requires": {
        "is-ssh": "^1.3.0",
        "normalize-url": "^1.9.1",
        "parse-path": "^3.0.1",
        "protocols": "^1.4.0"
      }
    },
    "parse5": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/parse5/-/parse5-4.0.0.tgz",
      "integrity": "sha512-VrZ7eOd3T1Fk4XWNXMgiGBK/z0MG48BWG2uQNU4I72fkQuKUTZpl+u9k+CxEG0twMVzSmXEEz12z5Fnw1jIQFA==",
      "dev": true
    },
    "pascalcase": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/pascalcase/-/pascalcase-0.1.1.tgz",
      "integrity": "sha1-s2PlXoAGym/iF4TS2yK9FdeRfxQ=",
      "dev": true
    },
    "path-browserify": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/path-browserify/-/path-browserify-0.0.1.tgz",
      "integrity": "sha512-BapA40NHICOS+USX9SN4tyhq+A2RrN/Ws5F0Z5aMHDp98Fl86lX8Oti8B7uN93L4Ifv4fHOEA+pQw87gmMO/lQ==",
      "dev": true
    },
    "path-dirname": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/path-dirname/-/path-dirname-1.0.2.tgz",
      "integrity": "sha1-zDPSTVJeCZpTiMAzbG4yuRYGCeA=",
      "dev": true
    },
    "path-exists": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-3.0.0.tgz",
      "integrity": "sha1-zg6+ql94yxiSXqfYENe1mwEP1RU=",
      "dev": true
    },
    "path-is-absolute": {
      "version": "1.0.1",
      "resolved": "http://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha1-F0uSaHNVNP+8es5r9TpanhtcX18=",
      "dev": true
    },
    "path-is-inside": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/path-is-inside/-/path-is-inside-1.0.2.tgz",
      "integrity": "sha1-NlQX3t5EQw0cEa9hAn+s8HS9/FM=",
      "dev": true
    },
    "path-key": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-2.0.1.tgz",
      "integrity": "sha1-QRyttXTFoUDTpLGRDUDYDMn0C0A=",
      "dev": true
    },
    "path-parse": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.6.tgz",
      "integrity": "sha512-GSmOT2EbHrINBf9SR7CDELwlJ8AENk3Qn7OikK4nFYAu3Ote2+JYNVvkpAEQm3/TLNEJFD/xZJjzyxg3KBWOzw==",
      "dev": true
    },
    "path-platform": {
      "version": "0.11.15",
      "resolved": "https://registry.npmjs.org/path-platform/-/path-platform-0.11.15.tgz",
      "integrity": "sha1-6GQhf3TDaFDwhSt43Hv31KVyG/I=",
      "dev": true
    },
    "path-root": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/path-root/-/path-root-0.1.1.tgz",
      "integrity": "sha1-mkpoFMrBwM1zNgqV8yCDyOpHRbc=",
      "dev": true,
      "requires": {
        "path-root-regex": "^0.1.0"
      }
    },
    "path-root-regex": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/path-root-regex/-/path-root-regex-0.1.2.tgz",
      "integrity": "sha1-v8zcjfWxLcUsi0PsONGNcsBLqW0=",
      "dev": true
    },
    "path-type": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-3.0.0.tgz",
      "integrity": "sha512-T2ZUsdZFHgA3u4e5PfPbjd7HDDpxPnQb5jN0SrDsjNSuVXHJqtwTnWqG0B1jZrgmJ/7lj1EmVIByWt1gxGkWvg==",
      "dev": true,
      "requires": {
        "pify": "^3.0.0"
      }
    },
    "pbkdf2": {
      "version": "3.0.17",
      "resolved": "https://registry.npmjs.org/pbkdf2/-/pbkdf2-3.0.17.tgz",
      "integrity": "sha512-U/il5MsrZp7mGg3mSQfn742na2T+1/vHDCG5/iTI3X9MKUuYUZVLQhyRsg06mCgDBTd57TxzgZt7P+fYfjRLtA==",
      "dev": true,
      "requires": {
        "create-hash": "^1.1.2",
        "create-hmac": "^1.1.4",
        "ripemd160": "^2.0.1",
        "safe-buffer": "^5.0.1",
        "sha.js": "^2.4.8"
      }
    },
    "performance-now": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/performance-now/-/performance-now-2.1.0.tgz",
      "integrity": "sha1-Ywn04OX6kT7BxpMHrjZLSzd8nns=",
      "dev": true
    },
    "pify": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-3.0.0.tgz",
      "integrity": "sha1-5aSs0sEB/fPZpNB/DbxNtJ3SgXY=",
      "dev": true
    },
    "pirates": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.1.tgz",
      "integrity": "sha512-WuNqLTbMI3tmfef2TKxlQmAiLHKtFhlsCZnPIpuv2Ow0RDVO8lfy1Opf4NUzlMXLjPl+Men7AuVdX6TA+s+uGA==",
      "dev": true,
      "requires": {
        "node-modules-regexp": "^1.0.0"
      }
    },
    "pkg-dir": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/pkg-dir/-/pkg-dir-3.0.0.tgz",
      "integrity": "sha512-/E57AYkoeQ25qkxMj5PBOVgF8Kiu/h7cYS30Z5+R7WaiCCBfLq58ZI/dSeaEKb9WVJV5n/03QwrN3IeWIFllvw==",
      "dev": true,
      "requires": {
        "find-up": "^3.0.0"
      },
      "dependencies": {
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "p-limit": {
          "version": "2.1.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.1.0.tgz",
          "integrity": "sha512-NhURkNcrVB+8hNfLuysU8enY5xn2KXphsHBaC2YmRNTZRc7RWusw6apSpdEj3jo4CMb6W9nrF6tTnsJsJeyu6g==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.0.0.tgz",
          "integrity": "sha512-hMp0onDKIajHfIkdRk3P4CdCmErkYAxxDtP3Wx/4nZ3aGlau2VKh3mZpcuFkH27WQkL/3WBCPOktzA9ZOAnMQQ==",
          "dev": true
        }
      }
    },
    "pn": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/pn/-/pn-1.1.0.tgz",
      "integrity": "sha512-2qHaIQr2VLRFoxe2nASzsV6ef4yOOH+Fi9FBOVH6cqeSgUnoyySPZkxzLuzd+RYOQTRpROA0ztTMqxROKSb/nA==",
      "dev": true
    },
    "posix-character-classes": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/posix-character-classes/-/posix-character-classes-0.1.1.tgz",
      "integrity": "sha1-AerA/jta9xoqbAL+q7jB/vfgDqs=",
      "dev": true
    },
    "prelude-ls": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.1.2.tgz",
      "integrity": "sha1-IZMqVJ9eUv/ZqCf1cOBL5iqX2lQ=",
      "dev": true
    },
    "prepend-http": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/prepend-http/-/prepend-http-1.0.4.tgz",
      "integrity": "sha1-1PRWKwzjaW5BrFLQ4ALlemNdxtw=",
      "dev": true
    },
    "pretty-format": {
      "version": "24.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-24.7.0.tgz",
      "integrity": "sha512-apen5cjf/U4dj7tHetpC7UEFCvtAgnNZnBDkfPv3fokzIqyOJckAG9OlAPC1BlFALnqT/lGB2tl9EJjlK6eCsA==",
      "dev": true,
      "requires": {
        "@jest/types": "^24.7.0",
        "ansi-regex": "^4.0.0",
        "ansi-styles": "^3.2.0",
        "react-is": "^16.8.4"
      },
      "dependencies": {
        "ansi-regex": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-4.1.0.tgz",
          "integrity": "sha512-1apePfXM1UOSqw0o9IiFAovVz9M5S1Dg+4TrDwfMewQ6p/rmMueb7tWZjQ1rx4Loy1ArBggoqGpfqqdI4rondg==",
          "dev": true
        }
      }
    },
    "private": {
      "version": "0.1.8",
      "resolved": "https://registry.npmjs.org/private/-/private-0.1.8.tgz",
      "integrity": "sha512-VvivMrbvd2nKkiG38qjULzlc+4Vx4wm/whI9pQD35YrARNnhxeiRktSOhSukRLFNlzg6Br/cJPet5J/u19r/mg==",
      "dev": true
    },
    "process": {
      "version": "0.11.10",
      "resolved": "https://registry.npmjs.org/process/-/process-0.11.10.tgz",
      "integrity": "sha1-czIwDoQBYb2j5podHZGn1LwW8YI=",
      "dev": true
    },
    "process-nextick-args": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.0.tgz",
      "integrity": "sha512-MtEC1TqN0EU5nephaJ4rAtThHtC86dNN9qCuEhtshvpVBkAW5ZO7BASN9REnF9eoXGcRub+pFuKEpOHE+HbEMw==",
      "dev": true
    },
    "progress": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/progress/-/progress-2.0.3.tgz",
      "integrity": "sha512-7PiHtLll5LdnKIMw100I+8xJXR5gW2QwWYkT6iJva0bXitZKa/XMrSbdmg3r2Xnaidz9Qumd0VPaMrZlF9V9sA==",
      "dev": true
    },
    "property-information": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-4.2.0.tgz",
      "integrity": "sha512-TlgDPagHh+eBKOnH2VYvk8qbwsCG/TAJdmTL7f1PROUcSO8qt/KSmShEQ/OKvock8X9tFjtqjCScyOkkkvIKVQ==",
      "dev": true,
      "requires": {
        "xtend": "^4.0.1"
      }
    },
    "protobufjs": {
      "version": "6.8.8",
      "resolved": "https://registry.npmjs.org/protobufjs/-/protobufjs-6.8.8.tgz",
      "integrity": "sha512-AAmHtD5pXgZfi7GMpllpO3q1Xw1OYldr+dMUlAnffGTAhqkg72WdmSY71uKBF/JuyiKs8psYbtKrhi0ASCD8qw==",
      "requires": {
        "@protobufjs/aspromise": "^1.1.2",
        "@protobufjs/base64": "^1.1.2",
        "@protobufjs/codegen": "^2.0.4",
        "@protobufjs/eventemitter": "^1.1.0",
        "@protobufjs/fetch": "^1.1.0",
        "@protobufjs/float": "^1.0.2",
        "@protobufjs/inquire": "^1.1.0",
        "@protobufjs/path": "^1.1.2",
        "@protobufjs/pool": "^1.1.0",
        "@protobufjs/utf8": "^1.1.0",
        "@types/long": "^4.0.0",
        "@types/node": "^10.1.0",
        "long": "^4.0.0"
      }
    },
    "protocols": {
      "version": "1.4.7",
      "resolved": "https://registry.npmjs.org/protocols/-/protocols-1.4.7.tgz",
      "integrity": "sha512-Fx65lf9/YDn3hUX08XUc0J8rSux36rEsyiv21ZGUC1mOyeM3lTRpZLcrm8aAolzS4itwVfm7TAPyxC2E5zd6xg==",
      "dev": true
    },
    "pseudomap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/pseudomap/-/pseudomap-1.0.2.tgz",
      "integrity": "sha1-8FKijacOYYkX7wqKw0wa5aaChrM=",
      "dev": true
    },
    "psl": {
      "version": "1.1.31",
      "resolved": "https://registry.npmjs.org/psl/-/psl-1.1.31.tgz",
      "integrity": "sha512-/6pt4+C+T+wZUieKR620OpzN/LlnNKuWjy1iFLQ/UG35JqHlR/89MP1d96dUfkf6Dne3TuLQzOYEYshJ+Hx8mw==",
      "dev": true
    },
    "public-encrypt": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/public-encrypt/-/public-encrypt-4.0.3.tgz",
      "integrity": "sha512-zVpa8oKZSz5bTMTFClc1fQOnyyEzpl5ozpi1B5YcvBrdohMjH2rfsBtyXcuNuwjsDIXmBYlF2N5FlJYhR29t8Q==",
      "dev": true,
      "requires": {
        "bn.js": "^4.1.0",
        "browserify-rsa": "^4.0.0",
        "create-hash": "^1.1.0",
        "parse-asn1": "^5.0.0",
        "randombytes": "^2.0.1",
        "safe-buffer": "^5.1.2"
      }
    },
    "pump": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/pump/-/pump-2.0.1.tgz",
      "integrity": "sha512-ruPMNRkN3MHP1cWJc9OWr+T/xDP0jhXYCLfJcBuX54hhfIBnaQmAUMfDcG4DM5UMWByBbJY69QSphm3jtDKIkA==",
      "dev": true,
      "requires": {
        "end-of-stream": "^1.1.0",
        "once": "^1.3.1"
      }
    },
    "pumpify": {
      "version": "1.5.1",
      "resolved": "https://registry.npmjs.org/pumpify/-/pumpify-1.5.1.tgz",
      "integrity": "sha512-oClZI37HvuUJJxSKKrC17bZ9Cu0ZYhEAGPsPUy9KlMUmv9dKX2o77RUmq7f3XjIxbwyGwYzbzQ1L2Ks8sIradQ==",
      "dev": true,
      "requires": {
        "duplexify": "^3.6.0",
        "inherits": "^2.0.3",
        "pump": "^2.0.0"
      }
    },
    "punycode": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.1.1.tgz",
      "integrity": "sha512-XRsRjdf+j5ml+y/6GKHPZbrF/8p2Yga0JPtdqTIY2Xe5ohJPD9saDJJLPvp9+NSBprVvevdXZybnj2cv8OEd0A==",
      "dev": true
    },
    "qs": {
      "version": "6.5.2",
      "resolved": "https://registry.npmjs.org/qs/-/qs-6.5.2.tgz",
      "integrity": "sha512-N5ZAX4/LxJmF+7wN74pUD6qAh9/wnvdQcjq9TZjevvXzSUo7bfmw91saqMjzGS2xq91/odN2dW/WOl7qQHNDGA==",
      "dev": true
    },
    "query-string": {
      "version": "4.3.4",
      "resolved": "https://registry.npmjs.org/query-string/-/query-string-4.3.4.tgz",
      "integrity": "sha1-u7aTucqRXCMlFbIosaArYJBD2+s=",
      "dev": true,
      "requires": {
        "object-assign": "^4.1.0",
        "strict-uri-encode": "^1.0.0"
      }
    },
    "querystring": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/querystring/-/querystring-0.2.0.tgz",
      "integrity": "sha1-sgmEkgO7Jd+CDadW50cAWHhSFiA=",
      "dev": true
    },
    "querystring-es3": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/querystring-es3/-/querystring-es3-0.2.1.tgz",
      "integrity": "sha1-nsYfeQSYdXB9aUFFlv2Qek1xHnM=",
      "dev": true
    },
    "randombytes": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/randombytes/-/randombytes-2.0.6.tgz",
      "integrity": "sha512-CIQ5OFxf4Jou6uOKe9t1AOgqpeU5fd70A8NPdHSGeYXqXsPe6peOwI0cUl88RWZ6sP1vPMV3avd/R6cZ5/sP1A==",
      "dev": true,
      "requires": {
        "safe-buffer": "^5.1.0"
      }
    },
    "randomfill": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/randomfill/-/randomfill-1.0.4.tgz",
      "integrity": "sha512-87lcbR8+MhcWcUiQ+9e+Rwx8MyR2P7qnt15ynUlbm3TU/fjbgz4GsvfSUDTemtCCtVCqb4ZcEFlyPNTh9bBTLw==",
      "dev": true,
      "requires": {
        "randombytes": "^2.0.5",
        "safe-buffer": "^5.1.0"
      }
    },
    "raw-body": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/raw-body/-/raw-body-1.1.7.tgz",
      "integrity": "sha1-HQJ8K/oRasxmI7yo8AAWVyqH1CU=",
      "dev": true,
      "requires": {
        "bytes": "1",
        "string_decoder": "0.10"
      },
      "dependencies": {
        "string_decoder": {
          "version": "0.10.31",
          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-0.10.31.tgz",
          "integrity": "sha1-YuIDvEF2bGwoyfyEMB2rHFMQ+pQ=",
          "dev": true
        }
      }
    },
    "react-is": {
      "version": "16.8.6",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.8.6.tgz",
      "integrity": "sha512-aUk3bHfZ2bRSVFFbbeVS4i+lNPZr3/WM5jT2J5omUVV1zzcs1nAaf3l51ctA5FFvCRbhrH0bdAsRRQddFJZPtA==",
      "dev": true
    },
    "read-only-stream": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/read-only-stream/-/read-only-stream-2.0.0.tgz",
      "integrity": "sha1-JyT9aoET1zdkrCiNQ4YnDB2/F/A=",
      "dev": true,
      "requires": {
        "readable-stream": "^2.0.2"
      }
    },
    "read-pkg": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/read-pkg/-/read-pkg-3.0.0.tgz",
      "integrity": "sha1-nLxoaXj+5l0WwA4rGcI3/Pbjg4k=",
      "dev": true,
      "requires": {
        "load-json-file": "^4.0.0",
        "normalize-package-data": "^2.3.2",
        "path-type": "^3.0.0"
      }
    },
    "read-pkg-up": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/read-pkg-up/-/read-pkg-up-4.0.0.tgz",
      "integrity": "sha512-6etQSH7nJGsK0RbG/2TeDzZFa8shjQ1um+SwQQ5cwKy0dhSXdOncEhb1CPpvQG4h7FyOV6EB6YlV0yJvZQNAkA==",
      "dev": true,
      "requires": {
        "find-up": "^3.0.0",
        "read-pkg": "^3.0.0"
      },
      "dependencies": {
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "p-limit": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.2.0.tgz",
          "integrity": "sha512-pZbTJpoUsCzV48Mc9Nh51VbwO0X9cuPFE8gYwx9BTCt9SF8/b7Zljd2fVgOxhIF/HDTKgpVzs+GPhyKfjLLFRQ==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
          "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
          "dev": true
        }
      }
    },
    "readable-stream": {
      "version": "2.3.6",
      "resolved": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.3.6.tgz",
      "integrity": "sha512-tQtKA9WIAhBF3+VLAseyMqZeBjW0AHJoxOtYqSUZNJxauErmLbVm2FW1y+J/YA9dUrAC39ITejlZWhVIwawkKw==",
      "dev": true,
      "requires": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "readdirp": {
      "version": "2.2.1",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-2.2.1.tgz",
      "integrity": "sha512-1JU/8q+VgFZyxwrJ+SVIOsh+KywWGpds3NTqikiKpDMZWScmAYyKIgqkO+ARvNWJfXeXR1zxz7aHF4u4CyH6vQ==",
      "dev": true,
      "requires": {
        "graceful-fs": "^4.1.11",
        "micromatch": "^3.1.10",
        "readable-stream": "^2.0.2"
      },
      "dependencies": {
        "arr-diff": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/arr-diff/-/arr-diff-4.0.0.tgz",
          "integrity": "sha1-1kYQdP6/7HHn4VI1dhoyml3HxSA=",
          "dev": true
        },
        "array-unique": {
          "version": "0.3.2",
          "resolved": "https://registry.npmjs.org/array-unique/-/array-unique-0.3.2.tgz",
          "integrity": "sha1-qJS3XUvE9s1nnvMkSp/Y9Gri1Cg=",
          "dev": true
        },
        "braces": {
          "version": "2.3.2",
          "resolved": "https://registry.npmjs.org/braces/-/braces-2.3.2.tgz",
          "integrity": "sha512-aNdbnj9P8PjdXU4ybaWLK2IF3jc/EoDYbC7AazW6to3TRsfXxscC9UXOB5iDiEQrkyIbWp2SLQda4+QAa7nc3w==",
          "dev": true,
          "requires": {
            "arr-flatten": "^1.1.0",
            "array-unique": "^0.3.2",
            "extend-shallow": "^2.0.1",
            "fill-range": "^4.0.0",
            "isobject": "^3.0.1",
            "repeat-element": "^1.1.2",
            "snapdragon": "^0.8.1",
            "snapdragon-node": "^2.0.1",
            "split-string": "^3.0.2",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "expand-brackets": {
          "version": "2.1.4",
          "resolved": "https://registry.npmjs.org/expand-brackets/-/expand-brackets-2.1.4.tgz",
          "integrity": "sha1-t3c14xXOMPa27/D4OwQVGiJEliI=",
          "dev": true,
          "requires": {
            "debug": "^2.3.3",
            "define-property": "^0.2.5",
            "extend-shallow": "^2.0.1",
            "posix-character-classes": "^0.1.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "0.2.5",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
              "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^0.1.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            },
            "is-accessor-descriptor": {
              "version": "0.1.6",
              "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-0.1.6.tgz",
              "integrity": "sha1-qeEss66Nh2cn7u84Q/igiXtcmNY=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-data-descriptor": {
              "version": "0.1.4",
              "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-0.1.4.tgz",
              "integrity": "sha1-C17mSDiOLIYCgueT8YVv7D8wG1Y=",
              "dev": true,
              "requires": {
                "kind-of": "^3.0.2"
              },
              "dependencies": {
                "kind-of": {
                  "version": "3.2.2",
                  "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
                  "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
                  "dev": true,
                  "requires": {
                    "is-buffer": "^1.1.5"
                  }
                }
              }
            },
            "is-descriptor": {
              "version": "0.1.6",
              "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-0.1.6.tgz",
              "integrity": "sha512-avDYr0SB3DwO9zsMov0gKCESFYqCnE4hq/4z3TdUlukEy5t9C0YRq7HLrsN52NAcqXKaepeCD0n+B0arnVG3Hg==",
              "dev": true,
              "requires": {
                "is-accessor-descriptor": "^0.1.6",
                "is-data-descriptor": "^0.1.4",
                "kind-of": "^5.0.0"
              }
            },
            "kind-of": {
              "version": "5.1.0",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-5.1.0.tgz",
              "integrity": "sha512-NGEErnH6F2vUuXDh+OlbcKW7/wOcfdRHaZ7VWtqCztfHri/++YKmP51OdWeGPuqCOba6kk2OTe5d02VmTB80Pw==",
              "dev": true
            }
          }
        },
        "extglob": {
          "version": "2.0.4",
          "resolved": "https://registry.npmjs.org/extglob/-/extglob-2.0.4.tgz",
          "integrity": "sha512-Nmb6QXkELsuBr24CJSkilo6UHHgbekK5UiZgfE6UHD3Eb27YC6oD+bhcT+tJ6cl8dmsgdQxnWlcry8ksBIBLpw==",
          "dev": true,
          "requires": {
            "array-unique": "^0.3.2",
            "define-property": "^1.0.0",
            "expand-brackets": "^2.1.4",
            "extend-shallow": "^2.0.1",
            "fragment-cache": "^0.2.1",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.1"
          },
          "dependencies": {
            "define-property": {
              "version": "1.0.0",
              "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
              "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
              "dev": true,
              "requires": {
                "is-descriptor": "^1.0.0"
              }
            },
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "fill-range": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-4.0.0.tgz",
          "integrity": "sha1-1USBHUKPmOsGpj3EAtJAPDKMOPc=",
          "dev": true,
          "requires": {
            "extend-shallow": "^2.0.1",
            "is-number": "^3.0.0",
            "repeat-string": "^1.6.1",
            "to-regex-range": "^2.1.0"
          },
          "dependencies": {
            "extend-shallow": {
              "version": "2.0.1",
              "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
              "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
              "dev": true,
              "requires": {
                "is-extendable": "^0.1.0"
              }
            }
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          },
          "dependencies": {
            "kind-of": {
              "version": "3.2.2",
              "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-3.2.2.tgz",
              "integrity": "sha1-MeohpzS6ubuw8yRm2JOupR5KPGQ=",
              "dev": true,
              "requires": {
                "is-buffer": "^1.1.5"
              }
            }
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        },
        "micromatch": {
          "version": "3.1.10",
          "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-3.1.10.tgz",
          "integrity": "sha512-MWikgl9n9M3w+bpsY3He8L+w9eF9338xRl8IAO5viDizwSzziFEyUzo2xrrloB64ADbTf8uA8vRqqttDTOmccg==",
          "dev": true,
          "requires": {
            "arr-diff": "^4.0.0",
            "array-unique": "^0.3.2",
            "braces": "^2.3.1",
            "define-property": "^2.0.2",
            "extend-shallow": "^3.0.2",
            "extglob": "^2.0.4",
            "fragment-cache": "^0.2.1",
            "kind-of": "^6.0.2",
            "nanomatch": "^1.2.9",
            "object.pick": "^1.3.0",
            "regex-not": "^1.0.0",
            "snapdragon": "^0.8.1",
            "to-regex": "^3.0.2"
          }
        }
      }
    },
    "realpath-native": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/realpath-native/-/realpath-native-1.1.0.tgz",
      "integrity": "sha512-wlgPA6cCIIg9gKz0fgAPjnzh4yR/LnXovwuo9hvyGvx3h8nX4+/iLZplfUWasXpqD8BdnGnP5njOFjkUwPzvjA==",
      "dev": true,
      "requires": {
        "util.promisify": "^1.0.0"
      }
    },
    "regenerate": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/regenerate/-/regenerate-1.4.0.tgz",
      "integrity": "sha512-1G6jJVDWrt0rK99kBjvEtziZNCICAuvIPkSiUFIQxVP06RCVpq3dmDo2oi6ABpYaDYaTRr67BEhL8r1wgEZZKg==",
      "dev": true
    },
    "regenerate-unicode-properties": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/regenerate-unicode-properties/-/regenerate-unicode-properties-7.0.0.tgz",
      "integrity": "sha512-s5NGghCE4itSlUS+0WUj88G6cfMVMmH8boTPNvABf8od+2dhT9WDlWu8n01raQAJZMOK8Ch6jSexaRO7swd6aw==",
      "dev": true,
      "requires": {
        "regenerate": "^1.4.0"
      }
    },
    "regenerator-transform": {
      "version": "0.13.3",
      "resolved": "https://registry.npmjs.org/regenerator-transform/-/regenerator-transform-0.13.3.tgz",
      "integrity": "sha512-5ipTrZFSq5vU2YoGoww4uaRVAK4wyYC4TSICibbfEPOruUu8FFP7ErV0BjmbIOEpn3O/k9na9UEdYR/3m7N6uA==",
      "dev": true,
      "requires": {
        "private": "^0.1.6"
      }
    },
    "regex-not": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/regex-not/-/regex-not-1.0.2.tgz",
      "integrity": "sha512-J6SDjUgDxQj5NusnOtdFxDwN/+HWykR8GELwctJ7mdqhcyy1xEc4SRFHUXvxTp661YaVKAjfRLZ9cCqS6tn32A==",
      "dev": true,
      "requires": {
        "extend-shallow": "^3.0.2",
        "safe-regex": "^1.1.0"
      }
    },
    "regexp-tree": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/regexp-tree/-/regexp-tree-0.1.0.tgz",
      "integrity": "sha512-rHQv+tzu+0l3KS/ERabas1yK49ahNVxuH40WcPg53CzP5p8TgmmyBgHELLyJcvjhTD0e5ahSY6C76LbEVtr7cg==",
      "dev": true,
      "requires": {
        "cli-table3": "^0.5.0",
        "colors": "^1.1.2",
        "yargs": "^10.0.3"
      },
      "dependencies": {
        "yargs": {
          "version": "10.1.2",
          "resolved": "https://registry.npmjs.org/yargs/-/yargs-10.1.2.tgz",
          "integrity": "sha512-ivSoxqBGYOqQVruxD35+EyCFDYNEFL/Uo6FcOnz+9xZdZzK0Zzw4r4KhbrME1Oo2gOggwJod2MnsdamSG7H9ig==",
          "dev": true,
          "requires": {
            "cliui": "^4.0.0",
            "decamelize": "^1.1.1",
            "find-up": "^2.1.0",
            "get-caller-file": "^1.0.1",
            "os-locale": "^2.0.0",
            "require-directory": "^2.1.1",
            "require-main-filename": "^1.0.1",
            "set-blocking": "^2.0.0",
            "string-width": "^2.0.0",
            "which-module": "^2.0.0",
            "y18n": "^3.2.1",
            "yargs-parser": "^8.1.0"
          }
        },
        "yargs-parser": {
          "version": "8.1.0",
          "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-8.1.0.tgz",
          "integrity": "sha512-yP+6QqN8BmrgW2ggLtTbdrOyBNSI7zBa4IykmiV5R1wl1JWNxQvWhMfMdmzIYtKU7oP3OOInY/tl2ov3BDjnJQ==",
          "dev": true,
          "requires": {
            "camelcase": "^4.1.0"
          }
        }
      }
    },
    "regexpp": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/regexpp/-/regexpp-2.0.1.tgz",
      "integrity": "sha512-lv0M6+TkDVniA3aD1Eg0DVpfU/booSu7Eev3TDO/mZKHBfVjgCGTV4t4buppESEYDtkArYFOxTJWv6S5C+iaNw==",
      "dev": true
    },
    "regexpu-core": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/regexpu-core/-/regexpu-core-4.4.0.tgz",
      "integrity": "sha512-eDDWElbwwI3K0Lo6CqbQbA6FwgtCz4kYTarrri1okfkRLZAqstU+B3voZBCjg8Fl6iq0gXrJG6MvRgLthfvgOA==",
      "dev": true,
      "requires": {
        "regenerate": "^1.4.0",
        "regenerate-unicode-properties": "^7.0.0",
        "regjsgen": "^0.5.0",
        "regjsparser": "^0.6.0",
        "unicode-match-property-ecmascript": "^1.0.4",
        "unicode-match-property-value-ecmascript": "^1.0.2"
      }
    },
    "regjsgen": {
      "version": "0.5.0",
      "resolved": "https://registry.npmjs.org/regjsgen/-/regjsgen-0.5.0.tgz",
      "integrity": "sha512-RnIrLhrXCX5ow/E5/Mh2O4e/oa1/jW0eaBKTSy3LaCj+M3Bqvm97GWDp2yUtzIs4LEn65zR2yiYGFqb2ApnzDA==",
      "dev": true
    },
    "regjsparser": {
      "version": "0.6.0",
      "resolved": "https://registry.npmjs.org/regjsparser/-/regjsparser-0.6.0.tgz",
      "integrity": "sha512-RQ7YyokLiQBomUJuUG8iGVvkgOLxwyZM8k6d3q5SAXpg4r5TZJZigKFvC6PpD+qQ98bCDC5YelPeA3EucDoNeQ==",
      "dev": true,
      "requires": {
        "jsesc": "~0.5.0"
      },
      "dependencies": {
        "jsesc": {
          "version": "0.5.0",
          "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-0.5.0.tgz",
          "integrity": "sha1-597mbjXW/Bb3EP6R1c9p9w8IkR0=",
          "dev": true
        }
      }
    },
    "remark": {
      "version": "9.0.0",
      "resolved": "https://registry.npmjs.org/remark/-/remark-9.0.0.tgz",
      "integrity": "sha512-amw8rGdD5lHbMEakiEsllmkdBP+/KpjW/PRK6NSGPZKCQowh0BT4IWXDAkRMyG3SB9dKPXWMviFjNusXzXNn3A==",
      "dev": true,
      "requires": {
        "remark-parse": "^5.0.0",
        "remark-stringify": "^5.0.0",
        "unified": "^6.0.0"
      }
    },
    "remark-html": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/remark-html/-/remark-html-8.0.0.tgz",
      "integrity": "sha512-3V2391GL3hxKhrkzYOyfPpxJ6taIKLCfuLVqumeWQOk3H9nTtSQ8St8kMYkBVIEAquXN1chT83qJ/2lAW+dpEg==",
      "dev": true,
      "requires": {
        "hast-util-sanitize": "^1.0.0",
        "hast-util-to-html": "^4.0.0",
        "mdast-util-to-hast": "^3.0.0",
        "xtend": "^4.0.1"
      }
    },
    "remark-parse": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/remark-parse/-/remark-parse-5.0.0.tgz",
      "integrity": "sha512-b3iXszZLH1TLoyUzrATcTQUZrwNl1rE70rVdSruJFlDaJ9z5aMkhrG43Pp68OgfHndL/ADz6V69Zow8cTQu+JA==",
      "dev": true,
      "requires": {
        "collapse-white-space": "^1.0.2",
        "is-alphabetical": "^1.0.0",
        "is-decimal": "^1.0.0",
        "is-whitespace-character": "^1.0.0",
        "is-word-character": "^1.0.0",
        "markdown-escapes": "^1.0.0",
        "parse-entities": "^1.1.0",
        "repeat-string": "^1.5.4",
        "state-toggle": "^1.0.0",
        "trim": "0.0.1",
        "trim-trailing-lines": "^1.0.0",
        "unherit": "^1.0.4",
        "unist-util-remove-position": "^1.0.0",
        "vfile-location": "^2.0.0",
        "xtend": "^4.0.1"
      }
    },
    "remark-reference-links": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/remark-reference-links/-/remark-reference-links-4.0.3.tgz",
      "integrity": "sha512-Q9d7JaK5r0JDBo3TInfrodBuI3xulI8htCr8jlX+0oXosF3GaebJbo5y228VYFoV6xJ+syDukkUGMKNlwSJWjQ==",
      "dev": true,
      "requires": {
        "unist-util-visit": "^1.0.0"
      }
    },
    "remark-slug": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/remark-slug/-/remark-slug-5.1.1.tgz",
      "integrity": "sha512-r591rdoDPJkSSAVvEaTVUkqbMp7c7AyZfif14V0Dp66GQkOHzaPAS6wyhawSbqpS0ZdTnfJS+TltFoxzi6bdIA==",
      "dev": true,
      "requires": {
        "github-slugger": "^1.0.0",
        "mdast-util-to-string": "^1.0.0",
        "unist-util-visit": "^1.0.0"
      }
    },
    "remark-stringify": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/remark-stringify/-/remark-stringify-5.0.0.tgz",
      "integrity": "sha512-Ws5MdA69ftqQ/yhRF9XhVV29mhxbfGhbz0Rx5bQH+oJcNhhSM6nCu1EpLod+DjrFGrU0BMPs+czVmJZU7xiS7w==",
      "dev": true,
      "requires": {
        "ccount": "^1.0.0",
        "is-alphanumeric": "^1.0.0",
        "is-decimal": "^1.0.0",
        "is-whitespace-character": "^1.0.0",
        "longest-streak": "^2.0.1",
        "markdown-escapes": "^1.0.0",
        "markdown-table": "^1.1.0",
        "mdast-util-compact": "^1.0.0",
        "parse-entities": "^1.0.2",
        "repeat-string": "^1.5.4",
        "state-toggle": "^1.0.0",
        "stringify-entities": "^1.0.1",
        "unherit": "^1.0.4",
        "xtend": "^4.0.1"
      }
    },
    "remark-toc": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/remark-toc/-/remark-toc-5.1.1.tgz",
      "integrity": "sha512-vCPW4YOsm2CfyuScdktM9KDnJXVHJsd/ZeRtst+dnBU3B3KKvt8bc+bs5syJjyptAHfqo7H+5Uhz+2blWBfwow==",
      "dev": true,
      "requires": {
        "mdast-util-toc": "^3.0.0",
        "remark-slug": "^5.0.0"
      }
    },
    "remote-origin-url": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/remote-origin-url/-/remote-origin-url-0.4.0.tgz",
      "integrity": "sha1-TT4pAvNOLTfRwmPYdxC3frQIajA=",
      "dev": true,
      "requires": {
        "parse-git-config": "^0.2.0"
      }
    },
    "remove-bom-buffer": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/remove-bom-buffer/-/remove-bom-buffer-3.0.0.tgz",
      "integrity": "sha512-8v2rWhaakv18qcvNeli2mZ/TMTL2nEyAKRvzo1WtnZBl15SHyEhrCu2/xKlJyUFKHiHgfXIyuY6g2dObJJycXQ==",
      "dev": true,
      "requires": {
        "is-buffer": "^1.1.5",
        "is-utf8": "^0.2.1"
      }
    },
    "remove-bom-stream": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/remove-bom-stream/-/remove-bom-stream-1.2.0.tgz",
      "integrity": "sha1-BfGlk/FuQuH7kOv1nejlaVJflSM=",
      "dev": true,
      "requires": {
        "remove-bom-buffer": "^3.0.0",
        "safe-buffer": "^5.1.0",
        "through2": "^2.0.3"
      }
    },
    "remove-trailing-separator": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/remove-trailing-separator/-/remove-trailing-separator-1.1.0.tgz",
      "integrity": "sha1-wkvOKig62tW8P1jg1IJJuSN52O8=",
      "dev": true
    },
    "repeat-element": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/repeat-element/-/repeat-element-1.1.3.tgz",
      "integrity": "sha512-ahGq0ZnV5m5XtZLMb+vP76kcAM5nkLqk0lpqAuojSKGgQtn4eRi4ZZGm2olo2zKFH+sMsWaqOCW1dqAnOru72g==",
      "dev": true
    },
    "repeat-string": {
      "version": "1.6.1",
      "resolved": "https://registry.npmjs.org/repeat-string/-/repeat-string-1.6.1.tgz",
      "integrity": "sha1-jcrkcOHIirwtYA//Sndihtp15jc=",
      "dev": true
    },
    "replace-ext": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/replace-ext/-/replace-ext-1.0.0.tgz",
      "integrity": "sha1-3mMSg3P8v3w8z6TeWkgMRaZ5WOs=",
      "dev": true
    },
    "request": {
      "version": "2.88.0",
      "resolved": "https://registry.npmjs.org/request/-/request-2.88.0.tgz",
      "integrity": "sha512-NAqBSrijGLZdM0WZNsInLJpkJokL72XYjUpnB0iwsRgxh7dB6COrHnTBNwN0E+lHDAJzu7kLAkDeY08z2/A0hg==",
      "dev": true,
      "requires": {
        "aws-sign2": "~0.7.0",
        "aws4": "^1.8.0",
        "caseless": "~0.12.0",
        "combined-stream": "~1.0.6",
        "extend": "~3.0.2",
        "forever-agent": "~0.6.1",
        "form-data": "~2.3.2",
        "har-validator": "~5.1.0",
        "http-signature": "~1.2.0",
        "is-typedarray": "~1.0.0",
        "isstream": "~0.1.2",
        "json-stringify-safe": "~5.0.1",
        "mime-types": "~2.1.19",
        "oauth-sign": "~0.9.0",
        "performance-now": "^2.1.0",
        "qs": "~6.5.2",
        "safe-buffer": "^5.1.2",
        "tough-cookie": "~2.4.3",
        "tunnel-agent": "^0.6.0",
        "uuid": "^3.3.2"
      },
      "dependencies": {
        "punycode": {
          "version": "1.4.1",
          "resolved": "https://registry.npmjs.org/punycode/-/punycode-1.4.1.tgz",
          "integrity": "sha1-wNWmOycYgArY4esPpSachN1BhF4=",
          "dev": true
        },
        "tough-cookie": {
          "version": "2.4.3",
          "resolved": "https://registry.npmjs.org/tough-cookie/-/tough-cookie-2.4.3.tgz",
          "integrity": "sha512-Q5srk/4vDM54WJsJio3XNn6K2sCG+CQ8G5Wz6bZhRZoAe/+TxjWB/GlFAnYEbkYVlON9FMk/fE3h2RLpPXo4lQ==",
          "dev": true,
          "requires": {
            "psl": "^1.1.24",
            "punycode": "^1.4.1"
          }
        }
      }
    },
    "request-promise-core": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/request-promise-core/-/request-promise-core-1.1.2.tgz",
      "integrity": "sha512-UHYyq1MO8GsefGEt7EprS8UrXsm1TxEvFUX1IMTuSLU2Rh7fTIdFtl8xD7JiEYiWU2dl+NYAjCTksTehQUxPag==",
      "dev": true,
      "requires": {
        "lodash": "^4.17.11"
      }
    },
    "request-promise-native": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/request-promise-native/-/request-promise-native-1.0.7.tgz",
      "integrity": "sha512-rIMnbBdgNViL37nZ1b3L/VfPOpSi0TqVDQPAvO6U14lMzOLrt5nilxCQqtDKhZeDiW0/hkCXGoQjhgJd/tCh6w==",
      "dev": true,
      "requires": {
        "request-promise-core": "1.1.2",
        "stealthy-require": "^1.1.1",
        "tough-cookie": "^2.3.3"
      }
    },
    "require-directory": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz",
      "integrity": "sha1-jGStX9MNqxyXbiNE/+f3kqam30I=",
      "dev": true
    },
    "require-main-filename": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/require-main-filename/-/require-main-filename-1.0.1.tgz",
      "integrity": "sha1-l/cXtp1IeE9fUmpsWqj/3aBVpNE=",
      "dev": true
    },
    "resolve": {
      "version": "1.1.7",
      "resolved": "http://registry.npmjs.org/resolve/-/resolve-1.1.7.tgz",
      "integrity": "sha1-IDEU2CrSxe2ejgQRs5ModeiJ6Xs=",
      "dev": true
    },
    "resolve-cwd": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/resolve-cwd/-/resolve-cwd-2.0.0.tgz",
      "integrity": "sha1-AKn3OHVW4nA46uIyyqNypqWbZlo=",
      "dev": true,
      "requires": {
        "resolve-from": "^3.0.0"
      }
    },
    "resolve-from": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-3.0.0.tgz",
      "integrity": "sha1-six699nWiBvItuZTM17rywoYh0g=",
      "dev": true
    },
    "resolve-options": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/resolve-options/-/resolve-options-1.1.0.tgz",
      "integrity": "sha1-MrueOcBtZzONyTeMDW1gdFZq0TE=",
      "dev": true,
      "requires": {
        "value-or-function": "^3.0.0"
      }
    },
    "resolve-url": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/resolve-url/-/resolve-url-0.2.1.tgz",
      "integrity": "sha1-LGN/53yJOv0qZj/iGqkIAGjiBSo=",
      "dev": true
    },
    "restore-cursor": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/restore-cursor/-/restore-cursor-2.0.0.tgz",
      "integrity": "sha1-n37ih/gv0ybU/RYpI9YhKe7g368=",
      "dev": true,
      "requires": {
        "onetime": "^2.0.0",
        "signal-exit": "^3.0.2"
      }
    },
    "ret": {
      "version": "0.1.15",
      "resolved": "https://registry.npmjs.org/ret/-/ret-0.1.15.tgz",
      "integrity": "sha512-TTlYpa+OL+vMMNG24xSlQGEJ3B/RzEfUlLct7b5G/ytav+wPrplCpVMFuwzXbkecJrb6IYo1iFb0S9v37754mg==",
      "dev": true
    },
    "rimraf": {
      "version": "2.6.3",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-2.6.3.tgz",
      "integrity": "sha512-mwqeW5XsA2qAejG46gYdENaxXjx9onRNCfn7L0duuP4hCuTIi/QO7PDK07KJfp1d+izWPrzEJDcSqBa0OZQriA==",
      "dev": true,
      "requires": {
        "glob": "^7.1.3"
      }
    },
    "ripemd160": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/ripemd160/-/ripemd160-2.0.2.tgz",
      "integrity": "sha512-ii4iagi25WusVoiC4B4lq7pbXfAp3D9v5CwfkY33vffw2+pkDjY1D8GaN7spsxvCSx8dkPqOZCEZyfxcmJG2IA==",
      "dev": true,
      "requires": {
        "hash-base": "^3.0.0",
        "inherits": "^2.0.1"
      }
    },
    "rsvp": {
      "version": "4.8.4",
      "resolved": "https://registry.npmjs.org/rsvp/-/rsvp-4.8.4.tgz",
      "integrity": "sha512-6FomvYPfs+Jy9TfXmBpBuMWNH94SgCsZmJKcanySzgNNP6LjWxBvyLTa9KaMfDDM5oxRfrKDB0r/qeRsLwnBfA==",
      "dev": true
    },
    "run-async": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/run-async/-/run-async-2.3.0.tgz",
      "integrity": "sha1-A3GrSuC91yDUFm19/aZP96RFpsA=",
      "dev": true,
      "requires": {
        "is-promise": "^2.1.0"
      }
    },
    "rxjs": {
      "version": "6.4.0",
      "resolved": "https://registry.npmjs.org/rxjs/-/rxjs-6.4.0.tgz",
      "integrity": "sha512-Z9Yfa11F6B9Sg/BK9MnqnQ+aQYicPLtilXBp2yUtDt2JRCE0h26d33EnfO3ZxoNxG0T92OUucP3Ct7cpfkdFfw==",
      "dev": true,
      "requires": {
        "tslib": "^1.9.0"
      }
    },
    "safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g=="
    },
    "safe-json-parse": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/safe-json-parse/-/safe-json-parse-1.0.1.tgz",
      "integrity": "sha1-PnZyPjjf3aE8mx0poeB//uSzC1c=",
      "dev": true
    },
    "safe-regex": {
      "version": "1.1.0",
      "resolved": "http://registry.npmjs.org/safe-regex/-/safe-regex-1.1.0.tgz",
      "integrity": "sha1-QKNmnzsHfR6UPURinhV91IAjvy4=",
      "dev": true,
      "requires": {
        "ret": "~0.1.10"
      }
    },
    "safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==",
      "dev": true
    },
    "sane": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/sane/-/sane-4.1.0.tgz",
      "integrity": "sha512-hhbzAgTIX8O7SHfp2c8/kREfEn4qO/9q8C9beyY6+tvZ87EpoZ3i1RIEvp27YBswnNbY9mWd6paKVmKbAgLfZA==",
      "dev": true,
      "requires": {
        "@cnakazawa/watch": "^1.0.3",
        "anymatch": "^2.0.0",
        "capture-exit": "^2.0.0",
        "exec-sh": "^0.3.2",
        "execa": "^1.0.0",
        "fb-watchman": "^2.0.0",
        "micromatch": "^3.1.4",
        "minimist": "^1.1.1",
        "walker": "~1.0.5"
      },
      "dependencies": {
        "cross-spawn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-6.0.5.tgz",
          "integrity": "sha512-eTVLrBSt7fjbDygz805pMnstIs2VTBNkRm0qxZd+M7A5XDdxVRWO5MxGBXZhjY4cqLYLdtrGqRf8mBPmzwSpWQ==",
          "dev": true,
          "requires": {
            "nice-try": "^1.0.4",
            "path-key": "^2.0.1",
            "semver": "^5.5.0",
            "shebang-command": "^1.2.0",
            "which": "^1.2.9"
          }
        },
        "execa": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/execa/-/execa-1.0.0.tgz",
          "integrity": "sha512-adbxcyWV46qiHyvSp50TKt05tB4tK3HcmF7/nxfAdhnox83seTDbwnaqKO4sXRy7roHAIFqJP/Rw/AuEbX61LA==",
          "dev": true,
          "requires": {
            "cross-spawn": "^6.0.0",
            "get-stream": "^4.0.0",
            "is-stream": "^1.1.0",
            "npm-run-path": "^2.0.0",
            "p-finally": "^1.0.0",
            "signal-exit": "^3.0.0",
            "strip-eof": "^1.0.0"
          }
        },
        "get-stream": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-4.1.0.tgz",
          "integrity": "sha512-GMat4EJ5161kIy2HevLlr4luNjBgvmj413KaQA7jt4V8B4RDsfpHk7WQ9GVqfYyyx8OS/L66Kox+rJRNklLK7w==",
          "dev": true,
          "requires": {
            "pump": "^3.0.0"
          }
        },
        "minimist": {
          "version": "1.2.0",
          "resolved": "http://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
          "dev": true
        },
        "pump": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.0.tgz",
          "integrity": "sha512-LwZy+p3SFs1Pytd/jYct4wpv49HiYCqd9Rlc5ZVdk0V+8Yzv6jR5Blk3TRmPL1ft69TxP0IMZGJ+WPFU2BFhww==",
          "dev": true,
          "requires": {
            "end-of-stream": "^1.1.0",
            "once": "^1.3.1"
          }
        }
      }
    },
    "sax": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/sax/-/sax-1.2.4.tgz",
      "integrity": "sha512-NqVDv9TpANUjFm0N8uM5GxL36UgKi9/atZw+x7YFnQ8ckwFGKrl4xX4yWtrey3UJm5nP1kUbnYgLopqWNSRhWw==",
      "dev": true
    },
    "semver": {
      "version": "5.6.0",
      "resolved": "https://registry.npmjs.org/semver/-/semver-5.6.0.tgz",
      "integrity": "sha512-RS9R6R35NYgQn++fkDWaOmqGoj4Ek9gGs+DPxNUZKuwE183xjJroKvyo1IzVFeXvUrvmALy6FWD5xrdJT25gMg==",
      "dev": true
    },
    "set-blocking": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/set-blocking/-/set-blocking-2.0.0.tgz",
      "integrity": "sha1-BF+XgtARrppoA93TgrJDkrPYkPc=",
      "dev": true
    },
    "set-value": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/set-value/-/set-value-2.0.0.tgz",
      "integrity": "sha512-hw0yxk9GT/Hr5yJEYnHNKYXkIA8mVJgd9ditYZCe16ZczcaELYYcfvaXesNACk2O8O0nTiPQcQhGUQj8JLzeeg==",
      "dev": true,
      "requires": {
        "extend-shallow": "^2.0.1",
        "is-extendable": "^0.1.1",
        "is-plain-object": "^2.0.3",
        "split-string": "^3.0.1"
      },
      "dependencies": {
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        }
      }
    },
    "setprototypeof": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.1.0.tgz",
      "integrity": "sha512-BvE/TwpZX4FXExxOxZyRGQQv651MSwmWKZGqvmPcRIjDqWub67kTKuIMx43cZZrS/cBBzwBcNDWoFxt2XEFIpQ=="
    },
    "sha.js": {
      "version": "2.4.11",
      "resolved": "https://registry.npmjs.org/sha.js/-/sha.js-2.4.11.tgz",
      "integrity": "sha512-QMEp5B7cftE7APOjk5Y6xgrbWu+WkLVQwk8JNjZ8nKRciZaByEW6MubieAiToS7+dwvrjGhH8jRXz3MVd0AYqQ==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "shasum": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/shasum/-/shasum-1.0.2.tgz",
      "integrity": "sha1-5wEjENj0F/TetXEhUOVni4euVl8=",
      "dev": true,
      "requires": {
        "json-stable-stringify": "~0.0.0",
        "sha.js": "~2.4.4"
      }
    },
    "shebang-command": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-1.2.0.tgz",
      "integrity": "sha1-RKrGW2lbAzmJaMOfNj/uXer98eo=",
      "dev": true,
      "requires": {
        "shebang-regex": "^1.0.0"
      }
    },
    "shebang-regex": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-1.0.0.tgz",
      "integrity": "sha1-2kL0l0DAtC2yypcoVxyxkMmO/qM=",
      "dev": true
    },
    "shell-quote": {
      "version": "1.6.1",
      "resolved": "https://registry.npmjs.org/shell-quote/-/shell-quote-1.6.1.tgz",
      "integrity": "sha1-9HgZSczkAmlxJ0MOo7PFR29IF2c=",
      "dev": true,
      "requires": {
        "array-filter": "~0.0.0",
        "array-map": "~0.0.0",
        "array-reduce": "~0.0.0",
        "jsonify": "~0.0.0"
      }
    },
    "shellwords": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/shellwords/-/shellwords-0.1.1.tgz",
      "integrity": "sha512-vFwSUfQvqybiICwZY5+DAWIPLKsWO31Q91JSKl3UYv+K5c2QRPzn0qzec6QPu1Qc9eHYItiP3NdJqNVqetYAww==",
      "dev": true
    },
    "signal-exit": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.2.tgz",
      "integrity": "sha1-tf3AjxKH6hF4Yo5BXiUTK3NkbG0=",
      "dev": true
    },
    "simple-concat": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/simple-concat/-/simple-concat-1.0.0.tgz",
      "integrity": "sha1-c0TLuLbib7J9ZrL8hvn21Zl1IcY=",
      "dev": true
    },
    "sisteransi": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/sisteransi/-/sisteransi-1.0.0.tgz",
      "integrity": "sha512-N+z4pHB4AmUv0SjveWRd6q1Nj5w62m5jodv+GD8lvmbY/83T/rpbJGZOnK5T149OldDj4Db07BSv9xY4K6NTPQ==",
      "dev": true
    },
    "slash": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-2.0.0.tgz",
      "integrity": "sha512-ZYKh3Wh2z1PpEXWr0MpSBZ0V6mZHAQfYevttO11c51CaWjGTaadiKZ+wVt1PbMlDV5qhMFslpZCemhwOK7C89A==",
      "dev": true
    },
    "slice-ansi": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/slice-ansi/-/slice-ansi-2.1.0.tgz",
      "integrity": "sha512-Qu+VC3EwYLldKa1fCxuuvULvSJOKEgk9pi8dZeCVK7TqBfUNTH4sFkk4joj8afVSfAYgJoSOetjx9QWOJ5mYoQ==",
      "dev": true,
      "requires": {
        "ansi-styles": "^3.2.0",
        "astral-regex": "^1.0.0",
        "is-fullwidth-code-point": "^2.0.0"
      }
    },
    "snapdragon": {
      "version": "0.8.2",
      "resolved": "https://registry.npmjs.org/snapdragon/-/snapdragon-0.8.2.tgz",
      "integrity": "sha512-FtyOnWN/wCHTVXOMwvSv26d+ko5vWlIDD6zoUJ7LW8vh+ZBC8QdljveRP+crNrtBwioEUWy/4dMtbBjA4ioNlg==",
      "dev": true,
      "requires": {
        "base": "^0.11.1",
        "debug": "^2.2.0",
        "define-property": "^0.2.5",
        "extend-shallow": "^2.0.1",
        "map-cache": "^0.2.2",
        "source-map": "^0.5.6",
        "source-map-resolve": "^0.5.0",
        "use": "^3.1.0"
      },
      "dependencies": {
        "define-property": {
          "version": "0.2.5",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
          "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^0.1.0"
          }
        },
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        }
      }
    },
    "snapdragon-node": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/snapdragon-node/-/snapdragon-node-2.1.1.tgz",
      "integrity": "sha512-O27l4xaMYt/RSQ5TR3vpWCAB5Kb/czIcqUFOM/C4fYcLnbZUc1PkjTAMjof2pBWaSTwOUd6qUHcFGVGj7aIwnw==",
      "dev": true,
      "requires": {
        "define-property": "^1.0.0",
        "isobject": "^3.0.0",
        "snapdragon-util": "^3.0.1"
      },
      "dependencies": {
        "define-property": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-1.0.0.tgz",
          "integrity": "sha1-dp66rz9KY6rTr56NMEybvnm/sOY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^1.0.0"
          }
        },
        "is-accessor-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-accessor-descriptor/-/is-accessor-descriptor-1.0.0.tgz",
          "integrity": "sha512-m5hnHTkcVsPfqx3AKlyttIPb7J+XykHvJP2B9bZDjlhLIoEq4XoK64Vg7boZlVWYK6LUY94dYPEE7Lh0ZkZKcQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-data-descriptor": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-data-descriptor/-/is-data-descriptor-1.0.0.tgz",
          "integrity": "sha512-jbRXy1FmtAoCjQkVmIVYwuuqDFUbaOeDjmed1tOGPrsMhtJA4rD9tkgA0F1qJ3gRFRXcHYVkdeaP50Q5rE/jLQ==",
          "dev": true,
          "requires": {
            "kind-of": "^6.0.0"
          }
        },
        "is-descriptor": {
          "version": "1.0.2",
          "resolved": "https://registry.npmjs.org/is-descriptor/-/is-descriptor-1.0.2.tgz",
          "integrity": "sha512-2eis5WqQGV7peooDyLmNEPUrps9+SXX5c9pL3xEB+4e9HnGuDa7mB7kHxHw4CbqS9k1T2hOH3miL8n8WtiYVtg==",
          "dev": true,
          "requires": {
            "is-accessor-descriptor": "^1.0.0",
            "is-data-descriptor": "^1.0.0",
            "kind-of": "^6.0.2"
          }
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        },
        "kind-of": {
          "version": "6.0.2",
          "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.2.tgz",
          "integrity": "sha512-s5kLOcnH0XqDO+FvuaLX8DDjZ18CGFk7VygH40QoKPUQhW4e2rvM0rwUq0t8IQDOwYSeLK01U90OjzBTme2QqA==",
          "dev": true
        }
      }
    },
    "snapdragon-util": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/snapdragon-util/-/snapdragon-util-3.0.1.tgz",
      "integrity": "sha512-mbKkMdQKsjX4BAL4bRYTj21edOf8cN7XHdYUJEe+Zn99hVEYcMvKPct1IqNe7+AZPirn8BCDOQBHQZknqmKlZQ==",
      "dev": true,
      "requires": {
        "kind-of": "^3.2.0"
      }
    },
    "sort-keys": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/sort-keys/-/sort-keys-1.1.2.tgz",
      "integrity": "sha1-RBttTTRnmPG05J6JIK37oOVD+a0=",
      "dev": true,
      "requires": {
        "is-plain-obj": "^1.0.0"
      }
    },
    "source-map": {
      "version": "0.5.7",
      "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.5.7.tgz",
      "integrity": "sha1-igOdLRAh0i0eoUyA2OpGi6LvP8w=",
      "dev": true
    },
    "source-map-resolve": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/source-map-resolve/-/source-map-resolve-0.5.2.tgz",
      "integrity": "sha512-MjqsvNwyz1s0k81Goz/9vRBe9SZdB09Bdw+/zYyO+3CuPk6fouTaxscHkgtE8jKvf01kVfl8riHzERQ/kefaSA==",
      "dev": true,
      "requires": {
        "atob": "^2.1.1",
        "decode-uri-component": "^0.2.0",
        "resolve-url": "^0.2.1",
        "source-map-url": "^0.4.0",
        "urix": "^0.1.0"
      }
    },
    "source-map-support": {
      "version": "0.5.12",
      "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.12.tgz",
      "integrity": "sha512-4h2Pbvyy15EE02G+JOZpUCmqWJuqrs+sEkzewTm++BPi7Hvn/HwcqLAcNxYAyI0x13CpPPn+kMjl+hplXMHITQ==",
      "dev": true,
      "requires": {
        "buffer-from": "^1.0.0",
        "source-map": "^0.6.0"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        }
      }
    },
    "source-map-url": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/source-map-url/-/source-map-url-0.4.0.tgz",
      "integrity": "sha1-PpNdfd1zYxuXZZlW1VEo6HtQhKM=",
      "dev": true
    },
    "space-separated-tokens": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-1.1.2.tgz",
      "integrity": "sha512-G3jprCEw+xFEs0ORweLmblJ3XLymGGr6hxZYTYZjIlvDti9vOBUjRQa1Rzjt012aRrocKstHwdNi+F7HguPsEA==",
      "dev": true,
      "requires": {
        "trim": "0.0.1"
      }
    },
    "spdx-correct": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/spdx-correct/-/spdx-correct-3.1.0.tgz",
      "integrity": "sha512-lr2EZCctC2BNR7j7WzJ2FpDznxky1sjfxvvYEyzxNyb6lZXHODmEoJeFu4JupYlkfha1KZpJyoqiJ7pgA1qq8Q==",
      "dev": true,
      "requires": {
        "spdx-expression-parse": "^3.0.0",
        "spdx-license-ids": "^3.0.0"
      }
    },
    "spdx-exceptions": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/spdx-exceptions/-/spdx-exceptions-2.2.0.tgz",
      "integrity": "sha512-2XQACfElKi9SlVb1CYadKDXvoajPgBVPn/gOQLrTvHdElaVhr7ZEbqJaRnJLVNeaI4cMEAgVCeBMKF6MWRDCRA==",
      "dev": true
    },
    "spdx-expression-parse": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/spdx-expression-parse/-/spdx-expression-parse-3.0.0.tgz",
      "integrity": "sha512-Yg6D3XpRD4kkOmTpdgbUiEJFKghJH03fiC1OPll5h/0sO6neh2jqRDVHOQ4o/LMea0tgCkbMgea5ip/e+MkWyg==",
      "dev": true,
      "requires": {
        "spdx-exceptions": "^2.1.0",
        "spdx-license-ids": "^3.0.0"
      }
    },
    "spdx-license-ids": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/spdx-license-ids/-/spdx-license-ids-3.0.3.tgz",
      "integrity": "sha512-uBIcIl3Ih6Phe3XHK1NqboJLdGfwr1UN3k6wSD1dZpmPsIkb8AGNbZYJ1fOBk834+Gxy8rpfDxrS6XLEMZMY2g==",
      "dev": true
    },
    "split-string": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/split-string/-/split-string-3.1.0.tgz",
      "integrity": "sha512-NzNVhJDYpwceVVii8/Hu6DKfD2G+NrQHlS/V/qgv763EYudVwEcMQNxd2lh+0VrUByXN/oJkl5grOhYWvQUYiw==",
      "dev": true,
      "requires": {
        "extend-shallow": "^3.0.0"
      }
    },
    "sprintf-js": {
      "version": "1.0.3",
      "resolved": "http://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
      "integrity": "sha1-BOaSb2YolTVPPdAVIDYzuFcpfiw=",
      "dev": true
    },
    "sshpk": {
      "version": "1.16.1",
      "resolved": "https://registry.npmjs.org/sshpk/-/sshpk-1.16.1.tgz",
      "integrity": "sha512-HXXqVUq7+pcKeLqqZj6mHFUMvXtOJt1uoUx09pFW6011inTMxqI8BA8PM95myrIyyKwdnzjdFjLiE6KBPVtJIg==",
      "dev": true,
      "requires": {
        "asn1": "~0.2.3",
        "assert-plus": "^1.0.0",
        "bcrypt-pbkdf": "^1.0.0",
        "dashdash": "^1.12.0",
        "ecc-jsbn": "~0.1.1",
        "getpass": "^0.1.1",
        "jsbn": "~0.1.0",
        "safer-buffer": "^2.0.2",
        "tweetnacl": "~0.14.0"
      },
      "dependencies": {
        "tweetnacl": {
          "version": "0.14.5",
          "resolved": "https://registry.npmjs.org/tweetnacl/-/tweetnacl-0.14.5.tgz",
          "integrity": "sha1-WuaBd/GS1EViadEIr6k/+HQ/T2Q=",
          "dev": true
        }
      }
    },
    "stack-utils": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-1.0.2.tgz",
      "integrity": "sha512-MTX+MeG5U994cazkjd/9KNAapsHnibjMLnfXodlkXw76JEea0UiNzrqidzo1emMwk7w5Qhc9jd4Bn9TBb1MFwA==",
      "dev": true
    },
    "state-toggle": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/state-toggle/-/state-toggle-1.0.1.tgz",
      "integrity": "sha512-Qe8QntFrrpWTnHwvwj2FZTgv+PKIsp0B9VxLzLLbSpPXWOgRgc5LVj/aTiSfK1RqIeF9jeC1UeOH8Q8y60A7og==",
      "dev": true
    },
    "static-extend": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/static-extend/-/static-extend-0.1.2.tgz",
      "integrity": "sha1-YICcOcv/VTNyJv1eC1IPNB8ftcY=",
      "dev": true,
      "requires": {
        "define-property": "^0.2.5",
        "object-copy": "^0.1.0"
      },
      "dependencies": {
        "define-property": {
          "version": "0.2.5",
          "resolved": "https://registry.npmjs.org/define-property/-/define-property-0.2.5.tgz",
          "integrity": "sha1-w1se+RjsPJkPmlvFe+BKrOxcgRY=",
          "dev": true,
          "requires": {
            "is-descriptor": "^0.1.0"
          }
        }
      }
    },
    "statuses": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-1.5.0.tgz",
      "integrity": "sha1-Fhx9rBd2Wf2YEfQ3cfqZOBR4Yow="
    },
    "stealthy-require": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/stealthy-require/-/stealthy-require-1.1.1.tgz",
      "integrity": "sha1-NbCYdbT/SfJqd35QmzCQoyJr8ks=",
      "dev": true
    },
    "stream-array": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/stream-array/-/stream-array-1.1.2.tgz",
      "integrity": "sha1-nl9zRfITfDDuO0mLkRToC1K7frU=",
      "dev": true,
      "requires": {
        "readable-stream": "~2.1.0"
      },
      "dependencies": {
        "process-nextick-args": {
          "version": "1.0.7",
          "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-1.0.7.tgz",
          "integrity": "sha1-FQ4gt1ZZCtP5EJPyWk8q2L/zC6M=",
          "dev": true
        },
        "readable-stream": {
          "version": "2.1.5",
          "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.1.5.tgz",
          "integrity": "sha1-ZvqLcg4UOLNkaB8q0aY8YYRIydA=",
          "dev": true,
          "requires": {
            "buffer-shims": "^1.0.0",
            "core-util-is": "~1.0.0",
            "inherits": "~2.0.1",
            "isarray": "~1.0.0",
            "process-nextick-args": "~1.0.6",
            "string_decoder": "~0.10.x",
            "util-deprecate": "~1.0.1"
          }
        },
        "string_decoder": {
          "version": "0.10.31",
          "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-0.10.31.tgz",
          "integrity": "sha1-YuIDvEF2bGwoyfyEMB2rHFMQ+pQ=",
          "dev": true
        }
      }
    },
    "stream-browserify": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/stream-browserify/-/stream-browserify-2.0.1.tgz",
      "integrity": "sha1-ZiZu5fm9uZQKTkUUyvtDu3Hlyds=",
      "dev": true,
      "requires": {
        "inherits": "~2.0.1",
        "readable-stream": "^2.0.2"
      }
    },
    "stream-combiner2": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/stream-combiner2/-/stream-combiner2-1.1.1.tgz",
      "integrity": "sha1-+02KFCDqNidk4hrUeAOXvry0HL4=",
      "dev": true,
      "requires": {
        "duplexer2": "~0.1.0",
        "readable-stream": "^2.0.2"
      }
    },
    "stream-http": {
      "version": "2.8.3",
      "resolved": "https://registry.npmjs.org/stream-http/-/stream-http-2.8.3.tgz",
      "integrity": "sha512-+TSkfINHDo4J+ZobQLWiMouQYB+UVYFttRA94FpEzzJ7ZdqcL4uUUQ7WkdkI4DSozGmgBUE/a47L+38PenXhUw==",
      "dev": true,
      "requires": {
        "builtin-status-codes": "^3.0.0",
        "inherits": "^2.0.1",
        "readable-stream": "^2.3.6",
        "to-arraybuffer": "^1.0.0",
        "xtend": "^4.0.0"
      }
    },
    "stream-shift": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/stream-shift/-/stream-shift-1.0.0.tgz",
      "integrity": "sha1-1cdSgl5TZ+eG944Y5EXqIjoVWVI=",
      "dev": true
    },
    "stream-splicer": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/stream-splicer/-/stream-splicer-2.0.0.tgz",
      "integrity": "sha1-G2O+Q4oTPktnHMGTUZdgAXWRDYM=",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "readable-stream": "^2.0.2"
      }
    },
    "strict-uri-encode": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/strict-uri-encode/-/strict-uri-encode-1.1.0.tgz",
      "integrity": "sha1-J5siXfHVgrH1TmWt3UNS4Y+qBxM=",
      "dev": true
    },
    "string-length": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/string-length/-/string-length-2.0.0.tgz",
      "integrity": "sha1-1A27aGo6zpYMHP/KVivyxF+DY+0=",
      "dev": true,
      "requires": {
        "astral-regex": "^1.0.0",
        "strip-ansi": "^4.0.0"
      }
    },
    "string-template": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/string-template/-/string-template-0.2.1.tgz",
      "integrity": "sha1-QpMuWYo1LQH8IuwzZ9nYTuxsmt0=",
      "dev": true
    },
    "string-width": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-2.1.1.tgz",
      "integrity": "sha512-nOqH59deCq9SRHlxq1Aw85Jnt4w6KvLKqWVik6oA9ZklXLNIOlqg4F2yrT1MVaTjAqvVwdfeZ7w7aCvJD7ugkw==",
      "dev": true,
      "requires": {
        "is-fullwidth-code-point": "^2.0.0",
        "strip-ansi": "^4.0.0"
      }
    },
    "string_decoder": {
      "version": "1.1.1",
      "resolved": "http://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "dev": true,
      "requires": {
        "safe-buffer": "~5.1.0"
      }
    },
    "stringify-entities": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/stringify-entities/-/stringify-entities-1.3.2.tgz",
      "integrity": "sha512-nrBAQClJAPN2p+uGCVJRPIPakKeKWZ9GtBCmormE7pWOSlHat7+x5A8gx85M7HM5Dt0BP3pP5RhVW77WdbJJ3A==",
      "dev": true,
      "requires": {
        "character-entities-html4": "^1.0.0",
        "character-entities-legacy": "^1.0.0",
        "is-alphanumerical": "^1.0.0",
        "is-hexadecimal": "^1.0.0"
      }
    },
    "strip-ansi": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-4.0.0.tgz",
      "integrity": "sha1-qEeQIusaw2iocTibY1JixQXuNo8=",
      "dev": true,
      "requires": {
        "ansi-regex": "^3.0.0"
      },
      "dependencies": {
        "ansi-regex": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-3.0.0.tgz",
          "integrity": "sha1-7QMXwyIGT3lGbAKWa922Bas32Zg=",
          "dev": true
        }
      }
    },
    "strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM=",
      "dev": true
    },
    "strip-eof": {
      "version": "1.0.0",
      "resolved": "http://registry.npmjs.org/strip-eof/-/strip-eof-1.0.0.tgz",
      "integrity": "sha1-u0P/VZim6wXYm1n80SnJgzE2Br8=",
      "dev": true
    },
    "strip-json-comments": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-2.0.1.tgz",
      "integrity": "sha1-PFMZQukIwml8DsNEhYwobHygpgo=",
      "dev": true
    },
    "subarg": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/subarg/-/subarg-1.0.0.tgz",
      "integrity": "sha1-9izxdYHplrSPyWVpn1TAauJouNI=",
      "dev": true,
      "requires": {
        "minimist": "^1.1.0"
      },
      "dependencies": {
        "minimist": {
          "version": "1.2.0",
          "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
          "integrity": "sha1-o1AIsg9BOD7sH7kU9M1d95omQoQ=",
          "dev": true
        }
      }
    },
    "supports-color": {
      "version": "5.5.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
      "dev": true,
      "requires": {
        "has-flag": "^3.0.0"
      }
    },
    "symbol-tree": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.2.tgz",
      "integrity": "sha1-rifbOPZgp64uHDt9G8KQgZuFGeY=",
      "dev": true
    },
    "syntax-error": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/syntax-error/-/syntax-error-1.4.0.tgz",
      "integrity": "sha512-YPPlu67mdnHGTup2A8ff7BC2Pjq0e0Yp/IyTFN03zWO0RcK07uLcbi7C2KpGR2FvWbaB0+bfE27a+sBKebSo7w==",
      "dev": true,
      "requires": {
        "acorn-node": "^1.2.0"
      }
    },
    "table": {
      "version": "5.2.3",
      "resolved": "https://registry.npmjs.org/table/-/table-5.2.3.tgz",
      "integrity": "sha512-N2RsDAMvDLvYwFcwbPyF3VmVSSkuF+G1e+8inhBLtHpvwXGw4QRPEZhihQNeEN0i1up6/f6ObCJXNdlRG3YVyQ==",
      "dev": true,
      "requires": {
        "ajv": "^6.9.1",
        "lodash": "^4.17.11",
        "slice-ansi": "^2.1.0",
        "string-width": "^3.0.0"
      },
      "dependencies": {
        "ajv": {
          "version": "6.9.2",
          "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.9.2.tgz",
          "integrity": "sha512-4UFy0/LgDo7Oa/+wOAlj44tp9K78u38E5/359eSrqEp1Z5PdVfimCcs7SluXMP755RUQu6d2b4AvF0R1C9RZjg==",
          "dev": true,
          "requires": {
            "fast-deep-equal": "^2.0.1",
            "fast-json-stable-stringify": "^2.0.0",
            "json-schema-traverse": "^0.4.1",
            "uri-js": "^4.2.2"
          }
        },
        "ansi-regex": {
          "version": "4.0.0",
          "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-4.0.0.tgz",
          "integrity": "sha512-iB5Dda8t/UqpPI/IjsejXu5jOGDrzn41wJyljwPH65VCIbk6+1BzFIMJGFwTNrYXT1CrD+B4l19U7awiQ8rk7w==",
          "dev": true
        },
        "emoji-regex": {
          "version": "7.0.3",
          "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-7.0.3.tgz",
          "integrity": "sha512-CwBLREIQ7LvYFB0WyRvwhq5N5qPhc6PMjD6bYggFlI5YyDgl+0vxq5VHbMOFqLg7hfWzmu8T5Z1QofhmTIhItA==",
          "dev": true
        },
        "string-width": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/string-width/-/string-width-3.0.0.tgz",
          "integrity": "sha512-rr8CUxBbvOZDUvc5lNIJ+OC1nPVpz+Siw9VBtUjB9b6jZehZLFt0JMCZzShFHIsI8cbhm0EsNIfWJMFV3cu3Ew==",
          "dev": true,
          "requires": {
            "emoji-regex": "^7.0.1",
            "is-fullwidth-code-point": "^2.0.0",
            "strip-ansi": "^5.0.0"
          }
        },
        "strip-ansi": {
          "version": "5.0.0",
          "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-5.0.0.tgz",
          "integrity": "sha512-Uu7gQyZI7J7gn5qLn1Np3G9vcYGTVqB+lFTytnDJv83dd8T22aGH451P3jueT2/QemInJDfxHB5Tde5OzgG1Ow==",
          "dev": true,
          "requires": {
            "ansi-regex": "^4.0.0"
          }
        }
      }
    },
    "tar": {
      "version": "4.4.8",
      "resolved": "https://registry.npmjs.org/tar/-/tar-4.4.8.tgz",
      "integrity": "sha512-LzHF64s5chPQQS0IYBn9IN5h3i98c12bo4NCO7e0sGM2llXQ3p2FGC5sdENN4cTW48O915Sh+x+EXx7XW96xYQ==",
      "dev": true,
      "optional": true,
      "requires": {
        "chownr": "^1.1.1",
        "fs-minipass": "^1.2.5",
        "minipass": "^2.3.4",
        "minizlib": "^1.1.1",
        "mkdirp": "^0.5.0",
        "safe-buffer": "^5.1.2",
        "yallist": "^3.0.2"
      },
      "dependencies": {
        "yallist": {
          "version": "3.0.3",
          "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.0.3.tgz",
          "integrity": "sha512-S+Zk8DEWE6oKpV+vI3qWkaK+jSbIK86pCwe2IF/xwIpQ8jEuxpw9NyaGjmp9+BoJv5FV2piqCDcoCtStppiq2A==",
          "dev": true,
          "optional": true
        }
      }
    },
    "terser": {
      "version": "3.14.1",
      "resolved": "https://registry.npmjs.org/terser/-/terser-3.14.1.tgz",
      "integrity": "sha512-NSo3E99QDbYSMeJaEk9YW2lTg3qS9V0aKGlb+PlOrei1X02r1wSBHCNX/O+yeTRFSWPKPIGj6MqvvdqV4rnVGw==",
      "dev": true,
      "requires": {
        "commander": "~2.17.1",
        "source-map": "~0.6.1",
        "source-map-support": "~0.5.6"
      },
      "dependencies": {
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true
        },
        "source-map-support": {
          "version": "0.5.10",
          "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.10.tgz",
          "integrity": "sha512-YfQ3tQFTK/yzlGJuX8pTwa4tifQj4QS2Mj7UegOu8jAz59MqIiMGPXxQhVQiIMNzayuUSF/jEuVnfFF5JqybmQ==",
          "dev": true,
          "requires": {
            "buffer-from": "^1.0.0",
            "source-map": "^0.6.0"
          }
        }
      }
    },
    "test-exclude": {
      "version": "5.2.2",
      "resolved": "https://registry.npmjs.org/test-exclude/-/test-exclude-5.2.2.tgz",
      "integrity": "sha512-N2pvaLpT8guUpb5Fe1GJlmvmzH3x+DAKmmyEQmFP792QcLYoGE1syxztSvPD1V8yPe6VrcCt6YGQVjSRjCASsA==",
      "dev": true,
      "requires": {
        "glob": "^7.1.3",
        "minimatch": "^3.0.4",
        "read-pkg-up": "^4.0.0",
        "require-main-filename": "^2.0.0"
      },
      "dependencies": {
        "require-main-filename": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/require-main-filename/-/require-main-filename-2.0.0.tgz",
          "integrity": "sha512-NKN5kMDylKuldxYLSUfrbo5Tuzh4hd+2E8NPPX02mZtn1VuREQToYe/ZdlJy+J3uCpfaiGF05e7B8W0iXbQHmg==",
          "dev": true
        }
      }
    },
    "text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha1-f17oI66AUgfACvLfSoTsP8+lcLQ=",
      "dev": true
    },
    "throat": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/throat/-/throat-4.1.0.tgz",
      "integrity": "sha1-iQN8vJLFarGJJua6TLsgDhVnKmo=",
      "dev": true
    },
    "through": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/through/-/through-2.3.8.tgz",
      "integrity": "sha1-DdTJ/6q8NXlgsbckEV1+Doai4fU=",
      "dev": true
    },
    "through2": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/through2/-/through2-2.0.5.tgz",
      "integrity": "sha512-/mrRod8xqpA+IHSLyGCQ2s8SPHiCDEeQJSep1jqLYeEUClOFG2Qsh+4FU6G9VeqpZnGW/Su8LQGc4YKni5rYSQ==",
      "dev": true,
      "requires": {
        "readable-stream": "~2.3.6",
        "xtend": "~4.0.1"
      }
    },
    "through2-filter": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/through2-filter/-/through2-filter-3.0.0.tgz",
      "integrity": "sha512-jaRjI2WxN3W1V8/FMZ9HKIBXixtiqs3SQSX4/YGIiP3gL6djW48VoZq9tDqeCWs3MT8YY5wb/zli8VW8snY1CA==",
      "dev": true,
      "requires": {
        "through2": "~2.0.0",
        "xtend": "~4.0.0"
      }
    },
    "timers-browserify": {
      "version": "1.4.2",
      "resolved": "https://registry.npmjs.org/timers-browserify/-/timers-browserify-1.4.2.tgz",
      "integrity": "sha1-ycWLV1voQHN1y14kYtrO50NZ9B0=",
      "dev": true,
      "requires": {
        "process": "~0.11.0"
      }
    },
    "tiny-lr": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/tiny-lr/-/tiny-lr-1.1.1.tgz",
      "integrity": "sha512-44yhA3tsaRoMOjQQ+5v5mVdqef+kH6Qze9jTpqtVufgYjYt08zyZAwNwwVBj3i1rJMnR52IxOW0LK0vBzgAkuA==",
      "dev": true,
      "requires": {
        "body": "^5.1.0",
        "debug": "^3.1.0",
        "faye-websocket": "~0.10.0",
        "livereload-js": "^2.3.0",
        "object-assign": "^4.1.0",
        "qs": "^6.4.0"
      },
      "dependencies": {
        "debug": {
          "version": "3.2.6",
          "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.6.tgz",
          "integrity": "sha512-mel+jf7nrtEl5Pn1Qx46zARXKDpBbvzezse7p7LqINmdoIk8PYP5SySaxEmYv6TZ0JyEKA1hsCId6DIhgITtWQ==",
          "dev": true,
          "requires": {
            "ms": "^2.1.1"
          }
        },
        "ms": {
          "version": "2.1.1",
          "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.1.tgz",
          "integrity": "sha512-tgp+dl5cGk28utYktBsrFqA7HKgrhgPsg6Z/EfhWI4gl1Hwq8B/GmY/0oXZ6nF8hDVesS/FpnYaD/kOWhYQvyg==",
          "dev": true
        }
      }
    },
    "tmp": {
      "version": "0.0.33",
      "resolved": "https://registry.npmjs.org/tmp/-/tmp-0.0.33.tgz",
      "integrity": "sha512-jRCJlojKnZ3addtTOjdIqoRuPEKBvNXcGYqzO6zWZX8KfKEpnGY5jfggJQ3EjKuu8D4bJRr0y+cYJFmYbImXGw==",
      "dev": true,
      "requires": {
        "os-tmpdir": "~1.0.2"
      }
    },
    "tmpl": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/tmpl/-/tmpl-1.0.4.tgz",
      "integrity": "sha1-I2QN17QtAEM5ERQIIOXPRA5SHdE=",
      "dev": true
    },
    "to-absolute-glob": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/to-absolute-glob/-/to-absolute-glob-2.0.2.tgz",
      "integrity": "sha1-GGX0PZ50sIItufFFt4z/fQ98hJs=",
      "dev": true,
      "requires": {
        "is-absolute": "^1.0.0",
        "is-negated-glob": "^1.0.0"
      }
    },
    "to-arraybuffer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/to-arraybuffer/-/to-arraybuffer-1.0.1.tgz",
      "integrity": "sha1-fSKbH8xjfkZsoIEYCDanqr/4P0M=",
      "dev": true
    },
    "to-object-path": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/to-object-path/-/to-object-path-0.3.0.tgz",
      "integrity": "sha1-KXWIt7Dn4KwI4E5nL4XB9JmeF68=",
      "dev": true,
      "requires": {
        "kind-of": "^3.0.2"
      }
    },
    "to-regex": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/to-regex/-/to-regex-3.0.2.tgz",
      "integrity": "sha512-FWtleNAtZ/Ki2qtqej2CXTOayOH9bHDQF+Q48VpWyDXjbYxA4Yz8iDB31zXOBUlOHHKidDbqGVrTUvQMPmBGBw==",
      "dev": true,
      "requires": {
        "define-property": "^2.0.2",
        "extend-shallow": "^3.0.2",
        "regex-not": "^1.0.2",
        "safe-regex": "^1.1.0"
      }
    },
    "to-regex-range": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-2.1.1.tgz",
      "integrity": "sha1-fIDBe53+vlmeJzZ+DU3VWQFB2zg=",
      "dev": true,
      "requires": {
        "is-number": "^3.0.0",
        "repeat-string": "^1.6.1"
      },
      "dependencies": {
        "is-number": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/is-number/-/is-number-3.0.0.tgz",
          "integrity": "sha1-JP1iAaR4LPUFYcgQJ2r8fRLXEZU=",
          "dev": true,
          "requires": {
            "kind-of": "^3.0.2"
          }
        }
      }
    },
    "to-through": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/to-through/-/to-through-2.0.0.tgz",
      "integrity": "sha1-/JKtq6ByZHvAtn1rA2ZKoZUJOvY=",
      "dev": true,
      "requires": {
        "through2": "^2.0.3"
      }
    },
    "toidentifier": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.0.tgz",
      "integrity": "sha512-yaOH/Pk/VEhBWWTlhI+qXxDFXlejDGcQipMlyxda9nthulaxLZUNcUqFxokp0vcYnvteJln5FNQDRrxj3YcbVw=="
    },
    "tough-cookie": {
      "version": "2.5.0",
      "resolved": "https://registry.npmjs.org/tough-cookie/-/tough-cookie-2.5.0.tgz",
      "integrity": "sha512-nlLsUzgm1kfLXSXfRZMc1KLAugd4hqJHDTvc2hDIwS3mZAfMEuMbc03SujMF+GEcpaX/qboeycw6iO8JwVv2+g==",
      "dev": true,
      "requires": {
        "psl": "^1.1.28",
        "punycode": "^2.1.1"
      }
    },
    "tr46": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-1.0.1.tgz",
      "integrity": "sha1-qLE/1r/SSJUZZ0zN5VujaTtwbQk=",
      "dev": true,
      "requires": {
        "punycode": "^2.1.0"
      }
    },
    "trim": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/trim/-/trim-0.0.1.tgz",
      "integrity": "sha1-WFhUf2spB1fulczMZm+1AITEYN0=",
      "dev": true
    },
    "trim-lines": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/trim-lines/-/trim-lines-1.1.1.tgz",
      "integrity": "sha512-X+eloHbgJGxczUk1WSjIvn7aC9oN3jVE3rQfRVKcgpavi3jxtCn0VVKtjOBj64Yop96UYn/ujJRpTbCdAF1vyg==",
      "dev": true
    },
    "trim-right": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/trim-right/-/trim-right-1.0.1.tgz",
      "integrity": "sha1-yy4SAwZ+DI3h9hQJS5/kVwTqYAM=",
      "dev": true
    },
    "trim-trailing-lines": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/trim-trailing-lines/-/trim-trailing-lines-1.1.1.tgz",
      "integrity": "sha512-bWLv9BbWbbd7mlqqs2oQYnLD/U/ZqeJeJwbO0FG2zA1aTq+HTvxfHNKFa/HGCVyJpDiioUYaBhfiT6rgk+l4mg==",
      "dev": true
    },
    "trough": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/trough/-/trough-1.0.3.tgz",
      "integrity": "sha512-fwkLWH+DimvA4YCy+/nvJd61nWQQ2liO/nF/RjkTpiOGi+zxZzVkhb1mvbHIIW4b/8nDsYI8uTmAlc0nNkRMOw==",
      "dev": true
    },
    "tslib": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-1.9.3.tgz",
      "integrity": "sha512-4krF8scpejhaOgqzBEcGM7yDIEfi0/8+8zDRZhNZZ2kjmHJ4hv3zCbQWxoJGz1iw5U0Jl0nma13xzHXcncMavQ==",
      "dev": true
    },
    "tty-browserify": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/tty-browserify/-/tty-browserify-0.0.1.tgz",
      "integrity": "sha512-C3TaO7K81YvjCgQH9Q1S3R3P3BtN3RIM8n+OvX4il1K1zgE8ZhI0op7kClgkxtutIE8hQrcrHBXvIheqKUUCxw==",
      "dev": true
    },
    "tunnel-agent": {
      "version": "0.6.0",
      "resolved": "https://registry.npmjs.org/tunnel-agent/-/tunnel-agent-0.6.0.tgz",
      "integrity": "sha1-J6XeoGs2sEoKmWZ3SykIaPD8QP0=",
      "dev": true,
      "requires": {
        "safe-buffer": "^5.0.1"
      }
    },
    "tweetnacl": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/tweetnacl/-/tweetnacl-1.0.0.tgz",
      "integrity": "sha1-cT2LgY2kIGh0C/aDhtBHnmb8ins="
    },
    "type-check": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.3.2.tgz",
      "integrity": "sha1-WITKtRLPHTVeP7eE8wgEsrUg23I=",
      "dev": true,
      "requires": {
        "prelude-ls": "~1.1.2"
      }
    },
    "typedarray": {
      "version": "0.0.6",
      "resolved": "https://registry.npmjs.org/typedarray/-/typedarray-0.0.6.tgz",
      "integrity": "sha1-hnrHTjhkGHsdPUfZlqeOxciDB3c=",
      "dev": true
    },
    "u3": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/u3/-/u3-0.1.0.tgz",
      "integrity": "sha1-AGCSdmO2g1PFOc2pnpUR1mh+3Z0="
    },
    "uglify-js": {
      "version": "3.5.9",
      "resolved": "https://registry.npmjs.org/uglify-js/-/uglify-js-3.5.9.tgz",
      "integrity": "sha512-WpT0RqsDtAWPNJK955DEnb6xjymR8Fn0OlK4TT4pS0ASYsVPqr5ELhgwOwLCP5J5vHeJ4xmMmz3DEgdqC10JeQ==",
      "dev": true,
      "optional": true,
      "requires": {
        "commander": "~2.20.0",
        "source-map": "~0.6.1"
      },
      "dependencies": {
        "commander": {
          "version": "2.20.0",
          "resolved": "https://registry.npmjs.org/commander/-/commander-2.20.0.tgz",
          "integrity": "sha512-7j2y+40w61zy6YC2iRNpUe/NwhNyoXrYpHMrSunaMG64nRnaf96zO/KMQR4OyN/UnE5KLyEBnKHd4aG3rskjpQ==",
          "dev": true,
          "optional": true
        },
        "source-map": {
          "version": "0.6.1",
          "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
          "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
          "dev": true,
          "optional": true
        }
      }
    },
    "uglifyify": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/uglifyify/-/uglifyify-5.0.1.tgz",
      "integrity": "sha512-PO44rgExvwj3rkK0UzenHVnPU18drBy9x9HOUmgkuRh6K2KIsDqrB5LqxGtjybgGTOS1JeP8SBc+TN5rhiva6w==",
      "dev": true,
      "requires": {
        "convert-source-map": "~1.1.0",
        "extend": "^1.2.1",
        "minimatch": "^3.0.2",
        "terser": "^3.7.5",
        "through": "~2.3.4"
      },
      "dependencies": {
        "convert-source-map": {
          "version": "1.1.3",
          "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-1.1.3.tgz",
          "integrity": "sha1-SCnId+n+SbMWHzvzZziI4gRpmGA=",
          "dev": true
        },
        "extend": {
          "version": "1.3.0",
          "resolved": "https://registry.npmjs.org/extend/-/extend-1.3.0.tgz",
          "integrity": "sha1-0VFvsP9WJNLr+RI+odrFoZlABPg=",
          "dev": true
        }
      }
    },
    "umd": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/umd/-/umd-3.0.3.tgz",
      "integrity": "sha512-4IcGSufhFshvLNcMCV80UnQVlZ5pMOC8mvNPForqwA4+lzYQuetTESLDQkeLmihq8bRcnpbQa48Wb8Lh16/xow==",
      "dev": true
    },
    "unc-path-regex": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/unc-path-regex/-/unc-path-regex-0.1.2.tgz",
      "integrity": "sha1-5z3T17DXxe2G+6xrCufYxqadUPo=",
      "dev": true
    },
    "undeclared-identifiers": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/undeclared-identifiers/-/undeclared-identifiers-1.1.2.tgz",
      "integrity": "sha512-13EaeocO4edF/3JKime9rD7oB6QI8llAGhgn5fKOPyfkJbRb6NFv9pYV6dFEmpa4uRjKeBqLZP8GpuzqHlKDMQ==",
      "dev": true,
      "requires": {
        "acorn-node": "^1.3.0",
        "get-assigned-identifiers": "^1.2.0",
        "simple-concat": "^1.0.0",
        "xtend": "^4.0.1"
      }
    },
    "unherit": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/unherit/-/unherit-1.1.1.tgz",
      "integrity": "sha512-+XZuV691Cn4zHsK0vkKYwBEwB74T3IZIcxrgn2E4rKwTfFyI1zCh7X7grwh9Re08fdPlarIdyWgI8aVB3F5A5g==",
      "dev": true,
      "requires": {
        "inherits": "^2.0.1",
        "xtend": "^4.0.1"
      }
    },
    "unicode-canonical-property-names-ecmascript": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/unicode-canonical-property-names-ecmascript/-/unicode-canonical-property-names-ecmascript-1.0.4.tgz",
      "integrity": "sha512-jDrNnXWHd4oHiTZnx/ZG7gtUTVp+gCcTTKr8L0HjlwphROEW3+Him+IpvC+xcJEFegapiMZyZe02CyuOnRmbnQ==",
      "dev": true
    },
    "unicode-match-property-ecmascript": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/unicode-match-property-ecmascript/-/unicode-match-property-ecmascript-1.0.4.tgz",
      "integrity": "sha512-L4Qoh15vTfntsn4P1zqnHulG0LdXgjSO035fEpdtp6YxXhMT51Q6vgM5lYdG/5X3MjS+k/Y9Xw4SFCY9IkR0rg==",
      "dev": true,
      "requires": {
        "unicode-canonical-property-names-ecmascript": "^1.0.4",
        "unicode-property-aliases-ecmascript": "^1.0.4"
      }
    },
    "unicode-match-property-value-ecmascript": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/unicode-match-property-value-ecmascript/-/unicode-match-property-value-ecmascript-1.0.2.tgz",
      "integrity": "sha512-Rx7yODZC1L/T8XKo/2kNzVAQaRE88AaMvI1EF/Xnj3GW2wzN6fop9DDWuFAKUVFH7vozkz26DzP0qyWLKLIVPQ==",
      "dev": true
    },
    "unicode-property-aliases-ecmascript": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/unicode-property-aliases-ecmascript/-/unicode-property-aliases-ecmascript-1.0.4.tgz",
      "integrity": "sha512-2WSLa6OdYd2ng8oqiGIWnJqyFArvhn+5vgx5GTxMbUYjCYKUcuKS62YLFF0R/BDGlB1yzXjQOLtPAfHsgirEpg==",
      "dev": true
    },
    "unified": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/unified/-/unified-6.2.0.tgz",
      "integrity": "sha512-1k+KPhlVtqmG99RaTbAv/usu85fcSRu3wY8X+vnsEhIxNP5VbVIDiXnLqyKIG+UMdyTg0ZX9EI6k2AfjJkHPtA==",
      "dev": true,
      "requires": {
        "bail": "^1.0.0",
        "extend": "^3.0.0",
        "is-plain-obj": "^1.1.0",
        "trough": "^1.0.0",
        "vfile": "^2.0.0",
        "x-is-string": "^0.1.0"
      },
      "dependencies": {
        "vfile": {
          "version": "2.3.0",
          "resolved": "https://registry.npmjs.org/vfile/-/vfile-2.3.0.tgz",
          "integrity": "sha512-ASt4mBUHcTpMKD/l5Q+WJXNtshlWxOogYyGYYrg4lt/vuRjC1EFQtlAofL5VmtVNIZJzWYFJjzGWZ0Gw8pzW1w==",
          "dev": true,
          "requires": {
            "is-buffer": "^1.1.4",
            "replace-ext": "1.0.0",
            "unist-util-stringify-position": "^1.0.0",
            "vfile-message": "^1.0.0"
          }
        }
      }
    },
    "union-value": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/union-value/-/union-value-1.0.0.tgz",
      "integrity": "sha1-XHHDTLW61dzr4+oM0IIHulqhrqQ=",
      "dev": true,
      "requires": {
        "arr-union": "^3.1.0",
        "get-value": "^2.0.6",
        "is-extendable": "^0.1.1",
        "set-value": "^0.4.3"
      },
      "dependencies": {
        "extend-shallow": {
          "version": "2.0.1",
          "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
          "integrity": "sha1-Ua99YUrZqfYQ6huvu5idaxxWiQ8=",
          "dev": true,
          "requires": {
            "is-extendable": "^0.1.0"
          }
        },
        "set-value": {
          "version": "0.4.3",
          "resolved": "https://registry.npmjs.org/set-value/-/set-value-0.4.3.tgz",
          "integrity": "sha1-fbCPnT0i3H945Trzw79GZuzfzPE=",
          "dev": true,
          "requires": {
            "extend-shallow": "^2.0.1",
            "is-extendable": "^0.1.1",
            "is-plain-object": "^2.0.1",
            "to-object-path": "^0.3.0"
          }
        }
      }
    },
    "unique-stream": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/unique-stream/-/unique-stream-2.3.1.tgz",
      "integrity": "sha512-2nY4TnBE70yoxHkDli7DMazpWiP7xMdCYqU2nBRO0UB+ZpEkGsSija7MvmvnZFUeC+mrgiUfcHSr3LmRFIg4+A==",
      "dev": true,
      "requires": {
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "through2-filter": "^3.0.0"
      }
    },
    "unist-builder": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/unist-builder/-/unist-builder-1.0.3.tgz",
      "integrity": "sha512-/KB8GEaoeHRyIqClL+Kam+Y5NWJ6yEiPsAfv1M+O1p+aKGgjR89WwoEHKTyOj17L6kAlqtKpAgv2nWvdbQDEig==",
      "dev": true,
      "requires": {
        "object-assign": "^4.1.0"
      }
    },
    "unist-util-generated": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/unist-util-generated/-/unist-util-generated-1.1.3.tgz",
      "integrity": "sha512-qlPeDqnQnd84KIqwphzOR+l02cxjDzvEYEBl84EjmKRrX4eUmjyAo8xJv1SCDhJqNjyHRnBMZWNKAiBtXE6hBg==",
      "dev": true
    },
    "unist-util-is": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/unist-util-is/-/unist-util-is-2.1.2.tgz",
      "integrity": "sha512-YkXBK/H9raAmG7KXck+UUpnKiNmUdB+aBGrknfQ4EreE1banuzrKABx3jP6Z5Z3fMSPMQQmeXBlKpCbMwBkxVw==",
      "dev": true
    },
    "unist-util-position": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/unist-util-position/-/unist-util-position-3.0.2.tgz",
      "integrity": "sha512-npmFu92l/+b1Ao6uGP4I1WFz9hsKv7qleZ4aliw6x0RVu6A9A3tAf57NMpFfzQ02jxRtJZuRn+C8xWT7GWnH0g==",
      "dev": true
    },
    "unist-util-remove-position": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/unist-util-remove-position/-/unist-util-remove-position-1.1.2.tgz",
      "integrity": "sha512-XxoNOBvq1WXRKXxgnSYbtCF76TJrRoe5++pD4cCBsssSiWSnPEktyFrFLE8LTk3JW5mt9hB0Sk5zn4x/JeWY7Q==",
      "dev": true,
      "requires": {
        "unist-util-visit": "^1.1.0"
      }
    },
    "unist-util-stringify-position": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/unist-util-stringify-position/-/unist-util-stringify-position-1.1.2.tgz",
      "integrity": "sha512-pNCVrk64LZv1kElr0N1wPiHEUoXNVFERp+mlTg/s9R5Lwg87f9bM/3sQB99w+N9D/qnM9ar3+AKDBwo/gm/iQQ==",
      "dev": true
    },
    "unist-util-visit": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/unist-util-visit/-/unist-util-visit-1.4.0.tgz",
      "integrity": "sha512-FiGu34ziNsZA3ZUteZxSFaczIjGmksfSgdKqBfOejrrfzyUy5b7YrlzT1Bcvi+djkYDituJDy2XB7tGTeBieKw==",
      "dev": true,
      "requires": {
        "unist-util-visit-parents": "^2.0.0"
      }
    },
    "unist-util-visit-parents": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/unist-util-visit-parents/-/unist-util-visit-parents-2.0.1.tgz",
      "integrity": "sha512-6B0UTiMfdWql4cQ03gDTCSns+64Zkfo2OCbK31Ov0uMizEz+CJeAp0cgZVb5Fhmcd7Bct2iRNywejT0orpbqUA==",
      "dev": true,
      "requires": {
        "unist-util-is": "^2.1.2"
      }
    },
    "unset-value": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/unset-value/-/unset-value-1.0.0.tgz",
      "integrity": "sha1-g3aHP30jNRef+x5vw6jtDfyKtVk=",
      "dev": true,
      "requires": {
        "has-value": "^0.3.1",
        "isobject": "^3.0.0"
      },
      "dependencies": {
        "has-value": {
          "version": "0.3.1",
          "resolved": "https://registry.npmjs.org/has-value/-/has-value-0.3.1.tgz",
          "integrity": "sha1-ex9YutpiyoJ+wKIHgCVlSEWZXh8=",
          "dev": true,
          "requires": {
            "get-value": "^2.0.3",
            "has-values": "^0.1.4",
            "isobject": "^2.0.0"
          },
          "dependencies": {
            "isobject": {
              "version": "2.1.0",
              "resolved": "https://registry.npmjs.org/isobject/-/isobject-2.1.0.tgz",
              "integrity": "sha1-8GVWEJaj8dou9GJy+BXIQNh+DIk=",
              "dev": true,
              "requires": {
                "isarray": "1.0.0"
              }
            }
          }
        },
        "has-values": {
          "version": "0.1.4",
          "resolved": "https://registry.npmjs.org/has-values/-/has-values-0.1.4.tgz",
          "integrity": "sha1-bWHeldkd/Km5oCCJrThL/49it3E=",
          "dev": true
        },
        "isobject": {
          "version": "3.0.1",
          "resolved": "https://registry.npmjs.org/isobject/-/isobject-3.0.1.tgz",
          "integrity": "sha1-TkMekrEalzFjaqH5yNHMvP2reN8=",
          "dev": true
        }
      }
    },
    "upath": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/upath/-/upath-1.1.0.tgz",
      "integrity": "sha512-bzpH/oBhoS/QI/YtbkqCg6VEiPYjSZtrHQM6/QnJS6OL9pKUFLqb3aFh4Scvwm45+7iAgiMkLhSbaZxUqmrprw==",
      "dev": true
    },
    "uri-js": {
      "version": "4.2.2",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.2.2.tgz",
      "integrity": "sha512-KY9Frmirql91X2Qgjry0Wd4Y+YTdrdZheS8TFwvkbLWf/G5KNJDCh6pKL5OZctEW4+0Baa5idK2ZQuELRwPznQ==",
      "dev": true,
      "requires": {
        "punycode": "^2.1.0"
      }
    },
    "urix": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/urix/-/urix-0.1.0.tgz",
      "integrity": "sha1-2pN/emLiH+wf0Y1Js1wpNQZ6bHI=",
      "dev": true
    },
    "url": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/url/-/url-0.11.0.tgz",
      "integrity": "sha1-ODjpfPxgUh63PFJajlW/3Z4uKPE=",
      "dev": true,
      "requires": {
        "punycode": "1.3.2",
        "querystring": "0.2.0"
      },
      "dependencies": {
        "punycode": {
          "version": "1.3.2",
          "resolved": "https://registry.npmjs.org/punycode/-/punycode-1.3.2.tgz",
          "integrity": "sha1-llOgNvt8HuQjQvIyXM7v6jkmxI0=",
          "dev": true
        }
      }
    },
    "use": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/use/-/use-3.1.1.tgz",
      "integrity": "sha512-cwESVXlO3url9YWlFW/TA9cshCEhtu7IKJ/p5soJ/gGpj7vbvFrAY/eIioQ6Dw23KjZhYgiIo8HOs1nQ2vr/oQ==",
      "dev": true
    },
    "util": {
      "version": "0.10.4",
      "resolved": "https://registry.npmjs.org/util/-/util-0.10.4.tgz",
      "integrity": "sha512-0Pm9hTQ3se5ll1XihRic3FDIku70C+iHUdT/W926rSgHV5QgXsYbKZN8MSC3tJtSkhuROzvsQjAaFENRXr+19A==",
      "dev": true,
      "requires": {
        "inherits": "2.0.3"
      }
    },
    "util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha1-RQ1Nyfpw3nMnYvvS1KKJgUGaDM8=",
      "dev": true
    },
    "util.promisify": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/util.promisify/-/util.promisify-1.0.0.tgz",
      "integrity": "sha512-i+6qA2MPhvoKLuxnJNpXAGhg7HphQOSUq2LKMZD0m15EiskXUkMvKdF4Uui0WYeCUGea+o2cw/ZuwehtfsrNkA==",
      "dev": true,
      "requires": {
        "define-properties": "^1.1.2",
        "object.getownpropertydescriptors": "^2.0.3"
      }
    },
    "uuid": {
      "version": "3.3.2",
      "resolved": "https://registry.npmjs.org/uuid/-/uuid-3.3.2.tgz",
      "integrity": "sha512-yXJmeNaw3DnnKAOKJE51sL/ZaYfWJRl1pK9dr19YFCu0ObS231AB1/LbqTKRAQ5kw8A90rA6fr4riOUpTZvQZA==",
      "dev": true
    },
    "validate-npm-package-license": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/validate-npm-package-license/-/validate-npm-package-license-3.0.4.tgz",
      "integrity": "sha512-DpKm2Ui/xN7/HQKCtpZxoRWBhZ9Z0kqtygG8XCgNQ8ZlDnxuQmWhj566j8fN4Cu3/JmbhsDo7fcAJq4s9h27Ew==",
      "dev": true,
      "requires": {
        "spdx-correct": "^3.0.0",
        "spdx-expression-parse": "^3.0.0"
      }
    },
    "value-or-function": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/value-or-function/-/value-or-function-3.0.0.tgz",
      "integrity": "sha1-HCQ6ULWVwb5Up1S/7OhWO5/42BM=",
      "dev": true
    },
    "verror": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/verror/-/verror-1.10.0.tgz",
      "integrity": "sha1-OhBcoXBTr1XW4nDB+CiGguGNpAA=",
      "dev": true,
      "requires": {
        "assert-plus": "^1.0.0",
        "core-util-is": "1.0.2",
        "extsprintf": "^1.2.0"
      }
    },
    "vfile": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/vfile/-/vfile-3.0.1.tgz",
      "integrity": "sha512-y7Y3gH9BsUSdD4KzHsuMaCzRjglXN0W2EcMf0gpvu6+SbsGhMje7xDc8AEoeXy6mIwCKMI6BkjMsRjzQbhMEjQ==",
      "dev": true,
      "requires": {
        "is-buffer": "^2.0.0",
        "replace-ext": "1.0.0",
        "unist-util-stringify-position": "^1.0.0",
        "vfile-message": "^1.0.0"
      },
      "dependencies": {
        "is-buffer": {
          "version": "2.0.3",
          "resolved": "https://registry.npmjs.org/is-buffer/-/is-buffer-2.0.3.tgz",
          "integrity": "sha512-U15Q7MXTuZlrbymiz95PJpZxu8IlipAp4dtS3wOdgPXx3mqBnslrWU14kxfHB+Py/+2PVKSr37dMAgM2A4uArw==",
          "dev": true
        }
      }
    },
    "vfile-location": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/vfile-location/-/vfile-location-2.0.4.tgz",
      "integrity": "sha512-KRL5uXQPoUKu+NGvQVL4XLORw45W62v4U4gxJ3vRlDfI9QsT4ZN1PNXn/zQpKUulqGDpYuT0XDfp5q9O87/y/w==",
      "dev": true
    },
    "vfile-message": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/vfile-message/-/vfile-message-1.1.1.tgz",
      "integrity": "sha512-1WmsopSGhWt5laNir+633LszXvZ+Z/lxveBf6yhGsqnQIhlhzooZae7zV6YVM1Sdkw68dtAW3ow0pOdPANugvA==",
      "dev": true,
      "requires": {
        "unist-util-stringify-position": "^1.1.1"
      }
    },
    "vfile-reporter": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/vfile-reporter/-/vfile-reporter-5.1.1.tgz",
      "integrity": "sha512-A/cfKvfVmeEmAKx1yyOWggCjC/k184Vkl5pVJAw5CEdppHd5FHBVcdyJ1JBSqIdJjJqyhZY4ZD3JycHr/uwmlA==",
      "dev": true,
      "requires": {
        "repeat-string": "^1.5.0",
        "string-width": "^2.0.0",
        "supports-color": "^5.4.0",
        "unist-util-stringify-position": "^1.0.0",
        "vfile-sort": "^2.1.2",
        "vfile-statistics": "^1.1.0"
      }
    },
    "vfile-sort": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/vfile-sort/-/vfile-sort-2.2.0.tgz",
      "integrity": "sha512-RgxLXVWrJBWb2GuP8FsSkqK7HmbjXjnI8qx3nD6NTWhsWaelaKvJuxfh1F1d1lkCPD7imo4zzi8cf6IOMgaTnQ==",
      "dev": true
    },
    "vfile-statistics": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/vfile-statistics/-/vfile-statistics-1.1.2.tgz",
      "integrity": "sha512-16wAC9eEGXdsD35LX9m/iXCRIZyX5LIrDgDtAF92rbATSqsBRbC4n05e0Rj5vt3XRpcKu0UJeWnTxWsSyvNZ+w==",
      "dev": true
    },
    "vinyl": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/vinyl/-/vinyl-2.2.0.tgz",
      "integrity": "sha512-MBH+yP0kC/GQ5GwBqrTPTzEfiiLjta7hTtvQtbxBgTeSXsmKQRQecjibMbxIXzVT3Y9KJK+drOz1/k+vsu8Nkg==",
      "dev": true,
      "requires": {
        "clone": "^2.1.1",
        "clone-buffer": "^1.0.0",
        "clone-stats": "^1.0.0",
        "cloneable-readable": "^1.0.0",
        "remove-trailing-separator": "^1.0.1",
        "replace-ext": "^1.0.0"
      }
    },
    "vinyl-fs": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/vinyl-fs/-/vinyl-fs-3.0.3.tgz",
      "integrity": "sha512-vIu34EkyNyJxmP0jscNzWBSygh7VWhqun6RmqVfXePrOwi9lhvRs//dOaGOTRUQr4tx7/zd26Tk5WeSVZitgng==",
      "dev": true,
      "requires": {
        "fs-mkdirp-stream": "^1.0.0",
        "glob-stream": "^6.1.0",
        "graceful-fs": "^4.0.0",
        "is-valid-glob": "^1.0.0",
        "lazystream": "^1.0.0",
        "lead": "^1.0.0",
        "object.assign": "^4.0.4",
        "pumpify": "^1.3.5",
        "readable-stream": "^2.3.3",
        "remove-bom-buffer": "^3.0.0",
        "remove-bom-stream": "^1.2.0",
        "resolve-options": "^1.1.0",
        "through2": "^2.0.0",
        "to-through": "^2.0.0",
        "value-or-function": "^3.0.0",
        "vinyl": "^2.0.0",
        "vinyl-sourcemap": "^1.1.0"
      }
    },
    "vinyl-sourcemap": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/vinyl-sourcemap/-/vinyl-sourcemap-1.1.0.tgz",
      "integrity": "sha1-kqgAWTo4cDqM2xHYswCtS+Y7PhY=",
      "dev": true,
      "requires": {
        "append-buffer": "^1.0.2",
        "convert-source-map": "^1.5.0",
        "graceful-fs": "^4.1.6",
        "normalize-path": "^2.1.1",
        "now-and-later": "^2.0.0",
        "remove-bom-buffer": "^3.0.0",
        "vinyl": "^2.0.0"
      }
    },
    "vm-browserify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/vm-browserify/-/vm-browserify-1.1.0.tgz",
      "integrity": "sha512-iq+S7vZJE60yejDYM0ek6zg308+UZsdtPExWP9VZoCFCz1zkJoXFnAX7aZfd/ZwrkidzdUZL0C/ryW+JwAiIGw==",
      "dev": true
    },
    "vue-template-compiler": {
      "version": "2.5.22",
      "resolved": "https://registry.npmjs.org/vue-template-compiler/-/vue-template-compiler-2.5.22.tgz",
      "integrity": "sha512-1VTw/NPTUeHNiwhkq6NkFzO7gYLjFCueBN0FX8NEiQIemd5EUMQ5hxrF7O0zCPo5tae+U9S/scETPea+hIz8Eg==",
      "dev": true,
      "requires": {
        "de-indent": "^1.0.2",
        "he": "^1.1.0"
      }
    },
    "w3c-hr-time": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/w3c-hr-time/-/w3c-hr-time-1.0.1.tgz",
      "integrity": "sha1-gqwr/2PZUOqeMYmlimViX+3xkEU=",
      "dev": true,
      "requires": {
        "browser-process-hrtime": "^0.1.2"
      }
    },
    "walker": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/walker/-/walker-1.0.7.tgz",
      "integrity": "sha1-L3+bj9ENZ3JisYqITijRlhjgKPs=",
      "dev": true,
      "requires": {
        "makeerror": "1.0.x"
      }
    },
    "webidl-conversions": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-4.0.2.tgz",
      "integrity": "sha512-YQ+BmxuTgd6UXZW3+ICGfyqRyHXVlD5GtQr5+qjiNW7bF0cqrzX500HVXPBOvgXb5YnzDd+h0zqyv61KUD7+Sg==",
      "dev": true
    },
    "websocket-driver": {
      "version": "0.7.0",
      "resolved": "https://registry.npmjs.org/websocket-driver/-/websocket-driver-0.7.0.tgz",
      "integrity": "sha1-DK+dLXVdk67gSdS90NP+LMoqJOs=",
      "dev": true,
      "requires": {
        "http-parser-js": ">=0.4.0",
        "websocket-extensions": ">=0.1.1"
      }
    },
    "websocket-extensions": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/websocket-extensions/-/websocket-extensions-0.1.3.tgz",
      "integrity": "sha512-nqHUnMXmBzT0w570r2JpJxfiSD1IzoI+HGVdd3aZ0yNi3ngvQ4jv1dtHt5VGxfI2yj5yqImPhOK4vmIh2xMbGg==",
      "dev": true
    },
    "whatwg-encoding": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/whatwg-encoding/-/whatwg-encoding-1.0.5.tgz",
      "integrity": "sha512-b5lim54JOPN9HtzvK9HFXvBma/rnfFeqsic0hSpjtDbVxR3dJKLc+KB4V6GgiGOvl7CY/KNh8rxSo9DKQrnUEw==",
      "dev": true,
      "requires": {
        "iconv-lite": "0.4.24"
      }
    },
    "whatwg-mimetype": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/whatwg-mimetype/-/whatwg-mimetype-2.3.0.tgz",
      "integrity": "sha512-M4yMwr6mAnQz76TbJm914+gPpB/nCwvZbJU28cUD6dR004SAxDLOOSUaB1JDRqLtaOV/vi0IC5lEAGFgrjGv/g==",
      "dev": true
    },
    "whatwg-url": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-6.5.0.tgz",
      "integrity": "sha512-rhRZRqx/TLJQWUpQ6bmrt2UV4f0HCQ463yQuONJqC6fO2VoEb1pTYddbe59SkYq87aoM5A3bdhMZiUiVws+fzQ==",
      "dev": true,
      "requires": {
        "lodash.sortby": "^4.7.0",
        "tr46": "^1.0.1",
        "webidl-conversions": "^4.0.2"
      }
    },
    "which": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/which/-/which-1.3.1.tgz",
      "integrity": "sha512-HxJdYWq1MTIQbJ3nw0cqssHoTNU267KlrDuGZ1WYlxDStUtKUhOaJmh112/TZmHxxUfuJqPXSOm7tDyas0OSIQ==",
      "dev": true,
      "requires": {
        "isexe": "^2.0.0"
      }
    },
    "which-module": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/which-module/-/which-module-2.0.0.tgz",
      "integrity": "sha1-2e8H3Od7mQK4o6j6SzHD4/fm6Ho=",
      "dev": true
    },
    "wordwrap": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/wordwrap/-/wordwrap-0.0.3.tgz",
      "integrity": "sha1-o9XabNXAvAAI03I0u68b7WMFkQc=",
      "dev": true
    },
    "wrap-ansi": {
      "version": "2.1.0",
      "resolved": "http://registry.npmjs.org/wrap-ansi/-/wrap-ansi-2.1.0.tgz",
      "integrity": "sha1-2Pw9KE3QV5T+hJc8rs3Rz4JP3YU=",
      "dev": true,
      "requires": {
        "string-width": "^1.0.1",
        "strip-ansi": "^3.0.1"
      },
      "dependencies": {
        "is-fullwidth-code-point": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-1.0.0.tgz",
          "integrity": "sha1-754xOG8DGn8NZDr4L95QxFfvAMs=",
          "dev": true,
          "requires": {
            "number-is-nan": "^1.0.0"
          }
        },
        "string-width": {
          "version": "1.0.2",
          "resolved": "http://registry.npmjs.org/string-width/-/string-width-1.0.2.tgz",
          "integrity": "sha1-EYvfW4zcUaKn5w0hHgfisLmxB9M=",
          "dev": true,
          "requires": {
            "code-point-at": "^1.0.0",
            "is-fullwidth-code-point": "^1.0.0",
            "strip-ansi": "^3.0.0"
          }
        },
        "strip-ansi": {
          "version": "3.0.1",
          "resolved": "http://registry.npmjs.org/strip-ansi/-/strip-ansi-3.0.1.tgz",
          "integrity": "sha1-ajhfuIU9lS1f8F0Oiq+UJ43GPc8=",
          "dev": true,
          "requires": {
            "ansi-regex": "^2.0.0"
          }
        }
      }
    },
    "wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha1-tSQ9jz7BqjXxNkYFvA0QNuMKtp8=",
      "dev": true
    },
    "write": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/write/-/write-1.0.3.tgz",
      "integrity": "sha512-/lg70HAjtkUgWPVZhZcm+T4hkL8Zbtp1nFNOn3lRrxnlv50SRBv7cR7RqR+GMsd3hUXy9hWBo4CHTbFTcOYwig==",
      "dev": true,
      "requires": {
        "mkdirp": "^0.5.1"
      }
    },
    "write-file-atomic": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/write-file-atomic/-/write-file-atomic-2.4.1.tgz",
      "integrity": "sha512-TGHFeZEZMnv+gBFRfjAcxL5bPHrsGKtnb4qsFAws7/vlh+QfwAaySIw4AXP9ZskTTh5GWu3FLuJhsWVdiJPGvg==",
      "dev": true,
      "requires": {
        "graceful-fs": "^4.1.11",
        "imurmurhash": "^0.1.4",
        "signal-exit": "^3.0.2"
      }
    },
    "ws": {
      "version": "5.2.2",
      "resolved": "https://registry.npmjs.org/ws/-/ws-5.2.2.tgz",
      "integrity": "sha512-jaHFD6PFv6UgoIVda6qZllptQsMlDEJkTQcybzzXDYM1XO9Y8em691FGMPmM46WGyLU4z9KMgQN+qrux/nhlHA==",
      "dev": true,
      "requires": {
        "async-limiter": "~1.0.0"
      }
    },
    "x-is-string": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/x-is-string/-/x-is-string-0.1.0.tgz",
      "integrity": "sha1-R0tQhlrzpJqcRlfwWs0UVFj3fYI=",
      "dev": true
    },
    "xml-name-validator": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/xml-name-validator/-/xml-name-validator-3.0.0.tgz",
      "integrity": "sha512-A5CUptxDsvxKJEU3yO6DuWBSJz/qizqzJKOMIfUJHETbBw/sFaDxgd6fxm1ewUaM0jZ444Fc5vC5ROYurg/4Pw==",
      "dev": true
    },
    "xtend": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/xtend/-/xtend-4.0.1.tgz",
      "integrity": "sha1-pcbVMr5lbiPbgg77lDofBJmNY68=",
      "dev": true
    },
    "y18n": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/y18n/-/y18n-3.2.1.tgz",
      "integrity": "sha1-bRX7qITAhnnA136I53WegR4H+kE=",
      "dev": true
    },
    "yallist": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-2.1.2.tgz",
      "integrity": "sha1-HBH5IY8HYImkfdUS+TxmmaaoHVI=",
      "dev": true
    },
    "yargs": {
      "version": "12.0.5",
      "resolved": "https://registry.npmjs.org/yargs/-/yargs-12.0.5.tgz",
      "integrity": "sha512-Lhz8TLaYnxq/2ObqHDql8dX8CJi97oHxrjUcYtzKbbykPtVW9WB+poxI+NM2UIzsMgNCZTIf0AQwsjK5yMAqZw==",
      "dev": true,
      "requires": {
        "cliui": "^4.0.0",
        "decamelize": "^1.2.0",
        "find-up": "^3.0.0",
        "get-caller-file": "^1.0.1",
        "os-locale": "^3.0.0",
        "require-directory": "^2.1.1",
        "require-main-filename": "^1.0.1",
        "set-blocking": "^2.0.0",
        "string-width": "^2.0.0",
        "which-module": "^2.0.0",
        "y18n": "^3.2.1 || ^4.0.0",
        "yargs-parser": "^11.1.1"
      },
      "dependencies": {
        "cross-spawn": {
          "version": "6.0.5",
          "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-6.0.5.tgz",
          "integrity": "sha512-eTVLrBSt7fjbDygz805pMnstIs2VTBNkRm0qxZd+M7A5XDdxVRWO5MxGBXZhjY4cqLYLdtrGqRf8mBPmzwSpWQ==",
          "dev": true,
          "requires": {
            "nice-try": "^1.0.4",
            "path-key": "^2.0.1",
            "semver": "^5.5.0",
            "shebang-command": "^1.2.0",
            "which": "^1.2.9"
          }
        },
        "execa": {
          "version": "1.0.0",
          "resolved": "https://registry.npmjs.org/execa/-/execa-1.0.0.tgz",
          "integrity": "sha512-adbxcyWV46qiHyvSp50TKt05tB4tK3HcmF7/nxfAdhnox83seTDbwnaqKO4sXRy7roHAIFqJP/Rw/AuEbX61LA==",
          "dev": true,
          "requires": {
            "cross-spawn": "^6.0.0",
            "get-stream": "^4.0.0",
            "is-stream": "^1.1.0",
            "npm-run-path": "^2.0.0",
            "p-finally": "^1.0.0",
            "signal-exit": "^3.0.0",
            "strip-eof": "^1.0.0"
          }
        },
        "find-up": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/find-up/-/find-up-3.0.0.tgz",
          "integrity": "sha512-1yD6RmLI1XBfxugvORwlck6f75tYL+iR0jqwsOrOxMZyGYqUuDhJ0l4AXdO1iX/FTs9cBAMEk1gWSEx1kSbylg==",
          "dev": true,
          "requires": {
            "locate-path": "^3.0.0"
          }
        },
        "get-stream": {
          "version": "4.1.0",
          "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-4.1.0.tgz",
          "integrity": "sha512-GMat4EJ5161kIy2HevLlr4luNjBgvmj413KaQA7jt4V8B4RDsfpHk7WQ9GVqfYyyx8OS/L66Kox+rJRNklLK7w==",
          "dev": true,
          "requires": {
            "pump": "^3.0.0"
          }
        },
        "invert-kv": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/invert-kv/-/invert-kv-2.0.0.tgz",
          "integrity": "sha512-wPVv/y/QQ/Uiirj/vh3oP+1Ww+AWehmi1g5fFWGPF6IpCBCDVrhgHRMvrLfdYcwDh3QJbGXDW4JAuzxElLSqKA==",
          "dev": true
        },
        "lcid": {
          "version": "2.0.0",
          "resolved": "https://registry.npmjs.org/lcid/-/lcid-2.0.0.tgz",
          "integrity": "sha512-avPEb8P8EGnwXKClwsNUgryVjllcRqtMYa49NTsbQagYuT1DcXnl1915oxWjoyGrXR6zH/Y0Zc96xWsPcoDKeA==",
          "dev": true,
          "requires": {
            "invert-kv": "^2.0.0"
          }
        },
        "locate-path": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-3.0.0.tgz",
          "integrity": "sha512-7AO748wWnIhNqAuaty2ZWHkQHRSNfPVIsPIfwEOWO22AmaoVrWavlOcMR5nzTLNYvp36X220/maaRsrec1G65A==",
          "dev": true,
          "requires": {
            "p-locate": "^3.0.0",
            "path-exists": "^3.0.0"
          }
        },
        "mem": {
          "version": "4.3.0",
          "resolved": "https://registry.npmjs.org/mem/-/mem-4.3.0.tgz",
          "integrity": "sha512-qX2bG48pTqYRVmDB37rn/6PT7LcR8T7oAX3bf99u1Tt1nzxYfxkgqDwUwolPlXweM0XzBOBFzSx4kfp7KP1s/w==",
          "dev": true,
          "requires": {
            "map-age-cleaner": "^0.1.1",
            "mimic-fn": "^2.0.0",
            "p-is-promise": "^2.0.0"
          }
        },
        "mimic-fn": {
          "version": "2.1.0",
          "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
          "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
          "dev": true
        },
        "os-locale": {
          "version": "3.1.0",
          "resolved": "https://registry.npmjs.org/os-locale/-/os-locale-3.1.0.tgz",
          "integrity": "sha512-Z8l3R4wYWM40/52Z+S265okfFj8Kt2cC2MKY+xNi3kFs+XGI7WXu/I309QQQYbRW4ijiZ+yxs9pqEhJh0DqW3Q==",
          "dev": true,
          "requires": {
            "execa": "^1.0.0",
            "lcid": "^2.0.0",
            "mem": "^4.0.0"
          }
        },
        "p-limit": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.2.0.tgz",
          "integrity": "sha512-pZbTJpoUsCzV48Mc9Nh51VbwO0X9cuPFE8gYwx9BTCt9SF8/b7Zljd2fVgOxhIF/HDTKgpVzs+GPhyKfjLLFRQ==",
          "dev": true,
          "requires": {
            "p-try": "^2.0.0"
          }
        },
        "p-locate": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-3.0.0.tgz",
          "integrity": "sha512-x+12w/To+4GFfgJhBEpiDcLozRJGegY+Ei7/z0tSLkMmxGZNybVMSfWj9aJn8Z5Fc7dBUNJOOVgPv2H7IwulSQ==",
          "dev": true,
          "requires": {
            "p-limit": "^2.0.0"
          }
        },
        "p-try": {
          "version": "2.2.0",
          "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
          "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
          "dev": true
        },
        "pump": {
          "version": "3.0.0",
          "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.0.tgz",
          "integrity": "sha512-LwZy+p3SFs1Pytd/jYct4wpv49HiYCqd9Rlc5ZVdk0V+8Yzv6jR5Blk3TRmPL1ft69TxP0IMZGJ+WPFU2BFhww==",
          "dev": true,
          "requires": {
            "end-of-stream": "^1.1.0",
            "once": "^1.3.1"
          }
        }
      }
    },
    "yargs-parser": {
      "version": "11.1.1",
      "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-11.1.1.tgz",
      "integrity": "sha512-C6kB/WJDiaxONLJQnF8ccx9SEeoTTLek8RVbaOIsrAUS8VrBEXfmeSnCZxygc+XC2sNMBIwOOnfcxiynjHsVSQ==",
      "dev": true,
      "requires": {
        "camelcase": "^5.0.0",
        "decamelize": "^1.2.0"
      },
      "dependencies": {
        "camelcase": {
          "version": "5.3.1",
          "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
          "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
          "dev": true
        }
      }
    }
  }
}

'''
'''--- nearlib/package.json ---
{
  "name": "nearlib",
  "description": "Javascript library to interact with near blockchain",
  "version": "0.6.0",
  "repository": {
    "type": "git",
    "url": "git@:nearprotocol/nearcore.git"
  },
  "homepage": "https://github.com/nearprotocol/nearcore",
  "main": "index.js",
  "browser": "browser.js",
  "dependencies": {
    "bs58": "^4.0.1",
    "error-polyfill": "^0.1.2",
    "http-errors": "^1.7.1",
    "js-sha256": "^0.9.0",
    "node-fetch": "^2.3.0",
    "protobufjs": "^6.8.8",
    "tweetnacl": "^1.0.0"
  },
  "devDependencies": {
    "browserify": "^16.2.3",
    "documentation": "^9.1.1",
    "eslint": "^5.14.0",
    "jest": "^24.1.0",
    "uglifyify": "^5.0.1"
  },
  "jest": {
    "coverageDirectory": "./coverage/",
    "collectCoverage": true
  },
  "keywords": [],
  "license": "MIT",
  "scripts": {
    "generate-protos": "../scripts/generate_js_transaction_proto.sh",
    "build": "npm run generate-protos && browserify browser-exports.js -i node-fetch -o dist/nearlib.js && browserify browser-exports.js -i node-fetch -g uglifyify -o dist/nearlib.min.js",
    "test": "npm run generate-protos && jest test",
    "lint": "eslint .",
    "fix": "eslint . --fix",
    "doc": "documentation readme near.js account.js wallet-account.js wallet-access-key.js signing/key_pair.js -f md --shallow --section=API --readme-file=API.md"
  },
  "author": "Evguenia Degtiareva"
}

'''
'''--- nearlib/protos.js ---
/*eslint-disable block-scoped-var, id-length, no-control-regex, no-magic-numbers, no-prototype-builtins, no-redeclare, no-shadow, no-var, sort-vars*/
"use strict";

var $protobuf = require("protobufjs/minimal");

// Common aliases
var $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;

// Exported root namespace
var $root = $protobuf.roots["default"] || ($protobuf.roots["default"] = {});

$root.CreateAccountTransaction = (function() {

    /**
     * Properties of a CreateAccountTransaction.
     * @exports ICreateAccountTransaction
     * @interface ICreateAccountTransaction
     * @property {number|Long|null} [nonce] CreateAccountTransaction nonce
     * @property {string|null} [originator] CreateAccountTransaction originator
     * @property {string|null} [newAccountId] CreateAccountTransaction newAccountId
     * @property {number|Long|null} [amount] CreateAccountTransaction amount
     * @property {Uint8Array|null} [publicKey] CreateAccountTransaction publicKey
     */

    /**
     * Constructs a new CreateAccountTransaction.
     * @exports CreateAccountTransaction
     * @classdesc Represents a CreateAccountTransaction.
     * @implements ICreateAccountTransaction
     * @constructor
     * @param {ICreateAccountTransaction=} [properties] Properties to set
     */
    function CreateAccountTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * CreateAccountTransaction nonce.
     * @member {number|Long} nonce
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * CreateAccountTransaction originator.
     * @member {string} originator
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.originator = "";

    /**
     * CreateAccountTransaction newAccountId.
     * @member {string} newAccountId
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.newAccountId = "";

    /**
     * CreateAccountTransaction amount.
     * @member {number|Long} amount
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * CreateAccountTransaction publicKey.
     * @member {Uint8Array} publicKey
     * @memberof CreateAccountTransaction
     * @instance
     */
    CreateAccountTransaction.prototype.publicKey = $util.newBuffer([]);

    /**
     * Creates a new CreateAccountTransaction instance using the specified properties.
     * @function create
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction=} [properties] Properties to set
     * @returns {CreateAccountTransaction} CreateAccountTransaction instance
     */
    CreateAccountTransaction.create = function create(properties) {
        return new CreateAccountTransaction(properties);
    };

    /**
     * Encodes the specified CreateAccountTransaction message. Does not implicitly {@link CreateAccountTransaction.verify|verify} messages.
     * @function encode
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction} message CreateAccountTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    CreateAccountTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.newAccountId);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 4, wireType 0 =*/32).uint64(message.amount);
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            writer.uint32(/* id 5, wireType 2 =*/42).bytes(message.publicKey);
        return writer;
    };

    /**
     * Encodes the specified CreateAccountTransaction message, length delimited. Does not implicitly {@link CreateAccountTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof CreateAccountTransaction
     * @static
     * @param {ICreateAccountTransaction} message CreateAccountTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    CreateAccountTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a CreateAccountTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof CreateAccountTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    CreateAccountTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.CreateAccountTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.newAccountId = reader.string();
                break;
            case 4:
                message.amount = reader.uint64();
                break;
            case 5:
                message.publicKey = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a CreateAccountTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof CreateAccountTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    CreateAccountTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a CreateAccountTransaction message.
     * @function verify
     * @memberof CreateAccountTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    CreateAccountTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            if (!$util.isString(message.newAccountId))
                return "newAccountId: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            if (!(message.publicKey && typeof message.publicKey.length === "number" || $util.isString(message.publicKey)))
                return "publicKey: buffer expected";
        return null;
    };

    /**
     * Creates a CreateAccountTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof CreateAccountTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {CreateAccountTransaction} CreateAccountTransaction
     */
    CreateAccountTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.CreateAccountTransaction)
            return object;
        var message = new $root.CreateAccountTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.newAccountId != null)
            message.newAccountId = String(object.newAccountId);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        if (object.publicKey != null)
            if (typeof object.publicKey === "string")
                $util.base64.decode(object.publicKey, message.publicKey = $util.newBuffer($util.base64.length(object.publicKey)), 0);
            else if (object.publicKey.length)
                message.publicKey = object.publicKey;
        return message;
    };

    /**
     * Creates a plain object from a CreateAccountTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof CreateAccountTransaction
     * @static
     * @param {CreateAccountTransaction} message CreateAccountTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    CreateAccountTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.newAccountId = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
            if (options.bytes === String)
                object.publicKey = "";
            else {
                object.publicKey = [];
                if (options.bytes !== Array)
                    object.publicKey = $util.newBuffer(object.publicKey);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.newAccountId != null && message.hasOwnProperty("newAccountId"))
            object.newAccountId = message.newAccountId;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        if (message.publicKey != null && message.hasOwnProperty("publicKey"))
            object.publicKey = options.bytes === String ? $util.base64.encode(message.publicKey, 0, message.publicKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.publicKey) : message.publicKey;
        return object;
    };

    /**
     * Converts this CreateAccountTransaction to JSON.
     * @function toJSON
     * @memberof CreateAccountTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    CreateAccountTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return CreateAccountTransaction;
})();

$root.DeployContractTransaction = (function() {

    /**
     * Properties of a DeployContractTransaction.
     * @exports IDeployContractTransaction
     * @interface IDeployContractTransaction
     * @property {number|Long|null} [nonce] DeployContractTransaction nonce
     * @property {string|null} [contractId] DeployContractTransaction contractId
     * @property {Uint8Array|null} [wasmByteArray] DeployContractTransaction wasmByteArray
     */

    /**
     * Constructs a new DeployContractTransaction.
     * @exports DeployContractTransaction
     * @classdesc Represents a DeployContractTransaction.
     * @implements IDeployContractTransaction
     * @constructor
     * @param {IDeployContractTransaction=} [properties] Properties to set
     */
    function DeployContractTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * DeployContractTransaction nonce.
     * @member {number|Long} nonce
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * DeployContractTransaction contractId.
     * @member {string} contractId
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.contractId = "";

    /**
     * DeployContractTransaction wasmByteArray.
     * @member {Uint8Array} wasmByteArray
     * @memberof DeployContractTransaction
     * @instance
     */
    DeployContractTransaction.prototype.wasmByteArray = $util.newBuffer([]);

    /**
     * Creates a new DeployContractTransaction instance using the specified properties.
     * @function create
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction=} [properties] Properties to set
     * @returns {DeployContractTransaction} DeployContractTransaction instance
     */
    DeployContractTransaction.create = function create(properties) {
        return new DeployContractTransaction(properties);
    };

    /**
     * Encodes the specified DeployContractTransaction message. Does not implicitly {@link DeployContractTransaction.verify|verify} messages.
     * @function encode
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction} message DeployContractTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeployContractTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.contractId);
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.wasmByteArray);
        return writer;
    };

    /**
     * Encodes the specified DeployContractTransaction message, length delimited. Does not implicitly {@link DeployContractTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof DeployContractTransaction
     * @static
     * @param {IDeployContractTransaction} message DeployContractTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    DeployContractTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a DeployContractTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof DeployContractTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {DeployContractTransaction} DeployContractTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeployContractTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.DeployContractTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.contractId = reader.string();
                break;
            case 3:
                message.wasmByteArray = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a DeployContractTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof DeployContractTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {DeployContractTransaction} DeployContractTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    DeployContractTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a DeployContractTransaction message.
     * @function verify
     * @memberof DeployContractTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    DeployContractTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            if (!$util.isString(message.contractId))
                return "contractId: string expected";
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            if (!(message.wasmByteArray && typeof message.wasmByteArray.length === "number" || $util.isString(message.wasmByteArray)))
                return "wasmByteArray: buffer expected";
        return null;
    };

    /**
     * Creates a DeployContractTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof DeployContractTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {DeployContractTransaction} DeployContractTransaction
     */
    DeployContractTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.DeployContractTransaction)
            return object;
        var message = new $root.DeployContractTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.contractId != null)
            message.contractId = String(object.contractId);
        if (object.wasmByteArray != null)
            if (typeof object.wasmByteArray === "string")
                $util.base64.decode(object.wasmByteArray, message.wasmByteArray = $util.newBuffer($util.base64.length(object.wasmByteArray)), 0);
            else if (object.wasmByteArray.length)
                message.wasmByteArray = object.wasmByteArray;
        return message;
    };

    /**
     * Creates a plain object from a DeployContractTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof DeployContractTransaction
     * @static
     * @param {DeployContractTransaction} message DeployContractTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    DeployContractTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.contractId = "";
            if (options.bytes === String)
                object.wasmByteArray = "";
            else {
                object.wasmByteArray = [];
                if (options.bytes !== Array)
                    object.wasmByteArray = $util.newBuffer(object.wasmByteArray);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            object.contractId = message.contractId;
        if (message.wasmByteArray != null && message.hasOwnProperty("wasmByteArray"))
            object.wasmByteArray = options.bytes === String ? $util.base64.encode(message.wasmByteArray, 0, message.wasmByteArray.length) : options.bytes === Array ? Array.prototype.slice.call(message.wasmByteArray) : message.wasmByteArray;
        return object;
    };

    /**
     * Converts this DeployContractTransaction to JSON.
     * @function toJSON
     * @memberof DeployContractTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    DeployContractTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return DeployContractTransaction;
})();

$root.FunctionCallTransaction = (function() {

    /**
     * Properties of a FunctionCallTransaction.
     * @exports IFunctionCallTransaction
     * @interface IFunctionCallTransaction
     * @property {number|Long|null} [nonce] FunctionCallTransaction nonce
     * @property {string|null} [originator] FunctionCallTransaction originator
     * @property {string|null} [contractId] FunctionCallTransaction contractId
     * @property {Uint8Array|null} [methodName] FunctionCallTransaction methodName
     * @property {Uint8Array|null} [args] FunctionCallTransaction args
     * @property {number|Long|null} [amount] FunctionCallTransaction amount
     */

    /**
     * Constructs a new FunctionCallTransaction.
     * @exports FunctionCallTransaction
     * @classdesc Represents a FunctionCallTransaction.
     * @implements IFunctionCallTransaction
     * @constructor
     * @param {IFunctionCallTransaction=} [properties] Properties to set
     */
    function FunctionCallTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * FunctionCallTransaction nonce.
     * @member {number|Long} nonce
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * FunctionCallTransaction originator.
     * @member {string} originator
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.originator = "";

    /**
     * FunctionCallTransaction contractId.
     * @member {string} contractId
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.contractId = "";

    /**
     * FunctionCallTransaction methodName.
     * @member {Uint8Array} methodName
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.methodName = $util.newBuffer([]);

    /**
     * FunctionCallTransaction args.
     * @member {Uint8Array} args
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.args = $util.newBuffer([]);

    /**
     * FunctionCallTransaction amount.
     * @member {number|Long} amount
     * @memberof FunctionCallTransaction
     * @instance
     */
    FunctionCallTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * Creates a new FunctionCallTransaction instance using the specified properties.
     * @function create
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction=} [properties] Properties to set
     * @returns {FunctionCallTransaction} FunctionCallTransaction instance
     */
    FunctionCallTransaction.create = function create(properties) {
        return new FunctionCallTransaction(properties);
    };

    /**
     * Encodes the specified FunctionCallTransaction message. Does not implicitly {@link FunctionCallTransaction.verify|verify} messages.
     * @function encode
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction} message FunctionCallTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    FunctionCallTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.contractId);
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            writer.uint32(/* id 4, wireType 2 =*/34).bytes(message.methodName);
        if (message.args != null && message.hasOwnProperty("args"))
            writer.uint32(/* id 5, wireType 2 =*/42).bytes(message.args);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 6, wireType 0 =*/48).uint64(message.amount);
        return writer;
    };

    /**
     * Encodes the specified FunctionCallTransaction message, length delimited. Does not implicitly {@link FunctionCallTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof FunctionCallTransaction
     * @static
     * @param {IFunctionCallTransaction} message FunctionCallTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    FunctionCallTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a FunctionCallTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof FunctionCallTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    FunctionCallTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.FunctionCallTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.contractId = reader.string();
                break;
            case 4:
                message.methodName = reader.bytes();
                break;
            case 5:
                message.args = reader.bytes();
                break;
            case 6:
                message.amount = reader.uint64();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a FunctionCallTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof FunctionCallTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    FunctionCallTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a FunctionCallTransaction message.
     * @function verify
     * @memberof FunctionCallTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    FunctionCallTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            if (!$util.isString(message.contractId))
                return "contractId: string expected";
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            if (!(message.methodName && typeof message.methodName.length === "number" || $util.isString(message.methodName)))
                return "methodName: buffer expected";
        if (message.args != null && message.hasOwnProperty("args"))
            if (!(message.args && typeof message.args.length === "number" || $util.isString(message.args)))
                return "args: buffer expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        return null;
    };

    /**
     * Creates a FunctionCallTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof FunctionCallTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {FunctionCallTransaction} FunctionCallTransaction
     */
    FunctionCallTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.FunctionCallTransaction)
            return object;
        var message = new $root.FunctionCallTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.contractId != null)
            message.contractId = String(object.contractId);
        if (object.methodName != null)
            if (typeof object.methodName === "string")
                $util.base64.decode(object.methodName, message.methodName = $util.newBuffer($util.base64.length(object.methodName)), 0);
            else if (object.methodName.length)
                message.methodName = object.methodName;
        if (object.args != null)
            if (typeof object.args === "string")
                $util.base64.decode(object.args, message.args = $util.newBuffer($util.base64.length(object.args)), 0);
            else if (object.args.length)
                message.args = object.args;
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        return message;
    };

    /**
     * Creates a plain object from a FunctionCallTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof FunctionCallTransaction
     * @static
     * @param {FunctionCallTransaction} message FunctionCallTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    FunctionCallTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.contractId = "";
            if (options.bytes === String)
                object.methodName = "";
            else {
                object.methodName = [];
                if (options.bytes !== Array)
                    object.methodName = $util.newBuffer(object.methodName);
            }
            if (options.bytes === String)
                object.args = "";
            else {
                object.args = [];
                if (options.bytes !== Array)
                    object.args = $util.newBuffer(object.args);
            }
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.contractId != null && message.hasOwnProperty("contractId"))
            object.contractId = message.contractId;
        if (message.methodName != null && message.hasOwnProperty("methodName"))
            object.methodName = options.bytes === String ? $util.base64.encode(message.methodName, 0, message.methodName.length) : options.bytes === Array ? Array.prototype.slice.call(message.methodName) : message.methodName;
        if (message.args != null && message.hasOwnProperty("args"))
            object.args = options.bytes === String ? $util.base64.encode(message.args, 0, message.args.length) : options.bytes === Array ? Array.prototype.slice.call(message.args) : message.args;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        return object;
    };

    /**
     * Converts this FunctionCallTransaction to JSON.
     * @function toJSON
     * @memberof FunctionCallTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    FunctionCallTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return FunctionCallTransaction;
})();

$root.SendMoneyTransaction = (function() {

    /**
     * Properties of a SendMoneyTransaction.
     * @exports ISendMoneyTransaction
     * @interface ISendMoneyTransaction
     * @property {number|Long|null} [nonce] SendMoneyTransaction nonce
     * @property {string|null} [originator] SendMoneyTransaction originator
     * @property {string|null} [receiver] SendMoneyTransaction receiver
     * @property {number|Long|null} [amount] SendMoneyTransaction amount
     */

    /**
     * Constructs a new SendMoneyTransaction.
     * @exports SendMoneyTransaction
     * @classdesc Represents a SendMoneyTransaction.
     * @implements ISendMoneyTransaction
     * @constructor
     * @param {ISendMoneyTransaction=} [properties] Properties to set
     */
    function SendMoneyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SendMoneyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * SendMoneyTransaction originator.
     * @member {string} originator
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.originator = "";

    /**
     * SendMoneyTransaction receiver.
     * @member {string} receiver
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.receiver = "";

    /**
     * SendMoneyTransaction amount.
     * @member {number|Long} amount
     * @memberof SendMoneyTransaction
     * @instance
     */
    SendMoneyTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * Creates a new SendMoneyTransaction instance using the specified properties.
     * @function create
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction=} [properties] Properties to set
     * @returns {SendMoneyTransaction} SendMoneyTransaction instance
     */
    SendMoneyTransaction.create = function create(properties) {
        return new SendMoneyTransaction(properties);
    };

    /**
     * Encodes the specified SendMoneyTransaction message. Does not implicitly {@link SendMoneyTransaction.verify|verify} messages.
     * @function encode
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction} message SendMoneyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SendMoneyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            writer.uint32(/* id 3, wireType 2 =*/26).string(message.receiver);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 4, wireType 0 =*/32).uint64(message.amount);
        return writer;
    };

    /**
     * Encodes the specified SendMoneyTransaction message, length delimited. Does not implicitly {@link SendMoneyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SendMoneyTransaction
     * @static
     * @param {ISendMoneyTransaction} message SendMoneyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SendMoneyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SendMoneyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SendMoneyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SendMoneyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SendMoneyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.receiver = reader.string();
                break;
            case 4:
                message.amount = reader.uint64();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SendMoneyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SendMoneyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SendMoneyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SendMoneyTransaction message.
     * @function verify
     * @memberof SendMoneyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SendMoneyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            if (!$util.isString(message.receiver))
                return "receiver: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        return null;
    };

    /**
     * Creates a SendMoneyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SendMoneyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SendMoneyTransaction} SendMoneyTransaction
     */
    SendMoneyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SendMoneyTransaction)
            return object;
        var message = new $root.SendMoneyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.receiver != null)
            message.receiver = String(object.receiver);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        return message;
    };

    /**
     * Creates a plain object from a SendMoneyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SendMoneyTransaction
     * @static
     * @param {SendMoneyTransaction} message SendMoneyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SendMoneyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            object.receiver = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.receiver != null && message.hasOwnProperty("receiver"))
            object.receiver = message.receiver;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        return object;
    };

    /**
     * Converts this SendMoneyTransaction to JSON.
     * @function toJSON
     * @memberof SendMoneyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SendMoneyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SendMoneyTransaction;
})();

$root.StakeTransaction = (function() {

    /**
     * Properties of a StakeTransaction.
     * @exports IStakeTransaction
     * @interface IStakeTransaction
     * @property {number|Long|null} [nonce] StakeTransaction nonce
     * @property {string|null} [originator] StakeTransaction originator
     * @property {number|Long|null} [amount] StakeTransaction amount
     */

    /**
     * Constructs a new StakeTransaction.
     * @exports StakeTransaction
     * @classdesc Represents a StakeTransaction.
     * @implements IStakeTransaction
     * @constructor
     * @param {IStakeTransaction=} [properties] Properties to set
     */
    function StakeTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * StakeTransaction nonce.
     * @member {number|Long} nonce
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * StakeTransaction originator.
     * @member {string} originator
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.originator = "";

    /**
     * StakeTransaction amount.
     * @member {number|Long} amount
     * @memberof StakeTransaction
     * @instance
     */
    StakeTransaction.prototype.amount = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * Creates a new StakeTransaction instance using the specified properties.
     * @function create
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction=} [properties] Properties to set
     * @returns {StakeTransaction} StakeTransaction instance
     */
    StakeTransaction.create = function create(properties) {
        return new StakeTransaction(properties);
    };

    /**
     * Encodes the specified StakeTransaction message. Does not implicitly {@link StakeTransaction.verify|verify} messages.
     * @function encode
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction} message StakeTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    StakeTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.amount != null && message.hasOwnProperty("amount"))
            writer.uint32(/* id 3, wireType 0 =*/24).uint64(message.amount);
        return writer;
    };

    /**
     * Encodes the specified StakeTransaction message, length delimited. Does not implicitly {@link StakeTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof StakeTransaction
     * @static
     * @param {IStakeTransaction} message StakeTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    StakeTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a StakeTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof StakeTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {StakeTransaction} StakeTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    StakeTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.StakeTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.amount = reader.uint64();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a StakeTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof StakeTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {StakeTransaction} StakeTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    StakeTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a StakeTransaction message.
     * @function verify
     * @memberof StakeTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    StakeTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (!$util.isInteger(message.amount) && !(message.amount && $util.isInteger(message.amount.low) && $util.isInteger(message.amount.high)))
                return "amount: integer|Long expected";
        return null;
    };

    /**
     * Creates a StakeTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof StakeTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {StakeTransaction} StakeTransaction
     */
    StakeTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.StakeTransaction)
            return object;
        var message = new $root.StakeTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.amount != null)
            if ($util.Long)
                (message.amount = $util.Long.fromValue(object.amount)).unsigned = true;
            else if (typeof object.amount === "string")
                message.amount = parseInt(object.amount, 10);
            else if (typeof object.amount === "number")
                message.amount = object.amount;
            else if (typeof object.amount === "object")
                message.amount = new $util.LongBits(object.amount.low >>> 0, object.amount.high >>> 0).toNumber(true);
        return message;
    };

    /**
     * Creates a plain object from a StakeTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof StakeTransaction
     * @static
     * @param {StakeTransaction} message StakeTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    StakeTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.amount = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.amount = options.longs === String ? "0" : 0;
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.amount != null && message.hasOwnProperty("amount"))
            if (typeof message.amount === "number")
                object.amount = options.longs === String ? String(message.amount) : message.amount;
            else
                object.amount = options.longs === String ? $util.Long.prototype.toString.call(message.amount) : options.longs === Number ? new $util.LongBits(message.amount.low >>> 0, message.amount.high >>> 0).toNumber(true) : message.amount;
        return object;
    };

    /**
     * Converts this StakeTransaction to JSON.
     * @function toJSON
     * @memberof StakeTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    StakeTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return StakeTransaction;
})();

$root.SwapKeyTransaction = (function() {

    /**
     * Properties of a SwapKeyTransaction.
     * @exports ISwapKeyTransaction
     * @interface ISwapKeyTransaction
     * @property {number|Long|null} [nonce] SwapKeyTransaction nonce
     * @property {string|null} [originator] SwapKeyTransaction originator
     * @property {Uint8Array|null} [curKey] SwapKeyTransaction curKey
     * @property {Uint8Array|null} [newKey] SwapKeyTransaction newKey
     */

    /**
     * Constructs a new SwapKeyTransaction.
     * @exports SwapKeyTransaction
     * @classdesc Represents a SwapKeyTransaction.
     * @implements ISwapKeyTransaction
     * @constructor
     * @param {ISwapKeyTransaction=} [properties] Properties to set
     */
    function SwapKeyTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SwapKeyTransaction nonce.
     * @member {number|Long} nonce
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.nonce = $util.Long ? $util.Long.fromBits(0,0,true) : 0;

    /**
     * SwapKeyTransaction originator.
     * @member {string} originator
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.originator = "";

    /**
     * SwapKeyTransaction curKey.
     * @member {Uint8Array} curKey
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.curKey = $util.newBuffer([]);

    /**
     * SwapKeyTransaction newKey.
     * @member {Uint8Array} newKey
     * @memberof SwapKeyTransaction
     * @instance
     */
    SwapKeyTransaction.prototype.newKey = $util.newBuffer([]);

    /**
     * Creates a new SwapKeyTransaction instance using the specified properties.
     * @function create
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction=} [properties] Properties to set
     * @returns {SwapKeyTransaction} SwapKeyTransaction instance
     */
    SwapKeyTransaction.create = function create(properties) {
        return new SwapKeyTransaction(properties);
    };

    /**
     * Encodes the specified SwapKeyTransaction message. Does not implicitly {@link SwapKeyTransaction.verify|verify} messages.
     * @function encode
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction} message SwapKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SwapKeyTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            writer.uint32(/* id 1, wireType 0 =*/8).uint64(message.nonce);
        if (message.originator != null && message.hasOwnProperty("originator"))
            writer.uint32(/* id 2, wireType 2 =*/18).string(message.originator);
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            writer.uint32(/* id 3, wireType 2 =*/26).bytes(message.curKey);
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            writer.uint32(/* id 4, wireType 2 =*/34).bytes(message.newKey);
        return writer;
    };

    /**
     * Encodes the specified SwapKeyTransaction message, length delimited. Does not implicitly {@link SwapKeyTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SwapKeyTransaction
     * @static
     * @param {ISwapKeyTransaction} message SwapKeyTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SwapKeyTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SwapKeyTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SwapKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SwapKeyTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SwapKeyTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.nonce = reader.uint64();
                break;
            case 2:
                message.originator = reader.string();
                break;
            case 3:
                message.curKey = reader.bytes();
                break;
            case 4:
                message.newKey = reader.bytes();
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SwapKeyTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SwapKeyTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SwapKeyTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SwapKeyTransaction message.
     * @function verify
     * @memberof SwapKeyTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SwapKeyTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (!$util.isInteger(message.nonce) && !(message.nonce && $util.isInteger(message.nonce.low) && $util.isInteger(message.nonce.high)))
                return "nonce: integer|Long expected";
        if (message.originator != null && message.hasOwnProperty("originator"))
            if (!$util.isString(message.originator))
                return "originator: string expected";
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            if (!(message.curKey && typeof message.curKey.length === "number" || $util.isString(message.curKey)))
                return "curKey: buffer expected";
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            if (!(message.newKey && typeof message.newKey.length === "number" || $util.isString(message.newKey)))
                return "newKey: buffer expected";
        return null;
    };

    /**
     * Creates a SwapKeyTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SwapKeyTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SwapKeyTransaction} SwapKeyTransaction
     */
    SwapKeyTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SwapKeyTransaction)
            return object;
        var message = new $root.SwapKeyTransaction();
        if (object.nonce != null)
            if ($util.Long)
                (message.nonce = $util.Long.fromValue(object.nonce)).unsigned = true;
            else if (typeof object.nonce === "string")
                message.nonce = parseInt(object.nonce, 10);
            else if (typeof object.nonce === "number")
                message.nonce = object.nonce;
            else if (typeof object.nonce === "object")
                message.nonce = new $util.LongBits(object.nonce.low >>> 0, object.nonce.high >>> 0).toNumber(true);
        if (object.originator != null)
            message.originator = String(object.originator);
        if (object.curKey != null)
            if (typeof object.curKey === "string")
                $util.base64.decode(object.curKey, message.curKey = $util.newBuffer($util.base64.length(object.curKey)), 0);
            else if (object.curKey.length)
                message.curKey = object.curKey;
        if (object.newKey != null)
            if (typeof object.newKey === "string")
                $util.base64.decode(object.newKey, message.newKey = $util.newBuffer($util.base64.length(object.newKey)), 0);
            else if (object.newKey.length)
                message.newKey = object.newKey;
        return message;
    };

    /**
     * Creates a plain object from a SwapKeyTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SwapKeyTransaction
     * @static
     * @param {SwapKeyTransaction} message SwapKeyTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SwapKeyTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults) {
            if ($util.Long) {
                var long = new $util.Long(0, 0, true);
                object.nonce = options.longs === String ? long.toString() : options.longs === Number ? long.toNumber() : long;
            } else
                object.nonce = options.longs === String ? "0" : 0;
            object.originator = "";
            if (options.bytes === String)
                object.curKey = "";
            else {
                object.curKey = [];
                if (options.bytes !== Array)
                    object.curKey = $util.newBuffer(object.curKey);
            }
            if (options.bytes === String)
                object.newKey = "";
            else {
                object.newKey = [];
                if (options.bytes !== Array)
                    object.newKey = $util.newBuffer(object.newKey);
            }
        }
        if (message.nonce != null && message.hasOwnProperty("nonce"))
            if (typeof message.nonce === "number")
                object.nonce = options.longs === String ? String(message.nonce) : message.nonce;
            else
                object.nonce = options.longs === String ? $util.Long.prototype.toString.call(message.nonce) : options.longs === Number ? new $util.LongBits(message.nonce.low >>> 0, message.nonce.high >>> 0).toNumber(true) : message.nonce;
        if (message.originator != null && message.hasOwnProperty("originator"))
            object.originator = message.originator;
        if (message.curKey != null && message.hasOwnProperty("curKey"))
            object.curKey = options.bytes === String ? $util.base64.encode(message.curKey, 0, message.curKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.curKey) : message.curKey;
        if (message.newKey != null && message.hasOwnProperty("newKey"))
            object.newKey = options.bytes === String ? $util.base64.encode(message.newKey, 0, message.newKey.length) : options.bytes === Array ? Array.prototype.slice.call(message.newKey) : message.newKey;
        return object;
    };

    /**
     * Converts this SwapKeyTransaction to JSON.
     * @function toJSON
     * @memberof SwapKeyTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SwapKeyTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SwapKeyTransaction;
})();

$root.SignedTransaction = (function() {

    /**
     * Properties of a SignedTransaction.
     * @exports ISignedTransaction
     * @interface ISignedTransaction
     * @property {Uint8Array|null} [signature] SignedTransaction signature
     * @property {ICreateAccountTransaction|null} [createAccount] SignedTransaction createAccount
     * @property {IDeployContractTransaction|null} [deployContract] SignedTransaction deployContract
     * @property {IFunctionCallTransaction|null} [functionCall] SignedTransaction functionCall
     * @property {ISendMoneyTransaction|null} [sendMoney] SignedTransaction sendMoney
     * @property {IStakeTransaction|null} [stake] SignedTransaction stake
     * @property {ISwapKeyTransaction|null} [swapKey] SignedTransaction swapKey
     */

    /**
     * Constructs a new SignedTransaction.
     * @exports SignedTransaction
     * @classdesc Represents a SignedTransaction.
     * @implements ISignedTransaction
     * @constructor
     * @param {ISignedTransaction=} [properties] Properties to set
     */
    function SignedTransaction(properties) {
        if (properties)
            for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)
                if (properties[keys[i]] != null)
                    this[keys[i]] = properties[keys[i]];
    }

    /**
     * SignedTransaction signature.
     * @member {Uint8Array} signature
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.signature = $util.newBuffer([]);

    /**
     * SignedTransaction createAccount.
     * @member {ICreateAccountTransaction|null|undefined} createAccount
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.createAccount = null;

    /**
     * SignedTransaction deployContract.
     * @member {IDeployContractTransaction|null|undefined} deployContract
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.deployContract = null;

    /**
     * SignedTransaction functionCall.
     * @member {IFunctionCallTransaction|null|undefined} functionCall
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.functionCall = null;

    /**
     * SignedTransaction sendMoney.
     * @member {ISendMoneyTransaction|null|undefined} sendMoney
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.sendMoney = null;

    /**
     * SignedTransaction stake.
     * @member {IStakeTransaction|null|undefined} stake
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.stake = null;

    /**
     * SignedTransaction swapKey.
     * @member {ISwapKeyTransaction|null|undefined} swapKey
     * @memberof SignedTransaction
     * @instance
     */
    SignedTransaction.prototype.swapKey = null;

    // OneOf field names bound to virtual getters and setters
    var $oneOfFields;

    /**
     * SignedTransaction body.
     * @member {"createAccount"|"deployContract"|"functionCall"|"sendMoney"|"stake"|"swapKey"|undefined} body
     * @memberof SignedTransaction
     * @instance
     */
    Object.defineProperty(SignedTransaction.prototype, "body", {
        get: $util.oneOfGetter($oneOfFields = ["createAccount", "deployContract", "functionCall", "sendMoney", "stake", "swapKey"]),
        set: $util.oneOfSetter($oneOfFields)
    });

    /**
     * Creates a new SignedTransaction instance using the specified properties.
     * @function create
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction=} [properties] Properties to set
     * @returns {SignedTransaction} SignedTransaction instance
     */
    SignedTransaction.create = function create(properties) {
        return new SignedTransaction(properties);
    };

    /**
     * Encodes the specified SignedTransaction message. Does not implicitly {@link SignedTransaction.verify|verify} messages.
     * @function encode
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction} message SignedTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SignedTransaction.encode = function encode(message, writer) {
        if (!writer)
            writer = $Writer.create();
        if (message.signature != null && message.hasOwnProperty("signature"))
            writer.uint32(/* id 1, wireType 2 =*/10).bytes(message.signature);
        if (message.createAccount != null && message.hasOwnProperty("createAccount"))
            $root.CreateAccountTransaction.encode(message.createAccount, writer.uint32(/* id 2, wireType 2 =*/18).fork()).ldelim();
        if (message.deployContract != null && message.hasOwnProperty("deployContract"))
            $root.DeployContractTransaction.encode(message.deployContract, writer.uint32(/* id 3, wireType 2 =*/26).fork()).ldelim();
        if (message.functionCall != null && message.hasOwnProperty("functionCall"))
            $root.FunctionCallTransaction.encode(message.functionCall, writer.uint32(/* id 4, wireType 2 =*/34).fork()).ldelim();
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney"))
            $root.SendMoneyTransaction.encode(message.sendMoney, writer.uint32(/* id 5, wireType 2 =*/42).fork()).ldelim();
        if (message.stake != null && message.hasOwnProperty("stake"))
            $root.StakeTransaction.encode(message.stake, writer.uint32(/* id 6, wireType 2 =*/50).fork()).ldelim();
        if (message.swapKey != null && message.hasOwnProperty("swapKey"))
            $root.SwapKeyTransaction.encode(message.swapKey, writer.uint32(/* id 7, wireType 2 =*/58).fork()).ldelim();
        return writer;
    };

    /**
     * Encodes the specified SignedTransaction message, length delimited. Does not implicitly {@link SignedTransaction.verify|verify} messages.
     * @function encodeDelimited
     * @memberof SignedTransaction
     * @static
     * @param {ISignedTransaction} message SignedTransaction message or plain object to encode
     * @param {$protobuf.Writer} [writer] Writer to encode to
     * @returns {$protobuf.Writer} Writer
     */
    SignedTransaction.encodeDelimited = function encodeDelimited(message, writer) {
        return this.encode(message, writer).ldelim();
    };

    /**
     * Decodes a SignedTransaction message from the specified reader or buffer.
     * @function decode
     * @memberof SignedTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @param {number} [length] Message length if known beforehand
     * @returns {SignedTransaction} SignedTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SignedTransaction.decode = function decode(reader, length) {
        if (!(reader instanceof $Reader))
            reader = $Reader.create(reader);
        var end = length === undefined ? reader.len : reader.pos + length, message = new $root.SignedTransaction();
        while (reader.pos < end) {
            var tag = reader.uint32();
            switch (tag >>> 3) {
            case 1:
                message.signature = reader.bytes();
                break;
            case 2:
                message.createAccount = $root.CreateAccountTransaction.decode(reader, reader.uint32());
                break;
            case 3:
                message.deployContract = $root.DeployContractTransaction.decode(reader, reader.uint32());
                break;
            case 4:
                message.functionCall = $root.FunctionCallTransaction.decode(reader, reader.uint32());
                break;
            case 5:
                message.sendMoney = $root.SendMoneyTransaction.decode(reader, reader.uint32());
                break;
            case 6:
                message.stake = $root.StakeTransaction.decode(reader, reader.uint32());
                break;
            case 7:
                message.swapKey = $root.SwapKeyTransaction.decode(reader, reader.uint32());
                break;
            default:
                reader.skipType(tag & 7);
                break;
            }
        }
        return message;
    };

    /**
     * Decodes a SignedTransaction message from the specified reader or buffer, length delimited.
     * @function decodeDelimited
     * @memberof SignedTransaction
     * @static
     * @param {$protobuf.Reader|Uint8Array} reader Reader or buffer to decode from
     * @returns {SignedTransaction} SignedTransaction
     * @throws {Error} If the payload is not a reader or valid buffer
     * @throws {$protobuf.util.ProtocolError} If required fields are missing
     */
    SignedTransaction.decodeDelimited = function decodeDelimited(reader) {
        if (!(reader instanceof $Reader))
            reader = new $Reader(reader);
        return this.decode(reader, reader.uint32());
    };

    /**
     * Verifies a SignedTransaction message.
     * @function verify
     * @memberof SignedTransaction
     * @static
     * @param {Object.<string,*>} message Plain object to verify
     * @returns {string|null} `null` if valid, otherwise the reason why it is not
     */
    SignedTransaction.verify = function verify(message) {
        if (typeof message !== "object" || message === null)
            return "object expected";
        var properties = {};
        if (message.signature != null && message.hasOwnProperty("signature"))
            if (!(message.signature && typeof message.signature.length === "number" || $util.isString(message.signature)))
                return "signature: buffer expected";
        if (message.createAccount != null && message.hasOwnProperty("createAccount")) {
            properties.body = 1;
            {
                var error = $root.CreateAccountTransaction.verify(message.createAccount);
                if (error)
                    return "createAccount." + error;
            }
        }
        if (message.deployContract != null && message.hasOwnProperty("deployContract")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.DeployContractTransaction.verify(message.deployContract);
                if (error)
                    return "deployContract." + error;
            }
        }
        if (message.functionCall != null && message.hasOwnProperty("functionCall")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.FunctionCallTransaction.verify(message.functionCall);
                if (error)
                    return "functionCall." + error;
            }
        }
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.SendMoneyTransaction.verify(message.sendMoney);
                if (error)
                    return "sendMoney." + error;
            }
        }
        if (message.stake != null && message.hasOwnProperty("stake")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.StakeTransaction.verify(message.stake);
                if (error)
                    return "stake." + error;
            }
        }
        if (message.swapKey != null && message.hasOwnProperty("swapKey")) {
            if (properties.body === 1)
                return "body: multiple values";
            properties.body = 1;
            {
                var error = $root.SwapKeyTransaction.verify(message.swapKey);
                if (error)
                    return "swapKey." + error;
            }
        }
        return null;
    };

    /**
     * Creates a SignedTransaction message from a plain object. Also converts values to their respective internal types.
     * @function fromObject
     * @memberof SignedTransaction
     * @static
     * @param {Object.<string,*>} object Plain object
     * @returns {SignedTransaction} SignedTransaction
     */
    SignedTransaction.fromObject = function fromObject(object) {
        if (object instanceof $root.SignedTransaction)
            return object;
        var message = new $root.SignedTransaction();
        if (object.signature != null)
            if (typeof object.signature === "string")
                $util.base64.decode(object.signature, message.signature = $util.newBuffer($util.base64.length(object.signature)), 0);
            else if (object.signature.length)
                message.signature = object.signature;
        if (object.createAccount != null) {
            if (typeof object.createAccount !== "object")
                throw TypeError(".SignedTransaction.createAccount: object expected");
            message.createAccount = $root.CreateAccountTransaction.fromObject(object.createAccount);
        }
        if (object.deployContract != null) {
            if (typeof object.deployContract !== "object")
                throw TypeError(".SignedTransaction.deployContract: object expected");
            message.deployContract = $root.DeployContractTransaction.fromObject(object.deployContract);
        }
        if (object.functionCall != null) {
            if (typeof object.functionCall !== "object")
                throw TypeError(".SignedTransaction.functionCall: object expected");
            message.functionCall = $root.FunctionCallTransaction.fromObject(object.functionCall);
        }
        if (object.sendMoney != null) {
            if (typeof object.sendMoney !== "object")
                throw TypeError(".SignedTransaction.sendMoney: object expected");
            message.sendMoney = $root.SendMoneyTransaction.fromObject(object.sendMoney);
        }
        if (object.stake != null) {
            if (typeof object.stake !== "object")
                throw TypeError(".SignedTransaction.stake: object expected");
            message.stake = $root.StakeTransaction.fromObject(object.stake);
        }
        if (object.swapKey != null) {
            if (typeof object.swapKey !== "object")
                throw TypeError(".SignedTransaction.swapKey: object expected");
            message.swapKey = $root.SwapKeyTransaction.fromObject(object.swapKey);
        }
        return message;
    };

    /**
     * Creates a plain object from a SignedTransaction message. Also converts values to other types if specified.
     * @function toObject
     * @memberof SignedTransaction
     * @static
     * @param {SignedTransaction} message SignedTransaction
     * @param {$protobuf.IConversionOptions} [options] Conversion options
     * @returns {Object.<string,*>} Plain object
     */
    SignedTransaction.toObject = function toObject(message, options) {
        if (!options)
            options = {};
        var object = {};
        if (options.defaults)
            if (options.bytes === String)
                object.signature = "";
            else {
                object.signature = [];
                if (options.bytes !== Array)
                    object.signature = $util.newBuffer(object.signature);
            }
        if (message.signature != null && message.hasOwnProperty("signature"))
            object.signature = options.bytes === String ? $util.base64.encode(message.signature, 0, message.signature.length) : options.bytes === Array ? Array.prototype.slice.call(message.signature) : message.signature;
        if (message.createAccount != null && message.hasOwnProperty("createAccount")) {
            object.createAccount = $root.CreateAccountTransaction.toObject(message.createAccount, options);
            if (options.oneofs)
                object.body = "createAccount";
        }
        if (message.deployContract != null && message.hasOwnProperty("deployContract")) {
            object.deployContract = $root.DeployContractTransaction.toObject(message.deployContract, options);
            if (options.oneofs)
                object.body = "deployContract";
        }
        if (message.functionCall != null && message.hasOwnProperty("functionCall")) {
            object.functionCall = $root.FunctionCallTransaction.toObject(message.functionCall, options);
            if (options.oneofs)
                object.body = "functionCall";
        }
        if (message.sendMoney != null && message.hasOwnProperty("sendMoney")) {
            object.sendMoney = $root.SendMoneyTransaction.toObject(message.sendMoney, options);
            if (options.oneofs)
                object.body = "sendMoney";
        }
        if (message.stake != null && message.hasOwnProperty("stake")) {
            object.stake = $root.StakeTransaction.toObject(message.stake, options);
            if (options.oneofs)
                object.body = "stake";
        }
        if (message.swapKey != null && message.hasOwnProperty("swapKey")) {
            object.swapKey = $root.SwapKeyTransaction.toObject(message.swapKey, options);
            if (options.oneofs)
                object.body = "swapKey";
        }
        return object;
    };

    /**
     * Converts this SignedTransaction to JSON.
     * @function toJSON
     * @memberof SignedTransaction
     * @instance
     * @returns {Object.<string,*>} JSON object
     */
    SignedTransaction.prototype.toJSON = function toJSON() {
        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
    };

    return SignedTransaction;
})();

module.exports = $root;

'''
'''--- nearlib/signing/account_info.js ---
const KeyPair = require('./key_pair');

/**
 * Utility functions for dealing with account information. 
 */
class AccountInfo {
    constructor(accountId, keyPair, networkId) {
        this.accountId = accountId;
        this.keyPair = keyPair;
        this.networkId = networkId;
    }

    /**
     * Reconstruct account info object from json.
     * @param {Object} json 
     */
    static fromJson(json) {
        if (!json.public_key || !json.secret_key || !json.account_id || !json.network_id) {
            throw 'Invalid account info format. Please ensure it contains public_key, secret_key, and account_id".';
        }
        return new AccountInfo(json.account_id, new KeyPair(json.public_key, json.secret_key), json.network_id);
    }

    /**
     * Convert to standard json format.
     */
    toJSON() {
        return {
            account_id: this.accountId,
            public_key: this.keyPair.getPublicKey(),
            secret_key: this.keyPair.getSecretKey(),
            network_id: this.networkId
        };
    }

    /**
     * Utility function to download account info as a standard file.
     */
    downloadAsFile() {
        const fileName = this.keyFileName;
        const text = JSON.stringify(this.toJSON());
      
        var element = document.createElement('a');
        element.setAttribute('href', 'data:text/plain;charset=utf-8,' + encodeURIComponent(text));
        element.setAttribute('download', fileName);
      
        element.style.display = 'none';
        document.body.appendChild(element);
      
        element.click();
      
        document.body.removeChild(element);
    }

    get keyFileName() {
        return this.networkId + '_' + this.accountId;
    }
}

module.exports = AccountInfo;

'''
'''--- nearlib/signing/browser_local_storage_key_store.js ---
/**
 * Stores keys in the browser local storage. This allows to retain keys between
 * browser sessions. Local storage likes to work with strings so we store public and private key separately.
 */
const KeyPair = require('./key_pair');
const AccountInfo = require('./account_info');

const LOCAL_STORAGE_SECRET_KEY_SUFFIX = '_secretkey';
const LOCAL_STORAGE_PUBLIC_KEY_SUFFIX = '_publickey';

class BrowserLocalStorageKeystore {
    constructor(networkId = 'unknown', localStorage = window.localStorage) {
        this.networkId = networkId;
        this.localStorage = localStorage;
    }

    static storageKeyForPublicKey(accountId) {
        return accountId + '_' + this.networkId + LOCAL_STORAGE_PUBLIC_KEY_SUFFIX;
    }

    static storageKeyForSecretKey(accountId) {
        return accountId + '_' + this.networkId + LOCAL_STORAGE_SECRET_KEY_SUFFIX;
    }

    /**
     * Save the key in local storage. 
     * @param {string} accountId 
     * @param {KeyPair} key 
     */
    async setKey(accountId, key) {
        this.localStorage.setItem(
            BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
        this.localStorage.setItem(
            BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
    }

    async setKeyFromJson(json) {
        const accountInfo =  AccountInfo.fromJson(json);
        if (this.networkId != accountInfo.networkId) {
            throw new Error('Setting key for a wrong network');
        }
        this.setKey(accountInfo.accountId, accountInfo.keyPair);
    }

    /**
     * Get the key from local storage and return as KeyPair object.
     * @param {string} accountId 
     */
    async getKey(accountId) {
        const publicKey = this.localStorage.getItem(
            BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId));
        const secretKey = this.localStorage.getItem(
            BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId));
        if (!publicKey || !secretKey) {
            return null;
        }
        return new KeyPair(publicKey, secretKey);
    }

    static getAccounts() {
        return Object.keys(this.localStorage).map(function(key) {
            if (key.endsWith('_public')) {
                return key.substr(0, key.length() - 7);
            }
        });
    }
}

module.exports = BrowserLocalStorageKeystore;
'''
'''--- nearlib/signing/in_memory_key_store.js ---
/**
 * Simple in-memory keystore for testing purposes.
 */
class InMemoryKeyStore {
    constructor(networkId) {
        this.networkId = networkId;
        this.keys = {};
    }

    async setKey(accountId, key) {
        this.keys[accountId + '_' + this.networkId] = key;
    }

    async getKey(accountId) {
        return this.keys[accountId  + '_' + this.networkId];
    }

    async clear() {
        this.keys = {};
    }
}

module.exports = InMemoryKeyStore;
'''
'''--- nearlib/signing/key_pair.js ---

const bs58 = require('bs58');
const nacl = require('tweetnacl');

/**
 * This class provides key pair functionality (generating key pairs, encoding key pairs).
 */
class KeyPair {
    /**
     * Construct an instance of key pair given a public key and secret key. It's generally assumed that these
     * are encoded in bs58.
     * @param {string} publicKey 
     * @param {string} secretKey 
     */
    constructor(publicKey, secretKey) {
        this.publicKey = publicKey;
        this.secretKey = secretKey;
    }

    /**
     * Get the public key.
     */
    getPublicKey() {
        return this.publicKey;
    }

    /**
     * Get the secret key.
     * @example
     *  // Passing existing key into a function to store in local storage
     *  async setKey(accountId, key) {
     *      window.localStorage.setItem(
     *          BrowserLocalStorageKeystore.storageKeyForPublicKey(accountId), key.getPublicKey());
     *      window.localStorage.setItem(
     *          BrowserLocalStorageKeystore.storageKeyForSecretKey(accountId), key.getSecretKey());
     *  }
     */
    getSecretKey() {
        return this.secretKey;
    }

    /**
     * Generate a new keypair from a random seed
     * @example
     * const keyWithRandomSeed = KeyPair.fromRandomSeed();
     * keyWithRandomSeed.getPublicKey()
     * // returns [PUBLIC_KEY]
     * 
     * keyWithRandomSeed.getSecretKey()
     * // returns [SECRET_KEY]
     */
    static fromRandomSeed() {
        let newKeypair = nacl.sign.keyPair();
        const result = new KeyPair(
            KeyPair.encodeBufferInBs58(newKeypair.publicKey),
            KeyPair.encodeBufferInBs58(newKeypair.secretKey));
        return result;
    }

    /**
     * Encode a buffer as string using bs58
     * @param {Buffer} buffer 
     * @example
     * KeyPair.encodeBufferInBs58(key.publicKey)
     */
    static encodeBufferInBs58(buffer) {
        const bytes = Buffer.from(buffer);
        const encodedValue = bs58.encode(bytes);
        return encodedValue;
    }
}
module.exports = KeyPair;

'''
'''--- nearlib/signing/simple_key_store_signer.js ---
/**
 * Simple signer that acquires a key from its single keystore and signs transactions.
 */
const bs58 = require('bs58');
const nacl = require('tweetnacl');
const { sha256 } = require('js-sha256');
const { google } = require('../protos');

class SimpleKeyStoreSigner {
    constructor(keyStore) {
        this.keyStore = keyStore;
    }

    /**
     * Signs a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        return this.signHash(new Uint8Array(sha256.array(buffer)), originator);
    }

    async signHash(hash, originator) {
        const encodedKey = await this.keyStore.getKey(originator);
        if (!encodedKey) {
            throw new Error(`Cannot find key for originator ${originator}`);
        }
        const key = bs58.decode(encodedKey.getSecretKey());
        const signature = [...nacl.sign.detached(Uint8Array.from(hash), key)];
        return {
            signature,
            publicKey: google.protobuf.BytesValue.create({
                value: bs58.decode(encodedKey.getPublicKey()),
            }),
        };
    }
}

module.exports = SimpleKeyStoreSigner;

'''
'''--- nearlib/signing/unencrypted_file_system_keystore.js ---
const fs = require('fs');
const keyDir = './neardev';
const AccountInfo = require('./account_info');
const {promisify} = require('util');

/**
 * Unencrypted file system key store.
 */
class UnencryptedFileSystemKeyStore {
    constructor(keyDir, networkId) {
        this.keyDir = keyDir;
        this.networkId = networkId;
    }

    /**
     * Set a key for an account with a given id on a given network.
     * @param {string} accountId 
     * @param {string} keypair 
     */
    async setKey(accountId, keypair) {
        if (!await promisify(fs.exists)(keyDir)){
            await promisify(fs.mkdir)(keyDir);
        }
        const accountInfo = new AccountInfo(accountId, keypair, this.networkId);
        const keyFileContent = accountInfo.toJSON();
        await promisify(fs.writeFile)(this.getKeyFilePath(accountId), JSON.stringify(keyFileContent));
    }

    /**
     * Get a single key for an account on a given network.
     * @param {string} accountId 
     */
    async getKey(accountId) {
        // Find keys/account id
        if (!await promisify(fs.exists)(this.getKeyFilePath(accountId))) {
            return null;
        }
        const json = await this.getRawKey(accountId);
        return AccountInfo.fromJson(json).keyPair;
    }

    /**
     * Returns all account ids for a particular network.
     */
    async getAccountIds() {
        if (!await promisify(fs.exists)(keyDir)) {
            return [];
        }
        const result = [];
        const dir = await promisify(fs.readdir)(keyDir);
        for (let i = 0; i < dir.length; i++) {
            if (dir[i].startsWith(this.networkId + '_')) {
                result.push(dir[i].substring(this.networkId.length + 1));
            }
        }
        return result;
    }

    async clear() {
        this.keys = {};
    }

    /**
     * Returns the key file path. The convention is to store the keys in file {networkId}.json
     */
    getKeyFilePath(accountId) {
        return keyDir + '/' + this.networkId + '_' + accountId;
    }

    async getRawKey(accountId) {
        return JSON.parse(await promisify(fs.readFile)(this.getKeyFilePath(accountId)));
    }
}

module.exports = UnencryptedFileSystemKeyStore;
'''
'''--- nearlib/test/.eslintrc.yml ---
extends: '../.eslintrc.yml'
env:
  jest: true
globals:
  window: false
  fail: true

'''
'''--- nearlib/test/browser_keystore.test.js ---
const BrowserLocalStorageKeystore = require('../signing/browser_local_storage_key_store.js');

const  { createFakeStorage } = require('./test-utils');

const KeyPair = require('../signing/key_pair.js');

const NETWORK_ID_SINGLE_KEY = 'singlekeynetworkid';
const ACCOUNT_ID_SINGLE_KEY = 'singlekeyaccountid';
const KEYPAIR_SINGLE_KEY = new KeyPair('public', 'secret');

describe('Browser keystore', () => {
    let keyStore;

    beforeAll(async () => {
        keyStore = new BrowserLocalStorageKeystore(NETWORK_ID_SINGLE_KEY, createFakeStorage());
        await keyStore.setKey(ACCOUNT_ID_SINGLE_KEY, KEYPAIR_SINGLE_KEY);
    });

    test('Get account id from empty keystore', async () => {
        const key = await keyStore.getKey('someaccount', 'somenetowrk');
        expect(key).toBeNull();  
    });
    
    test('Get account id from a network with single key', async () => {
        const key = await keyStore.getKey(ACCOUNT_ID_SINGLE_KEY);
        expect(key).toEqual(KEYPAIR_SINGLE_KEY);
    });

    test('Add two keys to network and retrieve them', async () => {
        const networkId = 'twoKeyNetwork';
        const newNetworkKeystore = new BrowserLocalStorageKeystore(networkId, createFakeStorage());
        const accountId1 = 'acc1';
        const accountId2 = 'acc2';
        const key1Expected = new KeyPair('p1', 's1');
        const key2Expected = new KeyPair('p2', 's2');
        await newNetworkKeystore.setKey(accountId1, key1Expected);
        await newNetworkKeystore.setKey(accountId2, key2Expected);
        const key1 = await newNetworkKeystore.getKey(accountId1);
        const key2 = await newNetworkKeystore.getKey(accountId2);
        expect(key1).toEqual(key1Expected);
        expect(key2).toEqual(key2Expected);
    });

    test('Set key from json and get key', async () => {
        const networkId = 'setFromJson';
        const keystore = new BrowserLocalStorageKeystore(networkId, createFakeStorage());
        const accountId = 'acc1';
        const expectedKey = new KeyPair('p1', 's1');
        const json = {
            account_id : accountId,
            public_key: expectedKey.getPublicKey(),
            secret_key: expectedKey.getSecretKey(),
            network_id: networkId
        };
        await keystore.setKeyFromJson(json);
        const key = await keystore.getKey(accountId);
        expect(key).toEqual(expectedKey);
    });

    test('Set key from json wrong network', async () => {
        const networkId = 'setFromJson';
        const keystore = new BrowserLocalStorageKeystore(networkId, createFakeStorage());
        const accountId = 'acc1';
        const expectedKey = new KeyPair('p1', 's1');
        const json = {
            account_id : accountId,
            public_key: expectedKey.getPublicKey(),
            secret_key: expectedKey.getSecretKey(),
            network_id: 'other network'
        };
        try {
            await keystore.setKeyFromJson(json);
            fail('setting key for wrong network should have failed');
        } catch (e) {
            expect(e).toEqual(new Error('Setting key for a wrong network'));
        }
    });
});
'''
'''--- nearlib/test/integration.test.js ---
const { Account, KeyPair, Near, InMemoryKeyStore } = require('../');
const  { aliceAccountName, newAccountCodeHash, storageAccountIdKey, createFakeStorage, sleep } = require('./test-utils');
const dev = require('../dev');
const fs = require('fs');
let nearjs;
let account;
let keyStore;
let networkId;

beforeAll(async () => {
    // To avoid nonce collisions with promise test on alice
    await sleep(3000);

    networkId = 'somenetwork';
    keyStore = new InMemoryKeyStore(networkId);
    const storage = createFakeStorage();
    nearjs = await dev.connect({
        nodeUrl: 'http://localhost:3030',
        useDevAccount: true,
        networkId: networkId,
        deps: { keyStore, storage },
    });
    account = new Account(nearjs.nearClient);
});

test('test creating default config', async () => {
    // Make sure createDefaultConfig doesn't crash.
    Near.createDefaultConfig();
});

describe('dev connect', () => {
    let deps;
    let options;
    beforeEach(async () => {
        const keyStore = new InMemoryKeyStore(networkId);
        const storage = createFakeStorage();
        deps = {
            keyStore,
            storage,
            createAccount: dev.createAccountWithLocalNodeConnection
        };
        options = {
            deps,
        };
    });

    test('test dev connect like template', async () => {
        window.localStorage = createFakeStorage();
        // Mocking some
        let tmpCreate = dev.createAccountWithContractHelper;
        let devConfig = dev.getConfig;
        dev.getConfig = async () => 'THE_CONFIG';
        dev.createAccountWithContractHelper = async (nearConfig, newAccountId, publicKey) => {
            expect(nearConfig).toEqual('THE_CONFIG');
            return await dev.createAccountWithLocalNodeConnection(newAccountId, publicKey);
        };
        // Calling
        let near = await dev.connect();
        // Restoring mocked functions
        dev.getConfig = devConfig;
        dev.createAccountWithContractHelper = tmpCreate;
        let accId = dev.myAccountId;
        let accjs = new Account(near.nearClient);
        const viewAccountResponse = await accjs.viewAccount(accId);
        expect(viewAccountResponse.account_id).toEqual(accId);
    });

    test('test dev connect with git no account creates a new account', async () => {
        await dev.connect(options);
        expect(Object.keys(deps.keyStore.keys).length).toEqual(2); // one key for dev account and one key for the new account.
        const newAccountId = deps.storage.getItem(storageAccountIdKey);
        const viewAccountResponse = await account.viewAccount(newAccountId);
        const newAccountKeyPair = await deps.keyStore.getKey(newAccountId);
        expect(newAccountKeyPair).toBeTruthy();
        const expectedAccount = {
            nonce: 0,
            account_id: newAccountId,
            amount: 1,
            code_hash: newAccountCodeHash,
            public_keys: viewAccountResponse.public_keys,
            stake: 0,
        };
        expect(viewAccountResponse).toEqual(expectedAccount);
        expect(deps.storage.getItem(storageAccountIdKey)).toEqual(newAccountId);
    });

    test('test dev connect with invalid account in storage creates a new account', async () => {
        // set up invalid account id in local storage
        deps.storage.setItem(storageAccountIdKey, await generateUniqueString('invalid'));
        await dev.connect(options);
        expect(Object.keys(deps.keyStore.keys).length).toEqual(2);
        const newAccountId = deps.storage.getItem(storageAccountIdKey);
        const viewAccountResponse = await account.viewAccount(newAccountId);
        const newAccountKeyPair = await deps.keyStore.getKey(newAccountId);
        expect(newAccountKeyPair).toBeTruthy();
        const expectedAccount = {
            nonce: 0,
            account_id: newAccountId,
            amount: 1,
            code_hash: newAccountCodeHash,
            public_keys: viewAccountResponse.public_keys,
            stake: 0,
        };
        expect(viewAccountResponse).toEqual(expectedAccount);
        expect(deps.storage.getItem(storageAccountIdKey)).toEqual(newAccountId);
    });

    test('test dev connect with valid account but no keys', async () => {
        // setup: connect with dev, but rmemove keys afterwards!
        deps.storage.setItem(storageAccountIdKey, await generateUniqueString('invalid'));
        await dev.connect(options);
        expect(Object.keys(deps.keyStore.keys).length).toEqual(2);
        const newAccountId = deps.storage.getItem(storageAccountIdKey);
        expect(deps.storage.getItem(storageAccountIdKey)).toEqual(newAccountId);
        await deps.keyStore.clear();
        await dev.connect(options);
        // we are expecting account to be recreated!
        expect(deps.storage.getItem(storageAccountIdKey)).not.toEqual(newAccountId);
    });
});

test('view pre-defined account works and returns correct name', async () => {
    // We do not want to check the other properties of this account since we create other accounts
    // using this account as the originator
    const viewAccountResponse = await account.viewAccount(aliceAccountName);
    expect(viewAccountResponse.account_id).toEqual(aliceAccountName);
});

test('create account and then view account returns the created account', async () => {
    const newAccountName = await generateUniqueString('create.account.test');
    const newAccountPublicKey = '9AhWenZ3JddamBoyMqnTbp7yVbRuvqAv3zwfrWgfVRJE';
    const createAccountResponse = await account.createAccount(newAccountName, newAccountPublicKey, 0, aliceAccountName);
    await nearjs.waitForTransactionResult(createAccountResponse);
    const result = await account.viewAccount(newAccountName);
    const expectedAccount = {
        nonce: 0,
        account_id: newAccountName,
        amount: 0,
        code_hash: newAccountCodeHash,
        public_keys: result.public_keys,
        stake: 0,
    };
    expect(result).toEqual(expectedAccount);
});

test('create account with a new key and then view account returns the created account', async () => {
    const newAccountName = await generateUniqueString('create.randomkey.test');
    const amount = 2;
    const aliceAccountBeforeCreation = await account.viewAccount(aliceAccountName);
    const createAccountResponse = await account.createAccountWithRandomKey(
        newAccountName,
        amount,
        aliceAccountName);
    await nearjs.waitForTransactionResult(createAccountResponse);
    expect(createAccountResponse['key']).not.toBeFalsy();
    const result = await account.viewAccount(newAccountName);
    const expectedAccount = {
        nonce: 0,
        account_id: newAccountName,
        amount: amount,
        code_hash: newAccountCodeHash,
        public_keys: result.public_keys,
        stake: 0,
    };
    expect(result).toEqual(expectedAccount);
    const aliceAccountAfterCreation = await account.viewAccount(aliceAccountName);
    expect(aliceAccountAfterCreation.amount).toBe(aliceAccountBeforeCreation.amount - amount);
});

describe('with access key', function () {
    let oldLog;
    let logs;
    let contractId = 'test_contract_' + Date.now();
    let newAccountId;
    let newAccountKeyPair;

    beforeAll(async () => {
        const keyWithRandomSeed = KeyPair.fromRandomSeed();
        const createAccountResponse = await account.createAccount(
            contractId,
            keyWithRandomSeed.getPublicKey(),
            10,
            aliceAccountName);
        await nearjs.waitForTransactionResult(createAccountResponse);
        await keyStore.setKey(contractId, keyWithRandomSeed);
        const data = [...fs.readFileSync('../tests/hello.wasm')];
        await nearjs.waitForTransactionResult(
            await nearjs.deployContract(contractId, data));

    });

    beforeEach(async () => {
        oldLog = console.log;
        logs = [];
        console.log = function() {
            logs.push(Array.from(arguments).join(' '));
        };

        newAccountId = await generateUniqueString('create.account.test');
        newAccountKeyPair = KeyPair.fromRandomSeed();
        const createAccountResponse = await account.createAccount(
            newAccountId,
            newAccountKeyPair.getPublicKey(),
            0,
            aliceAccountName);
        await nearjs.waitForTransactionResult(createAccountResponse);
        await keyStore.setKey(newAccountId, newAccountKeyPair);
    });

    afterEach(async () => {
        console.log = oldLog;
    });

    test('make function calls using access key', async () => {
        // Adding access key
        const keyForAccessKey = KeyPair.fromRandomSeed();
        const addAccessKeyResponse = await account.addAccessKey(
            newAccountId,
            keyForAccessKey.getPublicKey(),
            contractId,
            '',  // methodName
            '',  // fundingOwner
            0,  // fundingAmount
        );
        await nearjs.waitForTransactionResult(addAccessKeyResponse);
        // Replacing public key for the account with the access key
        await keyStore.setKey(newAccountId, keyForAccessKey);
        // test that load contract works and we can make calls afterwards
        const contract = await nearjs.loadContract(contractId, {
            viewMethods: ['getValue'],
            changeMethods: ['setValue'],
            sender: newAccountId,
        });
        const setCallValue2 = await generateUniqueString('setCallPrefix');
        const setValueResult = await contract.setValue({ value: setCallValue2 });
        expect(setValueResult.status).toBe('Completed');
        const getValueResult2 = await contract.getValue();
        expect(getValueResult2).toEqual(setCallValue2);
    });

});

describe('with deployed contract', () => {
    let contract;
    let oldLog;
    let logs;
    let contractName = 'test_contract_' + Date.now();
    let networkId = 'somenetwork';

    beforeAll(async () => {
        // See README.md for details about this contract source code location.
        const keyWithRandomSeed = KeyPair.fromRandomSeed();
        const createAccountResponse = await account.createAccount(
            contractName,
            keyWithRandomSeed.getPublicKey(),
            10,
            aliceAccountName);
        await nearjs.waitForTransactionResult(createAccountResponse);
        keyStore.setKey(contractName, keyWithRandomSeed, networkId);
        const data = [...fs.readFileSync('../tests/hello.wasm')];
        await nearjs.waitForTransactionResult(
            await nearjs.deployContract(contractName, data));
        contract = await nearjs.loadContract(contractName, {
            sender: aliceAccountName,
            viewMethods: ['getAllKeys', 'returnHiWithLogs'],
            changeMethods: ['generateLogs', 'triggerAssert', 'testSetRemove']
        });
    });

    beforeEach(async () => {
        oldLog = console.log;
        logs = [];
        console.log = function() {
            logs.push(Array.from(arguments).join(' '));
        };
    });

    afterEach(async () => {
        console.log = oldLog;
    });

    test('make function calls raw', async () => {
        const viewFunctionResult = await nearjs.callViewFunction(
            contractName,
            'hello', // this is the function defined in hello.wasm file that we are calling
            { name: 'trex' });
        expect(viewFunctionResult).toEqual('hello trex');

        const setCallValue = await generateUniqueString('setCallPrefix');
        const scheduleResult = await nearjs.scheduleFunctionCall(
            0,
            aliceAccountName,
            contractName,
            'setValue', // this is the function defined in hello.wasm file that we are calling
            { value: setCallValue });
        expect(scheduleResult.hash).not.toBeFalsy();
        const result = await nearjs.waitForTransactionResult(scheduleResult);
        expect(result.lastResult).toEqual(setCallValue);
        const getValueResult = await nearjs.callViewFunction(
            contractName,
            'getValue', // this is the function defined in hello.wasm file that we are calling
            {});
        expect(getValueResult).toEqual(setCallValue);
    });

    test('make function calls wrapped', async () => {
        // test that load contract works and we can make calls afterwards
        const contract = await nearjs.loadContract(contractName, {
            viewMethods: ['hello', 'getValue'],
            changeMethods: ['setValue'],
            sender: aliceAccountName,
        });
        const helloResult = await contract.hello({ name: 'trex' });
        expect(helloResult).toEqual('hello trex');
        const setCallValue2 = await generateUniqueString('setCallPrefix');
        const setValueResult = await contract.setValue({ value: setCallValue2 });
        expect(setValueResult.status).toBe('Completed');
        const getValueResult2 = await contract.getValue();
        expect(getValueResult2).toEqual(setCallValue2);
    });

    test('can get logs from method result', async () => {
        await contract.generateLogs();
        expect(logs).toEqual([`[${contractName}]: LOG: log1`, `[${contractName}]: LOG: log2`]);
    });

    test('can get logs from view call', async () => {
        let result = await contract.returnHiWithLogs();
        expect(result).toEqual('Hi');
        expect(logs).toEqual([`[${contractName}]: LOG: loooog1`, `[${contractName}]: LOG: loooog2`]);
    });

    test('can get assert message from method result', async () => {
        await expect(contract.triggerAssert()).rejects.toThrow(/Transaction .+ failed.+expected to fail/);
        expect(logs.length).toBe(3);
        expect(logs[0]).toEqual(`[${contractName}]: LOG: log before assert`);
        expect(logs[1]).toMatch(new RegExp(`^\\[${contractName}\\]: ABORT: "expected to fail" filename: "../out/main.ts" line: \\d+ col: \\d+$`));
        expect(logs[2]).toEqual(`[${contractName}]: Runtime error: wasm async call execution failed with error: Wasmer("call error: Call error: user-defined, opaque")`);
    });

    test('test set/remove', async () => {
        const result = await contract.testSetRemove({value: '123'});
        expect(result.status).toBe('Completed');
    });
});

// Generate some unique string with a given prefix using the alice nonce.
const generateUniqueString = async (prefix) => {
    const viewAccountResponse = await account.viewAccount(aliceAccountName);
    return prefix + viewAccountResponse.nonce;
};

'''
'''--- nearlib/test/promise.test.js ---
const { Account, KeyPair, InMemoryKeyStore } = require('../');
const  { aliceAccountName, createFakeStorage } = require('./test-utils');
const dev = require('../dev');
const fs = require('fs');
let nearjs;
let account;
let mainTestAccountName;
let keyStore;
let storage;

beforeAll(async () => {
    keyStore = new InMemoryKeyStore('somenetwork');
    storage = createFakeStorage();
    nearjs = await dev.connect({
        nodeUrl: 'http://localhost:3030',
        useDevAccount: true,
        deps: { keyStore, storage },
        network: 'somenetwork'
    });

    account = new Account(nearjs.nearClient);

    mainTestAccountName = 'dev_acc_' + Math.random();
    const keyWithRandomSeed = KeyPair.fromRandomSeed();
    const createAccountResponse = await account.createAccount(
        mainTestAccountName,
        keyWithRandomSeed.getPublicKey(),
        1000,
        aliceAccountName);
    await nearjs.waitForTransactionResult(createAccountResponse);
    await keyStore.setKey(mainTestAccountName, keyWithRandomSeed);
});

describe('with promises', () => { 
    let contract, contract1, contract2;
    let oldLog;
    let logs;
    let contractName = 'test_' + Date.now();
    let contractName1 = 'test_' + Math.random();
    let contractName2 = 'test_' + Math.random();

    jasmine.DEFAULT_TIMEOUT_INTERVAL = 20000;

    const deploy = async (contractName) => {
        const keyWithRandomSeed = KeyPair.fromRandomSeed();
        const createAccountResponse = await account.createAccount(
            contractName,
            keyWithRandomSeed.getPublicKey(),
            1,
            mainTestAccountName);
        await nearjs.waitForTransactionResult(createAccountResponse);
        keyStore.setKey(contractName, keyWithRandomSeed);
        const data = [...fs.readFileSync('../tests/hello.wasm')];
        await nearjs.waitForTransactionResult(
            await nearjs.deployContract(contractName, data));
        return await nearjs.loadContract(contractName, {
            sender: mainTestAccountName,
            viewMethods: ['getLastResult'],
            changeMethods: ['callPromise']
        });
    };

    beforeAll(async () => {
        // See README.md for details about this contract source code location.
        contract = await deploy(contractName);
        contract1 = await deploy(contractName1);
        contract2 = await deploy(contractName2);
    });

    beforeEach(async () => {
        oldLog = console.log;
        logs = [];
        console.log = function() {
            logs.push(Array.from(arguments).join(' '));
        };
    });

    afterEach(async () => {
        console.log = oldLog;
    });

    // -> means async call 
    // => means callback

    test('single promise, no callback (A->B)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callbackWithName',
            args: null,
            additionalMana: 0,
            callback: null,
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult = await contract1.getLastResult();
        expect(lastResult).toEqual({
            rs: [],
            n: contractName1,
        });
    });

    test('single promise with callback (A->B=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callbackWithName',
            args: null,
            additionalMana: 0,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult1 = await contract1.getLastResult();
        expect(lastResult1).toEqual({
            rs: [],
            n: contractName1,
        });
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: lastResult1,
            }],
            n: contractName,
        });
    });

    test('two promises, no callbacks (A->B->C)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callPromise',
            args: {
                receiver: contractName2,
                methodName: 'callbackWithName',
                args: null,
                additionalMana: 0,
                callback: null,
                callbackArgs: null,
                callbackAdditionalMana: 0,
            },
            additionalMana: 1,
            callback: null,
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult2 = await contract2.getLastResult();
        expect(lastResult2).toEqual({
            rs: [],
            n: contractName2,
        });
    });

    test('two promises, with two callbacks (A->B->C=>B=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callPromise',
            args: {
                receiver: contractName2,
                methodName: 'callbackWithName',
                args: null,
                additionalMana: 0,
                callback: 'callbackWithName',
                callbackArgs: null,
                callbackAdditionalMana: 0,
            },
            additionalMana: 2,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult2 = await contract2.getLastResult();
        expect(lastResult2).toEqual({
            rs: [],
            n: contractName2,
        });
        const lastResult1 = await contract1.getLastResult();
        expect(lastResult1).toEqual({
            rs: [{
                ok: true,
                r: lastResult2,
            }],
            n: contractName1,
        });
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: lastResult1,
            }],
            n: contractName,
        });
    });

    test('cross contract call with callbacks (A->B->A=>B=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callPromise',
            args: {
                receiver: contractName,
                methodName: 'callbackWithName',
                args: null,
                additionalMana: 0,
                callback: 'callbackWithName',
                callbackArgs: null,
                callbackAdditionalMana: 0,
            },
            additionalMana: 2,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult1 = await contract1.getLastResult();
        expect(lastResult1).toEqual({
            rs: [{
                ok: true,
                r: {
                    rs: [],
                    n: contractName,
                },
            }],
            n: contractName1,
        });
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: lastResult1,
            }],
            n: contractName,
        });
    });

    test('2 promises with 1 skipped callbacks (A->B->C=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callPromise',
            args: {
                receiver: contractName2,
                methodName: 'callbackWithName',
                args: null,
                additionalMana: 0,
                callback: null,
                callbackArgs: null,
                callbackAdditionalMana: 0,
            },
            additionalMana: 1,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult2 = await contract2.getLastResult();
        expect(lastResult2).toEqual({
            rs: [],
            n: contractName2,
        });
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: lastResult2,
            }],
            n: contractName,
        });
    });

    test('single promise with callback using deposit (empty method name) (A->B=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: '',  // Deposit (no execution)
            args: null,
            additionalMana: 0,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: null,
            }],
            n: contractName,
        });
    });

    test('2 promises with 1 skipped callbacks using deposit (empty method name) (A->B->C=>A)', async () => {
        const result = await contract.callPromise({args: {
            receiver: contractName1,
            methodName: 'callPromise',
            args: {
                receiver: contractName2,
                methodName: '',  // Deposit (no execution)
                args: null,
                additionalMana: 0,
                callback: null,
                callbackArgs: null,
                callbackAdditionalMana: 0,
            },
            additionalMana: 1,
            callback: 'callbackWithName',
            callbackArgs: null,
            callbackAdditionalMana: 0,
        }});
        expect(result.status).toBe('Completed');
        const lastResult = await contract.getLastResult();
        expect(lastResult).toEqual({
            rs: [{
                ok: true,
                r: null,
            }],
            n: contractName,
        });
    });
});

'''
'''--- nearlib/test/test-utils.js ---
const aliceAccountName = 'alice.near';
// every new account has this codehash
const newAccountCodeHash = 'GKot5hBsd81kMupNCXHaqbhv3huEbxAFMLnpcX2hniwn';
const storageAccountIdKey = 'dev_near_user';

const createFakeStorage = function() {
    let store = {};
    return {
        getItem: function(key) {
            return store[key];
        },
        setItem: function(key, value) {
            store[key] = value.toString();
        },
        clear: function() {
            store = {};
        },
        removeItem: function(key) {
            delete store[key];
        }
    };
};

function sleep(time) {
    return new Promise(function (resolve) {
        setTimeout(resolve, time);
    });
}

module.exports = { aliceAccountName, newAccountCodeHash, storageAccountIdKey, createFakeStorage, sleep };

'''
'''--- nearlib/test/unencrypted_file_system_keystore.test.js ---
const UnencryptedFileSystemKeyStore = require('../signing/unencrypted_file_system_keystore.js');

const KeyPair = require('../signing/key_pair.js');

const NETWORK_ID_SINGLE_KEY = 'singlekeynetworkid';
const ACCOUNT_ID_SINGLE_KEY = 'singlekeyaccountid';
const KEYPAIR_SINGLE_KEY = new KeyPair('public', 'secret');

describe('Unencrypted file system keystore', () => {
    let keyStore;

    beforeAll(async () => {
        keyStore = new UnencryptedFileSystemKeyStore('../tests', NETWORK_ID_SINGLE_KEY);
        await keyStore.setKey(ACCOUNT_ID_SINGLE_KEY, KEYPAIR_SINGLE_KEY);
    });

    test('Get all keys with empty network returns empty list', async () => {
        const emptyList = await new UnencryptedFileSystemKeyStore('../tests', 'emptynetowrk').getAccountIds();
        expect(emptyList).toEqual([]);
    });  
    
    test('Get all keys with single key in keystore', async () => {
        const accountIds = await keyStore.getAccountIds();
        expect(accountIds).toEqual([ACCOUNT_ID_SINGLE_KEY]);
    });

    test('Get account id from empty keystore', async () => {
        const key = await keyStore.getKey('someaccount', 'somenetowrk');
        expect(key).toBeNull();
    });

    test('Get account id from a network with single key', async () => {
        const key = await keyStore.getKey(ACCOUNT_ID_SINGLE_KEY);
        expect(key).toEqual(KEYPAIR_SINGLE_KEY);
    });

    test('Add two keys to network and retrieve them', async () => {
        const networkId = 'twoKeyNetwork';
        const newNetworkKeystore = new UnencryptedFileSystemKeyStore('../tests', networkId);
        const accountId1 = 'acc1';
        const accountId2 = 'acc2';
        const key1Expected = new KeyPair('p1', 's1');
        const key2Expected = new KeyPair('p2', 's2');
        await newNetworkKeystore.setKey(accountId1, key1Expected);
        await newNetworkKeystore.setKey(accountId2, key2Expected);
        const key1 = await newNetworkKeystore.getKey(accountId1);
        const key2 = await newNetworkKeystore.getKey(accountId2);
        expect(key1).toEqual(key1Expected);
        expect(key2).toEqual(key2Expected);
        const accountIds = await newNetworkKeystore.getAccountIds();
        expect(accountIds).toEqual([accountId1, accountId2]);
    });
});
'''
'''--- nearlib/wallet-access-key.js ---
/**
 * Access Key based signer that uses Wallet to authorize app on the account and receive the access key.
 */

const KeyPair = require('./signing/key_pair');
const BrowserLocalStorageKeystore = require('./signing/browser_local_storage_key_store');
const SimpleKeyStoreSigner = require('./signing/simple_key_store_signer');

const LOGIN_WALLET_URL_SUFFIX = '/login_v2/';
const LOCAL_STORAGE_KEY_SUFFIX = '_wallet_access_key';

/**
 * Access Key based signer that uses Wallet to authorize app on the account and receive the access key.
 * @example
 * // if importing WalletAccessKey directly
 * const walletAccount = new WalletAccessKey(contractName, walletBaseUrl)
 * // if importing in all of nearLib and calling from variable
 * const walletAccount = new nearlib.WalletAccessKey(contractName, walletBaseUrl)
 * // To access this signer globally
 * window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl);
 * // To provide custom signer where the keys would be stored
 * window.walletAccount = new nearlib.WalletAccessKey(config.contractName, walletBaseUrl, customSigner);
 */
class WalletAccessKey {
    constructor(appKeyPrefix, walletBaseUrl = 'https://wallet.nearprotocol.com', signer = null) {
        this._walletBaseUrl = walletBaseUrl;
        this._authDataKey = appKeyPrefix + LOCAL_STORAGE_KEY_SUFFIX;
        this._signer = signer || (new SimpleKeyStoreSigner(new BrowserLocalStorageKeystore()));

        this._authData = JSON.parse(window.localStorage.getItem(this._authDataKey) || '{}');

        if (!this.isSignedIn()) {
            this._tryInitFromUrl();
        }
    }

    /**
     * Returns true, if this WalletAccount is authorized with the wallet.
     * @example
     * walletAccount.isSignedIn();
     */
    isSignedIn() {
        return !!this._authData.accountId;
    }

    /**
     * Returns authorized Account ID.
     * @example
     * walletAccount.getAccountId();
     */
    getAccountId() {
        return this._authData.accountId || '';
    }

    /**
     * Redirects current page to the wallet authentication page.
     * @param {string} contractId contract ID of the application
     * @param {string} title name of the application
     * @param {string} successUrl url to redirect on success
     * @param {string} failureUrl url to redirect on failure
     */
    requestSignIn(contractId, title, successUrl, failureUrl) {
        this._authData.key = KeyPair.fromRandomSeed();
        const currentUrl = new URL(window.location.href);
        let newUrl = new URL(this._walletBaseUrl + LOGIN_WALLET_URL_SUFFIX);
        newUrl.searchParams.set('title', title);
        newUrl.searchParams.set('contract_id', contractId);
        newUrl.searchParams.set('public_key', this._authData.key.getPublicKey());
        newUrl.searchParams.set('success_url', successUrl || currentUrl.href);
        newUrl.searchParams.set('failure_url', failureUrl || currentUrl.href);
        newUrl.searchParams.set('app_url', currentUrl.origin);
        window.location.replace(newUrl.toString());
    }
    /**
     * Sign out from the current account
     * @example
     * walletAccount.signOut();
     */
    signOut() {
        if (this._authData.accountId) {
            this._signer.keyStore.setKey(this.getAccountId(), null).catch(console.error);
            this._authData = {};
            window.localStorage.removeItem(this._authDataKey);
        }
    }

    _saveAuthData() {
        window.localStorage.setItem(this._authDataKey, JSON.stringify(this._authData));
    }

    _tryInitFromUrl() {
        if (this._authData.key) {
            let currentUrl = new URL(window.location.href);
            let publicKey = currentUrl.searchParams.get('public_key') || '';
            let accountId = currentUrl.searchParams.get('account_id') || '';
            if (accountId && publicKey === this._authData.key.getPublicKey()) {
                this._signer.keyStore.setKey(accountId, this._authData.key);
                this._authData = {
                    accountId,
                    publicKey,
                };
                this._saveAuthData();
            }
        }
    }

    /**
     * Sign a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        if (!this.isSignedIn() || originator !== this.getAccountId()) {
            throw 'Unauthorized account_id ' + originator;
        }
        return await this._signer.signBuffer(buffer, originator);
    }

}

module.exports = WalletAccessKey;

'''
'''--- nearlib/wallet-account.js ---
/**
 * Wallet based account and signer that uses external wallet through the iframe to sign transactions.
 */

const { sha256 } = require('js-sha256');
const { FunctionCallTransaction } = require('./protos');

const EMBED_WALLET_URL_SUFFIX = '/embed/';
const LOGIN_WALLET_URL_SUFFIX = '/login/';
const RANDOM_ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
const REQUEST_ID_LENGTH = 32;

const LOCAL_STORAGE_KEY_SUFFIX = '_wallet_auth_key';

/**
 * Wallet based account and signer that uses external wallet through the iframe to sign transactions.
 * @example 
 * // if importing WalletAccount directly
 * const walletAccount = new WalletAccount(contractName, walletBaseUrl)
 * // if importing in all of nearLib and calling from variable 
 * const walletAccount = new nearlib.WalletAccount(contractName, walletBaseUrl)
 * // To access wallet globally use:
 * window.walletAccount = new nearlib.WalletAccount(config.contractName, walletBaseUrl);
 */
class WalletAccount {

    constructor(appKeyPrefix, walletBaseUrl = 'https://wallet.nearprotocol.com') {
        this._walletBaseUrl = walletBaseUrl;
        this._authDataKey = appKeyPrefix + LOCAL_STORAGE_KEY_SUFFIX;

        this._initHtmlElements();
        this._signatureRequests = {};
        this._authData = JSON.parse(window.localStorage.getItem(this._authDataKey) || '{}');

        if (!this.isSignedIn()) {
            this._tryInitFromUrl();
        }
    }

    /**
     * Returns true, if this WalletAccount is authorized with the wallet.
     * @example
     * walletAccount.isSignedIn();
     */
    isSignedIn() {
        return !!this._authData.accountId;
    }

    /**
     * Returns authorized Account ID.
     * @example 
     * walletAccount.getAccountId();
     */
    getAccountId() {
        return this._authData.accountId || '';
    }

    /**
     * Redirects current page to the wallet authentication page.
     * @param {string} contract_id contract ID of the application
     * @param {string} title name of the application
     * @param {string} success_url url to redirect on success
     * @param {string} failure_url url to redirect on failure
     * @example
     *   walletAccount.requestSignIn(
     *     myContractId,
     *     title,
     *     onSuccessHref,
     *     onFailureHref);
     */
    requestSignIn(contract_id, title, success_url, failure_url) {
        const currentUrl = new URL(window.location.href);
        let newUrl = new URL(this._walletBaseUrl + LOGIN_WALLET_URL_SUFFIX);
        newUrl.searchParams.set('title', title);
        newUrl.searchParams.set('contract_id', contract_id);
        newUrl.searchParams.set('success_url', success_url || currentUrl.href);
        newUrl.searchParams.set('failure_url', failure_url || currentUrl.href);
        newUrl.searchParams.set('app_url', currentUrl.origin);
        window.location.replace(newUrl.toString());
    }
    /**
     * Sign out from the current account
     * @example
     * walletAccount.signOut();
     */
    signOut() {
        this._authData = {};
        window.localStorage.removeItem(this._authDataKey);
    }

    _tryInitFromUrl() {
        let currentUrl = new URL(window.location.href);
        let authToken = currentUrl.searchParams.get('auth_token') || '';
        let accountId = currentUrl.searchParams.get('account_id') || '';
        if (!!authToken && !!accountId) {
            this._authData = {
                authToken,
                accountId,
            };
            window.localStorage.setItem(this._authDataKey, JSON.stringify(this._authData));
        }
    }

    _initHtmlElements() {
        // Wallet iframe
        const iframe = document.createElement('iframe');
        iframe.style = 'display: none;';
        iframe.src = this._walletBaseUrl + EMBED_WALLET_URL_SUFFIX;
        document.body.appendChild(iframe);
        this._walletWindow = iframe.contentWindow;

        // Message Event
        window.addEventListener('message', this.receiveMessage.bind(this), false);
    }

    receiveMessage(event) {
        if (!this._walletBaseUrl.startsWith(event.origin)) {
            // Only processing wallet messages.
            console.log('Wallet account ignoring message from ' + event.origin);
            return;
        }
        let data;
        try {
            data = JSON.parse(event.data);
        } catch (e) {
            console.error('Can\'t parse the result', event.data, e);
            return;
        }
        const request_id = data.request_id || '';
        if (!(request_id in this._signatureRequests)) {
            console.error('Request ID' + request_id + ' was not found');
            return;
        }
        let signatureRequest = this._signatureRequests[request_id];
        delete this._signatureRequests[request_id];

        if (data.success) {
            signatureRequest.resolve(data.result);
        } else {
            signatureRequest.reject(data.error);
        }
    }

    _randomRequestId() {
        var result = '';

        for (var i = 0; i < REQUEST_ID_LENGTH; i++) {
            result += RANDOM_ALPHABET.charAt(Math.floor(Math.random() * RANDOM_ALPHABET.length));
        }

        return result;
    }

    _remoteSign(hash, methodName, args) {
        // TODO(#482): Add timeout.
        return new Promise((resolve, reject) => {
            const request_id = this._randomRequestId();
            this._signatureRequests[request_id] = {
                request_id,
                resolve,
                reject,
            };
            this._walletWindow.postMessage(JSON.stringify({
                action: 'sign_transaction',
                token: this._authData.authToken,
                method_name: methodName,
                args: args || {},
                hash,
                request_id,
            }), this._walletBaseUrl);
        });
    }

    /**
     * Sign a buffer. If the key for originator is not present,
     * this operation will fail.
     * @param {Uint8Array} buffer
     * @param {string} originator
     */
    async signBuffer(buffer, originator) {
        if (!this.isSignedIn() || originator !== this.getAccountId()) {
            throw 'Unauthorized account_id ' + originator;
        }
        const body = FunctionCallTransaction.decode(buffer);
        let methodName = Buffer.from(body.methodName).toString();
        let args = JSON.parse(Buffer.from(body.args).toString());
        let signature = await this._remoteSign(sha256.array(buffer), methodName, args);
        return {
            signature,
        };
    }

}

module.exports = WalletAccount;

'''
'''--- ops/README.md ---
# NEAR Application Layer with Tendermint Consensus

#### Table of contents

1. [Running Locally](#running-locally)
2. [Running Remotely](#running-remotely)
3. [Developing NEAR Runtime](#developing-near-runtime)
4. [Building and Pushing Docker Image](#building-and-pushing-docker-image)

## Running Locally

To run NEAR locally you would need docker, see [installation instructions](https://www.docker.com/get-started).
Then run the following:
```bash
./ops/deploy_local.sh
```

After it starts you can open studio at [http://localhost](http://localhost).

To tear it down run:
```bash
./ops/teardown_local.sh
```

Note, it is not advised to run more than two nodes locally, especially on low performance machines. While the network
itself is able to function and produce blocks, the development tools might currently timeout on certain commands,
because the nodes do not produce blocks fast enough.

## Running Remotely
Similarly you deploy the network to the GCloud:
```bash
./ops/deploy_remote.sh
```
When the network is deployed it will print the address of the studio.

## Developing NEAR Runtime
This section is for those who want to develop the NEAR Runtime. If you only want to develop dApps then the above sections suffice.
Developing NEAR Runtime locally requires more installation and configuration.

### Installation

This mode of running requires compilation of the Rust code and installed Tendermint.

**1. Dependencies**

Install protobufs:
```bash
# Mac OS:
brew install protobuf

# Ubuntu:
apt-get install protobuf-compiler
```

**2. Rust**

Currently, the only way to install NEARMint application layer is to compile it from the source.
For that we would need to install Rust.

```bash
curl https://sh.rustup.rs -sSf | sh
rustup component add clippy-preview
rustup default nightly
```

**3. Source code**

We would need to copy the entire repository:

```bash
git clone https://github.com/nearprotocol/nearcore
cd nearcore
```

**4. Tendermint**

Follow the official instructions to install Tendermint: https://tendermint.com/docs/introduction/install.html

### Configure and run

To configure Tendermint run:

```bash
tendermint init
```

Configure Tendermint to use `3030` for its RPC. Open `~/.tendermint/config/config.toml` and change:
```yaml
[rpc]
laddr = "tcp://0.0.0.0:3030"
```

For local development we also recommend setting:
```yaml
create_empty_blocks = false
```

First, we want to set `alice.near` as a single validator. Open `~/.tendermint/config/priv_validator_key.json` and replace with:

```json
{
  "address": "27B2B6C138DDF7B77E4318A22CAE1A38F55AA29A",
  "pub_key": {
    "type": "tendermint/PubKeyEd25519",
    "value": "D1al8CjfwInsfDnBGDsyG02Pibpb7J4XYoA8wkkfbvg="
  },
  "priv_key": {
    "type": "tendermint/PrivKeyEd25519",
    "value": "YWxpY2UubmVhciAgICAgICAgICAgICAgICAgICAgICAPVqXwKN/Aiex8OcEYOzIbTY+JulvsnhdigDzCSR9u+A=="
  }
}
```

Navigate to the root of the repository, and run:
```bash
cargo run --package nearmint -- --devnet
```

This will start NEARMint in application mode, without consensus backing it up.

To start Tendermint run:
```bash
tendermint node
```

Now we can issue specific commands to the node:
```bash
curl http://localhost:3030/status
curl -s 'localhost:3030/abci_query?path="account/alice.near"'
curl -s 'localhost:3030/validators'
```

See full list of RPC endpoints here: https://tendermint.com/rpc/#endpoints

Unfortunately, transactions can be only submitted in base64 encoding, which is hard to do from the command line.

## Building and Pushing Docker Image

If you have modified the source code of NEAR Runtime and want to see how it performs in prod you would need to build
an docker image from it. Once the docker image is built you can run it locally or remotely.

### Building NEAR Runtime
To build docker image run from the root:
```bash
make docker-nearcore
```

This will build an image with `nearcore` name.

### Running locally

To run this image locally, run:
```bash
./ops/deploy_local.sh nearcore
```

### Running remotely

To run this image remotely we would need to tag and publish it to the docker hub. For instance, when using `nearprotocol` docker hub repo:

```bash
sudo docker tag nearcore nearprotocol/mynearcore
sudo docker push nearprotocol/mynearcore
```

Then run:
```bash
./ops/deploy_remote.sh nearprotocol/mynearcore
```

'''
'''--- ops/deploy_alphanet.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/alphanet:0.1.6}
PREFIX=${2:-alphanet}
STUDIO_IMAGE=${3:-nearprotocol/studio:0.1.8}
ZONE=${4:-us-west2-a}
REGION=${5:-us-west2}

echo "Starting 4 nodes prefixed ${PREFIX} of ${IMAGE} on GCloud ${ZONE} zone..."

set +e
gcloud compute firewall-rules describe alphanet-instance > /dev/null 2>&1
INSTANCE_FIRE_WALL_EXISTS=$?
set -e

if [[ ! ${INSTANCE_FIRE_WALL_EXISTS} -eq 0 ]]; then
gcloud compute firewall-rules create alphanet-instance \
    --allow tcp:3000,tcp:3030 \
    --target-tags=alphanet-instance
fi

gcloud compute disks create --size 200GB --zone ${ZONE} \
    ${PREFIX}-persistent-0 \
    ${PREFIX}-persistent-1 \
    ${PREFIX}-persistent-2 \
    ${PREFIX}-persistent-3

gcloud beta compute addresses create ${PREFIX}-0 --region ${REGION}

gcloud beta compute instances create-with-container ${PREFIX}-0 \
    --container-env BOOT_NODE_IP=127.0.0.1 \
    --container-env NODE_NUM=0 \
    --container-env TOTAL_NODES=4 \
    --container-image ${IMAGE} \
    --zone ${ZONE} \
    --tags=alphanet-instance \
    --disk name=${PREFIX}-persistent-0 \
    --container-mount-disk mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --address ${PREFIX}-0 \
    --machine-type n1-highcpu-4

BOOT_NODE_IP=$(
    gcloud beta compute addresses describe ${PREFIX}-0 --region ${REGION}  | head -n 1 | awk '{print $2}'
)
echo "Connect to boot node: ${BOOT_NODE_IP}:3000/7tkzFg8RHBmMw1ncRJZCCZAizgq4rwCftTKYLce8RU8t"

gcloud beta compute instances create-with-container ${PREFIX}-1 \
    --container-env BOOT_NODE_IP=${BOOT_NODE_IP} \
    --container-env NODE_NUM=1 \
    --container-env TOTAL_NODES=4 \
    --container-image ${IMAGE} \
    --zone ${ZONE} \
    --tags=alphanet-instance \
    --disk=name=${PREFIX}-persistent-1 \
    --container-mount-disk=mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --machine-type n1-highcpu-4

gcloud beta compute instances create-with-container ${PREFIX}-2 \
    --container-env BOOT_NODE_IP=${BOOT_NODE_IP} \
    --container-env NODE_NUM=2 \
    --container-env TOTAL_NODES=4 \
    --container-image ${IMAGE} \
    --zone ${ZONE} \
    --tags=alphanet-instance \
    --disk=name=${PREFIX}-persistent-2 \
    --container-mount-disk=mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --machine-type n1-highcpu-4

gcloud beta compute instances create-with-container ${PREFIX}-3 \
    --container-env BOOT_NODE_IP=${BOOT_NODE_IP} \
    --container-env NODE_NUM=3 \
    --container-env TOTAL_NODES=4 \
    --container-image ${IMAGE} \
    --zone ${ZONE} \
    --tags=alphanet-instance \
    --disk=name=${PREFIX}-persistent-3 \
    --container-mount-disk=mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --machine-type n1-highcpu-4

set +e
gcloud compute firewall-rules describe alphanet-studio > /dev/null 2>&1
STUDIO_FIRE_WALL_EXISTS=$?
set -e

if [[ ! ${STUDIO_FIRE_WALL_EXISTS} -eq 0 ]]; then
gcloud compute firewall-rules create alphanet-studio \
    --allow tcp:80 \
    --target-tags=alphanet-studio
fi

gcloud compute disks create --size 200GB --zone ${ZONE} \
    ${PREFIX}-studio-persistent

gcloud beta compute instances create-with-container ${PREFIX}-studio \
    --container-env DEVNET_HOST=http://${BOOT_NODE_IP} \
    --container-env PLATFORM=GCP \
    --container-image ${STUDIO_IMAGE} \
    --zone ${ZONE} \
    --tags=alphanet-studio \
    --disk=name=${PREFIX}-studio-persistent \
    --container-mount-disk=mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --machine-type n1-standard-2

# borrowed from https://stackoverflow.com/a/20369590
spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [ "$(ps a | awk '{print $1}' | grep $pid)" ]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

STUDIO_IP=$(
gcloud compute instances describe ${PREFIX}-studio \
    --zone ${ZONE} | grep natIP | \
    awk '{print $2}'
)

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I ${STUDIO_IP} 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

echo "Alphanet HTTP interface is accessible at ${BOOT_NODE_IP}:3030"
echo "Waiting for studio instance to start. This could take a few minutes..."
wait_for_studio & spinner
echo "NEARStudio is now accessible at http://${STUDIO_IP}"

'''
'''--- ops/deploy_local.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/nearcore:0.1.5}
STUDIO_IMAGE=${2:-nearprotocol/studio:0.2.4}
TOTAL_NODES=${3:-2}
NUM_ACCOUNTS=${4:-10}
NEARLIB_COMMIT="348509b526cf4ca0495d86cb211d1013d84629a2"
NEARLIB_VERSION="0.5.2"
STUDIO_IP=localhost

sudo docker run -d --name testnet-0 -p 3030:3030 -p 26656:26656 --rm \
	-e "NODE_ID=0" \
	-e "TOTAL_NODES=${TOTAL_NODES}" \
	-e "NODE_KEY=53Mr7IhcJXu3019FX+Ra+VbxSQ5y2q+pknmM463jzoFzldWZb16dSYRxrhYrLRXe/UA0wR2zFy4c3fY5yDHjlA==" \
	-e "PRIVATE_NETWORK=y" \
	-e "NUM_ACCOUNTS=${NUM_ACCOUNTS}" \
	${IMAGE}

for NODE_ID in $(seq 1 `expr $TOTAL_NODES - 1`)
do
sudo docker run -d --name testnet-${NODE_ID} -p $((3030+${NODE_ID})):3030 -p $((26656+${NODE_ID})):26656 \
    --add-host=testnet-0:172.17.0.2 \
	-e "BOOT_NODES=6f99d7b49a10fff319cd8bbbd13c3a964dcd0248@172.17.0.2:26656" \
	-e "NODE_ID=${NODE_ID}" \
	-e "TOTAL_NODES=${TOTAL_NODES}" \
	-e "NUM_ACCOUNTS=${NUM_ACCOUNTS}" \
	-e "PRIVATE_NETWORK=y" \
	${IMAGE}
done

sudo docker run -d --name studio -p 80:80 --add-host=testnet-0:172.17.0.2 --rm \
    -e "DEVNET_HOST=http://172.17.0.2" \
    -e "NEARLIB_COMMIT=${NEARLIB_COMMIT}" \
    -e "NEARLIB_VERSION=${NEARLIB_VERSION}" \
    -e "EXTERNAL_HOST_NAME=http://localhost" \
    ${STUDIO_IMAGE}

spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [ "$(ps a | awk '{print $1}' | grep $pid)" ]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I ${STUDIO_IP} 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

wait_for_studio & spinner
echo "NEARStudio is now accessible at http://${STUDIO_IP}"

'''
'''--- ops/deploy_remote.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/nearcore:0.1.5}
PREFIX=${2:-testnet-${USER}}
STUDIO_IMAGE=${3:-nearprotocol/studio:0.2.4}
ZONE=${4:-us-west2-a}
REGION=${5:-us-west2}
NUM_NODES=${6:-10}
NUM_ACCOUNTS=${7:-400}

echo "Starting ${NUM_NODES} nodes prefixed ${PREFIX} of ${IMAGE} on GCloud ${ZONE} zone..."

set +e
gcloud compute firewall-rules describe nearmint-instance > /dev/null 2>&1
INSTANCE_FIRE_WALL_EXISTS=$?
gcloud beta compute addresses describe ${PREFIX}-0 --region ${REGION} > /dev/null 2>&1
ADDRESS_EXISTS=$?
gcloud beta compute instances describe ${PREFIX}-0 --zone ${ZONE} > /dev/null 2>&1
BOOTNODE_EXISTS=$?
set -e

if [[ ! ${INSTANCE_FIRE_WALL_EXISTS} -eq 0 ]]; then
gcloud compute firewall-rules create nearmint-instance \
    --allow tcp:26656,tcp:3030 \
    --target-tags=nearmint-instance
fi

if [[ ! ${ADDRESS_EXISTS} -eq 0 ]]; then
gcloud beta compute addresses create ${PREFIX}-0 --region ${REGION}
fi

if [[ ! ${BOOTNODE_EXISTS} -eq 0 ]]; then
gcloud beta compute instances create-with-container ${PREFIX}-0 \
    --container-env NODE_ID=0 \
    --container-env TOTAL_NODES=${NUM_NODES} \
    --container-env NUM_ACCOUNTS=${NUM_ACCOUNTS} \
    --container-env NODE_KEY="53Mr7IhcJXu3019FX+Ra+VbxSQ5y2q+pknmM463jzoFzldWZb16dSYRxrhYrLRXe/UA0wR2zFy4c3fY5yDHjlA==" \
    --container-image ${IMAGE} \
    --zone ${ZONE} \
    --tags=nearmint-instance \
    --create-disk=name=${PREFIX}-persistent-0,auto-delete=yes \
    --container-mount-disk mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --address ${PREFIX}-0 \
    --machine-type n1-highcpu-4
fi

BOOT_NODE_IP=$(
    gcloud beta compute addresses describe ${PREFIX}-0 --region ${REGION}  | head -n 1 | awk '{print $2}'
)
echo "Connect to boot node: 6f99d7b49a10fff319cd8bbbd13c3a964dcd0248@${BOOT_NODE_IP}"

for NODE_ID in $(seq 1 `expr $NUM_NODES - 1`)
do

    set +e
    gcloud beta compute instances describe ${PREFIX}-${NODE_ID} --zone ${ZONE} > /dev/null 2>&1
    NODE_EXISTS=$?
    set -e

    if [[ ! ${NODE_EXISTS} -eq 0 ]]; then
    gcloud beta compute instances create-with-container ${PREFIX}-${NODE_ID} \
        --container-env BOOT_NODES="6f99d7b49a10fff319cd8bbbd13c3a964dcd0248@${BOOT_NODE_IP}:26656" \
        --container-env NODE_ID=${NODE_ID} \
	    --container-env TOTAL_NODES=${NUM_NODES} \
        --container-env NUM_ACCOUNTS=${NUM_ACCOUNTS} \
        --container-image ${IMAGE} \
        --zone ${ZONE} \
        --tags=testnet-instance \
        --create-disk=name=${PREFIX}-persistent-${NODE_ID},auto-delete=yes \
        --container-mount-disk=mount-path="/srv/near" \
        --boot-disk-size 200GB \
        --machine-type n1-highcpu-4 &

    fi
done
wait

echo "RPCs of the nodes"
for NODE_IP in $(gcloud compute instances list --filter="name:${PREFIX}*" | grep "RUNNING" | awk '{print $5}')
do
  echo "\"${NODE_IP}:3030\","
done

set +e
gcloud compute firewall-rules describe testnet-studio > /dev/null 2>&1
STUDIO_FIRE_WALL_EXISTS=$?
gcloud compute disks describe ${PREFIX}-studio-persistent  --zone ${ZONE} > /dev/null 2>&1
STUDIO_STORAGE_EXISTS=$?
gcloud beta compute instances describe ${PREFIX}-studio --zone ${ZONE} > /dev/null 2>&1
STUDIO_EXISTS=$?
gcloud beta compute addresses describe ${PREFIX}-studio --region ${REGION} > /dev/null 2>&1
STUDIO_ADDRESS_EXISTS=$?
set -e

if [[ ! ${STUDIO_FIRE_WALL_EXISTS} -eq 0 ]]; then
gcloud compute firewall-rules create testnet-studio \
    --allow tcp:80 \
    --target-tags=testnet-studio
fi

if [[ ! ${STUDIO_STORAGE_EXISTS} -eq 0 ]]; then
gcloud compute disks create --size 200GB --zone ${ZONE} \
    ${PREFIX}-studio-persistent
fi

if [[ ! ${STUDIO_ADDRESS_EXISTS} -eq 0 ]]; then
gcloud beta compute addresses create ${PREFIX}-studio --region ${REGION}
fi

if [[ !${STUDIO_EXISTS} -eq 0 ]]; then
gcloud beta compute instances create-with-container ${PREFIX}-studio \
    --container-env DEVNET_HOST=http://${BOOT_NODE_IP} \
    --container-env NEARLIB_COMMIT="348509b526cf4ca0495d86cb211d1013d84629a2" \
    --container-env NEARLIB_VERSION="0.5.2" \
    --container-env PLATFORM=GCP \
    --container-image ${STUDIO_IMAGE} \
    --zone ${ZONE} \
    --tags=testnet-studio \
    --disk=name=${PREFIX}-studio-persistent \
    --container-mount-disk=mount-path="/srv/near" \
    --boot-disk-size 200GB \
    --address ${PREFIX}-studio \
    --machine-type n1-standard-2
fi

# borrowed from https://stackoverflow.com/a/20369590
spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [ "$(ps a | awk '{print $1}' | grep $pid)" ]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

STUDIO_IP=$(
gcloud compute instances describe ${PREFIX}-studio \
    --zone ${ZONE} | grep natIP | \
    awk '{print $2}'
)

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I ${STUDIO_IP} 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

echo "TestNet HTTP RPC interface is accessible at ${BOOT_NODE_IP}:3030"
echo "Waiting for studio instance to start. This could take a few minutes..."
wait_for_studio & spinner
echo "NEARStudio is now accessible at http://${STUDIO_IP}"

'''
'''--- ops/local_alphanet.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/alphanet:0.1.6}
STUDIO_IMAGE=${2:-nearprotocol/studio:0.1.8}

sudo docker run -d --name alphanet-0 -p 3000:3000 -p 3030:3030 \
    -e "BOOT_NODE_IP=127.0.0.1" \
    -e "NODE_NUM=0" \
    -e "TOTAL_NODES=4" \
    ${IMAGE}

sudo docker run -d --name alphanet-1 --add-host=alphanet-0:172.17.0.2 -p 3031:3030 \
    -e "BOOT_NODE_IP=172.17.0.2" \
    -e "NODE_NUM=1" \
    -e "TOTAL_NODES=4" \
    ${IMAGE}

sudo docker run -d --name alphanet-2 --add-host=alphanet-0:172.17.0.2 -p 3032:3030 \
    -e "BOOT_NODE_IP=172.17.0.2" \
    -e "NODE_NUM=2" \
    -e "TOTAL_NODES=4" \
    ${IMAGE}

sudo docker run -d --name alphanet-3 --add-host=alphanet-0:172.17.0.2 -p 3033:3030 \
    -e "BOOT_NODE_IP=172.17.0.2" \
    -e "NODE_NUM=3" \
    -e "TOTAL_NODES=4" \
    ${IMAGE}

sudo docker run -d --name studio -p 80:80 --add-host=alphanet-0:172.17.0.2 \
    -e "DEVNET_HOST=http://172.17.0.2" \
    ${STUDIO_IMAGE}

# borrowed from https://stackoverflow.com/a/20369590
spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [ "$(ps a | awk '{print $1}' | grep $pid)" ]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I localhost 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

echo "Alphanet HTTP interface is accessible at 127.0.0.1:3030"
echo "Waiting for studio instance to start. This could take a few minutes..."
wait_for_studio & spinner
echo "NEARStudio is now accessible at http://localhost"

'''
'''--- ops/reset_alphanet.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/alphanet:0.1.6}
PREFIX=${2:-alphanet}
ZONE=${3:-us-west2-a}
REGION=${4:-us-west2}

gcloud beta compute instances stop --zone ${ZONE} \
    ${PREFIX}-0 \
    ${PREFIX}-1 \
    ${PREFIX}-2 \
    ${PREFIX}-3

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-0 \
    --remove-container-mounts mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-1 \
    --remove-container-mounts mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-2 \
    --remove-container-mounts mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-3 \
    --remove-container-mounts mount-path="/srv/near"

gcloud beta compute instances detach-disk --zone ${ZONE} ${PREFIX}-0 \
    --disk ${PREFIX}-persistent-0

gcloud beta compute instances detach-disk --zone ${ZONE} ${PREFIX}-1 \
    --disk ${PREFIX}-persistent-1

gcloud beta compute instances detach-disk --zone ${ZONE} ${PREFIX}-2 \
    --disk ${PREFIX}-persistent-2

gcloud beta compute instances detach-disk --zone ${ZONE} ${PREFIX}-3 \
    --disk ${PREFIX}-persistent-3

gcloud compute disks delete --zone ${ZONE} -q \
    ${PREFIX}-persistent-0 \
    ${PREFIX}-persistent-1 \
    ${PREFIX}-persistent-2 \
    ${PREFIX}-persistent-3

gcloud compute disks create --size 200GB --zone ${ZONE} \
    ${PREFIX}-persistent-0 \
    ${PREFIX}-persistent-1 \
    ${PREFIX}-persistent-2 \
    ${PREFIX}-persistent-3

gcloud beta compute instances attach-disk --zone ${ZONE} ${PREFIX}-0 \
    --disk ${PREFIX}-persistent-0 \
    --device-name ${PREFIX}-persistent-0

gcloud beta compute instances attach-disk --zone ${ZONE} ${PREFIX}-1 \
    --disk ${PREFIX}-persistent-1 \
    --device-name ${PREFIX}-persistent-1

gcloud beta compute instances attach-disk --zone ${ZONE} ${PREFIX}-2 \
    --disk ${PREFIX}-persistent-2 \
    --device-name ${PREFIX}-persistent-2

gcloud beta compute instances attach-disk --zone ${ZONE} ${PREFIX}-3 \
    --disk ${PREFIX}-persistent-3 \
    --device-name ${PREFIX}-persistent-3

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-0 \
    --container-mount-disk name="${PREFIX}-persistent-0",mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-1 \
    --container-mount-disk name="${PREFIX}-persistent-1",mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-2 \
    --container-mount-disk name="${PREFIX}-persistent-2",mount-path="/srv/near"

gcloud beta compute instances update-container --zone ${ZONE} ${PREFIX}-3 \
    --container-mount-disk name="${PREFIX}-persistent-3",mount-path="/srv/near"

gcloud beta compute instances start --zone ${ZONE} \
    ${PREFIX}-0 \
    ${PREFIX}-1 \
    ${PREFIX}-2 \
    ${PREFIX}-3

'''
'''--- ops/run.sh ---
#!/bin/bash
set -e

export TMHOME=/srv/near

tendermint init
cp /near/config.toml ${TMHOME}/config/config.toml

if [[ -z ${PRIVATE_NETWORK} ]]
then
echo "Not running on a private network"
else
sed -i 's/addr_book_strict\ =\ true/addr_book_strict\ =\ false/g' ${TMHOME}/config/config.toml
fi

cat << EOF > ${TMHOME}/config/genesis.json
{
  "genesis_time": "2019-04-19T21:02:18.967617Z",
  "chain_id": "test-chain",
  "consensus_params": {
    "block": {
      "max_bytes": "22020096",
      "max_gas": "-1",
      "time_iota_ms": "1000"
    },
    "evidence": {
      "max_age": "100000"
    },
    "validator": {
      "pub_key_types": [
        "ed25519"
      ]
    }
  },
  "app_hash": ""
}
EOF

if [[ -z ${CHAIN_SPEC_PATH} ]]
then
	generate-test-spec -a ${TOTAL_NODES} -c ${TMHOME}/chain_spec.json -n ${NUM_ACCOUNTS}
	CHAIN_SPEC_PATH="${TMHOME}/chain_spec.json"
fi

if [[ -z ${KEYGEN_SEED} ]] 
then
	KEYGEN_SEED="near.${NODE_ID}"
fi

keystore keygen --tendermint --test-seed ${KEYGEN_SEED} -p ${TMHOME}/config/

if [[ -n ${NODE_KEY} ]]
then
    cat << EOF > ${TMHOME}/config/node_key.json
{"priv_key": {"type": "tendermint/PrivKeyEd25519", "value": "$NODE_KEY"}}
EOF
	cat ${TMHOME}/config/node_key.json
fi

echo "Chain spec ${CHAIN_SPEC_PATH} with ${TOTAL_NODES}"
echo "Keygen: ${KEYGEN_SEED}"
echo "Bootnode: ${BOOT_NODES}"

tendermint node --p2p.persistent_peers="${BOOT_NODES}" &

nearmint --abci-address 127.0.0.1:26658 --chain-spec-file=${CHAIN_SPEC_PATH} --base-path=${TMHOME}

'''
'''--- ops/teardown_local.sh ---
#!/bin/bash

sudo docker stop $(sudo docker ps -q)
sudo docker rm $(sudo docker ps -q --all)

'''
'''--- ops/teardown_remote.sh ---
#!/bin/bash
set -e

PREFIX=${1:-testnet-${USER}}
NUM_NODES=${2:-50}
ZONE=${3:-us-west2-a}

for NODE_ID in $(seq 0 `expr $NUM_NODES - 1`)
do
    yes | gcloud beta compute instances delete ${PREFIX}-${NODE_ID} --zone=${ZONE} &
done
wait

'''
'''--- ops/tendermint-config.toml ---
# This is a TOML config file.
# For more information, see https://github.com/toml-lang/toml

##### main base config options #####

# TCP or UNIX socket address of the ABCI application,
# or the name of an ABCI application compiled in with the Tendermint binary
proxy_app = "tcp://127.0.0.1:26658"

# A custom human readable name for this node
moniker = "Node"

# If this node is many blocks behind the tip of the chain, FastSync
# allows them to catchup quickly by downloading blocks in parallel
# and verifying their commits
fast_sync = true

# Database backend: leveldb | memdb | cleveldb
db_backend = "leveldb"

# Database directory
db_dir = "data"

# Output level for logging, including package level options
log_level = "main:info,state:info,*:error"

# Output format: 'plain' (colored text) or 'json'
log_format = "plain"

##### additional base config options #####

# Path to the JSON file containing the initial validator set and other meta data
genesis_file = "config/genesis.json"

# Path to the JSON file containing the private key to use as a validator in the consensus protocol
priv_validator_key_file = "config/priv_validator_key.json"

# Path to the JSON file containing the last sign state of a validator
priv_validator_state_file = "data/priv_validator_state.json"

# TCP or UNIX socket address for Tendermint to listen on for
# connections from an external PrivValidator process
priv_validator_laddr = ""

# Path to the JSON file containing the private key to use for node authentication in the p2p protocol
node_key_file = "config/node_key.json"

# Mechanism to connect to the ABCI application: socket | grpc
abci = "socket"

# TCP or UNIX socket address for the profiling server to listen on
prof_laddr = ""

# If true, query the ABCI app on connecting to a new peer
# so the app can decide if we should keep the connection or not
filter_peers = false

##### advanced configuration options #####

##### rpc server configuration options #####
[rpc]

# TCP or UNIX socket address for the RPC server to listen on
laddr = "tcp://0.0.0.0:3030"

# A list of origins a cross-domain request can be executed from
# Default value '[]' disables cors support
# Use '["*"]' to allow any origin
cors_allowed_origins = []

# A list of methods the client is allowed to use with cross-domain requests
cors_allowed_methods = ["HEAD", "GET", "POST", ]

# A list of non simple headers the client is allowed to use with cross-domain requests
cors_allowed_headers = ["Origin", "Accept", "Content-Type", "X-Requested-With", "X-Server-Time", ]

# TCP or UNIX socket address for the gRPC server to listen on
# NOTE: This server only supports /broadcast_tx_commit
grpc_laddr = ""

# Maximum number of simultaneous connections.
# Does not include RPC (HTTP&WebSocket) connections. See max_open_connections
# If you want to accept a larger number than the default, make sure
# you increase your OS limits.
# 0 - unlimited.
# Should be < {ulimit -Sn} - {MaxNumInboundPeers} - {MaxNumOutboundPeers} - {N of wal, db and other open files}
# 1024 - 40 - 10 - 50 = 924 = ~900
grpc_max_open_connections = 900

# Activate unsafe RPC commands like /dial_seeds and /unsafe_flush_mempool
unsafe = false

# Maximum number of simultaneous connections (including WebSocket).
# Does not include gRPC connections. See grpc_max_open_connections
# If you want to accept a larger number than the default, make sure
# you increase your OS limits.
# 0 - unlimited.
# Should be < {ulimit -Sn} - {MaxNumInboundPeers} - {MaxNumOutboundPeers} - {N of wal, db and other open files}
# 1024 - 40 - 10 - 50 = 924 = ~900
max_open_connections = 900

# Maximum number of unique clientIDs that can /subscribe
# If you're using /broadcast_tx_commit, set to the estimated maximum number
# of broadcast_tx_commit calls per block.
max_subscription_clients = 100

# Maximum number of unique queries a given client can /subscribe to
# If you're using GRPC (or Local RPC client) and /broadcast_tx_commit, set to
# the estimated # maximum number of broadcast_tx_commit calls per block.
max_subscriptions_per_client = 5

# How long to wait for a tx to be committed during /broadcast_tx_commit.
# WARNING: Using a value larger than 10s will result in increasing the
# global HTTP write timeout, which applies to all connections and endpoints.
# See https://github.com/tendermint/tendermint/issues/3435
timeout_broadcast_tx_commit = "10s"

# The name of a file containing certificate that is used to create the HTTPS server.
# If the certificate is signed by a certificate authority,
# the certFile should be the concatenation of the server's certificate, any intermediates,
# and the CA's certificate.
# NOTE: both tls_cert_file and tls_key_file must be present for Tendermint to create HTTPS server. Otherwise, HTTP server is run.
tls_cert_file = ""

# The name of a file containing matching private key that is used to create the HTTPS server.
# NOTE: both tls_cert_file and tls_key_file must be present for Tendermint to create HTTPS server. Otherwise, HTTP server is run.
tls_key_file = ""

##### peer to peer configuration options #####
[p2p]

# Address to listen for incoming connections
laddr = "tcp://0.0.0.0:26656"

# Address to advertise to peers for them to dial
# If empty, will use the same port as the laddr,
# and will introspect on the listener or use UPnP
# to figure out the address.
external_address = ""

# Comma separated list of seed nodes to connect to
seeds = ""

# Comma separated list of nodes to keep persistent connections to
persistent_peers = ""

# UPNP port forwarding
upnp = false

# Path to address book
addr_book_file = "config/addrbook.json"

# Set true for strict address routability rules
# Set false for private or local networks
addr_book_strict = true

# Maximum number of inbound peers
max_num_inbound_peers = 40

# Maximum number of outbound peers to connect to, excluding persistent peers
max_num_outbound_peers = 10

# Time to wait before flushing messages out on the connection
flush_throttle_timeout = "100ms"

# Maximum size of a message packet payload, in bytes
max_packet_msg_payload_size = 1024

# Rate at which packets can be sent, in bytes/second
send_rate = 5120000

# Rate at which packets can be received, in bytes/second
recv_rate = 5120000

# Set true to enable the peer-exchange reactor
pex = true

# Seed mode, in which node constantly crawls the network and looks for
# peers. If another node asks it for addresses, it responds and disconnects.
#
# Does not work if the peer-exchange reactor is disabled.
seed_mode = false

# Comma separated list of peer IDs to keep private (will not be gossiped to other peers)
private_peer_ids = ""

# Toggle to disable guard against peers connecting from the same ip.
allow_duplicate_ip = false

# Peer connection configuration.
handshake_timeout = "20s"
dial_timeout = "3s"

##### mempool configuration options #####
[mempool]

recheck = true
broadcast = true
wal_dir = ""

# Maximum number of transactions in the mempool
size = 5000

# Limit the total size of all txs in the mempool.
# This only accounts for raw transactions (e.g. given 1MB transactions and
# max_txs_bytes=5MB, mempool will only accept 5 transactions).
max_txs_bytes = 1073741824

# Size of the cache (used to filter transactions we saw earlier) in transactions
cache_size = 10000

##### consensus configuration options #####
[consensus]

wal_file = "data/cs.wal/wal"

timeout_propose = "3s"
timeout_propose_delta = "500ms"
timeout_prevote = "1s"
timeout_prevote_delta = "500ms"
timeout_precommit = "1s"
timeout_precommit_delta = "500ms"
timeout_commit = "1s"

# Make progress as soon as we have all the precommits (as if TimeoutCommit = 0)
skip_timeout_commit = false

# EmptyBlocks mode and possible interval between empty blocks
create_empty_blocks = true
create_empty_blocks_interval = "0s"

# Reactor sleep duration parameters
peer_gossip_sleep_duration = "100ms"
peer_query_maj23_sleep_duration = "2s"

##### transactions indexer configuration options #####
[tx_index]

# What indexer to use for transactions
#
# Options:
#   1) "null"
#   2) "kv" (default) - the simplest possible indexer, backed by key-value storage (defaults to levelDB; see DBBackend).
indexer = "kv"

# Comma-separated list of tags to index (by default the only tag is "tx.hash")
#
# You can also index transactions by height by adding "tx.height" tag here.
#
# It's recommended to index only a subset of tags due to possible memory
# bloat. This is, of course, depends on the indexer's DB and the volume of
# transactions.
index_tags = ""

# When set to true, tells indexer to index all tags (predefined tags:
# "tx.hash", "tx.height" and all tags from DeliverTx responses).
#
# Note this may be not desirable (see the comment above). IndexTags has a
# precedence over IndexAllTags (i.e. when given both, IndexTags will be
# indexed).
index_all_tags = false

##### instrumentation configuration options #####
[instrumentation]

# When true, Prometheus metrics are served under /metrics on
# PrometheusListenAddr.
# Check out the documentation for the list of available metrics.
prometheus = false

# Address to listen for Prometheus collector(s) connections
prometheus_listen_addr = ":26660"

# Maximum number of simultaneous connections.
# If you want to accept a larger number than the default, make sure
# you increase your OS limits.
# 0 - unlimited.
max_open_connections = 3

# Instrumentation namespace
namespace = "tendermint"

'''
'''--- ops/update_alphanet.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/alphanet:0.1.6}
PREFIX=${2:-alphanet}
ZONE=${3:-us-west2-a}

gcloud beta compute instances update-container ${PREFIX}-0 \
    --zone ${ZONE} \
    --container-image ${IMAGE}

gcloud beta compute instances update-container ${PREFIX}-1 \
    --zone ${ZONE} \
    --container-image ${IMAGE}

gcloud beta compute instances update-container ${PREFIX}-2 \
    --zone ${ZONE} \
    --container-image ${IMAGE}

gcloud beta compute instances update-container ${PREFIX}-3 \
    --zone ${ZONE} \
    --container-image ${IMAGE}

'''
'''--- ops/update_remote_studio.sh ---
#!/bin/bash
set -e

STUDIO_IMAGE=${3:-nearprotocol/studio:0.2.6}
PREFIX=${2:-testnet}
ZONE=${3:-us-west2-a}

gcloud beta compute instances update-container ${PREFIX}-studio \
    --zone ${ZONE} \
    --container-image ${STUDIO_IMAGE}

# borrowed from https://stackoverflow.com/a/20369590
spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [[ "$(ps a | awk '{print $1}' | grep $pid)" ]]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

STUDIO_IP=$(
gcloud compute instances describe ${PREFIX}-studio \
    --zone us-west2-a | grep natIP | \
    awk '{print $2}'
)

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I ${STUDIO_IP} 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

echo "Waiting for studio instance to start. This could take a few minutes..."
wait_for_studio & spinner
echo "NEARStudio is now accessible at http://${STUDIO_IP}"

'''
'''--- ops/update_remote_testnet.sh ---
#!/bin/bash
set -e

IMAGE=${1:-nearprotocol/nearcore:0.1.3}
PREFIX=${2:-testnet}
ZONE=${3:-us-west2-a}
NUM_NODES=${4:-2}

for NODE_ID in $(seq 0 `expr $NUM_NODES - 1`)
do

gcloud beta compute instances update-container ${PREFIX}-${NODE_ID} \
    --zone ${ZONE} \
    --container-image ${IMAGE}

done

'''
'''--- ops/update_studio.sh ---
#!/bin/bash
set -e

STUDIO_IMAGE=${3:-nearprotocol/studio:0.1.8}
PREFIX=${2:-alphanet}
ZONE=${3:-us-west2-a}

gcloud beta compute instances update-container ${PREFIX}-studio \
    --zone ${ZONE} \
    --container-image ${STUDIO_IMAGE}

# borrowed from https://stackoverflow.com/a/20369590
spinner()
{
    local pid=$!
    local delay=0.75
    local spinstr='|/-\'
    while [[ "$(ps a | awk '{print $1}' | grep $pid)" ]]; do
        local temp=${spinstr#?}
        printf " [%c]  " "$spinstr"
        local spinstr=$temp${spinstr%"$temp"}
        sleep $delay
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

STUDIO_IP=$(
gcloud compute instances describe ${PREFIX}-studio \
    --zone us-west2-a | grep natIP | \
    awk '{print $2}'
)

wait_for_studio()
{
    while :
    do
        STATUS_CODE=$(curl -I ${STUDIO_IP} 2>/dev/null | head -n 1 | cut -d$' ' -f2);
        if [[ ${STATUS_CODE} -eq 200 ]]; then
            exit 0
        fi
        sleep 1
    done
}

echo "Waiting for studio instance to start. This could take a few minutes..."
wait_for_studio & spinner
echo "NEARStudio is now accessible at http://${STUDIO_IP}"

'''
'''--- ops/utils/README.md ---
# Setup

## Install python requirements

```bash
pip install -r requirements.txt
```

## Install kubectl

**MacOS**
```bash
brew install kubectl
```

**Ubuntu**
```bash
sudo snap install kubectl --classic
```

## Setup AWS Credentials (optional)

If you do not have your key pair set in a
[credentials file](https://docs.aws.amazon.com/cli/latest/userguide/cli-config-files.html),
you will need to have `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` set when running `build_and_run`.

## Install minikube (local only)
1) [Install virtualbox](https://www.virtualbox.org/wiki/Downloads)

2) [Install minikube](https://github.com/kubernetes/minikube/releases)

3) Configure minikube
```bash
minikube addons enable ingress
minikube addons enable registry
``` 

'''
'''--- ops/utils/requirements.txt ---
boto3==1.9.37
click==7.0
-e git://github.com/azban/delegator.py.git@91f74a007992cc2cf4bd73ee76962616d7e199ce#egg=delegator-py
jinja2>=2.10.1
requests==2.21.0

'''
'''--- package-lock.json ---
{
  "lockfileVersion": 1
}

'''
'''--- protos/builder/Cargo.toml ---
[package]
name = "protos-autogen"
version = "0.1.0"
edition = "2018"

[dependencies]
protoc-rust = "2.4"

'''
'''--- protos/builder/src/bin/protos_autogen.rs ---
extern crate protos_autogen;

fn main() { protos_autogen::autogenerate() }

'''
'''--- protos/builder/src/lib.rs ---
use std::env;
use std::fs;
use std::io::{Read, Write};
use std::path::Path;

use protoc_rust::Customize;

fn extract_mod_name(file_name: &str) -> String {
    let last = file_name.split('/').collect::<Vec<_>>().pop().unwrap();
    last.split('.').collect::<Vec<_>>()[0].to_string()
}

pub fn autogenerate() {
    // dumb vector hack because https://bit.ly/2RJcIH1
    let input_files: Vec<String> = fs::read_dir(Path::new("protos"))
        .expect("could not read protos directory")
        .map(|dir_entry| dir_entry.expect("unable to get entry").path().display().to_string())
        .collect();
    let input_files: Vec<&str> = input_files.iter().map(std::convert::AsRef::as_ref).collect();
    let out_dir = env::var("OUT_DIR").unwrap();
    println!("out dir: {}", out_dir);
    protoc_rust::run(protoc_rust::Args {
        out_dir: &out_dir,
        input: input_files.as_slice(),
        includes: &["protos", "/usr/local/include"],
        customize: Customize { expose_oneof: Some(true), ..Default::default() },
    })
    .expect("protoc");

    // a hack from https://github.com/googlecartographer/point_cloud_viewer/blob/bb73289523a3cee8091e9b6547b7b989d0fc61c7/build.rs
    // to avoid rust protobuf issue https://github.com/stepancheg/rust-protobuf/issues/117
    let output_files: Vec<String> = fs::read_dir(Path::new(&out_dir))
        .expect("could not read protos directory")
        .map(|dir_entry| dir_entry.expect("unable to get entry").path().display().to_string())
        .collect();
    for output_file in output_files {
        let mut contents = String::new();
        fs::File::open(&output_file).unwrap().read_to_string(&mut contents).unwrap();
        let mod_name = extract_mod_name(&output_file);
        let new_contents = format!("pub mod {} {{\n{}\n}}", mod_name, contents);

        fs::File::create(&output_file).unwrap().write_all(new_contents.as_bytes()).unwrap();
    }
}

'''
'''--- pynear/bin/generate_python_transaction_proto.sh ---
#!/usr/bin/env bash
REPO_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )/../.." >/dev/null && pwd )"
protoc -I=${REPO_DIR}/protos --python_out=${REPO_DIR}/pynear/src/near/pynear ${REPO_DIR}/protos/protos/signed_transaction.proto

'''
'''--- pynear/setup.py ---
from setuptools import find_packages, setup

tests_require = [
    'delegator.py==0.1.1',
    'pytest==4.3.0',
    'retrying==1.3.3',
]

setup(
    name='near.pynear',
    version='0.1.1',
    packages=find_packages('src'),
    package_dir={'': 'src'},
    install_requires=[
        'ed25519==1.4',
        'protobuf==3.6.1',
        'requests==2.21.0',
    ],
    entry_points='''
        [console_scripts]
        pynear=near.pynear.cli:run
    ''',
    setup_requires=['pytest-runner'],
    tests_require=tests_require,
    extras_require={
        'test_utils': tests_require,
    }
)

'''
'''--- pynear/src/near/__init__.py ---
from pkgutil import extend_path

__path__ = extend_path(__path__, __name__)

'''
'''--- pynear/src/near/pynear/__init__.py ---

'''
'''--- pynear/src/near/pynear/b58.py ---
import binascii

alphabet = b'123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'

def _b58encode_int(i):
    string = b''
    while i:
        i, idx = divmod(i, 58)
        string = alphabet[idx:idx + 1] + string
    return string

def b58encode(v):
    """
    :param v: bytes object or integer list representation of bytes
    :return: base58 encoded bytes
    """
    p, acc = 1, 0
    for c in reversed(list(bytearray(v))):
        acc += p * c
        p = p << 8

    result = _b58encode_int(acc)

    return result

def b58decode(s):
    if not s:
        return b''

    # Convert the string to an integer
    n = 0
    for char in s.encode('utf-8'):
        n *= 58
        if char not in alphabet:
            msg = "Character {} is not a valid base58 character".format(char)
            raise Exception(msg)

        digit = alphabet.index(char)
        n += digit

    # Convert the integer to bytes
    h = '%x' % n
    if len(h) % 2:
        h = '0' + h
    res = binascii.unhexlify(h.encode('utf8'))

    # Add padding back.
    pad = 0
    for c in s[:-1]:
        if c == alphabet[0]:
            pad += 1
        else:
            break

    return b'\x00' * pad + res

'''
'''--- pynear/src/near/pynear/cli.py ---
import argparse
import json
import sys

from near.pynear.key_store import InMemoryKeyStore, FileKeyStore
from near.pynear.lib import NearLib

class MultiCommandParser(object):
    def __init__(self):
        parser = argparse.ArgumentParser(
            usage="""pynear <command> [<args>]

Commands:
call_view_function        {}
deploy                    {}
send_money                {}
schedule_function_call    {}
view_account              {}
view_state                {}
stake                     {}
create_account            {}
swap_key                  {}
view_latest_beacon_block  {}
get_beacon_block_by_hash  {}
view_latest_shard_block   {}
get_beacon_block_by_hash  {}
            """.format(
                self.call_view_function.__doc__,
                self.deploy.__doc__,
                self.send_money.__doc__,
                self.schedule_function_call.__doc__,
                self.view_account.__doc__,
                self.view_state.__doc__,
                self.stake.__doc__,
                self.create_account.__doc__,
                self.swap_key.__doc__,
                self.view_latest_beacon_block.__doc__,
                self.get_beacon_block_by_hash.__doc__,
                self.view_latest_shard_block.__doc__,
                self.get_shard_block_by_hash.__doc__,
            )
        )
        parser.add_argument('command', help='Command to run')
        # parse_args defaults to [1:] for args, but you need to
        # exclude the rest of the args too, or validation will fail
        args = parser.parse_args(sys.argv[1:2])
        if not hasattr(self, args.command):
            print("Unrecognized command: {}\n".format(args.command))
            parser.print_help()
            exit(1)
        else:
            response = getattr(self, args.command)()
            print(json.dumps(response))

    @staticmethod
    def _get_command_parser(description):
        parser = argparse.ArgumentParser(
            description=description,
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        )
        parser.add_argument(
            '-u',
            '--server-url',
            type=str,
            default='http://127.0.0.1:3030/',
            help='url of RPC server',
        )
        parser.add_argument(
            '--debug',
            action="store_true",
            default=False,
            help='set to emit debug logs',
        )
        return parser

    @staticmethod
    def _add_transaction_args(parser):
        parser.add_argument(
            '-o',
            '--originator',
            type=str,
            default='alice.near',
            help='account_id of originator',
        )
        parser.add_argument(
            '-d',
            '--keystore-path',
            type=str,
            help='location of keystore for signing transactions',
        )
        parser.add_argument(
            '-k',
            '--public-key',
            type=str,
            help='public key for signing transactions',
        )

    @staticmethod
    def _get_command_args(parser):
        # now that we're inside a sub-command, ignore the first
        # two args, ie the command (pynear) and the sub-command (send_money)
        return parser.parse_args(sys.argv[2:])

    @staticmethod
    def _get_rpc_client(command_args):
        keystore_path = getattr(command_args, 'keystore_path', None)
        if keystore_path is not None:
            keystore = FileKeyStore(keystore_path)
        else:
            keystore = InMemoryKeyStore()
            keystore.create_key_pair(seed='alice.near')

        public_key = getattr(command_args, 'public_key', None)
        return NearLib(
            command_args.server_url,
            keystore,
            public_key,
            command_args.debug,
        )

    def send_money(self):
        """Send money from one account to another"""
        parser = self._get_command_parser(self.send_money.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument(
            '-r',
            '--receiver',
            type=str,
            default='bob.near',
            help='account_id of receiver',
        )
        parser.add_argument(
            '-a',
            '--amount',
            type=int,
            default=0,
            help='amount of money being sent',
        )
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.send_money(args.originator, args.receiver, args.amount)

    def deploy(self):
        """Deploy a smart contract"""
        parser = self._get_command_parser(self.deploy.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('contract_name', type=str)
        parser.add_argument('wasm_file_location', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.deploy_contract(
            args.contract_name,
            args.wasm_file_location,
        )

    def create_account(self):
        """Create an account"""
        parser = self._get_command_parser(self.create_account.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('account_id', type=str)
        parser.add_argument('amount', type=int)
        parser.add_argument('--account_public-key', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.create_account(
            args.originator,
            args.account_id,
            args.amount,
            args.account_public_key,
        )

    def swap_key(self):
        """Swap key for an account"""
        parser = self._get_command_parser(self.swap_key.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('current_key', type=str)
        parser.add_argument('new_key', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.swap_key(
            args.originator,
            args.current_key,
            args.new_key,
        )

    def schedule_function_call(self):
        """Schedule a function call on a smart contract"""
        parser = self._get_command_parser(self.schedule_function_call.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('contract_name', type=str)
        parser.add_argument('function_name', type=str)
        parser.add_argument('--args', type=str, default="{}")
        parser.add_argument(
            '-a',
            '--amount',
            type=int,
            default=0,
            help='amount of money being sent with the function call',
        )
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.schedule_function_call(
            args.originator,
            args.contract_name,
            args.function_name,
            args.amount,
            args.args,
        )

    def call_view_function(self):
        """Call a view function on a smart contract"""
        parser = self._get_command_parser(self.call_view_function.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('contract_name', type=str)
        parser.add_argument('function_name', type=str)
        parser.add_argument('--args', type=str, default="{}")
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.call_view_function(
            args.contract_name,
            args.function_name,
            args.args,
        )

    def view_account(self):
        """View an account"""
        parser = self._get_command_parser(self.view_account.__doc__)
        parser.add_argument(
            '-a',
            '--account',
            type=str,
            default='alice.near',
            help='id of account to view',
        )
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.view_account(args.account)

    def stake(self):
        """Stake money for validation"""
        parser = self._get_command_parser(self.stake.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument(
            '-a',
            '--amount',
            type=int,
            default=0,
            help='amount of money to stake',
        )
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.stake(args.originator, args.amount)

    def view_state(self):
        """View state of the contract."""
        parser = self._get_command_parser(self.view_state.__doc__)
        parser.add_argument('contract_name', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.view_state(args.contract_name)

    def view_latest_beacon_block(self):
        """View latest beacon block."""
        parser = self._get_command_parser(self.view_state.__doc__)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.view_latest_beacon_block()

    def get_beacon_block_by_hash(self):
        """Get beacon block by hash."""
        parser = self._get_command_parser(self.view_state.__doc__)
        parser.add_argument('hash', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.get_beacon_block_by_hash(args.hash)

    def view_latest_shard_block(self):
        """View latest shard block."""
        parser = self._get_command_parser(self.view_state.__doc__)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.view_latest_shard_block()

    def get_shard_block_by_hash(self):
        """Get shard block by hash."""
        parser = self._get_command_parser(self.view_state.__doc__)
        parser.add_argument('hash', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.get_shard_block_by_hash(args.hash)

    def generate_key_pair(self):
        """Write key file for seed."""
        parser = self._get_command_parser(self.generate_key_pair.__doc__)
        self._add_transaction_args(parser)
        parser.add_argument('seed', type=str)
        args = self._get_command_args(parser)
        client = self._get_rpc_client(args)
        return client.generate_key_pair(args.seed)

def run():
    MultiCommandParser()

if __name__ == "__main__":
    run()

'''
'''--- pynear/src/near/pynear/key_store.py ---
import json
import os

import ed25519

from near.pynear import b58

class AmbiguousPublicKey(Exception):
    def __init__(self):
        msg = 'public key must be specified if there is more ' \
              'than one key in the key store'
        super(AmbiguousPublicKey, self).__init__(msg)

class NoKeyPairs(Exception):
    pass

class KeyStore(object):
    @staticmethod
    def _create_key_pair(seed=None):
        if seed is not None:
            if len(seed) > 32:
                raise Exception('max seed length is 32')

            seed = seed.encode('utf-8')

        kwargs = {}
        if seed is not None:
            kwargs['entropy'] = lambda x: seed.ljust(32)

        return ed25519.create_keypair(**kwargs)

    def create_key_pair(self, seed=None):
        raise NotImplementedError

    def sign(self, data, public_key=None):
        raise NotImplementedError

    def get_only_public_key(self):
        raise NotImplementedError

class InMemoryKeyStore(KeyStore):
    def __init__(self):
        self._key_pairs = {}

    def create_key_pair(self, seed=None):
        (secret_key, public_key) = self._create_key_pair(seed)
        encoded = b58.b58encode(public_key.to_bytes()).decode('utf-8')
        self._key_pairs[encoded] = secret_key
        return encoded

    def sign(self, data, public_key=None):
        if public_key is None:
            public_key = self.get_only_public_key()

        secret_key = self._key_pairs[public_key]
        return secret_key.sign(data)

    def get_only_public_key(self):
        if len(self._key_pairs) > 1:
            raise AmbiguousPublicKey
        elif len(self._key_pairs) == 0:
            raise NoKeyPairs

        return list(self._key_pairs.keys())[0]

class FileKeyStore(KeyStore):
    def __init__(self, path):
        self._path = path

    def create_key_pair(self, seed=None):
        if not os.path.exists(self._path):
            os.makedirs(self._path)

        (secret_key, public_key) = self._create_key_pair(seed)
        encoded_pub = b58.b58encode(public_key.to_bytes()).decode('utf-8')
        encoded_secret = b58.b58encode(secret_key.to_bytes()).decode('utf-8')

        with open(os.path.join(self._path, encoded_pub), 'w') as f:
            key_file = {
                'public_key': encoded_pub,
                'secret_key': encoded_secret,
            }
            f.write(json.dumps(key_file))

        return encoded_pub

    def sign(self, data, public_key=None):
        if public_key is None:
            public_key = self.get_only_public_key()

        with open(os.path.join(self._path, public_key)) as f:
            key_file = json.loads(f.read())
            encoded_secret = key_file['secret_key']

        secret_key = b58.b58decode(encoded_secret)
        secret_key = ed25519.SigningKey(secret_key)
        return secret_key.sign(data)

    def get_only_public_key(self):
        if not os.path.exists(self._path):
            raise NoKeyPairs

        pub_keys = os.listdir(self._path)
        if len(pub_keys) > 1:
            raise AmbiguousPublicKey
        elif len(pub_keys) == 0:
            raise NoKeyPairs

        return pub_keys[0]

'''
'''--- pynear/src/near/pynear/lib.py ---
from __future__ import print_function

import base64
import hashlib
import json

import requests

from near.pynear import b58
from near.pynear.key_store import InMemoryKeyStore
from near.pynear.protos import signed_transaction_pb2

try:
    # py2
    from urllib2 import urlopen, Request, HTTPError, URLError
except ImportError:
    # py3
    from urllib.request import urlopen, Request
    from urllib.error import HTTPError, URLError

# Data is empty string instead of None because method is
# defined by whether or not data is None and cannot be
# specified otherwise in py2
def _post(url, data=''):
    if data != '':
        data = json.dumps(data).encode('utf-8')

    request = Request(url, data=data)

    if data is not None:
        request.add_header('Content-Type', 'application/json')

    connection = urlopen(request)
    return connection

class NearLib(object):
    def __init__(
            self,
            server_url='http://localhost:3030/',
            keystore=None,
            public_key=None,
            debug=False,
    ):
        self._server_url = server_url
        if keystore is None:
            keystore = InMemoryKeyStore()
        self.keystore = keystore
        self._public_key = public_key
        self._nonces = {}
        self._debug = debug

    def _get_nonce(self, originator):
        if originator not in self._nonces:
            view_result = self.view_account(originator)
            self._nonces[originator] = view_result.get('nonce', 0) + 1

        return self._nonces[originator]

    def _update_nonce(self, originator):
        self._nonces[originator] += 1

    def _call_rpc(self, method_name, params=None):
        data = params
        if self._debug:
            print(data)

        try:
            connection = _post(self._server_url + method_name, data)
            raw = connection.read()
            if self._debug:
                print(raw)
            return json.loads(raw.decode('utf-8'))
        except HTTPError as e:
            if e.code == 400:
                raise Exception(e.fp.read())
            raise
        except URLError:
            error = "Connection to {} refused. " \
                    "To start RPC server at http://127.0.0.1:3030, run:\n" \
                    "cargo run -p devnet"
            raise Exception(error.format(self._server_url))

    def _sign_transaction_body(self, body):
        body = body.SerializeToString()
        m = hashlib.sha256()
        m.update(body)
        data = m.digest()
        return self.keystore.sign(data, self._public_key)

    def _submit_transaction(self, transaction):
        transaction = transaction.SerializeToString()
        transaction = base64.b64encode(transaction).decode('utf-8')
        params = {'transaction': transaction}
        return self._call_rpc('submit_transaction', params)

    def _get_public_key(self):
        if self._public_key is None:
            self._public_key = self.keystore.get_only_public_key()

        return self._public_key

    def deploy_contract(self, contract_name, wasm_file):
        with open(wasm_file, 'rb') as f:
            wasm_byte_array = f.read()

        nonce = self._get_nonce(contract_name)

        deploy_contract = signed_transaction_pb2.DeployContractTransaction()
        deploy_contract.nonce = nonce
        deploy_contract.contract_id = contract_name
        deploy_contract.wasm_byte_array = wasm_byte_array

        signature = self._sign_transaction_body(deploy_contract)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.deploy_contract.CopyFrom(deploy_contract)
        signed_transaction.signature = signature

        self._update_nonce(contract_name)
        return self._submit_transaction(signed_transaction)

    def send_money(self, originator, receiver, amount):
        nonce = self._get_nonce(originator)

        send_money = signed_transaction_pb2.SendMoneyTransaction()
        send_money.nonce = nonce
        send_money.originator = originator
        send_money.receiver = receiver
        send_money.amount = amount

        signature = self._sign_transaction_body(send_money)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.send_money.CopyFrom(send_money)
        signed_transaction.signature = signature

        self._update_nonce(originator)
        return self._submit_transaction(signed_transaction)

    def stake(self, originator, amount):
        nonce = self._get_nonce(originator)

        stake = signed_transaction_pb2.StakeTransaction()
        stake.nonce = nonce
        stake.originator = originator
        stake.amount = amount

        signature = self._sign_transaction_body(stake)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.stake.CopyFrom(stake)
        signed_transaction.signature = signature

        self._update_nonce(originator)
        return self._submit_transaction(signed_transaction)

    def schedule_function_call(
            self,
            originator,
            contract_name,
            method_name,
            amount,
            args=None,
    ):
        if args is None:
            args = "{}"

        nonce = self._get_nonce(originator)
        function_call = signed_transaction_pb2.FunctionCallTransaction()
        function_call.nonce = nonce
        function_call.originator = originator
        function_call.contract_id = contract_name
        function_call.method_name = method_name.encode('utf-8')
        function_call.args = args.encode('utf-8')
        function_call.amount = amount

        signature = self._sign_transaction_body(function_call)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.function_call.CopyFrom(function_call)
        signed_transaction.signature = signature

        self._update_nonce(originator)
        return self._submit_transaction(signed_transaction)

    def view_state(self, contract_name):
        params = {'contract_account_id': contract_name}
        return self._call_rpc('view_state', params)

    def view_latest_beacon_block(self):
        return self._call_rpc('view_latest_beacon_block')

    def get_beacon_block_by_hash(self, _hash):
        params = {'hash': _hash}
        return self._call_rpc('get_beacon_block_by_hash', params)

    def view_latest_shard_block(self):
        return self._call_rpc('view_latest_shard_block')

    def get_shard_block_by_hash(self, _hash):
        params = {'hash': _hash}
        return self._call_rpc('get_shard_block_by_hash', params)

    def list_beacon_blocks(self, start=None, limit=None):
        params = {
            'start': start,
            'limit': limit,
        }
        return self._call_rpc('get_beacon_blocks_by_index', params)

    def create_account(
            self,
            originator,
            account_id,
            amount,
            account_public_key,
    ):
        if not account_public_key:
            account_public_key = self._get_public_key()

        nonce = self._get_nonce(originator)

        create_account = signed_transaction_pb2.CreateAccountTransaction()
        create_account.nonce = nonce
        create_account.originator = originator
        create_account.new_account_id = account_id
        create_account.amount = amount
        create_account.public_key = b58.b58decode(account_public_key)

        signature = self._sign_transaction_body(create_account)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.create_account.CopyFrom(create_account)
        signed_transaction.signature = signature

        self._update_nonce(originator)
        return self._submit_transaction(signed_transaction)

    def swap_key(
            self,
            account,
            current_key,
            new_key,
    ):
        nonce = self._get_nonce(account)

        swap_key = signed_transaction_pb2.SwapKeyTransaction()
        swap_key.nonce = nonce
        swap_key.originator = account
        swap_key.cur_key = b58.b58decode(current_key)
        swap_key.new_key = b58.b58decode(new_key)

        signature = self._sign_transaction_body(swap_key)

        signed_transaction = signed_transaction_pb2.SignedTransaction()
        signed_transaction.swap_key.CopyFrom(swap_key)
        signed_transaction.signature = signature

        self._update_nonce(account)
        return self._submit_transaction(signed_transaction)

    def view_account(self, account_id):
        params = {
            'account_id': account_id,
        }
        return self._call_rpc('view_account', params)

    def call_view_function(
            self,
            contract_name,
            function_name,
            args=None,
    ):
        if args is None:
            args = "{}"
        args = list(bytearray(args, 'utf-8'))

        params = {
            'contract_account_id': contract_name,
            'method_name': function_name,
            'args': args,
        }
        result = self._call_rpc('call_view_function', params)
        try:
            return json.loads(bytearray(result['result']).decode('utf-8'))
        except json.JSONDecodeError:
            return result

    def check_health(self):
        url = "{}status".format(self._server_url)
        response = requests.get(url)
        return response.status_code == 200

    def get_transaction_result(self, hash_):
        params = {'hash': hash_}
        return self._call_rpc('get_transaction_result', params)

    def get_contract_info(self, contract_account_id):
        params = {'contract_account_id': contract_account_id}
        return self._call_rpc('view_state', params)

    def generate_key_pair(self, seed):
        return self.keystore.create_key_pair(seed)

'''
'''--- pynear/src/near/pynear/protos/__init__.py ---
from . import signed_transaction_pb2

'''
'''--- pynear/src/near/pynear/protos/signed_transaction_pb2.py ---
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: signed_transaction.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()

DESCRIPTOR = _descriptor.FileDescriptor(
  name='signed_transaction.proto',
  package='',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=_b('\n\x18signed_transaction.proto\"y\n\x18\x43reateAccountTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x16\n\x0enew_account_id\x18\x03 \x01(\t\x12\x0e\n\x06\x61mount\x18\x04 \x01(\x04\x12\x12\n\npublic_key\x18\x05 \x01(\x0c\"X\n\x19\x44\x65ployContractTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x13\n\x0b\x63ontract_id\x18\x02 \x01(\t\x12\x17\n\x0fwasm_byte_array\x18\x03 \x01(\x0c\"\x84\x01\n\x17\x46unctionCallTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x13\n\x0b\x63ontract_id\x18\x03 \x01(\t\x12\x13\n\x0bmethod_name\x18\x04 \x01(\x0c\x12\x0c\n\x04\x61rgs\x18\x05 \x01(\x0c\x12\x0e\n\x06\x61mount\x18\x06 \x01(\x04\"[\n\x14SendMoneyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x10\n\x08receiver\x18\x03 \x01(\t\x12\x0e\n\x06\x61mount\x18\x04 \x01(\x04\"q\n\x10StakeTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0e\n\x06\x61mount\x18\x03 \x01(\x04\x12\x12\n\npublic_key\x18\x04 \x01(\t\x12\x16\n\x0e\x62ls_public_key\x18\x05 \x01(\t\"Y\n\x12SwapKeyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0f\n\x07\x63ur_key\x18\x03 \x01(\x0c\x12\x0f\n\x07new_key\x18\x04 \x01(\x0c\"G\n\x11\x41\x64\x64KeyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0f\n\x07new_key\x18\x03 \x01(\x0c\"J\n\x14\x44\x65leteKeyTransaction\x12\r\n\x05nonce\x18\x01 \x01(\x04\x12\x12\n\noriginator\x18\x02 \x01(\t\x12\x0f\n\x07\x63ur_key\x18\x03 \x01(\x0c\"\x9b\x03\n\x11SignedTransaction\x12\x11\n\tsignature\x18\x01 \x01(\x0c\x12\x33\n\x0e\x63reate_account\x18\x02 \x01(\x0b\x32\x19.CreateAccountTransactionH\x00\x12\x35\n\x0f\x64\x65ploy_contract\x18\x03 \x01(\x0b\x32\x1a.DeployContractTransactionH\x00\x12\x31\n\rfunction_call\x18\x04 \x01(\x0b\x32\x18.FunctionCallTransactionH\x00\x12+\n\nsend_money\x18\x05 \x01(\x0b\x32\x15.SendMoneyTransactionH\x00\x12\"\n\x05stake\x18\x06 \x01(\x0b\x32\x11.StakeTransactionH\x00\x12\'\n\x08swap_key\x18\x07 \x01(\x0b\x32\x13.SwapKeyTransactionH\x00\x12%\n\x07\x61\x64\x64_key\x18\x08 \x01(\x0b\x32\x12.AddKeyTransactionH\x00\x12+\n\ndelete_key\x18\t \x01(\x0b\x32\x15.DeleteKeyTransactionH\x00\x42\x06\n\x04\x62odyb\x06proto3')
)

_CREATEACCOUNTTRANSACTION = _descriptor.Descriptor(
  name='CreateAccountTransaction',
  full_name='CreateAccountTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='CreateAccountTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='CreateAccountTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='new_account_id', full_name='CreateAccountTransaction.new_account_id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='CreateAccountTransaction.amount', index=3,
      number=4, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='public_key', full_name='CreateAccountTransaction.public_key', index=4,
      number=5, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=28,
  serialized_end=149,
)

_DEPLOYCONTRACTTRANSACTION = _descriptor.Descriptor(
  name='DeployContractTransaction',
  full_name='DeployContractTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='DeployContractTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contract_id', full_name='DeployContractTransaction.contract_id', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='wasm_byte_array', full_name='DeployContractTransaction.wasm_byte_array', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=151,
  serialized_end=239,
)

_FUNCTIONCALLTRANSACTION = _descriptor.Descriptor(
  name='FunctionCallTransaction',
  full_name='FunctionCallTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='FunctionCallTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='FunctionCallTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contract_id', full_name='FunctionCallTransaction.contract_id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='method_name', full_name='FunctionCallTransaction.method_name', index=3,
      number=4, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='args', full_name='FunctionCallTransaction.args', index=4,
      number=5, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='FunctionCallTransaction.amount', index=5,
      number=6, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=242,
  serialized_end=374,
)

_SENDMONEYTRANSACTION = _descriptor.Descriptor(
  name='SendMoneyTransaction',
  full_name='SendMoneyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='SendMoneyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='SendMoneyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='receiver', full_name='SendMoneyTransaction.receiver', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='SendMoneyTransaction.amount', index=3,
      number=4, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=376,
  serialized_end=467,
)

_STAKETRANSACTION = _descriptor.Descriptor(
  name='StakeTransaction',
  full_name='StakeTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='StakeTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='StakeTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='amount', full_name='StakeTransaction.amount', index=2,
      number=3, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='public_key', full_name='StakeTransaction.public_key', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='bls_public_key', full_name='StakeTransaction.bls_public_key', index=4,
      number=5, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=469,
  serialized_end=582,
)

_SWAPKEYTRANSACTION = _descriptor.Descriptor(
  name='SwapKeyTransaction',
  full_name='SwapKeyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='SwapKeyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='SwapKeyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='cur_key', full_name='SwapKeyTransaction.cur_key', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='new_key', full_name='SwapKeyTransaction.new_key', index=3,
      number=4, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=584,
  serialized_end=673,
)

_ADDKEYTRANSACTION = _descriptor.Descriptor(
  name='AddKeyTransaction',
  full_name='AddKeyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='AddKeyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='AddKeyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='new_key', full_name='AddKeyTransaction.new_key', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=675,
  serialized_end=746,
)

_DELETEKEYTRANSACTION = _descriptor.Descriptor(
  name='DeleteKeyTransaction',
  full_name='DeleteKeyTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='nonce', full_name='DeleteKeyTransaction.nonce', index=0,
      number=1, type=4, cpp_type=4, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='originator', full_name='DeleteKeyTransaction.originator', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='cur_key', full_name='DeleteKeyTransaction.cur_key', index=2,
      number=3, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=748,
  serialized_end=822,
)

_SIGNEDTRANSACTION = _descriptor.Descriptor(
  name='SignedTransaction',
  full_name='SignedTransaction',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='signature', full_name='SignedTransaction.signature', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='create_account', full_name='SignedTransaction.create_account', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='deploy_contract', full_name='SignedTransaction.deploy_contract', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='function_call', full_name='SignedTransaction.function_call', index=3,
      number=4, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='send_money', full_name='SignedTransaction.send_money', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='stake', full_name='SignedTransaction.stake', index=5,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='swap_key', full_name='SignedTransaction.swap_key', index=6,
      number=7, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='add_key', full_name='SignedTransaction.add_key', index=7,
      number=8, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='delete_key', full_name='SignedTransaction.delete_key', index=8,
      number=9, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='body', full_name='SignedTransaction.body',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=825,
  serialized_end=1236,
)

_SIGNEDTRANSACTION.fields_by_name['create_account'].message_type = _CREATEACCOUNTTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['deploy_contract'].message_type = _DEPLOYCONTRACTTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['function_call'].message_type = _FUNCTIONCALLTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['send_money'].message_type = _SENDMONEYTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['stake'].message_type = _STAKETRANSACTION
_SIGNEDTRANSACTION.fields_by_name['swap_key'].message_type = _SWAPKEYTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['add_key'].message_type = _ADDKEYTRANSACTION
_SIGNEDTRANSACTION.fields_by_name['delete_key'].message_type = _DELETEKEYTRANSACTION
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['create_account'])
_SIGNEDTRANSACTION.fields_by_name['create_account'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['deploy_contract'])
_SIGNEDTRANSACTION.fields_by_name['deploy_contract'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['function_call'])
_SIGNEDTRANSACTION.fields_by_name['function_call'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['send_money'])
_SIGNEDTRANSACTION.fields_by_name['send_money'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['stake'])
_SIGNEDTRANSACTION.fields_by_name['stake'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['swap_key'])
_SIGNEDTRANSACTION.fields_by_name['swap_key'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['add_key'])
_SIGNEDTRANSACTION.fields_by_name['add_key'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
_SIGNEDTRANSACTION.oneofs_by_name['body'].fields.append(
  _SIGNEDTRANSACTION.fields_by_name['delete_key'])
_SIGNEDTRANSACTION.fields_by_name['delete_key'].containing_oneof = _SIGNEDTRANSACTION.oneofs_by_name['body']
DESCRIPTOR.message_types_by_name['CreateAccountTransaction'] = _CREATEACCOUNTTRANSACTION
DESCRIPTOR.message_types_by_name['DeployContractTransaction'] = _DEPLOYCONTRACTTRANSACTION
DESCRIPTOR.message_types_by_name['FunctionCallTransaction'] = _FUNCTIONCALLTRANSACTION
DESCRIPTOR.message_types_by_name['SendMoneyTransaction'] = _SENDMONEYTRANSACTION
DESCRIPTOR.message_types_by_name['StakeTransaction'] = _STAKETRANSACTION
DESCRIPTOR.message_types_by_name['SwapKeyTransaction'] = _SWAPKEYTRANSACTION
DESCRIPTOR.message_types_by_name['AddKeyTransaction'] = _ADDKEYTRANSACTION
DESCRIPTOR.message_types_by_name['DeleteKeyTransaction'] = _DELETEKEYTRANSACTION
DESCRIPTOR.message_types_by_name['SignedTransaction'] = _SIGNEDTRANSACTION
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

CreateAccountTransaction = _reflection.GeneratedProtocolMessageType('CreateAccountTransaction', (_message.Message,), dict(
  DESCRIPTOR = _CREATEACCOUNTTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:CreateAccountTransaction)
  ))
_sym_db.RegisterMessage(CreateAccountTransaction)

DeployContractTransaction = _reflection.GeneratedProtocolMessageType('DeployContractTransaction', (_message.Message,), dict(
  DESCRIPTOR = _DEPLOYCONTRACTTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:DeployContractTransaction)
  ))
_sym_db.RegisterMessage(DeployContractTransaction)

FunctionCallTransaction = _reflection.GeneratedProtocolMessageType('FunctionCallTransaction', (_message.Message,), dict(
  DESCRIPTOR = _FUNCTIONCALLTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:FunctionCallTransaction)
  ))
_sym_db.RegisterMessage(FunctionCallTransaction)

SendMoneyTransaction = _reflection.GeneratedProtocolMessageType('SendMoneyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SENDMONEYTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SendMoneyTransaction)
  ))
_sym_db.RegisterMessage(SendMoneyTransaction)

StakeTransaction = _reflection.GeneratedProtocolMessageType('StakeTransaction', (_message.Message,), dict(
  DESCRIPTOR = _STAKETRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:StakeTransaction)
  ))
_sym_db.RegisterMessage(StakeTransaction)

SwapKeyTransaction = _reflection.GeneratedProtocolMessageType('SwapKeyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SWAPKEYTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SwapKeyTransaction)
  ))
_sym_db.RegisterMessage(SwapKeyTransaction)

AddKeyTransaction = _reflection.GeneratedProtocolMessageType('AddKeyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _ADDKEYTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:AddKeyTransaction)
  ))
_sym_db.RegisterMessage(AddKeyTransaction)

DeleteKeyTransaction = _reflection.GeneratedProtocolMessageType('DeleteKeyTransaction', (_message.Message,), dict(
  DESCRIPTOR = _DELETEKEYTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:DeleteKeyTransaction)
  ))
_sym_db.RegisterMessage(DeleteKeyTransaction)

SignedTransaction = _reflection.GeneratedProtocolMessageType('SignedTransaction', (_message.Message,), dict(
  DESCRIPTOR = _SIGNEDTRANSACTION,
  __module__ = 'signed_transaction_pb2'
  # @@protoc_insertion_point(class_scope:SignedTransaction)
  ))
_sym_db.RegisterMessage(SignedTransaction)

# @@protoc_insertion_point(module_scope)

'''
'''--- pynear/src/near/pynear/test_utils/__init__.py ---
from . import cli

'''
'''--- pynear/src/near/pynear/test_utils/cli.py ---
import json

import delegator
from retrying import retry

class CliHelpers(object):
    def __init__(self, port=3030):
        self._url = "http://localhost:{}/".format(port)

    def run_command(self, command):
        command = "python -m near.pynear.cli {} -u {}".format(command, self._url)
        process = delegator.run(command)
        assert process.return_code == 0, process.err
        return process.out

    def get_latest_beacon_block(self):
        command = 'view_latest_beacon_block'
        out = self.run_command(command)
        return json.loads(out)

    def view_account(self, account_name=None):
        command = 'view_account'
        if account_name is not None:
            command = "{} --account {}".format(command, account_name)

        out = self.run_command(command)
        return json.loads(out)

    def get_latest_shard_block(self):
        command = 'view_latest_shard_block'
        out = self.run_command(command)
        return json.loads(out)

    def create_account(self, account_id):
        command = "create_account {} 10".format(account_id)
        self.run_command(command)

        @retry(stop_max_attempt_number=5, wait_fixed=1000)
        def _wait_for_account():
            return self.view_account(account_id)

        return _wait_for_account()

    def deploy_contract(self, contract_name, wasm_path=None):
        self.create_account(contract_name)

        command = "deploy {} {}".format(contract_name, wasm_path)
        out = self.run_command(command)
        data = json.loads(out)
        transaction_hash = data['hash']

        @retry(stop_max_attempt_number=5, wait_fixed=1000)
        def _wait_for_contract():
            return self.view_account(contract_name)

        contract = _wait_for_contract()
        assert contract['account_id'] == contract_name
        return contract, transaction_hash

'''
'''--- pynear/src/near/pynear/test_utils/fixtures.py ---
import os
import sys

import delegator
import pytest
import subprocess
from retrying import retry

from near.pynear.lib import NearLib

@retry(stop_max_attempt_number=5, wait_fixed=1000)
def check_devnet_health(process, nearlib):
    if not delegator.pid_exists(process.pid):
        return False

    return nearlib.check_health()

@pytest.fixture(scope='session')
def get_incrementing_number():
    # jank because py2 does not support nonlocal keyword
    # https://stackoverflow.com/a/3190783
    d = {'latest': -1}

    def _get_incrementing_number():
        d['latest'] += 1
        return d['latest']

    return _get_incrementing_number

@pytest.fixture
def make_devnet(request, get_incrementing_number):
    def _make_devnet(base_dir):
        port = 3030 + get_incrementing_number()
        devnet_exe = os.environ['NEAR_DEVNET_EXE']
        command = "{devnet_exe} -d {base_dir} --rpc_port {port} " \
                  "--test-block-period 5" \
            .format(devnet_exe=devnet_exe, base_dir=base_dir, port=port)
        process = subprocess.Popen(command.split(' '),  stdout=sys.stdout, stderr=sys.stdout)
        request.addfinalizer(process.kill)
        nearlib = NearLib("http://localhost:{}/".format(port))
        assert check_devnet_health(process, nearlib)
        return port

    return _make_devnet

'''
'''--- pynear/tests/integration/__init__.py ---

'''
'''--- pynear/tests/integration/test_cli.py ---
import json

from near.pynear.test_utils.cli import CliHelpers
from near.pynear.test_utils.fixtures import *

@pytest.fixture(scope='session')
def hello_wasm_path():
    cur_dir = os.path.abspath(os.path.dirname(__file__))
    hello_dir = os.path.join(cur_dir, '../../../tests/hello')
    command = 'npm install && npm run build'
    process = delegator.run(command, cwd=hello_dir)
    assert process.return_code == 0, process.err
    return os.path.join(hello_dir, '../hello.wasm')

def test_view_latest_beacon_block(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    CliHelpers(port).get_latest_beacon_block()

def test_get_beacon_block_by_hash(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    latest_block = CliHelpers(port).get_latest_beacon_block()
    hash_ = latest_block['hash']
    command = "get_beacon_block_by_hash {}".format(hash_)
    out = CliHelpers(port).run_command(command)
    assert latest_block == json.loads(out)

def test_view_latest_shard_block(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    CliHelpers(port).get_latest_shard_block()

def test_get_shard_block_by_hash(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    latest_block = CliHelpers(port).get_latest_shard_block()
    hash_ = latest_block['hash']
    command = "get_shard_block_by_hash {}".format(hash_)
    out = CliHelpers(port).run_command(command)
    assert latest_block == json.loads(out)

def test_view_account(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    CliHelpers(port).view_account()

def test_create_account(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    account_id = 'eve.near'
    CliHelpers(port).create_account(account_id)

def test_deploy_contract(
        make_devnet,
        tmpdir,
        get_incrementing_number,
        hello_wasm_path,
):
    port = make_devnet(tmpdir)
    buster = get_incrementing_number()
    contract_name = "test_contract_{}".format(buster)
    CliHelpers(port).deploy_contract(contract_name, hello_wasm_path)

def test_send_money(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    receiver = 'send_money_test.near'
    CliHelpers(port).create_account(receiver)
    command = "send_money --receiver {} --amount 1".format(receiver)
    CliHelpers(port).run_command(command)

    @retry(stop_max_attempt_number=5, wait_fixed=1000)
    def _wait_for_balance_change():
        account = CliHelpers(port).view_account(receiver)
        assert account['amount'] == 11

    _wait_for_balance_change()

def test_set_get_values(
        make_devnet,
        tmpdir,
        get_incrementing_number,
        hello_wasm_path,
):
    port = make_devnet(tmpdir)
    buster = get_incrementing_number()
    contract_name = "test_contract_{}".format(buster)
    contract, _ = CliHelpers(port).deploy_contract(contract_name, hello_wasm_path)
    contract_name = contract['account_id']
    value = 'test'
    args = {'value': value}
    command = "schedule_function_call {} setValue --args '{}'" \
        .format(contract_name, json.dumps(args))
    CliHelpers(port).run_command(command)

    @retry(stop_max_attempt_number=5, wait_fixed=1000)
    def _wait_for_state_change():
        command_ = "call_view_function {} getValue --args {{}}" \
            .format(contract_name)
        out = CliHelpers(port).run_command(command_)
        data = json.loads(out)
        assert data == value

    _wait_for_state_change()

def test_view_state(
        make_devnet,
        tmpdir,
        get_incrementing_number,
        hello_wasm_path,
):
    port = make_devnet(tmpdir)
    buster = get_incrementing_number()
    contract_name = "test_contract_{}".format(buster)
    contract, _ = CliHelpers(port).deploy_contract(contract_name, hello_wasm_path)
    contract_name = contract['account_id']
    command = "view_state {}".format(contract_name)
    out = CliHelpers(port).run_command(command)
    data = json.loads(out)
    assert data['values'] == {}

def test_swap_key(make_devnet, tmpdir):
    port = make_devnet(tmpdir)
    public_key = NearLib().keystore.create_key_pair('alice.near')
    command = "swap_key {} {}".format(public_key, public_key)
    CliHelpers(port).run_command(command)

'''
'''--- runtime/aes/Cargo.toml ---
[package]
name = "aes"
version = "0.1.0"
authors = ["rooat <welling1234@gmail.com>"]

[dependencies]
arrayref = "0.3.3"

'''
'''--- runtime/aes/README.md ---
# aes
Rust AES implementation

'''
'''--- runtime/aes/src/aes_crypto.rs ---
use constants::*;

#[derive(Copy,Clone)]
pub struct Key {
    data: [u8; 16]
}

impl Key {
    pub fn new(data: &[u8; 16]) -> Self {
        Key { data: data.clone() }
    }

    fn expand(&self) -> [Self; 11] {
        let mut keys: [[u8; 4]; 44] = [[0; 4]; 44]; // table of columns

        load_initial_key(&mut keys, &self.data);

        for i in 1..11 {
            ksa_core(&mut keys, i, i*4);
            expand_column(&mut keys, i*4+1);
            expand_column(&mut keys, i*4+2);
            expand_column(&mut keys, i*4+3);
        }

        return columns_to_keys(&keys);

        fn load_initial_key(keys: &mut [[u8;4];44], data: &[u8;16]) {
            let (a, b, c, d) = array_refs![data,4,4,4,4];
            keys[0] = a.clone();
            keys[1] = b.clone();
            keys[2] = c.clone();
            keys[3] = d.clone();
        }

        fn ksa_core(keys: &mut [[u8;4];44], i: usize, column: usize) {
            keys[column][0] = SBOX[keys[column-1][1] as usize];
            keys[column][1] = SBOX[keys[column-1][2] as usize];
            keys[column][2] = SBOX[keys[column-1][3] as usize];
            keys[column][3] = SBOX[keys[column-1][0] as usize];

            keys[column][0] ^= RCON[i];

            keys[column][0] ^= keys[column-4][0];
            keys[column][1] ^= keys[column-4][1];
            keys[column][2] ^= keys[column-4][2];
            keys[column][3] ^= keys[column-4][3];
        }

        fn expand_column(keys: &mut [[u8;4];44], column: usize) {
            keys[column][0] = keys[column-4][0] ^ keys[column-1][0];
            keys[column][1] = keys[column-4][1] ^ keys[column-1][1];
            keys[column][2] = keys[column-4][2] ^ keys[column-1][2];
            keys[column][3] = keys[column-4][3] ^ keys[column-1][3];
        }

        fn columns_to_keys(columns: &[[u8;4];44]) -> [Key; 11] {
            let mut keys = [Key { data: [0;16] }; 11];
            for i in 0..11 {
                keys[i].data[0..4].copy_from_slice(&columns[i*4] as &[u8]);
                keys[i].data[4..8].copy_from_slice(&columns[i*4 + 1] as &[u8]);
                keys[i].data[8..12].copy_from_slice(&columns[i*4 + 2] as &[u8]);
                keys[i].data[12..16].copy_from_slice(&columns[i*4 + 3] as &[u8]);
            }
            return keys;
        }
    }
}

#[derive(Eq,PartialEq,Clone,Copy,Debug)]
pub struct Block {
    data: [u8; 16]
}

impl Block {
    pub fn new(data: &[u8; 16]) -> Block {
        Block { data: data.clone() }
    }

    pub fn as_bytes(&self) -> &[u8; 16] {
        &self.data
    }

    fn add_round_key(&mut self, key: &Key) {
        for i in 0..16 {
            self.data[i] ^= key.data[i];
        }
    }

    fn sub_bytes(&mut self) {
        for i in 0..16 {
            self.data[i] = SBOX[self.data[i] as usize];
        }
    }

    fn inv_sub_bytes(&mut self) {
        for i in 0..16 {
            self.data[i] = INV_SBOX[self.data[i] as usize];
        }
    }

    fn shift_rows(&mut self) {
        let mut new_data = self.data.clone();
        for row in 1..4 {
            for col in 0..4 {
                new_data[col*4 + row] = self.data[((col + row)*4 + row) % 16]
            }
        }
        self.data = new_data;
    }

    fn inv_shift_rows(&mut self) {
        let mut new_data = self.data.clone();
        for row in 1..4 {
            for col in 0..4 {
                new_data[col*4 + row] = self.data[((col + 4 - row)*4 + row) % 16]
            }
        }
        self.data = new_data;
    }

    fn mix_columns(&mut self) {
        mix_column(&mut self.data[0..4]);
        mix_column(&mut self.data[4..8]);
        mix_column(&mut self.data[8..12]);
        mix_column(&mut self.data[12..16]);

        fn mix_column(col: &mut[u8]) {
            let mut c: [u8; 4] = [0; 4];
            c.copy_from_slice(col);

            col[0] = MUL2[c[0] as usize] ^ MUL3[c[1] as usize] ^ c[2] ^ c[3];
            col[1] = c[0] ^ MUL2[c[1] as usize] ^ MUL3[c[2] as usize] ^ c[3];
            col[2] = c[0] ^ c[1] ^ MUL2[c[2] as usize] ^ MUL3[c[3] as usize];
            col[3] = MUL3[c[0] as usize] ^ c[1] ^ c[2] ^ MUL2[c[3] as usize];
        }
    }

    fn inv_mix_columns(&mut self) {
        inv_mix_column(&mut self.data[0..4]);
        inv_mix_column(&mut self.data[4..8]);
        inv_mix_column(&mut self.data[8..12]);
        inv_mix_column(&mut self.data[12..16]);

        fn inv_mix_column(col: &mut[u8]) {
            let mut c: [u8; 4] = [0; 4];
            c.copy_from_slice(col);

            col[0] = MUL14[c[0] as usize] ^ MUL11[c[1] as usize]
                    ^ MUL13[c[2] as usize] ^ MUL9[c[3] as usize];
            col[1] = MUL9[c[0] as usize] ^ MUL14[c[1] as usize]
                    ^ MUL11[c[2] as usize] ^ MUL13[c[3] as usize];
            col[2] = MUL13[c[0] as usize] ^ MUL9[c[1] as usize]
                    ^ MUL14[c[2] as usize] ^ MUL11[c[3] as usize];
            col[3] = MUL11[c[0] as usize] ^ MUL13[c[1] as usize]
                    ^ MUL9[c[2] as usize] ^ MUL14[c[3] as usize];
        }
    }
}

pub fn encrypt(key: Key, block: Block) -> Block {
    let mut state = block.clone();
    let keys: [Key; 11] = key.expand();

    state.add_round_key(&keys[0]);

    for i in 1..10 {
        state.sub_bytes();
        state.shift_rows();
        state.mix_columns();
        state.add_round_key(&keys[i]);
    }

    state.sub_bytes();
    state.shift_rows();
    state.add_round_key(&keys[10]);

    return state;
}

pub fn decrypt(key: Key, block: Block) -> Block {
    let mut state = block.clone();
    let keys: [Key; 11] = key.expand();

    state.add_round_key(&keys[10]);

    for i in 1..10 {
        state.inv_shift_rows();
        state.inv_sub_bytes();
        state.add_round_key(&keys[10-i]);
        state.inv_mix_columns();
    }

    state.inv_shift_rows();
    state.inv_sub_bytes();
    state.add_round_key(&keys[0]);

    return state;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn encryption_decryption_test() {
        let key = Key { data: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] };
        let message = Block { data: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] };

        let result = decrypt(key, encrypt(key, message));

        assert_eq!(message, result);
    }

    #[test]
    fn encryption_test() {
        let key = Key { data: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] };
        let message = Block { data: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] };
        let expected = Block { data: [0x0a,0x94,0x0b,0xb5,0x41,0x6e,0xf0,0x45
                                     ,0xf1,0xc3,0x94,0x58,0xc6,0x53,0xea,0x5a
                                     ]
                             };
        let encrypted = encrypt(key, message);

        assert_eq!(expected, encrypted);
    }

    #[test]
    fn key_schedule_test() {
        let key = Key { data: [ 0x2b, 0x7e, 0x15, 0x16
                              , 0x28, 0xae, 0xd2, 0xa6
                              , 0xab, 0xf7, 0x15, 0x88
                              , 0x09, 0xcf, 0x4f, 0x3c
                              ]};
        let expected = [ 0xa0, 0xfa, 0xfe, 0x17
                       , 0x88, 0x54, 0x2c, 0xb1
                       , 0x23, 0xa3, 0x39, 0x39
                       , 0x2a, 0x6c, 0x76, 0x05
                       ];

        let expanded = key.expand()[1];

        assert_eq!(expected, expanded.data);
    }

    #[test]
    fn mix_columns_test() {
        let mut block = Block { data:
                                [ 219, 19, 83, 69
                                , 1, 1, 1, 1
                                , 198, 198, 198, 198
                                , 45, 38, 49, 76
                                ] };
        let expected = [ 142, 77, 161, 188
                       , 1, 1, 1, 1
                       , 198, 198, 198, 198
                       , 77, 126, 189, 248
                       ];
        block.mix_columns();
        assert_eq!(expected, block.data);
    }

    #[test]
    fn inverse_mix_columns_test() {
        let mut block = Block { data:
                                [ 219, 19, 83, 69
                                , 1, 1, 1, 1
                                , 198, 198, 198, 198
                                , 45, 38, 49, 76
                                ] };
        let expected = block.clone();

        block.mix_columns();
        block.inv_mix_columns();

        assert_eq!(expected, block);
    }

    #[test]
    fn shift_rows_test() {
        let mut block = Block { data:
                                [ 1, 5, 9, 13
                                , 2, 6, 10, 14
                                , 3, 7, 11, 15
                                , 4, 8, 12, 16
                                ] };
        let expected = [ 1, 6, 11, 16
                       , 2, 7, 12, 13
                       , 3, 8, 9, 14
                       , 4, 5, 10, 15
                       ];
        block.shift_rows();
        assert_eq!(expected, block.data);
    }

    #[test]
    fn inverse_shift_rows_test() {
        let mut block = Block { data:
                                [ 1, 6, 11, 16
                                , 2, 7, 12, 13
                                , 3, 8, 9, 14
                                , 4, 5, 10, 15
                                ] };
        let expected = [ 1, 5, 9, 13
                       , 2, 6, 10, 14
                       , 3, 7, 11, 15
                       , 4, 8, 12, 16
                       ];
        block.inv_shift_rows();
        assert_eq!(expected, block.data);
    }
}

'''
'''--- runtime/aes/src/constants.rs ---
pub const SBOX: [u8; 256] = [
    0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5,
    0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,
    0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0,
    0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,
    0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc,
    0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,
    0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a,
    0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,
    0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0,
    0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,
    0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b,
    0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,
    0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85,
    0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,
    0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5,
    0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,
    0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17,
    0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,
    0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88,
    0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,
    0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c,
    0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,
    0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9,
    0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,
    0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6,
    0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,
    0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e,
    0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,
    0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94,
    0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,
    0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68,
    0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
];

pub const INV_SBOX: [u8; 256] = [
    0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38,
    0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb,
    0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87,
    0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb,
    0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d,
    0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e,
    0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2,
    0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25,
    0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16,
    0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92,
    0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda,
    0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84,
    0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a,
    0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06,
    0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02,
    0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b,
    0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea,
    0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73,
    0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85,
    0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e,
    0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89,
    0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b,
    0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20,
    0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4,
    0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31,
    0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f,
    0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d,
    0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef,
    0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0,
    0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61,
    0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26,
    0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d,
];

pub const MUL2: [u8; 256] = [
    0x00,0x02,0x04,0x06,0x08,0x0a,0x0c,0x0e,0x10,0x12,0x14,0x16,0x18,0x1a,0x1c,0x1e,
    0x20,0x22,0x24,0x26,0x28,0x2a,0x2c,0x2e,0x30,0x32,0x34,0x36,0x38,0x3a,0x3c,0x3e,
    0x40,0x42,0x44,0x46,0x48,0x4a,0x4c,0x4e,0x50,0x52,0x54,0x56,0x58,0x5a,0x5c,0x5e,
    0x60,0x62,0x64,0x66,0x68,0x6a,0x6c,0x6e,0x70,0x72,0x74,0x76,0x78,0x7a,0x7c,0x7e,
    0x80,0x82,0x84,0x86,0x88,0x8a,0x8c,0x8e,0x90,0x92,0x94,0x96,0x98,0x9a,0x9c,0x9e,
    0xa0,0xa2,0xa4,0xa6,0xa8,0xaa,0xac,0xae,0xb0,0xb2,0xb4,0xb6,0xb8,0xba,0xbc,0xbe,
    0xc0,0xc2,0xc4,0xc6,0xc8,0xca,0xcc,0xce,0xd0,0xd2,0xd4,0xd6,0xd8,0xda,0xdc,0xde,
    0xe0,0xe2,0xe4,0xe6,0xe8,0xea,0xec,0xee,0xf0,0xf2,0xf4,0xf6,0xf8,0xfa,0xfc,0xfe,
    0x1b,0x19,0x1f,0x1d,0x13,0x11,0x17,0x15,0x0b,0x09,0x0f,0x0d,0x03,0x01,0x07,0x05,
    0x3b,0x39,0x3f,0x3d,0x33,0x31,0x37,0x35,0x2b,0x29,0x2f,0x2d,0x23,0x21,0x27,0x25,
    0x5b,0x59,0x5f,0x5d,0x53,0x51,0x57,0x55,0x4b,0x49,0x4f,0x4d,0x43,0x41,0x47,0x45,
    0x7b,0x79,0x7f,0x7d,0x73,0x71,0x77,0x75,0x6b,0x69,0x6f,0x6d,0x63,0x61,0x67,0x65,
    0x9b,0x99,0x9f,0x9d,0x93,0x91,0x97,0x95,0x8b,0x89,0x8f,0x8d,0x83,0x81,0x87,0x85,
    0xbb,0xb9,0xbf,0xbd,0xb3,0xb1,0xb7,0xb5,0xab,0xa9,0xaf,0xad,0xa3,0xa1,0xa7,0xa5,
    0xdb,0xd9,0xdf,0xdd,0xd3,0xd1,0xd7,0xd5,0xcb,0xc9,0xcf,0xcd,0xc3,0xc1,0xc7,0xc5,
    0xfb,0xf9,0xff,0xfd,0xf3,0xf1,0xf7,0xf5,0xeb,0xe9,0xef,0xed,0xe3,0xe1,0xe7,0xe5
];

pub const MUL3: [u8; 256] = [
    0x00,0x03,0x06,0x05,0x0c,0x0f,0x0a,0x09,0x18,0x1b,0x1e,0x1d,0x14,0x17,0x12,0x11,
    0x30,0x33,0x36,0x35,0x3c,0x3f,0x3a,0x39,0x28,0x2b,0x2e,0x2d,0x24,0x27,0x22,0x21,
    0x60,0x63,0x66,0x65,0x6c,0x6f,0x6a,0x69,0x78,0x7b,0x7e,0x7d,0x74,0x77,0x72,0x71,
    0x50,0x53,0x56,0x55,0x5c,0x5f,0x5a,0x59,0x48,0x4b,0x4e,0x4d,0x44,0x47,0x42,0x41,
    0xc0,0xc3,0xc6,0xc5,0xcc,0xcf,0xca,0xc9,0xd8,0xdb,0xde,0xdd,0xd4,0xd7,0xd2,0xd1,
    0xf0,0xf3,0xf6,0xf5,0xfc,0xff,0xfa,0xf9,0xe8,0xeb,0xee,0xed,0xe4,0xe7,0xe2,0xe1,
    0xa0,0xa3,0xa6,0xa5,0xac,0xaf,0xaa,0xa9,0xb8,0xbb,0xbe,0xbd,0xb4,0xb7,0xb2,0xb1,
    0x90,0x93,0x96,0x95,0x9c,0x9f,0x9a,0x99,0x88,0x8b,0x8e,0x8d,0x84,0x87,0x82,0x81,
    0x9b,0x98,0x9d,0x9e,0x97,0x94,0x91,0x92,0x83,0x80,0x85,0x86,0x8f,0x8c,0x89,0x8a,
    0xab,0xa8,0xad,0xae,0xa7,0xa4,0xa1,0xa2,0xb3,0xb0,0xb5,0xb6,0xbf,0xbc,0xb9,0xba,
    0xfb,0xf8,0xfd,0xfe,0xf7,0xf4,0xf1,0xf2,0xe3,0xe0,0xe5,0xe6,0xef,0xec,0xe9,0xea,
    0xcb,0xc8,0xcd,0xce,0xc7,0xc4,0xc1,0xc2,0xd3,0xd0,0xd5,0xd6,0xdf,0xdc,0xd9,0xda,
    0x5b,0x58,0x5d,0x5e,0x57,0x54,0x51,0x52,0x43,0x40,0x45,0x46,0x4f,0x4c,0x49,0x4a,
    0x6b,0x68,0x6d,0x6e,0x67,0x64,0x61,0x62,0x73,0x70,0x75,0x76,0x7f,0x7c,0x79,0x7a,
    0x3b,0x38,0x3d,0x3e,0x37,0x34,0x31,0x32,0x23,0x20,0x25,0x26,0x2f,0x2c,0x29,0x2a,
    0x0b,0x08,0x0d,0x0e,0x07,0x04,0x01,0x02,0x13,0x10,0x15,0x16,0x1f,0x1c,0x19,0x1a
];

pub const MUL9: [u8; 256] = [
    0x00,0x09,0x12,0x1b,0x24,0x2d,0x36,0x3f,0x48,0x41,0x5a,0x53,0x6c,0x65,0x7e,0x77,
    0x90,0x99,0x82,0x8b,0xb4,0xbd,0xa6,0xaf,0xd8,0xd1,0xca,0xc3,0xfc,0xf5,0xee,0xe7,
    0x3b,0x32,0x29,0x20,0x1f,0x16,0x0d,0x04,0x73,0x7a,0x61,0x68,0x57,0x5e,0x45,0x4c,
    0xab,0xa2,0xb9,0xb0,0x8f,0x86,0x9d,0x94,0xe3,0xea,0xf1,0xf8,0xc7,0xce,0xd5,0xdc,
    0x76,0x7f,0x64,0x6d,0x52,0x5b,0x40,0x49,0x3e,0x37,0x2c,0x25,0x1a,0x13,0x08,0x01,
    0xe6,0xef,0xf4,0xfd,0xc2,0xcb,0xd0,0xd9,0xae,0xa7,0xbc,0xb5,0x8a,0x83,0x98,0x91,
    0x4d,0x44,0x5f,0x56,0x69,0x60,0x7b,0x72,0x05,0x0c,0x17,0x1e,0x21,0x28,0x33,0x3a,
    0xdd,0xd4,0xcf,0xc6,0xf9,0xf0,0xeb,0xe2,0x95,0x9c,0x87,0x8e,0xb1,0xb8,0xa3,0xaa,
    0xec,0xe5,0xfe,0xf7,0xc8,0xc1,0xda,0xd3,0xa4,0xad,0xb6,0xbf,0x80,0x89,0x92,0x9b,
    0x7c,0x75,0x6e,0x67,0x58,0x51,0x4a,0x43,0x34,0x3d,0x26,0x2f,0x10,0x19,0x02,0x0b,
    0xd7,0xde,0xc5,0xcc,0xf3,0xfa,0xe1,0xe8,0x9f,0x96,0x8d,0x84,0xbb,0xb2,0xa9,0xa0,
    0x47,0x4e,0x55,0x5c,0x63,0x6a,0x71,0x78,0x0f,0x06,0x1d,0x14,0x2b,0x22,0x39,0x30,
    0x9a,0x93,0x88,0x81,0xbe,0xb7,0xac,0xa5,0xd2,0xdb,0xc0,0xc9,0xf6,0xff,0xe4,0xed,
    0x0a,0x03,0x18,0x11,0x2e,0x27,0x3c,0x35,0x42,0x4b,0x50,0x59,0x66,0x6f,0x74,0x7d,
    0xa1,0xa8,0xb3,0xba,0x85,0x8c,0x97,0x9e,0xe9,0xe0,0xfb,0xf2,0xcd,0xc4,0xdf,0xd6,
    0x31,0x38,0x23,0x2a,0x15,0x1c,0x07,0x0e,0x79,0x70,0x6b,0x62,0x5d,0x54,0x4f,0x46
];

pub const MUL11: [u8; 256] = [
    0x00,0x0b,0x16,0x1d,0x2c,0x27,0x3a,0x31,0x58,0x53,0x4e,0x45,0x74,0x7f,0x62,0x69,
    0xb0,0xbb,0xa6,0xad,0x9c,0x97,0x8a,0x81,0xe8,0xe3,0xfe,0xf5,0xc4,0xcf,0xd2,0xd9,
    0x7b,0x70,0x6d,0x66,0x57,0x5c,0x41,0x4a,0x23,0x28,0x35,0x3e,0x0f,0x04,0x19,0x12,
    0xcb,0xc0,0xdd,0xd6,0xe7,0xec,0xf1,0xfa,0x93,0x98,0x85,0x8e,0xbf,0xb4,0xa9,0xa2,
    0xf6,0xfd,0xe0,0xeb,0xda,0xd1,0xcc,0xc7,0xae,0xa5,0xb8,0xb3,0x82,0x89,0x94,0x9f,
    0x46,0x4d,0x50,0x5b,0x6a,0x61,0x7c,0x77,0x1e,0x15,0x08,0x03,0x32,0x39,0x24,0x2f,
    0x8d,0x86,0x9b,0x90,0xa1,0xaa,0xb7,0xbc,0xd5,0xde,0xc3,0xc8,0xf9,0xf2,0xef,0xe4,
    0x3d,0x36,0x2b,0x20,0x11,0x1a,0x07,0x0c,0x65,0x6e,0x73,0x78,0x49,0x42,0x5f,0x54,
    0xf7,0xfc,0xe1,0xea,0xdb,0xd0,0xcd,0xc6,0xaf,0xa4,0xb9,0xb2,0x83,0x88,0x95,0x9e,
    0x47,0x4c,0x51,0x5a,0x6b,0x60,0x7d,0x76,0x1f,0x14,0x09,0x02,0x33,0x38,0x25,0x2e,
    0x8c,0x87,0x9a,0x91,0xa0,0xab,0xb6,0xbd,0xd4,0xdf,0xc2,0xc9,0xf8,0xf3,0xee,0xe5,
    0x3c,0x37,0x2a,0x21,0x10,0x1b,0x06,0x0d,0x64,0x6f,0x72,0x79,0x48,0x43,0x5e,0x55,
    0x01,0x0a,0x17,0x1c,0x2d,0x26,0x3b,0x30,0x59,0x52,0x4f,0x44,0x75,0x7e,0x63,0x68,
    0xb1,0xba,0xa7,0xac,0x9d,0x96,0x8b,0x80,0xe9,0xe2,0xff,0xf4,0xc5,0xce,0xd3,0xd8,
    0x7a,0x71,0x6c,0x67,0x56,0x5d,0x40,0x4b,0x22,0x29,0x34,0x3f,0x0e,0x05,0x18,0x13,
    0xca,0xc1,0xdc,0xd7,0xe6,0xed,0xf0,0xfb,0x92,0x99,0x84,0x8f,0xbe,0xb5,0xa8,0xa3
];

pub const MUL13: [u8; 256] = [
    0x00,0x0d,0x1a,0x17,0x34,0x39,0x2e,0x23,0x68,0x65,0x72,0x7f,0x5c,0x51,0x46,0x4b,
    0xd0,0xdd,0xca,0xc7,0xe4,0xe9,0xfe,0xf3,0xb8,0xb5,0xa2,0xaf,0x8c,0x81,0x96,0x9b,
    0xbb,0xb6,0xa1,0xac,0x8f,0x82,0x95,0x98,0xd3,0xde,0xc9,0xc4,0xe7,0xea,0xfd,0xf0,
    0x6b,0x66,0x71,0x7c,0x5f,0x52,0x45,0x48,0x03,0x0e,0x19,0x14,0x37,0x3a,0x2d,0x20,
    0x6d,0x60,0x77,0x7a,0x59,0x54,0x43,0x4e,0x05,0x08,0x1f,0x12,0x31,0x3c,0x2b,0x26,
    0xbd,0xb0,0xa7,0xaa,0x89,0x84,0x93,0x9e,0xd5,0xd8,0xcf,0xc2,0xe1,0xec,0xfb,0xf6,
    0xd6,0xdb,0xcc,0xc1,0xe2,0xef,0xf8,0xf5,0xbe,0xb3,0xa4,0xa9,0x8a,0x87,0x90,0x9d,
    0x06,0x0b,0x1c,0x11,0x32,0x3f,0x28,0x25,0x6e,0x63,0x74,0x79,0x5a,0x57,0x40,0x4d,
    0xda,0xd7,0xc0,0xcd,0xee,0xe3,0xf4,0xf9,0xb2,0xbf,0xa8,0xa5,0x86,0x8b,0x9c,0x91,
    0x0a,0x07,0x10,0x1d,0x3e,0x33,0x24,0x29,0x62,0x6f,0x78,0x75,0x56,0x5b,0x4c,0x41,
    0x61,0x6c,0x7b,0x76,0x55,0x58,0x4f,0x42,0x09,0x04,0x13,0x1e,0x3d,0x30,0x27,0x2a,
    0xb1,0xbc,0xab,0xa6,0x85,0x88,0x9f,0x92,0xd9,0xd4,0xc3,0xce,0xed,0xe0,0xf7,0xfa,
    0xb7,0xba,0xad,0xa0,0x83,0x8e,0x99,0x94,0xdf,0xd2,0xc5,0xc8,0xeb,0xe6,0xf1,0xfc,
    0x67,0x6a,0x7d,0x70,0x53,0x5e,0x49,0x44,0x0f,0x02,0x15,0x18,0x3b,0x36,0x21,0x2c,
    0x0c,0x01,0x16,0x1b,0x38,0x35,0x22,0x2f,0x64,0x69,0x7e,0x73,0x50,0x5d,0x4a,0x47,
    0xdc,0xd1,0xc6,0xcb,0xe8,0xe5,0xf2,0xff,0xb4,0xb9,0xae,0xa3,0x80,0x8d,0x9a,0x97
];

pub const MUL14: [u8; 256] = [
    0x00,0x0e,0x1c,0x12,0x38,0x36,0x24,0x2a,0x70,0x7e,0x6c,0x62,0x48,0x46,0x54,0x5a,
    0xe0,0xee,0xfc,0xf2,0xd8,0xd6,0xc4,0xca,0x90,0x9e,0x8c,0x82,0xa8,0xa6,0xb4,0xba,
    0xdb,0xd5,0xc7,0xc9,0xe3,0xed,0xff,0xf1,0xab,0xa5,0xb7,0xb9,0x93,0x9d,0x8f,0x81,
    0x3b,0x35,0x27,0x29,0x03,0x0d,0x1f,0x11,0x4b,0x45,0x57,0x59,0x73,0x7d,0x6f,0x61,
    0xad,0xa3,0xb1,0xbf,0x95,0x9b,0x89,0x87,0xdd,0xd3,0xc1,0xcf,0xe5,0xeb,0xf9,0xf7,
    0x4d,0x43,0x51,0x5f,0x75,0x7b,0x69,0x67,0x3d,0x33,0x21,0x2f,0x05,0x0b,0x19,0x17,
    0x76,0x78,0x6a,0x64,0x4e,0x40,0x52,0x5c,0x06,0x08,0x1a,0x14,0x3e,0x30,0x22,0x2c,
    0x96,0x98,0x8a,0x84,0xae,0xa0,0xb2,0xbc,0xe6,0xe8,0xfa,0xf4,0xde,0xd0,0xc2,0xcc,
    0x41,0x4f,0x5d,0x53,0x79,0x77,0x65,0x6b,0x31,0x3f,0x2d,0x23,0x09,0x07,0x15,0x1b,
    0xa1,0xaf,0xbd,0xb3,0x99,0x97,0x85,0x8b,0xd1,0xdf,0xcd,0xc3,0xe9,0xe7,0xf5,0xfb,
    0x9a,0x94,0x86,0x88,0xa2,0xac,0xbe,0xb0,0xea,0xe4,0xf6,0xf8,0xd2,0xdc,0xce,0xc0,
    0x7a,0x74,0x66,0x68,0x42,0x4c,0x5e,0x50,0x0a,0x04,0x16,0x18,0x32,0x3c,0x2e,0x20,
    0xec,0xe2,0xf0,0xfe,0xd4,0xda,0xc8,0xc6,0x9c,0x92,0x80,0x8e,0xa4,0xaa,0xb8,0xb6,
    0x0c,0x02,0x10,0x1e,0x34,0x3a,0x28,0x26,0x7c,0x72,0x60,0x6e,0x44,0x4a,0x58,0x56,
    0x37,0x39,0x2b,0x25,0x0f,0x01,0x13,0x1d,0x47,0x49,0x5b,0x55,0x7f,0x71,0x63,0x6d,
    0xd7,0xd9,0xcb,0xc5,0xef,0xe1,0xf3,0xfd,0xa7,0xa9,0xbb,0xb5,0x9f,0x91,0x83,0x8d
];

pub const RCON: [u8; 256] = [
    0x8d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36, 0x6c, 0xd8, 0xab, 0x4d, 0x9a, 
    0x2f, 0x5e, 0xbc, 0x63, 0xc6, 0x97, 0x35, 0x6a, 0xd4, 0xb3, 0x7d, 0xfa, 0xef, 0xc5, 0x91, 0x39, 
    0x72, 0xe4, 0xd3, 0xbd, 0x61, 0xc2, 0x9f, 0x25, 0x4a, 0x94, 0x33, 0x66, 0xcc, 0x83, 0x1d, 0x3a, 
    0x74, 0xe8, 0xcb, 0x8d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36, 0x6c, 0xd8, 
    0xab, 0x4d, 0x9a, 0x2f, 0x5e, 0xbc, 0x63, 0xc6, 0x97, 0x35, 0x6a, 0xd4, 0xb3, 0x7d, 0xfa, 0xef, 
    0xc5, 0x91, 0x39, 0x72, 0xe4, 0xd3, 0xbd, 0x61, 0xc2, 0x9f, 0x25, 0x4a, 0x94, 0x33, 0x66, 0xcc, 
    0x83, 0x1d, 0x3a, 0x74, 0xe8, 0xcb, 0x8d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 
    0x36, 0x6c, 0xd8, 0xab, 0x4d, 0x9a, 0x2f, 0x5e, 0xbc, 0x63, 0xc6, 0x97, 0x35, 0x6a, 0xd4, 0xb3, 
    0x7d, 0xfa, 0xef, 0xc5, 0x91, 0x39, 0x72, 0xe4, 0xd3, 0xbd, 0x61, 0xc2, 0x9f, 0x25, 0x4a, 0x94, 
    0x33, 0x66, 0xcc, 0x83, 0x1d, 0x3a, 0x74, 0xe8, 0xcb, 0x8d, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 
    0x40, 0x80, 0x1b, 0x36, 0x6c, 0xd8, 0xab, 0x4d, 0x9a, 0x2f, 0x5e, 0xbc, 0x63, 0xc6, 0x97, 0x35, 
    0x6a, 0xd4, 0xb3, 0x7d, 0xfa, 0xef, 0xc5, 0x91, 0x39, 0x72, 0xe4, 0xd3, 0xbd, 0x61, 0xc2, 0x9f, 
    0x25, 0x4a, 0x94, 0x33, 0x66, 0xcc, 0x83, 0x1d, 0x3a, 0x74, 0xe8, 0xcb, 0x8d, 0x01, 0x02, 0x04, 
    0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36, 0x6c, 0xd8, 0xab, 0x4d, 0x9a, 0x2f, 0x5e, 0xbc, 0x63, 
    0xc6, 0x97, 0x35, 0x6a, 0xd4, 0xb3, 0x7d, 0xfa, 0xef, 0xc5, 0x91, 0x39, 0x72, 0xe4, 0xd3, 0xbd, 
    0x61, 0xc2, 0x9f, 0x25, 0x4a, 0x94, 0x33, 0x66, 0xcc, 0x83, 0x1d, 0x3a, 0x74, 0xe8, 0xcb, 0x8d
];

'''
'''--- runtime/aes/src/main.rs ---
#[macro_use]
extern crate arrayref;

pub mod aes;
mod constants;

fn main() {
    let message_text = "Hello, world! <3";
    let mut message_array = [0; 16];
    message_array.copy_from_slice(message_text.as_bytes());

    let key_text = "I like computers";
    let mut key_array = [0; 16];
    key_array.copy_from_slice(key_text.as_bytes());

    let block = aes::Block::new(&message_array);
    let key = aes::Key::new(&key_array);

    let encrypted = aes::encrypt(key, block);
    let decrypted = aes::decrypt(key, encrypted);

    println!("Message:   {}", message_text);
    println!("Key:       {}", key_text);
    println!("Encrypted: {}", String::from_utf8_lossy(&encrypted.as_bytes()[..]));
    println!("Decrypted: {}", String::from_utf8_lossy(&decrypted.as_bytes()[..]));
}

'''
'''--- runtime/cbor/.travis.yml ---
language: rust
rust:
  - 1.31.0
  - stable
  - beta
  - nightly
matrix:
  allow_failures:
    - rust: nightly
sudo: false
before_script:
  - rustup component add rustfmt
  - rustup target add thumbv7em-none-eabihf     # Any target that does not have a standard library will do
script:
  - cargo fmt --all -- --check
  - cargo build
  - cargo test
  - cargo build --no-default-features --target thumbv7em-none-eabihf # Test we can build a platform that does not have std.
  - cargo test --no-default-features --lib --tests # Run no_std tests
  - cargo build --features unsealed_read_write # The crate should still build when the unsealed_read_write feature is enabled.

'''
'''--- runtime/cbor/CONTRIBUTING.md ---
# Contributing to Serde CBOR
Thanks for your interest!
There are many ways to help:

* write an issue about a problem you encountered
* submit a pull request
* add documentation and examples

## Pull Requests

Code should be easy to understand and documented.
For new features and fixed bugs please add a test to one of the files in `test/`.
The tests are run on Travis CI to catch regressions early.
Format your code with `cargo fmt` before committing.
Currently Serde CBOR does not contain `unsafe` code and I would like to keep it this way.

## Making a Release

* [ ] Make sure the crate compiles and all tests pass.
* [ ] (Optional) Test that the fuzzer works and fuzz the crate for some time.
* [ ] Write a list with all changes made since the last release
* [ ] Increment the version number in `Cargo.toml` and the `README.md`. Bugfixes increase the patch version while new features or an increased minimum Rust version require a new minor version.
* [ ] Check that the file `examples/readme.rs` and the example from the `README.md` match.
* [ ] Commit the changes.
* [ ] Add a git tag with the new version number:
    `git tag "v42.0.2"`
* [ ] Push the changes: `git push --tags`
* [ ] Run `cargo publish`
* [ ] Add a new release to GitHub with a list of changes.
'''
'''--- runtime/cbor/Cargo.toml ---
[package]
name = "serde_cbor"
version = "0.9.0"
authors = [
    "Pyfisch <pyfisch@gmail.com>",
    "Steven Fackler <sfackler@gmail.com>"]
repository = "https://github.com/pyfisch/cbor"
readme = "README.md"
license = "MIT/Apache-2.0"
description = "CBOR support for serde."
keywords = ["serde", "cbor", "serialization"]
categories = ["encoding"]
edition = "2018"

[badges]
travis-ci = { repository = "pyfisch/cbor" }
maintenance = { status = "actively-developed" }

[dependencies]
byteorder = { version = "1.0.0", default-features = false }
half = "1.2.0"
serde = { version = "1.0.14", default-features = false }
serde_derive = { version = "1.0.14", default-features = false }

[dev-dependencies]
serde_bytes = { version = "0.10", default-features = false }

[features]
default = ["std"]
std = ["serde/std", "serde_bytes/std" ]
unsealed_read_write = []

'''
'''--- runtime/cbor/README.md ---
# Serde CBOR
[![Build Status](https://travis-ci.org/pyfisch/cbor.svg?branch=master)](https://travis-ci.org/pyfisch/cbor)
[![Crates.io](https://img.shields.io/crates/v/serde_cbor.svg)](https://crates.io/crates/serde_cbor)
[![Documentation](https://docs.rs/serde_cbor/badge.svg)](https://docs.rs/serde_cbor)

This crate implements the Concise Binary Object Representation from [RFC 7049].
It builds on [Serde] the generic serialization  framework for Rust.
CBOR provides a binary encoding for a superset
of the JSON data model that is small and very fast to parse.

[RFC 7049]: https://tools.ietf.org/html/rfc7049
[Serde]: https://github.com/serde-rs/serde

## Usage

Serde CBOR supports Rust 1.31 and up. Add this to your `Cargo.toml`:
```toml
[dependencies]
serde_cbor = "0.9"
```

Storing and loading Rust types is easy and requires only
minimal modifications to the program code.

```rust
use serde_derive::{Deserialize, Serialize};
use std::error::Error;
use std::fs::File;

// Types annotated with `Serialize` can be stored as CBOR.
// To be able to load them again add `Deserialize`.
#[derive(Debug, Serialize, Deserialize)]
struct Mascot {
    name: String,
    species: String,
    year_of_birth: u32,
}

fn main() -> Result<(), Box<Error>> {
    let ferris = Mascot {
        name: "Ferris".to_owned(),
        species: "crab".to_owned(),
        year_of_birth: 2015,
    };

    let mut ferris_file = File::create("examples/ferris.cbor")?;
    // Write Ferris to the given file.
    // Instead of a file you can use any type that implements `io::Write`
    // like a HTTP body, database connection etc.
    serde_cbor::to_writer(&mut ferris_file, &ferris)?;

    let mut tux_file = File::open("examples/tux.cbor")?;
    // Load Tux from a file.
    // Serde CBOR performs roundtrip serialization meaning that
    // the data will not change in any way.
    let tux: Mascot = serde_cbor::from_reader(&mut tux_file)?;

    println!("{:?}", tux);
    // prints: Mascot { name: "Tux", species: "penguin", year_of_birth: 1996 }

    Ok(())
}
```

There are a lot of options available to customize the format.
To operate on untyped CBOR values have a look at the `Value` type.

## License
Licensed under either of

 * Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
 * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.

'''
'''--- runtime/cbor/examples/readme.rs ---
// NOTE: This file should be kept in sync with README.md

use serde_derive::{Deserialize, Serialize};
use std::error::Error;
use std::fs::File;

// Types annotated with `Serialize` can be stored as CBOR.
// To be able to load them again add `Deserialize`.
#[derive(Debug, Serialize, Deserialize)]
struct Mascot {
    name: String,
    species: String,
    year_of_birth: u32,
}

fn main() -> Result<(), Box<Error>> {
    let ferris = Mascot {
        name: "Ferris".to_owned(),
        species: "crab".to_owned(),
        year_of_birth: 2015,
    };

    let mut ferris_file = File::create("examples/ferris.cbor")?;
    // Write Ferris to the given file.
    // Instead of a file you can use any type that implements `io::Write`
    // like a HTTP body, database connection etc.
    serde_cbor::to_writer(&mut ferris_file, &ferris)?;

    let mut tux_file = File::open("examples/tux.cbor")?;
    // Load Tux from a file.
    // Serde CBOR performs roundtrip serialization meaning that
    // the data will not change in any way.
    let tux: Mascot = serde_cbor::from_reader(&mut tux_file)?;

    println!("{:?}", tux);
    // prints: Mascot { name: "Tux", species: "penguin", year_of_birth: 1996 }

    Ok(())
}

'''
'''--- runtime/cbor/fuzz/Cargo.toml ---

[package]
name = "serde_cbor-fuzz"
version = "0.0.1"
authors = ["Automatically generated"]
publish = false

[package.metadata]
cargo-fuzz = true

[dependencies.serde_cbor]
path = ".."
[dependencies.libfuzzer-sys]
git = "https://github.com/rust-fuzz/libfuzzer-sys.git"

# Prevent this from interfering with workspaces
[workspace]
members = ["."]

[[bin]]
name = "from_slice"
path = "fuzz_targets/from_slice.rs"

[[bin]]
name = "from_reader"
path = "fuzz_targets/from_reader.rs"

'''
'''--- runtime/cbor/fuzz/appendix_a.json ---
[
  {
    "cbor": "AA==",
    "hex": "00",
    "roundtrip": true,
    "decoded": 0
  },
  {
    "cbor": "AQ==",
    "hex": "01",
    "roundtrip": true,
    "decoded": 1
  },
  {
    "cbor": "Cg==",
    "hex": "0a",
    "roundtrip": true,
    "decoded": 10
  },
  {
    "cbor": "Fw==",
    "hex": "17",
    "roundtrip": true,
    "decoded": 23
  },
  {
    "cbor": "GBg=",
    "hex": "1818",
    "roundtrip": true,
    "decoded": 24
  },
  {
    "cbor": "GBk=",
    "hex": "1819",
    "roundtrip": true,
    "decoded": 25
  },
  {
    "cbor": "GGQ=",
    "hex": "1864",
    "roundtrip": true,
    "decoded": 100
  },
  {
    "cbor": "GQPo",
    "hex": "1903e8",
    "roundtrip": true,
    "decoded": 1000
  },
  {
    "cbor": "GgAPQkA=",
    "hex": "1a000f4240",
    "roundtrip": true,
    "decoded": 1000000
  },
  {
    "cbor": "GwAAAOjUpRAA",
    "hex": "1b000000e8d4a51000",
    "roundtrip": true,
    "decoded": 1000000000000
  },
  {
    "cbor": "G///////////",
    "hex": "1bffffffffffffffff",
    "roundtrip": true,
    "decoded": 18446744073709551615
  },
  {
    "cbor": "wkkBAAAAAAAAAAA=",
    "hex": "c249010000000000000000",
    "roundtrip": true,
    "decoded": 18446744073709551616
  },
  {
    "cbor": "O///////////",
    "hex": "3bffffffffffffffff",
    "roundtrip": true,
    "decoded": -18446744073709551616
  },
  {
    "cbor": "w0kBAAAAAAAAAAA=",
    "hex": "c349010000000000000000",
    "roundtrip": true,
    "decoded": -18446744073709551617
  },
  {
    "cbor": "IA==",
    "hex": "20",
    "roundtrip": true,
    "decoded": -1
  },
  {
    "cbor": "KQ==",
    "hex": "29",
    "roundtrip": true,
    "decoded": -10
  },
  {
    "cbor": "OGM=",
    "hex": "3863",
    "roundtrip": true,
    "decoded": -100
  },
  {
    "cbor": "OQPn",
    "hex": "3903e7",
    "roundtrip": true,
    "decoded": -1000
  },
  {
    "cbor": "+QAA",
    "hex": "f90000",
    "roundtrip": true,
    "decoded": 0.0
  },
  {
    "cbor": "+YAA",
    "hex": "f98000",
    "roundtrip": true,
    "decoded": -0.0
  },
  {
    "cbor": "+TwA",
    "hex": "f93c00",
    "roundtrip": true,
    "decoded": 1.0
  },
  {
    "cbor": "+z/xmZmZmZma",
    "hex": "fb3ff199999999999a",
    "roundtrip": true,
    "decoded": 1.1
  },
  {
    "cbor": "+T4A",
    "hex": "f93e00",
    "roundtrip": true,
    "decoded": 1.5
  },
  {
    "cbor": "+Xv/",
    "hex": "f97bff",
    "roundtrip": true,
    "decoded": 65504.0
  },
  {
    "cbor": "+kfDUAA=",
    "hex": "fa47c35000",
    "roundtrip": true,
    "decoded": 100000.0
  },
  {
    "cbor": "+n9///8=",
    "hex": "fa7f7fffff",
    "roundtrip": true,
    "decoded": 3.4028234663852886e+38
  },
  {
    "cbor": "+3435DyIAHWc",
    "hex": "fb7e37e43c8800759c",
    "roundtrip": true,
    "decoded": 1.0e+300
  },
  {
    "cbor": "+QAB",
    "hex": "f90001",
    "roundtrip": true,
    "decoded": 5.960464477539063e-08
  },
  {
    "cbor": "+QQA",
    "hex": "f90400",
    "roundtrip": true,
    "decoded": 6.103515625e-05
  },
  {
    "cbor": "+cQA",
    "hex": "f9c400",
    "roundtrip": true,
    "decoded": -4.0
  },
  {
    "cbor": "+8AQZmZmZmZm",
    "hex": "fbc010666666666666",
    "roundtrip": true,
    "decoded": -4.1
  },
  {
    "cbor": "+XwA",
    "hex": "f97c00",
    "roundtrip": true,
    "diagnostic": "Infinity"
  },
  {
    "cbor": "+X4A",
    "hex": "f97e00",
    "roundtrip": true,
    "diagnostic": "NaN"
  },
  {
    "cbor": "+fwA",
    "hex": "f9fc00",
    "roundtrip": true,
    "diagnostic": "-Infinity"
  },
  {
    "cbor": "+n+AAAA=",
    "hex": "fa7f800000",
    "roundtrip": false,
    "diagnostic": "Infinity"
  },
  {
    "cbor": "+n/AAAA=",
    "hex": "fa7fc00000",
    "roundtrip": false,
    "diagnostic": "NaN"
  },
  {
    "cbor": "+v+AAAA=",
    "hex": "faff800000",
    "roundtrip": false,
    "diagnostic": "-Infinity"
  },
  {
    "cbor": "+3/wAAAAAAAA",
    "hex": "fb7ff0000000000000",
    "roundtrip": false,
    "diagnostic": "Infinity"
  },
  {
    "cbor": "+3/4AAAAAAAA",
    "hex": "fb7ff8000000000000",
    "roundtrip": false,
    "diagnostic": "NaN"
  },
  {
    "cbor": "+//wAAAAAAAA",
    "hex": "fbfff0000000000000",
    "roundtrip": false,
    "diagnostic": "-Infinity"
  },
  {
    "cbor": "9A==",
    "hex": "f4",
    "roundtrip": true,
    "decoded": false
  },
  {
    "cbor": "9Q==",
    "hex": "f5",
    "roundtrip": true,
    "decoded": true
  },
  {
    "cbor": "9g==",
    "hex": "f6",
    "roundtrip": true,
    "decoded": null
  },
  {
    "cbor": "9w==",
    "hex": "f7",
    "roundtrip": true,
    "diagnostic": "undefined"
  },
  {
    "cbor": "8A==",
    "hex": "f0",
    "roundtrip": true,
    "diagnostic": "simple(16)"
  },
  {
    "cbor": "+Bg=",
    "hex": "f818",
    "roundtrip": true,
    "diagnostic": "simple(24)"
  },
  {
    "cbor": "+P8=",
    "hex": "f8ff",
    "roundtrip": true,
    "diagnostic": "simple(255)"
  },
  {
    "cbor": "wHQyMDEzLTAzLTIxVDIwOjA0OjAwWg==",
    "hex": "c074323031332d30332d32315432303a30343a30305a",
    "roundtrip": true,
    "diagnostic": "0(\"2013-03-21T20:04:00Z\")"
  },
  {
    "cbor": "wRpRS2ew",
    "hex": "c11a514b67b0",
    "roundtrip": true,
    "diagnostic": "1(1363896240)"
  },
  {
    "cbor": "wftB1FLZ7CAAAA==",
    "hex": "c1fb41d452d9ec200000",
    "roundtrip": true,
    "diagnostic": "1(1363896240.5)"
  },
  {
    "cbor": "10QBAgME",
    "hex": "d74401020304",
    "roundtrip": true,
    "diagnostic": "23(h'01020304')"
  },
  {
    "cbor": "2BhFZElFVEY=",
    "hex": "d818456449455446",
    "roundtrip": true,
    "diagnostic": "24(h'6449455446')"
  },
  {
    "cbor": "2CB2aHR0cDovL3d3dy5leGFtcGxlLmNvbQ==",
    "hex": "d82076687474703a2f2f7777772e6578616d706c652e636f6d",
    "roundtrip": true,
    "diagnostic": "32(\"http://www.example.com\")"
  },
  {
    "cbor": "QA==",
    "hex": "40",
    "roundtrip": true,
    "diagnostic": "h''"
  },
  {
    "cbor": "RAECAwQ=",
    "hex": "4401020304",
    "roundtrip": true,
    "diagnostic": "h'01020304'"
  },
  {
    "cbor": "YA==",
    "hex": "60",
    "roundtrip": true,
    "decoded": ""
  },
  {
    "cbor": "YWE=",
    "hex": "6161",
    "roundtrip": true,
    "decoded": "a"
  },
  {
    "cbor": "ZElFVEY=",
    "hex": "6449455446",
    "roundtrip": true,
    "decoded": "IETF"
  },
  {
    "cbor": "YiJc",
    "hex": "62225c",
    "roundtrip": true,
    "decoded": "\"\\"
  },
  {
    "cbor": "YsO8",
    "hex": "62c3bc",
    "roundtrip": true,
    "decoded": "ü"
  },
  {
    "cbor": "Y+awtA==",
    "hex": "63e6b0b4",
    "roundtrip": true,
    "decoded": "水"
  },
  {
    "cbor": "ZPCQhZE=",
    "hex": "64f0908591",
    "roundtrip": true,
    "decoded": "𐅑"
  },
  {
    "cbor": "gA==",
    "hex": "80",
    "roundtrip": true,
    "decoded": [

    ]
  },
  {
    "cbor": "gwECAw==",
    "hex": "83010203",
    "roundtrip": true,
    "decoded": [
      1,
      2,
      3
    ]
  },
  {
    "cbor": "gwGCAgOCBAU=",
    "hex": "8301820203820405",
    "roundtrip": true,
    "decoded": [
      1,
      [
        2,
        3
      ],
      [
        4,
        5
      ]
    ]
  },
  {
    "cbor": "mBkBAgMEBQYHCAkKCwwNDg8QERITFBUWFxgYGBk=",
    "hex": "98190102030405060708090a0b0c0d0e0f101112131415161718181819",
    "roundtrip": true,
    "decoded": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25
    ]
  },
  {
    "cbor": "oA==",
    "hex": "a0",
    "roundtrip": true,
    "decoded": {
    }
  },
  {
    "cbor": "ogECAwQ=",
    "hex": "a201020304",
    "roundtrip": true,
    "diagnostic": "{1: 2, 3: 4}"
  },
  {
    "cbor": "omFhAWFiggID",
    "hex": "a26161016162820203",
    "roundtrip": true,
    "decoded": {
      "a": 1,
      "b": [
        2,
        3
      ]
    }
  },
  {
    "cbor": "gmFhoWFiYWM=",
    "hex": "826161a161626163",
    "roundtrip": true,
    "decoded": [
      "a",
      {
        "b": "c"
      }
    ]
  },
  {
    "cbor": "pWFhYUFhYmFCYWNhQ2FkYURhZWFF",
    "hex": "a56161614161626142616361436164614461656145",
    "roundtrip": true,
    "decoded": {
      "a": "A",
      "b": "B",
      "c": "C",
      "d": "D",
      "e": "E"
    }
  },
  {
    "cbor": "X0IBAkMDBAX/",
    "hex": "5f42010243030405ff",
    "roundtrip": false,
    "diagnostic": "(_ h'0102', h'030405')"
  },
  {
    "cbor": "f2VzdHJlYWRtaW5n/w==",
    "hex": "7f657374726561646d696e67ff",
    "roundtrip": false,
    "decoded": "streaming"
  },
  {
    "cbor": "n/8=",
    "hex": "9fff",
    "roundtrip": false,
    "decoded": [

    ]
  },
  {
    "cbor": "nwGCAgOfBAX//w==",
    "hex": "9f018202039f0405ffff",
    "roundtrip": false,
    "decoded": [
      1,
      [
        2,
        3
      ],
      [
        4,
        5
      ]
    ]
  },
  {
    "cbor": "nwGCAgOCBAX/",
    "hex": "9f01820203820405ff",
    "roundtrip": false,
    "decoded": [
      1,
      [
        2,
        3
      ],
      [
        4,
        5
      ]
    ]
  },
  {
    "cbor": "gwGCAgOfBAX/",
    "hex": "83018202039f0405ff",
    "roundtrip": false,
    "decoded": [
      1,
      [
        2,
        3
      ],
      [
        4,
        5
      ]
    ]
  },
  {
    "cbor": "gwGfAgP/ggQF",
    "hex": "83019f0203ff820405",
    "roundtrip": false,
    "decoded": [
      1,
      [
        2,
        3
      ],
      [
        4,
        5
      ]
    ]
  },
  {
    "cbor": "nwECAwQFBgcICQoLDA0ODxAREhMUFRYXGBgYGf8=",
    "hex": "9f0102030405060708090a0b0c0d0e0f101112131415161718181819ff",
    "roundtrip": false,
    "decoded": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25
    ]
  },
  {
    "cbor": "v2FhAWFinwID//8=",
    "hex": "bf61610161629f0203ffff",
    "roundtrip": false,
    "decoded": {
      "a": 1,
      "b": [
        2,
        3
      ]
    }
  },
  {
    "cbor": "gmFhv2FiYWP/",
    "hex": "826161bf61626163ff",
    "roundtrip": false,
    "decoded": [
      "a",
      {
        "b": "c"
      }
    ]
  },
  {
    "cbor": "v2NGdW71Y0FtdCH/",
    "hex": "bf6346756ef563416d7421ff",
    "roundtrip": false,
    "decoded": {
      "Fun": true,
      "Amt": -2
    }
  }
]

'''
'''--- runtime/cbor/fuzz/fuzz_targets/from_reader.rs ---
#![no_main]
#[macro_use] extern crate libfuzzer_sys;
extern crate serde_cbor;

use serde_cbor::Value;

fuzz_target!(|data: &[u8]| {
    let mut data = data;
    let _ = serde_cbor::from_reader::<Value, _>(&mut data);
});

'''
'''--- runtime/cbor/fuzz/fuzz_targets/from_slice.rs ---
#![no_main]
#[macro_use] extern crate libfuzzer_sys;
extern crate serde_cbor;

use serde_cbor::Value;

fuzz_target!(|data: &[u8]| {
    let _ = serde_cbor::from_slice::<Value>(data);
});

'''
'''--- runtime/cbor/fuzz/make_corpus.py ---
#!/usr/bin/env python

import base64
import json
import sys
import os.path

out_dir = sys.argv[1]
os.makedirs(out_dir)

with open("appendix_a.json") as f:
    appendix = json.load(f)

for i, entry in enumerate(appendix):
    buf = base64.b64decode(entry["cbor"])
    with open(os.path.join(out_dir, str(i)), 'wb') as f:
        f.write(buf)

'''
'''--- runtime/cbor/src/de.rs ---
//! Deserialization.

use byteorder::{BigEndian, ByteOrder};
use core::f32;
use core::marker::PhantomData;
use core::result;
use core::str;
use half::f16;
use serde::de;
#[cfg(feature = "std")]
use std::io;

use crate::error::{Error, ErrorCode, Result};
#[cfg(not(feature = "unsealed_read_write"))]
use crate::read::EitherLifetime;
#[cfg(feature = "unsealed_read_write")]
pub use crate::read::EitherLifetime;
use crate::read::Offset;
#[cfg(feature = "std")]
pub use crate::read::{IoRead, SliceRead};
pub use crate::read::{MutSliceRead, Read, SliceReadFixed};

/// Decodes a value from CBOR data in a slice.
///
/// # Examples
///
/// Deserialize a `String`
///
/// ```
/// # use serde_cbor::de;
/// let v: Vec<u8> = vec![0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72];
/// let value: String = de::from_slice(&v[..]).unwrap();
/// assert_eq!(value, "foobar");
/// ```
///
/// Deserialize a borrowed string with zero copies.
///
/// ```
/// # use serde_cbor::de;
/// let v: Vec<u8> = vec![0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72];
/// let value: &str = de::from_slice(&v[..]).unwrap();
/// assert_eq!(value, "foobar");
/// ```
#[cfg(feature = "std")]
pub fn from_slice<'a, T>(slice: &'a [u8]) -> Result<T>
where
    T: de::Deserialize<'a>,
{
    let mut deserializer = Deserializer::from_slice(slice);
    let value = de::Deserialize::deserialize(&mut deserializer)?;
    deserializer.end()?;
    Ok(value)
}

// When the "std" feature is enabled there should be little to no need to ever use this function,
// as `from_slice` covers all use cases (at the expense of being less efficient).
#[cfg_attr(feature = "std", doc(hidden))]
/// Decode a value from CBOR data in a mutable slice.
///
/// This can be used in analogy to `from_slice`. Unlike `from_slice`, this will use the slice's
/// mutability to rearrange data in it in order to resolve indefinite byte or text strings without
/// resorting to allocations.
pub fn from_mut_slice<'a, T>(slice: &'a mut [u8]) -> Result<T>
where
    T: de::Deserialize<'a>,
{
    let mut deserializer = Deserializer::from_mut_slice(slice);
    let value = de::Deserialize::deserialize(&mut deserializer)?;
    deserializer.end()?;
    Ok(value)
}

// When the "std" feature is enabled there should be little to no need to ever use this function,
// as `from_slice` covers all use cases and is much more reliable (at the expense of being less
// efficient).
#[cfg_attr(feature = "std", doc(hidden))]
/// Decode a value from CBOR data using a scratch buffer.
///
/// Users should generally prefer to use `from_slice` or `from_mut_slice` over this function,
/// as decoding may fail when the scratch buffer turns out to be too small.
///
/// A realistic use case for this method would be decoding in a `no_std` environment from an
/// immutable slice that is too large to copy.
pub fn from_slice_with_scratch<'a, 'b, T>(slice: &'a [u8], scratch: &'b mut [u8]) -> Result<T>
where
    T: de::Deserialize<'a>,
{
    let mut deserializer = Deserializer::from_slice_with_scratch(slice, scratch);
    let value = de::Deserialize::deserialize(&mut deserializer)?;
    deserializer.end()?;
    Ok(value)
}

/// Decodes a value from CBOR data in a reader.
///
/// # Examples
///
/// Deserialize a `String`
///
/// ```
/// # use serde_cbor::de;
/// let v: Vec<u8> = vec![0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72];
/// let value: String = de::from_reader(&v[..]).unwrap();
/// assert_eq!(value, "foobar");
/// ```
///
/// Note that `from_reader` cannot borrow data:
///
/// ```compile_fail
/// # use serde_cbor::de;
/// let v: Vec<u8> = vec![0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72];
/// let value: &str = de::from_reader(&v[..]).unwrap();
/// assert_eq!(value, "foobar");
/// ```
#[cfg(feature = "std")]
pub fn from_reader<T, R>(reader: R) -> Result<T>
where
    T: de::DeserializeOwned,
    R: io::Read,
{
    let mut deserializer = Deserializer::from_reader(reader);
    let value = de::Deserialize::deserialize(&mut deserializer)?;
    deserializer.end()?;
    Ok(value)
}

/// A Serde `Deserialize`r of CBOR data.
pub struct Deserializer<R> {
    read: R,
    remaining_depth: u8,
}

#[cfg(feature = "std")]
impl<R> Deserializer<IoRead<R>>
where
    R: io::Read,
{
    /// Constructs a `Deserializer` which reads from a `Read`er.
    pub fn from_reader(reader: R) -> Deserializer<IoRead<R>> {
        Deserializer::new(IoRead::new(reader))
    }
}

#[cfg(feature = "std")]
impl<'a> Deserializer<SliceRead<'a>> {
    /// Constructs a `Deserializer` which reads from a slice.
    ///
    /// Borrowed strings and byte slices will be provided when possible.
    pub fn from_slice(bytes: &'a [u8]) -> Deserializer<SliceRead<'a>> {
        Deserializer::new(SliceRead::new(bytes))
    }
}

impl<'a> Deserializer<MutSliceRead<'a>> {
    /// Constructs a `Deserializer` which reads from a mutable slice that doubles as its own
    /// scratch buffer.
    ///
    /// Borrowed strings and byte slices will be provided even for indefinite strings.
    pub fn from_mut_slice(bytes: &'a mut [u8]) -> Deserializer<MutSliceRead<'a>> {
        Deserializer::new(MutSliceRead::new(bytes))
    }
}

impl<'a, 'b> Deserializer<SliceReadFixed<'a, 'b>> {
    #[doc(hidden)]
    pub fn from_slice_with_scratch(
        bytes: &'a [u8],
        scratch: &'b mut [u8],
    ) -> Deserializer<SliceReadFixed<'a, 'b>> {
        Deserializer::new(SliceReadFixed::new(bytes, scratch))
    }
}

impl<'de, R> Deserializer<R>
where
    R: Read<'de>,
{
    /// Constructs a `Deserializer` from one of the possible serde_cbor input sources.
    ///
    /// `from_slice` and `from_reader` should normally be used instead of this method.
    pub fn new(read: R) -> Self {
        Deserializer {
            read,
            remaining_depth: 128,
        }
    }

    /// This method should be called after a value has been deserialized to ensure there is no
    /// trailing data in the input source.
    pub fn end(&mut self) -> Result<()> {
        match self.next()? {
            Some(_) => Err(self.error(ErrorCode::TrailingData)),
            None => Ok(()),
        }
    }

    /// Turn a CBOR deserializer into an iterator over values of type T.
    pub fn into_iter<T>(self) -> StreamDeserializer<'de, R, T>
    where
        T: de::Deserialize<'de>,
    {
        StreamDeserializer {
            de: self,
            output: PhantomData,
            lifetime: PhantomData,
        }
    }

    fn next(&mut self) -> Result<Option<u8>> {
        self.read.next()
    }

    fn peek(&mut self) -> Result<Option<u8>> {
        self.read.peek()
    }

    fn consume(&mut self) {
        self.read.discard();
    }

    fn error(&self, reason: ErrorCode) -> Error {
        let offset = self.read.offset();
        Error::syntax(reason, offset)
    }

    fn parse_u8(&mut self) -> Result<u8> {
        match self.next()? {
            Some(byte) => Ok(byte),
            None => Err(self.error(ErrorCode::EofWhileParsingValue)),
        }
    }

    fn parse_u16(&mut self) -> Result<u16> {
        let mut buf = [0; 2];
        self.read.read_into(&mut buf)?;
        Ok(BigEndian::read_u16(&buf))
    }

    fn parse_u32(&mut self) -> Result<u32> {
        let mut buf = [0; 4];
        self.read.read_into(&mut buf)?;
        Ok(BigEndian::read_u32(&buf))
    }

    fn parse_u64(&mut self) -> Result<u64> {
        let mut buf = [0; 8];
        self.read.read_into(&mut buf)?;
        Ok(BigEndian::read_u64(&buf))
    }

    fn parse_bytes<V>(&mut self, len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        match self.read.read(len)? {
            EitherLifetime::Long(buf) => visitor.visit_borrowed_bytes(buf),
            EitherLifetime::Short(buf) => visitor.visit_bytes(buf),
        }
    }

    fn parse_indefinite_bytes<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.read.clear_buffer();
        loop {
            let byte = self.parse_u8()?;
            let len = match byte {
                0x40..=0x57 => byte as usize - 0x40,
                0x58 => self.parse_u8()? as usize,
                0x59 => self.parse_u16()? as usize,
                0x5a => self.parse_u32()? as usize,
                0x5b => {
                    let len = self.parse_u64()?;
                    if len > usize::max_value() as u64 {
                        return Err(self.error(ErrorCode::LengthOutOfRange));
                    }
                    len as usize
                }
                0xff => break,
                _ => return Err(self.error(ErrorCode::UnexpectedCode)),
            };

            self.read.read_to_buffer(len)?;
        }

        match self.read.take_buffer() {
            EitherLifetime::Long(buf) => visitor.visit_borrowed_bytes(buf),
            EitherLifetime::Short(buf) => visitor.visit_bytes(buf),
        }
    }

    fn convert_str<'a>(buf: &'a [u8], buf_end_offset: u64) -> Result<&'a str> {
        match str::from_utf8(buf) {
            Ok(s) => Ok(s),
            Err(e) => {
                let shift = buf.len() - e.valid_up_to();
                let offset = buf_end_offset - shift as u64;
                Err(Error::syntax(ErrorCode::InvalidUtf8, offset))
            }
        }
    }

    fn parse_str<V>(&mut self, len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        if let Some(offset) = self.read.offset().checked_add(len as u64) {
            match self.read.read(len)? {
                EitherLifetime::Long(buf) => {
                    let s = Self::convert_str(buf, offset)?;
                    visitor.visit_borrowed_str(s)
                }
                EitherLifetime::Short(buf) => {
                    let s = Self::convert_str(buf, offset)?;
                    visitor.visit_str(s)
                }
            }
        } else {
            // An overflow would have occured.
            Err(Error::syntax(
                ErrorCode::LengthOutOfRange,
                self.read.offset(),
            ))
        }
    }

    fn parse_indefinite_str<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.read.clear_buffer();
        loop {
            let byte = self.parse_u8()?;
            let len = match byte {
                0x60..=0x77 => byte as usize - 0x60,
                0x78 => self.parse_u8()? as usize,
                0x79 => self.parse_u16()? as usize,
                0x7a => self.parse_u32()? as usize,
                0x7b => {
                    let len = self.parse_u64()?;
                    if len > usize::max_value() as u64 {
                        return Err(self.error(ErrorCode::LengthOutOfRange));
                    }
                    len as usize
                }
                0xff => break,
                _ => return Err(self.error(ErrorCode::UnexpectedCode)),
            };

            self.read.read_to_buffer(len)?;
        }

        let offset = self.read.offset();
        match self.read.take_buffer() {
            EitherLifetime::Long(buf) => {
                let s = Self::convert_str(buf, offset)?;
                visitor.visit_borrowed_str(s)
            }
            EitherLifetime::Short(buf) => {
                let s = Self::convert_str(buf, offset)?;
                visitor.visit_str(s)
            }
        }
    }

    fn recursion_checked<F, T>(&mut self, f: F) -> Result<T>
    where
        F: FnOnce(&mut Deserializer<R>) -> Result<T>,
    {
        self.remaining_depth -= 1;
        if self.remaining_depth == 0 {
            return Err(self.error(ErrorCode::RecursionLimitExceeded));
        }
        let r = f(self);
        self.remaining_depth += 1;
        r
    }

    fn parse_array<V>(&mut self, mut len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_seq(SeqAccess { de, len: &mut len })?;

            if len != 0 {
                Err(de.error(ErrorCode::TrailingData))
            } else {
                Ok(value)
            }
        })
    }

    fn parse_indefinite_array<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_seq(IndefiniteSeqAccess { de })?;
            match de.next()? {
                Some(0xff) => Ok(value),
                Some(_) => Err(de.error(ErrorCode::TrailingData)),
                None => Err(de.error(ErrorCode::EofWhileParsingArray)),
            }
        })
    }

    fn parse_map<V>(&mut self, mut len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_map(MapAccess { de, len: &mut len })?;

            if len != 0 {
                Err(de.error(ErrorCode::TrailingData))
            } else {
                Ok(value)
            }
        })
    }

    fn parse_indefinite_map<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_map(IndefiniteMapAccess { de })?;
            match de.next()? {
                Some(0xff) => Ok(value),
                Some(_) => Err(de.error(ErrorCode::TrailingData)),
                None => Err(de.error(ErrorCode::EofWhileParsingMap)),
            }
        })
    }

    fn parse_enum<V>(&mut self, mut len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_enum(VariantAccess {
                seq: SeqAccess { de, len: &mut len },
            })?;

            if len != 0 {
                Err(de.error(ErrorCode::TrailingData))
            } else {
                Ok(value)
            }
        })
    }

    fn parse_enum_map<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let mut len = 1;
            let value = visitor.visit_enum(VariantAccessMap {
                map: MapAccess { de, len: &mut len },
            })?;

            if len != 0 {
                Err(de.error(ErrorCode::TrailingData))
            } else {
                Ok(value)
            }
        })
    }

    fn parse_indefinite_enum<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.recursion_checked(|de| {
            let value = visitor.visit_enum(VariantAccess {
                seq: IndefiniteSeqAccess { de },
            })?;
            match de.next()? {
                Some(0xff) => Ok(value),
                Some(_) => Err(de.error(ErrorCode::TrailingData)),
                None => Err(de.error(ErrorCode::EofWhileParsingArray)),
            }
        })
    }

    fn parse_f16(&mut self) -> Result<f32> {
        Ok(f32::from(f16::from_bits(self.parse_u16()?)))
    }

    fn parse_f32(&mut self) -> Result<f32> {
        let mut buf = [0; 4];
        self.read.read_into(&mut buf)?;
        Ok(BigEndian::read_f32(&buf))
    }

    fn parse_f64(&mut self) -> Result<f64> {
        let mut buf = [0; 8];
        self.read.read_into(&mut buf)?;
        Ok(BigEndian::read_f64(&buf))
    }

    // Don't warn about the `unreachable!` in case
    // exhaustive integer pattern matching is enabled.
    #[allow(unreachable_patterns)]
    fn parse_value<V>(&mut self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        let byte = self.parse_u8()?;
        match byte {
            // Major type 0: an unsigned integer
            0x00..=0x17 => visitor.visit_u8(byte),
            0x18 => {
                let value = self.parse_u8()?;
                visitor.visit_u8(value)
            }
            0x19 => {
                let value = self.parse_u16()?;
                visitor.visit_u16(value)
            }
            0x1a => {
                let value = self.parse_u32()?;
                visitor.visit_u32(value)
            }
            0x1b => {
                let value = self.parse_u64()?;
                visitor.visit_u64(value)
            }
            0x1c..=0x1f => Err(self.error(ErrorCode::UnassignedCode)),

            // Major type 1: a negative integer
            0x20..=0x37 => visitor.visit_i8(-1 - (byte - 0x20) as i8),
            0x38 => {
                let value = self.parse_u8()?;
                visitor.visit_i16(-1 - i16::from(value))
            }
            0x39 => {
                let value = self.parse_u16()?;
                visitor.visit_i32(-1 - i32::from(value))
            }
            0x3a => {
                let value = self.parse_u32()?;
                visitor.visit_i64(-1 - i64::from(value))
            }
            0x3b => {
                let value = self.parse_u64()?;
                if value > i64::max_value() as u64 {
                    return visitor.visit_i128(-1 - value as i128);
                }
                visitor.visit_i64(-1 - value as i64)
            }
            0x3c..=0x3f => Err(self.error(ErrorCode::UnassignedCode)),

            // Major type 2: a byte string
            0x40..=0x57 => self.parse_bytes(byte as usize - 0x40, visitor),
            0x58 => {
                let len = self.parse_u8()?;
                self.parse_bytes(len as usize, visitor)
            }
            0x59 => {
                let len = self.parse_u16()?;
                self.parse_bytes(len as usize, visitor)
            }
            0x5a => {
                let len = self.parse_u32()?;
                self.parse_bytes(len as usize, visitor)
            }
            0x5b => {
                let len = self.parse_u64()?;
                if len > usize::max_value() as u64 {
                    return Err(self.error(ErrorCode::LengthOutOfRange));
                }
                self.parse_bytes(len as usize, visitor)
            }
            0x5c..=0x5e => Err(self.error(ErrorCode::UnassignedCode)),
            0x5f => self.parse_indefinite_bytes(visitor),

            // Major type 3: a text string
            0x60..=0x77 => self.parse_str(byte as usize - 0x60, visitor),
            0x78 => {
                let len = self.parse_u8()?;
                self.parse_str(len as usize, visitor)
            }
            0x79 => {
                let len = self.parse_u16()?;
                self.parse_str(len as usize, visitor)
            }
            0x7a => {
                let len = self.parse_u32()?;
                self.parse_str(len as usize, visitor)
            }
            0x7b => {
                let len = self.parse_u64()?;
                if len > usize::max_value() as u64 {
                    return Err(self.error(ErrorCode::LengthOutOfRange));
                }
                self.parse_str(len as usize, visitor)
            }
            0x7c..=0x7e => Err(self.error(ErrorCode::UnassignedCode)),
            0x7f => self.parse_indefinite_str(visitor),

            // Major type 4: an array of data items
            0x80..=0x97 => self.parse_array(byte as usize - 0x80, visitor),
            0x98 => {
                let len = self.parse_u8()?;
                self.parse_array(len as usize, visitor)
            }
            0x99 => {
                let len = self.parse_u16()?;
                self.parse_array(len as usize, visitor)
            }
            0x9a => {
                let len = self.parse_u32()?;
                self.parse_array(len as usize, visitor)
            }
            0x9b => {
                let len = self.parse_u64()?;
                if len > usize::max_value() as u64 {
                    return Err(self.error(ErrorCode::LengthOutOfRange));
                }
                self.parse_array(len as usize, visitor)
            }
            0x9c..=0x9e => Err(self.error(ErrorCode::UnassignedCode)),
            0x9f => self.parse_indefinite_array(visitor),

            // Major type 5: a map of pairs of data items
            0xa0..=0xb7 => self.parse_map(byte as usize - 0xa0, visitor),
            0xb8 => {
                let len = self.parse_u8()?;
                self.parse_map(len as usize, visitor)
            }
            0xb9 => {
                let len = self.parse_u16()?;
                self.parse_map(len as usize, visitor)
            }
            0xba => {
                let len = self.parse_u32()?;
                self.parse_map(len as usize, visitor)
            }
            0xbb => {
                let len = self.parse_u64()?;
                if len > usize::max_value() as u64 {
                    return Err(self.error(ErrorCode::LengthOutOfRange));
                }
                self.parse_map(len as usize, visitor)
            }
            0xbc..=0xbe => Err(self.error(ErrorCode::UnassignedCode)),
            0xbf => self.parse_indefinite_map(visitor),

            // Major type 6: optional semantic tagging of other major types
            0xc0..=0xd7 => self.parse_value(visitor),
            0xd8 => {
                self.parse_u8()?;
                self.parse_value(visitor)
            }
            0xd9 => {
                self.parse_u16()?;
                self.parse_value(visitor)
            }
            0xda => {
                self.parse_u32()?;
                self.parse_value(visitor)
            }
            0xdb => {
                self.parse_u64()?;
                self.parse_value(visitor)
            }
            0xdc..=0xdf => Err(self.error(ErrorCode::UnassignedCode)),

            // Major type 7: floating-point numbers and other simple data types that need no content
            0xe0..=0xf3 => Err(self.error(ErrorCode::UnassignedCode)),
            0xf4 => visitor.visit_bool(false),
            0xf5 => visitor.visit_bool(true),
            0xf6 => visitor.visit_unit(),
            0xf7 => visitor.visit_unit(),
            0xf8 => Err(self.error(ErrorCode::UnassignedCode)),
            0xf9 => {
                let value = self.parse_f16()?;
                visitor.visit_f32(value)
            }
            0xfa => {
                let value = self.parse_f32()?;
                visitor.visit_f32(value)
            }
            0xfb => {
                let value = self.parse_f64()?;
                visitor.visit_f64(value)
            }
            0xfc..=0xfe => Err(self.error(ErrorCode::UnassignedCode)),
            0xff => Err(self.error(ErrorCode::UnexpectedCode)),

            _ => unreachable!(),
        }
    }
}

impl<'de, 'a, R> de::Deserializer<'de> for &'a mut Deserializer<R>
where
    R: Read<'de>,
{
    type Error = Error;

    #[inline]
    fn deserialize_any<V>(self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        self.parse_value(visitor)
    }

    #[inline]
    fn deserialize_option<V>(self, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        match self.peek()? {
            Some(0xf6) => {
                self.consume();
                visitor.visit_none()
            }
            _ => visitor.visit_some(self),
        }
    }

    #[inline]
    fn deserialize_newtype_struct<V>(self, _name: &str, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        visitor.visit_newtype_struct(self)
    }

    // Unit variants are encoded as just the variant identifier.
    // Tuple variants are encoded as an array of the variant identifier followed by the fields.
    // Struct variants are encoded as an array of the variant identifier followed by the struct.
    #[inline]
    fn deserialize_enum<V>(
        self,
        _name: &str,
        _variants: &'static [&'static str],
        visitor: V,
    ) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        match self.peek()? {
            Some(byte @ 0x80..=0x9f) => {
                self.consume();
                match byte {
                    0x80..=0x97 => self.parse_enum(byte as usize - 0x80, visitor),
                    0x98 => {
                        let len = self.parse_u8()?;
                        self.parse_enum(len as usize, visitor)
                    }
                    0x99 => {
                        let len = self.parse_u16()?;
                        self.parse_enum(len as usize, visitor)
                    }
                    0x9a => {
                        let len = self.parse_u32()?;
                        self.parse_enum(len as usize, visitor)
                    }
                    0x9b => {
                        let len = self.parse_u64()?;
                        if len > usize::max_value() as u64 {
                            return Err(self.error(ErrorCode::LengthOutOfRange));
                        }
                        self.parse_enum(len as usize, visitor)
                    }
                    0x9c..=0x9e => Err(self.error(ErrorCode::UnassignedCode)),
                    0x9f => self.parse_indefinite_enum(visitor),

                    _ => unreachable!(),
                }
            }
            Some(0xa1) => {
                self.consume();
                self.parse_enum_map(visitor)
            }
            None => Err(self.error(ErrorCode::EofWhileParsingValue)),
            _ => visitor.visit_enum(UnitVariantAccess { de: self }),
        }
    }

    #[inline]
    fn is_human_readable(&self) -> bool {
        false
    }

    serde::forward_to_deserialize_any! {
        bool i8 i16 i32 i64 i128 u8 u16 u32 u64 u128 f32 f64 char str string unit
        unit_struct seq tuple tuple_struct map struct identifier ignored_any
        bytes byte_buf
    }
}

impl<R> Deserializer<R>
where
    R: Offset,
{
    /// Return the current offset in the reader
    #[inline]
    pub fn byte_offset(&self) -> usize {
        self.read.byte_offset()
    }
}

trait MakeError {
    fn error(&self, code: ErrorCode) -> Error;
}

struct SeqAccess<'a, R> {
    de: &'a mut Deserializer<R>,
    len: &'a mut usize,
}

impl<'de, 'a, R> de::SeqAccess<'de> for SeqAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;

    fn next_element_seed<T>(&mut self, seed: T) -> Result<Option<T::Value>>
    where
        T: de::DeserializeSeed<'de>,
    {
        if *self.len == 0 {
            return Ok(None);
        }
        *self.len -= 1;

        let value = seed.deserialize(&mut *self.de)?;
        Ok(Some(value))
    }

    fn size_hint(&self) -> Option<usize> {
        Some(*self.len)
    }
}

impl<'de, 'a, R> MakeError for SeqAccess<'a, R>
where
    R: Read<'de>,
{
    fn error(&self, code: ErrorCode) -> Error {
        self.de.error(code)
    }
}

struct IndefiniteSeqAccess<'a, R> {
    de: &'a mut Deserializer<R>,
}

impl<'de, 'a, R> de::SeqAccess<'de> for IndefiniteSeqAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;

    fn next_element_seed<T>(&mut self, seed: T) -> Result<Option<T::Value>>
    where
        T: de::DeserializeSeed<'de>,
    {
        match self.de.peek()? {
            Some(0xff) => return Ok(None),
            Some(_) => {}
            None => return Err(self.de.error(ErrorCode::EofWhileParsingArray)),
        }

        let value = seed.deserialize(&mut *self.de)?;
        Ok(Some(value))
    }
}

impl<'de, 'a, R> MakeError for IndefiniteSeqAccess<'a, R>
where
    R: Read<'de>,
{
    fn error(&self, code: ErrorCode) -> Error {
        self.de.error(code)
    }
}

struct MapAccess<'a, R> {
    de: &'a mut Deserializer<R>,
    len: &'a mut usize,
}

impl<'de, 'a, R> de::MapAccess<'de> for MapAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;

    fn next_key_seed<K>(&mut self, seed: K) -> Result<Option<K::Value>>
    where
        K: de::DeserializeSeed<'de>,
    {
        if *self.len == 0 {
            return Ok(None);
        }
        *self.len -= 1;

        let value = seed.deserialize(&mut *self.de)?;
        Ok(Some(value))
    }

    fn next_value_seed<V>(&mut self, seed: V) -> Result<V::Value>
    where
        V: de::DeserializeSeed<'de>,
    {
        seed.deserialize(&mut *self.de)
    }

    fn size_hint(&self) -> Option<usize> {
        Some(*self.len)
    }
}

impl<'de, 'a, R> MakeError for MapAccess<'a, R>
where
    R: Read<'de>,
{
    fn error(&self, code: ErrorCode) -> Error {
        self.de.error(code)
    }
}

struct IndefiniteMapAccess<'a, R> {
    de: &'a mut Deserializer<R>,
}

impl<'de, 'a, R> de::MapAccess<'de> for IndefiniteMapAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;

    fn next_key_seed<K>(&mut self, seed: K) -> Result<Option<K::Value>>
    where
        K: de::DeserializeSeed<'de>,
    {
        match self.de.peek()? {
            Some(0xff) => return Ok(None),
            Some(_) => {}
            None => return Err(self.de.error(ErrorCode::EofWhileParsingMap)),
        }

        let value = seed.deserialize(&mut *self.de)?;
        Ok(Some(value))
    }

    fn next_value_seed<V>(&mut self, seed: V) -> Result<V::Value>
    where
        V: de::DeserializeSeed<'de>,
    {
        seed.deserialize(&mut *self.de)
    }
}

struct UnitVariantAccess<'a, R> {
    de: &'a mut Deserializer<R>,
}

impl<'de, 'a, R> de::EnumAccess<'de> for UnitVariantAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;
    type Variant = UnitVariantAccess<'a, R>;

    fn variant_seed<V>(self, seed: V) -> Result<(V::Value, UnitVariantAccess<'a, R>)>
    where
        V: de::DeserializeSeed<'de>,
    {
        let variant = seed.deserialize(&mut *self.de)?;
        Ok((variant, self))
    }
}

impl<'de, 'a, R> de::VariantAccess<'de> for UnitVariantAccess<'a, R>
where
    R: Read<'de>,
{
    type Error = Error;

    fn unit_variant(self) -> Result<()> {
        Ok(())
    }

    fn newtype_variant_seed<T>(self, _seed: T) -> Result<T::Value>
    where
        T: de::DeserializeSeed<'de>,
    {
        Err(de::Error::invalid_type(
            de::Unexpected::UnitVariant,
            &"newtype variant",
        ))
    }

    fn tuple_variant<V>(self, _len: usize, _visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        Err(de::Error::invalid_type(
            de::Unexpected::UnitVariant,
            &"tuple variant",
        ))
    }

    fn struct_variant<V>(self, _fields: &'static [&'static str], _visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        Err(de::Error::invalid_type(
            de::Unexpected::UnitVariant,
            &"struct variant",
        ))
    }
}

struct VariantAccess<T> {
    seq: T,
}

impl<'de, T> de::EnumAccess<'de> for VariantAccess<T>
where
    T: de::SeqAccess<'de, Error = Error> + MakeError,
{
    type Error = Error;
    type Variant = VariantAccess<T>;

    fn variant_seed<V>(mut self, seed: V) -> Result<(V::Value, VariantAccess<T>)>
    where
        V: de::DeserializeSeed<'de>,
    {
        let variant = match self.seq.next_element_seed(seed) {
            Ok(Some(variant)) => variant,
            Ok(None) => return Err(self.seq.error(ErrorCode::ArrayTooShort)),
            Err(e) => return Err(e),
        };
        Ok((variant, self))
    }
}

impl<'de, T> de::VariantAccess<'de> for VariantAccess<T>
where
    T: de::SeqAccess<'de, Error = Error> + MakeError,
{
    type Error = Error;

    fn unit_variant(mut self) -> Result<()> {
        match self.seq.next_element() {
            Ok(Some(())) => Ok(()),
            Ok(None) => Err(self.seq.error(ErrorCode::ArrayTooLong)),
            Err(e) => Err(e),
        }
    }

    fn newtype_variant_seed<S>(mut self, seed: S) -> Result<S::Value>
    where
        S: de::DeserializeSeed<'de>,
    {
        match self.seq.next_element_seed(seed) {
            Ok(Some(variant)) => Ok(variant),
            Ok(None) => Err(self.seq.error(ErrorCode::ArrayTooShort)),
            Err(e) => Err(e),
        }
    }

    fn tuple_variant<V>(self, _len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        visitor.visit_seq(self.seq)
    }

    fn struct_variant<V>(mut self, _fields: &'static [&'static str], visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        let seed = StructVariantSeed { visitor };
        match self.seq.next_element_seed(seed) {
            Ok(Some(variant)) => Ok(variant),
            Ok(None) => Err(self.seq.error(ErrorCode::ArrayTooShort)),
            Err(e) => Err(e),
        }
    }
}

struct StructVariantSeed<V> {
    visitor: V,
}

impl<'de, V> de::DeserializeSeed<'de> for StructVariantSeed<V>
where
    V: de::Visitor<'de>,
{
    type Value = V::Value;

    fn deserialize<D>(self, de: D) -> result::Result<V::Value, D::Error>
    where
        D: de::Deserializer<'de>,
    {
        de.deserialize_any(self.visitor)
    }
}

/// Iterator that deserializes a stream into multiple CBOR values.
///
/// A stream deserializer can be created from any CBOR deserializer using the
/// `Deserializer::into_iter` method.
pub struct StreamDeserializer<'de, R, T> {
    de: Deserializer<R>,
    output: PhantomData<T>,
    lifetime: PhantomData<&'de ()>,
}

impl<'de, R, T> StreamDeserializer<'de, R, T>
where
    R: Read<'de>,
    T: de::Deserialize<'de>,
{
    /// Create a new CBOR stream deserializer from one of the possible
    /// serde_cbor input sources.
    ///
    /// Typically it is more convenient to use one of these methods instead:
    ///
    /// * `Deserializer::from_slice(...).into_iter()`
    /// * `Deserializer::from_reader(...).into_iter()`
    pub fn new(read: R) -> StreamDeserializer<'de, R, T> {
        StreamDeserializer {
            de: Deserializer::new(read),
            output: PhantomData,
            lifetime: PhantomData,
        }
    }
}

impl<'de, R, T> Iterator for StreamDeserializer<'de, R, T>
where
    R: Read<'de>,
    T: de::Deserialize<'de>,
{
    type Item = Result<T>;

    fn next(&mut self) -> Option<Result<T>> {
        match self.de.peek() {
            Ok(Some(_)) => Some(T::deserialize(&mut self.de)),
            Ok(None) => None,
            Err(e) => Some(Err(e)),
        }
    }
}

struct VariantAccessMap<T> {
    map: T,
}

impl<'de, T> de::EnumAccess<'de> for VariantAccessMap<T>
where
    T: de::MapAccess<'de, Error = Error> + MakeError,
{
    type Error = Error;
    type Variant = VariantAccessMap<T>;

    fn variant_seed<V>(mut self, seed: V) -> Result<(V::Value, VariantAccessMap<T>)>
    where
        V: de::DeserializeSeed<'de>,
    {
        let variant = match self.map.next_key_seed(seed) {
            Ok(Some(variant)) => variant,
            Ok(None) => return Err(self.map.error(ErrorCode::ArrayTooShort)),
            Err(e) => return Err(e),
        };
        Ok((variant, self))
    }
}

impl<'de, T> de::VariantAccess<'de> for VariantAccessMap<T>
where
    T: de::MapAccess<'de, Error = Error> + MakeError,
{
    type Error = Error;

    fn unit_variant(mut self) -> Result<()> {
        match self.map.next_value() {
            Ok(()) => Ok(()),
            Err(e) => Err(e),
        }
    }

    fn newtype_variant_seed<S>(mut self, seed: S) -> Result<S::Value>
    where
        S: de::DeserializeSeed<'de>,
    {
        self.map.next_value_seed(seed)
    }

    fn tuple_variant<V>(mut self, _len: usize, visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        let seed = StructVariantSeed { visitor };
        self.map.next_value_seed(seed)
    }

    fn struct_variant<V>(mut self, _fields: &'static [&'static str], visitor: V) -> Result<V::Value>
    where
        V: de::Visitor<'de>,
    {
        let seed = StructVariantSeed { visitor };
        self.map.next_value_seed(seed)
    }
}

'''
'''--- runtime/cbor/src/error.rs ---
//! When serializing or deserializing CBOR goes wrong.
use core::fmt;
use core::result;
use serde::de;
use serde::ser;
#[cfg(feature = "std")]
use std::error;
#[cfg(feature = "std")]
use std::io;

/// This type represents all possible errors that can occur when serializing or deserializing CBOR
/// data.
pub struct Error(ErrorImpl);

/// Alias for a `Result` with the error type `serde_cbor::Error`.
pub type Result<T> = result::Result<T, Error>;

/// Categorizes the cause of a `serde_cbor::Error`.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub enum Category {
    /// The error was caused by a failure to read or write bytes on an IO stream.
    Io,
    /// The error was caused by input that was not syntactically valid CBOR.
    Syntax,
    /// The error was caused by input data that was semantically incorrect.
    Data,
    /// The error was caused by prematurely reaching the end of the input data.
    Eof,
}

impl Error {
    /// The byte offset at which the error occurred.
    pub fn offset(&self) -> u64 {
        self.0.offset
    }

    pub(crate) fn syntax(code: ErrorCode, offset: u64) -> Error {
        Error(ErrorImpl { code, offset })
    }

    #[cfg(feature = "std")]
    pub(crate) fn io(error: io::Error) -> Error {
        Error(ErrorImpl {
            code: ErrorCode::Io(error),
            offset: 0,
        })
    }

    #[cfg(all(not(feature = "std"), feature = "unsealed_read_write"))]
    /// Creates an error signalling that the underlying `Read` encountered an I/O error.
    pub fn io() -> Error {
        Error(ErrorImpl {
            code: ErrorCode::Io,
            offset: 0,
        })
    }

    #[cfg(feature = "unsealed_read_write")]
    /// Creates an error signalling that the scratch buffer was too small to fit the data.
    pub fn scratch_too_small(offset: u64) -> Error {
        Error(ErrorImpl {
            code: ErrorCode::ScratchTooSmall,
            offset: offset,
        })
    }

    #[cfg(not(feature = "unsealed_read_write"))]
    pub(crate) fn scratch_too_small(offset: u64) -> Error {
        Error(ErrorImpl {
            code: ErrorCode::ScratchTooSmall,
            offset,
        })
    }

    #[cfg(feature = "unsealed_read_write")]
    /// Creates an error with a custom message.
    ///
    /// **Note**: When the "std" feature is disabled, the message will be discarded.
    pub fn message<T: fmt::Display>(_msg: T) -> Error {
        #[cfg(not(feature = "std"))]
        {
            Error(ErrorImpl {
                code: ErrorCode::Message,
                offset: 0,
            })
        }
        #[cfg(feature = "std")]
        {
            Error(ErrorImpl {
                code: ErrorCode::Message(_msg.to_string()),
                offset: 0,
            })
        }
    }

    #[cfg(not(feature = "unsealed_read_write"))]
    pub(crate) fn message<T: fmt::Display>(_msg: T) -> Error {
        #[cfg(not(feature = "std"))]
        {
            Error(ErrorImpl {
                code: ErrorCode::Message,
                offset: 0,
            })
        }
        #[cfg(feature = "std")]
        {
            Error(ErrorImpl {
                code: ErrorCode::Message(_msg.to_string()),
                offset: 0,
            })
        }
    }

    #[cfg(feature = "unsealed_read_write")]
    /// Creates an error signalling that the underlying read
    /// encountered an end of input.
    pub fn eof(offset: u64) -> Error {
        Error(ErrorImpl {
            code: ErrorCode::EofWhileParsingValue,
            offset,
        })
    }

    /// Categorizes the cause of this error.
    pub fn classify(&self) -> Category {
        match self.0.code {
            #[cfg(feature = "std")]
            ErrorCode::Message(_) => Category::Data,
            #[cfg(not(feature = "std"))]
            ErrorCode::Message => Category::Data,
            #[cfg(feature = "std")]
            ErrorCode::Io(_) => Category::Io,
            #[cfg(not(feature = "std"))]
            ErrorCode::Io => Category::Io,
            ErrorCode::ScratchTooSmall => Category::Io,
            ErrorCode::EofWhileParsingValue
            | ErrorCode::EofWhileParsingArray
            | ErrorCode::EofWhileParsingMap => Category::Eof,
            ErrorCode::LengthOutOfRange
            | ErrorCode::InvalidUtf8
            | ErrorCode::UnassignedCode
            | ErrorCode::UnexpectedCode
            | ErrorCode::TrailingData
            | ErrorCode::ArrayTooShort
            | ErrorCode::ArrayTooLong
            | ErrorCode::RecursionLimitExceeded => Category::Syntax,
        }
    }

    /// Returns true if this error was caused by a failure to read or write bytes on an IO stream.
    pub fn is_io(&self) -> bool {
        match self.classify() {
            Category::Io => true,
            _ => false,
        }
    }

    /// Returns true if this error was caused by input that was not syntactically valid CBOR.
    pub fn is_syntax(&self) -> bool {
        match self.classify() {
            Category::Syntax => true,
            _ => false,
        }
    }

    /// Returns true if this error was caused by data that was semantically incorrect.
    pub fn is_data(&self) -> bool {
        match self.classify() {
            Category::Data => true,
            _ => false,
        }
    }

    /// Returns true if this error was caused by prematurely reaching the end of the input data.
    pub fn is_eof(&self) -> bool {
        match self.classify() {
            Category::Eof => true,
            _ => false,
        }
    }

    /// Returns true if this error was caused by the scratch buffer being too small.
    ///
    /// Note this being `true` implies that `is_io()` is also `true`.
    pub fn is_scratch_too_small(&self) -> bool {
        match self.0.code {
            ErrorCode::ScratchTooSmall => true,
            _ => false,
        }
    }
}

#[cfg(feature = "std")]
impl error::Error for Error {
    fn source(&self) -> Option<&(dyn error::Error + 'static)> {
        match self.0.code {
            ErrorCode::Io(ref err) => Some(err),
            _ => None,
        }
    }
}

impl fmt::Display for Error {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if self.0.offset == 0 {
            fmt::Display::fmt(&self.0.code, f)
        } else {
            write!(f, "{} at offset {}", self.0.code, self.0.offset)
        }
    }
}

impl fmt::Debug for Error {
    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {
        fmt::Debug::fmt(&self.0, fmt)
    }
}

impl de::Error for Error {
    fn custom<T: fmt::Display>(msg: T) -> Error {
        Error::message(msg)
    }

    fn invalid_type(unexp: de::Unexpected<'_>, exp: &dyn de::Expected) -> Error {
        if let de::Unexpected::Unit = unexp {
            Error::custom(format_args!("invalid type: null, expected {}", exp))
        } else {
            Error::custom(format_args!("invalid type: {}, expected {}", unexp, exp))
        }
    }
}

impl ser::Error for Error {
    fn custom<T: fmt::Display>(msg: T) -> Error {
        Error::message(msg)
    }
}

#[cfg(feature = "std")]
impl From<io::Error> for Error {
    fn from(e: io::Error) -> Error {
        Error::io(e)
    }
}

#[cfg(not(feature = "std"))]
impl From<core::fmt::Error> for Error {
    fn from(_: core::fmt::Error) -> Error {
        Error(ErrorImpl {
            code: ErrorCode::Message,
            offset: 0,
        })
    }
}

#[derive(Debug)]
struct ErrorImpl {
    code: ErrorCode,
    offset: u64,
}

#[derive(Debug)]
pub(crate) enum ErrorCode {
    #[cfg(feature = "std")]
    Message(String),
    #[cfg(not(feature = "std"))]
    Message,
    #[cfg(feature = "std")]
    Io(io::Error),
    #[cfg(not(feature = "std"))]
    Io,
    ScratchTooSmall,
    EofWhileParsingValue,
    EofWhileParsingArray,
    EofWhileParsingMap,
    LengthOutOfRange,
    InvalidUtf8,
    UnassignedCode,
    UnexpectedCode,
    TrailingData,
    ArrayTooShort,
    ArrayTooLong,
    RecursionLimitExceeded,
}

impl fmt::Display for ErrorCode {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            #[cfg(feature = "std")]
            ErrorCode::Message(ref msg) => f.write_str(msg),
            #[cfg(not(feature = "std"))]
            ErrorCode::Message => f.write_str("Unknown error"),
            #[cfg(feature = "std")]
            ErrorCode::Io(ref err) => fmt::Display::fmt(err, f),
            #[cfg(not(feature = "std"))]
            ErrorCode::Io => f.write_str("Unknown I/O error"),
            ErrorCode::ScratchTooSmall => f.write_str("Scratch buffer too small"),
            ErrorCode::EofWhileParsingValue => f.write_str("EOF while parsing a value"),
            ErrorCode::EofWhileParsingArray => f.write_str("EOF while parsing an array"),
            ErrorCode::EofWhileParsingMap => f.write_str("EOF while parsing a map"),
            ErrorCode::LengthOutOfRange => f.write_str("length out of range"),
            ErrorCode::InvalidUtf8 => f.write_str("invalid UTF-8"),
            ErrorCode::UnassignedCode => f.write_str("unassigned type"),
            ErrorCode::UnexpectedCode => f.write_str("unexpected code"),
            ErrorCode::TrailingData => f.write_str("trailing data"),
            ErrorCode::ArrayTooShort => f.write_str("array too short"),
            ErrorCode::ArrayTooLong => f.write_str("array too long"),
            ErrorCode::RecursionLimitExceeded => f.write_str("recursion limit exceeded"),
        }
    }
}

'''
'''--- runtime/cbor/src/lib.rs ---
//! CBOR and serialization.
//!
//! # What is CBOR?
//! [CBOR](http://cbor.io) is a way to encode data in a space-efficient and fast binary format.
//! CBORs data-model is a superset of the JSONs.
//!
//! A simple object describing a person in diagnostic notation (it is actually JSON plus some
//! annotations) looks like
//!
//! ```json
//! {
//!     "FirstName": "John",
//!     "LastName": "Doe",
//!     "Age": 43,
//!     "Address": {
//!         "Street": "Downing Street 10",
//!         "City": "London",
//!         "Country": "Great Britain"
//!     },
//!     "PhoneNumbers": [
//!         "+44 1234567",
//!         "+44 2345678"
//!     ]
//! }
//! ```
//!
//! The CBOR encoded object with comments in hexadecimal notation looks like
//!
//! ```cbor
//! a5                                      # map(5)
//!    69                                   # text(9)
//!       46697273744e616d65                # "FirstName"
//!    64                                   # text(4)
//!       4a6f686e                          # "John"
//!    68                                   # text(8)
//!       4c6173744e616d65                  # "LastName"
//!    63                                   # text(3)
//!       446f65                            # "Doe"
//!    63                                   # text(3)
//!       416765                            # "Age"
//!    18 2b                                # unsigned(43)
//!    67                                   # text(7)
//!       41646472657373                    # "Address"
//!    a3                                   # map(3)
//!       66                                # text(6)
//!          537472656574                   # "Street"
//!       71                                # text(17)
//!          446f776e696e6720537472656574203130 # "Downing Street 10"
//!       64                                # text(4)
//!          43697479                       # "City"
//!       66                                # text(6)
//!          4c6f6e646f6e                   # "London"
//!       67                                # text(7)
//!          436f756e747279                 # "Country"
//!       6d                                # text(13)
//!          4772656174204272697461696e     # "Great Britain"
//!    6c                                   # text(12)
//!       50686f6e654e756d62657273          # "PhoneNumbers"
//!    82                                   # array(2)
//!       6b                                # text(11)
//!          2b34342031323334353637         # "+44 1234567"
//!       6b                                # text(11)
//!          2b34342032333435363738         # "+44 2345678"
//! ```
//! While the JSON encoding is 174 bytes long the CBOR representation is only 141 bytes long.
//! This is 19% shorter! Sometimes compression will even better, but never CBOR will be longer
//! than the corresponding JSON. More importantly CBOR supports binary data, custom data tyes,
//! annotations for dates, times and expected encoding and is faster to serialize and deserialize.
//! It can even be used on embedded devices.
//!
//! # Type-based Serialization and Deserialization
//! Serde provides a mechanism for low boilerplate serialization & deserialization of values to and
//! from CBOR via the serialization API. To be able to serialize a piece of data, it must implement
//! the `serde::Serialize` trait. To be able to deserialize a piece of data, it must implement the
//! `serde::Deserialize` trait. Serde provides an annotation to automatically generate the
//! code for these traits: `#[derive(Serialize, Deserialize)]`.
//!
//! The CBOR API also provides an enum `serde_cbor::Value`.
//!
//! # Packed Encoding
//! When serializing structs or enums in CBOR the keys or enum variant names will be serialized
//! as string keys to a map. Especially in embedded environments this can increase the file
//! size too much. In packed encoding the keys and variants will be serialized as variable sized
//! integers. The first 24 entries in any struct consume only a single byte!
//! To serialize a document in packed encoding use `ser::to_(vec|writer)_packed`, deserialization
//! works without any changes.
//!
//! # Self describing documents
//! In some contexts different formats are used but there is no way to declare the format used
//! out of band. For this reason CBOR has a magic number that may be added before any document.
//! The *`_sd` (for *s*elf*d*escribe) append the magic number before documents.
//!
//! # Examples
//! Read a CBOR value that is known to be a map of string keys to string values and print it.
//!
//! ```rust
//! use std::collections::BTreeMap;
//! use serde_cbor::from_slice;
//!
//! let slice = b"\xa5aaaAabaBacaCadaDaeaE";
//! let value: BTreeMap<String, String> = from_slice(slice).unwrap();
//! println!("{:?}", value); // {"e": "E", "d": "D", "a": "A", "c": "C", "b": "B"}
//! ```
//!
//! Read a general CBOR value with an unknown content.
//!
//! ```rust
//! use serde_cbor::{from_slice, Value};
//!
//! let slice = b"\x82\x01\xa1aaab";
//! let value: Value = from_slice(slice).unwrap();
//! println!("{:?}", value); // Array([U64(1), Object({String("a"): String("b")})])
//! ```
//!
//! Serialize an object.
//!
//! ```rust
//! use std::collections::BTreeMap;
//! use serde_cbor::to_vec;
//!
//! let mut programming_languages = BTreeMap::new();
//! programming_languages.insert("rust", vec!["safe", "concurrent", "fast"]);
//! programming_languages.insert("python", vec!["powerful", "friendly", "open"]);
//! programming_languages.insert("js", vec!["lightweight", "interpreted", "object-oriented"]);
//! let encoded = to_vec(&programming_languages);
//! assert_eq!(encoded.unwrap().len(), 103);
//! ```
//!
//! Serializing a `Vec` as a specialized byte string uses about 2x less RAM and
//! 100x less CPU time than serializing it as an array.
//!
//! ```rust
//! # extern crate serde_bytes;
//! # extern crate serde_cbor;
//! use std::collections::BTreeMap;
//! use serde_bytes::ByteBuf;
//! use serde_cbor::to_vec;
//!
//! # fn main() {
//! let data: Vec<u8> = vec![0, 1, 255];
//! let serialized_array = to_vec(&data).unwrap();
//! let byte_buf = ByteBuf::from(data);
//! let serialized_byte_string = to_vec(&byte_buf).unwrap();
//! assert!(serialized_byte_string.len() < serialized_array.len());
//! # }
//! ```
//!
//! Deserializing data in the middle of a slice
//! ```
//! # extern crate serde_cbor;
//! use serde_cbor::Deserializer;
//!
//! # fn main() {
//! let data: Vec<u8> = vec![
//!     0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72, 0x66, 0x66, 0x6f, 0x6f, 0x62,
//!     0x61, 0x72,
//! ];
//! let mut deserializer = Deserializer::from_slice(&data);
//! let value: &str = serde::de::Deserialize::deserialize(&mut deserializer)
//!     .unwrap();
//! let rest = &data[deserializer.byte_offset()..];
//! assert_eq!(value, "foobar");
//! assert_eq!(rest, &[0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72]);
//! # }
//! ```
//!
//! # Limitations
//!
//! While Serde CBOR strives to support all features of Serde and CBOR
//! there are a few limitations.
//!
//! * [Tags] are ignored during deserialization and can't be emitted during
//!     serialization. This is because Serde has no concept of tagged
//!     values. See:&nbsp;[#3]
//! * Unknown [simple values] cause an `UnassignedCode` error.
//!     The simple values *False* and *True* are recognized and parsed as bool.
//!     *Null* and *Undefined* are both deserialized as *unit*.
//!     The *unit* type is serialized as *Null*. See:&nbsp;[#86]
//! * [128-bit integers] can't be directly encoded in CBOR. If you need them
//!     store them as a byte string. See:&nbsp;[#77]
//!
//! [Tags]: https://tools.ietf.org/html/rfc7049#section-2.4.4
//! [#3]: https://github.com/pyfisch/cbor/issues/3
//! [simple values]: https://tools.ietf.org/html/rfc7049#section-3.5
//! [#86]: https://github.com/pyfisch/cbor/issues/86
//! [128-bit integers]: https://doc.rust-lang.org/std/primitive.u128.html
//! [#77]: https://github.com/pyfisch/cbor/issues/77

#![deny(missing_docs)]
#![cfg_attr(not(feature = "std"), no_std)]

// When we are running tests in no_std mode we need to explicitly link std, because `cargo test`
// will not work without it.
#[cfg(all(not(feature = "std"), test))]
extern crate std;

pub mod de;
pub mod error;
mod read;
pub mod ser;
mod write;

#[cfg(feature = "std")]
pub mod value;

#[doc(inline)]
pub use crate::de::{from_mut_slice, from_slice_with_scratch, Deserializer, StreamDeserializer};
#[doc(inline)]
#[cfg(feature = "std")]
pub use crate::de::{from_reader, from_slice};

#[doc(inline)]
#[cfg(feature = "std")]
pub use crate::ser::{to_vec, to_vec_with_options, to_writer};
pub use crate::ser::{Serializer, SerializerOptions};
#[doc(inline)]
#[cfg(feature = "std")]
pub use crate::value::{from_value, to_value, ObjectKey, Value};

'''
'''--- runtime/cbor/src/read.rs ---
#[cfg(feature = "std")]
use core::cmp;
use core::mem;

#[cfg(feature = "std")]
use std::io::{self, Read as StdRead};

use crate::error::{Error, ErrorCode, Result};

#[cfg(not(feature = "unsealed_read_write"))]
/// Trait used by the deserializer for iterating over input.
///
/// This trait is sealed by default, enabling the `unsealed_read_write` feature removes this bound
/// to allow objects outside of this crate to implement this trait.
pub trait Read<'de>: private::Sealed {
    #[doc(hidden)]
    /// Read n bytes from the input.
    ///
    /// Implementations that can are asked to return a slice with a Long lifetime that outlives the
    /// decoder, but others (eg. ones that need to allocate the data into a temporary buffer) can
    /// return it with a Short lifetime that just lives for the time of read's mutable borrow of
    /// the reader.
    ///
    /// This may, as a side effect, clear the reader's scratch buffer (as the provided
    /// implementation does).

    // A more appropriate lifetime setup for this (that would allow the Deserializer::convert_str
    // to stay a function) would be something like `fn read<'a, 'r: 'a>(&'a mut 'r immut self, ...) -> ...
    // EitherLifetime<'r, 'de>>`, which borrows self mutably for the duration of the function and
    // downgrates that reference to an immutable one that outlives the result (protecting the
    // scratch buffer from changes), but alas, that can't be expressed (yet?).
    fn read<'a>(&'a mut self, n: usize) -> Result<EitherLifetime<'a, 'de>> {
        self.clear_buffer();
        self.read_to_buffer(n)?;

        Ok(self.take_buffer())
    }

    #[doc(hidden)]
    fn next(&mut self) -> Result<Option<u8>>;

    #[doc(hidden)]
    fn peek(&mut self) -> Result<Option<u8>>;

    #[doc(hidden)]
    fn clear_buffer(&mut self);

    #[doc(hidden)]
    fn read_to_buffer(&mut self, n: usize) -> Result<()>;

    #[doc(hidden)]
    fn take_buffer<'a>(&'a mut self) -> EitherLifetime<'a, 'de>;

    #[doc(hidden)]
    fn read_into(&mut self, buf: &mut [u8]) -> Result<()>;

    #[doc(hidden)]
    fn discard(&mut self);

    #[doc(hidden)]
    fn offset(&self) -> u64;
}

#[cfg(feature = "unsealed_read_write")]
/// Trait used by the deserializer for iterating over input.
pub trait Read<'de> {
    /// Read n bytes from the input.
    ///
    /// Implementations that can are asked to return a slice with a Long lifetime that outlives the
    /// decoder, but others (eg. ones that need to allocate the data into a temporary buffer) can
    /// return it with a Short lifetime that just lives for the time of read's mutable borrow of
    /// the reader.
    ///
    /// This may, as a side effect, clear the reader's scratch buffer (as the provided
    /// implementation does).

    // A more appropriate lifetime setup for this (that would allow the Deserializer::convert_str
    // to stay a function) would be something like `fn read<'a, 'r: 'a>(&'a mut 'r immut self, ...) -> ...
    // EitherLifetime<'r, 'de>>`, which borrows self mutably for the duration of the function and
    // downgrates that reference to an immutable one that outlives the result (protecting the
    // scratch buffer from changes), but alas, that can't be expressed (yet?).
    fn read<'a>(&'a mut self, n: usize) -> Result<EitherLifetime<'a, 'de>> {
        self.clear_buffer();
        self.read_to_buffer(n)?;

        Ok(self.take_buffer())
    }

    /// Read the next byte from the input, if any.
    fn next(&mut self) -> Result<Option<u8>>;

    /// Peek at the next byte of the input, if any. This does not advance the reader, so the result
    /// of this function will remain the same until a read or clear occurs.
    fn peek(&mut self) -> Result<Option<u8>>;

    /// Clear the underlying scratch buffer
    fn clear_buffer(&mut self);

    /// Append n bytes from the reader to the reader's scratch buffer (without clearing it)
    fn read_to_buffer(&mut self, n: usize) -> Result<()>;

    /// Read out everything accumulated in the reader's scratch buffer. This may, as a side effect,
    /// clear it.
    fn take_buffer<'a>(&'a mut self) -> EitherLifetime<'a, 'de>;

    /// Read from the input until `buf` is full or end of input is encountered.
    fn read_into(&mut self, buf: &mut [u8]) -> Result<()>;

    /// Discard any data read by `peek`.
    fn discard(&mut self);

    /// Returns the offset from the start of the reader.
    fn offset(&self) -> u64;
}

/// Represents a reader that can return its current position
pub trait Offset {
    fn byte_offset(&self) -> usize;
}

/// Represents a buffer with one of two lifetimes.
pub enum EitherLifetime<'short, 'long> {
    /// The short lifetime
    Short(&'short [u8]),
    /// The long lifetime
    Long(&'long [u8]),
}

#[cfg(not(feature = "unsealed_read_write"))]
mod private {
    pub trait Sealed {}
}

/// CBOR input source that reads from a std::io input stream.
#[cfg(feature = "std")]
pub struct IoRead<R>
where
    R: io::Read,
{
    reader: OffsetReader<R>,
    scratch: Vec<u8>,
    ch: Option<u8>,
}

#[cfg(feature = "std")]
impl<R> IoRead<R>
where
    R: io::Read,
{
    /// Creates a new CBOR input source to read from a std::io input stream.
    pub fn new(reader: R) -> IoRead<R> {
        IoRead {
            reader: OffsetReader { reader, offset: 0 },
            scratch: vec![],
            ch: None,
        }
    }

    #[inline]
    fn next_inner(&mut self) -> Result<Option<u8>> {
        let mut buf = [0; 1];
        loop {
            match self.reader.read(&mut buf) {
                Ok(0) => return Ok(None),
                Ok(_) => return Ok(Some(buf[0])),
                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => {}
                Err(e) => return Err(Error::io(e)),
            }
        }
    }
}

#[cfg(all(feature = "std", not(feature = "unsealed_read_write")))]
impl<R> private::Sealed for IoRead<R> where R: io::Read {}

#[cfg(feature = "std")]
impl<'de, R> Read<'de> for IoRead<R>
where
    R: io::Read,
{
    #[inline]
    fn next(&mut self) -> Result<Option<u8>> {
        match self.ch.take() {
            Some(ch) => Ok(Some(ch)),
            None => self.next_inner(),
        }
    }

    #[inline]
    fn peek(&mut self) -> Result<Option<u8>> {
        match self.ch {
            Some(ch) => Ok(Some(ch)),
            None => {
                self.ch = self.next_inner()?;
                Ok(self.ch)
            }
        }
    }

    fn read_to_buffer(&mut self, mut n: usize) -> Result<()> {
        // defend against malicious input pretending to be huge strings by limiting growth
        self.scratch.reserve(cmp::min(n, 16 * 1024));

        if n == 0 {
            return Ok(());
        }

        if let Some(ch) = self.ch.take() {
            self.scratch.push(ch);
            n -= 1;
        }

        // n == 0 is OK here and needs no further special treatment

        let transfer_result = {
            // Prepare for take() (which consumes its reader) by creating a reference adaptor
            // that'll only live in this block
            let reference = self.reader.by_ref();
            // Append the first n bytes of the reader to the scratch vector (or up to
            // an error or EOF indicated by a shorter read)
            let mut taken = reference.take(n as u64);
            taken.read_to_end(&mut self.scratch)
        };

        match transfer_result {
            Ok(r) if r == n => Ok(()),
            Ok(_) => Err(Error::syntax(
                ErrorCode::EofWhileParsingValue,
                self.offset(),
            )),
            Err(e) => Err(Error::io(e)),
        }
    }

    fn clear_buffer(&mut self) {
        self.scratch.clear();
    }

    fn take_buffer<'a>(&'a mut self) -> EitherLifetime<'a, 'de> {
        EitherLifetime::Short(&self.scratch)
    }

    fn read_into(&mut self, buf: &mut [u8]) -> Result<()> {
        self.reader.read_exact(buf).map_err(|e| {
            if e.kind() == io::ErrorKind::UnexpectedEof {
                Error::syntax(ErrorCode::EofWhileParsingValue, self.offset())
            } else {
                Error::io(e)
            }
        })
    }

    #[inline]
    fn discard(&mut self) {
        self.ch = None;
    }

    fn offset(&self) -> u64 {
        self.reader.offset
    }
}

#[cfg(feature = "std")]
struct OffsetReader<R> {
    reader: R,
    offset: u64,
}

#[cfg(feature = "std")]
impl<R> io::Read for OffsetReader<R>
where
    R: io::Read,
{
    #[inline]
    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {
        let r = self.reader.read(buf);
        if let Ok(count) = r {
            self.offset += count as u64;
        }
        r
    }
}

/// A CBOR input source that reads from a slice of bytes.
#[cfg(feature = "std")]
pub struct SliceRead<'a> {
    slice: &'a [u8],
    scratch: Vec<u8>,
    index: usize,
}

#[cfg(feature = "std")]
impl<'a> SliceRead<'a> {
    /// Creates a CBOR input source to read from a slice of bytes.
    pub fn new(slice: &'a [u8]) -> SliceRead<'a> {
        SliceRead {
            slice,
            scratch: vec![],
            index: 0,
        }
    }

    fn end(&self, n: usize) -> Result<usize> {
        match self.index.checked_add(n) {
            Some(end) if end <= self.slice.len() => Ok(end),
            _ => Err(Error::syntax(
                ErrorCode::EofWhileParsingValue,
                self.slice.len() as u64,
            )),
        }
    }
}

#[cfg(feature = "std")]
impl<'a> Offset for SliceRead<'a> {
    #[inline]
    fn byte_offset(&self) -> usize {
        self.index
    }
}

#[cfg(all(feature = "std", not(feature = "unsealed_read_write")))]
impl<'a> private::Sealed for SliceRead<'a> {}

#[cfg(feature = "std")]
impl<'a> Read<'a> for SliceRead<'a> {
    #[inline]
    fn next(&mut self) -> Result<Option<u8>> {
        Ok(if self.index < self.slice.len() {
            let ch = self.slice[self.index];
            self.index += 1;
            Some(ch)
        } else {
            None
        })
    }

    #[inline]
    fn peek(&mut self) -> Result<Option<u8>> {
        Ok(if self.index < self.slice.len() {
            Some(self.slice[self.index])
        } else {
            None
        })
    }

    fn clear_buffer(&mut self) {
        self.scratch.clear();
    }

    fn read_to_buffer(&mut self, n: usize) -> Result<()> {
        let end = self.end(n)?;
        let slice = &self.slice[self.index..end];
        self.scratch.extend_from_slice(slice);
        self.index = end;

        Ok(())
    }

    #[inline]
    fn read<'b>(&'b mut self, n: usize) -> Result<EitherLifetime<'b, 'a>> {
        let end = self.end(n)?;
        let slice = &self.slice[self.index..end];
        self.index = end;
        Ok(EitherLifetime::Long(slice))
    }

    fn take_buffer<'b>(&'b mut self) -> EitherLifetime<'b, 'a> {
        EitherLifetime::Short(&self.scratch)
    }

    #[inline]
    fn read_into(&mut self, buf: &mut [u8]) -> Result<()> {
        let end = self.end(buf.len())?;
        buf.copy_from_slice(&self.slice[self.index..end]);
        self.index = end;
        Ok(())
    }

    #[inline]
    fn discard(&mut self) {
        self.index += 1;
    }

    fn offset(&self) -> u64 {
        self.index as u64
    }
}

/// A CBOR input source that reads from a slice of bytes using a fixed size scratch buffer.
///
/// [`SliceRead`](struct.SliceRead.html) and [`MutSliceRead`](struct.MutSliceRead.html) are usually
/// preferred over this, as they can handle indefinite length items.
pub struct SliceReadFixed<'a, 'b> {
    slice: &'a [u8],
    scratch: &'b mut [u8],
    index: usize,
    scratch_index: usize,
}

impl<'a, 'b> SliceReadFixed<'a, 'b> {
    /// Creates a CBOR input source to read from a slice of bytes, backed by a scratch buffer.
    pub fn new(slice: &'a [u8], scratch: &'b mut [u8]) -> SliceReadFixed<'a, 'b> {
        SliceReadFixed {
            slice,
            scratch,
            index: 0,
            scratch_index: 0,
        }
    }

    fn end(&self, n: usize) -> Result<usize> {
        match self.index.checked_add(n) {
            Some(end) if end <= self.slice.len() => Ok(end),
            _ => Err(Error::syntax(
                ErrorCode::EofWhileParsingValue,
                self.slice.len() as u64,
            )),
        }
    }

    fn scratch_end(&self, n: usize) -> Result<usize> {
        match self.scratch_index.checked_add(n) {
            Some(end) if end <= self.scratch.len() => Ok(end),
            _ => Err(Error::scratch_too_small(self.index as u64)),
        }
    }
}

#[cfg(not(feature = "unsealed_read_write"))]
impl<'a, 'b> private::Sealed for SliceReadFixed<'a, 'b> {}

impl<'a, 'b> Read<'a> for SliceReadFixed<'a, 'b> {
    #[inline]
    fn next(&mut self) -> Result<Option<u8>> {
        Ok(if self.index < self.slice.len() {
            let ch = self.slice[self.index];
            self.index += 1;
            Some(ch)
        } else {
            None
        })
    }

    #[inline]
    fn peek(&mut self) -> Result<Option<u8>> {
        Ok(if self.index < self.slice.len() {
            Some(self.slice[self.index])
        } else {
            None
        })
    }

    fn clear_buffer(&mut self) {
        self.scratch_index = 0;
    }

    fn read_to_buffer(&mut self, n: usize) -> Result<()> {
        let end = self.end(n)?;
        let scratch_end = self.scratch_end(n)?;
        let slice = &self.slice[self.index..end];
        self.scratch[self.scratch_index..scratch_end].copy_from_slice(&slice);
        self.index = end;
        self.scratch_index = scratch_end;

        Ok(())
    }

    fn read<'c>(&'c mut self, n: usize) -> Result<EitherLifetime<'c, 'a>> {
        let end = self.end(n)?;
        let slice = &self.slice[self.index..end];
        self.index = end;
        Ok(EitherLifetime::Long(slice))
    }

    fn take_buffer<'c>(&'c mut self) -> EitherLifetime<'c, 'a> {
        EitherLifetime::Short(&self.scratch[0..self.scratch_index])
    }

    #[inline]
    fn read_into(&mut self, buf: &mut [u8]) -> Result<()> {
        let end = self.end(buf.len())?;
        buf.copy_from_slice(&self.slice[self.index..end]);
        self.index = end;
        Ok(())
    }

    #[inline]
    fn discard(&mut self) {
        self.index += 1;
    }

    fn offset(&self) -> u64 {
        self.index as u64
    }
}

/// A CBOR input source that reads from a slice of bytes, and can move data around internally to
/// reassemble indefinite strings without the need of an allocated scratch buffer.
pub struct MutSliceRead<'a> {
    /// A complete view of the reader's data. It is promised that bytes before buffer_end are not
    /// mutated any more.
    slice: &'a mut [u8],
    /// Read cursor position in slice
    index: usize,
    /// Number of bytes already discarded from the slice
    before: usize,
    /// End of the buffer area that contains all bytes read_into_buffer. This is always <= index.
    buffer_end: usize,
}

impl<'a> MutSliceRead<'a> {
    /// Creates a CBOR input source to read from a slice of bytes.
    pub fn new(slice: &'a mut [u8]) -> MutSliceRead<'a> {
        MutSliceRead {
            slice,
            index: 0,
            before: 0,
            buffer_end: 0,
        }
    }

    fn end(&self, n: usize) -> Result<usize> {
        match self.index.checked_add(n) {
            Some(end) if end <= self.slice.len() => Ok(end),
            _ => Err(Error::syntax(
                ErrorCode::EofWhileParsingValue,
                self.slice.len() as u64,
            )),
        }
    }
}

#[cfg(not(feature = "unsealed_read_write"))]
impl<'a> private::Sealed for MutSliceRead<'a> {}

impl<'a> Read<'a> for MutSliceRead<'a> {
    #[inline]
    fn next(&mut self) -> Result<Option<u8>> {
        // This is duplicated from SliceRead, can that be eased?
        Ok(if self.index < self.slice.len() {
            let ch = self.slice[self.index];
            self.index += 1;
            Some(ch)
        } else {
            None
        })
    }

    #[inline]
    fn peek(&mut self) -> Result<Option<u8>> {
        // This is duplicated from SliceRead, can that be eased?
        Ok(if self.index < self.slice.len() {
            Some(self.slice[self.index])
        } else {
            None
        })
    }

    fn clear_buffer(&mut self) {
        self.slice = &mut mem::replace(&mut self.slice, &mut [])[self.index..];
        self.before += self.index;
        self.index = 0;
        self.buffer_end = 0;
    }

    fn read_to_buffer(&mut self, n: usize) -> Result<()> {
        let end = self.end(n)?;
        debug_assert!(
            self.buffer_end <= self.index,
            "MutSliceRead invariant violated: scratch buffer exceeds index"
        );
        self.slice[self.buffer_end..end].rotate_left(self.index - self.buffer_end);
        self.buffer_end += n;
        self.index = end;

        Ok(())
    }

    fn take_buffer<'b>(&'b mut self) -> EitherLifetime<'b, 'a> {
        let (left, right) = mem::replace(&mut self.slice, &mut []).split_at_mut(self.index);
        self.slice = right;
        self.before += self.index;
        self.index = 0;

        let left = &left[..self.buffer_end];
        self.buffer_end = 0;

        EitherLifetime::Long(left)
    }

    #[inline]
    fn read_into(&mut self, buf: &mut [u8]) -> Result<()> {
        // This is duplicated from SliceRead, can that be eased?
        let end = self.end(buf.len())?;
        buf.copy_from_slice(&self.slice[self.index..end]);
        self.index = end;
        Ok(())
    }

    #[inline]
    fn discard(&mut self) {
        self.index += 1;
    }

    fn offset(&self) -> u64 {
        (self.before + self.index) as u64
    }
}

'''
'''--- runtime/cbor/src/ser.rs ---
//! Serialize a Rust data structure to CBOR data.

#[cfg(feature = "std")]
pub use crate::write::IoWrite;
pub use crate::write::{SliceWrite, Write};

use crate::error::{Error, Result};
use byteorder::{BigEndian, ByteOrder};
use half::f16;
use serde::ser::{self, Serialize};
#[cfg(feature = "std")]
use std::io;

/// Serializes a value to a writer.
#[cfg(feature = "std")]
pub fn to_writer<W, T>(writer: &mut W, value: &T) -> Result<()>
where
    W: io::Write,
    T: ser::Serialize,
{
    value.serialize(&mut Serializer::new(&mut IoWrite::new(writer)))
}

/// Serializes a value to a writer and adds a CBOR self-describe tag.
#[cfg(feature = "std")]
pub fn to_writer_sd<W, T>(writer: &mut W, value: &T) -> Result<()>
where
    W: io::Write,
    T: ser::Serialize,
{
    let mut writer = IoWrite::new(writer);
    let mut ser = Serializer::new(&mut writer);
    ser.self_describe()?;
    value.serialize(&mut ser)
}

/// Serializes a value without names to a writer.
///
/// Struct fields and enum variants are identified by their numeric indices rather than names to
/// save space.
#[cfg(feature = "std")]
pub fn to_writer_packed<W, T>(writer: &mut W, value: &T) -> Result<()>
where
    W: io::Write,
    T: ser::Serialize,
{
    value.serialize(&mut Serializer::packed(&mut IoWrite::new(writer)))
}

/// Serializes a value without names to a writer and adds a CBOR self-describe tag.
///
/// Struct fields and enum variants are identified by their numeric indices rather than names to
/// save space.
#[cfg(feature = "std")]
pub fn to_writer_packed_sd<W, T>(writer: &mut W, value: &T) -> Result<()>
where
    W: io::Write,
    T: ser::Serialize,
{
    let mut writer = IoWrite::new(writer);
    let mut ser = Serializer::packed(&mut writer);
    ser.self_describe()?;
    value.serialize(&mut ser)
}

/// Serializes a value to a vector.
#[cfg(feature = "std")]
pub fn to_vec<T>(value: &T) -> Result<Vec<u8>>
where
    T: ser::Serialize,
{
    let mut vec = Vec::new();
    to_writer(&mut vec, value)?;
    Ok(vec)
}

/// Serializes a value to a vector and adds a CBOR self-describe tag.
#[cfg(feature = "std")]
pub fn to_vec_sd<T>(value: &T) -> Result<Vec<u8>>
where
    T: ser::Serialize,
{
    let mut vec = Vec::new();
    to_writer_sd(&mut vec, value)?;
    Ok(vec)
}

/// Serializes a value without names to a vector.
///
/// Struct fields and enum variants are identified by their numeric indices rather than names to
/// save space.
#[cfg(feature = "std")]
pub fn to_vec_packed<T>(value: &T) -> Result<Vec<u8>>
where
    T: ser::Serialize,
{
    let mut vec = Vec::new();
    to_writer_packed(&mut vec, value)?;
    Ok(vec)
}

/// Serializes a value without names to a vector and adds a CBOR self-describe tag.
///
/// Struct fields and enum variants are identified by their numeric indices rather than names to
/// save space.
#[cfg(feature = "std")]
pub fn to_vec_packed_sd<T>(value: &T) -> Result<Vec<u8>>
where
    T: ser::Serialize,
{
    let mut vec = Vec::new();
    to_writer_packed_sd(&mut vec, value)?;
    Ok(vec)
}

/// Serializes a value to a vector.
#[cfg(feature = "std")]
pub fn to_vec_with_options<T>(value: &T, options: &SerializerOptions) -> Result<Vec<u8>>
where
    T: ser::Serialize,
{
    let mut vec = Vec::new();
    {
        let mut ser = Serializer::new_with_options(&mut vec, options);
        if options.self_describe {
            ser.self_describe()?;
        }
        value.serialize(&mut ser)?;
    }
    Ok(vec)
}

/// Options for a CBOR serializer.
///
/// The `enum_as_map` option determines how enums are encoded.
///
/// This makes no difference when encoding and decoding enums using
/// this crate, but it shows up when decoding to a `Value` or decoding
/// in other languages.
///
/// With enum_as_map true, the encoding scheme matches the default encoding
/// scheme used by `serde_json`.
///
/// # Examples
///
/// Given the following enum
/// ```
/// enum Enum {
///     Unit,
///     NewType(i32),
///     Tuple(String, bool),
///     Struct{ x: i32, y: i32 },
/// }
/// ```
/// we will give the `Value` with the same encoding for each case using
/// JSON notation.
///
/// ## Default encodings
///
/// * `Enum::Unit` encodes as `"Unit"`
/// * `Enum::NewType(10)` encodes as `["NewType", 10]`
/// * `Enum::Tuple("x", true)` encodes as `["Tuple", "x", true]`
/// * `Enum::Struct{ x: 5, y: -5 }` encodes as `["Struct", {"x": 5, "y": -5}]`
///
/// ## Encodings with enum_as_map true
///
/// * `Enum::Unit` encodes as `"Unit"`
/// * `Enum::NewType(10)` encodes as `{"NewType": 10}`
/// * `Enum::Tuple("x", true)` encodes as `{"Tuple": ["x", true]}`
/// * `Enum::Struct{ x: 5, y: -5 }` encodes as `{"Struct": {"x": 5, "y": -5}}`
#[derive(Default)]
pub struct SerializerOptions {
    /// When set, struct fields and enum variants are identified by their numeric indices rather than names
    /// to save space.
    pub packed: bool,
    /// When set, enums are encoded as maps rather than arrays.
    pub enum_as_map: bool,
    /// When set, `to_vec` will prepend the CBOR self-describe tag.
    pub self_describe: bool,
}

#[cfg(feature = "std")]
impl SerializerOptions {
    /// Serializes a value to a vector.
    pub fn to_vec<T: ser::Serialize>(&self, value: &T) -> Result<Vec<u8>> {
        to_vec_with_options(value, self)
    }
}

/// A structure for serializing Rust values to CBOR.
pub struct Serializer<W> {
    writer: W,
    packed: bool,
    enum_as_map: bool,
}

impl<W> Serializer<W>
where
    W: Write,
{
    /// Creates a new CBOR serializer.
    ///
    /// `to_vec` and `to_writer` should normally be used instead of this method.
    #[inline]
    pub fn new(writer: W) -> Serializer<W> {
        Serializer {
            writer: writer,
            packed: false,
            enum_as_map: false,
        }
    }

    /// Creates a new "packed" CBOR serializer.
    ///
    /// Struct fields and enum variants are identified by their numeric indices rather than names
    /// to save space.
    #[inline]
    pub fn packed(writer: W) -> Serializer<W> {
        Serializer {
            writer,
            packed: true,
            enum_as_map: false,
        }
    }

    /// Creates a new CBOR serializer with the specified options.
    #[inline]
    pub fn new_with_options(writer: W, options: &SerializerOptions) -> Serializer<W> {
        Serializer {
            writer,
            packed: options.packed,
            enum_as_map: options.enum_as_map,
        }
    }

    #[cfg(feature = "std")]
    fn serialize_with_same_settings<V: Serialize>(&self, v: V) -> Result<Vec<u8>> {
        let buf: Vec<u8> = vec![];
        let mut s = Serializer {
            writer: buf,
            packed: self.packed,
            enum_as_map: self.enum_as_map,
        };
        v.serialize(&mut s)?;
        Ok(s.writer)
    }

    #[cfg(not(feature = "std"))]
    fn serialize_with_same_settings<V: Serialize>(&mut self, v: V) -> Result<()> {
        let mut s = Serializer {
            writer: &mut self.writer,
            packed: self.packed,
            enum_as_map: self.enum_as_map,
        };
        v.serialize(&mut s)?;
        Ok(())
    }

    /// Writes a CBOR self-describe tag to the stream.
    ///
    /// Tagging allows a decoder to distinguish different file formats based on their content
    /// without further information.
    #[inline]
    pub fn self_describe(&mut self) -> Result<()> {
        let mut buf = [6 << 5 | 25, 0, 0];
        BigEndian::write_u16(&mut buf[1..], 55799);
        self.writer.write_all(&buf).map_err(|e| e.into())
    }

    /// Unwrap the `Writer` from the `Serializer`.
    #[inline]
    pub fn into_inner(self) -> W {
        self.writer
    }

    #[inline]
    fn write_u8(&mut self, major: u8, value: u8) -> Result<()> {
        if value <= 0x17 {
            self.writer.write_all(&[major << 5 | value])
        } else {
            let buf = [major << 5 | 24, value];
            self.writer.write_all(&buf)
        }
        .map_err(|e| e.into())
    }

    #[inline]
    fn write_u16(&mut self, major: u8, value: u16) -> Result<()> {
        if value <= u16::from(u8::max_value()) {
            self.write_u8(major, value as u8)
        } else {
            let mut buf = [major << 5 | 25, 0, 0];
            BigEndian::write_u16(&mut buf[1..], value);
            self.writer.write_all(&buf).map_err(|e| e.into())
        }
    }

    #[inline]
    fn write_u32(&mut self, major: u8, value: u32) -> Result<()> {
        if value <= u32::from(u16::max_value()) {
            self.write_u16(major, value as u16)
        } else {
            let mut buf = [major << 5 | 26, 0, 0, 0, 0];
            BigEndian::write_u32(&mut buf[1..], value);
            self.writer.write_all(&buf).map_err(|e| e.into())
        }
    }

    #[inline]
    fn write_u64(&mut self, major: u8, value: u64) -> Result<()> {
        if value <= u64::from(u32::max_value()) {
            self.write_u32(major, value as u32)
        } else {
            let mut buf = [major << 5 | 27, 0, 0, 0, 0, 0, 0, 0, 0];
            BigEndian::write_u64(&mut buf[1..], value);
            self.writer.write_all(&buf).map_err(|e| e.into())
        }
    }

    #[inline]
    fn serialize_collection<'a>(
        &'a mut self,
        major: u8,
        len: Option<usize>,
    ) -> Result<CollectionSerializer<'a, W>> {
        let needs_eof = match len {
            Some(len) => {
                self.write_u64(major, len as u64)?;
                false
            }
            None => {
                self.writer
                    .write_all(&[major << 5 | 31])
                    .map_err(|e| e.into())?;
                true
            }
        };

        Ok(CollectionSerializer {
            ser: self,
            needs_eof,
        })
    }
}

impl<'a, W> ser::Serializer for &'a mut Serializer<W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    type SerializeSeq = CollectionSerializer<'a, W>;
    type SerializeTuple = &'a mut Serializer<W>;
    type SerializeTupleStruct = &'a mut Serializer<W>;
    type SerializeTupleVariant = &'a mut Serializer<W>;
    type SerializeMap = CollectionSerializer<'a, W>;
    type SerializeStruct = StructSerializer<'a, W>;
    type SerializeStructVariant = StructSerializer<'a, W>;

    #[inline]
    fn serialize_bool(self, value: bool) -> Result<()> {
        let value = if value { 0xf5 } else { 0xf4 };
        self.writer.write_all(&[value]).map_err(|e| e.into())
    }

    #[inline]
    fn serialize_i8(self, value: i8) -> Result<()> {
        if value < 0 {
            self.write_u8(1, -(value + 1) as u8)
        } else {
            self.write_u8(0, value as u8)
        }
    }

    #[inline]
    fn serialize_i16(self, value: i16) -> Result<()> {
        if value < 0 {
            self.write_u16(1, -(value + 1) as u16)
        } else {
            self.write_u16(0, value as u16)
        }
    }

    #[inline]
    fn serialize_i32(self, value: i32) -> Result<()> {
        if value < 0 {
            self.write_u32(1, -(value + 1) as u32)
        } else {
            self.write_u32(0, value as u32)
        }
    }

    #[inline]
    fn serialize_i64(self, value: i64) -> Result<()> {
        if value < 0 {
            self.write_u64(1, -(value + 1) as u64)
        } else {
            self.write_u64(0, value as u64)
        }
    }

    #[inline]
    fn serialize_i128(self, value: i128) -> Result<()> {
        if value < 0 {
            if -(value + 1) > u64::max_value() as i128 {
                return Err(Error::message("The number can't be stored in CBOR"));
            }
            self.write_u64(1, -(value + 1) as u64)
        } else {
            if value > u64::max_value() as i128 {
                return Err(Error::message("The number can't be stored in CBOR"));
            }
            self.write_u64(0, value as u64)
        }
    }

    #[inline]
    fn serialize_u8(self, value: u8) -> Result<()> {
        self.write_u8(0, value)
    }

    #[inline]
    fn serialize_u16(self, value: u16) -> Result<()> {
        self.write_u16(0, value)
    }

    #[inline]
    fn serialize_u32(self, value: u32) -> Result<()> {
        self.write_u32(0, value)
    }

    #[inline]
    fn serialize_u64(self, value: u64) -> Result<()> {
        self.write_u64(0, value)
    }

    #[inline]
    fn serialize_u128(self, value: u128) -> Result<()> {
        if value > u64::max_value() as u128 {
            return Err(Error::message("The number can't be stored in CBOR"));
        }
        self.write_u64(0, value as u64)
    }

    #[inline]
    #[allow(clippy::float_cmp)]
    fn serialize_f32(self, value: f32) -> Result<()> {
        if value.is_infinite() {
            if value.is_sign_positive() {
                self.writer.write_all(&[0xf9, 0x7c, 0x00])
            } else {
                self.writer.write_all(&[0xf9, 0xfc, 0x00])
            }
        } else if value.is_nan() {
            self.writer.write_all(&[0xf9, 0x7e, 0x00])
        } else if f32::from(f16::from_f32(value)) == value {
            let mut buf = [0xf9, 0, 0];
            BigEndian::write_u16(&mut buf[1..], f16::from_f32(value).to_bits());
            self.writer.write_all(&buf)
        } else {
            let mut buf = [0xfa, 0, 0, 0, 0];
            BigEndian::write_f32(&mut buf[1..], value);
            self.writer.write_all(&buf)
        }
        .map_err(|e| e.into())
    }

    #[inline]
    #[allow(clippy::float_cmp)]
    fn serialize_f64(self, value: f64) -> Result<()> {
        if !value.is_finite() || f64::from(value as f32) == value {
            self.serialize_f32(value as f32)
        } else {
            let mut buf = [0xfb, 0, 0, 0, 0, 0, 0, 0, 0];
            BigEndian::write_f64(&mut buf[1..], value);
            self.writer.write_all(&buf).map_err(|e| e.into())
        }
    }

    #[inline]
    fn serialize_char(self, value: char) -> Result<()> {
        // A char encoded as UTF-8 takes 4 bytes at most.
        let mut buf = [0; 4];
        self.serialize_str(value.encode_utf8(&mut buf))
    }

    #[inline]
    fn serialize_str(self, value: &str) -> Result<()> {
        self.write_u64(3, value.len() as u64)?;
        self.writer
            .write_all(value.as_bytes())
            .map_err(|e| e.into())
    }

    #[inline]
    fn serialize_bytes(self, value: &[u8]) -> Result<()> {
        self.write_u64(2, value.len() as u64)?;
        self.writer.write_all(value).map_err(|e| e.into())
    }

    #[inline]
    fn serialize_unit(self) -> Result<()> {
        self.serialize_none()
    }

    #[inline]
    fn serialize_some<T>(self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(self)
    }

    #[inline]
    fn serialize_none(self) -> Result<()> {
        self.writer.write_all(&[0xf6]).map_err(|e| e.into())
    }

    #[inline]
    fn serialize_unit_struct(self, _name: &'static str) -> Result<()> {
        self.serialize_unit()
    }

    #[inline]
    fn serialize_unit_variant(
        self,
        _name: &'static str,
        variant_index: u32,
        variant: &'static str,
    ) -> Result<()> {
        if self.packed {
            self.serialize_u32(variant_index)
        } else {
            self.serialize_str(variant)
        }
    }

    #[inline]
    fn serialize_newtype_struct<T>(self, _name: &'static str, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(self)
    }

    #[inline]
    fn serialize_newtype_variant<T>(
        self,
        name: &'static str,
        variant_index: u32,
        variant: &'static str,
        value: &T,
    ) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        if self.enum_as_map {
            self.write_u64(5, 1u64)?;
            variant.serialize(&mut *self)?;
        } else {
            self.writer.write_all(&[4 << 5 | 2]).map_err(|e| e.into())?;
            self.serialize_unit_variant(name, variant_index, variant)?;
        }
        value.serialize(self)
    }

    #[inline]
    fn serialize_seq(self, len: Option<usize>) -> Result<CollectionSerializer<'a, W>> {
        self.serialize_collection(4, len)
    }

    #[inline]
    fn serialize_tuple(self, len: usize) -> Result<&'a mut Serializer<W>> {
        self.write_u64(4, len as u64)?;
        Ok(self)
    }

    #[inline]
    fn serialize_tuple_struct(
        self,
        _name: &'static str,
        len: usize,
    ) -> Result<&'a mut Serializer<W>> {
        self.serialize_tuple(len)
    }

    #[inline]
    fn serialize_tuple_variant(
        self,
        name: &'static str,
        variant_index: u32,
        variant: &'static str,
        len: usize,
    ) -> Result<&'a mut Serializer<W>> {
        if self.enum_as_map {
            self.write_u64(5, 1u64)?;
            variant.serialize(&mut *self)?;
            self.serialize_tuple(len)
        } else {
            self.write_u64(4, (len + 1) as u64)?;
            self.serialize_unit_variant(name, variant_index, variant)?;
            Ok(self)
        }
    }

    #[inline]
    fn serialize_map(self, len: Option<usize>) -> Result<CollectionSerializer<'a, W>> {
        self.serialize_collection(5, len)
    }

    #[cfg(feature = "std")]
    fn collect_map<K, V, I>(self, iter: I) -> Result<Self::Ok>
    where
        K: Serialize,
        V: Serialize,
        I: IntoIterator<Item = (K, V)>,
    {
        use serde::ser::SerializeMap;

        let entry_results = iter
            .into_iter()
            .map(|(k, v)| {
                (
                    self.serialize_with_same_settings(k),
                    self.serialize_with_same_settings(v),
                )
            })
            .collect::<Vec<_>>();

        let mut entries = vec![];
        for (k, v) in entry_results {
            let (k, v) = (k?, v?);
            entries.push((k, v));
        }

        entries.sort_by(|a, b| a.0.cmp(&b.0));

        let serializer = self.serialize_map(Some(entries.len()))?;

        for (key, value) in entries {
            serializer
                .ser
                .writer
                .write_all(&key)
                .map_err(|e| e.into())?;
            serializer
                .ser
                .writer
                .write_all(&value)
                .map_err(|e| e.into())?;
        }
        serializer.end()
    }

    #[cfg(not(feature = "std"))]
    fn collect_str<T: ?Sized>(self, value: &T) -> Result<()>
    where
        T: core::fmt::Display,
    {
        use crate::write::FmtWrite;
        use core::fmt::Write;

        let mut w = FmtWrite::new(&mut self.writer);
        write!(w, "{}", value)?;
        Ok(())
    }

    #[inline]
    fn serialize_struct(self, _name: &'static str, len: usize) -> Result<StructSerializer<'a, W>> {
        self.write_u64(5, len as u64)?;
        Ok(StructSerializer {
            ser: self,
            idx: 0,
            #[cfg(feature = "std")]
            entries: vec![],
        })
    }

    #[inline]
    fn serialize_struct_variant(
        self,
        name: &'static str,
        variant_index: u32,
        variant: &'static str,
        len: usize,
    ) -> Result<StructSerializer<'a, W>> {
        if self.enum_as_map {
            self.write_u64(5, 1u64)?;
        } else {
            self.writer.write_all(&[4 << 5 | 2]).map_err(|e| e.into())?;
        }
        self.serialize_unit_variant(name, variant_index, variant)?;
        self.serialize_struct(name, len)
    }

    #[inline]
    fn is_human_readable(&self) -> bool {
        false
    }
}

impl<'a, W> ser::SerializeTuple for &'a mut Serializer<W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_element<T>(&mut self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(&mut **self)
    }

    #[inline]
    fn end(self) -> Result<()> {
        Ok(())
    }
}

impl<'a, W> ser::SerializeTupleStruct for &'a mut Serializer<W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_field<T>(&mut self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(&mut **self)
    }

    #[inline]
    fn end(self) -> Result<()> {
        Ok(())
    }
}

impl<'a, W> ser::SerializeTupleVariant for &'a mut Serializer<W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_field<T>(&mut self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(&mut **self)
    }

    #[inline]
    fn end(self) -> Result<()> {
        Ok(())
    }
}

#[cfg(feature = "std")]
#[doc(hidden)]
pub struct StructSerializer<'a, W> {
    ser: &'a mut Serializer<W>,
    idx: u32,
    entries: Vec<(Vec<u8>, Vec<u8>)>,
}

#[cfg(not(feature = "std"))]
#[doc(hidden)]
pub struct StructSerializer<'a, W> {
    ser: &'a mut Serializer<W>,
    idx: u32,
}

#[cfg(feature = "std")]
impl<'a, W> StructSerializer<'a, W>
where
    W: Write,
{
    #[inline]
    fn serialize_field_inner<T>(&mut self, key: &'static str, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        let key_bytes = if self.ser.packed {
            self.ser.serialize_with_same_settings(self.idx)?
        } else {
            self.ser.serialize_with_same_settings(key)?
        };
        self.idx += 1;
        self.entries
            .push((key_bytes, self.ser.serialize_with_same_settings(value)?));
        Ok(())
    }

    #[inline]
    fn skip_field_inner(&mut self, _: &'static str) -> Result<()> {
        self.idx += 1;
        Ok(())
    }

    #[inline]
    fn end_inner(mut self) -> Result<()> {
        self.entries.sort_by(|a, b| a.0.cmp(&b.0));
        for (k, v) in self.entries {
            self.ser.writer.write_all(&k).map_err(|e| e.into())?;
            self.ser.writer.write_all(&v).map_err(|e| e.into())?;
        }
        Ok(())
    }
}

// Version of `StructSerializer` that does not canonicalize its output, suitable for embedded
// platforms.
#[cfg(not(feature = "std"))]
impl<'a, W> StructSerializer<'a, W>
where
    W: Write,
{
    #[inline]
    fn serialize_field_inner<T>(&mut self, key: &'static str, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        if self.ser.packed {
            self.ser.serialize_with_same_settings(self.idx)?;
        } else {
            self.ser.serialize_with_same_settings(key)?;
        }
        self.ser.serialize_with_same_settings(value)?;
        self.idx += 1;
        Ok(())
    }

    #[inline]
    fn skip_field_inner(&mut self, _: &'static str) -> Result<()> {
        self.idx += 1;
        Ok(())
    }

    #[inline]
    fn end_inner(self) -> Result<()> {
        Ok(())
    }
}

impl<'a, W> ser::SerializeStruct for StructSerializer<'a, W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_field<T>(&mut self, key: &'static str, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        self.serialize_field_inner(key, value)
    }

    #[inline]
    fn skip_field(&mut self, key: &'static str) -> Result<()> {
        self.skip_field_inner(key)
    }

    #[inline]
    fn end(self) -> Result<()> {
        self.end_inner()
    }
}

impl<'a, W> ser::SerializeStructVariant for StructSerializer<'a, W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_field<T>(&mut self, key: &'static str, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        self.serialize_field_inner(key, value)
    }

    #[inline]
    fn skip_field(&mut self, key: &'static str) -> Result<()> {
        self.skip_field_inner(key)
    }

    #[inline]
    fn end(self) -> Result<()> {
        self.end_inner()
    }
}

#[doc(hidden)]
pub struct CollectionSerializer<'a, W> {
    ser: &'a mut Serializer<W>,
    needs_eof: bool,
}

impl<'a, W> CollectionSerializer<'a, W>
where
    W: Write,
{
    #[inline]
    fn end_inner(self) -> Result<()> {
        if self.needs_eof {
            self.ser.writer.write_all(&[0xff]).map_err(|e| e.into())
        } else {
            Ok(())
        }
    }
}

impl<'a, W> ser::SerializeSeq for CollectionSerializer<'a, W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_element<T>(&mut self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(&mut *self.ser)
    }

    #[inline]
    fn end(self) -> Result<()> {
        self.end_inner()
    }
}

impl<'a, W> ser::SerializeMap for CollectionSerializer<'a, W>
where
    W: Write,
{
    type Ok = ();
    type Error = Error;

    #[inline]
    fn serialize_key<T>(&mut self, key: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        key.serialize(&mut *self.ser)
    }

    #[inline]
    fn serialize_value<T>(&mut self, value: &T) -> Result<()>
    where
        T: ?Sized + ser::Serialize,
    {
        value.serialize(&mut *self.ser)
    }

    #[inline]
    fn end(self) -> Result<()> {
        self.end_inner()
    }
}

'''
'''--- runtime/cbor/src/value/mod.rs ---
//! CBOR values, keys and serialization routines.

pub mod ser;
pub mod value;

pub use self::ser::to_value;
pub use self::value::{from_value, ObjectKey, Value};

'''
'''--- runtime/cbor/src/value/ser.rs ---
//! Value serialization routines

// Copyright 2017 Serde Developers
//
// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or
// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license
// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.

use std::collections::BTreeMap;

use crate::error::Error;
use serde::{self, Serialize};

use crate::value::ObjectKey;
use crate::value::Value;

struct Serializer;

impl serde::Serializer for Serializer {
    type Ok = Value;
    type Error = Error;

    type SerializeSeq = SerializeVec;
    type SerializeTuple = SerializeVec;
    type SerializeTupleStruct = SerializeVec;
    type SerializeTupleVariant = SerializeTupleVariant;
    type SerializeMap = SerializeMap;
    type SerializeStruct = SerializeMap;
    type SerializeStructVariant = SerializeStructVariant;

    #[inline]
    fn serialize_bool(self, value: bool) -> Result<Value, Error> {
        Ok(Value::Bool(value))
    }

    #[inline]
    fn serialize_i8(self, value: i8) -> Result<Value, Error> {
        self.serialize_i64(i64::from(value))
    }

    #[inline]
    fn serialize_i16(self, value: i16) -> Result<Value, Error> {
        self.serialize_i64(i64::from(value))
    }

    #[inline]
    fn serialize_i32(self, value: i32) -> Result<Value, Error> {
        self.serialize_i64(i64::from(value))
    }

    fn serialize_i64(self, value: i64) -> Result<Value, Error> {
        Ok(Value::I64(value))
    }

    #[inline]
    fn serialize_u8(self, value: u8) -> Result<Value, Error> {
        self.serialize_u64(u64::from(value))
    }

    #[inline]
    fn serialize_u16(self, value: u16) -> Result<Value, Error> {
        self.serialize_u64(u64::from(value))
    }

    #[inline]
    fn serialize_u32(self, value: u32) -> Result<Value, Error> {
        self.serialize_u64(u64::from(value))
    }

    #[inline]
    fn serialize_u64(self, value: u64) -> Result<Value, Error> {
        Ok(Value::U64(value))
    }

    #[inline]
    fn serialize_f32(self, value: f32) -> Result<Value, Error> {
        self.serialize_f64(f64::from(value))
    }

    #[inline]
    fn serialize_f64(self, value: f64) -> Result<Value, Error> {
        Ok(Value::F64(value))
    }

    #[inline]
    fn serialize_char(self, value: char) -> Result<Value, Error> {
        let mut s = String::new();
        s.push(value);
        self.serialize_str(&s)
    }

    #[inline]
    fn serialize_str(self, value: &str) -> Result<Value, Error> {
        Ok(Value::String(value.to_owned()))
    }

    fn serialize_bytes(self, value: &[u8]) -> Result<Value, Error> {
        Ok(Value::Bytes(value.to_vec()))
    }

    #[inline]
    fn serialize_unit(self) -> Result<Value, Error> {
        Ok(Value::Null)
    }

    #[inline]
    fn serialize_unit_struct(self, _name: &'static str) -> Result<Value, Error> {
        self.serialize_unit()
    }

    #[inline]
    fn serialize_unit_variant(
        self,
        _name: &'static str,
        _variant_index: u32,
        variant: &'static str,
    ) -> Result<Value, Error> {
        self.serialize_str(variant)
    }

    #[inline]
    fn serialize_newtype_struct<T: ?Sized>(
        self,
        _name: &'static str,
        value: &T,
    ) -> Result<Value, Error>
    where
        T: Serialize,
    {
        value.serialize(self)
    }

    fn serialize_newtype_variant<T: ?Sized>(
        self,
        _name: &'static str,
        _variant_index: u32,
        variant: &'static str,
        value: &T,
    ) -> Result<Value, Error>
    where
        T: Serialize,
    {
        let mut values = BTreeMap::new();
        values.insert(ObjectKey::from(variant.to_owned()), to_value(&value)?);
        Ok(Value::Object(values))
    }

    #[inline]
    fn serialize_none(self) -> Result<Value, Error> {
        self.serialize_unit()
    }

    #[inline]
    fn serialize_some<T: ?Sized>(self, value: &T) -> Result<Value, Error>
    where
        T: Serialize,
    {
        value.serialize(self)
    }

    fn serialize_seq(self, len: Option<usize>) -> Result<Self::SerializeSeq, Error> {
        Ok(SerializeVec {
            vec: Vec::with_capacity(len.unwrap_or(0)),
        })
    }

    fn serialize_tuple(self, len: usize) -> Result<Self::SerializeTuple, Error> {
        self.serialize_seq(Some(len))
    }

    fn serialize_tuple_struct(
        self,
        _name: &'static str,
        len: usize,
    ) -> Result<Self::SerializeTupleStruct, Error> {
        self.serialize_tuple(len)
    }

    fn serialize_tuple_variant(
        self,
        _name: &'static str,
        _variant_index: u32,
        variant: &'static str,
        len: usize,
    ) -> Result<Self::SerializeTupleVariant, Error> {
        Ok(SerializeTupleVariant {
            name: String::from(variant),
            vec: Vec::with_capacity(len),
        })
    }

    fn serialize_map(self, _len: Option<usize>) -> Result<Self::SerializeMap, Error> {
        Ok(SerializeMap {
            map: BTreeMap::new(),
            next_key: None,
        })
    }

    fn serialize_struct(
        self,
        _name: &'static str,
        len: usize,
    ) -> Result<Self::SerializeStruct, Error> {
        self.serialize_map(Some(len))
    }

    fn serialize_struct_variant(
        self,
        _name: &'static str,
        _variant_index: u32,
        variant: &'static str,
        _len: usize,
    ) -> Result<Self::SerializeStructVariant, Error> {
        Ok(SerializeStructVariant {
            name: String::from(variant),
            map: BTreeMap::new(),
        })
    }
}

#[doc(hidden)]
pub struct SerializeVec {
    vec: Vec<Value>,
}

#[doc(hidden)]
pub struct SerializeTupleVariant {
    name: String,
    vec: Vec<Value>,
}

#[doc(hidden)]
pub struct SerializeMap {
    map: BTreeMap<ObjectKey, Value>,
    next_key: Option<ObjectKey>,
}

#[doc(hidden)]
pub struct SerializeStructVariant {
    name: String,
    map: BTreeMap<ObjectKey, Value>,
}

impl serde::ser::SerializeSeq for SerializeVec {
    type Ok = Value;
    type Error = Error;

    fn serialize_element<T: ?Sized>(&mut self, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        self.vec.push(to_value(&value)?);
        Ok(())
    }

    fn end(self) -> Result<Value, Error> {
        Ok(Value::Array(self.vec))
    }
}

impl serde::ser::SerializeTuple for SerializeVec {
    type Ok = Value;
    type Error = Error;

    fn serialize_element<T: ?Sized>(&mut self, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        serde::ser::SerializeSeq::serialize_element(self, value)
    }

    fn end(self) -> Result<Value, Error> {
        serde::ser::SerializeSeq::end(self)
    }
}

impl serde::ser::SerializeTupleStruct for SerializeVec {
    type Ok = Value;
    type Error = Error;

    fn serialize_field<T: ?Sized>(&mut self, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        serde::ser::SerializeSeq::serialize_element(self, value)
    }

    fn end(self) -> Result<Value, Error> {
        serde::ser::SerializeSeq::end(self)
    }
}

impl serde::ser::SerializeTupleVariant for SerializeTupleVariant {
    type Ok = Value;
    type Error = Error;

    fn serialize_field<T: ?Sized>(&mut self, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        self.vec.push(to_value(&value)?);
        Ok(())
    }

    fn end(self) -> Result<Value, Error> {
        let mut object = BTreeMap::new();

        object.insert(ObjectKey::from(self.name), Value::Array(self.vec));

        Ok(Value::Object(object))
    }
}

impl serde::ser::SerializeMap for SerializeMap {
    type Ok = Value;
    type Error = Error;

    fn serialize_key<T: ?Sized>(&mut self, key: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        self.next_key = Some(ObjectKey::from(to_value(&key)?));
        Ok(())
    }

    fn serialize_value<T: ?Sized>(&mut self, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        let key = self.next_key.take();
        // Panic because this indicates a bug in the program rather than an
        // expected failure.
        let key = key.expect("serialize_value called before serialize_key");
        self.map.insert(key, to_value(&value)?);
        Ok(())
    }

    fn end(self) -> Result<Value, Error> {
        Ok(Value::Object(self.map))
    }
}

impl serde::ser::SerializeStruct for SerializeMap {
    type Ok = Value;
    type Error = Error;

    fn serialize_field<T: ?Sized>(&mut self, key: &'static str, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        serde::ser::SerializeMap::serialize_key(self, key)?;
        serde::ser::SerializeMap::serialize_value(self, value)
    }

    fn end(self) -> Result<Value, Error> {
        serde::ser::SerializeMap::end(self)
    }
}

impl serde::ser::SerializeStructVariant for SerializeStructVariant {
    type Ok = Value;
    type Error = Error;

    fn serialize_field<T: ?Sized>(&mut self, key: &'static str, value: &T) -> Result<(), Error>
    where
        T: Serialize,
    {
        self.map
            .insert(ObjectKey::from(String::from(key)), to_value(&value)?);
        Ok(())
    }

    fn end(self) -> Result<Value, Error> {
        let mut object = BTreeMap::new();

        object.insert(ObjectKey::from(self.name), Value::Object(self.map));

        Ok(Value::Object(object))
    }
}

/// Convert a `T` into `serde_cbor::Value` which is an enum that can represent
/// any valid CBOR data.
///
/// ```rust
/// extern crate serde;
///
/// #[macro_use]
/// extern crate serde_derive;
/// extern crate serde_cbor;
///
/// use std::error::Error;
///
/// #[derive(Serialize)]
/// struct User {
///     fingerprint: String,
///     location: String,
/// }
///
/// fn main() {
///     let u = User {
///         fingerprint: "0xF9BA143B95FF6D82".to_owned(),
///         location: "Menlo Park, CA".to_owned(),
///     };
///
///     let v = serde_cbor::to_value(u).unwrap();
/// }
/// ```
#[allow(clippy::needless_pass_by_value)]
// Taking by value is more friendly to iterator adapters, option and result
pub fn to_value<T>(value: T) -> Result<Value, Error>
where
    T: Serialize,
{
    value.serialize(Serializer)
}

'''
'''--- runtime/cbor/src/value/value.rs ---
//! CBOR values and keys.

use std::cmp::{Ord, Ordering, PartialOrd};
use std::collections::BTreeMap;
use std::fmt;

use serde::de;
use serde::ser;

/// An enum over all possible CBOR types.
#[derive(Clone, Debug, PartialEq)]
pub enum Value {
    /// Represents an unsigned integer.
    U64(u64),
    /// Represents a signed integer.
    I64(i64),
    /// Represents a byte string.
    Bytes(Vec<u8>),
    /// Represents an UTF-8 string.
    String(String),
    /// Represents a list.
    Array(Vec<Value>),
    /// Represents a map.
    Object(BTreeMap<ObjectKey, Value>),
    /// Represents a floating point value.
    F64(f64),
    /// Represents a boolean value.
    Bool(bool),
    /// Represents the absence of a value or the value undefined.
    Null,
}

impl Value {
    /// Returns true if the value is an object.
    pub fn is_object(&self) -> bool {
        self.as_object().is_some()
    }

    /// If the value is an object, returns the associated BTreeMap. Returns None otherwise.
    pub fn as_object(&self) -> Option<&BTreeMap<ObjectKey, Value>> {
        if let Value::Object(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// If the value is an object, returns the associated mutable BTreeMap. Returns None otherwise.
    pub fn as_object_mut(&mut self) -> Option<&mut BTreeMap<ObjectKey, Value>> {
        if let Value::Object(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the value is an array.
    pub fn is_array(&self) -> bool {
        self.as_array().is_some()
    }

    /// If the value is an array, returns the associated Vec. Returns None otherwise.
    pub fn as_array(&self) -> Option<&Vec<Value>> {
        if let Value::Array(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// If the value is an array, returns the associated mutable Vec. Returns None otherwise.
    pub fn as_array_mut(&mut self) -> Option<&mut Vec<Value>> {
        if let Value::Array(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the value is a byte string.
    pub fn is_bytes(&self) -> bool {
        self.as_bytes().is_some()
    }

    /// Returns the associated byte string or `None` if the value has a different type.
    pub fn as_bytes(&self) -> Option<&Vec<u8>> {
        if let Value::Bytes(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns the associated mutable byte string or `None` if the value has a different type.
    pub fn as_bytes_mut(&mut self) -> Option<&mut Vec<u8>> {
        if let Value::Bytes(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the value is a string.
    pub fn is_string(&self) -> bool {
        self.as_string().is_some()
    }

    /// Returns the associated string or `None` if the value has a different type.
    pub fn as_string(&self) -> Option<&String> {
        if let Value::String(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns the associated mutable string or `None` if the value has a different type.
    pub fn as_string_mut(&mut self) -> Option<&mut String> {
        if let Value::String(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Retrns true if the value is a number.
    pub fn is_number(&self) -> bool {
        match *self {
            Value::U64(_) | Value::I64(_) | Value::F64(_) => true,
            _ => false,
        }
    }

    /// Returns true if the `Value` is a i64. Returns false otherwise.
    pub fn is_i64(&self) -> bool {
        match *self {
            Value::I64(_) => true,
            _ => false,
        }
    }

    /// Returns true if the `Value` is a u64. Returns false otherwise.
    pub fn is_u64(&self) -> bool {
        match *self {
            Value::U64(_) => true,
            _ => false,
        }
    }

    /// Returns true if the `Value` is a f64. Returns false otherwise.
    pub fn is_f64(&self) -> bool {
        match *self {
            Value::F64(_) => true,
            _ => false,
        }
    }

    /// If the `Value` is a number, return or cast it to a i64. Returns None otherwise.
    pub fn as_i64(&self) -> Option<i64> {
        match *self {
            Value::I64(n) => Some(n),
            Value::U64(n) => Some(n as i64),
            _ => None,
        }
    }

    /// If the `Value` is a number, return or cast it to a u64. Returns None otherwise.
    pub fn as_u64(&self) -> Option<u64> {
        match *self {
            Value::I64(n) => Some(n as u64),
            Value::U64(n) => Some(n),
            _ => None,
        }
    }

    /// If the `Value` is a number, return or cast it to a f64. Returns None otherwise.
    pub fn as_f64(&self) -> Option<f64> {
        match *self {
            Value::I64(n) => Some(n as f64),
            Value::U64(n) => Some(n as f64),
            Value::F64(n) => Some(n),
            _ => None,
        }
    }

    /// Returns true if the value is a boolean.
    pub fn is_boolean(&self) -> bool {
        self.as_boolean().is_some()
    }

    /// If the value is a Boolean, returns the associated bool. Returns None otherwise.
    pub fn as_boolean(&self) -> Option<bool> {
        if let Value::Bool(v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the value is a Null. Returns false otherwise.
    pub fn is_null(&self) -> bool {
        self.as_null().is_some()
    }

    /// If the value is a Null, returns (). Returns None otherwise.
    pub fn as_null(&self) -> Option<()> {
        if let Value::Null = *self {
            Some(())
        } else {
            None
        }
    }
}

impl<'de> de::Deserialize<'de> for Value {
    #[inline]
    fn deserialize<D>(deserializer: D) -> Result<Value, D::Error>
    where
        D: de::Deserializer<'de>,
    {
        struct ValueVisitor;

        impl<'de> de::Visitor<'de> for ValueVisitor {
            type Value = Value;

            fn expecting(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {
                fmt.write_str("any valid CBOR value")
            }

            #[inline]
            fn visit_str<E>(self, value: &str) -> Result<Value, E>
            where
                E: de::Error,
            {
                self.visit_string(String::from(value))
            }

            #[inline]
            fn visit_string<E>(self, value: String) -> Result<Value, E>
            where
                E: de::Error,
            {
                Ok(Value::String(value))
            }
            #[inline]
            fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                self.visit_byte_buf(v.to_owned())
            }

            #[inline]
            fn visit_byte_buf<E>(self, v: Vec<u8>) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::Bytes(v))
            }

            #[inline]
            fn visit_u64<E>(self, v: u64) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::U64(v))
            }

            #[inline]
            fn visit_i64<E>(self, v: i64) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::I64(v))
            }

            #[inline]
            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::Bool(v))
            }

            #[inline]
            fn visit_none<E>(self) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                self.visit_unit()
            }

            #[inline]
            fn visit_unit<E>(self) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::Null)
            }

            #[inline]
            fn visit_seq<V>(self, mut visitor: V) -> Result<Self::Value, V::Error>
            where
                V: de::SeqAccess<'de>,
            {
                let mut vec = Vec::new();

                while let Some(elem) = visitor.next_element()? {
                    vec.push(elem);
                }

                Ok(Value::Array(vec))
            }

            #[inline]
            fn visit_map<V>(self, mut visitor: V) -> Result<Value, V::Error>
            where
                V: de::MapAccess<'de>,
            {
                let mut values = BTreeMap::new();

                while let Some((key, value)) = visitor.next_entry()? {
                    values.insert(key, value);
                }

                Ok(Value::Object(values))
            }

            #[inline]
            fn visit_f64<E>(self, v: f64) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(Value::F64(v))
            }
        }

        deserializer.deserialize_any(ValueVisitor)
    }
}

impl ser::Serialize for Value {
    #[inline]
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: ser::Serializer,
    {
        match *self {
            Value::U64(v) => serializer.serialize_u64(v),
            Value::I64(v) => serializer.serialize_i64(v),
            Value::Bytes(ref v) => serializer.serialize_bytes(&v),
            Value::String(ref v) => serializer.serialize_str(&v),
            Value::Array(ref v) => v.serialize(serializer),
            Value::Object(ref v) => v.serialize(serializer),
            Value::F64(v) => serializer.serialize_f64(v),
            Value::Bool(v) => serializer.serialize_bool(v),
            Value::Null => serializer.serialize_unit(),
        }
    }
}

/// A simplified CBOR value containing only types useful for keys.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum ObjectKey {
    /// An integer.
    Integer(i64),
    /// A byte string.
    Bytes(Vec<u8>),
    /// An UTF-8 string.
    String(String),
    /// A boolean value.
    Bool(bool),
    /// No value.
    Null,
}

impl Ord for ObjectKey {
    fn cmp(&self, other: &ObjectKey) -> Ordering {
        self.canonical_sort_key().cmp(&other.canonical_sort_key())
    }
}

impl PartialOrd for ObjectKey {
    fn partial_cmp(&self, other: &ObjectKey) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl ObjectKey {
    // Returns a key to sort `ObjectKey`s by major type, then byte-length, then lexicographically
    // by content. Equivalent to sorting `ObjectKey`s __lexicographically__ by their CBOR serialization.
    //
    // Note: the first guidelines regarding canonicalized CBOR
    // [located here](https://tools.ietf.org/html/rfc7049#section-3.9) sorted keys by length
    // before sorting by major type, but a [later draft](https://tools.ietf.org/html/draft-ietf-cbor-7049bis-04#section-4.10)
    // has moved to a purely lexicographic ordering. This newer ordering is also used by the
    // [WebAuthn standard](https://fidoalliance.org/specs/fido-v2.0-id-20180227/fido-client-to-authenticator-protocol-v2.0-id-20180227.html#ctap2-canonical-cbor-encoding-form).
    fn canonical_sort_key(&self) -> (u8, usize, Option<&[u8]>) {
        use crate::ObjectKey::*;
        match *self {
            Integer(i) => {
                let major_type = if i >= 0 { 0u8 } else { 1u8 };
                let magnitude = if i >= 0 { i } else { -(i + 1) };
                (major_type, magnitude as usize, None)
            }
            Bytes(ref v) => (2, v.len(), Some(v)),
            String(ref s) => (3, s.len(), Some(s.as_bytes())),
            Bool(b) => (7, if b { 21 } else { 20 }, None),
            Null => (7, 22, None),
        }
    }
    /// Returns true if the ObjectKey is a byte string.
    pub fn is_bytes(&self) -> bool {
        self.as_bytes().is_some()
    }

    /// Returns the associated byte string or `None` if the ObjectKey has a different type.
    pub fn as_bytes(&self) -> Option<&Vec<u8>> {
        if let ObjectKey::Bytes(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns the associated mutable byte string or `None` if the ObjectKey has a different type.
    pub fn as_bytes_mut(&mut self) -> Option<&mut Vec<u8>> {
        if let ObjectKey::Bytes(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the ObjectKey is a string.
    pub fn is_string(&self) -> bool {
        self.as_string().is_some()
    }

    /// Returns the associated string or `None` if the *ObjectKey` has a different type.
    pub fn as_string(&self) -> Option<&String> {
        if let ObjectKey::String(ref v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns the associated mutable string or `None` if the `ObjectKey` has a different type.
    pub fn as_string_mut(&mut self) -> Option<&mut String> {
        if let ObjectKey::String(ref mut v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Retrns true if the `ObjectKey` is a number.
    pub fn is_number(&self) -> bool {
        match *self {
            ObjectKey::Integer(_) => true,
            _ => false,
        }
    }

    /// If the `ObjectKey` is a number, return or cast it to a i64. Returns None otherwise.
    pub fn as_i64(&self) -> Option<i64> {
        match *self {
            ObjectKey::Integer(n) => Some(n),
            _ => None,
        }
    }

    /// If the `ObjectKey` is a number, return or cast it to a u64. Returns None otherwise.
    pub fn as_u64(&self) -> Option<u64> {
        match *self {
            ObjectKey::Integer(n) => Some(n as u64),
            _ => None,
        }
    }

    /// Returns true if the ObjectKey is a boolean.
    pub fn is_boolean(&self) -> bool {
        self.as_boolean().is_some()
    }

    /// If the ObjectKey is a Boolean, returns the associated bool. Returns None otherwise.
    pub fn as_boolean(&self) -> Option<bool> {
        if let ObjectKey::Bool(v) = *self {
            Some(v)
        } else {
            None
        }
    }

    /// Returns true if the ObjectKey is a Null. Returns false otherwise.
    pub fn is_null(&self) -> bool {
        self.as_null().is_some()
    }

    /// If the ObjectKey is a Null, returns (). Returns None otherwise.
    pub fn as_null(&self) -> Option<()> {
        if let ObjectKey::Null = *self {
            Some(())
        } else {
            None
        }
    }
}

impl<'de> de::Deserialize<'de> for ObjectKey {
    #[inline]
    fn deserialize<D>(deserializer: D) -> Result<ObjectKey, D::Error>
    where
        D: de::Deserializer<'de>,
    {
        struct ObjectKeyVisitor;

        impl<'de> de::Visitor<'de> for ObjectKeyVisitor {
            type Value = ObjectKey;

            fn expecting(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {
                fmt.write_str("any valid CBOR key")
            }

            #[inline]
            fn visit_str<E>(self, value: &str) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                self.visit_string(String::from(value))
            }

            #[inline]
            fn visit_string<E>(self, value: String) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::String(value))
            }
            #[inline]
            fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                self.visit_byte_buf(v.to_owned())
            }

            #[inline]
            fn visit_byte_buf<E>(self, v: Vec<u8>) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::Bytes(v))
            }

            #[inline]
            fn visit_u64<E>(self, v: u64) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::Integer(v as i64))
            }

            #[inline]
            fn visit_i64<E>(self, v: i64) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::Integer(v))
            }

            #[inline]
            fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::Bool(v))
            }

            #[inline]
            fn visit_none<E>(self) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                self.visit_unit()
            }

            #[inline]
            fn visit_unit<E>(self) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                Ok(ObjectKey::Null)
            }
        }

        deserializer.deserialize_any(ObjectKeyVisitor)
    }
}

impl ser::Serialize for ObjectKey {
    #[inline]
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: ser::Serializer,
    {
        match *self {
            ObjectKey::Integer(v) => serializer.serialize_i64(v),
            ObjectKey::Bytes(ref v) => serializer.serialize_bytes(&v),
            ObjectKey::String(ref v) => serializer.serialize_str(&v),
            ObjectKey::Bool(v) => serializer.serialize_bool(v),
            ObjectKey::Null => serializer.serialize_unit(),
        }
    }
}

impl From<ObjectKey> for Value {
    fn from(key: ObjectKey) -> Value {
        match key {
            ObjectKey::Integer(v) => Value::I64(v),
            ObjectKey::Bytes(v) => Value::Bytes(v),
            ObjectKey::String(v) => Value::String(v),
            ObjectKey::Bool(v) => Value::Bool(v),
            ObjectKey::Null => Value::Null,
        }
    }
}

impl From<Value> for ObjectKey {
    fn from(value: Value) -> ObjectKey {
        match value {
            Value::U64(v) => ObjectKey::Integer(v as i64),
            Value::I64(v) => ObjectKey::Integer(v),
            Value::Bytes(v) => ObjectKey::Bytes(v),
            Value::String(v) => ObjectKey::String(v),
            Value::Bool(v) => ObjectKey::Bool(v),
            Value::Null => ObjectKey::Null,
            _ => panic!("invalid value type for key"),
        }
    }
}

macro_rules! impl_from {
    ($for_enum:ident, $variant:ident, $for_type:ty) => {
        impl From<$for_type> for $for_enum {
            fn from(v: $for_type) -> $for_enum {
                $for_enum::$variant(v)
            }
        }
    };
}

// All except &'a str and Cow<'a, str>
impl_from!(ObjectKey, Integer, i64);
impl_from!(ObjectKey, Bytes, Vec<u8>);
impl_from!(ObjectKey, String, String);
impl_from!(ObjectKey, Bool, bool);

// All except &'a str and Cow<'a, str>
impl_from!(Value, U64, u64);
impl_from!(Value, I64, i64);
impl_from!(Value, Bytes, Vec<u8>);
impl_from!(Value, String, String);
impl_from!(Value, Array, Vec<Value>);
impl_from!(Value, Object, BTreeMap<ObjectKey, Value>);
impl_from!(Value, F64, f64);
impl_from!(Value, Bool, bool);

/// Convert a `serde_cbor::Value` into a type `T`
#[allow(clippy::needless_pass_by_value)]
pub fn from_value<T>(value: Value) -> Result<T, crate::error::Error>
where
    T: de::DeserializeOwned,
{
    // TODO implement in a way that doesn't require
    // roundtrip through buffer (i.e. by implementing
    // `serde::de::Deserializer` for `Value` and then doing
    // `T::deserialize(value)`).
    let buf = crate::to_vec(&value)?;
    crate::from_slice(buf.as_slice())
}

'''
'''--- runtime/cbor/src/write.rs ---
#[cfg(not(feature = "std"))]
use core::fmt;
#[cfg(feature = "std")]
use std::io;

use crate::error;

#[cfg(not(feature = "unsealed_read_write"))]
/// A sink for serialized CBOR.
///
/// This trait is similar to the [`Write`]() trait in the standard library,
/// but has a smaller and more general API.
///
/// Any object implementing `std::io::Write`
/// can be wrapped in an [`IoWrite`](../write/struct.IoWrite.html) that implements
/// this trait for the underlying object.
pub trait Write: private::Sealed {
    /// The type of error returned when a write operation fails.
    #[doc(hidden)]
    type Error: Into<error::Error>;

    /// Attempts to write an entire buffer into this write.
    #[doc(hidden)]
    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error>;
}

#[cfg(feature = "unsealed_read_write")]
/// A sink for serialized CBOR.
///
/// This trait is similar to the [`Write`]() trait in the standard library,
/// but has a smaller and more general API.
///
/// Any object implementing `std::io::Write`
/// can be wrapped in an [`IoWrite`](../write/struct.IoWrite.html) that implements
/// this trait for the underlying object.
///
/// This trait is sealed by default, enabling the `unsealed_read_write` feature removes this bound
/// to allow objects outside of this crate to implement this trait.
pub trait Write {
    /// The type of error returned when a write operation fails.
    type Error: Into<error::Error>;

    /// Attempts to write an entire buffer into this write.
    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error>;
}

#[cfg(not(feature = "unsealed_read_write"))]
mod private {
    pub trait Sealed {}
}

impl<W> Write for &mut W
where
    W: Write,
{
    type Error = W::Error;

    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error> {
        (*self).write_all(buf)
    }
}

#[cfg(not(feature = "unsealed_read_write"))]
impl<W> private::Sealed for &mut W where W: Write {}

#[cfg(feature = "std")]
/// A wrapper for types that implement
/// [`std::io::Write`](https://doc.rust-lang.org/std/io/trait.Write.html) to implement the local
/// [`Write`](trait.Write.html) trait.
pub struct IoWrite<'a, W>(&'a mut W);

#[cfg(feature = "std")]
impl<'a, W: io::Write> IoWrite<'a, W> {
    /// Wraps an `io::Write` writer to make it compatible with [`Write`](trait.Write.html)
    pub fn new(w: &'a mut W) -> IoWrite<'a, W> {
        IoWrite(w)
    }
}

#[cfg(feature = "std")]
impl<'a, W: io::Write> Write for IoWrite<'a, W> {
    type Error = io::Error;

    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error> {
        self.0.write_all(buf)
    }
}

#[cfg(all(feature = "std", not(feature = "unsealed_read_write")))]
impl<'a, W> private::Sealed for IoWrite<'a, W> where W: io::Write {}

// TODO this should be possible with just alloc
#[cfg(feature = "std")]
impl Write for Vec<u8> {
    type Error = io::Error;

    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error> {
        io::Write::write_all(self, buf)
    }
}

#[cfg(all(feature = "std", not(feature = "unsealed_read_write")))]
impl private::Sealed for Vec<u8> {}

#[cfg(not(feature = "std"))]
pub struct FmtWrite<'a, W: Write>(&'a mut W);

#[cfg(not(feature = "std"))]
impl<'a, W: Write> FmtWrite<'a, W> {
    /// Wraps an `fmt::Write` writer to make it compatible with [`Write`](trait.Write.html)
    pub fn new(w: &'a mut W) -> FmtWrite<'a, W> {
        FmtWrite(w)
    }
}

#[cfg(not(feature = "std"))]
impl<'a, W: Write> fmt::Write for FmtWrite<'a, W> {
    fn write_str(&mut self, s: &str) -> fmt::Result {
        self.0.write_all(s.as_bytes()).map_err(|_| fmt::Error)
    }
}

#[cfg(all(not(feature = "std"), not(feature = "unsealed_read_write")))]
impl<'a, W> private::Sealed for FmtWrite<'a, W> where W: Write {}

/// Implements [`Write`](trait.Write.html) for mutable byte slices (`&mut [u8]`).
///
/// Returns an error if the value to serialize is too large to fit in the slice.
pub struct SliceWrite<'a> {
    slice: &'a mut [u8],
    index: usize,
}

impl<'a> SliceWrite<'a> {
    /// Wraps a mutable slice so it can be used as a `Write`.
    pub fn new(slice: &'a mut [u8]) -> SliceWrite<'a> {
        SliceWrite { slice, index: 0 }
    }

    /// Returns the number of bytes written to the underlying slice.
    pub fn bytes_written(&self) -> usize {
        self.index
    }

    /// Returns the underlying slice.
    pub fn into_inner(self) -> &'a mut [u8] {
        self.slice
    }
}

impl<'a> Write for SliceWrite<'a> {
    type Error = error::Error;

    fn write_all(&mut self, buf: &[u8]) -> Result<(), Self::Error> {
        if self.slice.len() - self.index < buf.len() {
            // This buffer will not fit in our slice
            return Err(error::Error::scratch_too_small(self.index as u64));
        }
        let end = self.index + buf.len();
        self.slice[self.index..end].copy_from_slice(buf);
        self.index = end;
        Ok(())
    }
}

#[cfg(not(feature = "unsealed_read_write"))]
impl<'a> private::Sealed for SliceWrite<'a> {}

'''
'''--- runtime/cbor/tests/bennofs.rs ---
#[macro_use]
extern crate serde_derive;

use serde::Serialize;
use serde_cbor::ser::SliceWrite;
use serde_cbor::{self, Serializer};

#[derive(Debug, PartialEq, Serialize, Deserialize)]
struct Example {
    foo: Foo,
    payload: u8,
}

#[derive(Debug, PartialEq, Serialize, Deserialize)]
struct Foo {
    x: u8,
    color: Color,
}

#[derive(Debug, PartialEq, Serialize, Deserialize)]
enum Color {
    Red,
    Blue,
    Yellow(u8),
}

const EXAMPLE: Example = Example {
    foo: Foo {
        x: 0xAA,
        color: Color::Yellow(40),
    },
    payload: 0xCC,
};

#[cfg(feature = "std")]
mod std_tests {
    use super::*;

    #[test]
    fn test() {
        let serialized = serde_cbor::ser::to_vec_packed(&EXAMPLE).unwrap();
        let deserialized: Example = serde_cbor::from_slice(&serialized).unwrap();
        assert_eq!(EXAMPLE, deserialized);
    }
}

#[test]
fn test() {
    let mut slice = [0u8; 64];
    let writer = SliceWrite::new(&mut slice);
    let mut serializer = Serializer::packed(writer);
    EXAMPLE.serialize(&mut serializer).unwrap();
    let writer = serializer.into_inner();
    let end = writer.bytes_written();
    let slice = writer.into_inner();
    let deserialized: Example =
        serde_cbor::from_slice_with_scratch(&slice[..end], &mut []).unwrap();
    assert_eq!(EXAMPLE, deserialized);
}

'''
'''--- runtime/cbor/tests/canonical.rs ---
#[cfg(feature = "std")]
mod std_tests {
    use serde_cbor::ObjectKey;

    #[test]
    fn integer_canonical_sort_order() {
        let expected = [
            0,
            23,
            24,
            255,
            256,
            65535,
            65536,
            4294967295,
            -1,
            -24,
            -25,
            -256,
            -257,
            -65536,
            -65537,
            -4294967296,
        ]
        .into_iter()
        .map(|i| ObjectKey::Integer(*i))
        .collect::<Vec<_>>();

        let mut sorted = expected.clone();
        sorted.sort();

        assert_eq!(expected, sorted);
    }

    #[test]
    fn string_canonical_sort_order() {
        let expected = ["", "a", "b", "aa"]
            .into_iter()
            .map(|s| ObjectKey::String(s.to_string()))
            .collect::<Vec<_>>();

        let mut sorted = expected.clone();
        sorted.sort();

        assert_eq!(expected, sorted);
    }

    #[test]
    fn bytes_canonical_sort_order() {
        let expected = vec![vec![], vec![0u8], vec![1u8], vec![0u8, 0u8]]
            .into_iter()
            .map(|v| ObjectKey::Bytes(v))
            .collect::<Vec<_>>();

        let mut sorted = expected.clone();
        sorted.sort();

        assert_eq!(expected, sorted);
    }

    #[test]
    fn simple_data_canonical_sort_order() {
        let expected = vec![
            ObjectKey::Bool(false),
            ObjectKey::Bool(true),
            ObjectKey::Null,
        ];

        let mut sorted = expected.clone();
        sorted.sort();

        assert_eq!(expected, sorted);
    }

    #[test]
    fn major_type_canonical_sort_order() {
        let expected = vec![
            ObjectKey::Integer(0),
            ObjectKey::Integer(-1),
            ObjectKey::Bytes(vec![]),
            ObjectKey::String("".to_string()),
            ObjectKey::Null,
        ]
        .into_iter()
        .collect::<Vec<_>>();

        let mut sorted = expected.clone();
        sorted.sort();

        assert_eq!(expected, sorted);
    }
}

'''
'''--- runtime/cbor/tests/de.rs ---
#[macro_use]
extern crate serde_derive;

use serde_cbor;
use serde_cbor::de;

#[test]
fn test_str() {
    let s: &str =
        de::from_slice_with_scratch(&[0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72], &mut []).unwrap();
    assert_eq!(s, "foobar");
}

#[test]
fn test_bytes() {
    let s: &[u8] =
        de::from_slice_with_scratch(&[0x46, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72], &mut []).unwrap();
    assert_eq!(s, b"foobar");
}

#[test]
fn test_int() {
    let num: i64 = de::from_slice_with_scratch(&[0x39, 0x07, 0xde], &mut []).unwrap();
    assert_eq!(num, -2015);
}

#[test]
fn test_float() {
    let float: f64 = de::from_slice_with_scratch(b"\xfa\x47\xc3\x50\x00", &mut []).unwrap();
    assert_eq!(float, 100000.0);
}

#[test]
fn test_indefinite_object() {
    #[derive(Debug, Deserialize, PartialEq)]
    struct Foo {
        a: u64,
        b: [u64; 2],
    }
    let expected = Foo { a: 1, b: [2, 3] };
    let actual: Foo =
        de::from_slice_with_scratch(b"\xbfaa\x01ab\x9f\x02\x03\xff\xff", &mut []).unwrap();
    assert_eq!(expected, actual);
}

#[cfg(feature = "std")]
mod std_tests {
    use serde_bytes::ByteBuf;
    use std::collections::BTreeMap;

    use serde::de as serde_de;
    use serde_cbor::{de, error, from_reader, to_vec, Deserializer, ObjectKey, Value};

    #[test]
    fn test_string1() {
        let value: error::Result<Value> =
            de::from_slice(&[0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72]);
        assert_eq!(value.unwrap(), Value::String("foobar".to_owned()));
    }

    #[test]
    fn test_string2() {
        let value: error::Result<Value> = de::from_slice(&[
            0x71, 0x49, 0x20, 0x6d, 0x65, 0x74, 0x20, 0x61, 0x20, 0x74, 0x72, 0x61, 0x76, 0x65,
            0x6c, 0x6c, 0x65, 0x72,
        ]);
        assert_eq!(
            value.unwrap(),
            Value::String("I met a traveller".to_owned())
        );
    }

    #[test]
    fn test_string3() {
        let slice = b"\x78\x2fI met a traveller from an antique land who said";
        let value: error::Result<Value> = de::from_slice(slice);
        assert_eq!(
            value.unwrap(),
            Value::String("I met a traveller from an antique land who said".to_owned())
        );
    }

    #[test]
    fn test_byte_string() {
        let value: error::Result<Value> =
            de::from_slice(&[0x46, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72]);
        assert_eq!(value.unwrap(), Value::Bytes(b"foobar".to_vec()));
    }

    #[test]
    fn test_numbers1() {
        let value: error::Result<Value> = de::from_slice(&[0x00]);
        assert_eq!(value.unwrap(), Value::U64(0));
    }

    #[test]
    fn test_numbers2() {
        let value: error::Result<Value> = de::from_slice(&[0x1a, 0x00, 0xbc, 0x61, 0x4e]);
        assert_eq!(value.unwrap(), Value::U64(12345678));
    }

    #[test]
    fn test_numbers3() {
        let value: error::Result<Value> = de::from_slice(&[0x39, 0x07, 0xde]);
        assert_eq!(value.unwrap(), Value::I64(-2015));
    }

    #[test]
    fn test_bool() {
        let value: error::Result<Value> = de::from_slice(b"\xf4");
        assert_eq!(value.unwrap(), Value::Bool(false));
    }

    #[test]
    fn test_trailing_bytes() {
        let value: error::Result<Value> = de::from_slice(b"\xf4trailing");
        assert!(value.is_err());
    }

    #[test]
    fn test_list1() {
        let value: error::Result<Value> = de::from_slice(b"\x83\x01\x02\x03");
        assert_eq!(
            value.unwrap(),
            Value::Array(vec![Value::U64(1), Value::U64(2), Value::U64(3)])
        );
    }

    #[test]
    fn test_list2() {
        let value: error::Result<Value> = de::from_slice(b"\x82\x01\x82\x02\x81\x03");
        assert_eq!(
            value.unwrap(),
            Value::Array(vec![
                Value::U64(1),
                Value::Array(vec![Value::U64(2), Value::Array(vec![Value::U64(3)])])
            ])
        );
    }

    #[test]
    fn test_object() {
        let value: error::Result<Value> = de::from_slice(b"\xa5aaaAabaBacaCadaDaeaE");
        let mut object = BTreeMap::new();
        object.insert(
            ObjectKey::String("a".to_owned()),
            Value::String("A".to_owned()),
        );
        object.insert(
            ObjectKey::String("b".to_owned()),
            Value::String("B".to_owned()),
        );
        object.insert(
            ObjectKey::String("c".to_owned()),
            Value::String("C".to_owned()),
        );
        object.insert(
            ObjectKey::String("d".to_owned()),
            Value::String("D".to_owned()),
        );
        object.insert(
            ObjectKey::String("e".to_owned()),
            Value::String("E".to_owned()),
        );
        assert_eq!(value.unwrap(), Value::Object(object));
    }

    #[test]
    fn test_indefinite_object() {
        let value: error::Result<Value> = de::from_slice(b"\xbfaa\x01ab\x9f\x02\x03\xff\xff");
        let mut object = BTreeMap::new();
        object.insert(ObjectKey::String("a".to_owned()), Value::U64(1));
        object.insert(
            ObjectKey::String("b".to_owned()),
            Value::Array(vec![Value::U64(2), Value::U64(3)]),
        );
        assert_eq!(value.unwrap(), Value::Object(object));
    }

    #[test]
    fn test_indefinite_list() {
        let value: error::Result<Value> = de::from_slice(b"\x9f\x01\x02\x03\xff");
        assert_eq!(
            value.unwrap(),
            Value::Array(vec![Value::U64(1), Value::U64(2), Value::U64(3)])
        );
    }

    #[test]
    fn test_indefinite_string() {
        let value: error::Result<Value> =
            de::from_slice(b"\x7f\x65Mary \x64Had \x62a \x67Little \x60\x64Lamb\xff");
        assert_eq!(
            value.unwrap(),
            Value::String("Mary Had a Little Lamb".to_owned())
        );
    }

    #[test]
    fn test_indefinite_byte_string() {
        let value: error::Result<Value> = de::from_slice(b"\x5f\x42\x01\x23\x42\x45\x67\xff");
        assert_eq!(value.unwrap(), Value::Bytes(b"\x01#Eg".to_vec()));
    }

    #[test]
    fn test_multiple_indefinite_strings() {
        let input = b"\x82\x7f\x65Mary \x64Had \x62a \x67Little \x60\x64Lamb\xff\x5f\x42\x01\x23\x42\x45\x67\xff";
        _test_multiple_indefinite_strings(de::from_slice(input));
        _test_multiple_indefinite_strings(de::from_mut_slice(input.to_vec().as_mut()));
        let mut buf = [0u8; 64];
        _test_multiple_indefinite_strings(de::from_slice_with_scratch(input, &mut buf));
    }
    fn _test_multiple_indefinite_strings(value: error::Result<Value>) {
        // This assures that buffer rewinding in infinite buffers works as intended.
        assert_eq!(
            value.unwrap(),
            Value::Array(vec![
                Value::String("Mary Had a Little Lamb".to_owned()),
                Value::Bytes(b"\x01#Eg".to_vec())
            ])
        );
    }

    #[test]
    fn test_float() {
        let value: error::Result<Value> = de::from_slice(b"\xfa\x47\xc3\x50\x00");
        assert_eq!(value.unwrap(), Value::F64(100000.0));
    }

    #[test]
    fn test_self_describing() {
        let value: error::Result<Value> =
            de::from_slice(&[0xd9, 0xd9, 0xf7, 0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72]);
        assert_eq!(value.unwrap(), Value::String("foobar".to_owned()));
    }

    #[test]
    fn test_f16() {
        let mut x: Value = de::from_slice(&[0xf9, 0x41, 0x00]).unwrap();
        assert_eq!(x, Value::F64(2.5));
        x = de::from_slice(&[0xf9, 0x41, 0x90]).unwrap();
        assert_eq!(x, Value::F64(2.78125));
        x = de::from_slice(&[0xf9, 0x50, 0x90]).unwrap();
        assert_eq!(x, Value::F64(36.5));
        x = de::from_slice(&[0xf9, 0xd0, 0x90]).unwrap();
        assert_eq!(x, Value::F64(-36.5));
    }

    #[test]
    fn test_crazy_list() {
        let slice = b"\x88\x1b\x00\x00\x00\x1c\xbe\x99\x1d\xc7\x3b\x00\x7a\xcf\x51\xdc\x51\x70\xdb\x3a\x1b\x3a\x06\xdd\xf5\xf6\xf7\xfb\x41\x76\x5e\xb1\xf8\x00\x00\x00\xf9\x7c\x00";
        let value: Vec<Value> = de::from_slice(slice).unwrap();
        assert_eq!(
            value,
            vec![
                Value::U64(123456789959),
                Value::I64(-34567897654325468),
                Value::I64(-456787678),
                Value::Bool(true),
                Value::Null,
                Value::Null,
                Value::F64(23456543.5),
                Value::F64(::std::f64::INFINITY)
            ]
        );
    }

    #[test]
    fn test_nan() {
        let value: f64 = de::from_slice(b"\xf9\x7e\x00").unwrap();
        assert!(value.is_nan());
    }

    #[test]
    fn test_32f16() {
        let value: f32 = de::from_slice(b"\xf9\x50\x00").unwrap();
        assert_eq!(value, 32.0f32);
    }

    #[test]
    // The file was reported as not working by user kie0tauB
    // but it parses to a cbor value.
    fn test_kietaub_file() {
        let file = include_bytes!("kietaub.cbor");
        let value_result: error::Result<Value> = de::from_slice(file);
        value_result.unwrap();
    }

    #[test]
    fn test_option_roundtrip() {
        let obj1 = Some(10u32);

        let v = to_vec(&obj1).unwrap();
        let obj2: Result<Option<u32>, _> = serde_cbor::de::from_reader(&v[..]);
        println!("{:?}", obj2);

        assert_eq!(obj1, obj2.unwrap());
    }

    #[test]
    fn test_option_none_roundtrip() {
        let obj1 = None;

        let v = to_vec(&obj1).unwrap();
        println!("{:?}", v);
        let obj2: Result<Option<u32>, _> = serde_cbor::de::from_reader(&v[..]);

        assert_eq!(obj1, obj2.unwrap());
    }

    #[test]
    fn test_variable_length_map() {
        let slice = b"\xbf\x67\x6d\x65\x73\x73\x61\x67\x65\x64\x70\x6f\x6e\x67\xff";
        let value: Value = de::from_slice(slice).unwrap();
        let mut map = BTreeMap::new();
        map.insert(
            ObjectKey::String("message".to_string()),
            Value::String("pong".to_string()),
        );
        assert_eq!(value, Value::Object(map))
    }

    #[test]
    fn test_object_determinism_roundtrip() {
        let expected = b"\xa2aa\x01ab\x82\x02\x03";

        // 0.1% chance of not catching failure
        for _ in 0..10 {
            assert_eq!(
                &to_vec(&de::from_slice::<Value>(expected).unwrap()).unwrap(),
                expected
            );
        }
    }

    #[test]
    fn stream_deserializer() {
        let slice = b"\x01\x66foobar";
        let mut it = Deserializer::from_slice(slice).into_iter::<Value>();
        assert_eq!(Value::U64(1), it.next().unwrap().unwrap());
        assert_eq!(
            Value::String("foobar".to_string()),
            it.next().unwrap().unwrap()
        );
        assert!(it.next().is_none());
    }

    #[test]
    fn stream_deserializer_eof() {
        let slice = b"\x01\x66foob";
        let mut it = Deserializer::from_slice(slice).into_iter::<Value>();
        assert_eq!(Value::U64(1), it.next().unwrap().unwrap());
        assert!(it.next().unwrap().unwrap_err().is_eof());
    }

    #[test]
    fn stream_deserializer_eof_in_indefinite() {
        let slice = b"\x7f\x65Mary \x64Had \x62a \x60\x67Little \x60\x64Lamb\xff";
        let indices: &[usize] = &[
            2,  // announcement but no data
            10, // mid-buffer EOF
            12, // neither new element nor end marker
        ];
        for end_of_slice in indices {
            let mut it = Deserializer::from_slice(&slice[..*end_of_slice]).into_iter::<Value>();
            assert!(it.next().unwrap().unwrap_err().is_eof());

            let mut mutcopy = slice[..*end_of_slice].to_vec();
            let mut it = Deserializer::from_mut_slice(mutcopy.as_mut()).into_iter::<Value>();
            assert!(it.next().unwrap().unwrap_err().is_eof());

            let mut buf = [0u8; 64];
            let mut it = Deserializer::from_slice_with_scratch(&slice[..*end_of_slice], &mut buf)
                .into_iter::<Value>();
            assert!(it.next().unwrap().unwrap_err().is_eof());
        }
    }

    #[test]
    fn test_large_bytes() {
        let expected = (0..2 * 1024 * 1024)
            .map(|i| (i * 7) as u8)
            .collect::<Vec<_>>();
        let expected = ByteBuf::from(expected);
        let v = to_vec(&expected).unwrap();

        let actual = from_reader(&v[..]).unwrap();
        assert_eq!(expected, actual);
    }

    #[test]
    fn crash() {
        let file = include_bytes!("crash.cbor");
        let value_result: error::Result<Value> = de::from_slice(file);
        assert_eq!(
            value_result.unwrap_err().classify(),
            serde_cbor::error::Category::Syntax
        );
    }

    fn from_slice_stream<'a, T>(slice: &'a [u8]) -> error::Result<(&'a [u8], T)>
    where
        T: serde_de::Deserialize<'a>,
    {
        let mut deserializer = Deserializer::from_slice(slice);
        let value = serde_de::Deserialize::deserialize(&mut deserializer)?;
        let rest = &slice[deserializer.byte_offset()..];

        Ok((rest, value))
    }

    #[test]
    fn test_slice_offset() {
        let v: Vec<u8> = vec![
            0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72, 0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72,
        ];
        let (rest, value): (&[u8], String) = from_slice_stream(&v[..]).unwrap();
        assert_eq!(value, "foobar");
        assert_eq!(rest, &[0x66, 0x66, 0x6f, 0x6f, 0x62, 0x61, 0x72]);
        let (rest, value): (&[u8], String) = from_slice_stream(rest).unwrap();
        assert_eq!(value, "foobar");
        assert_eq!(rest, &[]);
    }
}

'''
'''--- runtime/cbor/tests/enum.rs ---
use serde::Serialize;
use serde_cbor;
use serde_cbor::ser::{Serializer, SliceWrite};

#[macro_use]
extern crate serde_derive;

#[test]
fn test_simple_data_enum_roundtrip() {
    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    enum DataEnum {
        A(u32),
        B(f32),
    }

    let a = DataEnum::A(42);

    let mut slice = [0u8; 64];
    let writer = SliceWrite::new(&mut slice);
    let mut serializer = Serializer::new(writer);
    a.serialize(&mut serializer).unwrap();
    let writer = serializer.into_inner();
    let end = writer.bytes_written();
    let slice = writer.into_inner();
    let deserialized: DataEnum =
        serde_cbor::from_slice_with_scratch(&slice[..end], &mut []).unwrap();
    assert_eq!(a, deserialized);
}

#[cfg(feature = "std")]
mod std_tests {
    use std::collections::BTreeMap;

    use serde_cbor::{from_slice, to_vec, ObjectKey, Value};

    #[derive(Debug, Serialize, Deserialize, PartialEq, Eq)]
    enum Enum {
        A,
        B,
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq, Eq)]
    struct EnumStruct {
        e: Enum,
    }

    #[test]
    fn test_enum() {
        let enum_struct = EnumStruct { e: Enum::B };
        let raw = &to_vec(&enum_struct).unwrap();
        println!("raw enum {:?}", raw);
        let re: EnumStruct = from_slice(raw).unwrap();
        assert_eq!(enum_struct, re);
    }

    #[repr(u16)]
    #[derive(Debug, Serialize, Deserialize, PartialEq, Eq)]
    enum ReprEnum {
        A,
        B,
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq, Eq)]
    struct ReprEnumStruct {
        e: ReprEnum,
    }

    #[test]
    fn test_repr_enum() {
        let repr_enum_struct = ReprEnumStruct { e: ReprEnum::B };
        let re: ReprEnumStruct = from_slice(&to_vec(&repr_enum_struct).unwrap()).unwrap();
        assert_eq!(repr_enum_struct, re);
    }

    #[derive(Debug, Serialize, Deserialize, PartialEq, Eq)]
    enum DataEnum {
        A(u32),
        B(bool, u8),
        C { x: u8, y: String },
    }

    #[test]
    fn test_data_enum() {
        let data_enum_a = DataEnum::A(4);
        let re_a: DataEnum = from_slice(&to_vec(&data_enum_a).unwrap()).unwrap();
        assert_eq!(data_enum_a, re_a);
        let data_enum_b = DataEnum::B(true, 42);
        let re_b: DataEnum = from_slice(&to_vec(&data_enum_b).unwrap()).unwrap();
        assert_eq!(data_enum_b, re_b);
        let data_enum_c = DataEnum::C {
            x: 3,
            y: "foo".to_owned(),
        };
        println!("{:?}", &to_vec(&data_enum_c).unwrap());
        let re_c: DataEnum = from_slice(&to_vec(&data_enum_c).unwrap()).unwrap();
        assert_eq!(data_enum_c, re_c);
    }

    #[test]
    fn test_serialize() {
        assert_eq!(to_vec(&Enum::A).unwrap(), &[97, 65]);
        assert_eq!(to_vec(&Enum::B).unwrap(), &[97, 66]);
        assert_eq!(to_vec(&DataEnum::A(42)).unwrap(), &[130, 97, 65, 24, 42]);
        assert_eq!(
            to_vec(&DataEnum::B(true, 9)).unwrap(),
            &[131, 97, 66, 245, 9]
        );
    }

    #[test]
    fn test_newtype_struct() {
        #[derive(Debug, Deserialize, Serialize, PartialEq, Eq)]
        pub struct Newtype(u8);
        assert_eq!(to_vec(&142u8).unwrap(), to_vec(&Newtype(142u8)).unwrap());
        assert_eq!(from_slice::<Newtype>(&[24, 142]).unwrap(), Newtype(142));
    }

    #[derive(Deserialize, PartialEq, Debug)]
    enum Foo {
        #[serde(rename = "require")]
        Require,
    }

    #[test]
    fn test_variable_length_array() {
        let slice = b"\x9F\x67\x72\x65\x71\x75\x69\x72\x65\xFF";
        let value: Vec<Foo> = from_slice(slice).unwrap();
        assert_eq!(value, [Foo::Require]);
    }

    #[derive(Serialize, Deserialize, PartialEq, Debug)]
    enum Bar {
        Empty,
        Number(i32),
        Flag(String, bool),
        Point { x: i32, y: i32 },
    }

    #[test]
    fn test_enum_as_map() {
        // unit variants serialize like bare strings
        let empty_s = to_vec(&Bar::Empty).unwrap();
        let empty_str_s = to_vec(&"Empty").unwrap();
        assert_eq!(empty_s, empty_str_s);

        // tuple-variants serialize like ["<variant>", values..]
        let number_s = to_vec(&Bar::Number(42)).unwrap();
        let number_vec = vec![Value::String("Number".to_string()), Value::I64(42)];
        let number_vec_s = to_vec(&number_vec).unwrap();
        assert_eq!(number_s, number_vec_s);

        let flag_s = to_vec(&Bar::Flag("foo".to_string(), true)).unwrap();
        let flag_vec = vec![
            Value::String("Flag".to_string()),
            Value::String("foo".to_string()),
            Value::Bool(true),
        ];
        let flag_vec_s = to_vec(&flag_vec).unwrap();
        assert_eq!(flag_s, flag_vec_s);

        // struct-variants serialize like ["<variant>", {struct..}]
        let point_s = to_vec(&Bar::Point { x: 5, y: -5 }).unwrap();
        let mut struct_map = BTreeMap::new();
        struct_map.insert(ObjectKey::String("x".to_string()), Value::I64(5));
        struct_map.insert(ObjectKey::String("y".to_string()), Value::I64(-5));
        let point_vec = vec![
            Value::String("Point".to_string()),
            Value::Object(struct_map.clone()),
        ];
        let point_vec_s = to_vec(&point_vec).unwrap();
        assert_eq!(point_s, point_vec_s);

        // enum_as_map matches serde_json's default serialization for enums.
        let opts = serde_cbor::SerializerOptions {
            enum_as_map: true,
            ..Default::default()
        };

        // unit variants still serialize like bare strings
        let empty_s = opts.to_vec(&Bar::Empty).unwrap();
        assert_eq!(empty_s, empty_str_s);

        // 1-element tuple variants serialize like {"<variant>": value}
        let number_s = opts.to_vec(&Bar::Number(42)).unwrap();
        let mut number_map = BTreeMap::new();
        number_map.insert("Number", 42);
        let number_map_s = to_vec(&number_map).unwrap();
        assert_eq!(number_s, number_map_s);

        // multi-element tuple variants serialize like {"<variant>": [values..]}
        let flag_s = opts.to_vec(&Bar::Flag("foo".to_string(), true)).unwrap();
        let mut flag_map = BTreeMap::new();
        flag_map.insert(
            "Flag",
            vec![Value::String("foo".to_string()), Value::Bool(true)],
        );
        let flag_map_s = to_vec(&flag_map).unwrap();
        assert_eq!(flag_s, flag_map_s);

        // struct-variants serialize like {"<variant>", {struct..}}
        let point_s = opts.to_vec(&Bar::Point { x: 5, y: -5 }).unwrap();
        let mut point_map = BTreeMap::new();
        point_map.insert("Point", Value::Object(struct_map));
        let point_map_s = to_vec(&point_map).unwrap();
        assert_eq!(point_s, point_map_s);

        // deserialization of all encodings should just work
        let empty_str_ds = from_slice(&empty_str_s).unwrap();
        assert_eq!(Bar::Empty, empty_str_ds);

        let number_vec_ds = from_slice(&number_vec_s).unwrap();
        assert_eq!(Bar::Number(42), number_vec_ds);
        let number_map_ds = from_slice(&number_map_s).unwrap();
        assert_eq!(Bar::Number(42), number_map_ds);

        let flag_vec_ds = from_slice(&flag_vec_s).unwrap();
        assert_eq!(Bar::Flag("foo".to_string(), true), flag_vec_ds);
        let flag_map_ds = from_slice(&flag_map_s).unwrap();
        assert_eq!(Bar::Flag("foo".to_string(), true), flag_map_ds);

        let point_vec_ds = from_slice(&point_vec_s).unwrap();
        assert_eq!(Bar::Point { x: 5, y: -5 }, point_vec_ds);
        let point_map_ds = from_slice(&point_map_s).unwrap();
        assert_eq!(Bar::Point { x: 5, y: -5 }, point_map_ds);
    }
}

'''
'''--- runtime/cbor/tests/ser.rs ---
use serde::Serialize;
use serde_cbor::ser::{Serializer, SliceWrite};

#[test]
fn test_str() {
    serialize_and_compare("foobar", b"ffoobar");
}

#[test]
fn test_list() {
    serialize_and_compare(&[1, 2, 3], b"\x83\x01\x02\x03");
}

#[test]
fn test_float() {
    serialize_and_compare(12.3f64, b"\xfb@(\x99\x99\x99\x99\x99\x9a");
}

#[test]
fn test_integer() {
    // u8
    serialize_and_compare(24, b"\x18\x18");
    // i8
    serialize_and_compare(-5, b"\x24");
    // i16
    serialize_and_compare(-300, b"\x39\x01\x2b");
    // i32
    serialize_and_compare(-23567997, b"\x3a\x01\x67\x9e\x7c");
    // u64
    serialize_and_compare(::core::u64::MAX, b"\x1b\xff\xff\xff\xff\xff\xff\xff\xff");
}

fn serialize_and_compare<T: Serialize>(value: T, expected: &[u8]) {
    let mut slice = [0u8; 64];
    let writer = SliceWrite::new(&mut slice);
    let mut serializer = Serializer::new(writer);
    value.serialize(&mut serializer).unwrap();
    let writer = serializer.into_inner();
    let end = writer.bytes_written();
    let slice = writer.into_inner();
    assert_eq!(&slice[..end], expected);
}

#[cfg(feature = "std")]
mod std_tests {
    use serde::Serializer;
    use serde_bytes::{ByteBuf, Bytes};
    use serde_cbor::ser;
    use serde_cbor::{from_slice, to_vec};
    use std::collections::BTreeMap;

    #[test]
    fn test_string() {
        let value = "foobar".to_owned();
        assert_eq!(&to_vec(&value).unwrap()[..], b"ffoobar");
    }

    #[test]
    fn test_list() {
        let value = vec![1, 2, 3];
        assert_eq!(&to_vec(&value).unwrap()[..], b"\x83\x01\x02\x03");
    }

    #[test]
    fn test_object() {
        let mut object = BTreeMap::new();
        object.insert("a".to_owned(), "A".to_owned());
        object.insert("b".to_owned(), "B".to_owned());
        object.insert("c".to_owned(), "C".to_owned());
        object.insert("d".to_owned(), "D".to_owned());
        object.insert("e".to_owned(), "E".to_owned());
        let vec = to_vec(&object).unwrap();
        let test_object = from_slice(&vec[..]).unwrap();
        assert_eq!(object, test_object);
    }

    #[test]
    fn test_object_list_keys() {
        let mut object = BTreeMap::new();
        object.insert(vec![0i64], ());
        object.insert(vec![100i64], ());
        object.insert(vec![-1i64], ());
        object.insert(vec![-2i64], ());
        object.insert(vec![0i64, 0i64], ());
        object.insert(vec![0i64, -1i64], ());
        let vec = to_vec(&object).unwrap();
        assert_eq!(
            vec![
                166, 129, 0, 246, 129, 24, 100, 246, 129, 32, 246, 129, 33, 246, 130, 0, 0, 246,
                130, 0, 32, 246
            ],
            vec
        );
        let test_object = from_slice(&vec[..]).unwrap();
        assert_eq!(object, test_object);
    }

    #[test]
    fn test_object_object_keys() {
        use std::iter::FromIterator;
        let mut object = BTreeMap::new();
        let keys = vec![
            vec!["a"],
            vec!["b"],
            vec!["c"],
            vec!["d"],
            vec!["aa"],
            vec!["a", "aa"],
        ]
        .into_iter()
        .map(|v| BTreeMap::from_iter(v.into_iter().map(|s| (s.to_owned(), ()))));

        for key in keys {
            object.insert(key, ());
        }
        let vec = to_vec(&object).unwrap();
        assert_eq!(
            vec![
                166, 161, 97, 97, 246, 246, 161, 97, 98, 246, 246, 161, 97, 99, 246, 246, 161, 97,
                100, 246, 246, 161, 98, 97, 97, 246, 246, 162, 97, 97, 246, 98, 97, 97, 246, 246
            ],
            vec
        );
        let test_object = from_slice(&vec[..]).unwrap();
        assert_eq!(object, test_object);
    }

    #[test]
    fn test_float() {
        let vec = to_vec(&12.3f64).unwrap();
        assert_eq!(vec, b"\xfb@(\x99\x99\x99\x99\x99\x9a");
    }

    #[test]
    fn test_f32() {
        let vec = to_vec(&4000.5f32).unwrap();
        assert_eq!(vec, b"\xfa\x45\x7a\x08\x00");
    }

    #[test]
    fn test_infinity() {
        let vec = to_vec(&::std::f64::INFINITY).unwrap();
        assert_eq!(vec, b"\xf9|\x00");
    }

    #[test]
    fn test_neg_infinity() {
        let vec = to_vec(&::std::f64::NEG_INFINITY).unwrap();
        assert_eq!(vec, b"\xf9\xfc\x00");
    }

    #[test]
    fn test_nan() {
        let vec = to_vec(&::std::f32::NAN).unwrap();
        assert_eq!(vec, b"\xf9\x7e\x00");
    }

    #[test]
    fn test_integer() {
        // u8
        let vec = to_vec(&24).unwrap();
        assert_eq!(vec, b"\x18\x18");
        // i8
        let vec = to_vec(&-5).unwrap();
        assert_eq!(vec, b"\x24");
        // i16
        let vec = to_vec(&-300).unwrap();
        assert_eq!(vec, b"\x39\x01\x2b");
        // i32
        let vec = to_vec(&-23567997).unwrap();
        assert_eq!(vec, b"\x3a\x01\x67\x9e\x7c");
        // u64
        let vec = to_vec(&::std::u64::MAX).unwrap();
        assert_eq!(vec, b"\x1b\xff\xff\xff\xff\xff\xff\xff\xff");
    }

    #[test]
    fn test_self_describing() {
        let mut vec = Vec::new();
        {
            let mut serializer = ser::Serializer::new(&mut vec);
            serializer.self_describe().unwrap();
            serializer.serialize_u64(9).unwrap();
        }
        assert_eq!(vec, b"\xd9\xd9\xf7\x09");

        let sd = ser::SerializerOptions {
            self_describe: true,
            ..Default::default()
        };
        let vec = sd.to_vec(&9).unwrap();
        assert_eq!(vec, b"\xd9\xd9\xf7\x09");
    }

    #[test]
    fn test_ip_addr() {
        use std::net::Ipv4Addr;

        let addr = Ipv4Addr::new(8, 8, 8, 8);
        let vec = to_vec(&addr).unwrap();
        println!("{:?}", vec);
        assert_eq!(vec.len(), 5);
        let test_addr: Ipv4Addr = from_slice(&vec).unwrap();
        assert_eq!(addr, test_addr);
    }

    /// Test all of CBOR's fixed-length byte string types
    #[test]
    fn test_byte_string() {
        // Very short byte strings have 1-byte headers
        let short = ByteBuf::from(vec![0, 1, 2, 255]);
        let short_s = to_vec(&short).unwrap();
        assert_eq!(&short_s[..], [0x44, 0, 1, 2, 255]);

        // Encoding a slice should work the same as a vector
        let short_slice_s = to_vec(&Bytes::from(&short[..])).unwrap();
        assert_eq!(&short_slice_s[..], [0x44, 0, 1, 2, 255]);

        // byte strings > 23 bytes have 2-byte headers
        let medium = ByteBuf::from(vec![
            0u8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 255,
        ]);
        let medium_s = to_vec(&medium).unwrap();
        assert_eq!(
            &medium_s[..],
            [
                0x58, 24, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
                21, 22, 255
            ]
        );

        // byte strings > 256 bytes have 3-byte headers
        let long_vec = (0..256).map(|i| (i & 0xFF) as u8).collect::<Vec<_>>();
        let long = ByteBuf::from(long_vec);
        let long_s = to_vec(&long).unwrap();
        assert_eq!(&long_s[0..3], [0x59, 1, 0]);
        assert_eq!(&long_s[3..], &long[..]);

        // byte strings > 2^16 bytes have 5-byte headers
        let very_long_vec = (0..65536).map(|i| (i & 0xFF) as u8).collect::<Vec<_>>();
        let very_long = ByteBuf::from(very_long_vec);
        let very_long_s = to_vec(&very_long).unwrap();
        assert_eq!(&very_long_s[0..5], [0x5a, 0, 1, 0, 0]);
        assert_eq!(&very_long_s[5..], &very_long[..]);

        // byte strings > 2^32 bytes have 9-byte headers, but they take too much RAM
        // to test in Travis.
    }

    #[test]
    fn test_half() {
        let vec = to_vec(&42.5f32).unwrap();
        assert_eq!(vec, b"\xF9\x51\x50");
        assert_eq!(from_slice::<f32>(&vec[..]).unwrap(), 42.5f32);
    }
}

'''
'''--- runtime/cbor/tests/std_types.rs ---
#[macro_use]
extern crate serde_derive;

#[cfg(feature = "std")]
mod std_tests {
    use std::u8;

    use serde_bytes::ByteBuf;

    use serde_cbor::ser::{to_vec, to_vec_packed};
    use serde_cbor::{from_mut_slice, from_reader, from_slice};

    fn to_binary(s: &'static str) -> Vec<u8> {
        assert!(s.len() % 2 == 0);
        let mut b = Vec::with_capacity(s.len() / 2);
        for i in 0..s.len() / 2 {
            b.push(u8::from_str_radix(&s[i * 2..(i + 1) * 2], 16).unwrap());
        }
        b
    }

    macro_rules! testcase {
        ($name:ident, f64, $expr:expr, $s:expr) => {
            #[test]
            fn $name() {
                let expr: f64 = $expr;
                let mut serialized = to_binary($s);
                assert_eq!(to_vec(&expr).unwrap(), serialized);
                let parsed: f64 = from_slice(&serialized[..]).unwrap();
                if !expr.is_nan() {
                    assert_eq!(expr, parsed);
                } else {
                    assert!(parsed.is_nan())
                }

                let parsed: f64 = from_reader(&mut &serialized[..]).unwrap();
                if !expr.is_nan() {
                    assert_eq!(expr, parsed);
                } else {
                    assert!(parsed.is_nan())
                }

                let parsed: f64 = from_mut_slice(&mut serialized[..]).unwrap();
                if !expr.is_nan() {
                    assert_eq!(expr, parsed);
                } else {
                    assert!(parsed.is_nan())
                }
            }
        };
        ($name:ident, $ty:ty, $expr:expr, $s:expr) => {
            #[test]
            fn $name() {
                let expr: $ty = $expr;
                let mut serialized = to_binary($s);
                assert_eq!(
                    to_vec(&expr).expect("ser1 works"),
                    serialized,
                    "serialization differs"
                );
                let parsed: $ty = from_slice(&serialized[..]).expect("de1 works");
                assert_eq!(parsed, expr, "parsed result differs");
                let packed = &to_vec_packed(&expr).expect("serializing packed")[..];
                let parsed_from_packed: $ty = from_slice(packed).expect("parsing packed");
                assert_eq!(parsed_from_packed, expr, "packed roundtrip fail");

                let parsed: $ty = from_reader(&mut &serialized[..]).unwrap();
                assert_eq!(parsed, expr, "parsed result differs");
                let mut packed = to_vec_packed(&expr).expect("serializing packed");
                let parsed_from_packed: $ty =
                    from_reader(&mut &packed[..]).expect("parsing packed");
                assert_eq!(parsed_from_packed, expr, "packed roundtrip fail");

                let parsed: $ty = from_mut_slice(&mut serialized[..]).unwrap();
                assert_eq!(parsed, expr, "parsed result differs");
                let parsed_from_packed: $ty =
                    from_mut_slice(&mut packed[..]).expect("parsing packed");
                assert_eq!(parsed_from_packed, expr, "packed roundtrip fail");
            }
        };
    }

    testcase!(test_bool_false, bool, false, "f4");
    testcase!(test_bool_true, bool, true, "f5");
    testcase!(test_isize_neg_256, isize, -256, "38ff");
    testcase!(test_isize_neg_257, isize, -257, "390100");
    testcase!(test_isize_255, isize, 255, "18ff");
    testcase!(test_i8_5, i8, 5, "05");
    testcase!(test_i8_23, i8, 23, "17");
    testcase!(test_i8_24, i8, 24, "1818");
    testcase!(test_i8_neg_128, i8, -128, "387f");
    testcase!(test_u32_98745874, u32, 98745874, "1a05e2be12");
    testcase!(test_f32_1234_point_5, f32, 1234.5, "fa449a5000");
    testcase!(test_f64_12345_point_6, f64, 12345.6, "fb40c81ccccccccccd");
    testcase!(test_f64_nan, f64, ::std::f64::NAN, "f97e00");
    testcase!(test_f64_infinity, f64, ::std::f64::INFINITY, "f97c00");
    testcase!(test_f64_neg_infinity, f64, -::std::f64::INFINITY, "f9fc00");
    testcase!(test_char_null, char, '\x00', "6100");
    testcase!(test_char_broken_heart, char, '💔', "64f09f9294");
    testcase!(
        test_str_pangram_de,
        String,
        "aâø↓é".to_owned(),
        "6a61c3a2c3b8e28693c3a9"
    );
    testcase!(test_bytes, ByteBuf, b"\x00\xab".to_vec().into(), "4200ab");
    testcase!(test_unit, (), (), "f6");

    #[derive(Debug, PartialEq, Deserialize, Serialize)]
    struct UnitStruct;
    testcase!(test_unit_struct, UnitStruct, UnitStruct, "f6");

    #[derive(Debug, PartialEq, Deserialize, Serialize)]
    struct NewtypeStruct(bool);
    testcase!(
        test_newtype_struct,
        NewtypeStruct,
        NewtypeStruct(true),
        "f5"
    );

    testcase!(test_option_none, Option<u8>, None, "f6");
    testcase!(test_option_some, Option<u8>, Some(42), "182a");

    #[derive(Debug, PartialEq, Deserialize, Serialize)]
    struct Person {
        name: String,
        year_of_birth: u16,
        profession: Option<String>,
    }

    testcase!(test_person_struct,
    Person,
    Person {
        name: "Grace Hopper".to_string(),
        year_of_birth: 1906,
        profession: Some("computer scientist".to_string()),
    },
    "a3646e616d656c477261636520486f707065726a70726f66657373696f6e72636f6d707574657220736369656e746973746d796561725f6f665f6269727468190772");

    #[derive(Debug, PartialEq, Deserialize, Serialize)]
    struct OptionalPerson {
        name: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        year_of_birth: Option<u16>,
        profession: Option<String>,
    }

    testcase!(test_optional_person_struct,
    OptionalPerson,
    OptionalPerson {
        name: "Grace Hopper".to_string(),
        year_of_birth: None,
        profession: Some("computer scientist".to_string()),
    },
    "a2646e616d656c477261636520486f707065726a70726f66657373696f6e72636f6d707574657220736369656e74697374");

    #[derive(Debug, PartialEq, Deserialize, Serialize)]
    enum Color {
        Red,
        Blue,
        Yellow,
        Other(u64),
        Alpha(u64, u8),
    }

    testcase!(test_color_enum, Color, Color::Blue, "64426c7565");
    testcase!(
        test_color_enum_transparent,
        Color,
        Color::Other(42),
        "82654f74686572182a"
    );
    testcase!(
        test_color_enum_with_alpha,
        Color,
        Color::Alpha(234567, 60),
        "8365416c7068611a00039447183c"
    );
    testcase!(test_i128_a, i128, -1i128, "20");
    testcase!(
        test_i128_b,
        i128,
        -18446744073709551616i128,
        "3BFFFFFFFFFFFFFFFF"
    );
    testcase!(test_u128, u128, 17, "11");
}

'''
'''--- runtime/cbor/tests/value.rs ---
#[macro_use]
extern crate serde_derive;

#[cfg(feature = "std")]
mod std_tests {
    use serde_cbor;

    use std::collections::BTreeMap;

    #[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
    struct TupleStruct(String, i32, u64);

    #[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
    struct UnitStruct;

    #[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
    struct Struct<'a> {
        tuple_struct: TupleStruct,
        tuple: (String, f32, f64),
        map: BTreeMap<String, String>,
        bytes: &'a [u8],
        array: Vec<String>,
        unit_array: Vec<UnitStruct>,
    }

    use serde_cbor::Value;
    use std::iter::FromIterator;

    #[test]
    fn serde() {
        let tuple_struct = TupleStruct(format!("test"), -60, 3000);

        let tuple = (format!("hello"), -50.0040957, -12.094635556478);

        let map = BTreeMap::from_iter(
            [
                (format!("key1"), format!("value1")),
                (format!("key2"), format!("value2")),
                (format!("key3"), format!("value3")),
                (format!("key4"), format!("value4")),
            ]
            .into_iter()
            .cloned(),
        );

        let bytes = b"test byte string";

        let array = vec![format!("one"), format!("two"), format!("three")];
        let unit_array = vec![UnitStruct, UnitStruct, UnitStruct];

        let data = Struct {
            tuple_struct,
            tuple,
            map,
            bytes,
            array,
            unit_array,
        };

        let value = serde_cbor::to_value(data.clone()).unwrap();
        println!("{:?}", value);

        let data_ser = serde_cbor::to_vec(&value).unwrap();
        let data_de_value: Value = serde_cbor::from_slice(&data_ser).unwrap();

        for ((k1, v1), (k2, v2)) in value
            .as_object()
            .unwrap()
            .iter()
            .zip(data_de_value.as_object().unwrap().iter())
        {
            assert_eq!(k1, k2);
            assert_eq!(v1, v2);
        }

        assert_eq!(value, data_de_value);
    }
}

'''
'''--- runtime/handler/Cargo.toml ---
[package]
description = "Handler IPFS-compatible API"
name = "filesys-ipfs-api"
version = "1.12.0"
license = "GPL-3.0"
authors = ["Parity Technologies <admin@parity.io>"]

[dependencies]
filesys-api = { path = "../../filesys-api" }
parity-bytes = "0.1"
ethereum-types = "0.4"
jsonrpc-core = "10.0.1"
jsonrpc-http-server = "10.0.1"
rlp = { version = "0.3.0", features = ["ethereum"] }
cid = "0.3"
multihash = "0.8"
unicase = "2.0"
multiaddr = "*"
multibase = "*"

[dev-dependencies]

'''
'''--- runtime/handler/src/error.rs ---
use {multihash, cid, http};
use route::Out;

pub type Result<T> = ::std::result::Result<T, Error>;

/// Handler server error
#[derive(Debug)]
pub enum ServerError {
	/// Wrapped `std::io::Error`
	IoError(::std::io::Error),
	/// Other `hyper` error
	Other(http::hyper::error::Error),
	/// Invalid --ipfs-api-interface
	InvalidInterface
}

/// Handle IO errors (ports taken when starting the server).
impl From<::std::io::Error> for ServerError {
	fn from(err: ::std::io::Error) -> ServerError {
		ServerError::IoError(err)
	}
}

impl From<http::hyper::error::Error> for ServerError {
	fn from(err: http::hyper::error::Error) -> ServerError {
		ServerError::Other(err)
	}
}

impl From<ServerError> for String {
	fn from(err: ServerError) -> String {
		match err {
			ServerError::IoError(err) => err.to_string(),
			ServerError::Other(err) => err.to_string(),
			ServerError::InvalidInterface => "Invalid --ipfs-api-interface parameter".into(),
		}
	}
}

impl ::std::fmt::Display for ServerError {
	fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        match self {
        	ServerError::IoError(err) => write!(f, "Io Error: {}", err),
        	ServerError::Other(err) => write!(f, "Other error: {}", err),
        	ServerError::InvalidInterface => write!(f, "Invalid interface"),
        }
    }
}

impl ::std::error::Error for ServerError {}

#[derive(Debug, PartialEq)]
pub enum Error {
	CidParsingFailed,
	UnsupportedHash,
	UnsupportedCid,
	BlockNotFound,
	TransactionNotFound,
	StateRootNotFound,
	ContractNotFound,
}

/// Convert Error into Out, handy when switching from Rust's Result-based
/// error handling to Hyper's request handling.
impl From<Error> for Out {
	fn from(err: Error) -> Out {
		use self::Error::*;

		match err {
			UnsupportedHash => Out::Bad("Hash must be Keccak-256"),
			UnsupportedCid => Out::Bad("CID codec not supported"),
			CidParsingFailed => Out::Bad("CID parsing failed"),
			BlockNotFound => Out::NotFound("Block not found"),
			TransactionNotFound => Out::NotFound("Transaction not found"),
			StateRootNotFound => Out::NotFound("State root not found"),
			ContractNotFound => Out::NotFound("Contract not found"),
		}
	}
}

/// Convert Content ID errors.
impl From<cid::Error> for Error {
	fn from(_: cid::Error) -> Error {
		Error::CidParsingFailed
	}
}

/// Convert multihash errors (multihash being part of CID).
impl From<multihash::Error> for Error {
	fn from(_: multihash::Error) -> Error {
		Error::CidParsingFailed
	}
}

'''
'''--- runtime/handler/src/lib.rs ---
extern crate multihash;
extern crate cid;
extern crate unicase;

extern crate rlp;
extern crate parity_bytes as bytes;
extern crate ethereum_types;
extern crate jsonrpc_core as core;
extern crate jsonrpc_http_server as http;

pub mod error;
mod route;

use std::thread;
use std::sync::{mpsc, Arc};
use std::net::{SocketAddr, IpAddr};

use core::futures::future::{self, FutureResult};
use core::futures::{self, Future};
use filesys_api::FileSysClient;
use http::hyper::{self, server, Method, StatusCode, Body,
	header::{self, HeaderValue},
};

use error::ServerError;
use route::Out;

pub use http::{AccessControlAllowOrigin, Host, DomainsValidation};

/// Request/response handler
pub struct Handler {
	/// Allowed CORS domains
	cors_domains: Option<Vec<AccessControlAllowOrigin>>,
	/// Hostnames allowed in the `Host` request header
	allowed_hosts: Option<Vec<Host>>,
	/// Reference to the Blockchain Client
	client: Arc<FileSysClient>,
}

impl Handler {
	pub fn Client(&self) -> &FileSysClient {
		&*self.client
	}

	pub fn new(cors: DomainsValidation<AccessControlAllowOrigin>, hosts: DomainsValidation<Host>, client: Arc<Client>) -> Self {
		Handler {
			cors_domains: cors.into(),
			allowed_hosts: hosts.into(),
			client: client,
		}
	}
	pub fn on_request(&self, req: hyper::Request<Body>) -> (Option<HeaderValue>, Out) {
		match *req.method() {
			Method::GET | Method::POST => {},
			_ => return (None, Out::Bad("Invalid Request")),
		}

		if !http::is_host_allowed(&req, &self.allowed_hosts) {
			return (None, Out::Bad("Disallowed Host header"));
		}

		let cors_header = http::cors_allow_origin(&req, &self.cors_domains);
		if cors_header == http::AllowCors::Invalid {
			return (None, Out::Bad("Disallowed Origin header"));
		}

		let path = req.uri().path();
		let query = req.uri().query();
		return (cors_header.into(), self.route(path, query));
	}
}

impl hyper::service::Service for Handler {
	type ReqBody = Body;
	type ResBody = Body;
	type Error = hyper::Error;
	type Future = FutureResult<hyper::Response<Body>, Self::Error>;

	fn call(&mut self, request: hyper::Request<Self::ReqBody>) -> Self::Future {
		let (cors_header, out) = self.on_request(request);

		let mut res = match out {
			Out::OctetStream(bytes) => {
				hyper::Response::builder()
					.status(StatusCode::OK)
					.header("content-type", HeaderValue::from_static("application/octet-stream"))
					.body(bytes.into())
			},
			Out::NotFound(reason) => {
				hyper::Response::builder()
					.status(StatusCode::NOT_FOUND)
					.header("content-type", HeaderValue::from_static("text/plain; charset=utf-8"))
					.body(reason.into())
			},
			Out::Bad(reason) => {
				hyper::Response::builder()
					.status(StatusCode::BAD_REQUEST)
					.header("content-type", HeaderValue::from_static("text/plain; charset=utf-8"))
					.body(reason.into())
			}
		}.expect("Response builder: Parsing 'content-type' header name will not fail; qed");

		if let Some(cors_header) = cors_header {
			res.headers_mut().append(header::ACCESS_CONTROL_ALLOW_ORIGIN, cors_header);
			res.headers_mut().append(header::VARY, HeaderValue::from_static("origin"));
		}

		future::ok(res)
	}
}

/// Add current interface (default: "127.0.0.1:5001") to list of allowed hosts
fn include_current_interface(mut hosts: Vec<Host>, interface: String, port: u16) -> Vec<Host> {
	hosts.push(match port {
		80 => interface,
		_ => format!("{}:{}", interface, port),
	}.into());

	hosts
}

#[derive(Debug)]
pub struct Listening {
	close: Option<futures::sync::oneshot::Sender<()>>,
	thread: Option<thread::JoinHandle<()>>,
}

impl Drop for Listening {
	fn drop(&mut self) {
		self.close.take().unwrap().send(()).unwrap();
		let _ = self.thread.take().unwrap().join();
	}
}

pub fn start_server(
	port: u16,
	interface: String,
	cors: DomainsValidation<AccessControlAllowOrigin>,
	hosts: DomainsValidation<Host>,
	client: Arc<FileSysClient>
) -> Result<Listening, ServerError> {

	let ip: IpAddr = interface.parse().map_err(|_| ServerError::InvalidInterface)?;
	let addr = SocketAddr::new(ip, port);
	let hosts: Option<Vec<_>> = hosts.into();
	let hosts: DomainsValidation<_> = hosts.map(move |hosts| include_current_interface(hosts, interface, port)).into();

	let (close, shutdown_signal) = futures::sync::oneshot::channel::<()>();
	let (tx, rx) = mpsc::sync_channel::<Result<(), ServerError>>(1);
	let thread = thread::spawn(move || {
		let send = |res| tx.send(res).expect("rx end is never dropped; qed");

		let server_bldr = match server::Server::try_bind(&addr) {
			Ok(s) => s,
			Err(err) => {
				send(Err(ServerError::from(err)));
				return;
			}
		};

		let new_service = move || {
			Ok::<_, ServerError>(
				Handler::new(cors.clone(), hosts.clone(), client.clone())
			)
		};

		let server = server_bldr
	        .serve(new_service)
	        .map_err(|_| ())
	        .select(shutdown_signal.map_err(|_| ()))
	        .then(|_| Ok(()));

	    hyper::rt::run(server);
		send(Ok(()));
	});

	// Wait for server to start successfuly.
	rx.recv().expect("tx end is never dropped; qed")?;

	Ok(Listening {
		close: close.into(),
		thread: thread.into(),
	})
}

'''
'''--- runtime/handler/src/route.rs ---
use {rlp, multihash, Handler};
use error::{Error, Result};
use cid::{ToCid, Codec};

use multihash::Hash;
use ethereum_types::H256;
use bytes::Bytes;
use ethcore::client::{BlockId, TransactionId};

type Reason = &'static str;

/// Keeps the state of the response to send out
#[derive(Debug, PartialEq)]
pub enum Out {
	OctetStream(Bytes),
	NotFound(Reason),
	Bad(Reason),
}

impl Handler {
	/// Route path + query string to a specialized method
	pub fn route(&self, path: &str, query: Option<&str>) -> Out {
		match path {
			"/api/v0/block/get" => {
				let arg = query.and_then(|q| get_param(q, "arg")).unwrap_or("");

				self.route_cid(arg).unwrap_or_else(Into::into)
			},

			_ => Out::NotFound("Route not found")
		}
	}

	/// Attempt to read Content ID from `arg` query parameter, get a hash and
	/// route further by the CID's codec.
	fn route_cid(&self, cid: &str) -> Result<Out> {
		let cid = cid.to_cid()?;

		let mh = multihash::decode(&cid.hash)?;

		if mh.alg != Hash::Keccak256 { return Err(Error::UnsupportedHash); }

		let hash: H256 = mh.digest.into();

		match cid.codec {
			Codec::EthereumBlock => self.block(hash),
			Codec::EthereumBlockList => self.block_list(hash),
			Codec::EthereumTx => self.transaction(hash),
			Codec::EthereumStateTrie => self.state_trie(hash),
			Codec::Raw => self.contract_code(hash),
			_ => return Err(Error::UnsupportedCid),
		}
	}

	/// Get block header by hash as raw binary.
	fn block(&self, hash: H256) -> Result<Out> {
		let block_id = BlockId::Hash(hash);
		let block = self.client().block_header(block_id).ok_or(Error::BlockNotFound)?;

		Ok(Out::OctetStream(block.into_inner()))
	}

	/// Get list of block ommers by hash as raw binary.
	fn block_list(&self, hash: H256) -> Result<Out> {
		let uncles = self.client().find_uncles(&hash).ok_or(Error::BlockNotFound)?;

		Ok(Out::OctetStream(rlp::encode_list(&uncles)))
	}

	/// Get transaction by hash and return as raw binary.
	fn transaction(&self, hash: H256) -> Result<Out> {
		let tx_id = TransactionId::Hash(hash);
		let tx = self.client().transaction(tx_id).ok_or(Error::TransactionNotFound)?;

		Ok(Out::OctetStream(rlp::encode(&*tx)))
	}

	/// Get state trie node by hash and return as raw binary.
	fn state_trie(&self, hash: H256) -> Result<Out> {
		let data = self.client().state_data(&hash).ok_or(Error::StateRootNotFound)?;

		Ok(Out::OctetStream(data))
	}

	/// Get state trie node by hash and return as raw binary.
	fn contract_code(&self, hash: H256) -> Result<Out> {
		let data = self.client().state_data(&hash).ok_or(Error::ContractNotFound)?;

		Ok(Out::OctetStream(data))
	}
}

/// Get a query parameter's value by name.
fn get_param<'a>(query: &'a str, name: &str) -> Option<&'a str> {
	query.split('&')
		.find(|part| part.starts_with(name) && part[name.len()..].starts_with("="))
		.map(|part| &part[name.len() + 1..])
}

#[cfg(test)]
mod tests {
	use std::sync::Arc;
	use super::*;
	use ethcore::client::TestBlockChainClient;

	fn get_mocked_handler() -> IpfsHandler {
		IpfsHandler::new(None.into(), None.into(), Arc::new(TestBlockChainClient::new()))
	}

	#[test]
	fn test_get_param() {
		let query = "foo=100&bar=200&qux=300";

		assert_eq!(get_param(query, "foo"), Some("100"));
		assert_eq!(get_param(query, "bar"), Some("200"));
		assert_eq!(get_param(query, "qux"), Some("300"));
		assert_eq!(get_param(query, "bar="), None);
		assert_eq!(get_param(query, "200"), None);
		assert_eq!(get_param("", "foo"), None);
		assert_eq!(get_param("foo", "foo"), None);
		assert_eq!(get_param("foo&bar", "foo"), None);
		assert_eq!(get_param("bar&foo", "foo"), None);
	}

	#[test]
	fn cid_route_block() {
		let handler = get_mocked_handler();

		// `eth-block` with Keccak-256
		let cid = "z43AaGF5tmkT9SEX6urrhwpEW5ZSaACY73Vw357ZXTsur2fR8BM";

		assert_eq!(Err(Error::BlockNotFound), handler.route_cid(cid));
	}

	#[test]
	fn cid_route_block_list() {
		let handler = get_mocked_handler();

		// `eth-block-list` with Keccak-256
		let cid = "z43c7o7FsNxqdLJW8Ucj19tuCALtnmUb2EkDptj4W6xSkFVTqWs";

		assert_eq!(Err(Error::BlockNotFound), handler.route_cid(cid));
	}

	#[test]
	fn cid_route_tx() {
		let handler = get_mocked_handler();

		// `eth-tx` with Keccak-256
		let cid = "z44VCrqbpbPcb8SUBc8Tba4EaKuoDz2grdEoQXx4TP7WYh9ZGBu";

		assert_eq!(Err(Error::TransactionNotFound), handler.route_cid(cid));
	}

	#[test]
	fn cid_route_state_trie() {
		let handler = get_mocked_handler();

		// `eth-state-trie` with Keccak-256
		let cid = "z45oqTS7kR2n2peRGJQ4VCJEeaG9sorqcCyfmznZPJM7FMdhQCT";

		assert_eq!(Err(Error::StateRootNotFound), handler.route_cid(&cid));
	}

	#[test]
	fn cid_route_contract_code() {
		let handler = get_mocked_handler();

		// `raw` with Keccak-256
		let cid = "zb34WAp1Q5fhtLGZ3w3jhnTWaNbVV5ZZvGq4vuJQzERj6Pu3H";

		assert_eq!(Err(Error::ContractNotFound), handler.route_cid(&cid));
	}

	#[test]
	fn cid_route_invalid_hash() {
		let handler = get_mocked_handler();

		// `eth-block` with SHA3-256 hash
		let cid = "z43Aa9gr1MM7TENJh4Em9d9Ttr7p3UcfyMpNei6WLVeCmSEPu8F";

		assert_eq!(Err(Error::UnsupportedHash), handler.route_cid(cid));
	}

	#[test]
	fn cid_route_invalid_codec() {
		let handler = get_mocked_handler();

		// `bitcoin-block` with Keccak-256
		let cid = "z4HFyHvb8CarYARyxz4cCcPaciduXd49TFPCKLhYmvNxf7Auvwu";

		assert_eq!(Err(Error::UnsupportedCid), handler.route_cid(&cid));
	}

	#[test]
	fn route_block() {
		let handler = get_mocked_handler();

		let out = handler.route("/api/v0/block/get", Some("arg=z43AaGF5tmkT9SEX6urrhwpEW5ZSaACY73Vw357ZXTsur2fR8BM"));

		assert_eq!(out, Out::NotFound("Block not found"));
	}

	#[test]
	fn route_block_missing_query() {
		let handler = get_mocked_handler();

		let out = handler.route("/api/v0/block/get", None);

		assert_eq!(out, Out::Bad("CID parsing failed"));
	}

	#[test]
	fn route_block_invalid_query() {
		let handler = get_mocked_handler();

		let out = handler.route("/api/v0/block/get", Some("arg=foobarz43AaGF5tmkT9SEX6urrhwpEW5ZSaACY73Vw357ZXTsur2fR8BM"));

		assert_eq!(out, Out::Bad("CID parsing failed"));
	}

	#[test]
	fn route_invalid_route() {
		let handler = get_mocked_handler();

		let out = handler.route("/foo/bar/baz", Some("arg=z43AaGF5tmkT9SEX6urrhwpEW5ZSaACY73Vw357ZXTsur2fR8BM"));

		assert_eq!(out, Out::NotFound("Route not found"));
	}
}

'''
'''--- runtime/primitives/Cargo.toml ---
[package]
name = "primitives"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
regex = "1"
bincode = { version = "1.0", features = ["i128"] }
bs58 = "0.2.0"
base64 = "0.10.0"
byteorder = "1.2"
exonum_sodiumoxide = "0.0.20"
futures = "0.1"
heapsize = "0.4"
lazy_static = "1.3"
serde = "1.0"
serde_derive = "1.0"
sha2 = "0.8.0"
serde_json = "1.0"
pairing = { git = "https://github.com/nearprotocol/pairing.git", rev = "f009a9f54c1c1149cea4ee3e6e58ed71d72bb2e9" }
rand = "0.6"
rand_xorshift = "0.1"
protobuf = "2.4"
jemallocator = "0.3.0"

near-protos = { path = "../protos" }

[dev-dependencies]
bencher = "0.1.5"
serde_json = "1.0"

[[bench]]
name = "bls"
harness = false

'''
'''--- runtime/primitives/benches/bls.rs ---
#[macro_use]
extern crate bencher;

use bencher::Bencher;

extern crate primitives;

use primitives::crypto::aggregate_signature::{BlsAggregatePublicKey, BlsAggregateSignature, BlsSecretKey};

fn bls_sign(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";

    bench.iter(|| {
        key.sign(message.as_bytes());
    });
}

fn bls_verify(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let public = key.get_public_key();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());

    bench.iter(|| {
        public.verify(message.as_bytes(), &signature);
    });
}

fn bls_aggregate_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let mut agg_sig = BlsAggregateSignature::new();

    bench.iter(|| {
        agg_sig.aggregate(&signature);
    });
}

fn bls_aggregate_pubkey(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let public = key.get_public_key();
    let mut agg_key = BlsAggregatePublicKey::new();

    bench.iter(|| {
        agg_key.aggregate(&public);
    });
}

/// Aggregate signatures, but keep them in affine coordinates at each step
fn bls_aggregate_signature_slow(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let mut signature = key.sign(message.as_bytes());

    bench.iter(|| {
        let mut agg_sig = BlsAggregateSignature::new();
        agg_sig.aggregate(&signature);
        agg_sig.aggregate(&signature);
        signature = agg_sig.get_signature();
    });
}

/// Aggregate pubkeys, but keep them in affine coordinates at each step
fn bls_aggregate_pubkey_slow(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let mut public = key.get_public_key();

    bench.iter(|| {
        let mut agg_key = BlsAggregatePublicKey::new();
        agg_key.aggregate(&public);
        agg_key.aggregate(&public);
        public = agg_key.get_key();
    });
}

fn bls_decompress_pubkey(bench: &mut Bencher) {
    let public = BlsSecretKey::generate().get_public_key();
    let compressed = public.compress();

    bench.iter(|| {
        compressed.decompress().unwrap();
    });
}

fn bls_decompress_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let compressed = signature.compress();

    bench.iter(|| {
        compressed.decode().unwrap();
    });
}

fn bls_decompress_pubkey_unchecked(bench: &mut Bencher) {
    let public = BlsSecretKey::generate().get_public_key();
    let compressed = public.compress();

    bench.iter(|| {
        compressed.decompress_unchecked();
    });
}

fn bls_decode_uncompressed_signature(bench: &mut Bencher) {
    let key = BlsSecretKey::generate();
    let message = "Hello, world!";
    let signature = key.sign(message.as_bytes());
    let encoded = signature.encode_uncompressed();

    bench.iter(|| {
        encoded.decode().ok();
    })
}

benchmark_group!(
    benches,
    bls_sign,
    bls_verify,
    bls_aggregate_signature,
    bls_aggregate_pubkey,
    bls_aggregate_signature_slow,
    bls_aggregate_pubkey_slow,
    bls_decompress_signature,
    bls_decompress_pubkey,
    bls_decompress_pubkey_unchecked,
    bls_decode_uncompressed_signature,
);
benchmark_main!(benches);

'''
'''--- runtime/primitives/src/account.rs ---
use std::fmt;

use crate::crypto::signature::PublicKey;
use crate::hash::CryptoHash;
use crate::logging;
use crate::types::{AccountId, Balance, BlockIndex, Nonce, StorageUsage};

use near_protos::access_key as access_key_proto;

use protobuf::well_known_types::BytesValue;
use protobuf::well_known_types::StringValue;
use protobuf::SingularPtrField;

/// Per account information stored in the state.
#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
pub struct Account {
    pub public_keys: Vec<PublicKey>,
    pub nonce: Nonce,
    // amount + staked is the total value of the account
    pub amount: Balance,
    pub staked: Balance,
    pub code_hash: CryptoHash,
    /// Storage used by the given account.
    pub storage_usage: StorageUsage,
    /// Last block index at which the storage was paid for.
    pub storage_paid_at: BlockIndex,
}

impl Account {
    pub fn new(public_keys: Vec<PublicKey>, amount: Balance, code_hash: CryptoHash) -> Self {
        Account {
            public_keys,
            nonce: 0,
            amount,
            staked: 0,
            code_hash,
            storage_usage: 0,
            storage_paid_at: 0,
        }
    }

    /// Try debiting the balance by the given amount.
    pub fn checked_sub(&mut self, amount: Balance) -> Result<(), String> {
        self.amount = self.amount.checked_sub(amount).ok_or_else(|| {
            format!(
                "Sender does not have enough balance {} for operation costing {}",
                self.amount, amount
            )
        })?;
        Ok(())
    }
}

/// Limited Access key to use owner's account with the fixed public_key.
/// Access Key is stored under the key of owner's `account_id` and the `public_key`.
#[derive(Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct AccessKey {
    /// Balance amount on this Access Key. Can be used to pay for the transactions.
    pub amount: Balance,
    /// Owner of the balance of this Access Key. None means the account owner.
    pub balance_owner: Option<AccountId>,
    /// Contract ID that can be called with this Access Key. None means the account owner.
    /// Access key only allows to call given contract_id.
    pub contract_id: Option<AccountId>,
    /// The only method name that can be called with this Access Key. None means any method name.
    pub method_name: Option<Vec<u8>>,
}

impl fmt::Debug for AccessKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AccessKey")
            .field("amount", &self.amount)
            .field("balance_owner", &self.balance_owner)
            .field("contract_id", &self.contract_id)
            .field("method_name", &self.method_name.as_ref().map(|v| logging::pretty_utf8(&v)))
            .finish()
    }
}

impl From<access_key_proto::AccessKey> for AccessKey {
    fn from(access_key: access_key_proto::AccessKey) -> Self {
        AccessKey {
            amount: access_key.amount,
            balance_owner: access_key.balance_owner.into_option().map(|s| s.value),
            contract_id: access_key.contract_id.into_option().map(|s| s.value),
            method_name: access_key.method_name.into_option().map(|s| s.value),
        }
    }
}

impl From<AccessKey> for access_key_proto::AccessKey {
    fn from(access_key: AccessKey) -> access_key_proto::AccessKey {
        access_key_proto::AccessKey {
            amount: access_key.amount,
            balance_owner: SingularPtrField::from_option(access_key.balance_owner.map(|v| {
                let mut res = StringValue::new();
                res.set_value(v);
                res
            })),
            contract_id: SingularPtrField::from_option(access_key.contract_id.map(|v| {
                let mut res = StringValue::new();
                res.set_value(v);
                res
            })),
            method_name: SingularPtrField::from_option(access_key.method_name.map(|v| {
                let mut res = BytesValue::new();
                res.set_value(v);
                res
            })),
            ..Default::default()
        }
    }
}

'''
'''--- runtime/primitives/src/beacon.rs ---
use crate::block_traits::{SignedBlock, SignedHeader};
use crate::crypto::group_signature::GroupSignature;
use crate::hash::{hash_struct, CryptoHash};
use crate::types::{AuthorityStake, PartialSignature};
use crate::utils::{proto_to_result, proto_to_type};
use near_protos::chain as chain_proto;
use protobuf::{RepeatedField, SingularPtrField};
use std::borrow::Borrow;
use std::convert::{TryFrom, TryInto};
use std::hash::{Hash, Hasher};
use std::iter::FromIterator;

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Eq)]
pub struct BeaconBlockHeader {
    /// Parent hash.
    pub parent_hash: CryptoHash,
    /// Block index.
    pub index: u64,
    /// Authority proposals.
    pub authority_proposal: Vec<AuthorityStake>,
    /// Hash of the shard block.
    pub shard_block_hash: CryptoHash,
}

impl TryFrom<chain_proto::BeaconBlockHeader> for BeaconBlockHeader {
    type Error = String;

    fn try_from(proto: chain_proto::BeaconBlockHeader) -> Result<Self, Self::Error> {
        let parent_hash = proto.parent_hash.try_into()?;
        let index = proto.index;
        let shard_block_hash = proto.shard_block_hash.try_into()?;
        let authority_proposal = proto
            .authority_proposal
            .into_iter()
            .map(TryInto::try_into)
            .collect::<Result<Vec<_>, _>>()?;
        Ok(BeaconBlockHeader { parent_hash, index, authority_proposal, shard_block_hash })
    }
}

impl From<BeaconBlockHeader> for chain_proto::BeaconBlockHeader {
    fn from(header: BeaconBlockHeader) -> Self {
        chain_proto::BeaconBlockHeader {
            parent_hash: header.parent_hash.into(),
            index: header.index,
            authority_proposal: RepeatedField::from_iter(
                header.authority_proposal.into_iter().map(std::convert::Into::into),
            ),
            shard_block_hash: header.shard_block_hash.into(),
            ..Default::default()
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Eq)]
pub struct SignedBeaconBlockHeader {
    pub body: BeaconBlockHeader,
    pub hash: CryptoHash,
    pub signature: GroupSignature,
}

impl TryFrom<chain_proto::SignedBeaconBlockHeader> for SignedBeaconBlockHeader {
    type Error = String;

    fn try_from(proto: chain_proto::SignedBeaconBlockHeader) -> Result<Self, Self::Error> {
        let hash = proto.hash.try_into()?;
        let body = proto_to_type(proto.body)?;
        let signature = proto_to_type(proto.signature)?;
        Ok(SignedBeaconBlockHeader { body, hash, signature })
    }
}

impl From<SignedBeaconBlockHeader> for chain_proto::SignedBeaconBlockHeader {
    fn from(header: SignedBeaconBlockHeader) -> Self {
        chain_proto::SignedBeaconBlockHeader {
            body: SingularPtrField::some(header.body.into()),
            hash: header.hash.into(),
            signature: SingularPtrField::some(header.signature.into()),
            ..Default::default()
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Eq)]
pub struct BeaconBlock {
    pub header: BeaconBlockHeader,
}

impl TryFrom<chain_proto::BeaconBlock> for BeaconBlock {
    type Error = String;

    fn try_from(proto: chain_proto::BeaconBlock) -> Result<Self, Self::Error> {
        proto_to_result(proto.header)
            .and_then(TryInto::try_into)
            .map(|header| BeaconBlock { header })
    }
}

impl From<BeaconBlock> for chain_proto::BeaconBlock {
    fn from(block: BeaconBlock) -> Self {
        chain_proto::BeaconBlock {
            header: SingularPtrField::some(block.header.into()),
            ..Default::default()
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SignedBeaconBlock {
    pub body: BeaconBlock,
    pub hash: CryptoHash,
    pub signature: GroupSignature,
}

impl TryFrom<chain_proto::SignedBeaconBlock> for SignedBeaconBlock {
    type Error = String;

    fn try_from(proto: chain_proto::SignedBeaconBlock) -> Result<Self, Self::Error> {
        let body = proto_to_type(proto.body)?;
        let signature = proto_to_type(proto.signature)?;
        let hash = proto.hash.try_into()?;
        Ok(SignedBeaconBlock { body, hash, signature })
    }
}

impl From<SignedBeaconBlock> for chain_proto::SignedBeaconBlock {
    fn from(block: SignedBeaconBlock) -> Self {
        chain_proto::SignedBeaconBlock {
            body: SingularPtrField::some(block.body.into()),
            hash: block.hash.into(),
            signature: SingularPtrField::some(block.signature.into()),
            ..Default::default()
        }
    }
}

impl Borrow<CryptoHash> for SignedBeaconBlock {
    fn borrow(&self) -> &CryptoHash {
        &self.hash
    }
}

impl Hash for SignedBeaconBlock {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl PartialEq for SignedBeaconBlock {
    fn eq(&self, other: &SignedBeaconBlock) -> bool {
        self.hash == other.hash
    }
}

impl Eq for SignedBeaconBlock {}

impl SignedHeader for SignedBeaconBlockHeader {
    #[inline]
    fn block_hash(&self) -> CryptoHash {
        self.hash
    }
    #[inline]
    fn index(&self) -> u64 {
        self.body.index
    }
    #[inline]
    fn parent_hash(&self) -> CryptoHash {
        self.body.parent_hash
    }
}

impl SignedBeaconBlock {
    pub fn new(
        index: u64,
        parent_hash: CryptoHash,
        authority_proposal: Vec<AuthorityStake>,
        shard_block_hash: CryptoHash,
    ) -> SignedBeaconBlock {
        let header = BeaconBlockHeader { index, parent_hash, authority_proposal, shard_block_hash };
        let hash = hash_struct(&header);
        SignedBeaconBlock {
            body: BeaconBlock { header },
            hash,
            signature: GroupSignature::default(),
        }
    }

    pub fn genesis(shard_block_hash: CryptoHash) -> SignedBeaconBlock {
        SignedBeaconBlock::new(0, CryptoHash::default(), vec![], shard_block_hash)
    }
}

impl SignedBlock for SignedBeaconBlock {
    type SignedHeader = SignedBeaconBlockHeader;

    fn header(&self) -> Self::SignedHeader {
        SignedBeaconBlockHeader {
            body: self.body.header.clone(),
            hash: self.hash,
            signature: self.signature.clone(),
        }
    }

    #[inline]
    fn index(&self) -> u64 {
        self.body.header.index
    }

    #[inline]
    fn block_hash(&self) -> CryptoHash {
        self.hash
    }

    fn add_signature(&mut self, signature: &PartialSignature, authority_id: usize) {
        self.signature.add_signature(signature, authority_id);
    }

    fn weight(&self) -> u128 {
        // TODO(#279): sum stakes instead of counting them
        self.signature.authority_count() as u128
    }
}

'''
'''--- runtime/primitives/src/block_traits.rs ---
use std::fmt::Debug;

use serde::{de::DeserializeOwned, Serialize};

use crate::crypto::signer::BLSSigner;
use crate::hash::CryptoHash;
use crate::serialize::Decode;
use crate::serialize::Encode;
use crate::types::PartialSignature;

/// Trait that abstracts ``Header"
pub trait SignedHeader:
    Debug + Clone + Encode + Decode + Send + Sync + Eq + Serialize + DeserializeOwned + 'static
{
    /// Returns hash of the block body.
    fn block_hash(&self) -> CryptoHash;

    /// Returns block index.
    fn index(&self) -> u64;

    /// Returns hash of parent block.
    fn parent_hash(&self) -> CryptoHash;
}

/// Trait that abstracts a ``Block", Is used for both beacon-chain blocks
/// and shard-chain blocks.
pub trait SignedBlock:
    Debug + Clone + Encode + Decode + Send + Sync + Eq + Serialize + DeserializeOwned + 'static
{
    type SignedHeader: SignedHeader;

    /// Returns signed header for given block.
    fn header(&self) -> Self::SignedHeader;

    /// Returns index of given block.
    fn index(&self) -> u64;

    /// Returns hash of the block body.
    fn block_hash(&self) -> CryptoHash;

    /// Signs this block with given signer and returns part of multi signature.
    fn sign(&self, signer: &BLSSigner) -> PartialSignature {
        signer.bls_sign(self.block_hash().as_ref())
    }

    /// Add signature to multi sign.
    fn add_signature(&mut self, signature: &PartialSignature, authority_id: usize);

    /// Returns stake weight of given block signers.
    fn weight(&self) -> u128;
}

'''
'''--- runtime/primitives/src/chain.rs ---
use std::borrow::Borrow;
use std::convert::{TryFrom, TryInto};
use std::hash::{Hash, Hasher};
use std::iter::FromIterator;

use serde_derive::{Deserialize, Serialize};

use crate::block_traits::{SignedBlock, SignedHeader};
use crate::consensus::Payload;
use crate::crypto::group_signature::GroupSignature;
use crate::hash::{hash_struct, CryptoHash};
use crate::merkle::{Direction, MerklePath};
use crate::transaction::{ReceiptTransaction, SignedTransaction};
use crate::types::PartialSignature;
use crate::types::{AuthorityId, BlockIndex, MerkleHash, ShardId};
use crate::utils::proto_to_type;
use near_protos::chain as chain_proto;
use near_protos::network as network_proto;
use near_protos::types as types_proto;
use protobuf::{RepeatedField, SingularPtrField};

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct ShardBlockHeader {
    pub parent_hash: CryptoHash,
    pub shard_id: ShardId,
    pub index: BlockIndex,
    pub merkle_root_state: MerkleHash,
    /// If there are no receipts generated in this block, the root is hash(0)
    pub receipt_merkle_root: MerkleHash,
}

impl TryFrom<chain_proto::ShardBlockHeader> for ShardBlockHeader {
    type Error = String;

    fn try_from(proto: chain_proto::ShardBlockHeader) -> Result<Self, Self::Error> {
        Ok(ShardBlockHeader {
            parent_hash: proto.parent_hash.try_into()?,
            shard_id: proto.shard_id,
            index: proto.block_index,
            merkle_root_state: proto.merkle_root_state.try_into()?,
            receipt_merkle_root: proto.receipt_merkle_root.try_into()?,
        })
    }
}

impl From<ShardBlockHeader> for chain_proto::ShardBlockHeader {
    fn from(header: ShardBlockHeader) -> Self {
        chain_proto::ShardBlockHeader {
            parent_hash: header.parent_hash.into(),
            shard_id: header.shard_id,
            block_index: header.index,
            merkle_root_state: header.merkle_root_state.into(),
            receipt_merkle_root: header.receipt_merkle_root.into(),
            ..Default::default()
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct SignedShardBlockHeader {
    pub body: ShardBlockHeader,
    pub hash: CryptoHash,
    pub signature: GroupSignature,
}

impl TryFrom<chain_proto::SignedShardBlockHeader> for SignedShardBlockHeader {
    type Error = String;

    fn try_from(proto: chain_proto::SignedShardBlockHeader) -> Result<Self, Self::Error> {
        let body = proto_to_type(proto.body)?;
        let signature = proto_to_type(proto.signature)?;
        let hash = proto.hash.try_into()?;
        Ok(SignedShardBlockHeader { body, hash, signature })
    }
}

impl From<SignedShardBlockHeader> for chain_proto::SignedShardBlockHeader {
    fn from(header: SignedShardBlockHeader) -> Self {
        chain_proto::SignedShardBlockHeader {
            body: SingularPtrField::some(header.body.into()),
            hash: header.hash.into(),
            signature: SingularPtrField::some(header.signature.into()),
            ..Default::default()
        }
    }
}

impl SignedShardBlockHeader {
    #[inline]
    pub fn shard_id(&self) -> ShardId {
        self.body.shard_id
    }

    #[inline]
    pub fn merkle_root_state(&self) -> MerkleHash {
        self.body.merkle_root_state
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct ShardBlock {
    pub header: ShardBlockHeader,
    pub transactions: Vec<SignedTransaction>,
    pub receipts: Vec<ReceiptBlock>,
}

impl TryFrom<chain_proto::ShardBlock> for ShardBlock {
    type Error = String;

    fn try_from(proto: chain_proto::ShardBlock) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let header = proto_to_type(proto.header)?;
        Ok(ShardBlock { header, transactions, receipts })
    }
}

impl From<ShardBlock> for chain_proto::ShardBlock {
    fn from(block: ShardBlock) -> Self {
        chain_proto::ShardBlock {
            header: SingularPtrField::some(block.header.into()),
            transactions: block.transactions.into_iter().map(std::convert::Into::into).collect(),
            receipts: block.receipts.into_iter().map(std::convert::Into::into).collect(),
            ..Default::default()
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SignedShardBlock {
    pub body: ShardBlock,
    pub hash: CryptoHash,
    pub signature: GroupSignature,
}

impl TryFrom<chain_proto::SignedShardBlock> for SignedShardBlock {
    type Error = String;

    fn try_from(proto: chain_proto::SignedShardBlock) -> Result<Self, Self::Error> {
        let body = proto_to_type(proto.body)?;
        let signature = proto_to_type(proto.signature)?;
        let hash = proto.hash.try_into()?;
        Ok(SignedShardBlock { body, hash, signature })
    }
}

impl From<SignedShardBlock> for chain_proto::SignedShardBlock {
    fn from(block: SignedShardBlock) -> Self {
        chain_proto::SignedShardBlock {
            body: SingularPtrField::some(block.body.into()),
            hash: block.hash.into(),
            signature: SingularPtrField::some(block.signature.into()),
            ..Default::default()
        }
    }
}

impl Borrow<CryptoHash> for SignedShardBlock {
    fn borrow(&self) -> &CryptoHash {
        &self.hash
    }
}

impl Hash for SignedShardBlock {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state);
    }
}

impl PartialEq for SignedShardBlock {
    fn eq(&self, other: &SignedShardBlock) -> bool {
        self.hash == other.hash
    }
}

impl Eq for SignedShardBlock {}

#[derive(Debug, Clone, Eq, Serialize, Deserialize)]
pub struct ReceiptBlock {
    pub header: SignedShardBlockHeader,
    pub path: MerklePath,
    // receipts should not be empty
    pub receipts: Vec<ReceiptTransaction>,
    /// The shard that the receipt block goes to.
    pub shard_id: ShardId,
    // hash is the hash of receipts. It is
    // sufficient to uniquely identify the
    // receipt block because of the uniqueness
    // of nonce in receipts
    hash: CryptoHash,
}

impl TryFrom<chain_proto::ReceiptBlock> for ReceiptBlock {
    type Error = String;

    fn try_from(proto: chain_proto::ReceiptBlock) -> Result<Self, Self::Error> {
        let path = proto
            .path
            .into_iter()
            .map(|node| {
                let direction = if node.direction { Direction::Left } else { Direction::Right };
                Ok::<_, String>((node.hash.try_into()?, direction))
            })
            .collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let header = proto_to_type(proto.header)?;
        Ok(ReceiptBlock {
            header,
            path,
            receipts,
            shard_id: proto.shard_id,
            hash: proto.hash.try_into()?,
        })
    }
}

impl From<ReceiptBlock> for chain_proto::ReceiptBlock {
    fn from(receipt: ReceiptBlock) -> Self {
        let path = RepeatedField::from_iter(receipt.path.into_iter().map(|(hash, dir)| {
            types_proto::MerkleNode {
                hash: hash.into(),
                direction: dir == Direction::Left,
                ..Default::default()
            }
        }));
        chain_proto::ReceiptBlock {
            header: SingularPtrField::some(receipt.header.into()),
            path,
            receipts: RepeatedField::from_iter(
                receipt.receipts.into_iter().map(std::convert::Into::into),
            ),
            shard_id: receipt.shard_id,
            hash: receipt.hash.into(),
            ..Default::default()
        }
    }
}

impl PartialEq for ReceiptBlock {
    fn eq(&self, other: &ReceiptBlock) -> bool {
        self.hash == other.hash
    }
}

impl Hash for ReceiptBlock {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl Borrow<CryptoHash> for ReceiptBlock {
    fn borrow(&self) -> &CryptoHash {
        &self.hash
    }
}

impl ReceiptBlock {
    pub fn new(
        header: SignedShardBlockHeader,
        path: MerklePath,
        receipts: Vec<ReceiptTransaction>,
        shard_id: ShardId,
    ) -> Self {
        let hash = hash_struct(&receipts);
        ReceiptBlock { header, path, receipts, shard_id, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }
}

impl SignedHeader for SignedShardBlockHeader {
    #[inline]
    fn block_hash(&self) -> CryptoHash {
        self.hash
    }
    #[inline]
    fn index(&self) -> u64 {
        self.body.index
    }
    #[inline]
    fn parent_hash(&self) -> CryptoHash {
        self.body.parent_hash
    }
}

impl SignedShardBlock {
    pub fn new(
        shard_id: ShardId,
        index: u64,
        parent_hash: CryptoHash,
        merkle_root_state: MerkleHash,
        transactions: Vec<SignedTransaction>,
        receipts: Vec<ReceiptBlock>,
        receipt_merkle_root: MerkleHash,
    ) -> Self {
        let header = ShardBlockHeader {
            shard_id,
            index,
            parent_hash,
            merkle_root_state,
            receipt_merkle_root,
        };
        let hash = hash_struct(&header);
        SignedShardBlock {
            body: ShardBlock { header, transactions, receipts },
            hash,
            signature: GroupSignature::default(),
        }
    }

    pub fn genesis(merkle_root_state: MerkleHash) -> SignedShardBlock {
        SignedShardBlock::new(
            0,
            0,
            CryptoHash::default(),
            merkle_root_state,
            vec![],
            vec![],
            CryptoHash::default(),
        )
    }

    #[inline]
    pub fn merkle_root_state(&self) -> MerkleHash {
        self.body.header.merkle_root_state
    }

    #[inline]
    pub fn shard_id(&self) -> ShardId {
        self.body.header.shard_id
    }
}

impl SignedBlock for SignedShardBlock {
    type SignedHeader = SignedShardBlockHeader;

    fn header(&self) -> Self::SignedHeader {
        SignedShardBlockHeader {
            body: self.body.header.clone(),
            hash: self.hash,
            signature: self.signature.clone(),
        }
    }

    #[inline]
    fn index(&self) -> u64 {
        self.body.header.index
    }

    #[inline]
    fn block_hash(&self) -> CryptoHash {
        self.hash
    }

    fn add_signature(&mut self, signature: &PartialSignature, authority_id: usize) {
        self.signature.add_signature(signature, authority_id);
    }

    fn weight(&self) -> u128 {
        1
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct ChainPayload {
    pub transactions: Vec<SignedTransaction>,
    pub receipts: Vec<ReceiptBlock>,
    hash: CryptoHash,
}

impl TryFrom<chain_proto::ChainPayload> for ChainPayload {
    type Error = String;

    fn try_from(proto: chain_proto::ChainPayload) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(ChainPayload { transactions, receipts, hash: proto.hash.try_into()? })
    }
}

impl From<ChainPayload> for chain_proto::ChainPayload {
    fn from(payload: ChainPayload) -> Self {
        chain_proto::ChainPayload {
            transactions: RepeatedField::from_iter(
                payload.transactions.into_iter().map(std::convert::Into::into),
            ),
            receipts: RepeatedField::from_iter(
                payload.receipts.into_iter().map(std::convert::Into::into),
            ),
            hash: payload.hash.into(),
            ..Default::default()
        }
    }
}

impl ChainPayload {
    pub fn new(transactions: Vec<SignedTransaction>, receipts: Vec<ReceiptBlock>) -> Self {
        let hash = hash_struct(&(&transactions, &receipts));
        ChainPayload { transactions, receipts, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }
}

impl Hash for ChainPayload {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl PartialEq for ChainPayload {
    fn eq(&self, other: &ChainPayload) -> bool {
        self.hash == other.hash
    }
}

impl Borrow<CryptoHash> for ChainPayload {
    fn borrow(&self) -> &CryptoHash {
        &self.hash
    }
}

impl Eq for ChainPayload {}

impl Payload for ChainPayload {
    fn verify(&self) -> Result<(), &'static str> {
        Ok(())
    }

    fn union_update(&mut self, mut other: Self) {
        self.transactions.extend(other.transactions.drain(..));
        self.receipts.extend(other.receipts.drain(..))
    }

    fn is_empty(&self) -> bool {
        self.transactions.is_empty() && self.receipts.is_empty()
    }

    fn new() -> Self {
        Self { transactions: vec![], receipts: vec![], hash: CryptoHash::default() }
    }
}

#[derive(PartialEq, Eq, Debug, Serialize, Deserialize, Clone)]
pub struct ChainState {
    pub genesis_hash: CryptoHash,
    pub last_index: u64,
}

impl TryFrom<chain_proto::ChainState> for ChainState {
    type Error = String;

    fn try_from(proto: chain_proto::ChainState) -> Result<Self, Self::Error> {
        Ok(ChainState {
            genesis_hash: proto.genesis_hash.try_into()?,
            last_index: proto.last_index,
        })
    }
}

impl From<ChainState> for chain_proto::ChainState {
    fn from(chain_state: ChainState) -> chain_proto::ChainState {
        chain_proto::ChainState {
            genesis_hash: chain_state.genesis_hash.into(),
            last_index: chain_state.last_index,
            ..Default::default()
        }
    }
}

/// request missing parts of the payload snapshot which has hash snapshot_hash
#[derive(PartialEq, Eq, Debug, Serialize, Deserialize, Clone)]
pub struct MissingPayloadRequest {
    pub transactions: Vec<CryptoHash>,
    pub receipts: Vec<CryptoHash>,
    pub snapshot_hash: CryptoHash,
}

impl TryFrom<network_proto::MissingPayloadRequest> for MissingPayloadRequest {
    type Error = String;

    fn try_from(proto: network_proto::MissingPayloadRequest) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(MissingPayloadRequest {
            transactions,
            receipts,
            snapshot_hash: proto.snapshot_hash.try_into()?,
        })
    }
}

impl From<MissingPayloadRequest> for network_proto::MissingPayloadRequest {
    fn from(response: MissingPayloadRequest) -> Self {
        let transactions = RepeatedField::from_iter(
            response.transactions.into_iter().map(std::convert::Into::into),
        );
        let receipts =
            RepeatedField::from_iter(response.receipts.into_iter().map(std::convert::Into::into));
        network_proto::MissingPayloadRequest {
            transactions,
            receipts,
            snapshot_hash: response.snapshot_hash.into(),
            ..Default::default()
        }
    }
}

/// response to missing parts of the payload snapshot which has hash snapshot_hash
/// it is basically a ChainPayload except that snapshot_hash is not the hash of the payload
#[derive(PartialEq, Eq, Debug, Serialize, Deserialize, Clone)]
pub struct MissingPayloadResponse {
    pub transactions: Vec<SignedTransaction>,
    pub receipts: Vec<ReceiptBlock>,
    pub snapshot_hash: CryptoHash,
}

impl TryFrom<network_proto::MissingPayloadResponse> for MissingPayloadResponse {
    type Error = String;

    fn try_from(proto: network_proto::MissingPayloadResponse) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(MissingPayloadResponse {
            transactions,
            receipts,
            snapshot_hash: proto.snapshot_hash.try_into()?,
        })
    }
}

impl From<MissingPayloadResponse> for network_proto::MissingPayloadResponse {
    fn from(response: MissingPayloadResponse) -> Self {
        let transactions = RepeatedField::from_iter(
            response.transactions.into_iter().map(std::convert::Into::into),
        );
        let receipts =
            RepeatedField::from_iter(response.receipts.into_iter().map(std::convert::Into::into));
        network_proto::MissingPayloadResponse {
            transactions,
            receipts,
            snapshot_hash: response.snapshot_hash.into(),
            ..Default::default()
        }
    }
}

impl MissingPayloadResponse {
    pub fn is_empty(&self) -> bool {
        self.transactions.is_empty() && self.receipts.is_empty()
    }
}

pub enum PayloadRequest {
    General(AuthorityId, MissingPayloadRequest),
    BlockProposal(AuthorityId, CryptoHash),
}

pub enum PayloadResponse {
    General(AuthorityId, MissingPayloadResponse),
    BlockProposal(AuthorityId, Snapshot),
}

/// snapshot of payload. Stores only necessary information for retrieving
/// the actual payload.
#[derive(Default, Clone, Debug, Serialize, Deserialize)]
pub struct Snapshot {
    pub transactions: Vec<CryptoHash>,
    pub receipts: Vec<CryptoHash>,
    hash: CryptoHash,
}

impl TryFrom<network_proto::Snapshot> for Snapshot {
    type Error = String;

    fn try_from(proto: network_proto::Snapshot) -> Result<Self, Self::Error> {
        let transactions =
            proto.transactions.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let receipts =
            proto.receipts.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        Ok(Snapshot { transactions, receipts, hash: proto.hash.try_into()? })
    }
}

impl From<Snapshot> for network_proto::Snapshot {
    fn from(snapshot: Snapshot) -> Self {
        let transactions = RepeatedField::from_iter(
            snapshot.transactions.into_iter().map(std::convert::Into::into),
        );
        let receipts =
            RepeatedField::from_iter(snapshot.receipts.into_iter().map(std::convert::Into::into));
        network_proto::Snapshot {
            transactions,
            receipts,
            hash: snapshot.hash.into(),
            ..Default::default()
        }
    }
}

impl PartialEq for Snapshot {
    fn eq(&self, other: &Snapshot) -> bool {
        self.hash == other.hash
    }
}

impl Eq for Snapshot {}

impl Hash for Snapshot {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl Borrow<CryptoHash> for Snapshot {
    fn borrow(&self) -> &CryptoHash {
        &self.hash
    }
}

impl Snapshot {
    pub fn new(transactions: Vec<CryptoHash>, receipts: Vec<CryptoHash>) -> Self {
        let hash = hash_struct(&(&transactions, &receipts));
        Snapshot { transactions, receipts, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }

    pub fn is_empty(&self) -> bool {
        self.transactions.is_empty() && self.receipts.is_empty()
    }

    pub fn clear(&mut self) {
        self.transactions.clear();
        self.receipts.clear();
        self.hash = CryptoHash::default();
    }
}

'''
'''--- runtime/primitives/src/consensus.rs ---
use std::fmt::Debug;
use std::hash::Hash;

pub use crate::serialize::{Decode, Encode};
use crate::hash::CryptoHash;
use crate::crypto::signature::bs58_serializer;
use crate::types::{AuthorityId, PartialSignature};

pub type GenericResult = Result<(), &'static str>;

/// General payload that can be stored on TxFlow. Should either not have references,
/// or the references should live for static lifetime.
pub trait Payload: Clone + Send + Hash + Debug + Encode + Decode + 'static {
    fn verify(&self) -> GenericResult;
    // Merge content from another payload into this one.
    fn union_update(&mut self, other: Self);
    fn is_empty(&self) -> bool;
    // Creates empty payload.
    fn new() -> Self;
}

/// Partial BLS for the beacon and shard blocks.
#[derive(PartialEq, Debug, Serialize, Deserialize, Clone)]
#[allow(clippy::large_enum_variant)]
pub enum JointBlockBLS {
    Request {
        sender_id: AuthorityId,
        receiver_id: AuthorityId,
        // TODO: consider replacing beacon_hash / shard_hash with block_index.
        beacon_hash: CryptoHash,
        shard_hash: CryptoHash,
    },
    General {
        sender_id: AuthorityId,
        receiver_id: AuthorityId,
        beacon_hash: CryptoHash,
        shard_hash: CryptoHash,
        #[serde(with = "bs58_serializer")]
        beacon_sig: PartialSignature,
        #[serde(with = "bs58_serializer")]
        shard_sig: PartialSignature,
    },
}

'''
'''--- runtime/primitives/src/crypto/aggregate_signature.rs ---
use crate::traits::{Base58Encoded, ToBytes};
use crate::types::ReadableBlsPublicKey;
use bs58;
use pairing::{
    CurveAffine, CurveProjective, EncodedPoint, Engine, Field, GroupDecodingError, PrimeField,
    PrimeFieldRepr, Rand,
};
use rand::rngs::OsRng;
use rand::Rng;
use std::convert::TryFrom;
use std::error::Error;
use std::fmt;
use std::io::Cursor;

const DOMAIN_SIGNATURE: &[u8] = b"_s";
const DOMAIN_PROOF_OF_POSSESSION: &[u8] = b"_p";

pub fn get_bls_key_pair() -> (BlsPublicKey, BlsSecretKey) {
    let secret_key = BlsSecretKey::generate();
    let public_key = secret_key.get_public_key();
    (public_key, secret_key)
}

#[derive(Clone, Debug)]
pub struct SecretKey<E: Engine> {
    scalar: E::Fr,
}

#[derive(Clone)]
pub struct PublicKey<E: Engine> {
    // G1 is the small-and-fast group.  G2 is the big-and-slow group.  Either one can be used for
    // public keys, and the other for signatures.  Since signature aggregation only needs to be
    // performed by provers, but pubkey aggregation needs to be done by verifiers, we choose the
    // small-and-fast group for public keys.
    point: E::G1Affine,
}

#[derive(Clone, Debug)]
pub struct Signature<E: Engine> {
    // A point on the G2 curve, but not necessarily in the correct G2 subgroup.
    point: E::G2Affine,
}

// TODO: it will usually be desirable to store pubkeys and signatures in compressed form, even in
// memory.  The compressed representations are half the size.
#[derive(Clone)]
pub struct CompressedPublicKey<E: Engine>(<E::G1Affine as CurveAffine>::Compressed);

#[derive(Clone)]
pub struct CompressedSignature<E: Engine>(<E::G2Affine as CurveAffine>::Compressed);

// For those times when time is more important than space, UncompressedSignature is 192 bytes, twice
// as large as CompressedSignature but much faster (about 250x) to decode.
#[derive(Clone)]
pub struct UncompressedSignature<E: Engine>(<E::G2Affine as CurveAffine>::Uncompressed);

impl<E: Engine> SecretKey<E> {
    /// Generate a new secret key from the OS rng.  Panics if OS is unable to provide randomness
    pub fn generate() -> Self {
        let mut rng = OsRng::new().expect("Unable to generate random numbers");
        Self::generate_from_rng(&mut rng)
    }

    pub fn generate_from_rng<R: Rng>(csprng: &mut R) -> Self {
        SecretKey { scalar: E::Fr::rand(csprng) }
    }

    pub fn empty() -> Self {
        SecretKey { scalar: E::Fr::zero() }
    }

    pub fn get_public_key(&self) -> PublicKey<E> {
        PublicKey { point: E::G1Affine::one().mul(self.scalar).into_affine() }
    }

    pub fn sign(&self, message: &[u8]) -> Signature<E> {
        self.sign_domain(message, DOMAIN_SIGNATURE)
    }

    pub fn get_proof_of_possession(&self) -> Signature<E> {
        let message = self.get_public_key().compress();
        self.sign_domain(message.as_ref(), DOMAIN_PROOF_OF_POSSESSION)
    }

    fn sign_domain(&self, message: &[u8], domain: &[u8]) -> Signature<E> {
        // TODO: it would be really nice if CurveProjective::hash took a pair of arguments instead
        // of just one.  The copy here is silly and avoidable.  It's here because we require domain
        // separation for the proof-of-possession.  Simply signing your own public key is not
        // sufficient.  See https://rist.tech.cornell.edu/papers/pkreg.pdf
        let padded_message = [message, domain].concat();
        self.sign_internal(padded_message.as_ref())
    }

    fn sign_internal(&self, message: &[u8]) -> Signature<E> {
        let h = E::G2::hash(message).into_affine();
        Signature { point: h.mul(self.scalar).into_affine() }
    }
}

impl<E: Engine> PublicKey<E> {
    pub fn empty() -> Self {
        PublicKey { point: E::G1Affine::zero() }
    }

    pub fn is_empty(&self) -> bool {
        self.point == E::G1Affine::zero()
    }

    pub fn compress(&self) -> CompressedPublicKey<E> {
        CompressedPublicKey(self.point.into_compressed())
    }

    pub fn to_readable(&self) -> ReadableBlsPublicKey {
        ReadableBlsPublicKey(self.to_string())
    }

    pub fn verify(&self, message: &[u8], signature: &Signature<E>) -> bool {
        self.verify_domain(message, DOMAIN_SIGNATURE, signature)
    }

    pub fn verify_proof_of_possession(&self, signature: &Signature<E>) -> bool {
        let message = self.compress();
        self.verify_domain(message.as_ref(), DOMAIN_PROOF_OF_POSSESSION, signature)
    }

    fn verify_domain(&self, message: &[u8], domain: &[u8], signature: &Signature<E>) -> bool {
        let padded_message = [message, domain].concat();
        self.verify_internal(padded_message.as_ref(), signature)
    }

    fn verify_internal(&self, message: &[u8], signature: &Signature<E>) -> bool {
        if !signature.point.is_in_correct_subgroup_assuming_on_curve() {
            return false;
        }
        let h = E::G2::hash(message).into_affine();
        let lhs = E::pairing(E::G1Affine::one(), signature.point);
        let rhs = E::pairing(self.point, h);
        lhs == rhs
    }
}

impl<E: Engine> fmt::Debug for PublicKey<E> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", bs58::encode(self.compress().as_ref()).into_string())
    }
}

impl<E: Engine> fmt::Display for PublicKey<E> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", bs58::encode(self.compress().as_ref()).into_string())
    }
}

// Note: deriving PartialEq and Eq doesn't work
impl<E: Engine> PartialEq for PublicKey<E> {
    fn eq(&self, other: &PublicKey<E>) -> bool {
        self.point == other.point
    }
}

impl<E: Engine> Eq for PublicKey<E> {}

impl<E: Engine> std::hash::Hash for PublicKey<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        state.write(&self.to_bytes());
    }
}

impl<E: Engine> Signature<E> {
    pub fn compress(&self) -> CompressedSignature<E> {
        CompressedSignature(self.point.into_compressed())
    }

    pub fn encode_uncompressed(&self) -> UncompressedSignature<E> {
        UncompressedSignature(self.point.into_uncompressed())
    }

    pub fn empty() -> Self {
        Signature { point: E::G2Affine::zero() }
    }
}

// Note: deriving PartialEq and Eq doesn't work
impl<E: Engine> PartialEq for Signature<E> {
    fn eq(&self, other: &Signature<E>) -> bool {
        self.point == other.point
    }
}

impl<E: Engine> Eq for Signature<E> {}

impl<E: Engine> std::hash::Hash for Signature<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        self.compress().as_ref().hash(state);
    }
}

impl<E: Engine> Default for Signature<E> {
    fn default() -> Self {
        Self::empty()
    }
}

impl<E: Engine> ToBytes for SecretKey<E> {
    fn to_bytes(&self) -> Vec<u8> {
        let repr = self.scalar.into_repr();
        let mut res = Vec::new();
        res.resize(repr.num_bits() as usize / 8, 0);
        let buf = Cursor::new(&mut res);
        repr.write_be(buf).unwrap();
        res
    }
}

impl<E: Engine> TryFrom<&[u8]> for SecretKey<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let mut repr: <E::Fr as PrimeField>::Repr = Default::default();
        let buf = Cursor::new(v);
        repr.read_be(buf)?;
        let scalar = <E::Fr as PrimeField>::from_repr(repr)?;
        Ok(Self { scalar })
    }
}

// `Eq`, `PartialEq`, and `Hash` traits allow us to use `SecretKey<E>` in standard std containers
// and macros.
impl<E: Engine> Eq for SecretKey<E> {}

impl<E: Engine> PartialEq for SecretKey<E> {
    fn eq(&self, other: &Self) -> bool {
        self.scalar == other.scalar
    }
}

impl<E: Engine> std::hash::Hash for SecretKey<E> {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        state.write(&self.to_bytes());
    }
}

impl<E: Engine> ToBytes for PublicKey<E> {
    fn to_bytes(&self) -> Vec<u8> {
        self.compress().as_ref().to_vec()
    }
}

#[derive(Debug)]
pub struct LengthError(usize, usize);

impl Error for LengthError {
    fn description(&self) -> &str {
        "encoding has incorrect length"
    }
}

impl fmt::Display for LengthError {
    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {
        write!(f, "{}, expected {}, got {}", self.description(), self.0, self.1)
    }
}

impl<E: Engine> TryFrom<&[u8]> for PublicKey<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        Ok(CompressedPublicKey::try_from(v)?.decompress()?)
    }
}

impl<E: Engine> ToBytes for Signature<E> {
    fn to_bytes(&self) -> Vec<u8> {
        self.compress().to_bytes()
    }
}

impl<E: Engine> TryFrom<&[u8]> for Signature<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        Ok(CompressedSignature::try_from(v)?.decode()?)
    }
}

impl<E: Engine> Base58Encoded for SecretKey<E> {}
impl<E: Engine> Base58Encoded for PublicKey<E> {}
impl<E: Engine> Base58Encoded for Signature<E> {}
impl<E: Engine> Base58Encoded for CompressedPublicKey<E> {}
impl<E: Engine> Base58Encoded for CompressedSignature<E> {}
impl<E: Engine> Base58Encoded for UncompressedSignature<E> {}

impl<E: Engine> CompressedPublicKey<E> {
    pub fn decompress(&self) -> Result<PublicKey<E>, GroupDecodingError> {
        Ok(PublicKey { point: self.0.into_affine()? })
    }

    /// Decompress a pubkey, without verifying that the resulting point is actually on the curve.
    /// Verifying is very slow, so if we know we've already done it (for example, if we're reading
    /// from disk a previously validated block), we can skip point verification.  Use with caution.
    pub fn decompress_unchecked(&self) -> PublicKey<E> {
        PublicKey { point: self.0.into_affine_unchecked().unwrap() }
    }
}

impl<E: Engine> AsRef<[u8]> for CompressedPublicKey<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for CompressedPublicKey<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> ToBytes for CompressedPublicKey<E> {
    fn to_bytes(&self) -> Vec<u8> {
        self.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for CompressedPublicKey<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G1Affine as CurveAffine>::Compressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(From::from(LengthError(expected, v.len())));
        }
        let mut encoded = <E::G1Affine as CurveAffine>::Compressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

impl<E: Engine> CompressedSignature<E> {
    pub fn decode(&self) -> Result<Signature<E>, GroupDecodingError> {
        // Subgroup check is postponed until signature verification
        Ok(Signature { point: self.0.into_affine_semi_checked()? })
    }
}

impl<E: Engine> AsRef<[u8]> for CompressedSignature<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for CompressedSignature<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> ToBytes for CompressedSignature<E> {
    fn to_bytes(&self) -> Vec<u8> {
        self.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for CompressedSignature<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G2Affine as CurveAffine>::Compressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(From::from(LengthError(expected, v.len())));
        }
        let mut encoded = <E::G2Affine as CurveAffine>::Compressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

impl<E: Engine> UncompressedSignature<E> {
    pub fn decode(&self) -> Result<Signature<E>, GroupDecodingError> {
        // Subgroup check is postponed until signature verification
        Ok(Signature { point: self.0.into_affine_semi_checked()? })
    }
}

impl<E: Engine> AsRef<[u8]> for UncompressedSignature<E> {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<E: Engine> AsMut<[u8]> for UncompressedSignature<E> {
    fn as_mut(&mut self) -> &mut [u8] {
        self.0.as_mut()
    }
}

impl<E: Engine> ToBytes for UncompressedSignature<E> {
    fn to_bytes(&self) -> Vec<u8> {
        self.as_ref().to_vec()
    }
}

impl<E: Engine> TryFrom<&[u8]> for UncompressedSignature<E> {
    type Error = Box<Error>;

    fn try_from(v: &[u8]) -> Result<Self, Self::Error> {
        let expected = <<E::G2Affine as CurveAffine>::Uncompressed as EncodedPoint>::size();
        if v.len() != expected {
            return Err(From::from(LengthError(expected, v.len())));
        }
        let mut encoded = <E::G2Affine as CurveAffine>::Uncompressed::empty();
        encoded.as_mut().copy_from_slice(v);
        Ok(Self(encoded))
    }
}

#[derive(Debug, Clone)]
pub struct AggregatePublicKey<E: Engine> {
    // This is the same as a public key, but stored in projective coordinates instead of affine.
    point: E::G1,
}

#[derive(Debug, Clone)]
pub struct AggregateSignature<E: Engine> {
    // This is the same as a signature, but stored in projective coordinates instead of affine.
    point: E::G2,
}

impl<E: Engine> AggregatePublicKey<E> {
    pub fn new() -> Self {
        AggregatePublicKey { point: E::G1::zero() }
    }

    // Very important: you must verify a proof-of-possession for each public key!
    pub fn aggregate(&mut self, pubkey: &PublicKey<E>) {
        self.point.add_assign_mixed(&pubkey.point);
    }

    pub fn get_key(&self) -> PublicKey<E> {
        PublicKey { point: self.point.into_affine() }
    }
}

impl<E: Engine> Default for AggregatePublicKey<E> {
    fn default() -> Self {
        Self::new()
    }
}

impl<E: Engine> AggregateSignature<E> {
    pub fn new() -> Self {
        AggregateSignature { point: E::G2::zero() }
    }

    pub fn aggregate(&mut self, sig: &Signature<E>) {
        self.point.add_assign_mixed(&sig.point);
    }

    pub fn get_signature(&self) -> Signature<E> {
        Signature { point: self.point.into_affine() }
    }
}

impl<E: Engine> Default for AggregateSignature<E> {
    fn default() -> Self {
        Self::new()
    }
}

use pairing::bls12_381::Bls12;

pub type BlsSecretKey = SecretKey<Bls12>;
pub type BlsPublicKey = PublicKey<Bls12>;
pub type BlsSignature = Signature<Bls12>;
pub type BlsAggregatePublicKey = AggregatePublicKey<Bls12>;
pub type BlsAggregateSignature = AggregateSignature<Bls12>;

pub mod uncompressed_bs58_signature_serializer {
    use crate::crypto::aggregate_signature::{Bls12, BlsSignature, UncompressedSignature};
    use crate::traits::Base58Encoded;
    use serde::{Deserialize, Deserializer, Serializer};

    pub fn serialize<S>(sig: &BlsSignature, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&sig.encode_uncompressed().to_base58())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<BlsSignature, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        let uncompressed = UncompressedSignature::<Bls12>::from_base58(&s).unwrap();
        Ok(uncompressed.decode().unwrap())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use rand::SeedableRng;
    use rand_xorshift::XorShiftRng;

    #[test]
    fn sign_verify() {
        let mut rng = XorShiftRng::seed_from_u64(1);

        let secret = (0..2).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();
        let pubkey = (0..2).map(|i| secret[i].get_public_key()).collect::<Vec<_>>();
        let message = (0..2).map(|i| format!("message {}", i)).collect::<Vec<_>>();
        let signature = (0..2).map(|i| secret[i].sign(message[i].as_bytes())).collect::<Vec<_>>();

        for i in 0..2 {
            for j in 0..2 {
                for k in 0..2 {
                    assert_eq!(
                        pubkey[i].verify(message[j].as_bytes(), &signature[k]),
                        (i == j) && (j == k)
                    );
                }
            }
        }
    }

    #[test]
    fn proof_verify() {
        let mut rng = XorShiftRng::seed_from_u64(2);

        let secret = (0..2).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();
        let pubkey = (0..2).map(|i| secret[i].get_public_key()).collect::<Vec<_>>();
        let proof = (0..2).map(|i| secret[i].get_proof_of_possession()).collect::<Vec<_>>();

        for i in 0..2 {
            for j in 0..2 {
                assert_eq!(pubkey[i].verify_proof_of_possession(&proof[j]), i == j);
            }
        }

        // make sure domain-separation is working
        let fake_proof = secret[0].sign(pubkey[0].compress().as_ref());
        assert!(!pubkey[0].verify_proof_of_possession(&fake_proof));
    }

    #[test]
    fn aggregate_signature() {
        let mut rng = XorShiftRng::seed_from_u64(3);

        let secret = (0..10).map(|_| BlsSecretKey::generate_from_rng(&mut rng)).collect::<Vec<_>>();

        let mut signature = BlsAggregateSignature::new();
        let mut pubkey = BlsAggregatePublicKey::new();

        let message = "Hello, world!";

        for i in 0..10 {
            signature.aggregate(&secret[i].sign(message.as_bytes()));
            pubkey.aggregate(&secret[i].get_public_key());
        }

        assert!(pubkey.get_key().verify(message.as_bytes(), &signature.get_signature()));

        // Signature should not validate on empty pubkey set
        let blank_pk = BlsAggregatePublicKey::new().get_key();
        assert!(!blank_pk.verify(message.as_bytes(), &signature.get_signature()));

        // Blank signature should not validate on non-empty pubkey set
        let blank_signature = BlsAggregateSignature::new().get_signature();
        assert!(!pubkey.get_key().verify(message.as_bytes(), &blank_signature));

        // Blank signature does validate on empty pubkey set for any message.  It does seem a little
        // odd, but it's consistent.
        assert!(blank_pk.verify(message.as_bytes(), &blank_signature));
    }

    #[test]
    fn encoding() {
        let mut rng = XorShiftRng::seed_from_u64(4);

        let secret = BlsSecretKey::generate_from_rng(&mut rng);
        let _pubkey = secret.get_public_key();
        let message = "Hello, world!";
        let signature = secret.sign(message.as_bytes());

        let compressed = signature.compress();
        let uncompressed = signature.encode_uncompressed();

        assert_eq!(
            CompressedSignature::try_from(compressed.as_ref()).unwrap().decode().unwrap(),
            signature
        );
        assert_eq!(
            UncompressedSignature::try_from(uncompressed.as_ref()).unwrap().decode().unwrap(),
            signature
        );
        assert!(CompressedSignature::<Bls12>::try_from(uncompressed.as_ref()).is_err());
        assert!(UncompressedSignature::<Bls12>::try_from(compressed.as_ref()).is_err());
    }
}

'''
'''--- runtime/primitives/src/crypto/group_signature.rs ---
use crate::crypto::aggregate_signature::{
    BlsAggregatePublicKey, BlsAggregateSignature, BlsPublicKey, BlsSignature,
};
use crate::crypto::signature::bs58_serializer;
use crate::logging::pretty_hash;
use crate::traits::{Base58Encoded, ToBytes};
use crate::types::{AuthorityMask, PartialSignature};
use core::fmt;
use std::convert::TryFrom;
use near_protos::types as types_proto;

#[derive(Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct GroupSignature {
    #[serde(with = "bs58_serializer")]
    pub signature: BlsSignature,
    pub authority_mask: AuthorityMask,
}

impl TryFrom<types_proto::GroupSignature> for GroupSignature {
    type Error = String;

    fn try_from(proto: types_proto::GroupSignature) -> Result<Self, String> {
        Base58Encoded::from_base58(&proto.signature)
            .map(|signature| GroupSignature { signature, authority_mask: proto.authority_mask })
            .map_err(|e| format!("cannot decode signature {:?}", e))
    }
}

impl From<GroupSignature> for types_proto::GroupSignature {
    fn from(signature: GroupSignature) -> Self {
        types_proto::GroupSignature {
            signature: Base58Encoded::to_base58(&signature.signature),
            authority_mask: signature.authority_mask,
            ..Default::default()
        }
    }
}

impl fmt::Debug for GroupSignature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(
            f,
            "{:?} {:?}",
            self.authority_mask,
            pretty_hash(&bs58::encode(&self.signature.to_bytes()).into_string())
        )
    }
}

impl GroupSignature {
    // TODO (optimization): It's better to keep the signature in projective coordinates while
    // building it, then switch to affine coordinates at the end.  For the time being we just keep
    // it in affine coordinates always.
    pub fn add_signature(&mut self, signature: &PartialSignature, authority_id: usize) {
        if authority_id >= self.authority_mask.len() {
            self.authority_mask.resize(authority_id + 1, false);
        }
        if self.authority_mask[authority_id] {
            return;
        }
        let mut new_sig = BlsAggregateSignature::new();
        new_sig.aggregate(&signature);
        if self.signature != BlsSignature::default() {
            new_sig.aggregate(&self.signature);
        }
        self.signature = new_sig.get_signature();
        self.authority_mask[authority_id] = true;
    }

    pub fn authority_count(&self) -> usize {
        self.authority_mask.iter().filter(|&x| *x).count()
    }

    pub fn verify(&self, keys: &[BlsPublicKey], message: &[u8]) -> bool {
        if keys.len() < self.authority_mask.len() {
            return false;
        }
        // Empty signature + empty public key would pass verification
        if self.authority_count() == 0 {
            return false;
        }
        let mut group_key = BlsAggregatePublicKey::new();
        for (index, key) in keys.iter().enumerate() {
            if let Some(true) = self.authority_mask.get(index) {
                group_key.aggregate(&key);
            }
        }
        group_key.get_key().verify(message, &self.signature)
    }
}

impl Default for GroupSignature {
    fn default() -> Self {
        GroupSignature {
            signature: BlsSignature::empty(),
            authority_mask: AuthorityMask::default(),
        }
    }
}

'''
'''--- runtime/primitives/src/crypto/mod.rs ---
pub mod aggregate_signature;
pub mod group_signature;
pub mod signature;
pub mod signer;

'''
'''--- runtime/primitives/src/crypto/signature.rs ---
extern crate exonum_sodiumoxide as sodiumoxide;

use std::convert::TryFrom;
use std::fmt;

use bs58;

use crate::logging::pretty_hash;
use crate::traits::{Base58Encoded, ToBytes};
use crate::types::ReadablePublicKey;
pub use exonum_sodiumoxide::crypto::sign::ed25519::Seed;

#[derive(Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]
pub struct PublicKey(pub sodiumoxide::crypto::sign::ed25519::PublicKey);

#[derive(Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct SecretKey(pub sodiumoxide::crypto::sign::ed25519::SecretKey);

#[derive(Clone, Eq, PartialEq, Serialize, Deserialize, Hash)]
pub struct Signature(pub sodiumoxide::crypto::sign::ed25519::Signature);

pub fn sign(data: &[u8], secret_key: &SecretKey) -> Signature {
    Signature(sodiumoxide::crypto::sign::ed25519::sign_detached(data, &secret_key.0))
}

pub fn verify(data: &[u8], signature: &Signature, public_key: &PublicKey) -> bool {
    sodiumoxide::crypto::sign::ed25519::verify_detached(&signature.0, data, &public_key.0)
}

pub fn get_key_pair() -> (PublicKey, SecretKey) {
    let (public_key, secret_key) = sodiumoxide::crypto::sign::ed25519::gen_keypair();
    (PublicKey(public_key), SecretKey(secret_key))
}

impl Base58Encoded for PublicKey {}
impl Base58Encoded for SecretKey {}
impl ToBytes for PublicKey {
    fn to_bytes(&self) -> Vec<u8> {
        self.as_ref().to_vec()
    }
}

impl ToBytes for SecretKey {
    fn to_bytes(&self) -> Vec<u8> {
        self.as_ref().to_vec()
    }
}

const SIG: [u8; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES] =
    [0u8; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];

pub const DEFAULT_SIGNATURE: Signature =
    Signature(sodiumoxide::crypto::sign::ed25519::Signature(SIG));

impl PublicKey {
    pub fn to_readable(&self) -> ReadablePublicKey {
        ReadablePublicKey(self.to_string())
    }

    pub fn to_base64(&self) -> String {
        base64::encode(&self.to_bytes())
    }
}

impl SecretKey {
    pub fn to_base64(&self) -> String {
        base64::encode(&self.to_bytes())
    }
}

impl TryFrom<&[u8]> for PublicKey {
    type Error = Box<std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES {
            return Err("bytes not the size of a public key".into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES];
        array.copy_from_slice(bytes);
        let public_key = sodiumoxide::crypto::sign::ed25519::PublicKey(array);
        Ok(PublicKey(public_key))
    }
}

impl TryFrom<&str> for PublicKey {
    type Error = String;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::PUBLICKEYBYTES];
        let bytes = bs58::decode(s)
            .into_vec()
            .map_err(|e| format!("Failed to convert public key from base58: {}", e))?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for public key", s));
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let public_key = sodiumoxide::crypto::sign::ed25519::PublicKey(array);
        Ok(PublicKey(public_key))
    }
}

impl TryFrom<&[u8]> for SecretKey {
    type Error = Box<std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES {
            return Err("bytes not the size of a secret key".into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES];
        array.copy_from_slice(bytes);
        let secret_key = sodiumoxide::crypto::sign::ed25519::SecretKey(array);
        Ok(SecretKey(secret_key))
    }
}

impl TryFrom<&str> for SecretKey {
    type Error = String;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SECRETKEYBYTES];
        let bytes = bs58::decode(s)
            .into_vec()
            .map_err(|e| format!("Failed to convert secret key from base58: {}", e))?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for secret key", s));
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let secret_key = sodiumoxide::crypto::sign::ed25519::SecretKey(array);
        Ok(SecretKey(secret_key))
    }
}

impl TryFrom<&[u8]> for Signature {
    type Error = Box<std::error::Error>;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES {
            return Err("bytes not the size of a signature".into());
        }
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];
        array.copy_from_slice(bytes);
        let signature = sodiumoxide::crypto::sign::ed25519::Signature(array);
        Ok(Signature(signature))
    }
}

impl TryFrom<&str> for Signature {
    type Error = String;

    fn try_from(s: &str) -> Result<Self, Self::Error> {
        let mut array = [0; sodiumoxide::crypto::sign::ed25519::SIGNATUREBYTES];
        let bytes = bs58::decode(s)
            .into_vec()
            .map_err(|e| format!("Failed to convert signature from base58: {}", e))?;
        if bytes.len() != array.len() {
            return Err(format!("decoded {} is not long enough for signature", s));
        }
        let bytes_arr = &bytes[..array.len()];
        array.copy_from_slice(bytes_arr);
        let signature = sodiumoxide::crypto::sign::ed25519::Signature(array);
        Ok(Signature(signature))
    }
}

impl std::convert::AsRef<[u8]> for PublicKey {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl<'a> From<&'a PublicKey> for String {
    fn from(h: &'a PublicKey) -> Self {
        bs58::encode(h.0).into_string()
    }
}

impl fmt::Debug for PublicKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for PublicKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl std::convert::AsRef<[u8]> for SecretKey {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl<'a> From<&'a SecretKey> for String {
    fn from(h: &'a SecretKey) -> Self {
        bs58::encode(h).into_string()
    }
}

impl std::convert::AsRef<[u8]> for Signature {
    fn as_ref(&self) -> &[u8] {
        &self.0[..]
    }
}

impl fmt::Debug for SecretKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for SecretKey {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl<'a> From<&'a Signature> for String {
    fn from(h: &'a Signature) -> Self {
        bs58::encode(h).into_string()
    }
}

impl fmt::Debug for Signature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for Signature {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

pub mod bs58_pub_key_format {
    use serde::{de::Error, Deserialize, Deserializer, Serializer};

    use super::PublicKey;
    use std::convert::TryInto;

    pub fn serialize<S>(public_key: &PublicKey, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(String::from(public_key).as_str())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<PublicKey, D::Error>
    where
        D: Deserializer<'de>,
    {
        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
    }
}

pub mod bs58_secret_key_format {
    use serde::{de::Error, Deserialize, Deserializer, Serializer};

    use super::SecretKey;
    use std::convert::TryInto;

    pub fn serialize<S>(secret_key: &SecretKey, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(String::from(secret_key).as_str())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<SecretKey, D::Error>
    where
        D: Deserializer<'de>,
    {
        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
    }
}

pub mod bs58_signature_format {
    use serde::{de::Error, Deserialize, Deserializer, Serializer};

    use super::Signature;
    use std::convert::TryInto;

    pub fn serialize<S>(signature: &Signature, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(String::from(signature).as_str())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<Signature, D::Error>
    where
        D: Deserializer<'de>,
    {
        String::deserialize(deserializer)?.as_str().try_into().map_err(Error::custom)
    }
}

pub mod bs58_serializer {
    use serde::{Deserialize, Deserializer, Serializer};

    use crate::traits::Base58Encoded;

    pub fn serialize<T, S>(t: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        T: Base58Encoded,
        S: Serializer,
    {
        serializer.serialize_str(&t.to_base58())
    }

    pub fn deserialize<'de, T, D>(deserializer: D) -> Result<T, D::Error>
    where
        T: Base58Encoded,
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        Ok(T::from_base58(&s).unwrap())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_verify() {
        let (public_key, private_key) = get_key_pair();
        let data = b"123";
        let signature = sign(data, &private_key);
        assert!(verify(data, &signature, &public_key));
    }
}

'''
'''--- runtime/primitives/src/crypto/signer.rs ---
use std::fs;
use std::path::Path;
use std::process;

use rand::distributions::Alphanumeric;
use rand::rngs::OsRng;
use rand::Rng;

use crate::crypto::aggregate_signature::{BlsPublicKey, BlsSecretKey};
use crate::crypto::signature::{
    bs58_pub_key_format, bs58_secret_key_format, bs58_serializer, get_key_pair, sign, PublicKey,
    SecretKey, Signature,
};
use crate::types::{AccountId, PartialSignature};

/// Trait to abstract the signer account.
pub trait AccountSigner: Sync + Send {
    fn account_id(&self) -> AccountId;
}

/// Trait to abstract the way transaction signing with ed25519.
/// Can be used to not keep private key in the given binary via cross-process communication.
pub trait EDSigner: Sync + Send {
    fn public_key(&self) -> PublicKey;
    fn sign(&self, data: &[u8]) -> Signature;
}

/// Trait to abstract the way signing with bls.
/// Can be used to not keep private key in the given binary via cross-process communication.
pub trait BLSSigner: Sync + Send {
    fn bls_public_key(&self) -> BlsPublicKey;
    fn bls_sign(&self, data: &[u8]) -> PartialSignature;
}

#[derive(Serialize, Deserialize)]
pub struct KeyFile {
    #[serde(with = "bs58_pub_key_format")]
    pub public_key: PublicKey,
    #[serde(with = "bs58_secret_key_format")]
    pub secret_key: SecretKey,
}

pub fn write_key_file(
    key_store_path: &Path,
    public_key: PublicKey,
    secret_key: SecretKey,
) -> String {
    if !key_store_path.exists() {
        fs::create_dir_all(key_store_path).unwrap();
    }

    let key_file = KeyFile { public_key, secret_key };
    let key_file_path = key_store_path.join(Path::new(&public_key.to_string()));
    let serialized = serde_json::to_string(&key_file).unwrap();
    fs::write(key_file_path, serialized).unwrap();
    public_key.to_string()
}

pub fn get_key_file(key_store_path: &Path, public_key: Option<String>) -> KeyFile {
    if !key_store_path.exists() {
        println!("Key store path does not exist: {:?}", &key_store_path);
        process::exit(3);
    }

    let mut key_files = fs::read_dir(key_store_path).unwrap();
    let key_file = key_files.next();
    let key_file_string = if key_files.count() != 0 {
        if let Some(p) = public_key {
            let key_file_path = key_store_path.join(Path::new(&p));
            fs::read_to_string(key_file_path).unwrap()
        } else {
            println!(
                "Public key must be specified when there is more than one \
                 file in the keystore"
            );
            process::exit(4);
        }
    } else {
        fs::read_to_string(key_file.unwrap().unwrap().path()).unwrap()
    };

    serde_json::from_str(&key_file_string).unwrap()
}

#[derive(Serialize, Deserialize)]
pub struct BlockProducerKeyFile {
    #[serde(with = "bs58_serializer")]
    pub public_key: PublicKey,
    #[serde(with = "bs58_serializer")]
    pub secret_key: SecretKey,
    #[serde(with = "bs58_serializer")]
    pub bls_public_key: BlsPublicKey,
    #[serde(with = "bs58_serializer")]
    pub bls_secret_key: BlsSecretKey,
}

pub fn write_block_producer_key_file(
    key_store_path: &Path,
    public_key: PublicKey,
    secret_key: SecretKey,
    bls_public_key: BlsPublicKey,
    bls_secret_key: BlsSecretKey,
) -> String {
    if !key_store_path.exists() {
        fs::create_dir_all(key_store_path).unwrap();
    }

    let key_file = BlockProducerKeyFile { public_key, secret_key, bls_public_key, bls_secret_key };
    let key_file_path = key_store_path.join(Path::new(&key_file.public_key.to_string()));
    let serialized = serde_json::to_string(&key_file).unwrap();
    fs::write(key_file_path, serialized).unwrap();
    key_file.public_key.to_string()
}

pub fn get_block_producer_key_file(
    key_store_path: &Path,
    public_key: Option<String>,
) -> BlockProducerKeyFile {
    if !key_store_path.exists() {
        println!("Key store path does not exist: {:?}", &key_store_path);
        process::exit(3);
    }

    let mut key_files = fs::read_dir(key_store_path).unwrap();
    let key_file = key_files.next();
    let key_files_count = key_files.count();
    if key_files_count == 0 && key_file.is_none() {
        panic!("No key file found in {:?}. Run `cargo run --package keystore -- keygen --test-seed alice.near` to set up testing keys.", key_store_path);
    }
    let key_file_string = if key_files_count > 0 {
        if let Some(p) = public_key {
            let key_file_path = key_store_path.join(Path::new(&p));
            match fs::read_to_string(key_file_path.clone()) {
                Ok(content) => content,
                Err(err) => {
                    panic!("Failed to read key file {:?} with error: {}", key_file_path, err);
                }
            }
        } else {
            println!(
                "Public key must be specified when there is more than one \
                 file in the keystore"
            );
            process::exit(4);
        }
    } else {
        let path = key_file.unwrap().unwrap().path();
        match fs::read_to_string(path.clone()) {
            Ok(content) => content,
            Err(err) => {
                panic!("Failed to read key file {:?} with error: {}", path, err);
            }
        }
    };

    serde_json::from_str(&key_file_string).unwrap()
}

pub fn get_or_create_key_file(
    key_store_path: &Path,
    public_key: Option<String>,
) -> BlockProducerKeyFile {
    if !key_store_path.exists() {
        let (public_key, secret_key) = get_key_pair();
        let bls_secret_key = BlsSecretKey::generate();
        let bls_public_key = bls_secret_key.get_public_key();
        let new_public_key = write_block_producer_key_file(
            key_store_path,
            public_key,
            secret_key,
            bls_public_key,
            bls_secret_key,
        );
        get_block_producer_key_file(key_store_path, Some(new_public_key))
    } else {
        get_block_producer_key_file(key_store_path, public_key)
    }
}

#[derive(Clone)]
pub struct InMemorySigner {
    pub account_id: AccountId,
    pub public_key: PublicKey,
    pub secret_key: SecretKey,
    pub bls_public_key: BlsPublicKey,
    pub bls_secret_key: BlsSecretKey,
}

impl InMemorySigner {
    pub fn from_key_file(
        account_id: AccountId,
        key_store_path: &Path,
        public_key: Option<String>,
    ) -> Self {
        let key_file = get_or_create_key_file(key_store_path, public_key);
        InMemorySigner {
            account_id,
            public_key: key_file.public_key,
            secret_key: key_file.secret_key,
            bls_public_key: key_file.bls_public_key,
            bls_secret_key: key_file.bls_secret_key,
        }
    }

    /// Initialize `InMemorySigner` with a random ED25519 and BLS keys, and random account id. Used
    /// for testing only.
    pub fn from_random() -> Self {
        let mut rng = OsRng::new().expect("Unable to generate random numbers");
        let account_id: String =
            rng.sample_iter(&Alphanumeric).filter(char::is_ascii_alphabetic).take(10).collect();
        let (public_key, secret_key) = get_key_pair();
        let bls_secret_key = BlsSecretKey::generate();
        let bls_public_key = bls_secret_key.get_public_key();
        Self { account_id, public_key, secret_key, bls_public_key, bls_secret_key }
    }
}

impl AccountSigner for InMemorySigner {
    #[inline]
    fn account_id(&self) -> AccountId {
        self.account_id.clone()
    }
}

impl EDSigner for InMemorySigner {
    #[inline]
    fn public_key(&self) -> PublicKey {
        self.public_key
    }

    fn sign(&self, data: &[u8]) -> Signature {
        sign(data, &self.secret_key)
    }
}

impl BLSSigner for InMemorySigner {
    #[inline]
    fn bls_public_key(&self) -> BlsPublicKey {
        self.bls_public_key.clone()
    }

    fn bls_sign(&self, data: &[u8]) -> PartialSignature {
        self.bls_secret_key.sign(data)
    }
}

'''
'''--- runtime/primitives/src/hash.rs ---
use std::convert::TryFrom;
use std::fmt;
use std::hash::{Hash, Hasher};

use bs58;
use exonum_sodiumoxide as sodiumoxide;
use exonum_sodiumoxide::crypto::hash::sha256::Digest;
use heapsize;

use crate::logging::pretty_hash;
use crate::serialize::Encode;

#[derive(Copy, Clone, PartialOrd, Ord, Serialize, Deserialize)]
pub struct CryptoHash(pub Digest);

impl<'a> From<&'a CryptoHash> for String {
    fn from(h: &'a CryptoHash) -> Self {
        bs58::encode(h.0).into_string()
    }
}

impl TryFrom<String> for CryptoHash {
    type Error = String;

    fn try_from(s: String) -> Result<Self, Self::Error> {
        let bytes = bs58::decode(s).into_vec().map_err(|e| format!("{}", e))?;
        Self::try_from(bytes)
    }
}

impl Default for CryptoHash {
    fn default() -> Self {
        CryptoHash(Digest(Default::default()))
    }
}

impl AsRef<[u8]> for CryptoHash {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl AsMut<[u8]> for CryptoHash {
    fn as_mut(&mut self) -> &mut [u8] {
        (self.0).0.as_mut()
    }
}

impl TryFrom<&[u8]> for CryptoHash {
    type Error = String;

    fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
        if bytes.len() != 32 {
            return Err("incorrect length for hash".to_string());
        }
        let mut buf = [0; 32];
        buf.copy_from_slice(bytes);
        Ok(CryptoHash(Digest(buf)))
    }
}

impl TryFrom<Vec<u8>> for CryptoHash {
    type Error = String;

    fn try_from(v: Vec<u8>) -> Result<Self, Self::Error> {
        Self::try_from(v.as_ref())
    }
}

impl From<CryptoHash> for Vec<u8> {
    fn from(hash: CryptoHash) -> Vec<u8> {
        (hash.0).0.to_vec()
    }
}

impl fmt::Debug for CryptoHash {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", pretty_hash(&String::from(self)))
    }
}

impl fmt::Display for CryptoHash {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", String::from(self))
    }
}

impl Hash for CryptoHash {
    fn hash<H: Hasher>(&self, state: &mut H) {
        state.write(self.as_ref());
    }
}

impl PartialEq for CryptoHash {
    fn eq(&self, other: &CryptoHash) -> bool {
        self.0 == other.0
    }
}

impl Eq for CryptoHash {}

pub mod bs58_format {
    use serde::de;
    use serde::{Deserialize, Deserializer, Serializer};

    use super::{bs58, CryptoHash};
    use std::convert::TryFrom;

    pub fn serialize<S>(crypto_hash: &CryptoHash, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(String::from(crypto_hash).as_str())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<CryptoHash, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        let mut array = [0; 32];
        match bs58::decode(s).into(&mut array) {
            Ok(_) => CryptoHash::try_from(array.as_ref()).map_err(de::Error::custom),
            Err(e) => Err(de::Error::custom(e.to_string())),
        }
    }
}

/// Calculates a hash of a bytes slice.
///
/// # Examples
///
/// The example below calculates the hash of the indicated data.
///
/// ```
/// # extern crate primitives;
///
/// let data = [1, 2, 3];
/// let hash = primitives::hash::hash(&data);
/// ```
pub fn hash(data: &[u8]) -> CryptoHash {
    CryptoHash(sodiumoxide::crypto::hash::sha256::hash(data))
}

pub fn hash_struct<T: Encode>(obj: &T) -> CryptoHash {
    hash(&obj.encode().expect("Serialization failed"))
}

impl heapsize::HeapSizeOf for CryptoHash {
    fn heap_size_of_children(&self) -> usize {
        0
    }
}

#[cfg(test)]
mod tests {
    extern crate serde_json;

    use super::*;

    #[derive(Deserialize, Serialize)]
    struct Struct {
        #[serde(with = "bs58_format")]
        hash: CryptoHash,
    }

    #[test]
    fn test_serialize_success() {
        let hash = hash(&[0, 1, 2]);
        let s = Struct { hash };
        let encoded = serde_json::to_string(&s).unwrap();
        assert_eq!(encoded, "{\"hash\":\"CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf\"}");
    }

    #[test]
    fn test_serialize_default() {
        let s = Struct { hash: CryptoHash::default() };
        let encoded = serde_json::to_string(&s).unwrap();
        assert_eq!(encoded, "{\"hash\":\"11111111111111111111111111111111\"}");
    }

    #[test]
    fn test_deserialize_default() {
        let encoded = "{\"hash\":\"11111111111111111111111111111111\"}";
        let decoded: Struct = serde_json::from_str(&encoded).unwrap();
        assert_eq!(decoded.hash, CryptoHash::default());
    }

    #[test]
    fn test_deserialize_success() {
        let encoded = "{\"hash\":\"CjNSmWXTWhC3EhRVtqLhRmWMTkRbU96wUACqxMtV1uGf\"}";
        let decoded: Struct = serde_json::from_str(&encoded).unwrap();
        assert_eq!(decoded.hash, hash(&[0, 1, 2]));
    }

    #[test]
    fn test_deserialize_not_base58() {
        let encoded = "\"---\"";
        match serde_json::from_str(&encoded) {
            Ok(CryptoHash(_)) => assert!(false, "should have failed"),
            Err(_) => (),
        }
    }

    #[test]
    fn test_deserialize_not_crypto_hash() {
        let encoded = "\"CjNSmWXTWhC3ELhRmWMTkRbU96wUACqxMtV1uGf\"";
        match serde_json::from_str(&encoded) {
            Ok(CryptoHash(_)) => assert!(false, "should have failed"),
            Err(_) => (),
        }
    }
}

'''
'''--- runtime/primitives/src/lib.rs ---
extern crate jemallocator;

#[global_allocator]
static ALLOC: jemallocator::Jemalloc = jemallocator::Jemalloc;

extern crate bincode;
extern crate bs58;
extern crate byteorder;
extern crate exonum_sodiumoxide;
extern crate heapsize;
extern crate pairing;
extern crate rand;
extern crate regex;
extern crate serde;
#[macro_use]
extern crate serde_derive;
extern crate serde_json;

pub mod account;
pub mod beacon;
pub mod block_traits;
pub mod chain;
pub mod consensus;
pub mod crypto;
pub mod hash;
pub mod logging;
pub mod merkle;
pub mod network;
pub mod receipt;
pub mod rpc;
pub mod serialize;
pub mod test_utils;
pub mod traits;
pub mod transaction;
pub mod types;
pub mod utils;

'''
'''--- runtime/primitives/src/logging.rs ---
use std::fmt::Debug;

use bs58;
use serde::Serialize;

const VECTOR_MAX_LENGTH: usize = 5;
const STRING_PRINT_LEN: usize = 128;

pub fn pretty_vec<T: Debug>(buf: &[T]) -> String {
    if buf.len() <= VECTOR_MAX_LENGTH {
        format!("{:#?}", buf)
    } else {
        format!(
            "({})[{:#?}, {:#?}, … {:#?}, {:#?}]",
            buf.len(),
            buf[0],
            buf[1],
            buf[buf.len() - 2],
            buf[buf.len() - 1]
        )
    }
}

pub fn pretty_str(s: &str, print_len: usize) -> String {
    if s.len() <= print_len {
        format!("`{}`", s)
    } else {
        format!("({})`{}…`", s.len(), &s.chars().take(print_len).collect::<String>())
    }
}

pub fn pretty_hash(s: &str) -> String {
    pretty_str(s, STRING_PRINT_LEN)
}

pub fn pretty_utf8(buf: &[u8]) -> String {
    match std::str::from_utf8(buf) {
        Ok(s) => pretty_hash(s),
        Err(_) => {
            if buf.len() <= STRING_PRINT_LEN {
                pretty_hash(&bs58::encode(buf).into_string())
            } else {
                pretty_vec(buf)
            }
        }
    }
}

pub fn pretty_result(result: &Option<Vec<u8>>) -> String {
    match result {
        Some(ref v) => pretty_utf8(&v),
        None => "None".to_string(),
    }
}

pub fn pretty_results(results: &[Option<Vec<u8>>]) -> String {
    let v: Vec<String> = results.iter().map(pretty_result).collect();
    format!("{:?}", pretty_vec(&v))
}

pub fn pretty_serializable<T: Serialize>(s: &T) -> String {
    match bincode::serialize(&s) {
        Ok(buf) => pretty_hash(&bs58::encode(&buf).into_string()),
        Err(e) => format!("[failed to serialize: {}]", e),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    static HI_NEAR: &str = "Привет, NEAR";

    #[test]
    fn test_non_ut8_string_truncation() {
        assert_eq!(format!("({})`Привет…`", HI_NEAR.len()), pretty_str(HI_NEAR, 6));
    }

    #[test]
    fn test_non_ut8_more_bytes_same_char_count() {
        assert_eq!(
            format!("({})`{}…`", HI_NEAR.len(), HI_NEAR),
            pretty_str(HI_NEAR, HI_NEAR.chars().count())
        );
    }

    #[test]
    fn test_non_ut8_no_truncation() {
        assert_eq!(format!("`{}`", HI_NEAR), pretty_str(HI_NEAR, HI_NEAR.len()));
    }
}

'''
'''--- runtime/primitives/src/merkle.rs ---
use crate::hash::{hash, hash_struct};
use crate::serialize::Encode;
use crate::types::MerkleHash;

pub type MerklePath = Vec<(MerkleHash, Direction)>;

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left,
    Right,
}

fn combine_hash(hash1: MerkleHash, hash2: MerkleHash) -> MerkleHash {
    let mut combined: Vec<u8> = hash1.into();
    combined.append(&mut hash2.into());
    hash(&combined)
}

/// Merklize an array of items. If the array is empty, returns hash of 0
pub fn merklize<T: Encode>(arr: &[T]) -> (MerkleHash, Vec<MerklePath>) {
    if arr.is_empty() {
        return (MerkleHash::default(), vec![]);
    }
    let mut len = (arr.len() as u32).next_power_of_two();
    let mut hashes: Vec<_> = (0..len)
        .map(|i| if i < arr.len() as u32 { hash_struct(&arr[i as usize]) } else { hash_struct(&0) })
        .collect();
    // degenerate case
    if len == 1 {
        return (hashes[0], vec![vec![]]);
    }
    let mut paths: Vec<MerklePath> = (0..arr.len())
        .map(|i| {
            if i % 2 == 0 {
                vec![(hashes[(i + 1) as usize], Direction::Right)]
            } else {
                vec![(hashes[(i - 1) as usize], Direction::Left)]
            }
        })
        .collect();

    let mut counter = 1;
    while len > 1 {
        len /= 2;
        counter *= 2;
        for i in 0..len {
            let hash = combine_hash(hashes[2 * i as usize], hashes[(2 * i + 1) as usize]);
            hashes[i as usize] = hash;
            if len > 1 {
                if i % 2 == 0 {
                    for j in 0..counter {
                        let index = ((i + 1) * counter + j) as usize;
                        if index < arr.len() {
                            paths[index].push((hash, Direction::Left));
                        }
                    }
                } else {
                    for j in 0..counter {
                        let index = ((i - 1) * counter + j) as usize;
                        if index < arr.len() {
                            paths[index].push((hash, Direction::Right));
                        }
                    }
                }
            }
        }
    }
    (hashes[0], paths)
}

/// Verify merkle path for given item and corresponding path.
pub fn verify_path<T: Encode>(root: MerkleHash, path: &MerklePath, item: &T) -> bool {
    let mut hash = hash_struct(item);
    for (h, d) in path {
        match d {
            Direction::Left => {
                hash = combine_hash(*h, hash);
            }
            Direction::Right => {
                hash = combine_hash(hash, *h);
            }
        }
    }
    hash == root
}

#[cfg(test)]
mod tests {
    use super::*;
    use rand::{SeedableRng, Rng};
    use rand::rngs::StdRng;

    fn test_with_len(n: u32, rng: &mut StdRng) {
        let mut arr: Vec<u32> = vec![];
        for _ in 0..n {
            arr.push(rng.gen_range(0, 1000));
        }
        let (root, paths) = merklize(&arr);
        assert_eq!(paths.len() as u32, n);
        for (i, item) in arr.iter().enumerate() {
            assert!(verify_path(root, &paths[i], item));
        }
    }

    #[test]
    fn test_merkle_path() {
        let mut rng: StdRng = SeedableRng::seed_from_u64(1);
        for _ in 0..10 {
            let len: u32 = rng.gen_range(1, 50);
            test_with_len(len, &mut rng);
        }
    }

    #[test]
    fn test_incorrect_path() {
        let items = vec![111, 222, 333];
        let (root, paths) = merklize(&items);
        for i in 0..items.len() {
            assert!(!verify_path(root, &paths[(i + 1) % 3], &items[i]))
        }
    }
}

'''
'''--- runtime/primitives/src/network.rs ---
use crate::chain::ChainState;
use crate::hash::CryptoHash;
use crate::types::{AccountId, PeerId};
use crate::utils::{proto_to_result, proto_to_type, to_string_value};
use near_protos::network as network_proto;
use protobuf::well_known_types::UInt32Value;
use protobuf::{RepeatedField, SingularPtrField};
use std::borrow::Borrow;
use std::convert::{Into, TryFrom, TryInto};
use std::fmt;
use std::fmt::{Display, Formatter};
use std::hash::{Hash, Hasher};
use std::iter::FromIterator;
use std::net::SocketAddr;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PeerAddr {
    pub id: PeerId,
    pub addr: SocketAddr,
}

impl PeerAddr {
    pub fn parse(addr_id: &str) -> Result<Self, String> {
        let addr_id: Vec<_> = addr_id.split('/').collect();
        let (addr, id) = (addr_id[0], addr_id[1]);
        Ok(PeerAddr {
            id: id.to_string().try_into()?,
            addr: addr
                .parse::<SocketAddr>()
                .map_err(|e| format!("Error parsing address {:?}: {:?}", addr, e))?,
        })
    }
}

impl Display for PeerAddr {
    fn fmt(&self, f: &mut Formatter) -> Result<(), std::fmt::Error> {
        write!(f, "{}/{}", self.addr, self.id)
    }
}

impl TryFrom<PeerInfo> for PeerAddr {
    type Error = String;

    fn try_from(peer_info: PeerInfo) -> Result<Self, Self::Error> {
        match peer_info.addr {
            Some(addr) => Ok(PeerAddr { id: peer_info.id, addr }),
            None => Err(format!("PeerInfo {:?} doesn't have an address", peer_info)),
        }
    }
}

/// Info about the peer. If peer is an authority then we also know its account id.
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PeerInfo {
    pub id: PeerId,
    pub addr: Option<SocketAddr>,
    pub account_id: Option<AccountId>,
}

impl PeerInfo {
    pub fn addr_port(&self) -> Option<u16> {
        self.addr.map(|addr| addr.port())
    }
}

impl PartialEq for PeerInfo {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}

impl Hash for PeerInfo {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.id.hash(state);
    }
}

impl Eq for PeerInfo {}

impl fmt::Display for PeerInfo {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if let Some(acc) = self.account_id.as_ref() {
            write!(f, "({}, {:?}, {})", self.id, self.addr, acc)
        } else {
            write!(f, "({}, {:?})", self.id, self.addr)
        }
    }
}

impl Borrow<PeerId> for PeerInfo {
    fn borrow(&self) -> &PeerId {
        &self.id
    }
}

impl From<PeerAddr> for PeerInfo {
    fn from(node_addr: PeerAddr) -> Self {
        PeerInfo { id: node_addr.id, addr: Some(node_addr.addr), account_id: None }
    }
}

impl TryFrom<network_proto::PeerInfo> for PeerInfo {
    type Error = String;

    fn try_from(proto: network_proto::PeerInfo) -> Result<Self, Self::Error> {
        let addr = proto.addr.into_option().and_then(|s| s.value.parse::<SocketAddr>().ok());
        let account_id = proto.account_id.into_option().map(|s| s.value);
        Ok(PeerInfo { id: CryptoHash::try_from(proto.id)?, addr, account_id })
    }
}

impl From<PeerInfo> for network_proto::PeerInfo {
    fn from(peer_info: PeerInfo) -> network_proto::PeerInfo {
        let id = peer_info.id;
        let addr = SingularPtrField::from_option(
            peer_info.addr.map(|s| to_string_value(format!("{}", s))),
        );
        let account_id = SingularPtrField::from_option(peer_info.account_id.map(to_string_value));
        network_proto::PeerInfo {
            id: id.into(),
            addr,
            account_id,
            ..Default::default()
        }
    }
}

pub type PeersInfo = Vec<PeerInfo>;

#[derive(PartialEq, Eq, Debug, Serialize, Deserialize, Clone)]
pub struct ConnectedInfo {
    pub chain_state: ChainState,
}

impl TryFrom<network_proto::ConnectedInfo> for ConnectedInfo {
    type Error = String;

    fn try_from(proto: network_proto::ConnectedInfo) -> Result<Self, Self::Error> {
        proto_to_result(proto.chain_state)
            .and_then(|state| Ok(ConnectedInfo { chain_state: state.try_into()? }))
    }
}

impl From<ConnectedInfo> for network_proto::ConnectedInfo {
    fn from(connected_info: ConnectedInfo) -> network_proto::ConnectedInfo {
        network_proto::ConnectedInfo {
            chain_state: SingularPtrField::some(connected_info.chain_state.into()),
            ..Default::default()
        }
    }
}

#[derive(PartialEq, Eq, Clone, Debug, Serialize, Deserialize)]
pub struct Handshake {
    /// Protocol version.
    pub version: u32,
    /// Sender's peer id.
    pub peer_id: PeerId,
    /// Sender's account id, if present.
    pub account_id: Option<AccountId>,
    /// Sender's listening addr.
    pub listen_port: Option<u16>,
    /// Sender's information about known peers.
    pub peers_info: PeersInfo,
    /// Connected info message that peer receives.
    pub connected_info: ConnectedInfo,
}

impl TryFrom<network_proto::HandShake> for Handshake {
    type Error = String;

    fn try_from(proto: network_proto::HandShake) -> Result<Self, Self::Error> {
        let account_id = proto.account_id.into_option().map(|s| s.value);
        let listen_port = proto.listen_port.into_option().map(|v| v.value as u16);
        let peers_info =
            proto.peers_info.into_iter().map(TryInto::try_into).collect::<Result<Vec<_>, _>>()?;
        let connected_info = proto_to_type(proto.connected_info)?;
        Ok(Handshake {
            version: proto.version,
            peer_id: proto.peer_id.try_into()?,
            account_id,
            listen_port,
            peers_info,
            connected_info,
        })
    }
}

impl From<Handshake> for network_proto::HandShake {
    fn from(hand_shake: Handshake) -> network_proto::HandShake {
        let account_id = SingularPtrField::from_option(hand_shake.account_id.map(to_string_value));
        let listen_port = SingularPtrField::from_option(hand_shake.listen_port.map(|v| {
            let mut res = UInt32Value::new();
            res.set_value(u32::from(v));
            res
        }));
        network_proto::HandShake {
            version: hand_shake.version,
            peer_id: hand_shake.peer_id.into(),
            peers_info: RepeatedField::from_iter(
                hand_shake.peers_info.into_iter().map(std::convert::Into::into),
            ),
            connected_info: SingularPtrField::some(hand_shake.connected_info.into()),
            account_id,
            listen_port,
            ..Default::default()
        }
    }
}

#[derive(PartialEq, Eq, Clone, Debug, Serialize, Deserialize)]
pub enum PeerMessage {
    Handshake(Handshake),
    InfoGossip(PeersInfo),
    Message(Vec<u8>),
}

impl TryFrom<network_proto::PeerMessage> for PeerMessage {
    type Error = String;

    fn try_from(proto: network_proto::PeerMessage) -> Result<Self, Self::Error> {
        match proto.message_type {
            Some(network_proto::PeerMessage_oneof_message_type::hand_shake(hand_shake)) => {
                hand_shake.try_into().map(PeerMessage::Handshake)
            }
            Some(network_proto::PeerMessage_oneof_message_type::info_gossip(gossip)) => {
                let peer_info = gossip
                    .info_gossip
                    .into_iter()
                    .map(TryInto::try_into)
                    .collect::<Result<Vec<_>, _>>()?;
                Ok(PeerMessage::InfoGossip(peer_info))
            }
            Some(network_proto::PeerMessage_oneof_message_type::message(message)) => {
                Ok(PeerMessage::Message(message))
            }
            None => unreachable!(),
        }
    }
}

impl From<PeerMessage> for network_proto::PeerMessage {
    fn from(message: PeerMessage) -> network_proto::PeerMessage {
        let message_type = match message {
            PeerMessage::Handshake(hand_shake) => {
                Some(network_proto::PeerMessage_oneof_message_type::hand_shake(hand_shake.into()))
            }
            PeerMessage::InfoGossip(peers_info) => {
                let gossip = network_proto::InfoGossip {
                    info_gossip: RepeatedField::from_iter(
                        peers_info.into_iter().map(std::convert::Into::into),
                    ),
                    ..Default::default()
                };
                Some(network_proto::PeerMessage_oneof_message_type::info_gossip(gossip))
            }
            PeerMessage::Message(message) => {
                Some(network_proto::PeerMessage_oneof_message_type::message(message))
            }
        };
        network_proto::PeerMessage {
            message_type,
            ..Default::default()
        }
    }
}

'''
'''--- runtime/primitives/src/proofs.rs ---
use crate::hash::{hash, hash_struct};

// SinglePartitionProofLen represents the number of bytes in a single partition
// PoRep or PoSt proof. The total length of a PoSt or PoRep proof equals the
// product of SinglePartitionProofLen and the number of partitions.
const SINGLEPARTITIONPROOFLEN: u32 = 192;

// PoStProof is the byte representation of the Proof of SpaceTime proof
pub type PoStProof = Vec<u8>;

// PoRepProof is the byte representation of the Seal Proof of Replication
pub type PoRepProof = Vec<u8>;

impl PoStProof {

    // ProofPartitions returns the number of partitions used to create the PoRep
    // proof, or an error if the PoRep proof has an unsupported length.
    //TODO: NOT IMPLEMENT
    pub fn ProofPartitions(){}
}

impl PoRepProof {
    // ProofPartitions returns the number of partitions used to create the PoSt
    // proof, or an error if the PoSt proof has an unsupported length.
    //TODO: NOT IMPLEMENT
    pub fn ProofPartitions(){}
}

'''
'''--- runtime/primitives/src/receipt.rs ---
use crate::transaction::{ReceiptTransaction, TransactionResult};

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct ReceiptInfo {
    pub receipt: ReceiptTransaction,
    pub block_index: u64,
    pub result: TransactionResult,
}

'''
'''--- runtime/primitives/src/rpc.rs ---
#[derive(Serialize, Deserialize, Debug)]
pub struct JsonRpcRequest {
    pub jsonrpc: String,
    pub method: String,
    pub params: Vec<serde_json::Value>,
    pub id: String,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct JsonRpcResponse {
    pub jsonrpc: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub result: Option<serde_json::Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<JsonRpcResponseError>,
    pub id: String,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct JsonRpcResponseError {
    code: i64,
    message: String,
    data: serde_json::Value,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct ABCIQueryResponse {
    pub code: u32,
    pub log: String,
    pub info: String,
    pub index: i64,
    pub key: Vec<u8>,
    pub value: Vec<u8>,
    pub proof: Vec<ProofOp>,
    pub height: i64,
    pub codespace: String,
}

impl ABCIQueryResponse {
    pub fn account<T: serde::Serialize>(key: &str, value: T) -> Self {
        ABCIQueryResponse {
            code: 0,
            log: "exists".to_string(),
            info: "".to_string(),
            index: -1,
            key: key.as_bytes().to_vec(),
            value: serde_json::to_string(&value).unwrap().as_bytes().to_vec(),
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }

    pub fn result(key: &str, value: Vec<u8>, logs: Vec<String>) -> Self {
        ABCIQueryResponse {
            code: 0,
            log: logs.join("\n"),
            info: "".to_string(),
            index: -1,
            key: key.as_bytes().to_vec(),
            value,
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }

    pub fn result_err(key: &str, message: String, logs: Vec<String>) -> Self {
        ABCIQueryResponse {
            code: 1,
            log: logs.join("\n"),
            info: message,
            index: -1,
            key: key.as_bytes().to_vec(),
            value: vec![],
            proof: vec![],
            height: 0,
            codespace: "".to_string(),
        }
    }
}

#[derive(Serialize, Deserialize, Debug)]
pub struct ProofOp {
    pub field_type: String,
    pub key: Vec<u8>,
    pub data: Vec<u8>,
}

'''
'''--- runtime/primitives/src/serialize.rs ---
use std::io;

use serde::{de::DeserializeOwned, Serialize};

pub type EncodeResult = Result<Vec<u8>, io::Error>;
pub type DecodeResult<T> = Result<T, io::Error>;

// encode a type to byte array
pub trait Encode {
    fn encode(&self) -> EncodeResult;
}

// decode from byte array
pub trait Decode: Sized {
    fn decode(data: &[u8]) -> DecodeResult<Self>;
}

impl<T: Serialize> Encode for T {
    fn encode(&self) -> EncodeResult {
        bincode::serialize(&self)
            .map_err(|_| io::Error::new(io::ErrorKind::Other, "Failed to serialize"))
    }
}

impl<T> Decode for T
where
    T: DeserializeOwned,
{
    fn decode(data: &[u8]) -> DecodeResult<Self> {
        bincode::deserialize(data)
            .map_err(|_| io::Error::new(io::ErrorKind::Other, "Failed to deserialize"))
    }
}

'''
'''--- runtime/primitives/src/test_utils.rs ---
use std::collections::hash_map::DefaultHasher;
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::sync::Arc;

use exonum_sodiumoxide::crypto::sign::ed25519::{keypair_from_seed, Seed};
use rand::SeedableRng;
use rand_xorshift::XorShiftRng;

use crate::beacon::SignedBeaconBlock;
use crate::block_traits::{SignedBlock, SignedHeader};
use crate::chain::{SignedShardBlock, SignedShardBlockHeader};
use crate::crypto::aggregate_signature::{BlsPublicKey, BlsSecretKey};
use crate::crypto::signature::{PublicKey, SecretKey};
use crate::crypto::signer::{AccountSigner, BLSSigner, EDSigner, InMemorySigner};
use crate::hash::CryptoHash;
use crate::transaction::{SignedTransaction, TransactionBody};
use crate::types::{AccountId, AuthorityId, AuthorityStake};

pub fn calculate_hash<T: Hash>(t: &T) -> u64 {
    let mut s = DefaultHasher::new();
    t.hash(&mut s);
    s.finish()
}

pub fn get_key_pair_from_seed(seed_string: &str) -> (PublicKey, SecretKey) {
    let mut seed: [u8; 32] = [b' '; 32];
    let len = ::std::cmp::min(32, seed_string.len());
    seed[..len].copy_from_slice(&seed_string.as_bytes()[..len]);

    let (public_key, secret_key) = keypair_from_seed(&Seed(seed));
    (PublicKey(public_key), SecretKey(secret_key))
}

pub fn get_bls_key_pair_from_seed(seed_string: &str) -> (BlsPublicKey, BlsSecretKey) {
    let mut rng = XorShiftRng::seed_from_u64(calculate_hash(&seed_string));
    let bls_secret_key = BlsSecretKey::generate_from_rng(&mut rng);
    (bls_secret_key.get_public_key(), bls_secret_key)
}

impl InMemorySigner {
    pub fn from_seed(account_id: &str, seed_string: &str) -> Self {
        let (public_key, secret_key) = get_key_pair_from_seed(seed_string);
        let (bls_public_key, bls_secret_key) = get_bls_key_pair_from_seed(seed_string);
        InMemorySigner {
            account_id: account_id.to_string(),
            public_key,
            secret_key,
            bls_public_key,
            bls_secret_key,
        }
    }
}

pub trait TestSignedBlock: SignedBlock {
    fn sign_all<T: BLSSigner + AccountSigner>(
        &mut self,
        authorities: &HashMap<AuthorityId, AuthorityStake>,
        signers: &[Arc<T>],
    ) {
        let signer_map: HashMap<AccountId, Arc<T>> =
            signers.iter().map(|s| (s.account_id(), s.clone())).collect();
        for (i, authority_stake) in authorities.iter() {
            self.add_signature(&self.sign(&*signer_map[&authority_stake.account_id]), *i);
        }
    }
}

impl SignedShardBlock {
    pub fn empty(prev: &SignedShardBlockHeader) -> Self {
        SignedShardBlock::new(
            prev.shard_id(),
            prev.index() + 1,
            prev.hash,
            prev.merkle_root_state(),
            vec![],
            vec![],
            CryptoHash::default(),
        )
    }
}

impl TestSignedBlock for SignedShardBlock {}
impl TestSignedBlock for SignedBeaconBlock {}

impl TransactionBody {
    pub fn sign(self, signer: &EDSigner) -> SignedTransaction {
        let signature = signer.sign(self.get_hash().as_ref());
        SignedTransaction::new(signature, self, Some(signer.public_key()))
    }
}

'''
'''--- runtime/primitives/src/traits.rs ---
use std::convert::TryFrom;

/// ToBytes is like Into<Vec<u8>>, but doesn't consume self
pub trait ToBytes: Sized {
    fn to_bytes(&self) -> Vec<u8>;
}

pub trait Base58Encoded:
    for<'a> TryFrom<&'a [u8], Error = Box<std::error::Error>> + ToBytes
{
    fn from_base58(s: &str) -> Result<Self, Box<std::error::Error>> {
        let bytes = bs58::decode(s).into_vec()?;
        Self::try_from(&bytes)
    }

    fn to_base58(&self) -> String {
        let bytes = self.to_bytes();
        bs58::encode(bytes).into_string()
    }
}

'''
'''--- runtime/primitives/src/transaction.rs ---
use std::borrow::Borrow;
use std::convert::{TryFrom, TryInto};
use std::fmt;
use std::hash::{Hash, Hasher};

use protobuf::well_known_types::BytesValue;
use protobuf::SingularPtrField;

use near_protos::receipt as receipt_proto;
use near_protos::signed_transaction as transaction_proto;
use near_protos::Message as ProtoMessage;

use crate::account::AccessKey;
use crate::crypto::signature::{verify, PublicKey, Signature, DEFAULT_SIGNATURE};
use crate::hash::{hash, CryptoHash};
use crate::logging;
use crate::traits::ToBytes;
use crate::types::{AccountId, Balance, CallbackId, Nonce, ShardId, StructSignature};
use crate::utils::{account_to_shard_id, proto_to_result};

pub type LogEntry = String;

#[derive(Hash, PartialEq, Eq, Debug, Clone, Serialize, Deserialize)]
pub enum TransactionBody {
    CreateAccount(CreateAccountTransaction),
    DeployContract(DeployContractTransaction),
    FunctionCall(FunctionCallTransaction),
    SendMoney(SendMoneyTransaction),
    Stake(StakeTransaction),
    SwapKey(SwapKeyTransaction),
    AddKey(AddKeyTransaction),
    DeleteKey(DeleteKeyTransaction),
}

impl TransactionBody {
    pub fn send_money(nonce: Nonce, originator: &str, receiver: &str, amount: u64) -> Self {
        TransactionBody::SendMoney(SendMoneyTransaction {
            nonce,
            originator: originator.to_string(),
            receiver: receiver.to_string(),
            amount,
        })
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct CreateAccountTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub new_account_id: AccountId,
    pub amount: u64,
    pub public_key: Vec<u8>,
}

impl From<transaction_proto::CreateAccountTransaction> for CreateAccountTransaction {
    fn from(t: transaction_proto::CreateAccountTransaction) -> Self {
        CreateAccountTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_account_id: t.new_account_id,
            amount: t.amount,
            public_key: t.public_key,
        }
    }
}

impl From<CreateAccountTransaction> for transaction_proto::CreateAccountTransaction {
    fn from(t: CreateAccountTransaction) -> transaction_proto::CreateAccountTransaction {
        transaction_proto::CreateAccountTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_account_id: t.new_account_id,
            amount: t.amount,
            public_key: t.public_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for CreateAccountTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CreateAccountTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("new_account_id", &format_args!("{}", &self.new_account_id))
            .field("amount", &format_args!("{}", &self.amount))
            .field("public_key", &format_args!("{}", logging::pretty_utf8(&self.public_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct DeployContractTransaction {
    pub nonce: Nonce,
    pub contract_id: AccountId,
    pub wasm_byte_array: Vec<u8>,
}

impl fmt::Debug for DeployContractTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("DeployContractTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("contract_id", &format_args!("{}", &self.contract_id))
            .field(
                "wasm_byte_array",
                &format_args!("{}", logging::pretty_utf8(&self.wasm_byte_array)),
            )
            .finish()
    }
}

impl From<transaction_proto::DeployContractTransaction> for DeployContractTransaction {
    fn from(t: transaction_proto::DeployContractTransaction) -> Self {
        DeployContractTransaction {
            nonce: t.nonce,
            contract_id: t.contract_id,
            wasm_byte_array: t.wasm_byte_array,
        }
    }
}

impl From<DeployContractTransaction> for transaction_proto::DeployContractTransaction {
    fn from(t: DeployContractTransaction) -> transaction_proto::DeployContractTransaction {
        transaction_proto::DeployContractTransaction {
            nonce: t.nonce,
            contract_id: t.contract_id,
            wasm_byte_array: t.wasm_byte_array,
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct FunctionCallTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub contract_id: AccountId,
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub amount: Balance,
}

impl From<transaction_proto::FunctionCallTransaction> for FunctionCallTransaction {
    fn from(t: transaction_proto::FunctionCallTransaction) -> Self {
        FunctionCallTransaction {
            nonce: t.nonce,
            originator: t.originator,
            contract_id: t.contract_id,
            method_name: t.method_name,
            args: t.args,
            amount: t.amount,
        }
    }
}

impl From<FunctionCallTransaction> for transaction_proto::FunctionCallTransaction {
    fn from(t: FunctionCallTransaction) -> transaction_proto::FunctionCallTransaction {
        transaction_proto::FunctionCallTransaction {
            nonce: t.nonce,
            originator: t.originator,
            contract_id: t.contract_id,
            method_name: t.method_name,
            args: t.args,
            amount: t.amount,
            ..Default::default()
        }
    }
}

impl fmt::Debug for FunctionCallTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("FunctionCallTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("contract_id", &format_args!("{}", &self.contract_id))
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("amount", &format_args!("{}", &self.amount))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub struct SendMoneyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub receiver: AccountId,
    pub amount: Balance,
}

impl From<transaction_proto::SendMoneyTransaction> for SendMoneyTransaction {
    fn from(t: transaction_proto::SendMoneyTransaction) -> Self {
        SendMoneyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            receiver: t.receiver,
            amount: t.amount,
        }
    }
}

impl From<SendMoneyTransaction> for transaction_proto::SendMoneyTransaction {
    fn from(t: SendMoneyTransaction) -> transaction_proto::SendMoneyTransaction {
        transaction_proto::SendMoneyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            receiver: t.receiver,
            amount: t.amount,
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub struct StakeTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub amount: Balance,
    pub public_key: String,
    pub bls_public_key: String,
}

impl From<transaction_proto::StakeTransaction> for StakeTransaction {
    fn from(t: transaction_proto::StakeTransaction) -> Self {
        StakeTransaction {
            nonce: t.nonce,
            originator: t.originator,
            amount: t.amount,
            public_key: t.public_key,
            bls_public_key: t.bls_public_key,
        }
    }
}

impl From<StakeTransaction> for transaction_proto::StakeTransaction {
    fn from(t: StakeTransaction) -> transaction_proto::StakeTransaction {
        transaction_proto::StakeTransaction {
            nonce: t.nonce,
            originator: t.originator,
            amount: t.amount,
            public_key: t.public_key,
            bls_public_key: t.bls_public_key,
            ..Default::default()
        }
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct SwapKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    // one of the current keys to the account that will be swapped out
    pub cur_key: Vec<u8>,
    pub new_key: Vec<u8>,
}

impl From<transaction_proto::SwapKeyTransaction> for SwapKeyTransaction {
    fn from(t: transaction_proto::SwapKeyTransaction) -> Self {
        SwapKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            new_key: t.new_key,
        }
    }
}

impl From<SwapKeyTransaction> for transaction_proto::SwapKeyTransaction {
    fn from(t: SwapKeyTransaction) -> transaction_proto::SwapKeyTransaction {
        transaction_proto::SwapKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            new_key: t.new_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for SwapKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("SwapKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("cur_key", &format_args!("{}", logging::pretty_utf8(&self.cur_key)))
            .field("new_key", &format_args!("{}", logging::pretty_utf8(&self.new_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct AddKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub new_key: Vec<u8>,
    pub access_key: Option<AccessKey>,
}

impl From<transaction_proto::AddKeyTransaction> for AddKeyTransaction {
    fn from(t: transaction_proto::AddKeyTransaction) -> Self {
        AddKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_key: t.new_key,
            access_key: t.access_key.into_option().map(AccessKey::from),
        }
    }
}

impl From<AddKeyTransaction> for transaction_proto::AddKeyTransaction {
    fn from(t: AddKeyTransaction) -> transaction_proto::AddKeyTransaction {
        transaction_proto::AddKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            new_key: t.new_key,
            access_key: SingularPtrField::from_option(t.access_key.map(std::convert::Into::into)),
            ..Default::default()
        }
    }
}

impl fmt::Debug for AddKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AddKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("new_key", &format_args!("{}", logging::pretty_utf8(&self.new_key)))
            .finish()
    }
}

#[derive(Hash, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct DeleteKeyTransaction {
    pub nonce: Nonce,
    pub originator: AccountId,
    pub cur_key: Vec<u8>,
}

impl From<transaction_proto::DeleteKeyTransaction> for DeleteKeyTransaction {
    fn from(t: transaction_proto::DeleteKeyTransaction) -> Self {
        DeleteKeyTransaction { nonce: t.nonce, originator: t.originator, cur_key: t.cur_key }
    }
}

impl From<DeleteKeyTransaction> for transaction_proto::DeleteKeyTransaction {
    fn from(t: DeleteKeyTransaction) -> transaction_proto::DeleteKeyTransaction {
        transaction_proto::DeleteKeyTransaction {
            nonce: t.nonce,
            originator: t.originator,
            cur_key: t.cur_key,
            ..Default::default()
        }
    }
}

impl fmt::Debug for DeleteKeyTransaction {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("DeleteKeyTransaction")
            .field("nonce", &format_args!("{}", &self.nonce))
            .field("originator", &format_args!("{}", &self.originator))
            .field("cur_key", &format_args!("{}", logging::pretty_utf8(&self.cur_key)))
            .finish()
    }
}

impl TransactionBody {
    pub fn get_nonce(&self) -> u64 {
        match self {
            TransactionBody::Stake(t) => t.nonce,
            TransactionBody::SendMoney(t) => t.nonce,
            TransactionBody::DeployContract(t) => t.nonce,
            TransactionBody::FunctionCall(t) => t.nonce,
            TransactionBody::CreateAccount(t) => t.nonce,
            TransactionBody::SwapKey(t) => t.nonce,
            TransactionBody::AddKey(t) => t.nonce,
            TransactionBody::DeleteKey(t) => t.nonce,
        }
    }

    pub fn get_originator(&self) -> AccountId {
        match self {
            TransactionBody::Stake(t) => t.originator.clone(),
            TransactionBody::SendMoney(t) => t.originator.clone(),
            TransactionBody::DeployContract(t) => t.contract_id.clone(),
            TransactionBody::FunctionCall(t) => t.originator.clone(),
            TransactionBody::CreateAccount(t) => t.originator.clone(),
            TransactionBody::SwapKey(t) => t.originator.clone(),
            TransactionBody::AddKey(t) => t.originator.clone(),
            TransactionBody::DeleteKey(t) => t.originator.clone(),
        }
    }

    /// Returns option contract_id for Mana and Gas accounting
    pub fn get_contract_id(&self) -> Option<AccountId> {
        match self {
            TransactionBody::CreateAccount(_) => None,
            TransactionBody::DeployContract(t) => Some(t.contract_id.clone()),
            TransactionBody::FunctionCall(t) => Some(t.contract_id.clone()),
            TransactionBody::SendMoney(t) => Some(t.receiver.clone()),
            TransactionBody::Stake(_) => None,
            TransactionBody::SwapKey(_) => None,
            TransactionBody::AddKey(_) => None,
            TransactionBody::DeleteKey(_) => None,
        }
    }

    pub fn get_hash(&self) -> CryptoHash {
        let bytes = match self.clone() {
            TransactionBody::CreateAccount(t) => {
                let proto: transaction_proto::CreateAccountTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::DeployContract(t) => {
                let proto: transaction_proto::DeployContractTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::FunctionCall(t) => {
                let proto: transaction_proto::FunctionCallTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::SendMoney(t) => {
                let proto: transaction_proto::SendMoneyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::Stake(t) => {
                let proto: transaction_proto::StakeTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::SwapKey(t) => {
                let proto: transaction_proto::SwapKeyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::AddKey(t) => {
                let proto: transaction_proto::AddKeyTransaction = t.into();
                proto.write_to_bytes()
            }
            TransactionBody::DeleteKey(t) => {
                let proto: transaction_proto::DeleteKeyTransaction = t.into();
                proto.write_to_bytes()
            }
        };
        let bytes = bytes.unwrap();
        hash(&bytes)
    }
}

#[derive(Eq, Debug, Clone, Serialize, Deserialize)]
pub struct SignedTransaction {
    pub body: TransactionBody,
    pub signature: StructSignature,
    // In case this TX uses AccessKey, it needs to provide the public_key
    pub public_key: Option<PublicKey>,
    hash: CryptoHash,
}

impl SignedTransaction {
    pub fn new(
        signature: StructSignature,
        body: TransactionBody,
        public_key: Option<PublicKey>,
    ) -> Self {
        let hash = body.get_hash();
        Self { signature, body, public_key, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }

    // this is for tests
    pub fn empty() -> SignedTransaction {
        let body = TransactionBody::SendMoney(SendMoneyTransaction {
            nonce: 0,
            originator: AccountId::default(),
            receiver: AccountId::default(),
            amount: 0,
        });
        SignedTransaction {
            signature: DEFAULT_SIGNATURE,
            body,
            public_key: None,
            hash: CryptoHash::default(),
        }
    }
}

impl Hash for SignedTransaction {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.hash.hash(state)
    }
}

impl PartialEq for SignedTransaction {
    fn eq(&self, other: &SignedTransaction) -> bool {
        self.hash == other.hash
            && self.signature == other.signature
            && self.public_key == other.public_key
    }
}

impl TryFrom<transaction_proto::SignedTransaction> for SignedTransaction {
    type Error = String;

    fn try_from(t: transaction_proto::SignedTransaction) -> Result<Self, Self::Error> {
        let mut bytes;
        let body = match t.body {
            Some(transaction_proto::SignedTransaction_oneof_body::create_account(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::CreateAccount(CreateAccountTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::deploy_contract(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::DeployContract(DeployContractTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::function_call(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::FunctionCall(FunctionCallTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::send_money(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::SendMoney(SendMoneyTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::stake(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::Stake(StakeTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::swap_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::SwapKey(SwapKeyTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::add_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::AddKey(AddKeyTransaction::from(t))
            }
            Some(transaction_proto::SignedTransaction_oneof_body::delete_key(t)) => {
                bytes = t.write_to_bytes();
                TransactionBody::DeleteKey(DeleteKeyTransaction::from(t))
            }
            None => return Err("No such transaction body type".to_string()),
        };
        let bytes = bytes.map_err(|e| format!("{}", e))?;
        let hash = hash(&bytes);
        let public_key: Option<PublicKey> = t
            .public_key
            .into_option()
            .map(|v| PublicKey::try_from(&v.value as &[u8]))
            .transpose()
            .map_err(|e| format!("{}", e))?;
        let signature: Signature =
            Signature::try_from(&t.signature as &[u8]).map_err(|e| format!("{}", e))?;
        Ok(SignedTransaction { body, signature, public_key, hash })
    }
}

impl From<SignedTransaction> for transaction_proto::SignedTransaction {
    fn from(tx: SignedTransaction) -> transaction_proto::SignedTransaction {
        let body = match tx.body {
            TransactionBody::CreateAccount(t) => {
                transaction_proto::SignedTransaction_oneof_body::create_account(t.into())
            }
            TransactionBody::DeployContract(t) => {
                transaction_proto::SignedTransaction_oneof_body::deploy_contract(t.into())
            }
            TransactionBody::FunctionCall(t) => {
                transaction_proto::SignedTransaction_oneof_body::function_call(t.into())
            }
            TransactionBody::SendMoney(t) => {
                transaction_proto::SignedTransaction_oneof_body::send_money(t.into())
            }
            TransactionBody::Stake(t) => {
                transaction_proto::SignedTransaction_oneof_body::stake(t.into())
            }
            TransactionBody::SwapKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::swap_key(t.into())
            }
            TransactionBody::AddKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::add_key(t.into())
            }
            TransactionBody::DeleteKey(t) => {
                transaction_proto::SignedTransaction_oneof_body::delete_key(t.into())
            }
        };
        transaction_proto::SignedTransaction {
            body: Some(body),
            signature: tx.signature.as_ref().to_vec(),
            public_key: SingularPtrField::from_option(tx.public_key.map(|v| {
                let mut res = BytesValue::new();
                res.set_value(v.to_bytes());
                res
            })),
            ..Default::default()
        }
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, Debug, PartialEq, Eq)]
pub enum ReceiptBody {
    NewCall(AsyncCall),
    Callback(CallbackResult),
    Refund(u64),
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct AsyncCall {
    pub amount: Balance,
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub callback: Option<CallbackInfo>,
    pub refund_account: AccountId,
}

impl TryFrom<receipt_proto::AsyncCall> for AsyncCall {
    type Error = String;

    fn try_from(proto: receipt_proto::AsyncCall) -> Result<Self, Self::Error> {
        Ok(AsyncCall {
            amount: proto.amount,
            method_name: proto.method_name,
            args: proto.args,
            callback: proto.callback.into_option().map(std::convert::Into::into),
            refund_account: proto.refund_account,
        })
    }
}

impl From<AsyncCall> for receipt_proto::AsyncCall {
    fn from(call: AsyncCall) -> Self {
        receipt_proto::AsyncCall {
            amount: call.amount,
            method_name: call.method_name,
            args: call.args,
            callback: SingularPtrField::from_option(call.callback.map(std::convert::Into::into)),
            refund_account: call.refund_account,
            ..Default::default()
        }
    }
}

impl AsyncCall {
    pub fn new(
        method_name: Vec<u8>,
        args: Vec<u8>,
        amount: Balance,
        refund_account: AccountId,
    ) -> Self {
        AsyncCall { amount, method_name, args, callback: None, refund_account }
    }
}

impl fmt::Debug for AsyncCall {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("AsyncCall")
            .field("amount", &format_args!("{}", &self.amount))
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("callback", &self.callback)
            .field("refund_account", &self.refund_account)
            .finish()
    }
}

#[derive(Clone, Serialize, Deserialize)]
pub struct Callback {
    pub method_name: Vec<u8>,
    pub args: Vec<u8>,
    pub results: Vec<Option<Vec<u8>>>,
    pub amount: Balance,
    pub callback: Option<CallbackInfo>,
    pub result_counter: usize,
    pub refund_account: AccountId,
}

impl Callback {
    pub fn new(
        method_name: Vec<u8>,
        args: Vec<u8>,
        amount: Balance,
        refund_account: AccountId,
    ) -> Self {
        Callback {
            method_name,
            args,
            results: vec![],
            amount,
            callback: None,
            result_counter: 0,
            refund_account,
        }
    }
}

impl fmt::Debug for Callback {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("Callback")
            .field("method_name", &format_args!("{}", logging::pretty_utf8(&self.method_name)))
            .field("args", &format_args!("{}", logging::pretty_utf8(&self.args)))
            .field("results", &format_args!("{}", logging::pretty_results(&self.results)))
            .field("amount", &format_args!("{}", &self.amount))
            .field("callback", &self.callback)
            .field("result_counter", &format_args!("{}", &self.result_counter))
            .field("refund_account", &self.refund_account)
            .finish()
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CallbackInfo {
    // callback id
    pub id: CallbackId,
    // index to write to
    pub result_index: usize,
    // receiver
    pub receiver: AccountId,
}

impl From<receipt_proto::CallbackInfo> for CallbackInfo {
    fn from(proto: receipt_proto::CallbackInfo) -> Self {
        CallbackInfo {
            id: proto.id,
            result_index: proto.result_index as usize,
            receiver: proto.receiver,
        }
    }
}

impl From<CallbackInfo> for receipt_proto::CallbackInfo {
    fn from(info: CallbackInfo) -> Self {
        receipt_proto::CallbackInfo {
            id: info.id,
            result_index: info.result_index as u64,
            receiver: info.receiver,
            ..Default::default()
        }
    }
}

impl CallbackInfo {
    pub fn new(id: CallbackId, result_index: usize, receiver: AccountId) -> Self {
        CallbackInfo { id, result_index, receiver }
    }
}

impl fmt::Debug for CallbackInfo {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CallbackInfo")
            .field("id", &format_args!("{}", logging::pretty_utf8(&self.id)))
            .field("result_index", &format_args!("{}", self.result_index))
            .field("receiver", &format_args!("{}", self.receiver))
            .finish()
    }
}

#[derive(Hash, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CallbackResult {
    // callback id
    pub info: CallbackInfo,
    // callback result
    pub result: Option<Vec<u8>>,
}

impl TryFrom<receipt_proto::CallbackResult> for CallbackResult {
    type Error = String;

    fn try_from(proto: receipt_proto::CallbackResult) -> Result<Self, Self::Error> {
        match proto_to_result(proto.info) {
            Ok(info) => Ok(CallbackResult {
                info: info.into(),
                result: proto.result.into_option().map(|v| v.value),
            }),
            Err(e) => Err(e),
        }
    }
}

impl From<CallbackResult> for receipt_proto::CallbackResult {
    fn from(result: CallbackResult) -> Self {
        receipt_proto::CallbackResult {
            info: SingularPtrField::some(result.info.into()),
            result: SingularPtrField::from_option(result.result.map(|v| {
                let mut res = BytesValue::new();
                res.set_value(v);
                res
            })),
            ..Default::default()
        }
    }
}

impl CallbackResult {
    pub fn new(info: CallbackInfo, result: Option<Vec<u8>>) -> Self {
        CallbackResult { info, result }
    }
}

impl fmt::Debug for CallbackResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("CallbackResult")
            .field("info", &self.info)
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone)]
pub struct ReceiptTransaction {
    // sender is the immediate predecessor
    pub originator: AccountId,
    pub receiver: AccountId,
    // nonce will be a hash
    pub nonce: CryptoHash,
    pub body: ReceiptBody,
}

impl TryFrom<receipt_proto::ReceiptTransaction> for ReceiptTransaction {
    type Error = String;

    fn try_from(proto: receipt_proto::ReceiptTransaction) -> Result<Self, Self::Error> {
        let body = match proto.body {
            Some(receipt_proto::ReceiptTransaction_oneof_body::new_call(new_call)) => {
                new_call.try_into().map(ReceiptBody::NewCall)
            }
            Some(receipt_proto::ReceiptTransaction_oneof_body::callback(callback)) => {
                callback.try_into().map(ReceiptBody::Callback)
            }
            Some(receipt_proto::ReceiptTransaction_oneof_body::refund(refund)) => {
                Ok(ReceiptBody::Refund(refund))
            }
            None => Err("No such receipt body type".to_string()),
        };
        match body {
            Ok(body) => Ok(ReceiptTransaction {
                originator: proto.originator,
                receiver: proto.receiver,
                nonce: proto.nonce.try_into()?,
                body,
            }),
            Err(e) => Err(e),
        }
    }
}

impl From<ReceiptTransaction> for receipt_proto::ReceiptTransaction {
    fn from(t: ReceiptTransaction) -> Self {
        let body = match t.body {
            ReceiptBody::NewCall(new_call) => {
                receipt_proto::ReceiptTransaction_oneof_body::new_call(new_call.into())
            }
            ReceiptBody::Callback(callback) => {
                receipt_proto::ReceiptTransaction_oneof_body::callback(callback.into())
            }
            ReceiptBody::Refund(refund) => {
                receipt_proto::ReceiptTransaction_oneof_body::refund(refund)
            }
        };
        receipt_proto::ReceiptTransaction {
            originator: t.originator,
            receiver: t.receiver,
            nonce: t.nonce.into(),
            body: Some(body),
            ..Default::default()
        }
    }
}

impl Borrow<CryptoHash> for ReceiptTransaction {
    fn borrow(&self) -> &CryptoHash {
        &self.nonce
    }
}

impl ReceiptTransaction {
    pub fn new(
        originator: AccountId,
        receiver: AccountId,
        nonce: CryptoHash,
        body: ReceiptBody,
    ) -> Self {
        ReceiptTransaction { originator, receiver, nonce, body }
    }

    pub fn shard_id(&self) -> ShardId {
        account_to_shard_id(&self.receiver)
    }
}

#[derive(Hash, Debug, PartialEq, Eq, Clone, Serialize, Deserialize)]
pub enum TransactionStatus {
    Unknown,
    Completed,
    Failed,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub enum FinalTransactionStatus {
    Unknown,
    Started,
    Failed,
    Completed,
}

impl FinalTransactionStatus {
    pub fn to_code(&self) -> u64 {
        match self {
            FinalTransactionStatus::Completed => 0,
            FinalTransactionStatus::Failed => 1,
            FinalTransactionStatus::Started => 2,
            FinalTransactionStatus::Unknown => std::u64::MAX,
        }
    }
}

impl Default for TransactionStatus {
    fn default() -> Self {
        TransactionStatus::Unknown
    }
}

#[derive(PartialEq, Clone, Serialize, Deserialize, Default)]
pub struct TransactionResult {
    /// Transaction status.
    pub status: TransactionStatus,
    /// Logs from this transaction.
    pub logs: Vec<LogEntry>,
    /// Receipt ids generated by this transaction.
    pub receipts: Vec<CryptoHash>,
    /// Execution Result
    pub result: Option<Vec<u8>>,
}

impl fmt::Debug for TransactionResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("TransactionResult")
            .field("status", &self.status)
            .field("logs", &format_args!("{}", logging::pretty_vec(&self.logs)))
            .field("receipts", &format_args!("{}", logging::pretty_vec(&self.receipts)))
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

/// Logs for transaction or receipt with given hash.
#[derive(PartialEq, Clone, Serialize, Deserialize)]
pub struct TransactionLogs {
    pub hash: CryptoHash,
    pub lines: Vec<LogEntry>,
    pub receipts: Vec<CryptoHash>,
    pub result: Option<Vec<u8>>,
}

impl fmt::Debug for TransactionLogs {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("TransactionLogs")
            .field("hash", &self.hash)
            .field("lines", &format_args!("{}", logging::pretty_vec(&self.lines)))
            .field("receipts", &format_args!("{}", logging::pretty_vec(&self.receipts)))
            .field("result", &format_args!("{}", logging::pretty_result(&self.result)))
            .finish()
    }
}

/// Result of transaction and all of subsequent the receipts.
#[derive(PartialEq, Clone, Serialize, Deserialize)]
pub struct FinalTransactionResult {
    /// Status of the whole transaction and it's receipts.
    pub status: FinalTransactionStatus,
    /// Logs per transaction / receipt ids ordered in DFS manner.
    pub logs: Vec<TransactionLogs>,
}

impl fmt::Debug for FinalTransactionResult {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("FinalTransactionResult")
            .field("status", &self.status)
            .field("logs", &format_args!("{}", logging::pretty_vec(&self.logs)))
            .finish()
    }
}

impl FinalTransactionResult {
    pub fn final_log(&self) -> String {
        let mut logs = vec![];
        for log in &self.logs {
            for line in &log.lines {
                logs.push(line.clone());
            }
        }
        logs.join("\n")
    }

    pub fn last_result(&self) -> Vec<u8> {
        for log in self.logs.iter().rev() {
            if let Some(r) = &log.result {
                return r.clone();
            }
        }
        vec![]
    }
}

/// Represents address of certain transaction within block
#[derive(Debug, PartialEq, Clone, Serialize, Deserialize)]
pub struct TransactionAddress {
    /// Block hash
    pub block_hash: CryptoHash,
    /// Transaction index within the block. If it is a receipt,
    /// index is the index in the receipt block.
    pub index: usize,
    /// Only for receipts. The shard that the receipt
    /// block is supposed to go
    pub shard_id: Option<ShardId>,
}

pub fn verify_transaction_signature(
    transaction: &SignedTransaction,
    public_keys: &[PublicKey],
) -> bool {
    let hash = transaction.get_hash();
    let hash = hash.as_ref();
    public_keys.iter().any(|key| verify(&hash, &transaction.signature, &key))
}

#[cfg(test)]
mod tests {
    use crate::crypto::signature::{get_key_pair, sign};

    use super::*;

    #[test]
    fn test_verify_transaction() {
        let (public_key, private_key) = get_key_pair();
        let mut transaction = SignedTransaction::empty();
        transaction.signature = sign(&transaction.hash.as_ref(), &private_key);
        let (wrong_public_key, _) = get_key_pair();
        let valid_keys = vec![public_key, wrong_public_key];
        assert!(verify_transaction_signature(&transaction, &valid_keys));

        let invalid_keys = vec![wrong_public_key];
        assert!(!verify_transaction_signature(&transaction, &invalid_keys));
    }
}

'''
'''--- runtime/primitives/src/types.rs ---
use std::convert::TryFrom;

use crate::crypto::aggregate_signature::{BlsPublicKey, BlsSignature};
use crate::crypto::signature::{bs58_serializer, PublicKey, Signature};
use crate::hash::CryptoHash;
use crate::traits::Base58Encoded;
use near_protos::types as types_proto;

/// Public key alias. Used to human readable public key.
#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct ReadablePublicKey(pub String);
#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Hash, Clone)]
pub struct ReadableBlsPublicKey(pub String);
/// Account identifier. Provides access to user's state.
pub type AccountId = String;
// TODO: Separate cryptographic hash from the hashmap hash.
/// Signature of a struct, i.e. signature of the struct's hash. It is a simple signature, not to be
/// confused with the multisig.
pub type StructSignature = Signature;
/// Hash used by a struct implementing the Merkle tree.
pub type MerkleHash = CryptoHash;
/// Authority identifier in current group.
pub type AuthorityId = usize;
/// Mask which authorities participated in multi sign.
pub type AuthorityMask = Vec<bool>;
/// Part of the signature.
pub type PartialSignature = BlsSignature;
/// Monetary balance of an account or an amount for transfer.
pub type Balance = u64;
/// StorageUsage is used to count the amount of storage used by a contract.
pub type StorageUsage = u64;
/// StorageUsageChange is used to count the storage usage within a single contract call.
pub type StorageUsageChange = i64;
/// Nonce for transactions.
pub type Nonce = u64;

pub type BlockIndex = u64;

pub type ShardId = u32;

pub type ReceiptId = Vec<u8>;
pub type CallbackId = Vec<u8>;

/// epoch for authority
pub type Epoch = u64;
/// slot for authority
pub type Slot = u64;

#[derive(Clone, Hash, PartialEq, Eq, Debug)]
pub enum PromiseId {
    Receipt(ReceiptId),
    Callback(CallbackId),
    Joiner(Vec<ReceiptId>),
}

#[derive(Debug, PartialEq, Eq, Serialize, Deserialize, Hash, Clone)]
pub enum BlockId {
    Number(BlockIndex),
    Hash(CryptoHash),
}

/// Stores authority and its stake.
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct AuthorityStake {
    /// Account that stakes money.
    pub account_id: AccountId,
    /// ED25591 Public key of the proposed authority.
    pub public_key: PublicKey,
    /// BLS Public key of the proposed authority.
    #[serde(with = "bs58_serializer")]
    pub bls_public_key: BlsPublicKey,
    /// Stake / weight of the authority.
    pub amount: u64,
}

impl TryFrom<types_proto::AuthorityStake> for AuthorityStake {
    type Error = String;

    fn try_from(proto: types_proto::AuthorityStake) -> Result<Self, Self::Error> {
        let bls_key = BlsPublicKey::from_base58(&proto.bls_public_key)
            .map_err(|e| format!("cannot decode signature {:?}", e))?;
        Ok(AuthorityStake {
            account_id: proto.account_id,
            public_key: PublicKey::try_from(proto.public_key.as_str())?,
            bls_public_key: bls_key,
            amount: proto.amount,
        })
    }
}

impl From<AuthorityStake> for types_proto::AuthorityStake {
    fn from(authority: AuthorityStake) -> Self {
        types_proto::AuthorityStake {
            account_id: authority.account_id,
            public_key: authority.public_key.to_string(),
            bls_public_key: authority.bls_public_key.to_base58(),
            amount: authority.amount,
            ..Default::default()
        }
    }
}

impl PartialEq for AuthorityStake {
    fn eq(&self, other: &Self) -> bool {
        self.account_id == other.account_id && self.public_key == other.public_key
    }
}

impl Eq for AuthorityStake {}

// network types (put here to avoid cyclic dependency)
/// unique identifier for nodes on the network
// Use hash for now
pub type PeerId = CryptoHash;

'''
'''--- runtime/primitives/src/utils.rs ---
use bs58;
use byteorder::{LittleEndian, WriteBytesExt};
use lazy_static::lazy_static;
use protobuf::{well_known_types::StringValue, SingularPtrField};
use std::convert::{TryFrom, TryInto};

use crate::crypto::signature::PublicKey;
use crate::hash::{hash, CryptoHash};
use crate::types::{AccountId, ShardId};
use regex::Regex;

pub mod col {
    pub const ACCOUNT: &[u8] = &[0];
    pub const CALLBACK: &[u8] = &[1];
    pub const CODE: &[u8] = &[2];
    pub const ACCESS_KEY: &[u8] = &[3];
}

fn key_for_column_account_id(column: &[u8], account_key: &AccountId) -> Vec<u8> {
    let mut key = column.to_vec();
    key.append(&mut account_key.clone().into_bytes());
    key
}

pub fn key_for_account(account_key: &AccountId) -> Vec<u8> {
    key_for_column_account_id(col::ACCOUNT, account_key)
}

pub fn prefix_for_access_key(account_id: &AccountId) -> Vec<u8> {
    let mut key = key_for_column_account_id(col::ACCESS_KEY, account_id);
    key.extend_from_slice(col::ACCESS_KEY);
    key
}

pub fn key_for_access_key(account_id: &AccountId, public_key: &PublicKey) -> Vec<u8> {
    let mut key = key_for_column_account_id(col::ACCESS_KEY, account_id);
    key.extend_from_slice(col::ACCESS_KEY);
    key.extend_from_slice(public_key.as_ref());
    key
}

pub fn key_for_code(account_key: &AccountId) -> Vec<u8> {
    key_for_column_account_id(col::CODE, account_key)
}

pub fn key_for_callback(id: &[u8]) -> Vec<u8> {
    let mut key = col::CALLBACK.to_vec();
    key.extend_from_slice(id);
    key
}

pub fn create_nonce_with_nonce(base: &CryptoHash, salt: u64) -> CryptoHash {
    let mut nonce: Vec<u8> = base.as_ref().to_owned();
    nonce.append(&mut index_to_bytes(salt));
    hash(&nonce)
}

pub fn index_to_bytes(index: u64) -> Vec<u8> {
    let mut bytes = vec![];
    bytes.write_u64::<LittleEndian>(index).expect("writing to bytes failed");
    bytes
}

#[allow(unused)]
pub fn account_to_shard_id(account_id: &AccountId) -> ShardId {
    // TODO: change to real sharding
    0
}

pub fn bs58_vec2str(buf: &[u8]) -> String {
    bs58::encode(buf).into_string()
}

lazy_static! {
    static ref VALID_ACCOUNT_ID: Regex = Regex::new(r"^[a-z0-9@._\-]{5,32}$").unwrap();
}

pub fn is_valid_account_id(account_id: &AccountId) -> bool {
    VALID_ACCOUNT_ID.is_match(account_id)
}

pub fn to_string_value(s: String) -> StringValue {
    let mut res = StringValue::new();
    res.set_value(s);
    res
}

pub fn proto_to_result<T>(proto: SingularPtrField<T>) -> Result<T, String> {
    proto.into_option().ok_or_else(|| "Bad Proto".to_string())
}

pub fn proto_to_type<T, U>(proto: SingularPtrField<T>) -> Result<U, String>
where
    U: TryFrom<T, Error = String>,
{
    proto_to_result(proto).and_then(TryInto::try_into)
}

'''
'''--- runtime/protos/Cargo.toml ---
[package]
name = "near-protos"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"
build = "build.rs"

[dependencies]
base64 = { version = "0.10.0", optional = true }
protobuf = { version = "2.2.4", features = ["with-bytes"] }
serde = { version = "1.0", optional = true }
serde_derive = { version = "1.0", optional = true }

[build-dependencies]
protos-autogen = { path = "../../protos/builder" }

[features]
with-serde = ["base64", "serde", "serde_derive"]

'''
'''--- runtime/protos/README.md ---
## Development
`.proto` files are under the `protos` directory. To add/delete protos, one also needs to change the include macro at the beginning of `src/lib.rs`. 

For example, if `example.proto` is added to `protos`, `include!(concat!(env!("OUT_DIR"), "/example.rs"))` needs to be added to `src/lib.rs`.
'''
'''--- runtime/protos/build.rs ---
use protos_autogen;

fn main() {
    protos_autogen::autogenerate();
}

'''
'''--- runtime/protos/src/lib.rs ---
include!(concat!(env!("OUT_DIR"), "/access_key.rs"));
include!(concat!(env!("OUT_DIR"), "/chain.rs"));
include!(concat!(env!("OUT_DIR"), "/network.rs"));
include!(concat!(env!("OUT_DIR"), "/nightshade.rs"));
include!(concat!(env!("OUT_DIR"), "/receipt.rs"));
include!(concat!(env!("OUT_DIR"), "/signed_transaction.rs"));
include!(concat!(env!("OUT_DIR"), "/types.rs"));

pub use protobuf::Message;

#[cfg(feature = "with-serde")]
pub mod serde;

'''
'''--- runtime/protos/src/serde.rs ---
pub mod b64_format {
    use base64;
    use serde::{Deserialize, Deserializer, Serializer};
    use protobuf::Message;

    pub fn serialize<S, T>(s: &T, serializer: S) -> Result<S::Ok, S::Error>
        where S: Serializer,
              T: Message,
    {
        let bytes = s.write_to_bytes().map_err(serde::ser::Error::custom)?;
        let encoded = base64::encode(&bytes);
        serializer.serialize_str(&encoded)
    }

    pub fn deserialize<'de, D, T>(deserializer: D) -> Result<T, D::Error>
        where D: Deserializer<'de>,
              T: Message,
    {
        let s = String::deserialize(deserializer)?;
        let bytes = base64::decode(&s).map_err(serde::de::Error::custom)?;
        Ok(protobuf::parse_from_bytes(&bytes).map_err(serde::de::Error::custom)?)
    }
}

'''
'''--- runtime/repo/Cargo.toml ---
[package]
name = "repo"
version = "0.1.0"
authors = ["luomijie <zhiwei-luo@hotmail.com>"]
edition = "2018"

[dependencies]

'''
'''--- runtime/repo/src/ds.rs ---

'''
'''--- runtime/repo/src/fs.rs ---
use crate::block::Cid;
use StoreItem;

#[derive(Clone, Debug)]
pub struct FsRepo {
    root: PathBuf,
    cids: Arc<Mutex<HashSet<Cid>>>,
    keystore:StoreItem,
    chain:StoreItem,
    wallet:StoreItem,
}

'''
'''--- runtime/repo/src/lib.rs ---
//! Repo functionality for Lighthouse.
//!
//! Provides the following stores:
//!
//! - `DataStore`: an on-disk store backed by leveldb. Used in production.
//! - `MemoryStore`: an in-memory store backed by a hash-map. Used for testing.
//!
//! Provides a simple API for storing/retrieving all types that sometimes needs type-hints. See
//! tests for implementation examples.

use crate::error::Error;
use crate::block::Cid;

const API_FILE: &str = "api";
const CONFIG_FILE_NAME: &str = "config.json";
const LOCK_FILE: &str = "repo.lock";
const VERSION_FILENAME: &str = "version";
const WALLET_DATASTORE_FILENAME_PREFIX: &str ="wallet";
const CHAIN_DATASTORE_FILENAME_PREFIX: &str ="chain";
const DEALS_DATASTROE_FILENAME_PREFIX: &str = "deals";
const SNAPSHOT_DATASTORE_FILENAME_PREFIX: &str ="snapshots";

/// Repo is a representation of all persistent data in a FileSys node.
pub trait Repo {

    /// WalletDatastore is a specific storage solution, only used to store sensitive wallet information.
    fn WalletDatastore()-> Resut<(),Error>;

    /// KeystoreDataStore is a specific storage solution, only used to store local keystore information.
    fn KeystoreDataStore() -> Result<(),Error>;

    /// ChainDatastore is a specific storage solution, only used to store already validated chain data.
    fn ChainDatastore() -> Result<(),Error>;

    /// DealsDatastore holds deals data.
    fn DealsDatastore() -> Result<(),Error>;

    /// Version returns the current repo version.
    fn Version() -> Result<(),Error>;

    ///	Path returns the repo path.
    fn Path() -> Result<(),Error>;

}

/// A unique column identifier.
pub enum DBColumn {
    Wallet,
    Keystore,
    BeaconBlock,
    BeaconState,
    BeaconChain,
}

impl<'a> Into<&'a str> for DBColumn {
    /// Returns a `&str` that can be used for keying a key-value data base.
    fn into(self) -> &'a str {
        match self {
            DBColumn::Wallet => &"wat",
            DBColumn::Keystore => &"kst",
            DBColumn::BeaconBlock => &"blk",
            DBColumn::BeaconState => &"ste",
            DBColumn::BeaconChain => &"bch",
        }
    }
}

/// An item that may be stored in a `Store`.
///
/// Provides default methods that are suitable for most applications, however when overridden they
/// provide full customizability of `Store` operations.
pub trait StoreItem : Sized {

    /// Identifies which column this item should be placed in.
    fn db_column() -> DBColumn;

    /// Serialize `self` as bytes.
    fn as_store_bytes(&self) -> Vec<u8>;

    /// De-serialize `self` from bytes.
    fn from_store_bytes(bytes: &mut [u8]) -> Result<Self, Error>;

    /// Store `self`.
    fn db_put(&self, store: &impl Store, key: &Cid) -> Result<(), Error> {
        let column = Self::db_column().into();
        let key = key.as_bytes();

        store
            .put_bytes(column, key, &self.as_store_bytes())
            .map_err(Into::into)
    }

    /// Retrieve an instance of `Self`.
    fn db_get(store: &impl Store, key: &Cid) -> Result<Option<Self>, Error> {
        let column = Self::db_column().into();
        let key = key.as_bytes();

        match store.get_bytes(column, key)? {
            Some(mut bytes) => Ok(Some(Self::from_store_bytes(&mut bytes[..])?)),
            None => Ok(None),
        }
    }

    /// Return `true` if an instance of `Self` exists in `Store`.
    fn db_exists(store: &impl Store, key: &Cid) -> Result<bool, Error> {
        let column = Self::db_column().into();
        let key = key.as_bytes();

        store.key_exists(column, key)
    }

    /// Delete `self` from the `Store`.
    fn db_delete(store: &impl Store, key: &Cid) -> Result<(), Error> {
        let column = Self::db_column().into();
        let key = key.as_bytes();

        store.key_delete(column, key)
    }

}

/// An object capable of storing and retrieving objects implementing `StoreItem`.
///
/// A `Store` is fundamentally backed by a key-value database, however it provides support for
/// columns. A simple column implementation might involve prefixing a key with some bytes unique to
/// each column.
pub trait DataStore : Sync + Send + Sized {
    /// Store an item in `Self`.
    fn put(&self, key: &Hash256, item: &impl StoreItem) -> Result<(), Error> {
        item.db_put(self, key)
    }

    /// Retrieve an item from `Self`.
    fn get<I: StoreItem>(&self, key: &Cid) -> Result<Option<I>, Error> {
        I::db_get(self, key)
    }

    /// Returns `true` if the given key represents an item in `Self`.
    fn exists<I: StoreItem>(&self, key: &Cid) -> Result<bool, Error> {
        I::db_exists(self, key)
    }

    /// Remove an item from `Self`.
    fn delete<I: StoreItem>(&self, key: &Cid) -> Result<(), Error> {
        I::db_delete(self, key)
    }

    /// Given the root of an existing block in the store (`start_block_root`), return a parent
    /// block with the specified `slot`.
    ///
    /// Returns `None` if no parent block exists at that slot, or if `slot` is greater than the
    /// slot of `start_block_root`.
    fn get_block_at_preceeding_slot(
        &self,
        start_block_root: Cid,
        slot: Slot,
    ) -> Result<Option<(Cid, BeaconBlock)>, Error> {
        block_at_slot::get_block_at_preceeding_slot(self, slot, start_block_root)
    }

    /// Retrieve some bytes in `column` with `key`.
    fn get_bytes(&self, column: &str, key: &[u8]) -> Result<Option<Vec<u8>>, Error>;

    /// Store some `value` in `column`, indexed with `key`.
    fn put_bytes(&self, column: &str, key: &[u8], value: &[u8]) -> Result<(), Error>;

    /// Return `true` if `key` exists in `column`.
    fn key_exists(&self, column: &str, key: &[u8]) -> Result<bool, Error>;

    /// Removes `key` from `column`.
    fn key_delete(&self, column: &str, key: &[u8]) -> Result<(), Error>;
}

#[cfg(test)]
mod tests {
    #[test]
    fn it_works() {
        assert_eq!(2 + 2, 4);
    }
}

'''
'''--- runtime/repo/src/mod.rs ---

'''
'''--- runtime/runtime/Cargo.toml ---
[package]
name = "node-runtime"
version = "0.0.1"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
bincode = "1.0.0"
byteorder = "1.2"
serde = "1.0"
serde_derive = "1.0"
serde_json = "1.0"
log = "0.4"
kvdb = "0.1"
rand = "0.6"
rand_xorshift = "0.1"
ethash = "0.3"
ethereum-bigint = "0.2"

near-primitives = { path = "../../core/primitives" }
near-store = { path = "../../core/store" }
near-verifier = { path = "../../runtime/verifier" }
wasm = { path = "../../runtime/wasm" }

[features]
test-utils = []

[dev-dependencies]
bencher = "0.1.5"
ethereum-rlp = "0.2"
ethereum-block = "0.3"
ethereum-hexutil = "0.2"
tempdir = "0.3"

testlib = { path = "../../test-utils/testlib" }

[[bench]]
name = "bench"
harness = false

'''
'''--- runtime/runtime/benches/bench.rs ---
#[macro_use]
extern crate bencher;

use bencher::Bencher;

use near_primitives::transaction::{
    CreateAccountTransaction, DeployContractTransaction, TransactionBody,
};
use near_primitives::types::Balance;
use testlib::node::{Node, RuntimeNode};
use wasm::types::ContractCode;

fn runtime_send_money(bench: &mut Bencher) {
    let node = RuntimeNode::new(&"alice.near".to_string());
    bench.iter(|| {
        node.send_money(&"bob.near".to_string(), 1);
    });
}

const FUNCTION_CALL_AMOUNT: Balance = 1_000_000_000;

fn setup_test_contract(wasm_binary: &[u8]) -> RuntimeNode {
    let node = RuntimeNode::new(&"alice.near".to_string());
    let account_id = node.account_id().unwrap();
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(&account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: "test_contract".to_string(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: 0,
    })
    .sign(&*node.signer());
    let user = node.user();
    user.add_transaction(transaction).unwrap();

    let transaction = TransactionBody::DeployContract(DeployContractTransaction {
        nonce: node.get_account_nonce(&account_id).unwrap_or_default() + 1,
        contract_id: "test_contract".to_string(),
        wasm_byte_array: wasm_binary.to_vec(),
    })
    .sign(&*node.signer());
    user.add_transaction(transaction).unwrap();
    node
}

fn runtime_wasm_bad_code(bench: &mut Bencher) {
    let code = include_bytes!("../../../tests/hello.wasm");
    let code = ContractCode::new(code.to_vec());
    let code = wasm::prepare::prepare_contract(&code, &wasm::types::Config::default()).unwrap();
    let node = setup_test_contract(&code);
    bench.iter(|| {
        node.call_function("test_contract", "benchmark", b"{}".to_vec(), FUNCTION_CALL_AMOUNT);
    });
}

fn runtime_wasm_set_value(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function(
            "test_contract",
            "setValue",
            b"{\"value\":\"123\"}".to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

fn runtime_wasm_benchmark_10_reads_legacy(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function("test_contract", "benchmark", b"{}".to_vec(), FUNCTION_CALL_AMOUNT);
    });
}

fn runtime_wasm_benchmark_storage_100(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function(
            "test_contract",
            "benchmark_storage",
            b"{\"n\":100}".to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

fn runtime_wasm_benchmark_storage_1000(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function(
            "test_contract",
            "benchmark_storage",
            b"{\"n\":1000}".to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

fn runtime_wasm_benchmark_sum_1000(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function(
            "test_contract",
            "benchmark_sum_n",
            b"{\"n\":1000}".to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

fn runtime_wasm_benchmark_sum_1000000(bench: &mut Bencher) {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    bench.iter(|| {
        node.call_function(
            "test_contract",
            "benchmark_sum_n",
            b"{\"n\":1000000}".to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

benchmark_group!(runtime_benches, runtime_send_money);
benchmark_group!(
    wasm_benches,
    runtime_wasm_set_value,
    runtime_wasm_bad_code,
    runtime_wasm_benchmark_10_reads_legacy,
    runtime_wasm_benchmark_storage_100,
    runtime_wasm_benchmark_storage_1000,
    runtime_wasm_benchmark_sum_1000,
    runtime_wasm_benchmark_sum_1000000
);
benchmark_main!(runtime_benches, wasm_benches);

'''
'''--- runtime/runtime/src/adapter.rs ---
use near_primitives::account::AccessKey;
use near_primitives::crypto::signature::PublicKey;
use near_primitives::rpc::ABCIQueryResponse;
use near_primitives::serialize::BaseDecode;
use near_primitives::types::{AccountId, BlockIndex, MerkleHash};

use crate::state_viewer::{AccountViewCallResult, ViewStateResult};

/// Adapter for querying runtime.
pub trait RuntimeAdapter {
    fn view_account(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<AccountViewCallResult, Box<dyn std::error::Error>>;

    fn call_function(
        &self,
        state_root: MerkleHash,
        height: BlockIndex,
        contract_id: &AccountId,
        method_name: &str,
        args: &[u8],
        logs: &mut Vec<String>,
    ) -> Result<Vec<u8>, Box<dyn std::error::Error>>;

    fn view_access_key(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, Box<dyn std::error::Error>>;

    fn view_access_keys(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<Vec<(PublicKey, AccessKey)>, Box<dyn std::error::Error>>;

    fn view_state(
        &self,
        state_root: MerkleHash,
        account_id: &AccountId,
    ) -> Result<ViewStateResult, Box<dyn std::error::Error>>;
}

/// Facade to query given client with <path> + <data> at <block height> with optional merkle prove request.
/// Given implementation only supports latest height, thus ignoring it.
pub fn query_client(
    adapter: &dyn RuntimeAdapter,
    state_root: MerkleHash,
    height: BlockIndex,
    path: &str,
    data: &[u8],
) -> Result<ABCIQueryResponse, Box<dyn std::error::Error>> {
    let path_parts: Vec<&str> = path.split('/').collect();
    if path_parts.is_empty() {
        return Err("Path must contain at least single token".into());
    }
    match path_parts[0] {
        "account" => match adapter.view_account(state_root, &AccountId::from(path_parts[1])) {
            Ok(r) => Ok(ABCIQueryResponse::account(path, r)),
            Err(e) => Err(e),
        },
        "call" => {
            let mut logs = vec![];
            match adapter.call_function(
                state_root,
                height,
                &AccountId::from(path_parts[1]),
                path_parts[2],
                &data,
                &mut logs,
            ) {
                Ok(result) => Ok(ABCIQueryResponse::result(path, result, logs)),
                Err(err) => Ok(ABCIQueryResponse::result_err(path, err.to_string(), logs)),
            }
        }
        "contract" => match adapter
            .view_state(state_root, &AccountId::from(path_parts[1]))
            .and_then(|r| serde_json::to_string(&r).map_err(|err| err.into()))
        {
            Ok(result) => Ok(ABCIQueryResponse::result(path, result.as_bytes().to_vec(), vec![])),
            Err(err) => Ok(ABCIQueryResponse::result_err(path, err.to_string(), vec![])),
        },
        "access_key" => {
            let result = if path_parts.len() == 2 {
                adapter
                    .view_access_keys(state_root, &AccountId::from(path_parts[1]))
                    .and_then(|r| serde_json::to_string(&r).map_err(|err| err.into()))
            } else {
                adapter
                    .view_access_key(
                        state_root,
                        &AccountId::from(path_parts[1]),
                        &PublicKey::from_base(path_parts[2])?,
                    )
                    .and_then(|r| serde_json::to_string(&r).map_err(|err| err.into()))
            };
            match result {
                Ok(result) => {
                    Ok(ABCIQueryResponse::result(path, result.as_bytes().to_vec(), vec![]))
                }
                Err(err) => Ok(ABCIQueryResponse::result_err(path, err.to_string(), vec![])),
            }
        }
        _ => Err(format!("Unknown path {}", path).into()),
    }
}

'''
'''--- runtime/runtime/src/chain_spec.rs ---
use std::fs::File;
use std::io::Read;
use std::path::PathBuf;

use serde_json;

use primitives::crypto::signer::{BLSSigner, EDSigner, InMemorySigner};
use primitives::types::{AccountId, Balance, ReadableBlsPublicKey, ReadablePublicKey};
use std::cmp::max;
use std::io::Write;
use std::sync::Arc;

#[derive(Clone, Serialize, Deserialize, Debug)]
pub enum AuthorityRotation {
    /// Authorities stay the same, just rotate circularly to change order.
    ProofOfAuthority,
    /// Use Thresholded Proof of Stake to rotate authorities.
    ThresholdedProofOfStake { epoch_length: u64, num_seats_per_slot: u64 },
}

/// Specification of the blockchain in general.
#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct ChainSpec {
    /// Genesis state accounts: (AccountId, PK, Initial Balance)
    pub accounts: Vec<(AccountId, ReadablePublicKey, Balance)>,

    /// Genesis smart contract code.
    pub genesis_wasm: Vec<u8>,

    /// Genesis state authorities that bootstrap the chain.
    pub initial_authorities: Vec<(AccountId, ReadablePublicKey, ReadableBlsPublicKey, Balance)>,

    /// Define authority rotation strategy.
    pub authority_rotation: AuthorityRotation,
}

/// Initial balance used in tests.
pub const TESTING_INIT_BALANCE: Balance = 1_000_000_000_000_000;
/// Stake used by authorities to validate used in tests.
pub const TESTING_INIT_STAKE: Balance = 100;

impl ChainSpec {
    /// Serializes ChainSpec to a string.
    pub fn to_string(&self) -> String {
        serde_json::to_string(self).expect("Error serializing the chain spec.")
    }

    /// Reads ChainSpec from a file.
    pub fn from_file(path: &PathBuf) -> Self {
        let mut file = File::open(path).expect("Could not open chain spec file.");
        let mut contents = String::new();
        file.read_to_string(&mut contents).expect("Could not read from chain spec file.");
        ChainSpec::from(contents.as_str())
    }

    /// Read ChainSpec from a file or use the default value.
    pub fn from_file_or_default(path: &Option<PathBuf>, default: Self) -> Self {
        path.as_ref().map(|p| Self::from_file(p)).unwrap_or(default)
    }

    /// Writes ChainSpec to the file.
    pub fn write_to_file(&self, path: &PathBuf) {
        let mut file = File::create(path).expect("Failed to create/write a chain spec file");
        if let Err(err) = file.write_all(self.to_string().as_bytes()) {
            panic!("Failed to write a chain spec file {}", err)
        }
    }

    /// Generates a `ChainSpec` that can be used for testing. The signers are seeded from the account
    /// names and therefore not secure to use in production.
    /// Args:
    /// * `id_type`: What is the style of the generated account ids, e.g. `alice.near` or `near.0`;
    /// * `num_accounts`: how many initial accounts should be created;
    /// * `num_initial_authorities`: how many initial authorities should be created;
    /// * `authority_rotation`: type of the authority rotation.
    /// Returns:
    /// * generated `ChainSpec`;
    /// * signers that can be used for assertions and mocking in tests.
    #[allow(clippy::needless_range_loop)]
    pub fn testing_spec(
        id_type: DefaultIdType,
        num_accounts: usize,
        num_initial_authorities: usize,
        authority_rotation: AuthorityRotation,
    ) -> (Self, Vec<Arc<InMemorySigner>>) {
        let num_signers = max(num_accounts, num_initial_authorities);

        let mut signers = vec![];
        let mut accounts = vec![];
        let mut initial_authorities = vec![];
        for i in 0..num_signers {
            let account_id = match id_type {
                DefaultIdType::Named => NAMED_IDS[i].to_string(),
                DefaultIdType::Enumerated => format!("near.{}", i),
            };
            let signer =
                Arc::new(InMemorySigner::from_seed(account_id.as_str(), account_id.as_str()));
            if i < num_accounts {
                accounts.push((
                    account_id.clone(),
                    signer.public_key().to_readable(),
                    TESTING_INIT_BALANCE,
                ));
            }
            if i < num_initial_authorities {
                initial_authorities.push((
                    account_id.clone(),
                    signer.public_key().to_readable(),
                    signer.bls_public_key().to_readable(),
                    TESTING_INIT_STAKE,
                ));
            }
            signers.push(signer);
        }
        {
            let account_id = "alice.near".to_owned();
            let signer = InMemorySigner::from_seed(account_id.as_str(), account_id.as_str());
            // Add alice.near.
            accounts.push((
                account_id.clone(),
                signer.public_key().to_readable(),
                TESTING_INIT_BALANCE,
            ));
        }

        let spec = ChainSpec {
            accounts,
            initial_authorities,
            genesis_wasm: include_bytes!("../../../runtime/wasm/runtest/res/wasm_with_mem.wasm")
                .to_vec(),
            authority_rotation,
        };
        (spec, signers)
    }

    /// Default ChainSpec used by PoA for testing.
    pub fn default_poa() -> Self {
        Self::testing_spec(DefaultIdType::Named, 3, 2, AuthorityRotation::ProofOfAuthority).0
    }

    /// Default ChainSpec used by DevNet for testing.
    pub fn default_devnet() -> Self {
        Self::testing_spec(DefaultIdType::Named, 18, 1, AuthorityRotation::ProofOfAuthority).0
    }
}

// Some of the standard named identifiers that we use for testing.
pub const ALICE_ID: &str = "alice.near";
pub const BOB_ID: &str = "bob.near";
pub const CAROL_ID: &str = "carol.near";
pub const NAMED_IDS: [&str; 18] = [
    ALICE_ID,
    BOB_ID,
    CAROL_ID,
    "dan.near",
    "eve.near",
    "frank.near",
    "grace.near",
    "heidi.near",
    "ivan.near",
    "judy.near",
    "mike.near",
    "niaj.near",
    "olivia.near",
    "pat.near",
    "sybil.near",
    "trudy.near",
    "victor.near",
    "wendy.near",
];

/// Type of id to use for the default ChainSpec. "alice.near" is a named id, "near.0" is an
/// enumerated id.
pub enum DefaultIdType {
    Named,
    Enumerated,
}

impl From<&str> for ChainSpec {
    fn from(config: &str) -> Self {
        serde_json::from_str(config).expect("Error deserializing the chain spec.")
    }
}

#[cfg(test)]
mod tests {
    use super::ChainSpec;
    use primitives::types::ReadableBlsPublicKey;
    use primitives::types::ReadablePublicKey;
    use serde_json::json;

    #[test]
    fn test_deserialize() {
        let data = json!({
            "accounts": [["alice.near", "6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq", 100]],
            "initial_authorities": [("alice.near", "6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq", "7AnjkhbpbtqbZHwg4gTZJd4ZGc84EN3FUj5diEbipGinQfYA2MDfaoe5uo1qRhCnkD", 50)],
            "genesis_wasm": [0,1],
            "authority_rotation": {"ThresholdedProofOfStake": {"epoch_length": 10, "num_seats_per_slot": 100}},
        });
        let spec = ChainSpec::from(data.to_string().as_str());
        assert_eq!(
            spec.initial_authorities[0],
            (
                "alice.near".to_string(),
                ReadablePublicKey("6fgp5mkRgsTWfd5UWw1VwHbNLLDYeLxrxw3jrkCeXNWq".to_string()),
                ReadableBlsPublicKey(
                    "7AnjkhbpbtqbZHwg4gTZJd4ZGc84EN3FUj5diEbipGinQfYA2MDfaoe5uo1qRhCnkD"
                        .to_string()
                ),
                50
            )
        );
    }

    #[test]
    fn test_default_spec() {
        let spec = ChainSpec::default_devnet();
        let spec_str1 = spec.to_string();
        let spec_str2 = ChainSpec::from(spec_str1.as_str()).to_string();
        assert_eq!(spec_str1, spec_str2);
    }
}

'''
'''--- runtime/runtime/src/economics_config.rs ---
//! Settings of the parameters of the economics.
use near_primitives::transaction::TransactionBody;
use near_primitives::types::Balance;
use wasm::types::Config;

/// The structure that holds the parameters of the economics.
#[derive(Default, Debug, Serialize, Deserialize, Clone)]
pub struct EconomicsConfig {
    /// The cost to store one byte of storage per block.
    pub storage_cost_byte_per_block: Balance,
    pub transactions_costs: TransactionsCosts,
    /// Config of wasm operations.
    pub wasm_config: Config,
}

/// The costs of the transactions.
#[derive(Default, Debug, Serialize, Deserialize, Clone)]
pub struct TransactionsCosts {
    pub create_account: Balance,
    pub deploy_contract: Balance,
    pub function_call: Balance,
    pub send_money: Balance,
    pub stake: Balance,
    pub swap_key: Balance,
    pub add_key: Balance,
    pub delete_key: Balance,
}

impl TransactionsCosts {
    /// Get the cost of the given transaction.
    pub fn cost(&self, transaction_body: &TransactionBody) -> Balance {
        use TransactionBody::*;
        match transaction_body {
            CreateAccount(_) => self.create_account.clone(),
            DeployContract(_) => self.deploy_contract.clone(),
            FunctionCall(_) => self.function_call.clone(),
            SendMoney(_) => self.send_money.clone(),
            Stake(_) => self.stake.clone(),
            SwapKey(_) => self.swap_key.clone(),
            AddKey(_) => self.add_key.clone(),
            DeleteKey(_) => self.delete_key.clone(),
        }
    }
}

'''
'''--- runtime/runtime/src/ethereum.rs ---
#![allow(unused)]
use std::mem;

use bigint::{H256, H64, U256};
use std::fs::{create_dir_all, File};
use std::io::{self, Read, Write};
use std::path::{Path, PathBuf};

const ETHASH_EPOCH_LENGTH: u64 = 30000;
const NODE_BYTES: usize = 64;

pub struct LightCache {
    epoch: u64,
    cache: Vec<u8>,
}

impl LightCache {
    fn storage_file(cache_dir: &PathBuf, epoch: u64) -> PathBuf {
        let mut path = cache_dir.clone();
        path.push(format!("{}", epoch));
        path
    }

    pub fn new(cache_dir: &PathBuf, epoch: u64) -> Self {
        match Self::from_file(cache_dir, epoch) {
            Ok(light_cache) => light_cache,
            Err(_) => {
                let cache_size = ethash::get_cache_size(epoch as usize);
                let mut cache = Vec::with_capacity(cache_size);
                cache.resize(cache_size, 0);
                let seed = ethash::get_seedhash(epoch as usize);
                ethash::make_cache(&mut cache, seed);
                let _ = Self::to_file(cache_dir, epoch, &cache);
                LightCache { epoch, cache }
            }
        }
    }

    fn to_file(cache_dir: &PathBuf, epoch: u64, cache: &[u8]) -> io::Result<usize> {
        create_dir_all(cache_dir)?;
        let mut file = File::create(Self::storage_file(cache_dir, epoch))?;
        file.write(cache)
    }

    pub fn from_file(cache_dir: &PathBuf, epoch: u64) -> io::Result<Self> {
        let mut file = File::open(Self::storage_file(cache_dir, epoch))?;
        let mut cache: Vec<u8> = Vec::with_capacity(
            file.metadata().map(|m| m.len() as _).unwrap_or(NODE_BYTES * 1_000_000),
        );
        file.read_to_end(&mut cache)?;
        cache.shrink_to_fit();

        if cache.len() % NODE_BYTES != 0 || cache.capacity() % NODE_BYTES != 0 {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "Node cache is not a multiple of node size",
            ));
        }
        Ok(LightCache { epoch, cache })
    }
}

pub struct EthashProvider {
    cache_dir: PathBuf,
    recent: Option<LightCache>,
    prev: Option<LightCache>,
}

impl EthashProvider {
    pub fn new(cache_dir: &Path) -> Self {
        EthashProvider { cache_dir: cache_dir.to_path_buf(), recent: None, prev: None }
    }

    pub fn check_ethash(
        &mut self,
        block_number: U256,
        header_hash: H256,
        nonce: H64,
        mix_hash: H256,
        difficulty: U256,
    ) -> bool {
        let epoch = block_number.as_u64() / ETHASH_EPOCH_LENGTH;
        let cache = {
            let cache = match &self.recent {
                Some(recent) if recent.epoch == epoch => self.recent.as_ref(),
                _ => match self.prev {
                    Some(ref prev) if prev.epoch == epoch => {
                        if self.recent.is_some() && self.recent.as_ref().unwrap().epoch > prev.epoch
                        {
                            None
                        } else {
                            mem::swap(&mut self.prev, &mut self.recent);
                            self.recent.as_ref()
                        }
                    }
                    _ => None,
                },
            };
            match cache {
                None => {
                    let cache = LightCache::new(&self.cache_dir, epoch);
                    self.prev = mem::replace(&mut self.recent, Some(cache));
                    self.recent.as_ref().unwrap()
                }
                Some(cache) => cache,
            }
        };
        let full_size = ethash::get_full_size(epoch as usize);
        let (result_mix_hash, result) =
            ethash::hashimoto_light(header_hash, nonce, full_size, &cache.cache);
        if result_mix_hash == mix_hash {
            let target = ethash::cross_boundary(difficulty);
            return U256::from(result) <= target;
        }
        false
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use block::Header;
    use hexutil::*;
    use std::process::Command;
    use tempdir::TempDir;

    #[test]
    #[cfg(feature = "expensive_tests")]
    fn test_header() {
        let dir = TempDir::new("ethashtest_header").unwrap();
        let header: Header = rlp::decode(&read_hex("f901f9a0d405da4e66f1445d455195229624e133f5baafe72b5cf7b3c36c12c8146e98b7a01dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347948888f1f195afa192cfee860698584c030f4c9db1a05fb2b4bfdef7b314451cb138a534d225c922fc0e5fbe25e451142732c3e25c25a088d2ec6b9860aae1a2c3b299f72b6a5d70d7f7ba4722c78f2c49ba96273c2158a007c6fdfa8eea7e86b81f5b0fc0f78f90cc19f4aa60d323151e0cac660199e9a1b90100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000008302008003832fefba82524d84568e932a80a0a0349d8c3df71f1a48a9df7d03fd5f14aeee7d91332c009ecaff0a71ead405bd88ab4e252a7e8c2a23").unwrap());

        let mut provider = EthashProvider::new(dir.path());
        assert!(provider.check_ethash(
            header.number,
            header.partial_hash(),
            H64::from("ab4e252a7e8c2a23"),
            header.mix_hash,
            header.difficulty,
        ));
    }

    #[test]
    #[cfg(feature = "expensive_tests")]
    fn test_invalid_header() {
        let dir = TempDir::new("ethashtest_invalid_header").unwrap();
        let header: Header = rlp::decode(&read_hex("f901f7a01bef91439a3e070a6586851c11e6fd79bbbea074b2b836727b8e75c7d4a6b698a01dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d4934794ea3cb5f94fa2ddd52ec6dd6eb75cf824f4058ca1a00c6e51346be0670ce63ac5f05324e27d20b180146269c5aab844d09a2b108c64a056e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421a056e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421b90100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000008302004002832fefd880845511ed2a80a0e55d02c555a7969361cf74a9ec6211d8c14e4517930a00442f171bdb1698d17588307692cf71b12f6d").unwrap());

        let mut provider = EthashProvider::new(dir.path());
        assert!(!provider.check_ethash(
            header.number,
            header.partial_hash(),
            H64::from("307692cf71b12f6d"),
            header.mix_hash,
            header.difficulty,
        ));
    }
}

'''
'''--- runtime/runtime/src/ext.rs ---
use std::collections::HashMap;
use std::iter::Peekable;
use std::sync::{Arc, Mutex};

use bigint::{H256, H64, U256};
use kvdb::DBValue;

use near_primitives::hash::CryptoHash;
use near_primitives::transaction::{
    AsyncCall, Callback, CallbackInfo, ReceiptBody, ReceiptTransaction,
};
use near_primitives::types::{AccountId, Balance, CallbackId, Nonce, PromiseId, ReceiptId};
use near_primitives::utils::{create_nonce_with_nonce, key_for_account, key_for_callback};
use near_store::set;
use near_store::{TrieUpdate, TrieUpdateIterator};
use wasm::ext::{Error as ExtError, External, Result as ExtResult};

use crate::ethereum::EthashProvider;
use crate::POISONED_LOCK_ERR;

pub const ACCOUNT_DATA_SEPARATOR: &[u8; 1] = b",";

pub struct RuntimeExt<'a> {
    trie_update: &'a mut TrieUpdate,
    storage_prefix: Vec<u8>,
    pub receipts: HashMap<ReceiptId, ReceiptTransaction>,
    pub callbacks: HashMap<CallbackId, Callback>,
    account_id: AccountId,
    refund_account_id: AccountId,
    nonce: Nonce,
    transaction_hash: &'a CryptoHash,
    iters: HashMap<u32, Peekable<TrieUpdateIterator<'a>>>,
    last_iter_id: u32,
    ethash_provider: Arc<Mutex<EthashProvider>>,
}

impl<'a> RuntimeExt<'a> {
    pub fn new(
        trie_update: &'a mut TrieUpdate,
        account_id: &AccountId,
        refund_account_id: &AccountId,
        transaction_hash: &'a CryptoHash,
        ethash_provider: Arc<Mutex<EthashProvider>>,
    ) -> Self {
        let mut prefix = key_for_account(account_id);
        prefix.append(&mut ACCOUNT_DATA_SEPARATOR.to_vec());
        RuntimeExt {
            trie_update,
            storage_prefix: prefix,
            receipts: HashMap::new(),
            callbacks: HashMap::new(),
            account_id: account_id.clone(),
            refund_account_id: refund_account_id.clone(),
            nonce: 0,
            transaction_hash,
            iters: HashMap::new(),
            last_iter_id: 0,
            ethash_provider,
        }
    }

    pub fn create_storage_key(&self, key: &[u8]) -> Vec<u8> {
        let mut storage_key = self.storage_prefix.clone();
        storage_key.extend_from_slice(key);
        storage_key
    }

    pub fn create_nonce(&mut self) -> CryptoHash {
        let nonce = create_nonce_with_nonce(self.transaction_hash, self.nonce);
        self.nonce += 1;
        nonce
    }

    pub fn get_receipts(&mut self) -> Vec<ReceiptTransaction> {
        let mut vec: Vec<ReceiptTransaction> = self.receipts.drain().map(|(_, v)| v).collect();
        vec.sort_by_key(|a| a.nonce);
        vec
    }

    /// write callbacks to stateUpdate
    pub fn flush_callbacks(&mut self) {
        for (id, callback) in self.callbacks.drain() {
            set(self.trie_update, key_for_callback(&id), &callback);
        }
    }
}

impl<'a> External for RuntimeExt<'a> {
    fn storage_set(&mut self, key: &[u8], value: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        let storage_key = self.create_storage_key(key);
        Ok(self.trie_update.set(storage_key, DBValue::from_slice(value)))
    }

    fn storage_get(&self, key: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        let storage_key = self.create_storage_key(key);
        let value = self.trie_update.get(&storage_key);
        Ok(value.map(|buf| buf.to_vec()))
    }

    fn storage_remove(&mut self, key: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        let storage_key = self.create_storage_key(key);
        Ok(self.trie_update.remove(&storage_key))
    }

    fn storage_iter(&mut self, prefix: &[u8]) -> ExtResult<u32> {
        self.iters.insert(
            self.last_iter_id,
            // It is safe to insert an iterator of lifetime 'a into a HashMap of lifetime 'a.
            // We just could not convince Rust that `self.trie_update` has lifetime 'a as it
            // shrinks the lifetime to the lifetime of `self`.
            unsafe { &mut *(self.trie_update as *mut TrieUpdate) }
                .iter(&self.create_storage_key(prefix))
                .map_err(|_| ExtError::TrieIteratorError)?
                .peekable(),
        );
        self.last_iter_id += 1;
        Ok(self.last_iter_id - 1)
    }

    fn storage_range(&mut self, start: &[u8], end: &[u8]) -> ExtResult<u32> {
        self.iters.insert(
            self.last_iter_id,
            unsafe { &mut *(self.trie_update as *mut TrieUpdate) }
                .range(&self.storage_prefix, start, end)
                .map_err(|_| ExtError::TrieIteratorError)?
                .peekable(),
        );
        self.last_iter_id += 1;
        Ok(self.last_iter_id - 1)
    }

    fn storage_iter_next(&mut self, id: u32) -> ExtResult<Option<Vec<u8>>> {
        let result = match self.iters.get_mut(&id) {
            Some(iter) => iter.next(),
            None => return Err(ExtError::TrieIteratorMissing),
        };
        if result.is_none() {
            self.iters.remove(&id);
        }
        Ok(result.map(|x| x[self.storage_prefix.len()..].to_vec()))
    }

    fn storage_iter_peek(&mut self, id: u32) -> ExtResult<Option<Vec<u8>>> {
        let result = match self.iters.get_mut(&id) {
            Some(iter) => iter.peek().cloned(),
            None => return Err(ExtError::TrieIteratorMissing),
        };
        Ok(result.map(|x| x[self.storage_prefix.len()..].to_vec()))
    }

    fn storage_iter_remove(&mut self, id: u32) {
        self.iters.remove(&id);
    }

    fn promise_create(
        &mut self,
        account_id: AccountId,
        method_name: Vec<u8>,
        arguments: Vec<u8>,
        amount: Balance,
    ) -> ExtResult<PromiseId> {
        let nonce = self.create_nonce();
        let receipt = ReceiptTransaction::new(
            self.account_id.clone(),
            account_id,
            nonce,
            ReceiptBody::NewCall(AsyncCall::new(
                method_name,
                arguments,
                amount,
                self.refund_account_id.clone(),
            )),
        );
        let promise_id = PromiseId::Receipt(nonce.as_ref().to_vec());
        self.receipts.insert(nonce.as_ref().to_vec(), receipt);
        Ok(promise_id)
    }

    fn promise_then(
        &mut self,
        promise_id: PromiseId,
        method_name: Vec<u8>,
        arguments: Vec<u8>,
        amount: Balance,
    ) -> ExtResult<PromiseId> {
        let callback_id = self.create_nonce();
        let receipt_ids = match promise_id {
            PromiseId::Receipt(r) => vec![r],
            PromiseId::Joiner(rs) => rs,
            PromiseId::Callback(_) => return Err(ExtError::WrongPromise),
        };
        let mut callback =
            Callback::new(method_name, arguments, amount, self.refund_account_id.clone());
        callback.results.resize(receipt_ids.len(), None);
        for (index, receipt_id) in receipt_ids.iter().enumerate() {
            let receipt = match self.receipts.get_mut(receipt_id) {
                Some(r) => r,
                _ => return Err(ExtError::PromiseIdNotFound),
            };
            match receipt.body {
                ReceiptBody::NewCall(ref mut async_call) => {
                    let callback_info = CallbackInfo::new(
                        callback_id.as_ref().to_vec(),
                        index,
                        self.account_id.clone(),
                    );
                    match async_call.callback {
                        Some(_) => return Err(ExtError::PromiseAlreadyHasCallback),
                        None => {
                            async_call.callback = Some(callback_info);
                        }
                    }
                }
                _ => {
                    return Err(ExtError::WrongPromise);
                }
            }
        }
        self.callbacks.insert(callback_id.as_ref().to_vec(), callback);
        Ok(PromiseId::Callback(callback_id.as_ref().to_vec()))
    }

    fn check_ethash(
        &mut self,
        block_number: u64,
        header_hash: &[u8],
        nonce: u64,
        mix_hash: &[u8],
        difficulty: u64,
    ) -> bool {
        self.ethash_provider.lock().expect(POISONED_LOCK_ERR).check_ethash(
            U256::from(block_number),
            H256::from(header_hash),
            H64::from(nonce),
            H256::from(mix_hash),
            U256::from(difficulty),
        )
    }
}

'''
'''--- runtime/runtime/src/lib.rs ---
#[macro_use]
extern crate log;
#[macro_use]
extern crate serde_derive;

use std::collections::{hash_map::Entry, HashMap};
use std::convert::TryFrom;
use std::sync::{Arc, Mutex};

use near_primitives::account::Account;
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::CryptoHash;
use near_primitives::serialize::{from_base, Encode};
use near_primitives::transaction::{
    AsyncCall, Callback, CallbackInfo, CallbackResult, FunctionCallTransaction, LogEntry,
    ReceiptBody, ReceiptTransaction, SignedTransaction, TransactionBody, TransactionResult,
    TransactionStatus,
};
use near_primitives::types::StorageUsage;
use near_primitives::types::{
    AccountId, Balance, BlockIndex, MerkleHash, PromiseId, ReadablePublicKey, ShardId,
    ValidatorStake,
};
use near_primitives::utils::{
    account_to_shard_id, create_nonce_with_nonce, key_for_account, key_for_callback, key_for_code,
    system_account,
};
use near_store::{get, set, StoreUpdate, TrieChanges, TrieUpdate};
use near_verifier::{TransactionVerifier, VerificationData};
use wasm::executor;
use wasm::types::{ContractCode, ReturnData, RuntimeContext};

use crate::economics_config::EconomicsConfig;
use crate::ethereum::EthashProvider;
use crate::ext::RuntimeExt;
use crate::system::{system_create_account, SYSTEM_METHOD_CREATE_ACCOUNT};

pub mod adapter;
pub mod economics_config;
pub mod ethereum;
pub mod ext;
pub mod state_viewer;
mod system;

pub const ETHASH_CACHE_PATH: &str = "ethash_cache";
pub(crate) const POISONED_LOCK_ERR: &str = "The lock was poisoned.";

#[derive(Debug)]
pub struct ApplyState {
    pub root: MerkleHash,
    pub shard_id: ShardId,
    pub block_index: u64,
    pub parent_block_hash: CryptoHash,
}

pub struct ApplyResult {
    pub root: MerkleHash,
    pub shard_id: ShardId,
    pub trie_changes: TrieChanges,
    pub validator_proposals: Vec<ValidatorStake>,
    pub new_receipts: HashMap<ShardId, Vec<ReceiptTransaction>>,
    pub tx_result: Vec<TransactionResult>,
    pub largest_tx_nonce: HashMap<AccountId, u64>,
}

pub struct Runtime {
    ethash_provider: Arc<Mutex<EthashProvider>>,
    economics_config: EconomicsConfig,
}

impl Runtime {
    pub fn new(ethash_provider: Arc<Mutex<EthashProvider>>) -> Self {
        Runtime { ethash_provider, economics_config: Default::default() }
    }

    fn call_function(
        &self,
        state_update: &mut TrieUpdate,
        transaction: &FunctionCallTransaction,
        hash: CryptoHash,
        sender: &mut Account,
        refund_account_id: &AccountId,
    ) -> Result<Vec<ReceiptTransaction>, String> {
        match transaction.method_name.get(0) {
            Some(b'_') => {
                return Err(format!(
                    "Account {} tries to call a private method {}",
                    transaction.originator,
                    std::str::from_utf8(&transaction.method_name)
                        .unwrap_or_else(|_| "NON_UTF8_METHOD_NAME"),
                ))
            }
            None if transaction.amount == 0 => {
                return Err(format!("Account {} tries to send 0 tokens", transaction.originator,))
            }
            _ => (),
        };
        if sender.amount >= transaction.amount {
            sender.amount -= transaction.amount;
            set(state_update, key_for_account(&transaction.originator), sender);
            let receipt = ReceiptTransaction::new(
                transaction.originator.clone(),
                transaction.contract_id.clone(),
                create_nonce_with_nonce(&hash, 0),
                ReceiptBody::NewCall(AsyncCall::new(
                    transaction.method_name.clone(),
                    transaction.args.clone(),
                    transaction.amount,
                    refund_account_id.clone(),
                )),
            );
            Ok(vec![receipt])
        } else {
            Err(
                format!(
                    "Account {} tries to call some contract with the amount {}, but has staked {} and only has {}",
                    transaction.originator,
                    transaction.amount,
                    sender.staked,
                    sender.amount
                )
            )
        }
    }

    /// Subtracts the storage rent from the given account balance.
    fn apply_rent(&self, account_id: &AccountId, account: &mut Account, block_index: BlockIndex) {
        // The number of bytes the account occupies in the Trie.
        let meta_storage = key_for_account(account_id).len() as StorageUsage
            + account.encode().unwrap().len() as StorageUsage;
        let total_storage = (account.storage_usage + meta_storage) as u128;
        let charge = ((block_index - account.storage_paid_at) as u128)
            * total_storage
            * self.economics_config.storage_cost_byte_per_block;
        account.amount = if charge <= account.amount { account.amount - charge } else { 0 };
        account.storage_paid_at = block_index;
    }

    /// node receives signed_transaction, processes it
    /// and generates the receipt to send to receiver
    fn apply_signed_transaction(
        &self,
        state_update: &mut TrieUpdate,
        block_index: BlockIndex,
        transaction: &SignedTransaction,
        validator_proposals: &mut Vec<ValidatorStake>,
    ) -> Result<Vec<ReceiptTransaction>, String> {
        let VerificationData { originator_id, mut originator, .. } = {
            let verifier = TransactionVerifier::new(state_update);
            verifier.verify_transaction(transaction)?
        };
        originator.nonce = transaction.body.get_nonce();
        let transaction_cost = self.economics_config.transactions_costs.cost(&transaction.body);
        originator.checked_sub(transaction_cost)?;
        self.apply_rent(&originator_id, &mut originator, block_index);
        set(state_update, key_for_account(&originator_id), &originator);
        state_update.commit();

        let refund_account_id = &originator_id;
        match transaction.body {
            TransactionBody::SendMoney(ref t) => system::send_money(
                state_update,
                &t,
                transaction.get_hash(),
                &mut originator,
                refund_account_id,
            ),
            TransactionBody::Stake(ref t) => system::staking(
                state_update,
                &t,
                &originator_id,
                &mut originator,
                validator_proposals,
            ),
            TransactionBody::FunctionCall(ref t) => self.call_function(
                state_update,
                &t,
                transaction.get_hash(),
                &mut originator,
                refund_account_id,
            ),
            TransactionBody::DeployContract(ref t) => {
                system::deploy(state_update, &t.contract_id, &t.wasm_byte_array, &mut originator)
            }
            TransactionBody::CreateAccount(ref t) => system::create_account(
                state_update,
                t,
                transaction.get_hash(),
                &mut originator,
                refund_account_id,
            ),
            TransactionBody::SwapKey(ref t) => system::swap_key(state_update, t, &mut originator),
            TransactionBody::AddKey(ref t) => system::add_key(state_update, t, &mut originator),
            TransactionBody::DeleteKey(ref t) => {
                system::delete_key(state_update, t, &mut originator, transaction.get_hash())
            }
        }
    }

    fn return_data_to_receipts(
        runtime_ext: &mut RuntimeExt,
        return_data: ReturnData,
        callback_info: &Option<CallbackInfo>,
        receiver_id: &AccountId,
    ) -> Result<Vec<ReceiptTransaction>, String> {
        let callback_info = match callback_info {
            Some(info) => info,
            _ => {
                let receipts = runtime_ext.get_receipts();
                runtime_ext.flush_callbacks();
                return Ok(receipts);
            }
        };
        let callback_res = match return_data {
            ReturnData::Value(v) => {
                let res = CallbackResult::new(callback_info.clone(), Some(v));
                Some(res)
            }
            ReturnData::None => {
                let res = CallbackResult::new(callback_info.clone(), Some(vec![]));
                Some(res)
            }
            ReturnData::Promise(PromiseId::Callback(id)) => {
                let callback = runtime_ext.callbacks.get_mut(&id).expect("callback must exist");
                if callback.callback.is_some() {
                    unreachable!("callback already has a callback");
                } else {
                    callback.callback = Some(callback_info.clone());
                }
                None
            }
            ReturnData::Promise(PromiseId::Receipt(id)) => {
                let receipt = runtime_ext.receipts.get_mut(&id).expect("receipt must exist");
                match receipt.body {
                    ReceiptBody::NewCall(ref mut call) => {
                        if call.callback.is_some() {
                            return Err(
                                "don't return original promise that already has a callback"
                                    .to_string(),
                            );
                        } else {
                            call.callback = Some(callback_info.clone());
                        }
                    }
                    _ => unreachable!("receipt body is not a new call"),
                }
                None
            }
            ReturnData::Promise(PromiseId::Joiner(_)) => {
                return Err(
                    "don't return a joined promise (using promise_and or Promise.all)".to_string()
                )
            }
        };
        let mut receipts = runtime_ext.get_receipts();
        if let Some(callback_res) = callback_res {
            let new_receipt = ReceiptTransaction::new(
                receiver_id.clone(),
                callback_info.receiver.clone(),
                runtime_ext.create_nonce(),
                ReceiptBody::Callback(callback_res),
            );
            receipts.push(new_receipt);
        }
        runtime_ext.flush_callbacks();
        Ok(receipts)
    }

    fn get_code(
        state_update: &TrieUpdate,
        receiver_id: &AccountId,
    ) -> Result<Arc<ContractCode>, String> {
        debug!(target:"runtime", "Calling the contract at account {}", receiver_id);
        let account = get::<Account>(state_update, &key_for_account(receiver_id))
            .ok_or_else(|| format!("cannot find account for account_id {}", receiver_id.clone()))?;
        let code_hash = account.code_hash;
        let code = || {
            get::<ContractCode>(state_update, &key_for_code(receiver_id)).ok_or_else(|| {
                format!("cannot find contract code for account {}", receiver_id.clone())
            })
        };
        wasm::cache::get_code_with_cache(code_hash, code)
    }

    fn apply_async_call(
        &self,
        state_update: &mut TrieUpdate,
        async_call: &AsyncCall,
        sender_id: &AccountId,
        receiver_id: &AccountId,
        nonce: &CryptoHash,
        receiver: &mut Account,
        leftover_balance: &mut Balance,
        block_index: BlockIndex,
        transaction_result: &mut TransactionResult,
    ) -> Result<Vec<ReceiptTransaction>, String> {
        let code = Self::get_code(state_update, receiver_id)?;
        let result = {
            let mut runtime_ext = RuntimeExt::new(
                state_update,
                receiver_id,
                &async_call.refund_account,
                nonce,
                self.ethash_provider.clone(),
            );
            let mut wasm_res = executor::execute(
                &code,
                &async_call.method_name,
                &async_call.args,
                &[],
                &mut runtime_ext,
                &wasm::types::Config::default(),
                &RuntimeContext::new(
                    receiver.amount,
                    async_call.amount,
                    sender_id,
                    receiver_id,
                    receiver.storage_usage,
                    block_index,
                    nonce.as_ref().to_vec(),
                    false,
                ),
            )
            .map_err(|e| format!("wasm async call preparation failed with error: {:?}", e))?;
            transaction_result.logs.append(&mut wasm_res.logs);
            let balance = wasm_res.frozen_balance;
            *leftover_balance += wasm_res.liquid_balance;
            let storage_usage = wasm_res.storage_usage;
            let return_data = wasm_res
                .return_data
                .map_err(|e| format!("wasm async call execution failed with error: {:?}", e))?;
            transaction_result.result = return_data.to_result();
            Self::return_data_to_receipts(
                &mut runtime_ext,
                return_data,
                &async_call.callback,
                receiver_id,
            )
            .and_then(|receipts| {
                receiver.amount = balance;
                receiver.storage_usage = storage_usage;
                Ok(receipts)
            })
        };
        set(state_update, key_for_account(&receiver_id), receiver);
        result
    }

    fn apply_callback(
        &self,
        state_update: &mut TrieUpdate,
        callback_res: &CallbackResult,
        sender_id: &AccountId,
        receiver_id: &AccountId,
        nonce: &CryptoHash,
        receiver: &mut Account,
        leftover_balance: &mut Balance,
        refund_account: &mut AccountId,
        block_index: BlockIndex,
        transaction_result: &mut TransactionResult,
    ) -> Result<Vec<ReceiptTransaction>, String> {
        let mut needs_removal = false;
        let mut callback: Option<Callback> =
            get(state_update, &key_for_callback(&callback_res.info.id));
        let code = Self::get_code(state_update, receiver_id)?;
        let receipts = match callback {
            Some(ref mut callback) => {
                callback.results[callback_res.info.result_index] = callback_res.result.clone();
                callback.result_counter += 1;
                // if we have gathered all results, execute the callback
                if callback.result_counter == callback.results.len() {
                    let mut runtime_ext = RuntimeExt::new(
                        state_update,
                        receiver_id,
                        &callback.refund_account,
                        nonce,
                        self.ethash_provider.clone(),
                    );

                    *refund_account = callback.refund_account.clone();
                    needs_removal = true;
                    executor::execute(
                        &code,
                        &callback.method_name,
                        &callback.args,
                        &callback.results,
                        &mut runtime_ext,
                        &wasm::types::Config::default(),
                        &RuntimeContext::new(
                            receiver.amount,
                            callback.amount,
                            sender_id,
                            receiver_id,
                            receiver.storage_usage,
                            block_index,
                            nonce.as_ref().to_vec(),
                            false,
                        ),
                    )
                    .map_err(|e| format!("wasm callback execution failed with error: {:?}", e))
                    .and_then(|mut res| {
                        transaction_result.logs.append(&mut res.logs);
                        let balance = res.frozen_balance;
                        *leftover_balance += res.liquid_balance;
                        let storage_usage = res.storage_usage;
                        res.return_data
                            .map_err(|e| {
                                format!("wasm callback execution failed with error: {:?}", e)
                            })
                            .and_then(|data| {
                                transaction_result.result = data.to_result();
                                Self::return_data_to_receipts(
                                    &mut runtime_ext,
                                    data,
                                    &callback.callback,
                                    receiver_id,
                                )
                            })
                            .and_then(|receipts| {
                                receiver.amount = balance;
                                receiver.storage_usage = storage_usage;
                                Ok(receipts)
                            })
                    })
                } else {
                    // otherwise no receipt is generated
                    Ok(vec![])
                }
            }
            _ => {
                return Err(format!("callback id: {:?} not found", callback_res.info.id));
            }
        };
        if needs_removal {
            if receipts.is_err() {
                // On error, we rollback previous changes and then commit the deletion
                state_update.rollback();
                state_update.remove(&key_for_callback(&callback_res.info.id));
                state_update.commit();
            } else {
                state_update.remove(&key_for_callback(&callback_res.info.id));
                set(state_update, key_for_account(&receiver_id), receiver);
            }
        } else {
            // if we don't need to remove callback, since it is updated, we need
            // to update the storage.
            let callback = callback.expect("Cannot be none");
            set(state_update, key_for_callback(&callback_res.info.id), &callback);
        }
        receipts
    }

    fn apply_receipt(
        &self,
        state_update: &mut TrieUpdate,
        receipt: &ReceiptTransaction,
        new_receipts: &mut Vec<ReceiptTransaction>,
        block_index: BlockIndex,
        transaction_result: &mut TransactionResult,
    ) -> Result<(), String> {
        let receiver: Option<Account> = get(state_update, &key_for_account(&receipt.receiver));
        let receiver_exists = receiver.is_some();
        let mut amount = 0;
        let mut callback_info = None;
        // Un-utilized leftover liquid balance that we can refund back to the originator.
        let mut leftover_balance = 0;
        let mut refund_account: String = Default::default();
        let result = match receiver {
            Some(mut receiver) => match &receipt.body {
                ReceiptBody::NewCall(async_call) => {
                    amount = async_call.amount;
                    refund_account = async_call.refund_account.clone();
                    callback_info = async_call.callback.clone();
                    if async_call.method_name.is_empty() {
                        transaction_result.result = Some(vec![]);
                        system::deposit(
                            state_update,
                            async_call.amount,
                            &async_call.callback,
                            &receipt.receiver,
                            &receipt.nonce,
                            &mut receiver,
                        )
                    } else if async_call.method_name == SYSTEM_METHOD_CREATE_ACCOUNT {
                        Err(format!("Account {} already exists", receipt.receiver))
                    } else {
                        self.apply_async_call(
                            state_update,
                            &async_call,
                            &receipt.originator,
                            &receipt.receiver,
                            &receipt.nonce,
                            &mut receiver,
                            &mut leftover_balance,
                            block_index,
                            transaction_result,
                        )
                    }
                }
                ReceiptBody::Callback(callback_res) => self.apply_callback(
                    state_update,
                    &callback_res,
                    &receipt.originator,
                    &receipt.receiver,
                    &receipt.nonce,
                    &mut receiver,
                    &mut leftover_balance,
                    &mut refund_account,
                    block_index,
                    transaction_result,
                ),
                ReceiptBody::Refund(amount) => {
                    receiver.amount += amount;
                    set(state_update, key_for_account(&receipt.receiver), &receiver);
                    Ok(vec![])
                }
            },
            _ => {
                let err = Err(format!("receiver {} does not exist", receipt.receiver));
                if let ReceiptBody::NewCall(call) = &receipt.body {
                    amount = call.amount;
                    if call.method_name == SYSTEM_METHOD_CREATE_ACCOUNT {
                        system_create_account(state_update, &call, &receipt.receiver)
                    } else {
                        err
                    }
                } else {
                    err
                }
            }
        };
        let res = match result {
            Ok(mut receipts) => {
                new_receipts.append(&mut receipts);
                Ok(())
            }
            Err(s) => {
                if amount > 0 {
                    let receiver =
                        if receiver_exists { receipt.receiver.clone() } else { system_account() };
                    let new_receipt = ReceiptTransaction::new(
                        receiver,
                        receipt.originator.clone(),
                        create_nonce_with_nonce(&receipt.nonce, new_receipts.len() as u64),
                        ReceiptBody::Refund(amount),
                    );
                    new_receipts.push(new_receipt);
                }
                if let Some(callback_info) = callback_info {
                    let new_receipt = ReceiptTransaction::new(
                        receipt.receiver.clone(),
                        callback_info.receiver.clone(),
                        create_nonce_with_nonce(&receipt.nonce, new_receipts.len() as u64),
                        ReceiptBody::Callback(CallbackResult::new(callback_info, None)),
                    );
                    new_receipts.push(new_receipt);
                }
                Err(s)
            }
        };
        if leftover_balance > 0 {
            let new_receipt = ReceiptTransaction::new(
                receipt.receiver.clone(),
                refund_account,
                create_nonce_with_nonce(&receipt.nonce, new_receipts.len() as u64),
                ReceiptBody::Refund(leftover_balance),
            );
            new_receipts.push(new_receipt);
        }
        res
    }

    fn print_log(log: &[LogEntry]) {
        if log.is_empty() {
            return;
        }
        let log_str = log.iter().fold(String::new(), |acc, s| {
            if acc.is_empty() {
                s.to_string()
            } else {
                acc + "\n" + s
            }
        });
        debug!(target: "runtime", "{}", log_str);
    }

    pub fn process_transaction(
        &self,
        state_update: &mut TrieUpdate,
        block_index: BlockIndex,
        transaction: &SignedTransaction,
        new_receipts: &mut HashMap<ShardId, Vec<ReceiptTransaction>>,
        validator_proposals: &mut Vec<ValidatorStake>,
    ) -> TransactionResult {
        let mut result = TransactionResult::default();
        match self.apply_signed_transaction(
            state_update,
            block_index,
            transaction,
            validator_proposals,
        ) {
            Ok(receipts) => {
                for receipt in receipts {
                    result.receipts.push(receipt.nonce);
                    let shard_id = receipt.shard_id();
                    new_receipts.entry(shard_id).or_insert_with(|| vec![]).push(receipt);
                }
                state_update.commit();
                result.status = TransactionStatus::Completed;
            }
            Err(s) => {
                state_update.rollback();
                result.logs.push(format!("Runtime error: {}", s));
                result.status = TransactionStatus::Failed;
            }
        };
        Self::print_log(&result.logs);
        result
    }

    pub fn process_receipt(
        &self,
        state_update: &mut TrieUpdate,
        shard_id: ShardId,
        block_index: BlockIndex,
        receipt: &ReceiptTransaction,
        new_receipts: &mut HashMap<ShardId, Vec<ReceiptTransaction>>,
    ) -> TransactionResult {
        let mut result = TransactionResult::default();
        if account_to_shard_id(&receipt.receiver) == shard_id {
            let mut tmp_new_receipts = vec![];
            let apply_result = self.apply_receipt(
                state_update,
                receipt,
                &mut tmp_new_receipts,
                block_index,
                &mut result,
            );
            for receipt in tmp_new_receipts {
                result.receipts.push(receipt.nonce);
                let shard_id = receipt.shard_id();
                new_receipts.entry(shard_id).or_insert_with(|| vec![]).push(receipt);
            }
            match apply_result {
                Ok(()) => {
                    state_update.commit();
                    result.status = TransactionStatus::Completed;
                }
                Err(s) => {
                    state_update.rollback();
                    result.logs.push(format!("Runtime error: {}", s));
                    result.status = TransactionStatus::Failed;
                }
            };
        } else {
            unreachable!("receipt sent to the wrong shard");
        };
        Self::print_log(&result.logs);
        result
    }

    /// apply receipts from previous block and transactions from this block
    pub fn apply(
        &self,
        mut state_update: TrieUpdate,
        apply_state: &ApplyState,
        prev_receipts: &[Vec<ReceiptTransaction>],
        transactions: &[SignedTransaction],
    ) -> Result<ApplyResult, Box<dyn std::error::Error>> {
        let mut new_receipts = HashMap::new();
        let mut validator_proposals = vec![];
        let shard_id = apply_state.shard_id;
        let block_index = apply_state.block_index;
        let mut tx_result = vec![];
        let mut largest_tx_nonce = HashMap::new();
        for receipt in prev_receipts.iter().flatten() {
            tx_result.push(self.process_receipt(
                &mut state_update,
                shard_id,
                block_index,
                receipt,
                &mut new_receipts,
            ));
        }
        for transaction in transactions {
            let sender = transaction.body.get_originator();
            let nonce = transaction.body.get_nonce();
            match largest_tx_nonce.entry(sender) {
                Entry::Occupied(mut e) => {
                    let largest_nonce = e.get_mut();
                    if *largest_nonce < nonce {
                        *largest_nonce = nonce;
                    }
                }
                Entry::Vacant(e) => {
                    e.insert(nonce);
                }
            };

            tx_result.push(self.process_transaction(
                &mut state_update,
                block_index,
                transaction,
                &mut new_receipts,
                &mut validator_proposals,
            ));
        }
        let trie_changes = state_update.finalize()?;
        Ok(ApplyResult {
            root: trie_changes.new_root,
            trie_changes,
            validator_proposals: validator_proposals,
            shard_id,
            new_receipts,
            tx_result,
            largest_tx_nonce,
        })
    }

    /// Balances are account, publickey, initial_balance, initial_tx_stake
    pub fn apply_genesis_state(
        &self,
        mut state_update: TrieUpdate,
        balances: &[(AccountId, ReadablePublicKey, Balance)],
        validators: &[(AccountId, ReadablePublicKey, Balance)],
        contracts: &[(AccountId, String)],
    ) -> (StoreUpdate, MerkleHash) {
        let mut code_hash: HashMap<String, CryptoHash> = HashMap::default();
        for (account_id, wasm) in contracts {
            let code =
                ContractCode::new(from_base(wasm).expect("Failed to decode wasm from base58"));
            code_hash.insert(account_id.clone(), code.get_hash());
            // TODO: why do we need code hash if we store code per account? should bee 1:n mapping.
            set(&mut state_update, key_for_code(&account_id), &code);
        }
        for (account_id, public_key, balance) in balances {
            set(
                &mut state_update,
                key_for_account(&account_id),
                &Account {
                    public_keys: vec![PublicKey::try_from(public_key.0.as_str()).unwrap()],
                    amount: *balance,
                    nonce: 0,
                    staked: 0,
                    code_hash: code_hash.remove(account_id).unwrap_or(CryptoHash::default()),
                    storage_usage: 0,
                    storage_paid_at: 0,
                },
            );
        }
        for (account_id, _, amount) in validators {
            let account_id_bytes = key_for_account(account_id);
            let mut account: Account =
                get(&state_update, &account_id_bytes).expect("account must exist");
            account.staked = *amount;
            set(&mut state_update, account_id_bytes, &account);
        }
        let trie = state_update.trie.clone();
        state_update
            .finalize()
            .expect("Genesis state update failed")
            .into(trie)
            .expect("Genesis state update failed")
    }
}

#[cfg(test)]
mod tests {
    use near_primitives::hash::hash;
    use near_primitives::types::MerkleHash;
    use near_store::test_utils::create_trie;
    use testlib::runtime_utils::bob_account;

    use super::*;

    // TODO(#348): Add tests for TX staking, mana charging and regeneration

    #[test]
    fn test_get_and_set_accounts() {
        let trie = create_trie();
        let mut state_update = TrieUpdate::new(trie, MerkleHash::default());
        let test_account = Account::new(vec![], 10, hash(&[]));
        let account_id = bob_account();
        set(&mut state_update, key_for_account(&account_id), &test_account);
        let get_res = get(&state_update, &key_for_account(&account_id)).unwrap();
        assert_eq!(test_account, get_res);
    }

    #[test]
    fn test_get_account_from_trie() {
        let trie = create_trie();
        let root = MerkleHash::default();
        let mut state_update = TrieUpdate::new(trie.clone(), root);
        let test_account = Account::new(vec![], 10, hash(&[]));
        let account_id = bob_account();
        set(&mut state_update, key_for_account(&account_id), &test_account);
        let (store_update, new_root) = state_update.finalize().unwrap().into(trie.clone()).unwrap();
        store_update.commit().unwrap();
        let new_state_update = TrieUpdate::new(trie.clone(), new_root);
        let get_res = get(&new_state_update, &key_for_account(&account_id)).unwrap();
        assert_eq!(test_account, get_res);
    }
}

'''
'''--- runtime/runtime/src/state_viewer.rs ---
use std::collections::HashMap;
use std::str;
use std::sync::{Arc, Mutex};
use std::time::Instant;

use near_primitives::account::{AccessKey, Account};
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::CryptoHash;
use near_primitives::serialize::{base_format, u128_hex_format};
use near_primitives::types::{AccountId, Balance, Nonce};
use near_primitives::utils::{is_valid_account_id, key_for_access_key, key_for_account};
use near_store::{get, TrieUpdate};
use wasm::executor;
use wasm::types::{ReturnData, RuntimeContext};

use crate::ethereum::EthashProvider;
use crate::Runtime;

use super::ext::ACCOUNT_DATA_SEPARATOR;
use super::RuntimeExt;

#[derive(Serialize, Deserialize)]
pub struct ViewStateResult {
    pub values: HashMap<Vec<u8>, Vec<u8>>,
}

pub struct TrieViewer {
    ethash_provider: Arc<Mutex<EthashProvider>>,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
pub struct AccountViewCallResult {
    pub account_id: AccountId,
    pub nonce: Nonce,
    #[serde(with = "u128_hex_format")]
    pub amount: Balance,
    #[serde(with = "u128_hex_format")]
    pub stake: Balance,
    pub public_keys: Vec<PublicKey>,
    #[serde(with = "base_format")]
    pub code_hash: CryptoHash,
}

impl TrieViewer {
    pub fn new(ethash_provider: Arc<Mutex<EthashProvider>>) -> Self {
        Self { ethash_provider }
    }

    pub fn view_account(
        &self,
        state_update: &TrieUpdate,
        account_id: &AccountId,
    ) -> Result<AccountViewCallResult, Box<dyn std::error::Error>> {
        if !is_valid_account_id(account_id) {
            return Err(format!("Account ID '{}' is not valid", account_id).into());
        }

        match get::<Account>(state_update, &key_for_account(account_id)) {
            Some(account) => Ok(AccountViewCallResult {
                account_id: account_id.clone(),
                nonce: account.nonce,
                amount: account.amount,
                stake: account.staked,
                public_keys: account.public_keys,
                code_hash: account.code_hash,
            }),
            _ => Err(format!("account {} does not exist while viewing", account_id).into()),
        }
    }

    pub fn view_access_key(
        &self,
        state_update: &TrieUpdate,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, Box<dyn std::error::Error>> {
        if !is_valid_account_id(account_id) {
            return Err(format!("Account ID '{}' is not valid", account_id).into());
        }

        Ok(get(state_update, &key_for_access_key(account_id, public_key)))
    }

    pub fn get_public_keys_for_account(
        &self,
        state_update: &TrieUpdate,
        account_id: &AccountId,
    ) -> Result<Vec<PublicKey>, Box<dyn std::error::Error>> {
        self.view_account(state_update, account_id).map(|account| account.public_keys)
    }

    pub fn view_state(
        &self,
        state_update: &TrieUpdate,
        account_id: &AccountId,
    ) -> Result<ViewStateResult, Box<dyn std::error::Error>> {
        if !is_valid_account_id(account_id) {
            return Err(format!("Account ID '{}' is not valid", account_id).into());
        }
        let mut values = HashMap::default();
        let mut prefix = key_for_account(account_id);
        prefix.extend_from_slice(ACCOUNT_DATA_SEPARATOR);
        state_update.for_keys_with_prefix(&prefix, |key| {
            if let Some(value) = state_update.get(key) {
                values.insert(key[prefix.len()..].to_vec(), value.to_vec());
            }
        });
        Ok(ViewStateResult { values })
    }

    pub fn call_function(
        &self,
        mut state_update: TrieUpdate,
        block_index: u64,
        contract_id: &AccountId,
        method_name: &str,
        args: &[u8],
        logs: &mut Vec<String>,
    ) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
        let now = Instant::now();
        if !is_valid_account_id(contract_id) {
            return Err(format!("Contract ID '{}' is not valid", contract_id).into());
        }
        let root = state_update.get_root();
        let code = Runtime::get_code(&state_update, contract_id)?;
        let wasm_res = match get::<Account>(&state_update, &key_for_account(contract_id)) {
            Some(account) => {
                let empty_hash = CryptoHash::default();
                let mut runtime_ext = RuntimeExt::new(
                    &mut state_update,
                    contract_id,
                    contract_id,
                    &empty_hash,
                    self.ethash_provider.clone(),
                );
                executor::execute(
                    &code,
                    method_name.as_bytes(),
                    &args.to_owned(),
                    &[],
                    &mut runtime_ext,
                    &wasm::types::Config::default(),
                    &RuntimeContext::new(
                        account.amount,
                        0,
                        contract_id,
                        contract_id,
                        0,
                        block_index,
                        root.as_ref().into(),
                        true,
                    ),
                )
            }
            None => return Err(format!("contract {} does not exist", contract_id).into()),
        };
        let elapsed = now.elapsed();
        let time_ms =
            (elapsed.as_secs() as f64 / 1_000.0) + f64::from(elapsed.subsec_nanos()) / 1_000_000.0;
        let time_str = format!("{:.*}ms", 2, time_ms);
        match wasm_res {
            Ok(res) => {
                debug!(target: "runtime", "(exec time {}) result of execution: {:#?}", time_str, res);
                logs.extend(res.logs);
                match res.return_data {
                    Ok(return_data) => {
                        let trie_update = state_update.finalize()?;
                        if trie_update.new_root != root {
                            return Err("function call for viewing tried to change storage".into());
                        }
                        let mut result = vec![];
                        if let ReturnData::Value(buf) = return_data {
                            result.extend(&buf);
                        }
                        Ok(result)
                    }
                    Err(e) => {
                        let message =
                            format!("wasm view call execution failed with error: {:?}", e);
                        debug!(target: "runtime", "{}", message);
                        Err(message.into())
                    }
                }
            }
            Err(e) => {
                let message = format!("wasm execution failed with error: {:?}", e);
                debug!(target: "runtime", "(exec time {}) {}", time_str, message);
                Err(message.into())
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use kvdb::DBValue;
    use tempdir::TempDir;

    use near_primitives::types::AccountId;
    use testlib::runtime_utils::{
        alice_account, encode_int, get_runtime_and_trie, get_test_trie_viewer,
    };

    use super::*;

    #[test]
    fn test_view_call() {
        let (viewer, root) = get_test_trie_viewer();

        let mut logs = vec![];
        let result =
            viewer.call_function(root, 1, &alice_account(), "run_test", &vec![], &mut logs);

        assert_eq!(result.unwrap(), encode_int(10));
    }

    #[test]
    fn test_view_call_bad_contract_id() {
        let (viewer, root) = get_test_trie_viewer();

        let mut logs = vec![];
        let result = viewer.call_function(
            root,
            1,
            &"bad!contract".to_string(),
            "run_test",
            &vec![],
            &mut logs,
        );

        assert!(result.is_err());
    }

    #[test]
    fn test_view_call_try_changing_storage() {
        let (viewer, root) = get_test_trie_viewer();

        let mut logs = vec![];
        let result = viewer.call_function(
            root,
            1,
            &alice_account(),
            "run_test_with_storage_change",
            &vec![],
            &mut logs,
        );
        // run_test tries to change storage, so it should fail
        assert!(result.is_err());
    }

    #[test]
    fn test_view_call_with_args() {
        let (viewer, root) = get_test_trie_viewer();
        let args = (1..3).into_iter().flat_map(|x| encode_int(x).to_vec()).collect::<Vec<_>>();
        let mut logs = vec![];
        let view_call_result =
            viewer.call_function(root, 1, &alice_account(), "sum_with_input", &args, &mut logs);
        assert_eq!(view_call_result.unwrap(), encode_int(3).to_vec());
    }

    fn account_suffix(account_id: &AccountId, suffix: &[u8]) -> Vec<u8> {
        let mut bytes = key_for_account(account_id);
        bytes.append(&mut ACCOUNT_DATA_SEPARATOR.to_vec());
        bytes.append(&mut suffix.clone().to_vec());
        bytes
    }

    #[test]
    fn test_view_state() {
        let (_, trie, root) = get_runtime_and_trie();
        let mut state_update = TrieUpdate::new(trie.clone(), root);
        state_update.set(account_suffix(&alice_account(), b"test123"), DBValue::from_slice(b"123"));
        let (db_changes, new_root) = state_update.finalize().unwrap().into(trie.clone()).unwrap();
        db_changes.commit().unwrap();

        let state_update = TrieUpdate::new(trie, new_root);
        let ethash_provider =
            EthashProvider::new(TempDir::new("runtime_user_test_ethash").unwrap().path());
        let trie_viewer = TrieViewer::new(Arc::new(Mutex::new(ethash_provider)));
        let result = trie_viewer.view_state(&state_update, &alice_account()).unwrap();
        assert_eq!(
            result.values,
            [(b"test123".to_vec(), b"123".to_vec())].iter().cloned().collect()
        );
    }
}

'''
'''--- runtime/runtime/src/system.rs ---
use std::convert::TryFrom;

use near_primitives::account::{AccessKey, Account};
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::{hash, CryptoHash};
use near_primitives::transaction::{
    AddKeyTransaction, AsyncCall, CallbackInfo, CallbackResult, CreateAccountTransaction,
    DeleteKeyTransaction, ReceiptBody, ReceiptTransaction, SendMoneyTransaction, StakeTransaction,
    SwapKeyTransaction,
};
use near_primitives::types::{AccountId, Balance, ValidatorStake};
use near_primitives::utils::{
    create_nonce_with_nonce, is_valid_account_id, key_for_access_key, key_for_account,
    key_for_code,
};
use near_store::{get, set, TrieUpdate};
use wasm::types::ContractCode;

pub const SYSTEM_METHOD_CREATE_ACCOUNT: &[u8] = b"_sys:create_account";

const INVALID_ACCOUNT_ID: &str =
    "does not match requirements. Must be 5-32 characters (lower case letters/numbers or '@._-')";

pub fn send_money(
    state_update: &mut TrieUpdate,
    transaction: &SendMoneyTransaction,
    hash: CryptoHash,
    sender: &mut Account,
    refund_account_id: &AccountId,
) -> Result<Vec<ReceiptTransaction>, String> {
    if transaction.amount == 0 {
        return Err("Sending 0 tokens".to_string());
    }
    if sender.amount >= transaction.amount {
        sender.amount -= transaction.amount;
        set(state_update, key_for_account(&transaction.originator), sender);
        let receipt = ReceiptTransaction::new(
            transaction.originator.clone(),
            transaction.receiver.clone(),
            create_nonce_with_nonce(&hash, 0),
            ReceiptBody::NewCall(AsyncCall::new(
                // Empty method name is used for deposit
                vec![],
                vec![],
                transaction.amount,
                refund_account_id.clone(),
            )),
        );
        Ok(vec![receipt])
    } else {
        Err(format!(
            "Account {} tries to send {}, but has staked {} and only has {}",
            transaction.originator, transaction.amount, sender.staked, sender.amount,
        ))
    }
}

pub fn staking(
    state_update: &mut TrieUpdate,
    body: &StakeTransaction,
    sender_account_id: &AccountId,
    sender: &mut Account,
    validator_proposals: &mut Vec<ValidatorStake>,
) -> Result<Vec<ReceiptTransaction>, String> {
    if sender.amount >= body.amount {
        validator_proposals.push(ValidatorStake {
            account_id: sender_account_id.clone(),
            public_key: PublicKey::try_from(body.public_key.as_str())
                .map_err(|err| err.to_string())?,
            amount: body.amount,
        });
        sender.amount -= body.amount;
        sender.staked += body.amount;
        set(state_update, key_for_account(sender_account_id), &sender);
        Ok(vec![])
    } else {
        let err_msg = format!(
            "Account {} tries to stake {}, but has staked {} and only has {}",
            body.originator, body.amount, sender.staked, sender.amount,
        );
        Err(err_msg)
    }
}

pub fn deposit(
    state_update: &mut TrieUpdate,
    amount: Balance,
    callback_info: &Option<CallbackInfo>,
    receiver_id: &AccountId,
    nonce: &CryptoHash,
    receiver: &mut Account,
) -> Result<Vec<ReceiptTransaction>, String> {
    let mut receipts = vec![];
    if let Some(callback_info) = callback_info {
        let new_nonce = create_nonce_with_nonce(&nonce, 0);
        let new_receipt = ReceiptTransaction::new(
            receiver_id.clone(),
            callback_info.receiver.clone(),
            new_nonce,
            ReceiptBody::Callback(CallbackResult::new(callback_info.clone(), Some(vec![]))),
        );
        receipts.push(new_receipt);
    }

    if amount > 0 {
        receiver.amount += amount;
        set(state_update, key_for_account(&receiver_id), receiver);
    }
    Ok(receipts)
}

pub fn create_account(
    state_update: &mut TrieUpdate,
    body: &CreateAccountTransaction,
    hash: CryptoHash,
    sender: &mut Account,
    refund_account_id: &AccountId,
) -> Result<Vec<ReceiptTransaction>, String> {
    if !is_valid_account_id(&body.new_account_id) {
        return Err(format!("Account name {} {}", body.new_account_id, INVALID_ACCOUNT_ID));
    }
    if sender.amount >= body.amount {
        sender.amount -= body.amount;
        set(state_update, key_for_account(&body.originator), &sender);
        let new_nonce = create_nonce_with_nonce(&hash, 0);
        let receipt = ReceiptTransaction::new(
            body.originator.clone(),
            body.new_account_id.clone(),
            new_nonce,
            ReceiptBody::NewCall(AsyncCall::new(
                SYSTEM_METHOD_CREATE_ACCOUNT.to_vec(),
                body.public_key.clone(),
                body.amount,
                refund_account_id.clone(),
            )),
        );
        Ok(vec![receipt])
    } else {
        Err(format!(
            "Account {} tries to create new account with {}, but only has {}",
            body.originator, body.amount, sender.amount
        ))
    }
}

pub fn deploy(
    state_update: &mut TrieUpdate,
    sender_id: &AccountId,
    code: &[u8],
    sender: &mut Account,
) -> Result<Vec<ReceiptTransaction>, String> {
    let code = ContractCode::new(code.to_vec());
    // Signature should be already checked at this point
    sender.code_hash = code.get_hash();
    set(state_update, key_for_code(&sender_id), &code);
    set(state_update, key_for_account(&sender_id), &sender);
    Ok(vec![])
}

pub fn swap_key(
    state_update: &mut TrieUpdate,
    body: &SwapKeyTransaction,
    account: &mut Account,
) -> Result<Vec<ReceiptTransaction>, String> {
    let cur_key = PublicKey::try_from(&body.cur_key as &[u8]).map_err(|e| format!("{}", e))?;
    let new_key = PublicKey::try_from(&body.new_key as &[u8]).map_err(|e| format!("{}", e))?;
    let num_keys = account.public_keys.len();
    account.public_keys.retain(|&x| x != cur_key);
    if account.public_keys.len() == num_keys {
        return Err(format!("Account {} does not have public key {}", body.originator, cur_key));
    }
    account.public_keys.push(new_key);
    set(state_update, key_for_account(&body.originator), &account);
    Ok(vec![])
}

pub fn add_key(
    state_update: &mut TrieUpdate,
    body: &AddKeyTransaction,
    account: &mut Account,
) -> Result<Vec<ReceiptTransaction>, String> {
    let new_key = PublicKey::try_from(&body.new_key as &[u8]).map_err(|e| format!("{}", e))?;
    let num_keys = account.public_keys.len();
    account.public_keys.retain(|&x| x != new_key);
    if account.public_keys.len() < num_keys {
        return Err("Cannot add a public key that already exists on the account".to_string());
    }
    if get::<AccessKey>(&state_update, &key_for_access_key(&body.originator, &new_key)).is_some() {
        return Err("Cannot add a public key that already used for an access key".to_string());
    }
    if let Some(access_key) = &body.access_key {
        if account.amount >= access_key.amount {
            if access_key.amount > 0 {
                account.amount -= access_key.amount;
                set(state_update, key_for_account(&body.originator), &account);
            }
        } else {
            return Err(format!(
                "Account {} tries to create new access key with {} amount, but only has {}",
                body.originator, access_key.amount, account.amount
            ));
        }
        if let Some(ref balance_owner) = access_key.balance_owner {
            if !is_valid_account_id(balance_owner) {
                return Err("Invalid account ID for balance owner in the access key".to_string());
            }
        }
        if let Some(ref contract_id) = access_key.contract_id {
            if !is_valid_account_id(contract_id) {
                return Err("Invalid account ID for contract ID in the access key".to_string());
            }
        }
        set(state_update, key_for_access_key(&body.originator, &new_key), access_key);
    } else {
        account.public_keys.push(new_key);
        set(state_update, key_for_account(&body.originator), &account);
    }
    Ok(vec![])
}

pub fn delete_key(
    state_update: &mut TrieUpdate,
    body: &DeleteKeyTransaction,
    account: &mut Account,
    nonce: CryptoHash,
) -> Result<Vec<ReceiptTransaction>, String> {
    let cur_key = PublicKey::try_from(&body.cur_key as &[u8]).map_err(|e| format!("{}", e))?;
    let num_keys = account.public_keys.len();
    let mut new_receipts = vec![];
    account.public_keys.retain(|&x| x != cur_key);
    if account.public_keys.len() == num_keys {
        let access_key: AccessKey = get(
            &state_update,
            &key_for_access_key(&body.originator, &cur_key),
        )
        .ok_or_else(|| {
            format!("Account {} tries to remove a public key that it does not own", body.originator)
        })?;
        if access_key.amount > 0 {
            let balance_owner_id: &AccountId =
                access_key.balance_owner.as_ref().unwrap_or(&body.originator);
            if balance_owner_id != &body.originator {
                let new_receipt = ReceiptTransaction::new(
                    body.originator.clone(),
                    balance_owner_id.clone(),
                    create_nonce_with_nonce(&nonce, 0),
                    ReceiptBody::Refund(access_key.amount),
                );
                new_receipts.push(new_receipt);
            } else {
                account.amount += access_key.amount;
                set(state_update, key_for_account(&body.originator), &account);
            }
        }
        // Remove access key
        state_update.remove(&key_for_access_key(&body.originator, &cur_key));
    } else {
        set(state_update, key_for_account(&body.originator), &account);
    }
    Ok(new_receipts)
}

pub fn system_create_account(
    state_update: &mut TrieUpdate,
    call: &AsyncCall,
    account_id: &AccountId,
) -> Result<Vec<ReceiptTransaction>, String> {
    if !is_valid_account_id(account_id) {
        return Err(format!("Account name {} {}", account_id, INVALID_ACCOUNT_ID));
    }
    let account_id_bytes = key_for_account(&account_id);

    let public_key = PublicKey::try_from(&call.args as &[u8]).map_err(|e| format!("{}", e))?;
    let new_account = Account::new(vec![public_key], call.amount, hash(&[]));
    set(state_update, account_id_bytes, &new_account);
    Ok(vec![])
}

'''
'''--- runtime/runtime/src/tx_stakes.rs ---
use std::cmp::{max, min};

use primitives::types::{Balance, BlockIndex, Gas, Mana};

// Transaction Stakes structs
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct TxStakeConfig {
    /// Common denumerator for mana accounting
    pub mana_common_denum: u64,
    /// How much mana you get for a single coin of stake (numerator).
    pub mana_per_coin_num: u64,
    /// Regeneration rate numerator of mana per block per coin of stake.
    /// Mana is regenerated only after gas is fully regenerated.
    pub mana_regen_per_block_per_coin_num: u64,

    /// Regeneration rate of gas per block per coin of stake.
    pub gas_regen_per_block_per_coin: Gas,
}

impl Default for TxStakeConfig {
    fn default() -> TxStakeConfig {
        TxStakeConfig {
            mana_common_denum: 1_000,
            /// Default is 10 mana per coin
            mana_per_coin_num: 10_000,
            /// Full mana regeneration within T blocks is:
            ///     mana_per_coin_num / T
            /// We use default 20 blocks for full regeneration
            mana_regen_per_block_per_coin_num: 10_000 / 20,
            /// For cheap transaction gas shouldn't be an issue, but for
            /// expensive we should count full gas limit as a few mana points
            /// Let's say full gas limit is 5 mana points
            /// If the full gas limit is 100K then equivalent of 1 mana is 20K
            /// We regenerate 10 mana per 20 blocks, it's 0.5 mana per block
            /// Which results in 0.5 * 20K = 10K gas per block per coin.
            gas_regen_per_block_per_coin: 10_000,
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct TxTotalStake {
    /// Used Mana numerator. Denumerator is common per config.
    mana_used_num: u64,
    /// Total amount of gas used. Without denumerator
    gas_used: Gas,
    /// Last update block index is used for mana and gas regeneration.
    /// Whenever we touch TxTotalStake we should use difference between the
    /// current and the last update block indices to recalculate and update
    /// mana_used and gas_used counters based on the current total_stake and
    /// the number of blocks from the last update.
    last_update_block_index: BlockIndex,
    total_active_stake: Balance,
    total_stake: Balance,
}

#[allow(unused)]
impl TxTotalStake {
    pub fn new(block_index: BlockIndex) -> TxTotalStake {
        TxTotalStake {
            mana_used_num: 0,
            gas_used: 0,
            last_update_block_index: block_index,
            total_active_stake: 0,
            total_stake: 0,
        }
    }

    /// Updates usage values and regenerates used mana and gas.
    /// Should always be called before modifying the stakes.
    pub fn update(&mut self, block_index: BlockIndex, config: &TxStakeConfig) {
        assert!(self.last_update_block_index <= block_index);
        if self.last_update_block_index == block_index {
            return;
        }
        let mut blocks_difference = block_index - self.last_update_block_index;
        self.last_update_block_index = block_index;
        if self.total_stake == 0 {
            return;
        }
        if self.gas_used > 0 {
            // Regenerating gas
            let gas_regen_rate = config.gas_regen_per_block_per_coin * self.total_stake;
            let blocks_needed = (self.gas_used + gas_regen_rate - 1) / gas_regen_rate;
            let blocks_regenerated = min(blocks_difference, blocks_needed);
            self.gas_used -= min(self.gas_used, blocks_regenerated * gas_regen_rate);
            blocks_difference -= blocks_regenerated;
        }
        if blocks_difference > 0 && self.mana_used_num > 0 {
            // Regenerating mana
            let mana_regen_rate_num = config.mana_regen_per_block_per_coin_num * self.total_stake;
            let blocks_needed =
                (self.mana_used_num + mana_regen_rate_num - 1) / mana_regen_rate_num;
            let blocks_regenerated = min(blocks_difference, blocks_needed);
            self.mana_used_num -= min(self.mana_used_num, blocks_regenerated * mana_regen_rate_num);
        }
    }

    /// Returns the available mana using the data from the last update.
    /// Make sure to update using the latest block index before calling it.
    pub fn available_mana(&self, config: &TxStakeConfig) -> Mana {
        // NEED to know the current block ID to add regeneration
        let mut mana_num = self.total_active_stake * config.mana_per_coin_num;
        mana_num -= self.mana_used_num;
        min(max(mana_num / config.mana_common_denum, 0), Mana::max_value().into()) as u32
    }

    pub fn charge_mana(&mut self, mana: Mana, config: &TxStakeConfig) {
        self.mana_used_num += u64::from(mana) * config.mana_common_denum;
    }

    pub fn refund_mana_and_charge_gas(
        &mut self,
        mana_refund: Mana,
        gas_used: Gas,
        config: &TxStakeConfig,
    ) {
        let mana_refund_num = u64::from(mana_refund) * config.mana_common_denum;
        if mana_refund_num >= self.mana_used_num {
            self.mana_used_num = 0
        } else {
            self.mana_used_num -= mana_refund_num;
        }
        self.gas_used += gas_used;
    }

    pub fn add_active_stake(&mut self, stake: Balance) {
        self.total_active_stake += stake;
        self.total_stake += stake;
    }
}

'''
'''--- runtime/runtime/tests/test_evil_contracts.rs ---
use near_primitives::transaction::{
    CreateAccountTransaction, DeployContractTransaction, TransactionBody,
};
use near_primitives::types::Balance;
use testlib::node::{Node, RuntimeNode};

const FUNCTION_CALL_AMOUNT: Balance = 1_000_000_000;

fn setup_test_contract(wasm_binary: &[u8]) -> RuntimeNode {
    let node = RuntimeNode::new(&"alice.near".to_string());
    let account_id = node.account_id().unwrap();
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(&account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: "test_contract".to_string(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: 0,
    })
    .sign(&*node.signer());
    let user = node.user();
    user.add_transaction(transaction).unwrap();

    let transaction = TransactionBody::DeployContract(DeployContractTransaction {
        nonce: node.get_account_nonce(&account_id).unwrap_or_default() + 1,
        contract_id: "test_contract".to_string(),
        wasm_byte_array: wasm_binary.to_vec(),
    })
    .sign(&*node.signer());
    user.add_transaction(transaction).unwrap();
    node
}

#[test]
fn test_evil_deep_trie() {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    (0..50).for_each(|i| {
        println!("insertStrings #{}", i);
        let input_data = format!("{{\"from\": {}, \"to\": {}}}", i * 10, (i + 1) * 10);
        node.call_function(
            "test_contract",
            "insertStrings",
            input_data.as_bytes().to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
    (0..50).rev().for_each(|i| {
        println!("deleteStrings #{}", i);
        let input_data = format!("{{\"from\": {}, \"to\": {}}}", i * 10, (i + 1) * 10);
        node.call_function(
            "test_contract",
            "deleteStrings",
            input_data.as_bytes().to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

#[test]
fn test_evil_deep_recursion() {
    let node = setup_test_contract(include_bytes!("../../../tests/hello.wasm"));
    [100, 1000, 10000, 100000, 1000000].iter().for_each(|n| {
        println!("{}", n);
        let input_data = format!("{{\"n\": {}}}", n);
        node.call_function(
            "test_contract",
            "recurse",
            input_data.as_bytes().to_vec(),
            FUNCTION_CALL_AMOUNT,
        );
    });
}

'''
'''--- runtime/storage/Cargo.toml ---
[package]
name = "storage"
version = "0.0.1"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
bincode = "1.0.0"
byteorder = "1.2"
elastic-array = { version = "0.10" }
kvdb = "0.1"
kvdb-memorydb = "0.1"
kvdb-rocksdb = "0.1.3"
log = "0.4"
parity-rocksdb = "0.5"
parking_lot = "0.7.1"
serde = "1.0"
serde_derive = "1.0"
cached = { git = "https://github.com/nearprotocol/cached", rev = "7e472eddef68607e344d5a106a0e6705d92e55be" }

primitives = { path = "../primitives" }

[dev-dependencies]
hex-literal = "0.1.1"
bencher = "0.1.5"
rand = "0.6"

[features]
test-utils = []

[[bench]]
name = "trie_bench"
harness = false

[[bench]]
name = "storage_bench"
harness = false

'''
'''--- runtime/storage/benches/storage_bench.rs ---
#[macro_use]
extern crate bencher;
extern crate rand;

use bencher::Bencher;

extern crate storage;

use std::sync::Arc;

use std::path::Path;
use std::sync::RwLock;
use storage::create_storage;
use storage::BeaconChainStorage;
use storage::ShardChainStorage;
use primitives::beacon::SignedBeaconBlock;
use primitives::hash::CryptoHash;
use storage::storages::GenericStorage;

const TMP_DIR: &str = "./tmp_bench/";

fn get_storage(
    test_name: &str,
) -> (Arc<RwLock<BeaconChainStorage>>, Arc<RwLock<ShardChainStorage>>) {
    let mut base_path = Path::new(TMP_DIR).to_owned();
    base_path.push(test_name);
    if base_path.exists() {
        std::fs::remove_dir_all(base_path.clone()).unwrap();
    }
    let (beacon_chain, mut shard_chains) = create_storage(base_path.to_str().unwrap(), 1);
    let shard_chain = shard_chains.pop().unwrap();
    (beacon_chain, shard_chain)
}

fn storage_save_block(bench: &mut Bencher) {
    let (beacon_chain, _) = get_storage("storage_save");
    let mut blocks = vec![];
    let mut prev_hash = CryptoHash::default();
    for i in 0..10 {
        let block = SignedBeaconBlock::new(i, prev_hash, vec![], CryptoHash::default());
        prev_hash = block.hash;
        if i == 0 {
            beacon_chain.write().unwrap().blockchain_storage_mut().set_genesis(block.clone()).unwrap();
        }
        blocks.push(block);
    }
    bench.iter(move || {
        for b in blocks.drain(..) {
            beacon_chain.write().unwrap().blockchain_storage_mut().add_block(b).unwrap();
        }
    });
}

fn storage_save_get_block(bench: &mut Bencher) {
    let (beacon_chain, _) = get_storage("storage_save");
    let mut blocks_hashes = vec![];
    let mut prev_hash = CryptoHash::default();
    for i in 0..10 {
        let block = SignedBeaconBlock::new(i, prev_hash, vec![], CryptoHash::default());
        prev_hash = block.hash;
        blocks_hashes.push(block.hash);
        if i == 0 {
            beacon_chain.write().unwrap().blockchain_storage_mut().set_genesis(block.clone()).unwrap();
        }
        beacon_chain.write().unwrap().blockchain_storage_mut().add_block(block).unwrap();
    }
    bench.iter(move || {
        for h in &blocks_hashes {
            beacon_chain.write().unwrap().blockchain_storage_mut().block(h).unwrap();
        }
    });
}

benchmark_group!(benches, storage_save_block, storage_save_get_block);
benchmark_main!(benches);

'''
'''--- runtime/storage/benches/trie_bench.rs ---
#[macro_use]
extern crate bencher;
extern crate rand;
extern crate storage;

use bencher::Bencher;
use rand::random;

use storage::test_utils::create_trie;
use storage::Trie;

fn rand_bytes() -> Vec<u8> {
    (0..10).map(|_| random::<u8>()).collect()
}

fn trie_lookup(bench: &mut Bencher) {
    let trie = create_trie();
    let root = Trie::empty_root();
    let mut changes = vec![];
    for _ in 0..100 {
        changes.push((rand_bytes(), Some(rand_bytes())));
    }
    let other_changes = changes.clone();
    let (db_changes, root) = trie.update(&root, changes.drain(..));
    trie.apply_changes(db_changes).expect("Failed to commit");

    bench.iter(|| {
        for _ in 0..1 {
            for (key, _) in other_changes.iter() {
                trie.get(&root, &key).unwrap();
            }
        }
    });
}

fn trie_update(bench: &mut Bencher) {
    let trie = create_trie();
    let root = Trie::empty_root();
    let mut changes = vec![];
    for _ in 0..100 {
        changes.push((rand_bytes(), Some(rand_bytes())));
    }

    bench.iter(|| {
        let mut this_changes = changes.clone();
        let (_, _) = trie.update(&root, this_changes.drain(..));
    });
}

benchmark_group!(benches, trie_lookup, trie_update);
benchmark_main!(benches);

'''
'''--- runtime/storage/src/lib.rs ---
extern crate byteorder;
extern crate elastic_array;
#[cfg(test)]
extern crate hex_literal;
#[macro_use]
extern crate log;
extern crate primitives;
#[cfg(test)]
extern crate rand;

use std::sync::Arc;
use std::sync::RwLock;

pub use kvdb::{DBTransaction, DBValue, KeyValueDB};
use kvdb_rocksdb::{Database, DatabaseConfig};

use serde::{de::DeserializeOwned, Serialize};

pub use crate::storages::beacon::BeaconChainStorage;
pub use crate::storages::shard::ShardChainStorage;
use crate::storages::NUM_COLS;
pub use crate::storages::{BlockChainStorage, GenericStorage};
pub use crate::trie::update::{TrieUpdate, TrieUpdateIterator};
pub use crate::trie::{DBChanges, Trie};
use primitives::serialize::{Decode, Encode};

pub mod storages;
pub mod test_utils;
pub mod trie;

pub fn get<T: DeserializeOwned>(state_update: &TrieUpdate, key: &[u8]) -> Option<T> {
    state_update.get(key).and_then(|data| Decode::decode(&data).ok())
}

pub fn set<T: Serialize>(state_update: &mut TrieUpdate, key: Vec<u8>, value: &T) {
    value.encode().ok().map(|data| state_update.set(key, DBValue::from_vec(data))).or_else(|| {
        debug!("set value failed");
        None
    });
}

/// Initializes beacon and shard chain storages from the given path.
pub fn create_storage(
    storage_path: &str,
    num_shards: u32,
) -> (Arc<RwLock<BeaconChainStorage>>, Vec<Arc<RwLock<ShardChainStorage>>>) {
    let db_config = DatabaseConfig::with_columns(Some(NUM_COLS));
    let db =
        Arc::new(Database::open(&db_config, storage_path).expect("Failed to open the database"));
    let beacon = Arc::new(RwLock::new(BeaconChainStorage::new(db.clone())));
    let mut shards = vec![];
    for id in 0..num_shards {
        shards.push(Arc::new(RwLock::new(ShardChainStorage::new(db.clone(), id))));
    }
    (beacon, shards)
}

'''
'''--- runtime/storage/src/storages/beacon.rs ---
use super::{
    extend_with_cache, prune_index, read_with_cache, write_with_cache, BlockChainStorage,
    GenericStorage, CACHE_SIZE, COL_ACCEPTED_AUTHORITY, COL_PARTICIPATION, COL_PROCESSED_BLOCKS,
    COL_PROPOSAL, COL_THRESHOLD,
};
use crate::storages::ChainId;
use crate::KeyValueDB;
use cached::SizedCache;
use primitives::beacon::{SignedBeaconBlock, SignedBeaconBlockHeader};
use primitives::types::{AuthorityMask, AuthorityStake, Epoch, Slot};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;

/// Beacon chain does not require additional behavior besides storing and retrieving blocks. Later,
/// we can add authority info.
pub struct BeaconChainStorage {
    generic_storage: BlockChainStorage<SignedBeaconBlockHeader, SignedBeaconBlock>,
    /// Proposals per slot in which they occur.
    proposals: SizedCache<Vec<u8>, Vec<AuthorityStake>>,
    /// Participation of authorities per slot in which they have happened.
    participation: SizedCache<Vec<u8>, AuthorityMask>,
    /// Records the blocks that it processed for the given epochs.
    processed_blocks: SizedCache<Vec<u8>, HashSet<Slot>>,

    // The following is derived information which we do not want to recompute.
    /// Computed thresholds for each epoch.
    thresholds: SizedCache<Vec<u8>, u64>,
    /// Authorities that were accepted for the given slots.
    accepted_authorities: SizedCache<Vec<u8>, Vec<AuthorityStake>>,
}

impl GenericStorage<SignedBeaconBlockHeader, SignedBeaconBlock> for BeaconChainStorage {
    #[inline]
    fn blockchain_storage_mut(
        &mut self,
    ) -> &mut BlockChainStorage<SignedBeaconBlockHeader, SignedBeaconBlock> {
        &mut self.generic_storage
    }
}

impl BeaconChainStorage {
    pub fn new(storage: Arc<KeyValueDB>) -> Self {
        Self {
            generic_storage: BlockChainStorage::new(storage, ChainId::BeaconChain),
            proposals: SizedCache::with_size(CACHE_SIZE),
            participation: SizedCache::with_size(CACHE_SIZE),
            processed_blocks: SizedCache::with_size(CACHE_SIZE),
            thresholds: SizedCache::with_size(CACHE_SIZE),
            accepted_authorities: SizedCache::with_size(CACHE_SIZE),
        }
    }

    /// whether there is authority info in storage
    pub fn is_authority_empty(&self) -> bool {
        let proposals: HashMap<_, _> =
            self.generic_storage.storage.iter(Some(COL_PROPOSAL)).collect();
        proposals.is_empty()
    }

    pub fn prune_authority_storage(
        &mut self,
        slot_filter: &Fn(Slot) -> bool,
        epoch_filter: &Fn(Epoch) -> bool,
    ) {
        prune_index(
            self.generic_storage.storage.as_ref(),
            COL_PROPOSAL,
            &mut self.proposals,
            slot_filter,
        )
        .expect("Failed to prune storage");
        prune_index(
            self.generic_storage.storage.as_ref(),
            COL_PARTICIPATION,
            &mut self.participation,
            slot_filter,
        )
        .expect("Failed to prune storage");
        prune_index(
            self.generic_storage.storage.as_ref(),
            COL_PROCESSED_BLOCKS,
            &mut self.processed_blocks,
            epoch_filter,
        )
        .expect("Failed to prune storage");
        prune_index(
            self.generic_storage.storage.as_ref(),
            COL_THRESHOLD,
            &mut self.thresholds,
            epoch_filter,
        )
        .expect("Failed to prune storage");
        prune_index(
            self.generic_storage.storage.as_ref(),
            COL_ACCEPTED_AUTHORITY,
            &mut self.accepted_authorities,
            slot_filter,
        )
        .expect("Failed to prune storage");
    }

    pub fn get_proposal(&mut self, slot: Slot) -> Option<&Vec<AuthorityStake>> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PROPOSAL,
            &mut self.proposals,
            &self.generic_storage.enc_index(slot),
        )
        .expect("Failed to read from storage")
    }

    pub fn set_proposal(&mut self, slot: Slot, proposal: Vec<AuthorityStake>) {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PROPOSAL,
            &mut self.proposals,
            &self.generic_storage.enc_index(slot),
            proposal,
        )
        .expect("Failed to write to storage")
    }

    pub fn get_participation(&mut self, slot: Slot) -> Option<&AuthorityMask> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PARTICIPATION,
            &mut self.participation,
            &self.generic_storage.enc_index(slot),
        )
        .expect("Failed to read from storage")
    }

    pub fn set_participation(&mut self, slot: Slot, mask: AuthorityMask) {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PARTICIPATION,
            &mut self.participation,
            &self.generic_storage.enc_index(slot),
            mask,
        )
        .expect("Failed to write to storage")
    }

    pub fn get_processed_blocks(&mut self, epoch: Epoch) -> Option<&HashSet<Slot>> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PROCESSED_BLOCKS,
            &mut self.processed_blocks,
            &self.generic_storage.enc_index(epoch),
        )
        .expect("Failed to read from storage")
    }

    pub fn set_processed_blocks(&mut self, epoch: Epoch, processed_blocks: HashSet<Slot>) {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_PROCESSED_BLOCKS,
            &mut self.processed_blocks,
            &self.generic_storage.enc_index(epoch),
            processed_blocks,
        )
        .expect("Failed to write to storage")
    }

    pub fn get_threshold(&mut self, epoch: Epoch) -> Option<&u64> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_THRESHOLD,
            &mut self.thresholds,
            &self.generic_storage.enc_index(epoch),
        )
        .expect("Failed to read from storage")
    }

    pub fn set_threshold(&mut self, epoch: Epoch, threshold: u64) {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_THRESHOLD,
            &mut self.thresholds,
            &self.generic_storage.enc_index(epoch),
            threshold,
        )
        .expect("Failed to write to storage")
    }

    pub fn get_accepted_authorities(&mut self, slot: Slot) -> Option<&Vec<AuthorityStake>> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_ACCEPTED_AUTHORITY,
            &mut self.accepted_authorities,
            &self.generic_storage.enc_index(slot),
        )
        .expect("Failed to read from storage")
    }

    pub fn set_accepted_authorities(&mut self, slot: Slot, authorities: Vec<AuthorityStake>) {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_ACCEPTED_AUTHORITY,
            &mut self.accepted_authorities,
            &self.generic_storage.enc_index(slot),
            authorities,
        )
        .expect("Failed to write to storage")
    }

    pub fn extend_accepted_authorities(&mut self, authorities: HashMap<Slot, Vec<AuthorityStake>>) {
        let updates = authorities
            .into_iter()
            .map(|(k, v)| (self.generic_storage.enc_index(k).to_vec(), v))
            .collect();
        extend_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_ACCEPTED_AUTHORITY,
            &mut self.accepted_authorities,
            updates,
        )
        .expect("Failed to write to storage");
    }
}

'''
'''--- runtime/storage/src/storages/mod.rs ---
//! Several specializations of the storage over the general-purpose key-value storage used by the
//! generic BlockChain and by specific BeaconChain/ShardChain.
use crate::KeyValueDB;
use cached::{Cached, SizedCache};
use primitives::block_traits::SignedBlock;
use primitives::block_traits::SignedHeader;
use primitives::hash::CryptoHash;
use primitives::serialize::{Decode, Encode};
use std::collections::HashMap;
use std::io;
use std::sync::Arc;

pub mod beacon;
pub mod shard;

type StorageResult<T> = io::Result<Option<T>>;

/// Uniquely identifies the chain.
#[derive(Clone)]
pub enum ChainId {
    BeaconChain,
    ShardChain(u32),
}

impl From<ChainId> for u32 {
    fn from(id: ChainId) -> u32 {
        match id {
            ChainId::BeaconChain => 0u32,
            ChainId::ShardChain(i) => i + 1,
        }
    }
}

impl From<u32> for ChainId {
    fn from(id: u32) -> Self {
        if id == 0 {
            ChainId::BeaconChain
        } else {
            ChainId::ShardChain(id - 1)
        }
    }
}

// Columns that are used both by beacon and shard chain.
/// Column that stores the mapping: genesis hash -> best block hash.
const COL_BEST_BLOCK: u32 = 0;
/// Column that stores the mapping: header hash -> header.
const COL_HEADERS: u32 = 1;
/// Column that stores the mapping: block header hash -> block.
const COL_BLOCKS: u32 = 2;
/// Column that stores the indices of the current chain through the mapping: block index -> header
/// hash.
const COL_BLOCK_INDICES: u32 = 3;

// Columns that are used by the shard chain only.
const COL_STATE: u32 = 4;
const COL_TRANSACTION_RESULTS: u32 = 5;
const COL_TRANSACTION_ADDRESSES: u32 = 6;
const COL_RECEIPT_BLOCK: u32 = 7;
const COL_TX_NONCE: u32 = 8;

// Columns used by the beacon chain only.
const COL_PROPOSAL: u32 = 9;
const COL_PARTICIPATION: u32 = 10;
const COL_PROCESSED_BLOCKS: u32 = 11;
const COL_THRESHOLD: u32 = 12;
const COL_ACCEPTED_AUTHORITY: u32 = 13;

/// Number of columns per chain.
pub const NUM_COLS: u32 = 14;

/// Error that occurs when we try operating with genesis-specific columns, without setting the
/// genesis in advance.
const MISSING_GENESIS_ERR: &str = "Genesis is not set.";

/// lru cache size
const CACHE_SIZE: usize = 20;

pub struct BlockChainStorage<H, B> {
    chain_id: ChainId,
    storage: Arc<KeyValueDB>,
    genesis_hash: Option<CryptoHash>,
    // keyed by hash
    best_block_hash: SizedCache<Vec<u8>, CryptoHash>,
    best_block_index: SizedCache<Vec<u8>, u64>,
    // keyed by hash
    headers: SizedCache<Vec<u8>, H>,
    // keyed by hash
    blocks: SizedCache<Vec<u8>, B>,
    // keyed by index
    block_indices: SizedCache<Vec<u8>, CryptoHash>,
}

/// Specific block chain storages like beacon chain storage and shard chain storage should implement
/// this trait to allow them to be used in specific beacon chain and shard chain. Rust way of doing
/// polymorphism.
pub trait GenericStorage<H, B> {
    /// Returns reference to the internal generic BlockChain storage.
    fn blockchain_storage_mut(&mut self) -> &mut BlockChainStorage<H, B>;
}

impl<H, B> BlockChainStorage<H, B>
where
    H: SignedHeader,
    B: SignedBlock<SignedHeader = H>,
{
    /// Encodes a slice of bytes into a vector by adding a prefix that corresponds to the chain id.
    pub fn enc_slice(&self, slice: &[u8]) -> Vec<u8> {
        let id: u32 = self.chain_id.clone().into();
        let mut res = Vec::with_capacity(4 + slice.len());
        res.extend_from_slice(chain_id_to_bytes(&id));
        res.extend_from_slice(slice);
        res
    }

    /// Encodes hash by adding a prefix that corresponds to the chain id.
    pub fn enc_hash(&self, hash: &CryptoHash) -> [u8; 36] {
        let id: u32 = self.chain_id.clone().into();
        let mut res = [0; 36];
        res[..4].copy_from_slice(chain_id_to_bytes(&id));
        res[4..].copy_from_slice(hash.as_ref());
        res
    }

    /// Encodes block index by adding a prefix that corresponds to the chain id.
    fn enc_index(&self, index: u64) -> [u8; 12] {
        let id: u32 = self.chain_id.clone().into();
        let mut res = [0; 12];
        res[..4].copy_from_slice(chain_id_to_bytes(&id));
        res[4..].copy_from_slice(index_to_bytes(&index));
        res
    }

    pub fn new(storage: Arc<KeyValueDB>, chain_id: ChainId) -> Self {
        Self {
            storage,
            chain_id,
            genesis_hash: None,
            best_block_hash: SizedCache::with_size(CACHE_SIZE),
            best_block_index: SizedCache::with_size(CACHE_SIZE),
            headers: SizedCache::with_size(CACHE_SIZE),
            blocks: SizedCache::with_size(CACHE_SIZE),
            block_indices: SizedCache::with_size(CACHE_SIZE),
        }
    }

    pub fn genesis_hash(&self) -> &CryptoHash {
        self.genesis_hash.as_ref().expect(MISSING_GENESIS_ERR)
    }

    pub fn set_genesis_hash(&mut self, genesis_hash: CryptoHash) -> io::Result<()> {
        if let Some(current_genesis_hash) = self.genesis_hash {
            if current_genesis_hash != genesis_hash {
                return Err(io::Error::new(io::ErrorKind::InvalidInput, "invalid genesis"));
            }
        }
        self.genesis_hash = Some(genesis_hash);
        Ok(())
    }

    pub fn set_genesis(&mut self, genesis: B) -> io::Result<()> {
        self.set_genesis_hash(genesis.block_hash())?;
        if self.block(&genesis.block_hash())?.is_none() {
            // Only add genesis block if it was not added before. It might have been added before
            // if we have launched on the existing storage.
            self.add_block(genesis)
        } else {
            Ok(())
        }
    }

    pub fn add_block(&mut self, block: B) -> io::Result<()> {
        self.set_best_block_hash(block.block_hash())?;
        self.set_hash_by_index(block.index(), block.block_hash())?;
        self.set_header(&block.block_hash(), block.header())?;
        self.set_block(&block.block_hash(), block)
    }

    pub fn add_header(&mut self, header: B::SignedHeader) -> io::Result<()> {
        self.set_best_block_hash(header.block_hash())?;
        self.set_hash_by_index(header.index(), header.block_hash())?;
        self.set_header(&header.block_hash(), header)
    }

    #[inline]
    pub fn best_block_hash(&mut self) -> StorageResult<&CryptoHash> {
        let key = self.enc_hash(self.genesis_hash.as_ref().expect(MISSING_GENESIS_ERR));
        read_with_cache(self.storage.as_ref(), COL_BEST_BLOCK, &mut self.best_block_hash, &key)
    }

    #[inline]
    #[allow(clippy::redundant_closure)]
    pub fn best_block_index(&mut self) -> StorageResult<u64> {
        let mut key = self.enc_slice(self.genesis_hash.expect(MISSING_GENESIS_ERR).as_ref());
        key.extend_from_slice(&[0]);
        read_with_cache(self.storage.as_ref(), COL_BEST_BLOCK, &mut self.best_block_index, &key)
            .map(|x| x.cloned())
    }

    #[inline]
    pub fn set_best_block_hash(&mut self, value: CryptoHash) -> io::Result<()> {
        let key = self.enc_hash(self.genesis_hash.as_ref().expect(MISSING_GENESIS_ERR));
        write_with_cache(
            self.storage.as_ref(),
            COL_BEST_BLOCK,
            &mut self.best_block_hash,
            &key,
            value,
        )
    }

    #[inline]
    pub fn set_best_block_index(&mut self, value: u64) -> io::Result<()> {
        let mut key = self.enc_slice(self.genesis_hash.expect(MISSING_GENESIS_ERR).as_ref());
        key.extend_from_slice(&[0]);
        write_with_cache(
            self.storage.as_ref(),
            COL_BEST_BLOCK,
            &mut self.best_block_index,
            &key,
            value,
        )
    }

    #[inline]
    pub fn header(&mut self, hash: &CryptoHash) -> StorageResult<&H> {
        let key = self.enc_hash(hash);
        read_with_cache(self.storage.as_ref(), COL_HEADERS, &mut self.headers, &key)
    }

    #[inline]
    pub fn set_header(&mut self, hash: &CryptoHash, header: H) -> io::Result<()> {
        let key = self.enc_hash(hash);
        write_with_cache(self.storage.as_ref(), COL_HEADERS, &mut self.headers, &key, header)
    }

    #[inline]
    pub fn block(&mut self, hash: &CryptoHash) -> StorageResult<&B> {
        let key = self.enc_hash(hash);
        read_with_cache(self.storage.as_ref(), COL_BLOCKS, &mut self.blocks, &key)
    }

    #[inline]
    pub fn set_block(&mut self, hash: &CryptoHash, block: B) -> io::Result<()> {
        let key = self.enc_hash(hash);
        write_with_cache(self.storage.as_ref(), COL_BLOCKS, &mut self.blocks, &key, block)
    }

    #[inline]
    pub fn best_block(&mut self) -> StorageResult<&B> {
        let best_hash = *self.best_block_hash().unwrap().unwrap();
        self.block(&best_hash)
    }

    #[inline]
    pub fn hash_by_index(&mut self, index: u64) -> StorageResult<&CryptoHash> {
        // Check to make sure the requested index is not larger than the index of the best block.
        let best_block_index = match self.best_block_hash()?.cloned() {
            None => return Ok(None),
            Some(best_hash) => match self.block(&best_hash)? {
                None => return Ok(None),
                Some(block) => block.index(),
            },
        };
        if best_block_index < index {
            return Ok(None);
        }
        let key = self.enc_index(index);
        read_with_cache(self.storage.as_ref(), COL_BLOCK_INDICES, &mut self.block_indices, &key)
    }

    #[inline]
    pub fn set_hash_by_index(&mut self, index: u64, hash: CryptoHash) -> io::Result<()> {
        let key = self.enc_index(index);
        write_with_cache(
            self.storage.as_ref(),
            COL_BLOCK_INDICES,
            &mut self.block_indices,
            &key,
            hash,
        )
    }
}

/// Provides a view on the bytes that constitute the u64 index.
fn index_to_bytes(index: &u64) -> &[u8] {
    unsafe {
        std::slice::from_raw_parts(
            index as *const u64 as *const u8,
            std::mem::size_of::<u64>() / std::mem::size_of::<u8>(),
        )
    }
}

/// Provides a view on the bytes that constitute the chain id.
fn chain_id_to_bytes(index: &u32) -> &[u8] {
    unsafe {
        std::slice::from_raw_parts(
            index as *const u32 as *const u8,
            std::mem::size_of::<u32>() / std::mem::size_of::<u8>(),
        )
    }
}

fn write_with_cache<T: Clone + Encode>(
    storage: &KeyValueDB,
    col: u32,
    cache: &mut SizedCache<Vec<u8>, T>,
    key: &[u8],
    value: T,
) -> io::Result<()> {
    let data = Encode::encode(&value)?;
    let mut db_transaction = storage.transaction();
    db_transaction.put_vec(Some(col), key, data);
    storage.write(db_transaction)?;
    // If it has reached here then it is safe to put in cache.
    cache.cache_set(key.to_vec(), value);
    Ok(())
}

fn extend_with_cache<T: Clone + Encode>(
    storage: &KeyValueDB,
    col: u32,
    cache: &mut SizedCache<Vec<u8>, T>,
    values: HashMap<Vec<u8>, T>,
) -> io::Result<()> {
    let mut db_transaction = storage.transaction();
    let mut cache_to_extend = Vec::with_capacity(values.len());
    for (key, value) in values {
        let data = Encode::encode(&value)?;
        db_transaction.put_vec(Some(col), &key, data);
        cache_to_extend.push((key, value));
    }
    storage.write(db_transaction)?;
    // If it has reached here then it is safe to put in cache.
    for (key, value) in cache_to_extend {
        cache.cache_set(key, value);
    }
    Ok(())
}

fn read_with_cache<'a, T: Decode + Clone + 'a>(
    storage: &KeyValueDB,
    col: u32,
    cache: &'a mut SizedCache<Vec<u8>, T>,
    key: &[u8],
) -> StorageResult<&'a T> {
    let key_vec = key.to_vec();
    if cache.cache_get(&key_vec).is_some() {
        return Ok(Some(cache.cache_get(&key_vec).unwrap()));
    }
    if let Some(data) = storage.get(Some(col), key)? {
        let result = Decode::decode(data.as_ref())?;
        cache.cache_set(key.to_vec(), result);
        return Ok(cache.cache_get(&key_vec));
    }
    Ok(None)
}

/// prune column based on index
fn prune_index<T>(
    storage: &KeyValueDB,
    col: u32,
    cache: &mut SizedCache<Vec<u8>, T>,
    filter: &Fn(u64) -> bool,
) -> io::Result<()> {
    let get_u64_from_key = |k: &[u8]| {
        let mut buf: [u8; 8] = [0; 8];
        buf.copy_from_slice(&k[4..]);
        u64::from_le_bytes(buf)
    };
    let mut db_transaction = storage.transaction();
    for (k, _) in storage.iter(Some(col)) {
        let key = get_u64_from_key(&k);
        if !filter(key) {
            db_transaction.delete(Some(col), &k);
        }
    }
    storage.write(db_transaction)?;

    let mut keys_to_remove = vec![];
    for key in cache.key_order() {
        if !filter(get_u64_from_key(key)) {
            keys_to_remove.push(key.clone());
        }
    }
    for key in keys_to_remove {
        cache.cache_remove(&key);
    }
    Ok(())
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn test_cache_read_and_write() {
        let db = kvdb_memorydb::create(NUM_COLS);
        let mut cache = SizedCache::with_size(8);
        for i in 0..8 {
            write_with_cache(&db, 0, &mut cache, &[i as u8], i).unwrap();
        }
        for i in (8..12).rev() {
            write_with_cache(&db, 0, &mut cache, &[i as u8], i).unwrap();
        }
        let keys: Vec<u8> = cache.key_order().flatten().cloned().collect();
        assert_eq!(keys, vec![8, 9, 10, 11, 7, 6, 5, 4]);
        for i in 0..12 {
            let result = read_with_cache(&db, 0, &mut cache, &[i as u8]);
            assert_eq!(*result.unwrap().unwrap(), i);
        }
        let keys: Vec<u8> = cache.key_order().flatten().cloned().collect();
        assert_eq!(keys, vec![11, 10, 9, 8, 7, 6, 5, 4]);
    }
}

'''
'''--- runtime/storage/src/storages/shard.rs ---
use super::{extend_with_cache, read_with_cache, write_with_cache, StorageResult};
use super::{BlockChainStorage, GenericStorage};
use super::{ChainId, KeyValueDB};
use super::{
    CACHE_SIZE, COL_RECEIPT_BLOCK, COL_STATE, COL_TRANSACTION_ADDRESSES, COL_TRANSACTION_RESULTS,
    COL_TX_NONCE,
};
use cached::SizedCache;
use primitives::chain::{ReceiptBlock, SignedShardBlock, SignedShardBlockHeader};
use primitives::hash::CryptoHash;
use primitives::transaction::{TransactionAddress, TransactionResult};
use primitives::types::{AccountId, BlockIndex, ShardId};
use std::collections::HashMap;
use std::io;
use std::sync::Arc;

/// Shard chain
pub struct ShardChainStorage {
    generic_storage: BlockChainStorage<SignedShardBlockHeader, SignedShardBlock>,
    // keyed by transaction hash
    transaction_results: SizedCache<Vec<u8>, TransactionResult>,
    // keyed by transaction hash
    transaction_addresses: SizedCache<Vec<u8>, TransactionAddress>,
    // keyed by block index
    receipts: SizedCache<Vec<u8>, HashMap<ShardId, ReceiptBlock>>,
    // Records the largest transaction nonce per account
    tx_nonce: SizedCache<Vec<u8>, u64>,
}

impl GenericStorage<SignedShardBlockHeader, SignedShardBlock> for ShardChainStorage {
    #[inline]
    fn blockchain_storage_mut(
        &mut self,
    ) -> &mut BlockChainStorage<SignedShardBlockHeader, SignedShardBlock> {
        &mut self.generic_storage
    }
}

impl ShardChainStorage {
    pub fn new(storage: Arc<KeyValueDB>, shard_id: u32) -> Self {
        Self {
            generic_storage: BlockChainStorage::new(storage, ChainId::ShardChain(shard_id)),
            transaction_results: SizedCache::with_size(CACHE_SIZE),
            transaction_addresses: SizedCache::with_size(CACHE_SIZE),
            receipts: SizedCache::with_size(CACHE_SIZE),
            tx_nonce: SizedCache::with_size(CACHE_SIZE),
        }
    }

    /// Records the transaction addresses and the transaction results of the processed block.
    pub fn extend_transaction_results_addresses(
        &mut self,
        block: &SignedShardBlock,
        tx_results: Vec<TransactionResult>,
    ) -> io::Result<()> {
        let transaction_keys: Vec<_> = block
            .body
            .transactions
            .iter()
            .map(|t| self.generic_storage.enc_hash(&t.get_hash()).to_vec())
            .collect();
        let transaction_address_updates: HashMap<Vec<u8>, TransactionAddress> = transaction_keys
            .iter()
            .cloned()
            .enumerate()
            .map(|(i, key)| {
                (key, TransactionAddress { block_hash: block.hash, index: i, shard_id: None })
            })
            .collect();
        extend_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TRANSACTION_ADDRESSES,
            &mut self.transaction_addresses,
            transaction_address_updates,
        )?;

        let receipt_keys: Vec<_> = block
            .body
            .receipts
            .iter()
            .flat_map(|b| {
                b.receipts.iter().zip(std::iter::repeat(b.shard_id)).enumerate().map(
                    |(i, (r, shard_id))| {
                        (shard_id, i, self.generic_storage.enc_hash(&r.nonce).to_vec())
                    },
                )
            })
            .collect();
        let receipt_address_updates: HashMap<Vec<u8>, TransactionAddress> = receipt_keys
            .iter()
            .cloned()
            .map(|(shard_id, index, key)| {
                (
                    key,
                    TransactionAddress { block_hash: block.hash, index, shard_id: Some(shard_id) },
                )
            })
            .collect();
        extend_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TRANSACTION_ADDRESSES,
            &mut self.transaction_addresses,
            receipt_address_updates,
        )?;

        let updates: HashMap<Vec<u8>, TransactionResult> = receipt_keys
            .into_iter()
            .map(|(_, _, key)| key)
            .chain(transaction_keys.into_iter())
            .zip(tx_results.into_iter())
            .collect();
        extend_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TRANSACTION_RESULTS,
            &mut self.transaction_results,
            updates,
        )
    }

    #[inline]
    /// Get transaction address of the computed transaction from its hash.
    pub fn transaction_address(&mut self, hash: &CryptoHash) -> StorageResult<&TransactionAddress> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TRANSACTION_ADDRESSES,
            &mut self.transaction_addresses,
            &self.generic_storage.enc_hash(hash),
        )
    }

    #[inline]
    /// Get transaction hash of the computed transaction from its hash.
    pub fn transaction_result(&mut self, hash: &CryptoHash) -> StorageResult<&TransactionResult> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TRANSACTION_RESULTS,
            &mut self.transaction_results,
            &self.generic_storage.enc_hash(hash),
        )
    }

    #[inline]
    /// Gets trie-specific state by its hash.
    pub fn get_state(&self, hash: &CryptoHash) -> StorageResult<Vec<u8>> {
        self.generic_storage
            .storage
            .get(Some(COL_STATE), &self.generic_storage.enc_hash(hash))
            .map(|a| a.map(|b| b.to_vec()))
    }

    /// Saves state updates in the db.
    pub fn apply_state_updates(
        &self,
        changes: HashMap<Vec<u8>, Option<Vec<u8>>>,
    ) -> std::io::Result<()> {
        let mut db_transaction = self.generic_storage.storage.transaction();
        let col = Some(COL_STATE);
        for (key, value) in changes.into_iter() {
            match value {
                Some(arr) => db_transaction.put_vec(col, &self.generic_storage.enc_slice(&key), arr),
                None => db_transaction.delete(col, &self.generic_storage.enc_slice(&key)),
            }
        }
        self.generic_storage.storage.write(db_transaction)
    }

    #[inline]
    pub fn receipt_block(
        &mut self,
        index: BlockIndex,
        shard_id: ShardId,
    ) -> StorageResult<&ReceiptBlock> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_RECEIPT_BLOCK,
            &mut self.receipts,
            &self.generic_storage.enc_index(index),
        )
        .map(|receipts| receipts.and_then(|r| r.get(&shard_id)))
    }

    pub fn extend_receipts(
        &mut self,
        index: BlockIndex,
        receipts: HashMap<ShardId, ReceiptBlock>,
    ) -> io::Result<()> {
        write_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_RECEIPT_BLOCK,
            &mut self.receipts,
            &self.generic_storage.enc_index(index),
            receipts,
        )
    }

    pub fn tx_nonce(&mut self, account_id: AccountId) -> StorageResult<&u64> {
        read_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TX_NONCE,
            &mut self.tx_nonce,
            &self.generic_storage.enc_slice(&account_id.into_bytes()),
        )
    }

    pub fn extend_tx_nonce(&mut self, tx_nonces: HashMap<AccountId, u64>) -> io::Result<()> {
        let updates: HashMap<_, _> = tx_nonces
            .into_iter()
            .map(|(k, v)| (self.generic_storage.enc_slice(&k.into_bytes()).to_vec(), v))
            .collect();
        extend_with_cache(
            self.generic_storage.storage.as_ref(),
            COL_TX_NONCE,
            &mut self.tx_nonce,
            updates,
        )
    }
}

'''
'''--- runtime/storage/src/test.c ---
    #include<stdio.h>
    void say_hello() 
    {
        printf("Hello Rust!\n");
    }

'''
'''--- runtime/storage/src/test_utils.rs ---
use std::sync::Arc;

use crate::storages::beacon::BeaconChainStorage;
use crate::storages::shard::ShardChainStorage;
use crate::storages::NUM_COLS;
use crate::Trie;
use std::sync::RwLock;

/// Creates one beacon storage and one shard storage using in-memory database.
pub fn create_beacon_shard_storages(
) -> (Arc<RwLock<BeaconChainStorage>>, Arc<RwLock<ShardChainStorage>>) {
    let db = Arc::new(kvdb_memorydb::create(NUM_COLS));
    let beacon = BeaconChainStorage::new(db.clone());
    let shard = ShardChainStorage::new(db.clone(), 0);
    (Arc::new(RwLock::new(beacon)), Arc::new(RwLock::new(shard)))
}

/// Creates a Trie using a single shard storage that uses in-memory database.
pub fn create_trie() -> Arc<Trie> {
    let shard_storage = create_beacon_shard_storages().1;
    Arc::new(Trie::new(shard_storage))
}

'''
'''--- runtime/storage/src/trie/mod.rs ---
use self::nibble_slice::NibbleSlice;
use crate::storages::shard::ShardChainStorage;
use byteorder::{LittleEndian, ReadBytesExt, WriteBytesExt};
use cached::{Cached, SizedCache};
pub use kvdb::DBValue;
use primitives::hash::{hash, CryptoHash};
use std::collections::HashMap;
use std::convert::TryFrom;
use std::fmt;
use std::io::{Cursor, ErrorKind, Read, Write};
use std::sync::RwLock;
use std::sync::{Arc, Mutex};

mod nibble_slice;
pub mod update;

const POISONED_LOCK_ERR: &str = "The lock was poisoned.";

#[derive(Clone, Hash, Debug, Copy)]
struct StorageHandle(usize);

#[derive(Clone, Hash, Debug)]
enum NodeHandle {
    InMemory(StorageHandle),
    Hash(CryptoHash),
}

#[derive(Clone, Hash, Debug)]
enum TrieNode {
    /// Null trie node. Could be an empty root or an empty branch entry.
    Empty,
    /// Key and value of the leaf node.
    Leaf(Vec<u8>, Vec<u8>),
    /// Branch of 16 possible children and value if key ends here.
    Branch(Box<[Option<NodeHandle>; 16]>, Option<Vec<u8>>),
    /// Key and child of extension.
    Extension(Vec<u8>, NodeHandle),
}

impl TrieNode {
    fn new(rc_node: RawTrieNode) -> TrieNode {
        match rc_node {
            RawTrieNode::Leaf(key, value) => TrieNode::Leaf(key, value),
            RawTrieNode::Branch(children, value) => {
                let mut new_children: Box<[Option<NodeHandle>; 16]> = Default::default();
                for i in 0..children.len() {
                    new_children[i] = children[i].map(NodeHandle::Hash);
                }
                TrieNode::Branch(new_children, value)
            }
            RawTrieNode::Extension(key, child) => TrieNode::Extension(key, NodeHandle::Hash(child)),
        }
    }

    fn print(&self, f: &mut fmt::Write, memory: &NodesStorage, spaces: &mut String) -> fmt::Result {
        match self {
            TrieNode::Empty => {
                write!(f, "{}Empty", spaces)?;
            }
            TrieNode::Leaf(key, _value) => {
                let slice = NibbleSlice::from_encoded(key);
                write!(f, "{}Leaf({:?}, val)", spaces, slice.0)?;
            }
            TrieNode::Branch(children, value) => {
                writeln!(
                    f,
                    "{}Branch({}){{",
                    spaces,
                    if value.is_some() { "Some" } else { "None" }
                )?;
                spaces.push_str(" ");
                for (idx, child) in
                    children.iter().enumerate().filter(|(_idx, child)| child.is_some())
                {
                    let child = child.as_ref().unwrap();
                    write!(f, "{}{:01x}->", spaces, idx)?;
                    match child {
                        NodeHandle::Hash(hash) => {
                            write!(f, "{}", hash)?;
                        }
                        NodeHandle::InMemory(handle) => {
                            let child = memory.node_ref(*handle);
                            child.print(f, memory, spaces)?;
                        }
                    }
                    writeln!(f)?;
                }
                spaces.remove(spaces.len() - 1);
                write!(f, "{}}}", spaces)?;
            }
            TrieNode::Extension(key, child) => {
                let slice = NibbleSlice::from_encoded(key);
                writeln!(f, "{}Extension({:?})", spaces, slice)?;
                spaces.push_str(" ");
                match child {
                    NodeHandle::Hash(hash) => {
                        write!(f, "{}{}", spaces, hash)?;
                    }
                    NodeHandle::InMemory(handle) => {
                        let child = memory.node_ref(*handle);
                        child.print(f, memory, spaces)?;
                    }
                }
                writeln!(f)?;
                spaces.remove(spaces.len() - 1);
            }
        }
        Ok(())
    }

    #[allow(dead_code)]
    fn deep_to_string(&self, memory: &NodesStorage) -> String {
        let mut buf = String::new();
        self.print(&mut buf, memory, &mut "".to_string()).expect("printing failed");
        buf
    }
}

#[derive(Debug, Eq, PartialEq)]
#[allow(clippy::large_enum_variant)]
enum RawTrieNode {
    Leaf(Vec<u8>, Vec<u8>),
    Branch([Option<CryptoHash>; 16], Option<Vec<u8>>),
    Extension(Vec<u8>, CryptoHash),
}

struct NodesStorage {
    nodes: Vec<Option<TrieNode>>,
    refcount_changes: HashMap<CryptoHash, (Vec<u8>, i32)>,
}

const INVALID_STORAGE_HANDLE: &str = "invalid storage handle";

/// Local mutable storage that owns node objects.
impl NodesStorage {
    fn new() -> NodesStorage {
        NodesStorage { nodes: Vec::new(), refcount_changes: HashMap::new() }
    }

    fn destroy(&mut self, handle: StorageHandle) -> TrieNode {
        self.nodes
            .get_mut(handle.0)
            .expect(INVALID_STORAGE_HANDLE)
            .take()
            .expect(INVALID_STORAGE_HANDLE)
    }

    fn node_ref(&self, handle: StorageHandle) -> &TrieNode {
        self.nodes
            .get(handle.0)
            .expect(INVALID_STORAGE_HANDLE)
            .as_ref()
            .expect(INVALID_STORAGE_HANDLE)
    }

    fn store(&mut self, node: TrieNode) -> StorageHandle {
        self.nodes.push(Some(node));
        StorageHandle(self.nodes.len() - 1)
    }

    fn store_at(&mut self, handle: StorageHandle, node: TrieNode) {
        debug_assert!(self.nodes.get(handle.0).expect(INVALID_STORAGE_HANDLE).is_none());
        self.nodes[handle.0] = Some(node);
    }
}

const LEAF_NODE: u8 = 0;
const BRANCH_NODE_NO_VALUE: u8 = 1;
const BRANCH_NODE_WITH_VALUE: u8 = 2;
const EXTENSION_NODE: u8 = 3;

#[derive(Debug, Eq, PartialEq)]
struct RcTrieNode {
    data: RawTrieNode,
    rc: u32,
}

fn decode_children(cursor: &mut Cursor<&[u8]>) -> Result<[Option<CryptoHash>; 16], std::io::Error> {
    let mut children: [Option<CryptoHash>; 16] = Default::default();
    let bitmap = cursor.read_u16::<LittleEndian>()?;
    let mut pos = 1;
    for child in &mut children {
        if bitmap & pos != 0 {
            let mut arr = [0; 32];
            cursor.read_exact(&mut arr)?;
            *child = Some(CryptoHash::try_from(&arr[..]).unwrap());
        }
        pos <<= 1;
    }
    Ok(children)
}

impl RawTrieNode {
    fn encode_into(&self, out: &mut Vec<u8>) -> Result<(), std::io::Error> {
        let mut cursor = Cursor::new(out);
        match &self {
            RawTrieNode::Leaf(key, value) => {
                cursor.write_u8(LEAF_NODE)?;
                cursor.write_u32::<LittleEndian>(key.len() as u32)?;
                cursor.write_all(&key)?;
                cursor.write_u32::<LittleEndian>(value.len() as u32)?;
                cursor.write_all(&value)?;
            }
            RawTrieNode::Branch(children, value) => {
                if let Some(bytes) = value {
                    cursor.write_u8(BRANCH_NODE_WITH_VALUE)?;
                    cursor.write_u32::<LittleEndian>(bytes.len() as u32)?;
                    cursor.write_all(&bytes)?;
                } else {
                    cursor.write_u8(BRANCH_NODE_NO_VALUE)?;
                }
                let mut bitmap: u16 = 0;
                let mut pos: u16 = 1;
                for child in children.iter() {
                    if child.is_some() {
                        bitmap |= pos
                    }
                    pos <<= 1;
                }
                cursor.write_u16::<LittleEndian>(bitmap)?;
                for child in children.iter() {
                    if let Some(hash) = child {
                        cursor.write_all(hash.as_ref())?;
                    }
                }
            }
            RawTrieNode::Extension(key, child) => {
                cursor.write_u8(EXTENSION_NODE)?;
                cursor.write_u32::<LittleEndian>(key.len() as u32)?;
                cursor.write_all(&key)?;
                cursor.write_all(child.as_ref())?;
            }
        }
        Ok(())
    }

    #[allow(dead_code)]
    fn encode(&self) -> Result<Vec<u8>, std::io::Error> {
        let mut out = Vec::new();
        self.encode_into(&mut out)?;
        Ok(out)
    }

    fn decode(bytes: &[u8]) -> Result<Self, std::io::Error> {
        let mut cursor = Cursor::new(bytes);
        match cursor.read_u8()? {
            LEAF_NODE => {
                let key_length = cursor.read_u32::<LittleEndian>()?;
                let mut key = vec![0; key_length as usize];
                cursor.read_exact(&mut key)?;
                let value_length = cursor.read_u32::<LittleEndian>()?;
                let mut value = vec![0; value_length as usize];
                cursor.read_exact(&mut value)?;
                Ok(RawTrieNode::Leaf(key, value))
            }
            BRANCH_NODE_NO_VALUE => {
                let children = decode_children(&mut cursor)?;
                Ok(RawTrieNode::Branch(children, None))
            }
            BRANCH_NODE_WITH_VALUE => {
                let value_length = cursor.read_u32::<LittleEndian>()?;
                let mut value = vec![0; value_length as usize];
                cursor.read_exact(&mut value)?;
                let children = decode_children(&mut cursor)?;
                Ok(RawTrieNode::Branch(children, Some(value)))
            }
            EXTENSION_NODE => {
                let key_length = cursor.read_u32::<LittleEndian>()?;
                let mut key = vec![0; key_length as usize];
                cursor.read_exact(&mut key)?;
                let mut child = vec![0; 32];
                cursor.read_exact(&mut child)?;
                Ok(RawTrieNode::Extension(key, CryptoHash::try_from(child).unwrap()))
            }
            _ => Err(std::io::Error::new(std::io::ErrorKind::Other, "Wrong type")),
        }
    }
}

impl RcTrieNode {
    fn encode(data: &[u8], rc: u32) -> Result<Vec<u8>, std::io::Error> {
        let mut cursor = Cursor::new(Vec::with_capacity(data.len() + 4));
        cursor.write_all(data)?;
        cursor.write_u32::<LittleEndian>(rc)?;
        Ok(cursor.into_inner())
    }

    fn decode_raw(bytes: &[u8]) -> Result<(&[u8], u32), std::io::Error> {
        let mut cursor = Cursor::new(&bytes[bytes.len() - 4..]);
        let rc = cursor.read_u32::<LittleEndian>()?;
        Ok((&bytes[..bytes.len() - 4], rc))
    }

    fn decode(bytes: &[u8]) -> Result<(RawTrieNode, u32), std::io::Error> {
        let node = RawTrieNode::decode(&bytes[..bytes.len() - 4])?;
        let mut cursor = Cursor::new(&bytes[bytes.len() - 4..]);
        let rc = cursor.read_u32::<LittleEndian>()?;
        Ok((node, rc))
    }
}

pub struct TrieCachingStorage {
    storage: Arc<RwLock<ShardChainStorage>>,
    cache: Arc<Mutex<SizedCache<CryptoHash, Option<Vec<u8>>>>>,
}

impl TrieCachingStorage {
    fn new(storage: Arc<RwLock<ShardChainStorage>>) -> TrieCachingStorage {
        // TODO defend from huge values in cache
        TrieCachingStorage { storage, cache: Arc::new(Mutex::new(SizedCache::with_size(10000))) }
    }

    fn retrieve_raw_bytes(&self, hash: &CryptoHash) -> Option<(Vec<u8>)> {
        let mut guard = self.cache.lock().expect(POISONED_LOCK_ERR);
        if let Some(val) = (*guard).cache_get(hash) {
            val.clone()
        } else {
            let result = if let Ok(Some(bytes)) =
                self.storage.read().expect(POISONED_LOCK_ERR).get_state(hash)
            {
                Some(bytes)
            } else {
                None
            };
            (*guard).cache_set(*hash, result.clone());
            result
        }
    }

    fn retrieve_rc(&self, hash: &CryptoHash) -> Option<u32> {
        let mut guard = self.cache.lock().expect(POISONED_LOCK_ERR);
        if let Some(val) = (*guard).cache_get(hash) {
            val.as_ref().map(|vec| RcTrieNode::decode_raw(&vec).expect("failed to decode").1)
        } else {
            let val = if let Ok(Some(bytes)) =
                self.storage.read().expect(POISONED_LOCK_ERR).get_state(hash)
            {
                Some(bytes)
            } else {
                None
            };
            let rc =
                val.as_ref().map(|vec| RcTrieNode::decode_raw(&vec).expect("failed to decode").1);
            (*guard).cache_set(*hash, val);
            rc
        }
    }

    fn retrieve_node(&self, hash: &CryptoHash) -> Result<TrieNode, String> {
        if let Some(bytes) = self.retrieve_raw_bytes(hash) {
            match RcTrieNode::decode(&bytes) {
                Ok((value, _)) => Ok(TrieNode::new(value)),
                Err(_) => Err(format!("Failed to decode node {}", hash)),
            }
        } else {
            Err(format!("Node {} not found in storage", hash))
        }
    }
}

pub struct Trie {
    storage: TrieCachingStorage,
}

///
/// TrieChanges stores delta for refcount.
/// Multiple versions of the state work the following way:
///         __changes1___state1
/// state0 /
///        \__changes2___state2
///
/// To store state0, state1 and state2, apply insertions from changes1 and changes2
///
/// Then, to discard state2, apply insertions from changes2 as deletions
///
/// Then, to discard state0, apply deletions from changes1.
/// deleting state0 while both state1 and state2 exist is not possible.
/// Applying deletions from changes1 while state2 exists makes accessing state2 invalid.
///
///
/// create a fork -> apply insertions
/// resolve a fork -> apply opposite of insertions
/// discard old parent which has no forks from it -> apply deletions
///
/// Having old_root and values in deletions allows to apply TrieChanges in reverse
///
/// DBChanges are the changes from current state refcount to refcount + delta.
pub struct TrieChanges {
    #[allow(dead_code)]
    old_root: CryptoHash,
    new_root: CryptoHash,
    insertions: Vec<(CryptoHash, Vec<u8>, u32)>, // key, value, rc
    deletions: Vec<(CryptoHash, Vec<u8>, u32)>,  // key, value, rc
}

pub type DBChanges = HashMap<Vec<u8>, Option<Vec<u8>>>;

enum FlattenNodesCrumb {
    Entering,
    AtChild(Box<[Option<CryptoHash>; 16]>, usize),
    Exiting,
}

impl Trie {
    pub fn new(storage: Arc<RwLock<ShardChainStorage>>) -> Self {
        Trie { storage: TrieCachingStorage::new(storage) }
    }

    pub fn empty_root() -> CryptoHash {
        CryptoHash::default()
    }

    fn move_node_to_mutable(
        &self,
        memory: &mut NodesStorage,
        hash: &CryptoHash,
    ) -> Result<StorageHandle, String> {
        if *hash == Trie::empty_root() {
            Ok(memory.store(TrieNode::Empty))
        } else {
            if let Some(bytes) = self.storage.retrieve_raw_bytes(hash) {
                match RcTrieNode::decode(&bytes) {
                    Ok((value, _)) => {
                        let result = memory.store(TrieNode::new(value));
                        memory
                            .refcount_changes
                            .entry(*hash)
                            .or_insert_with(|| {
                                (
                                    RcTrieNode::decode_raw(&bytes)
                                        .expect("calling after decode()")
                                        .0
                                        .to_vec(),
                                    0,
                                )
                            })
                            .1 -= 1;
                        Ok(result)
                    }
                    Err(_) => Err(format!("Failed to decode node {}", hash)),
                }
            } else {
                Err(format!("Node {} not found in storage", hash))
            }
        }
    }

    fn retrieve_node(&self, hash: &CryptoHash) -> Result<TrieNode, String> {
        if *hash == Trie::empty_root() {
            return Ok(TrieNode::Empty);
        }
        self.storage.retrieve_node(hash)
    }

    fn lookup(&self, root: &CryptoHash, mut key: NibbleSlice) -> Result<Option<Vec<u8>>, String> {
        let mut hash = *root;

        loop {
            if hash == Trie::empty_root() {
                return Ok(None);
            }
            let node = match self.storage.retrieve_raw_bytes(&hash) {
                Some(bytes) => RcTrieNode::decode(&bytes)
                    .map(|trie_node| trie_node.0)
                    .map_err(|_| "Failed to decode node".to_string())?,
                _ => return Err(format!("Node {} not found in storage", hash)),
            };

            match node {
                RawTrieNode::Leaf(existing_key, value) => {
                    return Ok(if NibbleSlice::from_encoded(&existing_key).0 == key {
                        Some(value)
                    } else {
                        None
                    });
                }
                RawTrieNode::Extension(existing_key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&existing_key).0;
                    if key.starts_with(&existing_key) {
                        hash = child;
                        key = key.mid(existing_key.len());
                    } else {
                        return Ok(None);
                    }
                }
                RawTrieNode::Branch(mut children, value) => {
                    if key.is_empty() {
                        return Ok(value);
                    } else {
                        match children[key.at(0) as usize].take() {
                            Some(x) => {
                                hash = x;
                                key = key.mid(1);
                            }
                            None => return Ok(None),
                        }
                    }
                }
            };
        }
    }

    pub fn get(&self, root: &CryptoHash, key: &[u8]) -> Option<Vec<u8>> {
        let key = NibbleSlice::new(key);
        match self.lookup(root, key) {
            Ok(value) => value,
            Err(err) => {
                println!("Failed to lookup key={:?} for root={:?}: {}", key, root, err);
                None
            }
        }
    }

    /// Allowed to mutate nodes in NodesStorage.
    /// Insert while holding StorageHandles to NodesStorage is unsafe
    fn insert(
        &self,
        memory: &mut NodesStorage,
        node: StorageHandle,
        partial: NibbleSlice,
        value: Vec<u8>,
    ) -> Result<StorageHandle, String> {
        let root_handle = node;
        let mut handle = node;
        let mut value = Some(value);
        let mut partial = partial;

        loop {
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    let leaf_node =
                        TrieNode::Leaf(partial.encoded(true).into_vec(), value.take().unwrap());
                    memory.store_at(handle, leaf_node);
                    break;
                }
                TrieNode::Branch(mut children, existing_value) => {
                    // If the key ends here, store the value in branch's value.
                    if partial.is_empty() {
                        memory.store_at(
                            handle,
                            TrieNode::Branch(children, Some(value.take().unwrap())),
                        );
                        break;
                    } else {
                        let idx = partial.at(0) as usize;
                        let child = children[idx].take();
                        let child = match child {
                            Some(NodeHandle::Hash(hash)) => {
                                self.move_node_to_mutable(memory, &hash)?
                            }
                            Some(NodeHandle::InMemory(handle)) => handle,
                            None => memory.store(TrieNode::Empty),
                        };
                        children[idx] = Some(NodeHandle::InMemory(child));
                        memory.store_at(handle, TrieNode::Branch(children, existing_value));
                        handle = child;
                        partial = partial.mid(1);
                        continue;
                    }
                }
                TrieNode::Leaf(key, existing_value) => {
                    let existing_key = NibbleSlice::from_encoded(&key).0;
                    let common_prefix = partial.common_prefix(&existing_key);
                    if common_prefix == existing_key.len() && common_prefix == partial.len() {
                        // Equivalent leaf.
                        memory.store_at(handle, TrieNode::Leaf(key, value.take().unwrap()));
                        break;
                    } else if common_prefix == 0 {
                        let mut children = Default::default();
                        let branch_node = if existing_key.is_empty() {
                            TrieNode::Branch(children, Some(existing_value))
                        } else {
                            let idx = existing_key.at(0) as usize;
                            let new_leaf = TrieNode::Leaf(
                                existing_key.mid(1).encoded(true).into_vec(),
                                existing_value,
                            );
                            children[idx] = Some(NodeHandle::InMemory(memory.store(new_leaf)));
                            TrieNode::Branch(children, None)
                        };
                        memory.store_at(handle, branch_node);
                        continue;
                    } else if common_prefix == existing_key.len() {
                        let child = memory
                            .store(TrieNode::Branch(Default::default(), Some(existing_value)));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                existing_key.encoded(false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    } else {
                        // Partially shared prefix: convert to leaf and call recursively to add a branch.
                        let child = memory.store(TrieNode::Leaf(
                            existing_key.mid(common_prefix).encoded(true).into_vec(),
                            existing_value,
                        ));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                partial.encoded_leftmost(common_prefix, false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    }
                }
                TrieNode::Extension(key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&key).0;
                    let common_prefix = partial.common_prefix(&existing_key);
                    if common_prefix == 0 {
                        let idx = existing_key.at(0) as usize;
                        let mut children: Box<[Option<NodeHandle>; 16]> = Default::default();
                        children[idx] = if existing_key.len() == 1 {
                            Some(child)
                        } else {
                            let ext_node = TrieNode::Extension(
                                existing_key.mid(1).encoded(false).into_vec(),
                                child,
                            );
                            Some(NodeHandle::InMemory(memory.store(ext_node)))
                        };
                        let branch_node = TrieNode::Branch(children, None);
                        memory.store_at(handle, branch_node);
                        continue;
                    } else if common_prefix == existing_key.len() {
                        let child = match child {
                            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
                            NodeHandle::InMemory(handle) => handle,
                        };
                        memory.store_at(
                            handle,
                            TrieNode::Extension(key, NodeHandle::InMemory(child)),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    } else {
                        // Partially shared prefix: covert to shorter extension and recursively add a branch.
                        let child = memory.store(TrieNode::Extension(
                            existing_key.mid(common_prefix).encoded(false).into_vec(),
                            child,
                        ));
                        memory.store_at(
                            handle,
                            TrieNode::Extension(
                                existing_key.encoded_leftmost(common_prefix, false).into_vec(),
                                NodeHandle::InMemory(child),
                            ),
                        );
                        handle = child;
                        partial = partial.mid(common_prefix);
                        continue;
                    }
                }
            }
        }
        Ok(root_handle)
    }

    /// Deletes a node from the trie which has key = `partial` given root node.
    /// Returns (new root node or `None` if this was the node to delete, was it updated).
    /// While deleting keeps track of all the removed / updated nodes in `death_row`.
    fn delete(
        &self,
        memory: &mut NodesStorage,
        node: StorageHandle,
        partial: NibbleSlice,
    ) -> Result<(StorageHandle, bool), String> {
        let mut handle = node;
        let mut partial = partial;
        let root_node = handle;
        let mut path: Vec<StorageHandle> = Vec::new();
        let deleted: bool;
        loop {
            path.push(handle);
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    memory.store_at(handle, TrieNode::Empty);
                    deleted = false;
                    break;
                }
                TrieNode::Leaf(key, value) => {
                    if NibbleSlice::from_encoded(&key).0 == partial {
                        memory.store_at(handle, TrieNode::Empty);
                        deleted = true;
                        break;
                    } else {
                        memory.store_at(handle, TrieNode::Leaf(key, value));
                        deleted = false;
                        break;
                    }
                }
                TrieNode::Branch(mut children, value) => {
                    if partial.is_empty() {
                        if children.iter().filter(|&x| x.is_some()).count() == 0 {
                            memory.store_at(handle, TrieNode::Empty);
                            deleted = value.is_some();
                            break;
                        } else {
                            memory.store_at(handle, TrieNode::Branch(children, None));
                            deleted = value.is_some();
                            break;
                        }
                    } else {
                        let idx = partial.at(0) as usize;
                        if let Some(node_or_hash) = children[idx].take() {
                            let node = match node_or_hash {
                                NodeHandle::Hash(hash) => {
                                    self.move_node_to_mutable(memory, &hash)?
                                }
                                NodeHandle::InMemory(node) => node,
                            };
                            children[idx] = Some(NodeHandle::InMemory(node));
                            memory.store_at(handle, TrieNode::Branch(children, value));
                            handle = node;
                            partial = partial.mid(1);
                            continue;
                        } else {
                            memory.store_at(handle, TrieNode::Branch(children, value));
                            deleted = false;
                            break;
                        }
                    }
                }
                TrieNode::Extension(key, child) => {
                    let (common_prefix, existing_len) = {
                        let existing_key = NibbleSlice::from_encoded(&key).0;
                        (existing_key.common_prefix(&partial), existing_key.len())
                    };
                    if common_prefix == existing_len {
                        let node = match child {
                            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
                            NodeHandle::InMemory(node) => node,
                        };
                        memory
                            .store_at(handle, TrieNode::Extension(key, NodeHandle::InMemory(node)));
                        partial = partial.mid(existing_len);
                        handle = node;
                        continue;
                    } else {
                        memory.store_at(handle, TrieNode::Extension(key, child));
                        deleted = false;
                        break;
                    }
                }
            }
        }
        self.fix_nodes(memory, path)?;
        Ok((root_node, deleted))
    }

    fn fix_nodes(&self, memory: &mut NodesStorage, path: Vec<StorageHandle>) -> Result<(), String> {
        for handle in path.into_iter().rev() {
            match memory.destroy(handle) {
                TrieNode::Empty => {
                    memory.store_at(handle, TrieNode::Empty);
                }
                TrieNode::Leaf(key, value) => {
                    memory.store_at(handle, TrieNode::Leaf(key, value));
                }
                TrieNode::Branch(mut children, value) => {
                    children.iter_mut().for_each(|child| {
                        if let Some(NodeHandle::InMemory(h)) = child {
                            if let TrieNode::Empty = memory.node_ref(*h) {
                                *child = None
                            }
                        }
                    });
                    let num_children = children.iter().filter(|&x| x.is_some()).count();
                    if num_children == 0 {
                        if let Some(value) = value {
                            let empty = NibbleSlice::new(&[]).encoded(true).into_vec();
                            memory.store_at(handle, TrieNode::Leaf(empty, value));
                        } else {
                            memory.store_at(handle, TrieNode::Empty);
                        }
                    } else if num_children == 1 && value.is_none() {
                        // Branch with one child becomes extension
                        // Extension followed by leaf becomes leaf
                        // Extension followed by extension becomes extension
                        let idx =
                            children.iter().enumerate().find(|(_i, x)| x.is_some()).unwrap().0;
                        let key = NibbleSlice::new(&[(idx << 4) as u8])
                            .encoded_leftmost(1, false)
                            .into_vec();
                        self.fix_extension_node(
                            memory,
                            handle,
                            key,
                            children[idx].take().unwrap(),
                        )?;
                    } else {
                        memory.store_at(handle, TrieNode::Branch(children, value));
                    }
                }
                TrieNode::Extension(key, child) => {
                    self.fix_extension_node(memory, handle, key, child)?;
                }
            }
        }
        Ok(())
    }

    fn fix_extension_node(
        &self,
        memory: &mut NodesStorage,
        handle: StorageHandle,
        key: Vec<u8>,
        child: NodeHandle,
    ) -> Result<(), String> {
        let child = match child {
            NodeHandle::Hash(hash) => self.move_node_to_mutable(memory, &hash)?,
            NodeHandle::InMemory(h) => h,
        };
        match memory.destroy(child) {
            TrieNode::Empty => {
                memory.store_at(handle, TrieNode::Empty);
            }
            TrieNode::Leaf(child_key, value) => {
                let key = NibbleSlice::from_encoded(&key)
                    .0
                    .merge_encoded(&NibbleSlice::from_encoded(&child_key).0, true)
                    .into_vec();
                memory.store_at(handle, TrieNode::Leaf(key, value));
            }
            TrieNode::Branch(children, value) => {
                memory.store_at(child, TrieNode::Branch(children, value));
                memory.store_at(handle, TrieNode::Extension(key, NodeHandle::InMemory(child)));
            }
            TrieNode::Extension(child_key, child_child) => {
                let key = NibbleSlice::from_encoded(&key)
                    .0
                    .merge_encoded(&NibbleSlice::from_encoded(&child_key).0, false)
                    .into_vec();
                memory.store_at(handle, TrieNode::Extension(key, child_child));
            }
        }
        Ok(())
    }

    fn flatten_nodes(
        old_root: &CryptoHash,
        memory: NodesStorage,
        node: StorageHandle,
    ) -> TrieChanges {
        let mut stack: Vec<(StorageHandle, FlattenNodesCrumb)> = Vec::new();
        stack.push((node, FlattenNodesCrumb::Entering));
        let mut last_hash = CryptoHash::default();
        let mut buffer: Vec<u8> = Vec::new();
        let mut memory = memory;
        while !stack.is_empty() {
            let (node, position) = stack.pop().unwrap();
            let raw_node = match memory.node_ref(node) {
                TrieNode::Empty => {
                    last_hash = Trie::empty_root();
                    continue;
                }
                TrieNode::Branch(children, value) => match position {
                    FlattenNodesCrumb::Entering => {
                        let new_children: [Option<CryptoHash>; 16] = Default::default();
                        stack.push((node, FlattenNodesCrumb::AtChild(Box::new(new_children), 0)));
                        continue;
                    }
                    FlattenNodesCrumb::AtChild(mut new_children, mut i) => {
                        if i > 0 && children[i - 1].is_some() {
                            new_children[i - 1] = Some(last_hash);
                        }
                        while i < 16 {
                            match children[i].as_ref() {
                                Some(NodeHandle::InMemory(_)) => {
                                    break;
                                }
                                Some(NodeHandle::Hash(hash)) => {
                                    new_children[i] = Some(*hash);
                                }
                                None => {}
                            }
                            i += 1;
                        }
                        if i < 16 {
                            match children[i].as_ref() {
                                Some(NodeHandle::InMemory(child_node)) => {
                                    stack.push((
                                        node,
                                        FlattenNodesCrumb::AtChild(new_children, i + 1),
                                    ));
                                    stack.push((*child_node, FlattenNodesCrumb::Entering));
                                    continue;
                                }
                                _ => unreachable!(),
                            }
                        }
                        RawTrieNode::Branch(*new_children, value.clone())
                    }
                    FlattenNodesCrumb::Exiting => unreachable!(),
                },
                TrieNode::Extension(key, child) => match position {
                    FlattenNodesCrumb::Entering => match child {
                        NodeHandle::InMemory(child) => {
                            stack.push((node, FlattenNodesCrumb::Exiting));
                            stack.push((*child, FlattenNodesCrumb::Entering));
                            continue;
                        }
                        NodeHandle::Hash(hash) => RawTrieNode::Extension(key.clone(), *hash),
                    },
                    FlattenNodesCrumb::Exiting => RawTrieNode::Extension(key.clone(), last_hash),
                    _ => unreachable!(),
                },
                TrieNode::Leaf(key, value) => RawTrieNode::Leaf(key.clone(), value.clone()),
            };
            raw_node.encode_into(&mut buffer).expect("Failed to serialize");
            let key = hash(&buffer);

            let (_value, rc) =
                memory.refcount_changes.entry(key).or_insert_with(|| (buffer.clone(), 0));
            *rc += 1;
            buffer.clear();
            last_hash = key;
        }
        let (insertions, deletions) =
            Trie::convert_to_insertions_and_deletions(memory.refcount_changes);
        TrieChanges { old_root: *old_root, new_root: last_hash, insertions, deletions }
    }

    fn convert_to_insertions_and_deletions(
        changes: HashMap<CryptoHash, (Vec<u8>, i32)>,
    ) -> ((Vec<(CryptoHash, Vec<u8>, u32)>, Vec<(CryptoHash, Vec<u8>, u32)>)) {
        let mut deletions = Vec::new();
        let mut insertions = Vec::new();
        for (key, (value, rc)) in changes.into_iter() {
            if rc > 0 {
                insertions.push((key, value, rc as u32));
            } else if rc < 0 {
                deletions.push((key, value, (-rc) as u32));
            }
        }
        // Sort so that trie changes have unique representation
        insertions.sort();
        deletions.sort();
        (insertions, deletions)
    }

    pub fn update<I>(&self, root: &CryptoHash, changes: I) -> (DBChanges, CryptoHash)
    where
        I: Iterator<Item = (Vec<u8>, Option<Vec<u8>>)>,
    {
        let mut memory = NodesStorage::new();
        let mut root_node = self.move_node_to_mutable(&mut memory, root).expect("Root not found");
        for (key, value) in changes {
            let key = NibbleSlice::new(&key);
            match value {
                Some(arr) => {
                    root_node =
                        self.insert(&mut memory, root_node, key, arr).expect("Failed to insert");
                }
                None => {
                    root_node = match self
                        .delete(&mut memory, root_node, key)
                        .expect("Failed to remove element")
                    {
                        (value, _) => value,
                    };
                }
            }
        }
        let trie_changes = Trie::flatten_nodes(root, memory, root_node);

        self.convert_to_db_changes(trie_changes)
    }

    pub fn convert_to_db_changes(&self, changes: TrieChanges) -> (DBChanges, CryptoHash) {
        let mut db_changes = HashMap::default();
        let TrieChanges { old_root: _, new_root, insertions, deletions } = changes;
        for (key, value, rc) in insertions.into_iter() {
            let storage_rc = self.storage.retrieve_rc(&key).unwrap_or_default();
            let bytes = RcTrieNode::encode(&value, storage_rc + rc).expect("Failed to serialize");
            db_changes.insert(key.as_ref().to_vec(), Some(bytes));
        }
        for (key, value, rc) in deletions.into_iter() {
            let storage_rc = self.storage.retrieve_rc(&key).unwrap_or_default();
            assert!(rc <= storage_rc);
            if rc < storage_rc {
                let bytes =
                    RcTrieNode::encode(&value, storage_rc - rc).expect("Failed to serialize");
                db_changes.insert(key.as_ref().to_vec(), Some(bytes));
            } else {
                db_changes.insert(key.as_ref().to_vec(), None);
            }
        }
        (db_changes, new_root)
    }

    pub fn iter<'a>(&'a self, root: &CryptoHash) -> Result<TrieIterator<'a>, String> {
        TrieIterator::new(self, root)
    }

    #[inline]
    pub fn apply_changes(&self, changes: DBChanges) -> std::io::Result<()> {
        let mut guard = self.storage.cache.lock().expect(POISONED_LOCK_ERR);
        for (key, value) in changes.iter() {
            let hash = CryptoHash::try_from(&key[..])
                .map_err(|_| std::io::Error::new(ErrorKind::Other, "Key is always a hash"))?;
            (*guard).cache_set(hash, value.clone());
        }
        self.storage.storage.read().expect(POISONED_LOCK_ERR).apply_state_updates(changes)
    }
}

pub type TrieItem<'a> = Result<(Vec<u8>, DBValue), String>;

#[derive(Clone, Eq, PartialEq, Debug)]
enum CrumbStatus {
    Entering,
    At,
    AtChild(usize),
    Exiting,
}

#[derive(Debug)]
struct Crumb {
    node: TrieNode,
    status: CrumbStatus,
}

impl Crumb {
    fn increment(&mut self) {
        self.status = match (&self.status, &self.node) {
            (_, &TrieNode::Empty) => CrumbStatus::Exiting,
            (&CrumbStatus::Entering, _) => CrumbStatus::At,
            (&CrumbStatus::At, &TrieNode::Branch(_, _)) => CrumbStatus::AtChild(0),
            (&CrumbStatus::AtChild(x), &TrieNode::Branch(_, _)) if x < 15 => {
                CrumbStatus::AtChild(x + 1)
            }
            _ => CrumbStatus::Exiting,
        }
    }
}

pub struct TrieIterator<'a> {
    trie: &'a Trie,
    trail: Vec<Crumb>,
    key_nibbles: Vec<u8>,
    root: CryptoHash,
}

impl<'a> TrieIterator<'a> {
    #![allow(clippy::new_ret_no_self)]
    /// Create a new iterator.
    pub fn new(trie: &'a Trie, root: &CryptoHash) -> Result<Self, String> {
        let mut r = TrieIterator {
            trie,
            trail: Vec::with_capacity(8),
            key_nibbles: Vec::with_capacity(64),
            root: *root,
        };
        if let Ok(node) = trie.retrieve_node(root) {
            r.descend_into_node(&node);
            return Ok(r);
        }
        Err(format!("Root hash {} not found", root))
    }

    /// Position the iterator on the first element with key => `key`.
    pub fn seek(&mut self, key: &[u8]) -> Result<(), String> {
        self.trail.clear();
        self.key_nibbles.clear();
        let mut hash = NodeHandle::Hash(self.root);
        let mut key = NibbleSlice::new(key);
        loop {
            let node = match hash {
                NodeHandle::Hash(hash) => self.trie.retrieve_node(&hash)?,
                NodeHandle::InMemory(_node) => unreachable!(),
            };
            let copy_node = node.clone();
            match node {
                TrieNode::Empty => return Ok(()),
                TrieNode::Leaf(leaf_key, _) => {
                    let existing_key = NibbleSlice::from_encoded(&leaf_key).0;
                    self.trail.push(Crumb {
                        status: if existing_key >= key {
                            CrumbStatus::Entering
                        } else {
                            CrumbStatus::Exiting
                        },
                        node: copy_node,
                    });
                    self.key_nibbles.extend(existing_key.iter());
                    return Ok(());
                }
                TrieNode::Branch(mut children, _) => {
                    if key.is_empty() {
                        self.trail.push(Crumb { status: CrumbStatus::Entering, node: copy_node });
                        return Ok(());
                    } else {
                        let idx = key.at(0) as usize;
                        self.trail.push(Crumb {
                            status: CrumbStatus::AtChild(idx as usize),
                            node: copy_node,
                        });
                        self.key_nibbles.push(key.at(0));
                        if let Some(child) = children[idx].take() {
                            hash = child;
                            key = key.mid(1);
                        } else {
                            return Ok(());
                        }
                    }
                }
                TrieNode::Extension(ext_key, child) => {
                    let existing_key = NibbleSlice::from_encoded(&ext_key).0;
                    if key.starts_with(&existing_key) {
                        self.trail.push(Crumb { status: CrumbStatus::At, node: copy_node });
                        self.key_nibbles.extend(existing_key.iter());
                        hash = child;
                        key = key.mid(existing_key.len());
                    } else {
                        self.descend_into_node(&copy_node);
                        return Ok(());
                    }
                }
            }
        }
    }

    fn descend_into_node(&mut self, node: &TrieNode) {
        self.trail.push(Crumb { status: CrumbStatus::Entering, node: node.clone() });
        match &self.trail.last().expect("Just pushed item").node {
            TrieNode::Leaf(ref key, _) | TrieNode::Extension(ref key, _) => {
                let key = NibbleSlice::from_encoded(key).0;
                self.key_nibbles.extend(key.iter());
            }
            _ => {}
        }
    }

    fn key(&self) -> Vec<u8> {
        let mut result = <Vec<u8>>::with_capacity(self.key_nibbles.len() / 2);
        for i in (1..self.key_nibbles.len()).step_by(2) {
            result.push(self.key_nibbles[i - 1] * 16 + self.key_nibbles[i]);
        }
        result
    }
}

impl<'a> Iterator for TrieIterator<'a> {
    type Item = TrieItem<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        enum IterStep {
            Continue,
            PopTrail,
            Descend(Result<Box<TrieNode>, String>),
        }
        loop {
            let iter_step = {
                self.trail.last_mut()?.increment();
                let b = self.trail.last().expect("Trail finished.");
                match (b.status.clone(), &b.node) {
                    (CrumbStatus::Exiting, n) => {
                        match n {
                            TrieNode::Leaf(ref key, _) | TrieNode::Extension(ref key, _) => {
                                let existing_key = NibbleSlice::from_encoded(&key).0;
                                let l = self.key_nibbles.len();
                                self.key_nibbles.truncate(l - existing_key.len());
                            }
                            TrieNode::Branch(_, _) => {
                                self.key_nibbles.pop();
                            }
                            _ => {}
                        }
                        IterStep::PopTrail
                    }
                    (CrumbStatus::At, TrieNode::Branch(_, value)) => {
                        if let Some(value) = value {
                            return Some(Ok((self.key(), DBValue::from_slice(value))));
                        } else {
                            IterStep::Continue
                        }
                    }
                    (CrumbStatus::At, TrieNode::Leaf(_, value)) => {
                        return Some(Ok((self.key(), DBValue::from_slice(value))));
                    }
                    (CrumbStatus::At, TrieNode::Extension(_, child)) => {
                        let next_node = match child {
                            NodeHandle::Hash(hash) => self.trie.retrieve_node(hash).map(Box::new),
                            NodeHandle::InMemory(_node) => unreachable!(),
                        };
                        IterStep::Descend(next_node)
                    }
                    (CrumbStatus::AtChild(i), TrieNode::Branch(children, _))
                        if children[i].is_some() =>
                    {
                        match i {
                            0 => self.key_nibbles.push(0),
                            i => {
                                *self.key_nibbles.last_mut().expect("Pushed child value before") =
                                    i as u8
                            }
                        }
                        let next_node = match &children[i] {
                            Some(NodeHandle::Hash(hash)) => {
                                self.trie.retrieve_node(&hash).map(Box::new)
                            }
                            Some(NodeHandle::InMemory(_node)) => unreachable!(),
                            _ => panic!("Wrapped with is_some()"),
                        };
                        IterStep::Descend(next_node)
                    }
                    (CrumbStatus::AtChild(i), TrieNode::Branch(_, _)) => {
                        if i == 0 {
                            self.key_nibbles.push(0);
                        }
                        IterStep::Continue
                    }
                    _ => panic!("Should never see Entering or AtChild without a Branch here."),
                }
            };
            match iter_step {
                IterStep::PopTrail => {
                    self.trail.pop();
                }
                IterStep::Descend(Ok(node)) => self.descend_into_node(&node),
                IterStep::Descend(Err(e)) => return Some(Err(e)),
                IterStep::Continue => {}
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::test_utils::create_trie;
    use rand::seq::SliceRandom;
    use rand::{rngs::ThreadRng, Rng};

    type TrieChanges = Vec<(Vec<u8>, Option<Vec<u8>>)>;

    fn test_populate_trie(trie: &Trie, root: &CryptoHash, changes: TrieChanges) -> CryptoHash {
        let mut other_changes = changes.clone();
        let (db_changes, root) = trie.update(root, other_changes.drain(..));
        trie.apply_changes(db_changes).unwrap();
        for (key, value) in changes {
            assert_eq!(trie.get(&root, &key), value);
        }
        root
    }

    fn test_clear_trie(trie: &Trie, root: &CryptoHash, changes: TrieChanges) -> CryptoHash {
        let delete_changes: TrieChanges =
            changes.iter().map(|(key, _)| (key.clone(), None)).collect();
        let mut other_delete_changes = delete_changes.clone();
        let (db_changes, root) = trie.update(root, other_delete_changes.drain(..));
        trie.apply_changes(db_changes).unwrap();
        for (key, _) in delete_changes {
            assert_eq!(trie.get(&root, &key), None);
        }
        println!("nice trie has no keys");
        root
    }

    #[test]
    fn test_encode_decode() {
        let node = RawTrieNode::Leaf(vec![1, 2, 3], vec![123, 245, 255]);
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);

        let mut children: [Option<CryptoHash>; 16] = Default::default();
        children[3] = Some(CryptoHash::default());
        let node = RawTrieNode::Branch(children, Some(vec![123, 245, 255]));
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);

        let node = RawTrieNode::Extension(vec![123, 245, 255], CryptoHash::default());
        let buf = node.encode().expect("Failed to serialize");
        let new_node = RawTrieNode::decode(&buf).expect("Failed to deserialize");
        assert_eq!(node, new_node);
    }

    #[test]
    fn test_basic_trie() {
        let trie = create_trie();
        let empty_root = Trie::empty_root();
        assert_eq!(trie.get(&empty_root, &[122]), None);
        let changes = vec![
            (b"doge".to_vec(), Some(b"coin".to_vec())),
            (b"docu".to_vec(), Some(b"value".to_vec())),
            (b"do".to_vec(), Some(b"verb".to_vec())),
            (b"horse".to_vec(), Some(b"stallion".to_vec())),
            (b"dog".to_vec(), Some(b"puppy".to_vec())),
            (b"h".to_vec(), Some(b"value".to_vec())),
        ];
        let root = test_populate_trie(&trie, &empty_root, changes.clone());
        let new_root = test_clear_trie(&trie, &root, changes);
        assert_eq!(new_root, empty_root);
        assert_eq!(trie.iter(&new_root).unwrap().fold(0, |acc, _| acc + 1), 0);
    }

    #[test]
    fn test_trie_iter() {
        let trie = create_trie();
        let pairs = vec![
            (b"a".to_vec(), Some(b"111".to_vec())),
            (b"b".to_vec(), Some(b"222".to_vec())),
            (b"x".to_vec(), Some(b"333".to_vec())),
            (b"y".to_vec(), Some(b"444".to_vec())),
        ];
        let root = test_populate_trie(&trie, &Trie::empty_root(), pairs.clone());
        let mut iter_pairs = vec![];
        for pair in trie.iter(&root).unwrap() {
            let (key, value) = pair.unwrap();
            iter_pairs.push((key, Some(value.to_vec())));
        }
        assert_eq!(pairs, iter_pairs);

        let mut other_iter = trie.iter(&root).unwrap();
        other_iter.seek(b"r").unwrap();
        assert_eq!(other_iter.next().unwrap().unwrap().0, b"x".to_vec());
    }

    #[test]
    fn test_trie_leaf_into_branch() {
        let trie = create_trie();
        let changes = vec![
            (b"dog".to_vec(), Some(b"puppy".to_vec())),
            (b"dog2".to_vec(), Some(b"puppy".to_vec())),
            (b"xxx".to_vec(), Some(b"puppy".to_vec())),
        ];
        test_populate_trie(&trie, &Trie::empty_root(), changes);
    }

    #[test]
    fn test_trie_same_node() {
        let trie = create_trie();
        let changes = vec![
            (b"dogaa".to_vec(), Some(b"puppy".to_vec())),
            (b"dogbb".to_vec(), Some(b"puppy".to_vec())),
            (b"cataa".to_vec(), Some(b"puppy".to_vec())),
            (b"catbb".to_vec(), Some(b"puppy".to_vec())),
            (b"dogax".to_vec(), Some(b"puppy".to_vec())),
        ];
        test_populate_trie(&trie, &Trie::empty_root(), changes);
    }

    #[test]
    fn test_trie_iter_seek_stop_at_extension() {
        let trie = create_trie();
        let changes = vec![
            (vec![0, 116, 101, 115, 116], Some(vec![0])),
            (vec![2, 116, 101, 115, 116], Some(vec![0])),
            (
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 98, 111, 98,
                    46, 110, 101, 97, 114,
                ],
                Some(vec![0]),
            ),
            (
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 110, 117,
                    108, 108,
                ],
                Some(vec![0]),
            ),
        ];
        let root = test_populate_trie(&trie, &Trie::empty_root(), changes);
        let mut iter = trie.iter(&root).unwrap();
        iter.seek(&vec![0, 116, 101, 115, 116, 44]).unwrap();
        let mut pairs = vec![];
        for pair in iter {
            pairs.push(pair.unwrap().0);
        }
        assert_eq!(
            pairs[..2],
            [
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 98, 111, 98,
                    46, 110, 101, 97, 114
                ],
                vec![
                    0, 116, 101, 115, 116, 44, 98, 97, 108, 97, 110, 99, 101, 115, 58, 110, 117,
                    108, 108
                ],
            ]
        );
    }

    #[test]
    fn test_trie_remove_non_existent_key() {
        let trie = create_trie();
        let mut initial = vec![
            (vec![99, 44, 100, 58, 58, 49], Some(vec![1])),
            (vec![99, 44, 100, 58, 58, 50], Some(vec![1])),
            (vec![99, 44, 100, 58, 58, 50, 51], Some(vec![1])),
        ];
        let (db_changes, root) = trie.update(&Trie::empty_root(), initial.drain(..));
        trie.apply_changes(db_changes).unwrap();

        let mut changes = vec![
            (vec![99, 44, 100, 58, 58, 45, 49], None),
            (vec![99, 44, 100, 58, 58, 50, 52], None),
        ];
        let (db_changes, root) = trie.update(&root, changes.drain(..));
        trie.apply_changes(db_changes).unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }
    }

    #[test]
    fn test_equal_leafs() {
        let trie = create_trie();
        let mut initial = vec![
            (vec![1, 2, 3], Some(vec![1])),
            (vec![2, 2, 3], Some(vec![1])),
            (vec![3, 2, 3], Some(vec![1])),
        ];
        let (db_changes, root) = trie.update(&Trie::empty_root(), initial.drain(..));
        trie.apply_changes(db_changes).unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }

        let mut changes = vec![(vec![1, 2, 3], None)];
        let (db_changes, root) = trie.update(&root, changes.drain(..));
        trie.apply_changes(db_changes).unwrap();
        for r in trie.iter(&root).unwrap() {
            r.unwrap();
        }
    }

    fn gen_changes(rng: &mut ThreadRng) -> Vec<(Vec<u8>, Option<Vec<u8>>)> {
        let alphabet = &b"abcdefgh"[0..rng.gen_range(2, 8)];
        let max_length = rng.gen_range(2, 8);

        let mut state: HashMap<Vec<u8>, Vec<u8>> = HashMap::new();
        let mut result = Vec::new();
        let delete_probability = rng.gen_range(0.1, 0.5);
        let size = rng.gen_range(1, 20);
        for _ in 0..size {
            let key_length = rng.gen_range(1, max_length);
            let key: Vec<u8> =
                (0..key_length).map(|_| alphabet.choose(rng).unwrap().clone()).collect();

            let delete = rng.gen_range(0.0, 1.0) < delete_probability;
            if delete {
                let mut keys: Vec<_> = state.keys().cloned().collect();
                keys.push(key);
                let key = keys.choose(rng).unwrap().clone();
                state.remove(&key);
                result.push((key.clone(), None));
            } else {
                let value_length = rng.gen_range(1, max_length);
                let value: Vec<u8> =
                    (0..value_length).map(|_| alphabet.choose(rng).unwrap().clone()).collect();
                result.push((key.clone(), Some(value.clone())));
                state.insert(key, value);
            }
        }
        result
    }

    fn simplify_changes(
        changes: &Vec<(Vec<u8>, Option<Vec<u8>>)>,
    ) -> Vec<(Vec<u8>, Option<Vec<u8>>)> {
        let mut state: HashMap<Vec<u8>, Vec<u8>> = HashMap::new();
        for (key, value) in changes.iter() {
            if let Some(value) = value {
                state.insert(key.clone(), value.clone());
            } else {
                state.remove(key);
            }
        }
        let mut result: Vec<_> = state.into_iter().map(|(k, v)| (k, Some(v))).collect();
        result.sort();
        result
    }

    #[test]
    fn test_trie_unique() {
        let mut rng = rand::thread_rng();
        for _ in 0..100 {
            let trie = create_trie();
            let trie_changes = gen_changes(&mut rng);
            let simplified_changes = simplify_changes(&trie_changes);

            let (db_changes1, root1) =
                trie.update(&Trie::empty_root(), trie_changes.iter().cloned());
            let (db_changes2, root2) =
                trie.update(&Trie::empty_root(), simplified_changes.iter().cloned());
            if root1 != root2 {
                eprintln!("{:?}", trie_changes);
                eprintln!("{:?}", simplified_changes);
                eprintln!("root1: {}", root1);
                eprintln!("root2: {}", root2);
                panic!("MISMATCH!");
            }
            let mut db_changes1: Vec<_> = db_changes1.into_iter().collect();
            db_changes1.sort();
            let mut db_changes2: Vec<_> = db_changes2.into_iter().collect();
            db_changes2.sort();
            assert_eq!(db_changes1, db_changes2);
        }
    }
}

'''
'''--- runtime/storage/src/trie/nibble_slice.rs ---
// Copyright 2015-2017 Parity Technologies (UK) Ltd.
// This file is part of Parity.

// Parity is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// Parity is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with Parity.  If not, see <http://www.gnu.org/licenses/>.

//! Nibble-orientated view onto byte-slice, allowing nibble-precision offsets.

use elastic_array::ElasticArray36;
use std::cmp::*;
use std::fmt;

/// Nibble-orientated view onto byte-slice, allowing nibble-precision offsets.
///
/// This is an immutable struct. No operations actually change it.
///
/// # Example
/// ```snippet
/// use patricia_trie::nibbleslice::NibbleSlice;
/// fn main() {
///   let d1 = &[0x01u8, 0x23, 0x45];
///   let d2 = &[0x34u8, 0x50, 0x12];
///   let d3 = &[0x00u8, 0x12];
///   let n1 = NibbleSlice::new(d1);			// 0,1,2,3,4,5
///   let n2 = NibbleSlice::new(d2);			// 3,4,5,0,1,2
///   let n3 = NibbleSlice::new_offset(d3, 1);	// 0,1,2
///   assert!(n1 > n3);							// 0,1,2,... > 0,1,2
///   assert!(n1 < n2);							// 0,... < 3,...
///   assert!(n2.mid(3) == n3);					// 0,1,2 == 0,1,2
///   assert!(n1.starts_with(&n3));
///   assert_eq!(n1.common_prefix(&n3), 3);
///   assert_eq!(n2.mid(3).common_prefix(&n1), 3);
/// }
/// ```
#[derive(Copy, Clone, Eq, Ord)]
pub struct NibbleSlice<'a> {
    data: &'a [u8],
    offset: usize,
}

/// Iterator type for a nibble slice.
pub struct NibbleSliceIterator<'a> {
    p: &'a NibbleSlice<'a>,
    i: usize,
}

impl<'a> Iterator for NibbleSliceIterator<'a> {
    type Item = u8;
    fn next(&mut self) -> Option<u8> {
        self.i += 1;
        if self.i <= self.p.len() {
            Some(self.p.at(self.i - 1))
        } else {
            None
        }
    }
}

impl<'a> NibbleSlice<'a> {
    /// Create a new nibble slice with the given byte-slice.
    pub fn new(data: &'a [u8]) -> Self {
        NibbleSlice::new_offset(data, 0)
    }

    /// Create a new nibble slice with the given byte-slice with a nibble offset.
    pub fn new_offset(data: &'a [u8], offset: usize) -> Self {
        NibbleSlice { data, offset }
    }

    /// Get an iterator for the series of nibbles.
    pub fn iter(&'a self) -> NibbleSliceIterator<'a> {
        NibbleSliceIterator { p: self, i: 0 }
    }

    /// Create a new nibble slice from the given HPE encoded data (e.g. output of `encoded()`).
    pub fn from_encoded(data: &'a [u8]) -> (NibbleSlice, bool) {
        (Self::new_offset(data, if data[0] & 16 == 16 { 1 } else { 2 }), data[0] & 32 == 32)
    }

    /// Is this an empty slice?
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Get the length (in nibbles, naturally) of this slice.
    #[inline]
    pub fn len(&self) -> usize {
        self.data.len() * 2 - self.offset
    }

    /// Get the nibble at position `i`.
    #[inline(always)]
    pub fn at(&self, i: usize) -> u8 {
        if (self.offset + i) & 1 == 1 {
            self.data[(self.offset + i) / 2] & 15u8
        } else {
            self.data[(self.offset + i) / 2] >> 4
        }
    }

    /// Return object which represents a view on to this slice (further) offset by `i` nibbles.
    pub fn mid(&self, i: usize) -> NibbleSlice<'a> {
        NibbleSlice { data: self.data, offset: self.offset + i }
    }

    /// Do we start with the same nibbles as the whole of `them`?
    pub fn starts_with(&self, them: &Self) -> bool {
        self.common_prefix(them) == them.len()
    }

    /// How many of the same nibbles at the beginning do we match with `them`?
    pub fn common_prefix(&self, them: &Self) -> usize {
        let s = min(self.len(), them.len());
        for i in 0..s {
            if self.at(i) != them.at(i) {
                return i;
            }
        }
        s
    }

    /// Encode while nibble slice in prefixed hex notation, noting whether it `is_leaf`.
    #[inline]
    pub fn encoded(&self, is_leaf: bool) -> ElasticArray36<u8> {
        let l = self.len();
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            r.push(self.at(i) * 16 + self.at(i + 1));
            i += 2;
        }
        r
    }

    pub fn merge_encoded(&self, other: &Self, is_leaf: bool) -> ElasticArray36<u8> {
        let l = self.len() + other.len();
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            let bit1 = if i < self.len() { self.at(i) } else { other.at(i - self.len()) };
            let bit2 = if i + 1 < l {
                if i + 1 < self.len() {
                    self.at(i + 1)
                } else {
                    other.at(i + 1 - self.len())
                }
            } else {
                0
            };

            r.push(bit1 * 16 + bit2);
            i += 2;
        }
        r
    }

    /// Encode only the leftmost `n` bytes of the nibble slice in prefixed hex notation,
    /// noting whether it `is_leaf`.
    pub fn encoded_leftmost(&self, n: usize, is_leaf: bool) -> ElasticArray36<u8> {
        let l = min(self.len(), n);
        let mut r = ElasticArray36::new();
        let mut i = l % 2;
        r.push(if i == 1 { 0x10 + self.at(0) } else { 0 } + if is_leaf { 0x20 } else { 0 });
        while i < l {
            r.push(self.at(i) * 16 + self.at(i + 1));
            i += 2;
        }
        r
    }
}

impl<'a> PartialEq for NibbleSlice<'a> {
    fn eq(&self, them: &Self) -> bool {
        self.len() == them.len() && self.starts_with(them)
    }
}

impl<'a> PartialOrd for NibbleSlice<'a> {
    fn partial_cmp(&self, them: &Self) -> Option<Ordering> {
        let s = min(self.len(), them.len());
        for i in 0..s {
            match self.at(i).partial_cmp(&them.at(i)).unwrap() {
                Ordering::Less => return Some(Ordering::Less),
                Ordering::Greater => return Some(Ordering::Greater),
                _ => {}
            }
        }
        self.len().partial_cmp(&them.len())
    }
}

impl<'a> fmt::Debug for NibbleSlice<'a> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.is_empty() {
            return Ok(());
        }
        write!(f, "{:01x}", self.at(0))?;
        for i in 1..self.len() {
            write!(f, "'{:01x}", self.at(i))?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::NibbleSlice;
    use elastic_array::ElasticArray36;
    static D: &'static [u8; 3] = &[0x01u8, 0x23, 0x45];

    #[test]
    fn basics() {
        let n = NibbleSlice::new(D);
        assert_eq!(n.len(), 6);
        assert!(!n.is_empty());

        let n = NibbleSlice::new_offset(D, 6);
        assert!(n.is_empty());

        let n = NibbleSlice::new_offset(D, 3);
        assert_eq!(n.len(), 3);
        for i in 0..3 {
            assert_eq!(n.at(i), i as u8 + 3);
        }
    }

    #[test]
    fn iterator() {
        let n = NibbleSlice::new(D);
        let mut nibbles: Vec<u8> = vec![];
        nibbles.extend(n.iter());
        assert_eq!(nibbles, (0u8..6).collect::<Vec<_>>())
    }

    #[test]
    fn mid() {
        let n = NibbleSlice::new(D);
        let m = n.mid(2);
        for i in 0..4 {
            assert_eq!(m.at(i), i as u8 + 2);
        }
        let m = n.mid(3);
        for i in 0..3 {
            assert_eq!(m.at(i), i as u8 + 3);
        }
    }

    #[test]
    fn encoded() {
        let n = NibbleSlice::new(D);
        assert_eq!(n.encoded(false), ElasticArray36::from_slice(&[0x00, 0x01, 0x23, 0x45]));
        assert_eq!(n.encoded(true), ElasticArray36::from_slice(&[0x20, 0x01, 0x23, 0x45]));
        assert_eq!(n.mid(1).encoded(false), ElasticArray36::from_slice(&[0x11, 0x23, 0x45]));
        assert_eq!(n.mid(1).encoded(true), ElasticArray36::from_slice(&[0x31, 0x23, 0x45]));
    }

    #[test]
    fn from_encoded() {
        let n = NibbleSlice::new(D);
        assert_eq!((n, false), NibbleSlice::from_encoded(&[0x00, 0x01, 0x23, 0x45]));
        assert_eq!((n, true), NibbleSlice::from_encoded(&[0x20, 0x01, 0x23, 0x45]));
        assert_eq!((n.mid(1), false), NibbleSlice::from_encoded(&[0x11, 0x23, 0x45]));
        assert_eq!((n.mid(1), true), NibbleSlice::from_encoded(&[0x31, 0x23, 0x45]));
    }

    #[test]
    fn shared() {
        let n = NibbleSlice::new(D);

        let other = &[0x01u8, 0x23, 0x01, 0x23, 0x45, 0x67];
        let m = NibbleSlice::new(other);

        assert_eq!(n.common_prefix(&m), 4);
        assert_eq!(m.common_prefix(&n), 4);
        assert_eq!(n.mid(1).common_prefix(&m.mid(1)), 3);
        assert_eq!(n.mid(1).common_prefix(&m.mid(2)), 0);
        assert_eq!(n.common_prefix(&m.mid(4)), 6);
        assert!(!n.starts_with(&m.mid(4)));
        assert!(m.mid(4).starts_with(&n));
    }

    #[test]
    fn compare() {
        let other = &[0x01u8, 0x23, 0x01, 0x23, 0x45];
        let n = NibbleSlice::new(D);
        let m = NibbleSlice::new(other);

        assert!(n != m);
        assert!(n > m);
        assert!(m < n);

        assert!(n == m.mid(4));
        assert!(n >= m.mid(4));
        assert!(n <= m.mid(4));
    }

    #[test]
    fn nibble_indexing() {
        let encoded = vec![32, 116, 101, 115, 116];
        let n = NibbleSlice::from_encoded(&encoded).0;
        let nibbles: Vec<u8> = (0..n.len()).map(|i| n.at(i)).collect();
        assert_eq!(nibbles, vec![7, 4, 6, 5, 7, 3, 7, 4]);
    }
}

'''
'''--- runtime/storage/src/trie/update.rs ---
use kvdb::DBValue;
use primitives::types::MerkleHash;
use std::collections::btree_map::BTreeMap;
use std::iter::Peekable;
use std::sync::Arc;

use super::{DBChanges, Trie, TrieIterator};
use std::convert::identity;

/// Provides a way to access Storage and record changes with future commit.
pub struct TrieUpdate {
    trie: Arc<Trie>,
    root: MerkleHash,
    committed: BTreeMap<Vec<u8>, Option<Vec<u8>>>,
    prospective: BTreeMap<Vec<u8>, Option<Vec<u8>>>,
}

impl TrieUpdate {
    pub fn new(trie: Arc<Trie>, root: MerkleHash) -> Self {
        TrieUpdate { trie, root, committed: BTreeMap::default(), prospective: BTreeMap::default() }
    }
    pub fn get(&self, key: &[u8]) -> Option<DBValue> {
        if let Some(value) = self.prospective.get(key) {
            Some(DBValue::from_slice(value.as_ref()?))
        } else if let Some(value) = self.committed.get(key) {
            Some(DBValue::from_slice(value.as_ref()?))
        } else {
            self.trie.get(&self.root, key).map(DBValue::from_vec)
        }
    }
    pub fn set(&mut self, key: Vec<u8>, value: DBValue) -> Option<Vec<u8>> {
        self.prospective.insert(key, Some(value.into_vec())).and_then(identity)
    }
    pub fn remove(&mut self, key: &[u8]) -> Option<Vec<u8>> {
        self.prospective.insert(key.to_vec(), None).and_then(identity)
    }

    pub fn for_keys_with_prefix<F: FnMut(&[u8])>(&self, prefix: &[u8], mut f: F) {
        match self.iter(prefix) {
            Ok(iter) => {
                for key in iter {
                    f(&key);
                }
            }
            Err(e) => {
                debug!(target: "trie", "Error while iterating by prefix: {}", e);
            }
        }
    }

    pub fn commit(&mut self) {
        if self.committed.is_empty() {
            std::mem::swap(&mut self.prospective, &mut self.committed);
        } else {
            for (key, val) in std::mem::replace(&mut self.prospective, BTreeMap::new()).into_iter()
            {
                *self.committed.entry(key).or_default() = val;
            }
        }
    }
    pub fn rollback(&mut self) {
        self.prospective.clear();
    }
    pub fn finalize(mut self) -> (MerkleHash, DBChanges) {
        if !self.prospective.is_empty() {
            self.commit();
        }
        let TrieUpdate { trie, root, committed, .. } = self;
        let (db_changes, root) = trie.update(&root, committed.into_iter());
        (root, db_changes)
    }
    pub fn iter(&self, prefix: &[u8]) -> Result<TrieUpdateIterator, String> {
        TrieUpdateIterator::new(self, prefix, b"", None)
    }

    pub fn range(
        &self,
        prefix: &[u8],
        start: &[u8],
        end: &[u8],
    ) -> Result<TrieUpdateIterator, String> {
        TrieUpdateIterator::new(self, prefix, start, Some(end))
    }

    pub fn get_root(&self) -> MerkleHash {
        self.root
    }
}

struct MergeIter<'a, I: Iterator<Item = (&'a Vec<u8>, &'a Option<Vec<u8>>)>> {
    left: Peekable<I>,
    right: Peekable<I>,
}

impl<'a, I: Iterator<Item = (&'a Vec<u8>, &'a Option<Vec<u8>>)>> Iterator for MergeIter<'a, I> {
    type Item = (&'a Vec<u8>, &'a Option<Vec<u8>>);

    fn next(&mut self) -> Option<Self::Item> {
        let res = match (self.left.peek(), self.right.peek()) {
            (Some(&(ref left_key, _)), Some(&(ref right_key, _))) => {
                if left_key < right_key {
                    std::cmp::Ordering::Less
                } else if left_key == right_key {
                    std::cmp::Ordering::Equal
                } else {
                    std::cmp::Ordering::Greater
                }
            }
            (Some(_), None) => std::cmp::Ordering::Less,
            (None, Some(_)) => std::cmp::Ordering::Greater,
            (None, None) => return None,
        };

        // Check which elements comes first and only advance the corresponding iterator.
        // If two keys are equal, take the value from `right`.
        match res {
            std::cmp::Ordering::Less => self.left.next(),
            std::cmp::Ordering::Greater => self.right.next(),
            std::cmp::Ordering::Equal => {
                self.left.next();
                self.right.next()
            }
        }
    }
}

type MergeBTreeRange<'a> =
    MergeIter<'a, std::collections::btree_map::Range<'a, Vec<u8>, Option<Vec<u8>>>>;

pub struct TrieUpdateIterator<'a> {
    prefix: Vec<u8>,
    end_offset: Option<Vec<u8>>,
    trie_iter: Peekable<TrieIterator<'a>>,
    overlay_iter: Peekable<MergeBTreeRange<'a>>,
}

impl<'a> TrieUpdateIterator<'a> {
    #![allow(clippy::new_ret_no_self)]
    pub fn new(
        state_update: &'a TrieUpdate,
        prefix: &[u8],
        start: &[u8],
        end: Option<&[u8]>,
    ) -> Result<Self, String> {
        let mut trie_iter = state_update.trie.iter(&state_update.root)?;
        let mut start_offset = prefix.to_vec();
        start_offset.extend_from_slice(start);
        let end_offset = match end {
            Some(end) => {
                let mut p = prefix.to_vec();
                p.extend_from_slice(end);
                Some(p)
            }
            None => None,
        };
        trie_iter.seek(&start_offset)?;
        let committed_iter = state_update.committed.range(start_offset.clone()..);
        let prospective_iter = state_update.prospective.range(start_offset..);
        let overlay_iter =
            MergeIter { left: committed_iter.peekable(), right: prospective_iter.peekable() }
                .peekable();
        Ok(TrieUpdateIterator {
            prefix: prefix.to_vec(),
            end_offset,
            trie_iter: trie_iter.peekable(),
            overlay_iter,
        })
    }
}

impl<'a> Iterator for TrieUpdateIterator<'a> {
    type Item = Vec<u8>;

    fn next(&mut self) -> Option<Self::Item> {
        let stop_cond = |key: &Vec<u8>, prefix: &Vec<u8>, end_offset: &Option<Vec<u8>>| {
            !key.starts_with(prefix)
                || match end_offset {
                    Some(end) => key > end,
                    None => false,
                }
        };
        enum Ordering {
            Trie,
            Overlay,
            Both,
        }
        // Usually one iteration, unless need to skip None values in prospective / committed.
        loop {
            let res = {
                match (self.trie_iter.peek(), self.overlay_iter.peek()) {
                    (Some(&Ok((ref left_key, _))), Some(&(ref right_key, _))) => {
                        match (
                            stop_cond(left_key, &self.prefix, &self.end_offset),
                            stop_cond(*right_key, &self.prefix, &self.end_offset),
                        ) {
                            (false, false) => {
                                if left_key < *right_key {
                                    Ordering::Trie
                                } else if &left_key == right_key {
                                    Ordering::Both
                                } else {
                                    Ordering::Overlay
                                }
                            }
                            (false, true) => Ordering::Trie,
                            (true, false) => Ordering::Overlay,
                            (true, true) => {
                                return None;
                            }
                        }
                    }
                    (Some(&Ok((ref left_key, _))), None) => {
                        if stop_cond(left_key, &self.prefix, &self.end_offset) {
                            return None;
                        }
                        Ordering::Trie
                    }
                    (None, Some(&(ref right_key, _))) => {
                        if stop_cond(right_key, &self.prefix, &self.end_offset) {
                            return None;
                        }
                        Ordering::Overlay
                    }
                    (None, None) => return None,
                    (Some(&Err(_)), _) => return None,
                }
            };

            // Check which elements comes first and only advance the corresponding iterator.
            // If two keys are equal, take the value from `right`.
            return match res {
                Ordering::Trie => match self.trie_iter.next() {
                    Some(Ok(value)) => Some(value.0),
                    _ => None,
                },
                Ordering::Overlay => match self.overlay_iter.next() {
                    Some((key, Some(_))) => Some(key.clone()),
                    Some((_, None)) => continue,
                    None => None,
                },
                Ordering::Both => {
                    self.trie_iter.next();
                    match self.overlay_iter.next() {
                        Some((key, Some(_))) => Some(key.clone()),
                        Some((_, None)) => continue,
                        None => None,
                    }
                }
            };
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::test_utils::create_trie;

    use super::*;

    #[test]
    fn trie() {
        let trie = create_trie();
        let root = MerkleHash::default();
        let mut trie_update = TrieUpdate::new(trie.clone(), root);
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"xxx".to_vec(), DBValue::from_slice(b"puppy"));
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();
        let trie_update2 = TrieUpdate::new(trie.clone(), new_root);
        assert_eq!(trie_update2.get(b"dog").unwrap(), DBValue::from_slice(b"puppy"));
        let mut values = vec![];
        trie_update2.for_keys_with_prefix(b"dog", |key| values.push(key.to_vec()));
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);
    }

    #[test]
    fn trie_remove() {
        let trie = create_trie();

        // Delete non-existing element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.remove(b"dog");
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();
        assert_eq!(new_root, MerkleHash::default());

        // Add and right away delete element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.remove(b"dog");
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();
        assert_eq!(new_root, MerkleHash::default());

        // Add, apply changes and then delete element.
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();
        assert_ne!(new_root, MerkleHash::default());
        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.remove(b"dog");
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();
        assert_eq!(new_root, MerkleHash::default());
    }

    #[test]
    fn trie_iter() {
        let trie = create_trie();
        let mut trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
        trie_update.set(b"dog".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"aaa".to_vec(), DBValue::from_slice(b"puppy"));
        let (new_root, transaction) = trie_update.finalize();
        trie.apply_changes(transaction).ok();

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.set(b"xxx".to_vec(), DBValue::from_slice(b"puppy"));

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);

        trie_update.rollback();

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec()]);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.remove(b"dog");

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values.len(), 0);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.commit();
        trie_update.remove(b"dog2");

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec()]);

        let mut trie_update = TrieUpdate::new(trie.clone(), new_root);
        trie_update.set(b"dog2".to_vec(), DBValue::from_slice(b"puppy"));
        trie_update.commit();
        trie_update.set(b"dog3".to_vec(), DBValue::from_slice(b"puppy"));

        let values: Vec<Vec<u8>> = trie_update.iter(b"dog").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec(), b"dog3".to_vec()]);

        let values: Vec<Vec<u8>> = trie_update.range(b"do", b"g", b"g2").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec()]);

        let values: Vec<Vec<u8>> = trie_update.range(b"do", b"", b"xyz").unwrap().collect();
        assert_eq!(values, vec![b"dog".to_vec(), b"dog2".to_vec(), b"dog3".to_vec()]);
    }
}

'''
'''--- runtime/verifier/Cargo.toml ---
[package]
name = "near-verifier"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]

near-primitives = { path = "../../core/primitives" }
near-store = { path = "../../core/store"}

'''
'''--- runtime/verifier/src/lib.rs ---
use near_primitives::account::{AccessKey, Account};
use near_primitives::crypto::signature::{verify, PublicKey};
use near_primitives::logging;
use near_primitives::transaction::{SignedTransaction, TransactionBody};
use near_primitives::types::AccountId;
use near_primitives::utils::{is_valid_account_id, key_for_access_key, key_for_account};
use near_store::{get, TrieUpdate};

pub struct VerificationData {
    pub originator_id: AccountId,
    pub originator: Account,
    pub public_key: PublicKey,
    pub access_key: Option<AccessKey>,
}

pub struct TransactionVerifier<'a> {
    state_update: &'a TrieUpdate,
}

impl<'a> TransactionVerifier<'a> {
    pub fn new(state_update: &'a TrieUpdate) -> Self {
        TransactionVerifier { state_update }
    }

    pub fn verify_transaction(
        &self,
        transaction: &SignedTransaction,
    ) -> Result<VerificationData, String> {
        let originator_id = transaction.body.get_originator();
        let originator: Option<Account> = get(self.state_update, &key_for_account(&originator_id));
        match originator {
            Some(originator) => {
                if transaction.body.get_nonce() <= originator.nonce {
                    return Err(format!(
                        "Transaction nonce {} must be larger than originator's nonce {}",
                        transaction.body.get_nonce(),
                        originator.nonce,
                    ));
                }

                let contract_id = transaction.body.get_contract_id();
                if let Some(ref contract_id) = contract_id {
                    if !is_valid_account_id(&contract_id) {
                        return Err(format!(
                            "Invalid contract_id / receiver {} according to requirements",
                            contract_id
                        ));
                    }
                }

                let hash = transaction.get_hash();
                let hash = hash.as_ref();
                let public_key = originator
                    .public_keys
                    .iter()
                    .find(|key| verify(&hash, &transaction.signature, &key))
                    .cloned();

                if let Some(public_key) = public_key {
                    if let Some(ref tx_public_key) = transaction.public_key {
                        if &public_key != tx_public_key {
                            return Err(
                                "Transaction is signed with different public key than given"
                                    .to_string(),
                            );
                        }
                    }
                    Ok(VerificationData { originator_id, originator, public_key, access_key: None })
                } else {
                    if let Some(ref public_key) = transaction.public_key {
                        let access_key: Option<AccessKey> = get(
                            self.state_update,
                            &key_for_access_key(&originator_id, &public_key),
                        );
                        if let Some(access_key) = access_key {
                            if let TransactionBody::FunctionCall(ref function_call) =
                                transaction.body
                            {
                                let access_contract_id =
                                    access_key.contract_id.as_ref().unwrap_or(&originator_id);

                                if &function_call.contract_id != access_contract_id {
                                    return Err(format!(
                                        "Access key contract ID {:?} doesn't match TX contract account ID {:?}",
                                        access_contract_id,
                                        function_call.contract_id,
                                    ));
                                }
                                if let Some(ref access_method_name) = access_key.method_name {
                                    if &function_call.method_name != access_method_name {
                                        return Err(format!(
                                            "Transaction method name {:?} doesn't match the access key method name {:?}",
                                            logging::pretty_utf8(&function_call.method_name),
                                            logging::pretty_utf8(access_method_name),
                                        ));
                                    }
                                }
                                Ok(VerificationData {
                                    originator_id,
                                    originator,
                                    public_key: *public_key,
                                    access_key: Some(access_key),
                                })
                            } else {
                                Err("Access key can only be used with the FunctionCall transactions".to_string())
                            }
                        } else {
                            Err(format!(
                                "Transaction is not signed with a public key of the originator {:?}",
                                originator_id,
                            ))
                        }
                    } else {
                        Err(format!(
                            "Transaction is not signed with a public key of the originator {:?}",
                            originator_id,
                        ))
                    }
                }
            }
            _ => Err(format!("Originator {:?} does not exist", originator_id)),
        }
    }
}

'''
'''--- runtime/wasm/Cargo.toml ---
[package]
name = "wasm"
version = "0.0.2"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
wasmi = { version = "0.4.1" }
pwasm-utils = "0.7.0"
parity-wasm = "0.31.3"
wasmer-runtime = "0.4.2"
byteorder = "1.2"
hex = "0.3"
log = "0.4"
cached = { git = "https://github.com/nearprotocol/cached", rev = "7e472eddef68607e344d5a106a0e6705d92e55be" }
serde = "1.0"
serde_derive = "1.0"

near-primitives = { path = "../../core/primitives" }

[dev-dependencies]
assert_matches = "1.3.0"
wabt = "0.7.4"
'''
'''--- runtime/wasm/runtest/Cargo.toml ---
[package]
name = "runtest"
version = "0.0.1"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
byteorder = { version = "1", default-features = false }

wasm = { path = "../" }
near-primitives = { path = "../../../core/primitives" }

[dev-dependencies]
wabt = "0.7.4"

'''
'''--- runtime/wasm/runtest/generate-wasm/build.sh ---
#!/bin/bash

pushd $(dirname "$0")/to-wasm
cargo +nightly build --target wasm32-unknown-unknown --release
cp target/wasm32-unknown-unknown/release/to_wasm.wasm ../
wasm-gc ../to_wasm.wasm
cp ../to_wasm.wasm ../../res/wasm_with_mem.wasm
popd

rm $(dirname "$0")/to_wasm.wasm

'''
'''--- runtime/wasm/runtest/generate-wasm/to-wasm/Cargo.toml ---
[package]
name = "to-wasm"
version = "0.0.1"
authors = ["Near Inc <hello@nearprotocol.com>"]

[lib]
path = "src/lib.rs"
crate-type = ["cdylib"]

[dependencies]
wee_alloc = { version = "0.4.3", default-features = false }
byteorder = { version = "1", default-features = false }

[profile.release]
panic = "abort"
lto = true
opt-level = "z"

[workspace]
members = []

'''
'''--- runtime/wasm/runtest/generate-wasm/to-wasm/src/lib.rs ---
// We aren't using the standard library.
#![no_std]
#![feature(alloc_error_handler)]
#![feature(allocator_api)]
#![feature(const_vec_new)]
#![feature(alloc)]

use core::panic::PanicInfo;

#[allow(unused)]
#[macro_use]
extern crate alloc;

extern crate wee_alloc;

extern crate byteorder;

use alloc::vec::Vec;
use byteorder::{ByteOrder, LittleEndian};

#[global_allocator]
static ALLOC: wee_alloc::WeeAlloc = wee_alloc::WeeAlloc::INIT;

type DataTypeIndex = u32;

pub const DATA_TYPE_ORIGINATOR_ACCOUNT_ID: DataTypeIndex = 1;
pub const DATA_TYPE_CURRENT_ACCOUNT_ID: DataTypeIndex = 2;
pub const DATA_TYPE_STORAGE: DataTypeIndex = 3;
pub const DATA_TYPE_INPUT: DataTypeIndex = 4;
pub const DATA_TYPE_RESULT: DataTypeIndex = 5;
pub const DATA_TYPE_STORAGE_ITER: DataTypeIndex = 6;

#[allow(unused)]
extern "C" {
    fn storage_write(key_len: usize, key_ptr: *const u8, value_len: usize, value_ptr: *const u8);
    fn storage_remove(key_len: usize, key_ptr: *const u8);
    fn storage_has_key(key_len: usize, key_ptr: *const u8) -> bool;

    fn result_count() -> u32;
    fn result_is_ok(index: u32) -> bool;

    fn return_value(value_len: usize, value_ptr: *const u8);
    fn return_promise(promise_index: u32);

    fn data_read(
        data_type_index: u32,
        key_len: usize,
        key_ptr: *const u8,
        max_buf_len: usize,
        buf_ptr: *mut u8,
    ) -> usize;

    // AccountID is just 32 bytes without the prefix length.
    fn promise_create(
        account_id_len: usize,
        account_id_ptr: *const u8,
        method_name_len: usize,
        method_name_ptr: *const u8,
        arguments_len: usize,
        arguments_ptr: *const u8,
        amount_ptr: *const u8,
    ) -> u32;

    fn promise_then(
        promise_index: u32,
        method_name_len: usize,
        method_name_ptr: *const u8,
        arguments_len: usize,
        arguments_ptr: *const u8,
        amount_ptr: *const u8,
    ) -> u32;

    fn promise_and(promise_index1: u32, promise_index2: u32) -> u32;

    fn check_ethash(
        block_number: u64,
        header_hash_ptr: *const u8,
        header_hash_len: usize,
        nonce: u64,
        mix_hash_ptr: *const u8,
        mix_hash_len: usize,
        difficulty: u64,
    ) -> u32;

    fn frozen_balance(balance_ptr: *const u8);
    fn liquid_balance(balance_ptr: *const u8);
    fn deposit(min_amount_ptr: u32, max_amount_ptr: u32, balance_ptr: u32);
    fn withdraw(min_amount_ptr: u32, max_amount_ptr: u32, balance_ptr: u32);
    fn storage_usage() -> u64;
    fn received_amount() -> u64;
    fn assert(expr: bool);

    /// Hash buffer is 32 bytes
    fn hash(value_len: usize, value_ptr: *const u8, buf_ptr: *mut u8);
    fn hash32(value_len: usize, value_ptr: *const u8) -> u32;

    // Fills given buffer with random u8.
    fn random_buf(buf_len: u32, buf_ptr: *mut u8);
    fn random32() -> u32;

    fn block_index() -> u64;

    /// Log using utf-8 string format.
    fn debug(msg_len: usize, msg_ptr: *const u8);
}

const MAX_BUF_SIZE: usize = 1 << 16;
static mut SCRATCH_BUF: Vec<u8> = Vec::new();

fn read(type_index: u32, key_len: usize, key: *const u8) -> Vec<u8> {
    unsafe {
        if SCRATCH_BUF.len() == 0 {
            SCRATCH_BUF.resize(MAX_BUF_SIZE, 0);
        }
        let len = data_read(type_index, key_len, key, MAX_BUF_SIZE, SCRATCH_BUF.as_mut_ptr());
        assert(len <= MAX_BUF_SIZE);
        SCRATCH_BUF[..len as usize].to_vec()
    }
}

fn storage_read(key_len: usize, key: *const u8) -> Vec<u8> {
    read(DATA_TYPE_STORAGE, key_len, key)
}

fn input_read() -> Vec<u8> {
    read(DATA_TYPE_INPUT, 0, 0 as (*const u8))
}

fn my_log(msg: &[u8]) {
    unsafe {
        debug(msg.len(), msg.as_ptr());
    }
}

fn result_read(index: u32) -> Vec<u8> {
    read(DATA_TYPE_RESULT, 0, index as (*const u8))
}

fn return_i32(res: i32) {
    unsafe {
        let mut buf = [0u8; 4];
        LittleEndian::write_i32(&mut buf, res);
        return_value(4, buf.as_ptr())
    }
}

fn return_u64(res: u64) {
    unsafe {
        let mut buf = [0u8; 8];
        LittleEndian::write_u64(&mut buf, res);
        return_value(8, buf.as_ptr())
    }
}

//fn cast_2u64()
//
fn return_u128(res: u128) {
    unsafe {
//        let mut buf = [0u8; 16];
//        let ptr = write_u128(res);
//        LittleEndian::write_u64(&mut buf, ptr);
//        LittleEndian::write_u64(&mut buf[8..], ptr + 8);
        return_value(16, write_u128(&res))
    }
}

fn write_u128(value: &u128) -> *const u8 {
    value as *const u128 as *const u8
}

fn originator_id() -> Vec<u8> {
    read(DATA_TYPE_ORIGINATOR_ACCOUNT_ID, 0, 0 as (*const u8))
}

fn account_id() -> Vec<u8> {
    read(DATA_TYPE_CURRENT_ACCOUNT_ID, 0, 0 as (*const u8))
}

#[no_mangle]
fn key_to_str(key: u32) -> Vec<u8> {
    let mut str_key = b"key: 0000000000".to_vec();
    let mut pos = str_key.len() - 1;
    let mut mkey = key;
    while mkey > 0 {
        str_key[pos] = b'0' as u8 + (mkey % 10) as u8;
        pos -= 1;
        mkey /= 10;
    }
    str_key
}

#[no_mangle]
pub fn put_int(key: u32, value: i32) {
    unsafe {
        let mut val_bytes = [0u8; 4];
        LittleEndian::write_i32(&mut val_bytes, value);
        let key = key_to_str(key);
        storage_write(key.len(), key.as_ptr(), 4, val_bytes.as_ptr());
    }
}

#[no_mangle]
pub fn put_u64(key: u32, value: u64) {
    unsafe {
        let mut val_bytes = [0u8; 8];
        LittleEndian::write_u64(&mut val_bytes, value);
        let key = key_to_str(key);
        storage_write(key.len(), key.as_ptr(), 8, val_bytes.as_ptr());
    }
}

#[no_mangle]
pub fn get_int(key: u32) -> i32 {
    unsafe {
        let key = key_to_str(key);
        let val = storage_read(key.len(), key.as_ptr());
        assert(val.len() == 4);
        LittleEndian::read_i32(&val[..])
    }
}

#[no_mangle]
pub fn remove_int(key: u32) {
    unsafe {
        let key = key_to_str(key);
        storage_remove(key.len(), key.as_ptr());
    }
}

#[no_mangle]
pub fn has_int(key: u32) -> bool {
    unsafe {
        let key = key_to_str(key);
        storage_has_key(key.len(), key.as_ptr())
    }
}

#[no_mangle]
pub fn log_something() {
    my_log(b"hello");
}

#[no_mangle]
pub fn run_test() {
    return_i32(10)
}

#[no_mangle]
pub fn run_test_with_storage_change() {
    unsafe {
        put_int(10, 20);
        put_int(50, 150);
        put_int(100, 300);
        assert(has_int(50));
        remove_int(50);
        assert(!has_int(50));

        put_u64(100, 300);
        let res = get_int(10);
        return_i32(res)
    }
}

#[no_mangle]
pub fn sum_with_input() {
    unsafe {
        let input = input_read();
        assert(input.len() == 8);
        let a = LittleEndian::read_i32(&input[..4]);
        let b = LittleEndian::read_i32(&input[4..]);
        let sum = a + b;
        return_i32(sum)
    }
}

#[no_mangle]
pub fn get_account_id() {
    unsafe {
        let acc_id = account_id();
        return_value(acc_id.len(), acc_id.as_ptr())
    }
}

#[no_mangle]
pub fn get_originator_id() {
    unsafe {
        let acc_id = originator_id();
        return_value(acc_id.len(), acc_id.as_ptr())
    }
}

#[no_mangle]
pub fn sum_with_multiple_results() {
    unsafe {
        let cnt = result_count();
        if cnt == 0 {
            return return_i32(-100);
        }
        let mut sum = 0;
        for index in 0..cnt {
            if !result_is_ok(index) {
                return return_i32(-100);
            }
            sum += LittleEndian::read_i32(&result_read(index));
        }
        return_i32(sum)
    }
}

#[no_mangle]
pub fn create_promises_and_join() {
    unsafe {
        let promise1 = promise_create(
            5,
            b"test1".to_vec().as_ptr(),
            4,
            b"run1".to_vec().as_ptr(),
            5,
            b"args1".to_vec().as_ptr(),
            write_u128(&0)
        );
        let promise2 = promise_create(
            5,
            b"test2".to_vec().as_ptr(),
            4,
            b"run2".to_vec().as_ptr(),
            5,
            b"args2".to_vec().as_ptr(),
            write_u128(&0)
        );
        let promise_joined = promise_and(promise1, promise2);
        let callback =
            promise_then(
                promise_joined,
                8,
                b"run_test".to_vec().as_ptr(),
                0,
                0 as (*const u8),
                write_u128(&0)
            );
        return_promise(callback);
    }
}

#[no_mangle]
pub fn answer_to_life() {
    return_i32(43);
}

#[no_mangle]
pub fn transfer_to_bob() {
    unsafe {
        let promise1 = promise_create(
            3,
            b"bob".to_vec().as_ptr(),
            5,
            b"deposit".to_vec().as_ptr(),
            0,
            0 as (*const u8),
            write_u128(&0),
        );
        return_promise(promise1);
    }
}

fn buf_to_u128(buf: [u8; 16]) -> u128 {
    unsafe { *(&buf as *const u8 as *const u128) }
}

pub fn get_frozen_balance() -> u128 {
    unsafe {
        let mut buf = [0u8; 16];
        frozen_balance(buf.as_mut_ptr());
        buf_to_u128(buf)
    }
}

#[no_mangle]
pub fn test_frozen_balance() {
    let my_frozen_balance = get_frozen_balance();
    return_u128(my_frozen_balance);
}

pub fn get_liquid_balance() -> u128 {
    unsafe {
        let mut buf = [0u8; 16];
        liquid_balance(buf.as_mut_ptr());
        buf_to_u128(buf)
    }
}

#[no_mangle]
pub fn test_liquid_balance() {
    let my_liquid_balance = get_liquid_balance();
    return_u128(my_liquid_balance);
}

#[no_mangle]
pub fn get_storage_usage() {
    unsafe {
        let su = storage_usage();
        return_u64(su as u64);
    }
}

#[no_mangle]
pub fn get_block_index() {
    unsafe {
        let bi = block_index();
        return_u64(bi);
    }
}

#[no_mangle]
pub fn assert_sum() {
    unsafe {
        let input = input_read();
        assert(input.len() == 12);
        let a = LittleEndian::read_i32(&input[..4]);
        let b = LittleEndian::read_i32(&input[4..8]);
        let sum = LittleEndian::read_i32(&input[8..]);
        assert(a + b == sum);
    }
}

#[no_mangle]
pub fn get_random_32() {
    unsafe { return_i32(random32() as i32) }
}

#[no_mangle]
pub fn get_random_buf() {
    unsafe {
        let input = input_read();
        assert(input.len() == 4);
        let len = LittleEndian::read_u32(&input[..4]);
        let mut buf = vec![0u8; len as usize];
        random_buf(len, buf.as_mut_ptr());
        return_value(buf.len(), buf.as_ptr())
    }
}

#[no_mangle]
pub fn hash_given_input() {
    unsafe {
        let input = input_read();
        let mut buf = [0u8; 32];
        hash(input.len(), input.as_ptr(), buf.as_mut_ptr());
        return_value(buf.len(), buf.as_ptr())
    }
}

#[no_mangle]
pub fn hash32_given_input() {
    unsafe {
        let input = input_read();
        return_i32(hash32(input.len(), input.as_ptr()) as i32)
    }
}

#[no_mangle]
pub fn check_ethash_naive() {
    unsafe {
        let header_hash = [0u8; 32];
        let mix_hash = [0u8; 32];
        let res = check_ethash(1, header_hash.as_ptr(), 32, 0, mix_hash.as_ptr(), 32, 1);
        return_i32(res as i32)
    }
}

#[panic_handler]
fn panic(_info: &PanicInfo) -> ! {
    loop {}
}

#[alloc_error_handler]
fn foo(_: core::alloc::Layout) -> ! {
    loop {}
}

'''
'''--- runtime/wasm/runtest/src/lib.rs ---
use std::collections::BTreeMap;

use near_primitives::types::{AccountId, Balance, PromiseId, ReceiptId};
use wasm::ext::{Error as ExtError, External, Result as ExtResult};

#[derive(Default)]
struct MyExt {
    storage: BTreeMap<Vec<u8>, Vec<u8>>,
    num_receipts: u32,
}

fn generate_promise_id(index: u32) -> ReceiptId {
    [index as u8; 32].to_vec()
}

impl External for MyExt {
    fn storage_set(&mut self, key: &[u8], value: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        println!("PUT '{:?}' -> '{:?}'", key, value);
        let evicted = self.storage.insert(Vec::from(key), Vec::from(value));
        if let Some(evicted) = evicted.as_ref() {
            println!("EVICTED '{:?}' -> '{:?}'", key, evicted);
        }
        Ok(evicted)
    }

    fn storage_get(&self, key: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        let value = self.storage.get(key);
        match value {
            Some(buf) => {
                println!("GET '{:?}' -> '{:?}'", key, buf);
                Ok(Some(buf.to_vec()))
            }
            None => {
                println!("GET '{:?}' -> EMPTY", key);
                Ok(None)
            }
        }
    }

    fn storage_remove(&mut self, key: &[u8]) -> ExtResult<Option<Vec<u8>>> {
        let removed = self.storage.remove(key);
        if let Some(removed) = removed.as_ref() {
            println!("REMOVE '{:?}' -> '{:?}'", key, removed);
        } else {
            println!("REMOVE '{:?}' -> EMPTY", key);
        }
        Ok(removed)
    }

    fn storage_iter(&mut self, _prefix: &[u8]) -> ExtResult<u32> {
        Err(ExtError::NotImplemented)
    }

    fn storage_range(&mut self, _start: &[u8], _end: &[u8]) -> ExtResult<u32> {
        Err(ExtError::NotImplemented)
    }

    fn storage_iter_next(&mut self, _iter: u32) -> ExtResult<Option<Vec<u8>>> {
        Err(ExtError::NotImplemented)
    }

    fn storage_iter_peek(&mut self, _iter: u32) -> ExtResult<Option<Vec<u8>>> {
        Err(ExtError::NotImplemented)
    }

    fn storage_iter_remove(&mut self, _iter: u32) {}

    fn promise_create(
        &mut self,
        account_id: AccountId,
        _method_name: Vec<u8>,
        _arguments: Vec<u8>,
        _amount: Balance,
    ) -> ExtResult<PromiseId> {
        match self.num_receipts {
            0 => assert_eq!(&account_id, &"test1".to_string()),
            1 => assert_eq!(&account_id, &"test2".to_string()),
            _ => (),
        };
        self.num_receipts += 1;
        Ok(PromiseId::Receipt(generate_promise_id(self.num_receipts - 1)))
    }

    fn promise_then(
        &mut self,
        promise_id: PromiseId,
        _method_name: Vec<u8>,
        _arguments: Vec<u8>,
        _amount: Balance,
    ) -> ExtResult<PromiseId> {
        match promise_id {
            PromiseId::Receipt(_) => Err(ExtError::WrongPromise),
            PromiseId::Joiner(v) => {
                assert_eq!(v[0], generate_promise_id(0));
                assert_eq!(v[1], generate_promise_id(1));
                Ok(PromiseId::Callback(b"call_it_please".to_vec()))
            }
            _ => Err(ExtError::WrongPromise),
        }
    }

    fn check_ethash(
        &mut self,
        _block_number: u64,
        _header_hash: &[u8],
        _nonce: u64,
        _mix_hash: &[u8],
        _difficulty: u64,
    ) -> bool {
        false
    }
}

#[cfg(test)]
mod tests {
    use std::fs;
    use std::path::PathBuf;

    use byteorder::{ByteOrder, LittleEndian};

    use near_primitives::hash::hash;
    use near_primitives::types::StorageUsage;
    use wasm::executor::{self, ExecutionOutcome};
    use wasm::types::{Config, ContractCode, Error, ReturnData, RuntimeContext, RuntimeError};

    use super::*;

    fn infinite_initializer_contract() -> Vec<u8> {
        wabt::wat2wasm(
            r#" (module
                       (type (;0;) (func))
                       (func (;0;) (type 0) (loop (br 0)))
                       (func (;1;) (type 0))
                       (start 0)
                       (export "hello" (func 1)))"#,
        )
        .unwrap()
    }

    fn run_wasm_binary(
        wasm_binary: Vec<u8>,
        method_name: &[u8],
        input_data: &[u8],
        result_data: &[Option<Vec<u8>>],
        context: &RuntimeContext,
    ) -> Result<ExecutionOutcome, Error> {
        let code = ContractCode::new(wasm_binary);

        let mut ext = MyExt::default();
        let config = Config::default();

        executor::execute(
            &code,
            &method_name,
            &input_data,
            &result_data,
            &mut ext,
            &config,
            &context,
        )
    }

    fn run_with_filename(
        method_name: &[u8],
        input_data: &[u8],
        result_data: &[Option<Vec<u8>>],
        context: &RuntimeContext,
        filename: &str,
    ) -> Result<ExecutionOutcome, Error> {
        let wasm_binary = fs::read(filename).expect("Unable to read file");
        run_wasm_binary(wasm_binary, method_name, input_data, result_data, context)
    }

    fn run(
        method_name: &[u8],
        input_data: &[u8],
        result_data: &[Option<Vec<u8>>],
        context: &RuntimeContext,
    ) -> Result<ExecutionOutcome, Error> {
        let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        path.push("res/wasm_with_mem.wasm");
        run_with_filename(method_name, input_data, result_data, context, path.to_str().unwrap())
    }

    fn encode_i32(val: i32) -> [u8; 4] {
        let mut tmp = [0u8; 4];
        LittleEndian::write_i32(&mut tmp, val);
        tmp
    }

    fn decode_i32(val: &[u8]) -> i32 {
        LittleEndian::read_i32(val)
    }

    fn decode_u64(val: &[u8]) -> u64 {
        LittleEndian::read_u64(val)
    }

    fn decode_u128(val: &[u8]) -> u128 {
        LittleEndian::read_u128(val)
    }

    fn runtime_context(
        balance: u128,
        amount: u128,
        storage_usage: StorageUsage,
    ) -> RuntimeContext {
        RuntimeContext::new(
            balance.into(),
            amount.into(),
            &"alice.near".to_string(),
            &"bob".to_string(),
            storage_usage,
            123,
            b"yolo".to_vec(),
            false,
        )
    }

    fn run_hello_wasm(method_name: &[u8], input_data: &[u8], amount: u128) -> ExecutionOutcome {
        let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        path.push("../../../tests/hello.wasm");
        run_with_filename(
            method_name,
            input_data,
            &[],
            &runtime_context(0, amount, 0),
            path.to_str().unwrap(),
        )
        .expect("ok")
    }

    #[test]
    fn test_storage() {
        let input_data = [0u8; 0];

        let return_data = run(b"run_test", &input_data, &[], &runtime_context(0, 1_000_000, 0))
            .map(|outcome| outcome.return_data)
            .expect("ok");

        match return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_i32(&output_data), 10),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_input() {
        let input_data = [10u8, 0, 0, 0, 30u8, 0, 0, 0];

        let return_data =
            run(b"sum_with_input", &input_data, &[], &runtime_context(0, 1_000_000_000, 0))
                .map(|outcome| outcome.return_data)
                .expect("ok");

        match return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_i32(&output_data), 40),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_result_ok() {
        let input_data = [0u8; 0];
        let result_data = vec![
            Some(encode_i32(2).to_vec()),
            Some(encode_i32(4).to_vec()),
            Some(encode_i32(6).to_vec()),
        ];

        let return_data = run(
            b"sum_with_multiple_results",
            &input_data,
            &result_data,
            &runtime_context(0, 1_000_000_000, 0),
        )
        .map(|outcome| outcome.return_data)
        .expect("ok");

        match return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_i32(&output_data), 12),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_promises() {
        let input_data = [0u8; 0];

        let outcome =
            run(b"create_promises_and_join", &input_data, &[], &runtime_context(0, 1_000_000, 0))
                .expect("ok");

        match outcome.return_data {
            Ok(ReturnData::Promise(promise_id)) => {
                assert_eq!(&promise_id, &PromiseId::Callback(b"call_it_please".to_vec()))
            }
            _ => assert!(false, "Expected returned promise"),
        };
    }

    #[test]
    fn test_assert_sum_ok() {
        let input_data = [10u8, 0, 0, 0, 30u8, 0, 0, 0, 40u8, 0, 0, 0];

        run(b"assert_sum", &input_data, &[], &runtime_context(0, 0, 0)).expect("ok");
    }

    #[test]
    fn test_assert_sum_fail() {
        let input_data = [10u8, 0, 0, 0, 30u8, 0, 0, 0, 45u8, 0, 0, 0];

        let outcome = run(b"assert_sum", &input_data, &[], &runtime_context(0, 0, 0))
            .expect("outcome to be ok");

        match outcome.return_data {
            Err(_) => assert!(true, "That's legit"),
            _ => assert!(false, "Expected to fail with assert failure"),
        };
    }

    #[test]
    fn test_frozen_balance() {
        let input_data = [0u8; 0];

        let outcome =
            run(b"test_frozen_balance", &input_data, &[], &runtime_context(10, 100, 0)).expect("ok");

        // The frozen balance is not used for the runtime deductions.
        println!("{:?}", outcome);
        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_u128(&output_data), 10),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_liquid_balance() {
        let input_data = [0u8; 0];

        let outcome =
            run(b"test_liquid_balance", &input_data, &[], &runtime_context(0, 100, 0)).expect("ok");
        // At the moment of measurement the liquid balance is at 97 which is the value returned.
        // However returning the value itself costs additional balance which results in final
        // liquid balance being 55.
        println!("{:?}", outcome);
        assert_eq!(outcome.liquid_balance, 55);
        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_u128(&output_data), 74),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_get_storage_usage() {
        let input_data = [0u8; 0];
        let outcome =
            run(b"get_storage_usage", &input_data, &[], &runtime_context(0, 100, 10)).expect("ok");

        // The storage usage is not changed by this function call.
        assert_eq!(outcome.storage_usage, 10);

        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_u64(&output_data), 10),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_storage_usage_changed() {
        let input_data = [0u8; 0];
        let outcome = run(
            b"run_test_with_storage_change",
            &input_data,
            &[],
            &runtime_context(0, 1_000_000_000, 10),
        )
        .expect("ok");

        // We inserted three entries 15 (as defined in the contract) + 4 (i32) bytes each.
        // Then we removed one entry, and replaced another with 15 + 8 (u64) bytes.
        // 52 = 10 (was before) + 15 + 4 + 15 + 8.
        assert_eq!(outcome.storage_usage, 52);
    }

    #[test]
    fn test_hello_name() {
        let input_data = b"{\"name\": \"Alice\"}";

        let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        path.push("../../../tests/hello.wasm");
        let outcome = run_with_filename(
            b"hello",
            input_data,
            &[],
            &runtime_context(0, 1_000_000_000, 0),
            path.to_str().unwrap(),
        )
        .expect("ok");

        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(&output_data, b"\"hello Alice\""),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_gas_error() {
        let outcome = run_hello_wasm(b"hello", b"{\"name\": \"Alice\"}", 0);
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Runtime(RuntimeError::BalanceExceeded)) => {}
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    fn test_stack_overflow() {
        let outcome = run_hello_wasm(b"recurse", b"{\"n\": 100000}", 1_000_000);
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Wasmer(msg)) => {
                assert_eq!(msg, "WebAssembly trap occured during runtime: unknown")
            }
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    fn test_invalid_argument_type() {
        let outcome = run_hello_wasm(b"hello", b"{\"name\": 1}", 1_000_000);
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Runtime(RuntimeError::AssertFailed)) => {}
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    fn test_invalid_argument_none_string() {
        let outcome = run_hello_wasm(b"hello", b"{}", 1_000_000);
        println!("{:?}", outcome);
        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(&output_data, b"\"hello null\""),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_invalid_argument_none_int() {
        let outcome = run_hello_wasm(b"recurse", b"{}", 1_000_000);
        println!("{:?}", outcome);
        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(&output_data, b"0"),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_invalid_argument_extra() {
        let outcome =
            run_hello_wasm(b"hello", b"{\"name\": \"Alice\", \"name2\": \"Bob\"}", 1_000_000);
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Runtime(RuntimeError::AssertFailed)) => {}
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    fn test_trigger_assert() {
        let outcome = run_hello_wasm(b"triggerAssert", b"{}", 1_000_000);
        println!("{:?}", outcome);
        let ExecutionOutcome { return_data, logs, .. } = outcome;
        match return_data {
            Err(Error::Runtime(RuntimeError::AssertFailed)) => {}
            _ => panic!("unexpected outcome"),
        }
        assert_eq!(logs.len(), 2);
        assert_eq!(logs[0], "LOG: log before assert");
        assert!(logs[1].starts_with("ABORT: \"expected to fail\" filename:"));
    }

    #[test]
    fn test_storage_usage() {
        let input_data = b"{\"max_storage\":\"1024\"}";

        let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        path.push("../../../tests/hello.wasm");
        let outcome = run_with_filename(
            b"limited_storage",
            input_data,
            &[],
            &runtime_context(0, 1_000_000_000, 0),
            path.to_str().unwrap(),
        )
        .expect("ok");

        println!("{:?}", outcome.storage_usage);
        println!("{:?}", outcome.logs);

        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => {
                // 1024 bytes is 207 elements.
                assert_eq!(&output_data, b"\"207\"")
            }
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_originator() {
        let input_data = [0u8; 0];

        let return_data =
            run(b"get_originator_id", &input_data, &[], &runtime_context(0, 1_000_000_000, 0))
                .map(|outcome| outcome.return_data)
                .expect("ok");

        match return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(&output_data, b"alice.near"),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_random_32() {
        let input_data = [0u8; 0];

        let mut output_data = Vec::new();

        for _ in 0..2 {
            let return_data = run(b"get_random_32", &input_data, &[], &runtime_context(0, 100, 0))
                .map(|outcome| outcome.return_data)
                .expect("ok");

            output_data.push(match return_data {
                Ok(ReturnData::Value(output_data)) => output_data,
                _ => panic!("Expected returned value"),
            });
        }

        assert_ne!(&output_data[0], &encode_i32(0));
        assert_eq!(&output_data[0], &output_data[1]);
    }

    #[test]
    fn test_random_buf() {
        let input_data = [80u8, 0, 0, 0];

        let mut output_data = Vec::new();

        for _ in 0..2 {
            let return_data =
                run(b"get_random_buf", &input_data, &[], &runtime_context(0, 1_000_000_000, 0))
                    .map(|outcome| outcome.return_data)
                    .expect("ok");

            let data = match return_data {
                Ok(ReturnData::Value(output_data)) => output_data,
                _ => panic!("Expected returned value"),
            };
            assert_eq!(data.len(), 80);

            output_data.push(data);
        }

        assert_ne!(&output_data[0][..4], &encode_i32(0));
        assert_eq!(&output_data[0], &output_data[1]);
    }

    #[test]
    fn test_hash() {
        let input_data = b"testing_hashing_this_slice";

        let return_data =
            run(b"hash_given_input", input_data, &[], &runtime_context(0, 1_000_000_000, 0))
                .map(|outcome| outcome.return_data)
                .expect("ok");

        let output_data = match return_data {
            Ok(ReturnData::Value(output_data)) => output_data,
            _ => panic!("Expected returned value"),
        };

        let expected_result: Vec<u8> = hash(input_data).into();

        assert_eq!(&output_data, &expected_result);
    }

    #[test]
    fn test_hash32() {
        let input_data = b"testing_hashing_this_slice";

        let return_data =
            run(b"hash32_given_input", input_data, &[], &runtime_context(0, 1_000_000_000, 0))
                .map(|outcome| outcome.return_data)
                .expect("ok");

        let output_data = match return_data {
            Ok(ReturnData::Value(output_data)) => output_data,
            _ => panic!("Expected returned value"),
        };

        let input_data_hash: Vec<u8> = hash(input_data).into();
        let mut expected_result = input_data_hash[..4].to_vec();
        expected_result.reverse();

        assert_eq!(&output_data, &expected_result);
    }

    #[test]
    fn test_get_block_index() {
        let input_data = [0u8; 0];

        let outcome =
            run(b"get_block_index", &input_data, &[], &runtime_context(0, 100, 0)).expect("ok");

        match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => assert_eq!(decode_u64(&output_data), 123),
            _ => assert!(false, "Expected returned value"),
        };
    }

    #[test]
    fn test_debug() {
        let input_data = [0u8; 0];

        let outcome =
            run(b"log_something", &input_data, &[], &runtime_context(0, 100, 0)).expect("ok");

        assert_eq!(outcome.logs, vec!["LOG: hello".to_string(),]);
    }

    #[test]
    fn test_mock_check_ethash() {
        let input_data = [0u8; 0];
        let outcome =
            run(b"check_ethash_naive", &input_data, &[], &runtime_context(0, 100, 0)).expect("ok");
        println!("{:?}", outcome);

        let output_data = match outcome.return_data {
            Ok(ReturnData::Value(output_data)) => output_data,
            _ => panic!("Expected returned value"),
        };
        assert_eq!(output_data, encode_i32(0));
    }

    #[test]
    fn test_export_not_found() {
        let outcome = run(b"hello", &[], &[], &runtime_context(0, 1_000_000, 0)).expect("expect");
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Wasmer(msg)) => {
                assert_eq!(msg, "call error: Call error: Export not found: hello");
            }
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    fn test_infinite_initializer() {
        let outcome = run_wasm_binary(
            infinite_initializer_contract(),
            b"hello",
            &[],
            &[],
            &runtime_context(0, 1_000_000, 0),
        )
        .expect("expect");
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Runtime(RuntimeError::BalanceExceeded)) => {}
            _ => panic!("unexpected outcome"),
        }
    }

    #[test]
    // Current behavior is to run the initializer even if the method doesn't exist
    fn test_infinite_initializer_export_not_found() {
        let outcome = run_wasm_binary(
            infinite_initializer_contract(),
            b"hello2",
            &[],
            &[],
            &runtime_context(0, 1_000_000, 0),
        )
        .expect("expect");
        println!("{:?}", outcome);
        match outcome.return_data {
            Err(Error::Runtime(RuntimeError::BalanceExceeded)) => {}
            _ => panic!("unexpected outcome"),
        }
    }
}

'''
'''--- runtime/wasm/src/cache.rs ---
use std::sync::Arc;

use cached::SizedCache;
use wasmer_runtime;

use near_primitives::hash::{hash, CryptoHash};
use near_primitives::serialize::Encode;

use crate::prepare;
use crate::types::{Config, ContractCode, Error};

/// Cache size in number of cached modules to hold.
const CACHE_SIZE: usize = 1024;
// TODO: store a larger on-disk cache

cached_key! {
    CODE: SizedCache<CryptoHash, Result<Arc<ContractCode>, String>> = SizedCache::with_size(CACHE_SIZE);
    Key = {
        code_hash
    };

    fn get_code_with_cache(code_hash: CryptoHash, f: impl FnOnce() -> Result<ContractCode, String>) -> Result<Arc<ContractCode>, String> = {
        let code = f()?;
        assert_eq!(code_hash, code.get_hash());
        Ok(Arc::new(code))
    }
}

cached_key! {
    MODULES: SizedCache<(CryptoHash, CryptoHash), Result<wasmer_runtime::Module, Error>> = SizedCache::with_size(CACHE_SIZE);
    Key = {
        (code.get_hash(), hash(&config.encode().expect("encoding of config shouldn't fail")))
    };

    fn compile_cached_module(code: &ContractCode, config: &Config) -> Result<wasmer_runtime::Module, Error> = {
        let prepared_code = prepare::prepare_contract(code, config).map_err(Error::Prepare)?;

        wasmer_runtime::compile(&prepared_code)
            .map_err(|e| Error::Wasmer(format!("{}", e)))
    }
}

'''
'''--- runtime/wasm/src/executor.rs ---
use std::ffi::c_void;
use std::fmt;

use wasmer_runtime::{self, memory::Memory, units::Pages, wasm::MemoryDescriptor};

use near_primitives::logging;
use near_primitives::types::{Balance, StorageUsage, StorageUsageChange};

use crate::cache;
use crate::ext::External;
use crate::runtime::{self, Runtime};
use crate::types::{Config, ContractCode, Error, ReturnData, RuntimeContext};

pub struct ExecutionOutcome {
    pub frozen_balance: Balance,
    pub liquid_balance: Balance,
    pub storage_usage: StorageUsage,
    pub return_data: Result<ReturnData, Error>,
    pub random_seed: Vec<u8>,
    pub logs: Vec<String>,
}

impl fmt::Debug for ExecutionOutcome {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        f.debug_struct("ExecutionOutcome")
            .field("return_data", &self.return_data)
            .field("frozen_balance", &format_args!("{}", &self.frozen_balance))
            .field("liquid_balance", &format_args!("{}", &self.liquid_balance))
            .field("random_seed", &format_args!("{}", logging::pretty_utf8(&self.random_seed)))
            .field("logs", &format_args!("{}", logging::pretty_vec(&self.logs)))
            .finish()
    }
}

pub fn execute(
    code: &ContractCode,
    method_name: &[u8],
    input_data: &[u8],
    result_data: &[Option<Vec<u8>>],
    ext: &mut dyn External,
    config: &Config,
    context: &RuntimeContext,
) -> Result<ExecutionOutcome, Error> {
    if method_name.is_empty() {
        return Err(Error::EmptyMethodName);
    }

    let module = cache::compile_cached_module(code, config)?;

    debug!(target:"runtime", "Executing method {:?}", String::from_utf8(method_name.to_vec()).unwrap_or_else(|_| hex::encode(method_name)));

    let memory = Memory::new(MemoryDescriptor {
        minimum: Pages(config.initial_memory_pages),
        maximum: Some(Pages(config.max_memory_pages)),
        shared: false,
    })
    .map_err(Into::<wasmer_runtime::error::Error>::into)?;

    let mut runtime =
        Runtime::new(ext, input_data, result_data, context, config.clone(), memory.clone());

    let raw_ptr = &mut runtime as *mut _ as *mut c_void;
    let import_object = runtime::imports::build(memory, raw_ptr);

    let method_name = std::str::from_utf8(method_name).map_err(|_| Error::BadUtf8)?;

    match module
        .instantiate(&import_object)
        .and_then(|instance| instance.call(&method_name, &[]).map_err(|e| e.into()))
    {
        Ok(_) => {
            let e = ExecutionOutcome {
                storage_usage: (context.storage_usage as StorageUsageChange
                    + runtime.storage_counter) as StorageUsage,
                return_data: Ok(runtime.return_data),
                frozen_balance: runtime.frozen_balance,
                liquid_balance: runtime.liquid_balance,
                random_seed: runtime.random_seed,
                logs: runtime.logs,
            };
            debug!(target:"runtime", "{:?}", e);
            Ok(e)
        }
        Err(e) => {
            let e = ExecutionOutcome {
                storage_usage: context.storage_usage,
                return_data: Err(Into::<wasmer_runtime::error::Error>::into(e).into()),
                frozen_balance: runtime.frozen_balance,
                liquid_balance: runtime.liquid_balance,
                random_seed: runtime.random_seed,
                logs: runtime.logs,
            };
            debug!(target:"runtime", "{:?}", e);
            Ok(e)
        }
    }
}

'''
'''--- runtime/wasm/src/ext.rs ---
use near_primitives::types::{AccountId, Balance, PromiseId};

#[derive(Debug, Clone, PartialEq)]
pub enum Error {
    NotImplemented,
    PromiseIdNotFound,
    WrongPromise,
    PromiseAlreadyHasCallback,
    TrieIteratorError,
    TrieIteratorMissing,
}

pub type Result<T> = ::std::result::Result<T, Error>;

pub trait External {
    fn storage_set(&mut self, key: &[u8], value: &[u8]) -> Result<Option<Vec<u8>>>;

    fn storage_get(&self, key: &[u8]) -> Result<Option<Vec<u8>>>;

    fn storage_remove(&mut self, key: &[u8]) -> Result<Option<Vec<u8>>>;

    fn storage_iter(&mut self, prefix: &[u8]) -> Result<u32>;

    fn storage_range(&mut self, start: &[u8], end: &[u8]) -> Result<u32>;

    fn storage_iter_next(&mut self, id: u32) -> Result<Option<Vec<u8>>>;

    fn storage_iter_peek(&mut self, id: u32) -> Result<Option<Vec<u8>>>;

    fn storage_iter_remove(&mut self, id: u32);

    fn promise_create(
        &mut self,
        account_id: AccountId,
        method_name: Vec<u8>,
        arguments: Vec<u8>,
        amount: Balance,
    ) -> Result<PromiseId>;

    fn promise_then(
        &mut self,
        promise_id: PromiseId,
        method_name: Vec<u8>,
        arguments: Vec<u8>,
        amount: Balance,
    ) -> Result<PromiseId>;

    fn check_ethash(
        &mut self,
        block_number: u64,
        header_hash: &[u8],
        nonce: u64,
        mix_hash: &[u8],
        difficulty: u64,
    ) -> bool;
}

'''
'''--- runtime/wasm/src/lib.rs ---
#[cfg(test)]
#[macro_use]
extern crate assert_matches;
#[macro_use]
extern crate cached;
#[macro_use]
extern crate log;
#[macro_use]
extern crate serde_derive;
#[cfg(test)]
extern crate wabt;

pub mod cache;
pub mod executor;
pub mod ext;
pub mod prepare;
mod runtime;
pub mod types;

'''
'''--- runtime/wasm/src/prepare.rs ---
//! Module that takes care of loading, checking and preprocessing of a
//! wasm module before execution.

use crate::types::{Config, ContractCode, PrepareError as Error};
use parity_wasm::builder;
use parity_wasm::elements::{self, External, MemorySection, MemoryType, Type};
use pwasm_utils::{self, rules};

struct ContractModule<'a> {
    // An `Option` is used here for loaning (`take()`-ing) the module.
    // Invariant: Can't be `None` (i.e. on enter and on exit from the function
    // the value *must* be `Some`).
    module: Option<elements::Module>,
    config: &'a Config,
}

impl<'a> ContractModule<'a> {
    fn init(original_code: &[u8], config: &'a Config) -> Result<ContractModule<'a>, Error> {
        let module =
            elements::deserialize_buffer(original_code).map_err(|_| Error::Deserialization)?;
        Ok(ContractModule { module: Some(module), config })
    }

    fn standardize_mem(&mut self) {
        let mut module =
            self.module.take().expect("On entry to the function `module` can't be `None`; qed");

        let mut tmp = MemorySection::default();

        module.memory_section_mut().unwrap_or_else(|| &mut tmp).entries_mut().pop();

        let entry = elements::MemoryType::new(
            self.config.initial_memory_pages,
            Some(self.config.max_memory_pages),
        );

        let mut builder = builder::from_module(module);
        builder.push_import(elements::ImportEntry::new(
            "env".to_string(),
            "memory".to_string(),
            elements::External::Memory(entry),
        ));

        self.module = Some(builder.build());
    }

    /// Ensures that module doesn't declare internal memories.
    ///
    /// In this runtime we only allow wasm module to import memory from the environment.
    /// Memory section contains declarations of internal linear memories, so if we find one
    /// we reject such a module.
    fn ensure_no_internal_memory(&self) -> Result<(), Error> {
        let module =
            self.module.as_ref().expect("On entry to the function `module` can't be None; qed");
        if module.memory_section().map_or(false, |ms| !ms.entries().is_empty()) {
            return Err(Error::InternalMemoryDeclared);
        }
        Ok(())
    }

    fn inject_gas_metering(&mut self) -> Result<(), Error> {
        // TODO(#194): Re-enable .with_forbidden_floats() once AssemblyScript is fixed.
        let gas_rules = rules::Set::new(self.config.regular_op_cost, Default::default())
            .with_grow_cost(self.config.grow_mem_cost);

        let module =
            self.module.take().expect("On entry to the function `module` can't be `None`; qed");

        let contract_module = pwasm_utils::inject_gas_counter(module, &gas_rules)
            .map_err(|_| Error::GasInstrumentation)?;

        self.module = Some(contract_module);
        Ok(())
    }

    fn inject_stack_height_metering(&mut self) -> Result<(), Error> {
        let module =
            self.module.take().expect("On entry to the function `module` can't be `None`; qed");

        let contract_module =
            pwasm_utils::stack_height::inject_limiter(module, self.config.max_stack_height)
                .map_err(|_| Error::StackHeightInstrumentation)?;

        self.module = Some(contract_module);
        Ok(())
    }

    /// Scan an import section if any.
    ///
    /// This accomplishes two tasks:
    ///
    /// - checks any imported function against defined host functions set, incl.
    ///   their signatures.
    /// - if there is a memory import, returns it's descriptor
    fn scan_imports(&self) -> Result<Option<&MemoryType>, Error> {
        let module =
            self.module.as_ref().expect("On entry to the function `module` can't be `None`; qed");

        let types = module.type_section().map(elements::TypeSection::types).unwrap_or(&[]);
        let import_entries =
            module.import_section().map(elements::ImportSection::entries).unwrap_or(&[]);

        let mut imported_mem_type = None;

        for import in import_entries {
            if import.module() != "env" {
                // This import tries to import something from non-"env" module,
                // but all imports are located in "env" at the moment.
                return Err(Error::Instantiate);
            }

            let type_idx = match *import.external() {
                External::Function(ref type_idx) => type_idx,
                External::Memory(ref memory_type) => {
                    imported_mem_type = Some(memory_type);
                    continue;
                }
                _ => continue,
            };

            let Type::Function(ref _func_ty) =
                types.get(*type_idx as usize).ok_or_else(|| Error::Instantiate)?;

            // TODO: Function type check with Env
            /*

            let ext_func = env
                .funcs
                .get(import.field().as_bytes())
                .ok_or_else(|| Error::Instantiate)?;
            if !ext_func.func_type_matches(func_ty) {
                return Err(Error::Instantiate);
            }
            */
        }
        Ok(imported_mem_type)
    }

    fn into_wasm_code(mut self) -> Result<Vec<u8>, Error> {
        elements::serialize(
            self.module.take().expect("On entry to the function `module` can't be `None`; qed"),
        )
        .map_err(|_| Error::Serialization)
    }
}

/// Loads the given module given in `original_code`, performs some checks on it and
/// does some preprocessing.
///
/// The checks are:
///
/// - module doesn't define an internal memory instance,
/// - imported memory (if any) doesn't reserve more memory than permitted by the `config`,
/// - all imported functions from the external environment matches defined by `env` module,
///
/// The preprocessing includes injecting code for gas metering and metering the height of stack.
pub fn prepare_contract(original_code: &ContractCode, config: &Config) -> Result<Vec<u8>, Error> {
    let mut contract_module = ContractModule::init(original_code.get_code(), config)?;
    contract_module.standardize_mem();
    contract_module.ensure_no_internal_memory()?;
    contract_module.inject_gas_metering()?;
    contract_module.inject_stack_height_metering()?;

    if let Some(memory_type) = contract_module.scan_imports()? {
        // Inspect the module to extract the initial and maximum page count.
        let limits = memory_type.limits();
        if limits.initial() != config.initial_memory_pages
            || limits.maximum() != Some(config.max_memory_pages)
        {
            return Err(Error::Memory);
        }
    } else {
        return Err(Error::Memory);
    };

    contract_module.into_wasm_code()
}

#[cfg(test)]
mod tests {
    use super::*;
    use wabt;

    fn parse_and_prepare_wat(wat: &str) -> Result<Vec<u8>, Error> {
        let wasm = wabt::Wat2Wasm::new().validate(false).convert(wat).unwrap();
        let config = Config::default();
        let code = ContractCode::new(wasm.as_ref().to_vec());
        prepare_contract(&code, &config)
    }

    #[test]
    fn internal_memory_declaration() {
        let r = parse_and_prepare_wat(r#"(module (memory 1 1))"#);
        assert_matches!(r, Ok(_));
    }

    #[test]
    fn memory() {
        // This test assumes that maximum page number is configured to a certain number.
        assert_eq!(Config::default().max_memory_pages, 32);

        let r = parse_and_prepare_wat(r#"(module (import "env" "memory" (memory 1 1)))"#);
        assert_matches!(r, Ok(_));

        // No memory import
        let r = parse_and_prepare_wat(r#"(module)"#);
        assert_matches!(r, Ok(_));

        // initial exceed maximum
        let r = parse_and_prepare_wat(r#"(module (import "env" "memory" (memory 17 1)))"#);
        assert_matches!(r, Ok(_));

        // no maximum
        let r = parse_and_prepare_wat(r#"(module (import "env" "memory" (memory 1)))"#);
        assert_matches!(r, Ok(_));

        // requested maximum exceed configured maximum
        let r = parse_and_prepare_wat(r#"(module (import "env" "memory" (memory 1 33)))"#);
        assert_matches!(r, Ok(_));
    }

    #[test]
    fn imports() {
        // nothing can be imported from non-"env" module for now.
        let r =
            parse_and_prepare_wat(r#"(module (import "another_module" "memory" (memory 1 1)))"#);
        assert_matches!(r, Err(Error::Instantiate));

        let r = parse_and_prepare_wat(r#"(module (import "env" "gas" (func (param i32))))"#);
        assert_matches!(r, Ok(_));

        // TODO: Address tests once we check proper function signatures.
        /*
        // wrong signature
        let r = parse_and_prepare_wat(r#"(module (import "env" "gas" (func (param i64))))"#);
        assert_matches!(r, Err(Error::Instantiate));

        // unknown function name
        let r = parse_and_prepare_wat(r#"(module (import "env" "unknown_func" (func)))"#);
        assert_matches!(r, Err(Error::Instantiate));
        */
    }
}

'''
'''--- runtime/wasm/src/runtime.rs ---
use std::collections::HashSet;

use byteorder::{ByteOrder, LittleEndian};
use wasmer_runtime::{memory::Memory, units::Bytes};

use near_primitives::hash::hash;
use near_primitives::logging::pretty_utf8;
use near_primitives::types::{
    AccountId, Balance, PromiseId, ReceiptId, StorageUsage, StorageUsageChange,
};
use near_primitives::utils::is_valid_account_id;

use crate::ext::External;
use crate::types::{Config, ReturnData, RuntimeContext, RuntimeError as Error};

type Result<T> = ::std::result::Result<T, Error>;

type DataTypeIndex = u32;

pub const DATA_TYPE_ORIGINATOR_ACCOUNT_ID: DataTypeIndex = 1;
pub const DATA_TYPE_CURRENT_ACCOUNT_ID: DataTypeIndex = 2;
pub const DATA_TYPE_STORAGE: DataTypeIndex = 3;
pub const DATA_TYPE_INPUT: DataTypeIndex = 4;
pub const DATA_TYPE_RESULT: DataTypeIndex = 5;
pub const DATA_TYPE_STORAGE_ITER: DataTypeIndex = 6;

/// Converts u128 into array of bytes.
#[inline]
fn to_uint128<'a>(value: u128) -> &'a [u8] {
    unsafe { std::slice::from_raw_parts(&value as *const u128 as *const u8, 16) }
}

pub struct Runtime<'a> {
    ext: &'a mut dyn External,
    input_data: &'a [u8],
    result_data: &'a [Option<Vec<u8>>],
    pub frozen_balance: Balance,
    pub liquid_balance: Balance,
    /// Keep track of how much of the liquid balance is used by the contract so far,
    /// without deposits/withdrawals and resending of the balance to other contracts.
    usage_counter: Balance,
    context: &'a RuntimeContext,
    config: Config,
    pub storage_counter: StorageUsageChange,
    promise_ids: Vec<PromiseId>,
    pub return_data: ReturnData,
    pub random_seed: Vec<u8>,
    random_buffer_offset: usize,
    pub logs: Vec<String>,
    memory: Memory,
}

impl<'a> Runtime<'a> {
    pub fn new(
        ext: &'a mut dyn External,
        input_data: &'a [u8],
        result_data: &'a [Option<Vec<u8>>],
        context: &'a RuntimeContext,
        config: Config,
        memory: Memory,
    ) -> Runtime<'a> {
        Runtime {
            ext,
            input_data,
            result_data,
            frozen_balance: context.initial_balance,
            liquid_balance: context.received_amount,
            usage_counter: 0,
            context,
            config,
            storage_counter: 0,
            promise_ids: Vec::new(),
            return_data: ReturnData::None,
            random_seed: hash(&context.random_seed).into(),
            random_buffer_offset: 0,
            logs: Vec::new(),
            memory,
        }
    }

    fn memory_can_fit(&self, offset: usize, len: usize) -> bool {
        match offset.checked_add(len) {
            None => false,
            Some(end) => self.memory.size().bytes() >= Bytes(end),
        }
    }

    fn memory_get(&self, offset: usize, len: usize) -> Result<Vec<u8>> {
        if !self.memory_can_fit(offset, len) {
            Err(Error::MemoryAccessViolation)
        } else if len == 0 {
            Ok(Vec::new())
        } else {
            Ok(self.memory.view()[offset..(offset + len)]
                .iter()
                .map(std::cell::Cell::get)
                .collect())
        }
    }

    fn memory_set(&mut self, offset: usize, buf: &[u8]) -> Result<()> {
        if !self.memory_can_fit(offset, buf.len()) {
            Err(Error::MemoryAccessViolation)
        } else if buf.is_empty() {
            Ok(())
        } else {
            self.memory.view()[offset..(offset + buf.len())]
                .iter()
                .zip(buf.iter())
                .for_each(|(cell, v)| cell.set(*v));
            Ok(())
        }
    }

    fn memory_get_u32(&self, offset: usize) -> Result<u32> {
        let buf = self.memory_get(offset, 4)?;
        Ok(LittleEndian::read_u32(&buf))
    }

    fn memory_get_u128(&self, offset: usize) -> Result<u128> {
        let buf = self.memory_get(offset, 16)?;
        Ok(LittleEndian::read_u128(&buf))
    }

    fn random_u8(&mut self) -> u8 {
        if self.random_buffer_offset >= self.random_seed.len() {
            self.random_seed = hash(&self.random_seed).into();
            self.random_buffer_offset = 0;
        }
        self.random_buffer_offset += 1;
        self.random_seed[self.random_buffer_offset - 1]
    }

    /// Reads AssemblyScript string from utf-16
    fn read_string(&self, offset: usize) -> Result<String> {
        let len: u32 = self.memory_get_u32(offset)?;
        let buffer = self.memory_get(offset + 4, (len * 2) as usize)?;
        let mut u16_buffer = Vec::new();
        for i in 0..(len as usize) {
            let c = u16::from(buffer[i * 2]) + u16::from(buffer[i * 2 + 1]) * 0x100;
            u16_buffer.push(c);
        }
        String::from_utf16(&u16_buffer).map_err(|_| Error::BadUtf16)
    }

    fn promise_index_to_id(&self, promise_index: u32) -> Result<PromiseId> {
        Ok(self.promise_ids.get(promise_index as usize).ok_or(Error::InvalidPromiseIndex)?.clone())
    }

    fn read_and_parse_account_id(&self, ptr: u32, len: u32) -> Result<AccountId> {
        let buf = self.memory_get(ptr as usize, len as usize)?;
        let account_id = AccountId::from_utf8(buf).map_err(|_| Error::BadUtf8)?;
        if !is_valid_account_id(&account_id) {
            return Err(Error::InvalidAccountId);
        }
        Ok(account_id)
    }

    /// Attempt to charge liquid balance.
    fn charge_balance(&mut self, amount: Balance) -> Result<()> {
        if self.liquid_balance < amount {
            if self.context.free_of_charge {
                Ok(())
            } else {
                Err(Error::BalanceExceeded)
            }
        } else {
            self.liquid_balance -= amount;
            Ok(())
        }
    }

    /// Attempt to charge liquid balance, respecting usage limit.
    fn charge_balance_with_limit(&mut self, amount: Balance) -> Result<()> {
        let new_usage = self.usage_counter + amount;
        if new_usage > self.config.usage_limit as u128 {
            if self.context.free_of_charge {
                Ok(())
            } else {
                Err(Error::UsageLimit)
            }
        } else {
            self.charge_balance(amount).map(|res| {
                self.usage_counter = new_usage;
                res
            })
        }
    }

    /// Called by WASM.
    fn gas(&mut self, gas_amount: u32) -> Result<()> {
        let res = self.charge_balance_with_limit(Balance::from(gas_amount));
        res
    }

    /// Writes to storage from wasm memory
    fn storage_write(
        &mut self,
        key_len: u32,
        key_ptr: u32,
        value_len: u32,
        value_ptr: u32,
    ) -> Result<()> {
        let key = self.memory_get(key_ptr as usize, key_len as usize)?;
        let value = self.memory_get(value_ptr as usize, value_len as usize)?;

        let evicted = self.ext.storage_set(&key, &value).map_err(|_| Error::StorageUpdateError)?;
        if let Some(evicted) = evicted {
            self.storage_counter +=
                value_len as StorageUsageChange - evicted.len() as StorageUsageChange;
        } else {
            self.storage_counter += key_len as StorageUsageChange + value_len as StorageUsageChange;
        }
        debug!(target: "wasm", "storage_write('{}', '{}')", pretty_utf8(&key), pretty_utf8(&value));
        Ok(())
    }

    /// Remove key from storage
    fn storage_remove(&mut self, key_len: u32, key_ptr: u32) -> Result<()> {
        let key = self.memory_get(key_ptr as usize, key_len as usize)?;
        let removed = self.ext.storage_remove(&key).map_err(|_| Error::StorageRemoveError)?;
        if let Some(removed) = removed {
            self.storage_counter -=
                key_len as StorageUsageChange + removed.len() as StorageUsageChange;
        }
        debug!(target: "wasm", "storage_remove('{}')", pretty_utf8(&key));
        Ok(())
    }

    /// Returns whether the key is present in the storage
    fn storage_has_key(&mut self, key_len: u32, key_ptr: u32) -> Result<u32> {
        let key = self.memory_get(key_ptr as usize, key_len as usize)?;
        // TODO(#743): Improve performance of has_key. Don't need to retrive the value.
        let val = self.ext.storage_get(&key).map_err(|_| Error::StorageReadError)?;
        let res = val.is_some();
        debug!(target: "wasm", "storage_has_key('{}') -> {}", pretty_utf8(&key), res);
        Ok(res as u32)
    }

    /// Gets iterator for keys with given prefix
    fn storage_iter(&mut self, prefix_len: u32, prefix_ptr: u32) -> Result<u32> {
        let prefix = self.memory_get(prefix_ptr as usize, prefix_len as usize)?;
        let storage_id = self.ext.storage_iter(&prefix).map_err(|_| Error::StorageReadError)?;
        debug!(target: "wasm", "storage_iter('{}') -> {}", pretty_utf8(&prefix), storage_id);
        Ok(storage_id)
    }

    /// Gets iterator for the range of keys between given start and end keys
    fn storage_range(
        &mut self,
        start_len: u32,
        start_ptr: u32,
        end_len: u32,
        end_ptr: u32,
    ) -> Result<u32> {
        let start_key = self.memory_get(start_ptr as usize, start_len as usize)?;
        let end_key = self.memory_get(end_ptr as usize, end_len as usize)?;
        let storage_id =
            self.ext.storage_range(&start_key, &end_key).map_err(|_| Error::StorageReadError)?;
        debug!(target: "wasm", "storage_range('{}', '{}') -> {}",
            pretty_utf8(&start_key),
            pretty_utf8(&end_key),
            storage_id);
        Ok(storage_id)
    }

    /// Advances iterator. Returns true if iteration isn't finished yet.
    fn storage_iter_next(&mut self, storage_id: u32) -> Result<u32> {
        let key = self.ext.storage_iter_next(storage_id).map_err(|_| Error::StorageUpdateError)?;
        debug!(target: "wasm", "storage_iter_next({}) -> '{}'", storage_id, pretty_utf8(&key.clone().unwrap_or_default()));
        Ok(key.is_some() as u32)
    }

    fn promise_create(
        &mut self,
        account_id_len: u32,
        account_id_ptr: u32,
        method_name_len: u32,
        method_name_ptr: u32,
        arguments_len: u32,
        arguments_ptr: u32,
        amount_ptr: u32,
    ) -> Result<u32> {
        let amount = self.memory_get_u128(amount_ptr as usize)?;
        let account_id = self.read_and_parse_account_id(account_id_ptr, account_id_len)?;
        let method_name = self.memory_get(method_name_ptr as usize, method_name_len as usize)?;

        if let Some(b'_') = method_name.get(0) {
            return Err(Error::PrivateMethod);
        }

        let arguments = self.memory_get(arguments_ptr as usize, arguments_len as usize)?;
        self.charge_balance(self.config.contract_call_cost + amount)?;

        let promise_id = self
            .ext
            .promise_create(account_id, method_name, arguments, amount)
            .map_err(|_| Error::PromiseError)?;

        let promise_index = self.promise_ids.len();
        self.promise_ids.push(promise_id);

        Ok(promise_index as u32)
    }

    fn promise_then(
        &mut self,
        promise_index: u32,
        method_name_len: u32,
        method_name_ptr: u32,
        arguments_len: u32,
        arguments_ptr: u32,
        amount_ptr: u32,
    ) -> Result<u32> {
        let amount = self.memory_get_u128(amount_ptr as usize)?;
        let promise_id = self.promise_index_to_id(promise_index)?;
        let method_name = self.memory_get(method_name_ptr as usize, method_name_len as usize)?;
        if method_name.is_empty() {
            return Err(Error::EmptyMethodName);
        }
        let arguments = self.memory_get(arguments_ptr as usize, arguments_len as usize)?;

        let num_promises = match &promise_id {
            PromiseId::Receipt(_) => 1,
            PromiseId::Callback(_) => return Err(Error::PromiseError),
            PromiseId::Joiner(v) => v.len() as u64,
        } as u128;
        self.charge_balance((num_promises * self.config.contract_call_cost + amount).into())?;

        let promise_id = self
            .ext
            .promise_then(promise_id, method_name, arguments, amount.into())
            .map_err(|_| Error::PromiseError)?;

        let promise_index = self.promise_ids.len();
        self.promise_ids.push(promise_id);

        Ok(promise_index as u32)
    }

    fn promise_and(&mut self, promise_index1: u32, promise_index2: u32) -> Result<u32> {
        let promise_ids =
            [self.promise_index_to_id(promise_index1)?, self.promise_index_to_id(promise_index2)?];

        let mut receipt_ids = vec![];
        let mut unique_receipt_ids = HashSet::new();
        {
            let mut add_receipt_id = |receipt_id: ReceiptId| -> Result<()> {
                if !unique_receipt_ids.insert(receipt_id.clone()) {
                    return Err(Error::PromiseError);
                }
                receipt_ids.push(receipt_id);
                Ok(())
            };

            for promise_id in promise_ids.iter() {
                match promise_id {
                    PromiseId::Receipt(receipt_id) => add_receipt_id(receipt_id.clone())?,
                    PromiseId::Callback(_) => return Err(Error::PromiseError),
                    PromiseId::Joiner(v) => {
                        for receipt_id in v {
                            add_receipt_id(receipt_id.clone())?
                        }
                    }
                };
            }
        }

        let promise_id = PromiseId::Joiner(receipt_ids);
        let promise_index = self.promise_ids.len();
        self.promise_ids.push(promise_id);

        Ok(promise_index as u32)
    }

    fn check_ethash(
        &mut self,
        block_number: u64,
        header_hash_ptr: u32,
        header_hash_len: u32,
        nonce: u64,
        mix_hash_ptr: u32,
        mix_hash_len: u32,
        difficulty: u64,
    ) -> Result<u32> {
        let header_hash = self.memory_get(header_hash_ptr as usize, header_hash_len as usize)?;
        let mix_hash = self.memory_get(mix_hash_ptr as usize, mix_hash_len as usize)?;
        Ok(self.ext.check_ethash(block_number, &header_hash, nonce, &mix_hash, difficulty) as u32)
    }

    /// Returns the number of results.
    /// Results are available as part of the callback from a promise.
    fn result_count(&self) -> Result<u32> {
        Ok(self.result_data.len() as u32)
    }

    fn result_is_ok(&self, result_index: u32) -> Result<u32> {
        let result =
            self.result_data.get(result_index as usize).ok_or(Error::InvalidResultIndex)?;

        Ok(result.is_some() as u32)
    }

    fn return_value(&mut self, value_len: u32, value_ptr: u32) -> Result<()> {
        let return_val = self.memory_get(value_ptr as usize, value_len as usize)?;

        self.return_data = ReturnData::Value(return_val);

        Ok(())
    }

    fn return_promise(&mut self, promise_index: u32) -> Result<()> {
        let promise_id = self.promise_index_to_id(promise_index)?;

        self.return_data = ReturnData::Promise(promise_id);

        Ok(())
    }

    fn get_frozen_balance(&mut self, balance_ptr: u32) -> Result<()> {
        self.memory_set(balance_ptr as usize, to_uint128(self.frozen_balance))
    }

    fn get_liquid_balance(&mut self, balance_ptr: u32) -> Result<()> {
        self.memory_set(balance_ptr as usize, to_uint128(self.liquid_balance))
    }

    /// Helper function to transfer between two accounts.
    fn transfer_helper(
        from: &mut Balance,
        to: &mut Balance,
        min_amount: Balance,
        max_amount: Balance,
    ) -> Result<Balance> {
        let result = if *from >= max_amount {
            *from -= max_amount;
            *to += max_amount;
            max_amount
        } else {
            if *from >= min_amount {
                let amount = *from;
                *from = 0;
                *to += amount;
                amount
            } else {
                0
            }
        };
        Ok(result)
    }

    /// Deposit the given amount to the account balance and return deposited amount.
    /// If there is enough of liquid balance will deposit `max_amount`, otherwise will deposit
    /// as much as possible and will fail if there is less than `min_amount`.
    fn deposit(
        &mut self,
        min_amount_ptr: u32,
        max_amount_ptr: u32,
        balance_ptr: u32,
    ) -> Result<()> {
        let min_amount = self.memory_get_u128(min_amount_ptr as usize)?;
        let max_amount = self.memory_get_u128(max_amount_ptr as usize)?;
        Self::transfer_helper(
            &mut self.liquid_balance,
            &mut self.frozen_balance,
            min_amount,
            max_amount,
        )
        .map(to_uint128)
        .and_then(|val| self.memory_set(balance_ptr as usize, val))
    }

    /// Withdraw the given amount from the account balance and return withdrawn amount.
    /// If there is enough of frozen balance will withdraw `max_amount`, otherwise will withdraw
    /// as much as possible and will fail if there is less than `min_amount`.
    fn withdraw(
        &mut self,
        min_amount_ptr: u32,
        max_amount_ptr: u32,
        balance_ptr: u32,
    ) -> Result<()> {
        let min_amount = self.memory_get_u128(min_amount_ptr as usize)?;
        let max_amount = self.memory_get_u128(max_amount_ptr as usize)?;
        Self::transfer_helper(
            &mut self.frozen_balance,
            &mut self.liquid_balance,
            min_amount,
            max_amount,
        )
        .map(to_uint128)
        .and_then(|val| self.memory_set(balance_ptr as usize, val))
    }

    fn storage_usage(&self) -> Result<StorageUsage> {
        let storage_usage = self.context.storage_usage as StorageUsageChange + self.storage_counter;
        Ok(storage_usage as StorageUsage)
    }

    fn received_amount(&mut self, balance_ptr: u32) -> Result<()> {
        self.memory_set(balance_ptr as usize, to_uint128(self.context.received_amount))
    }

    fn assert(&self, expression: u32) -> Result<()> {
        if expression != 0 {
            Ok(())
        } else {
            Err(Error::AssertFailed)
        }
    }

    fn abort(&mut self, msg_ptr: u32, filename_ptr: u32, line: u32, col: u32) -> Result<()> {
        let msg = self.read_string(msg_ptr as usize)?;
        let filename = self.read_string(filename_ptr as usize)?;

        let message =
            format!("ABORT: {:?} filename: {:?} line: {:?} col: {:?}", msg, filename, line, col);
        debug!(target: "wasm", "{}", &message);
        self.logs.push(message);

        Err(Error::AssertFailed)
    }

    fn debug(&mut self, msg_len: u32, msg_ptr: u32) -> Result<()> {
        let val = self.memory_get(msg_ptr as usize, msg_len as usize)?;
        let message = format!(
            "LOG: {}",
            std::str::from_utf8(&val).unwrap_or_else(|_| "debug(): from_utf8 failed")
        );
        debug!(target: "wasm", "{}", &message);
        self.logs.push(message);

        Ok(())
    }

    fn log(&mut self, msg_ptr: u32) -> Result<()> {
        let message = format!(
            "LOG: {}",
            self.read_string(msg_ptr as usize)
                .unwrap_or_else(|_| "log(): read_string failed".to_string())
        );
        debug!(target: "wasm", "{}", &message);
        self.logs.push(message);

        Ok(())
    }

    /// Generic data read. Tries to write data into the given buffer, only if the buffer has available capacity.
    /// Returns length of the data in bytes for the given buffer type and the given key.
    /// NOTE: Majority of reads would be small enough in size to fit into the given preallocated buffer.
    /// Params:
    /// buffer_type_index -> The index of the data column type to read, e.g. storage, sender's account_id or results
    /// key_len and key_ptr -> Depends on buffer type. Represents a key to read.
    ///     key is either a pointer to a key buffer or a key index
    /// max_buf_len -> Capacity of the preallocated buffer to write data into. Can be 0, if we first want to read the length
    /// buf_ptr -> Pointer to the buffer to write data into.
    fn data_read(
        &mut self,
        data_type_index: DataTypeIndex,
        key_len: u32,
        key: u32,
        max_buf_len: u32,
        buf_ptr: u32,
    ) -> Result<u32> {
        let tmp_vec;
        let buf = match data_type_index {
            DATA_TYPE_ORIGINATOR_ACCOUNT_ID => self.context.originator_id.as_bytes(),
            DATA_TYPE_CURRENT_ACCOUNT_ID => self.context.account_id.as_bytes(),
            DATA_TYPE_STORAGE => {
                let key = self.memory_get(key as usize, key_len as usize)?;
                let val = self.ext.storage_get(&key).map_err(|_| Error::StorageUpdateError)?;
                match val {
                    Some(v) => {
                        tmp_vec = v;
                        &tmp_vec[..]
                    }
                    None => &[],
                }
            }
            DATA_TYPE_INPUT => self.input_data,
            DATA_TYPE_RESULT => {
                let result = self.result_data.get(key as usize).ok_or(Error::InvalidResultIndex)?;

                match result {
                    Some(v) => &v[..],
                    None => return Err(Error::ResultIsNotOk),
                }
            }
            DATA_TYPE_STORAGE_ITER => {
                let storage_id = key;
                let key_buf = self
                    .ext
                    .storage_iter_peek(storage_id)
                    .map_err(|_| Error::StorageUpdateError)?;
                match key_buf {
                    Some(v) => {
                        tmp_vec = v;
                        &tmp_vec[..]
                    }
                    None => &[],
                }
            }
            _ => return Err(Error::UnknownDataTypeIndex),
        };
        if buf.len() <= max_buf_len as usize {
            self.memory_set(buf_ptr as usize, &buf)?;
        }
        Ok(buf.len() as u32)
    }

    fn hash(&mut self, value_len: u32, value_ptr: u32, buf_ptr: u32) -> Result<()> {
        let buf = self.memory_get(value_ptr as usize, value_len as usize)?;
        let buf_hash = hash(&buf);

        self.memory_set(buf_ptr as usize, buf_hash.as_ref())
    }

    fn hash32(&self, value_len: u32, value_ptr: u32) -> Result<u32> {
        let buf = self.memory_get(value_ptr as usize, value_len as usize)?;
        let buf_hash = hash(&buf);
        let buf_hash_ref = buf_hash.as_ref();

        let mut buf_hash_32: u32 = 0;
        for b in buf_hash_ref.iter().take(4) {
            buf_hash_32 <<= 8;
            buf_hash_32 += u32::from(*b);
        }

        Ok(buf_hash_32)
    }

    fn random_buf(&mut self, len: u32, out_ptr: u32) -> Result<()> {
        if !self.memory_can_fit(out_ptr as usize, len as usize) {
            return Err(Error::MemoryAccessViolation);
        }

        let mut buf = Vec::with_capacity(len as usize);
        for _ in 0..len {
            buf.push(self.random_u8());
        }

        self.memory_set(out_ptr as usize, &buf)
    }

    fn random32(&mut self) -> Result<u32> {
        let mut random_val: u32 = 0;
        for _ in 0..4 {
            random_val <<= 8;
            random_val += u32::from(self.random_u8());
        }

        Ok(random_val)
    }

    fn block_index(&self) -> Result<u64> {
        Ok(self.context.block_index as u64)
    }
}

pub mod imports {
    use std::ffi::c_void;

    use wasmer_runtime::{func, imports, Ctx, ImportObject};

    use super::{Memory, Result, Runtime};

    macro_rules! wrapped_imports {
        ( $( $import_name:expr => $func:ident < [ $( $arg_name:ident : $arg_type:ident ),* ] -> [ $( $returns:ident ),* ] >, )* ) => {
            $(
                fn $func( ctx: &mut Ctx, $( $arg_name: $arg_type ),* ) -> Result<($( $returns ),*)> {
                    let runtime: &mut Runtime = unsafe { &mut *(ctx.data as *mut Runtime) };
                    runtime.$func( $( $arg_name, )* )
                }
            )*

            pub(crate) fn build(memory: Memory, raw_ptr: *mut c_void) -> ImportObject {
                let dtor = (|_: *mut c_void| {}) as fn(*mut c_void);
                imports! {
                    move || { (raw_ptr, dtor) },
                    "env" => {
                        "memory" => memory,
                        $(
                            $import_name => func!($func),
                        )*
                    },
                }
            }
        }
    }

    wrapped_imports! {
        // Storage related
        // name               // func          // signature
        // Storage write. Writes given value for the given key.
        "storage_write" => storage_write<[key_len: u32, key_ptr: u32, value_len: u32, value_ptr: u32] -> []>,
        "storage_iter" => storage_iter<[prefix_len: u32, prefix_ptr: u32] -> [u32]>,
        "storage_range" => storage_range<[start_len: u32, start_ptr: u32, end_len: u32, end_ptr: u32] -> [u32]>,
        "storage_iter_next" => storage_iter_next<[storage_id: u32] -> [u32]>,
        "storage_remove" => storage_remove<[key_len: u32, key_ptr: u32] -> []>,
        "storage_has_key" => storage_has_key<[key_len: u32, key_ptr: u32] -> [u32]>,
        // Generic data read. Tries to write data into the given buffer, only if the buffer has available capacity.
        "data_read" => data_read<[data_type_index: u32, key_len: u32, key: u32, max_buf_len: u32, buf_ptr: u32] -> [u32]>,

        // Promises, callbacks and async calls
        // Creates a new promise that makes an async call to some other contract.
        "promise_create" => promise_create<[
            account_id_len: u32, account_id_ptr: u32,
            method_name_len: u32, method_name_ptr: u32,
            arguments_len: u32, arguments_ptr: u32,
            amount_ptr: u32
        ] -> [u32]>,
        // Attaches a callback to a given promise. This promise can be either an
        // async call or multiple joined promises.
        // NOTE: The given promise can't be a callback.
        "promise_then" => promise_then<[
            promise_index: u32,
            method_name_len: u32, method_name_ptr: u32,
            arguments_len: u32, arguments_ptr: u32,
            amount_ptr: u32
        ] -> [u32]>,
        // Joins 2 given promises together and returns a new promise.
        "promise_and" => promise_and<[promise_index1: u32, promise_index2: u32] -> [u32]>,
        "check_ethash" => check_ethash<[
            block_number: u64,
            header_hash_ptr: u32, header_hash_len: u32,
            nonce: u64,
            mix_hash_ptr: u32, mix_hash_len: u32,
            difficulty: u64
        ] -> [u32]>,
        // Returns the number of returned results for this callback.
        "result_count" => result_count<[] -> [u32]>,
        "result_is_ok" => result_is_ok<[result_index: u32] -> [u32]>,

        // Called to return value from the function.
        "return_value" => return_value<[value_len: u32, value_ptr: u32] -> []>,
        // Called to return promise from the function.
        "return_promise" => return_promise<[promise_index: u32] -> []>,

        // Context
        // Returns the frozen balance.
        "frozen_balance" => get_frozen_balance<[balance_ptr: u32] -> []>,
        // Returns the liquid balance.
        "liquid_balance" => get_liquid_balance<[balance_ptr: u32] -> []>,
        // Deposits balance from liquid to frozen.
        "deposit" => deposit<[min_amount_ptr: u32, max_amount_ptr: u32, balance_ptr: u32] -> []>,
        // Withdraws balance from frozen to liquid.
         "withdraw" => withdraw<[min_amount_ptr: u32, max_amount_ptr: u32, balance_ptr: u32] -> []>,

        // Returns the storage usage.
        "storage_usage" => storage_usage<[] -> [u64]>,
        // Returns the amount of tokens received with this call.
        "received_amount" => received_amount<[amount_ptr: u32] -> []>,
        // Returns currently produced block index.
        "block_index" => block_index<[] -> [u64]>,

        // Contracts can assert properties. E.g. check the amount available mana.
        "assert" => assert<[expression: u32] -> []>,
        // Assembly Script specific abort
        "abort" => abort<[msg_ptr: u32, filename_ptr: u32, line: u32, col: u32] -> []>,
        // Hashes given value and writes 32 bytes of result in the given pointer.
        "hash" => hash<[value_len: u32, value_ptr: u32, buf_ptr: u32] -> []>,
        // Hashes given value and returns first 32 bits as u32.
        "hash32" => hash32<[value_len: u32, value_ptr: u32] -> [u32]>,
        // Fills given buffer of given length with random values.
        "random_buf" => random_buf<[buf_len: u32, buf_ptr: u32] -> []>,
        // Returns random u32.
        "random32" => random32<[] -> [u32]>,
        // Prints to logs utf-8 string using given msg and msg_ptr
        "debug" => debug<[msg_len: u32, msg_ptr: u32] -> []>,
        // Prints to logs given AssemblyScript string in utf-16 format
        "log" => log<[msg_ptr: u32] -> []>,

        // Function for the injected gas counter. Automatically called by the gas meter.
        "gas" => gas<[gas_amount: u32] -> []>,
    }
}

'''
'''--- runtime/wasm/src/types.rs ---
use std::fmt;

use wasmer_runtime::error as WasmerError;

use near_primitives::hash::{hash, CryptoHash};
use near_primitives::logging;
use near_primitives::types::{AccountId, Balance, BlockIndex, PromiseId, StorageUsage};

use crate::types::Error::Runtime;

#[derive(Debug, Clone)]
/// Error that can occur while preparing or executing wasm smart-contract.
pub enum PrepareError {
    /// Error happened while serializing the module.
    Serialization,

    /// Error happened while deserializing the module.
    Deserialization,

    /// Internal memory declaration has been found in the module.
    InternalMemoryDeclared,

    /// Gas instrumentation failed.
    ///
    /// This most likely indicates the module isn't valid.
    GasInstrumentation,

    /// Stack instrumentation failed.
    ///
    /// This  most likely indicates the module isn't valid.
    StackHeightInstrumentation,

    /// Error happened during invocation of the contract's entrypoint.
    ///
    /// Most likely because of trap.
    Invoke,

    /// Error happened during instantiation.
    ///
    /// This might indicate that `start` function trapped, or module isn't
    /// instantiable and/or unlinkable.
    Instantiate,

    /// Memory error.
    Memory,
}

/// User trap in native code
#[allow(unused)]
#[derive(Debug, Clone, PartialEq)]
pub enum RuntimeError {
    /// Storage read error
    StorageReadError,
    /// Storage update error
    StorageUpdateError,
    /// Storage remove error
    StorageRemoveError,
    /// Memory access violation
    MemoryAccessViolation,
    /// Native code returned incorrect value
    InvalidReturn,
    /// Error in external promise method
    PromiseError,
    /// Invalid promise index given by the WASM
    InvalidPromiseIndex,
    /// Invalid result index given by the WASM to read results
    InvalidResultIndex,
    // WASM is trying to read data from a result that is an error
    ResultIsNotOk,
    /// Invalid gas state inside interpreter
    InvalidGasState,
    /// Query of the balance resulted in an error
    BalanceQueryError,
    /// Transfer exceeded the available balance of the account
    BalanceExceeded,
    /// WASM-side assert failed
    AssertFailed,
    /// Gas limit reached
    UsageLimit,
    /// Unknown runtime function
    Unknown,
    /// Passed string had invalid utf-8 encoding
    BadUtf8,
    /// Passed string had invalid utf-16 encoding
    BadUtf16,
    /// Log event error
    Log,
    /// Other error in native code
    Other,
    /// Syscall signature mismatch
    InvalidSyscall,
    /// Unreachable instruction encountered
    Unreachable,
    /// Invalid virtual call
    InvalidVirtualCall,
    /// Division by zero
    DivisionByZero,
    /// Invalid conversion to integer
    InvalidConversionToInt,
    /// Stack overflow
    StackOverflow,
    /// Unknown data type index for reading or writing
    UnknownDataTypeIndex,
    /// Invalid account id
    InvalidAccountId,
    /// Creating a promise with a private method. The method name starts with '_'.
    PrivateMethod,
    /// Creating a callback with an empty method name.
    EmptyMethodName,
    /// Panic with message
    Panic(String),
}

impl ::std::fmt::Display for RuntimeError {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::result::Result<(), ::std::fmt::Error> {
        match *self {
            RuntimeError::StorageReadError => write!(f, "Storage read error"),
            RuntimeError::StorageUpdateError => write!(f, "Storage update error"),
            RuntimeError::StorageRemoveError => write!(f, "Storage remove error"),
            RuntimeError::MemoryAccessViolation => write!(f, "Memory access violation"),
            RuntimeError::InvalidGasState => write!(f, "Invalid gas state"),
            RuntimeError::BalanceQueryError => write!(f, "Balance query resulted in an error"),
            RuntimeError::BalanceExceeded => {
                write!(f, "Transfer exceeded the available balance of the account")
            }
            RuntimeError::InvalidReturn => write!(f, "Invalid return value"),
            RuntimeError::PromiseError => write!(f, "Error in the external promise method"),
            RuntimeError::InvalidPromiseIndex => write!(f, "Invalid promise index given by WASM"),
            RuntimeError::InvalidResultIndex => {
                write!(f, "Invalid result index given by the WASM to read results")
            }
            RuntimeError::ResultIsNotOk => {
                write!(f, "WASM is trying to read data from a result that is an error")
            }
            RuntimeError::Unknown => write!(f, "Unknown runtime function invoked"),
            RuntimeError::AssertFailed => write!(f, "WASM-side assert failed"),
            RuntimeError::BadUtf8 => write!(f, "String encoding is bad utf-8 sequence"),
            RuntimeError::BadUtf16 => write!(f, "String encoding is bad utf-16 sequence"),
            RuntimeError::UsageLimit => write!(f, "Invocation resulted in usage limit violated"),
            RuntimeError::Log => write!(f, "Error occured while logging an event"),
            RuntimeError::InvalidSyscall => {
                write!(f, "Invalid syscall signature encountered at runtime")
            }
            RuntimeError::Other => write!(f, "Other unspecified error"),
            RuntimeError::Unreachable => write!(f, "Unreachable instruction encountered"),
            RuntimeError::InvalidVirtualCall => write!(f, "Invalid virtual call"),
            RuntimeError::DivisionByZero => write!(f, "Division by zero"),
            RuntimeError::StackOverflow => write!(f, "Stack overflow"),
            RuntimeError::InvalidConversionToInt => write!(f, "Invalid conversion to integer"),
            RuntimeError::UnknownDataTypeIndex => {
                write!(f, "Unknown data type index for reading or writing")
            }
            RuntimeError::InvalidAccountId => write!(f, "Invalid AccountID"),
            RuntimeError::PrivateMethod => write!(f, "Creating a promise with a private method"),
            RuntimeError::EmptyMethodName => {
                write!(f, "Creating a callback with an empty method name")
            }
            RuntimeError::Panic(ref msg) => write!(f, "Panic: {}", msg),
        }
    }
}

/// Wrapped error
#[derive(Debug, Clone)]
pub enum Error {
    /// Method name can't be decoded to UTF8.
    BadUtf8,

    /// Method name is empty.
    EmptyMethodName,

    /// Method is private, because it starts with '_'.
    PrivateMethod,

    Wasmer(String), // TODO: WasmerError::Error is not shareable between threads

    Runtime(RuntimeError),

    Prepare(PrepareError),

    Cache(String),
}

impl From<WasmerError::RuntimeError> for Error {
    fn from(e: WasmerError::RuntimeError) -> Self {
        let default_msg = Error::Wasmer(format!("{}", e));
        match e {
            WasmerError::RuntimeError::Trap { msg: _ } => default_msg,
            WasmerError::RuntimeError::Error { data } => {
                if let Some(err) = data.downcast_ref::<RuntimeError>() {
                    Runtime(err.clone())
                } else {
                    default_msg
                }
            }
        }
    }
}

impl From<WasmerError::Error> for Error {
    fn from(e: WasmerError::Error) -> Self {
        let default_msg = Error::Wasmer(format!("{}", e));
        match e {
            WasmerError::Error::CallError(ce) => match ce {
                WasmerError::CallError::Resolve(_) => default_msg,
                WasmerError::CallError::Runtime(re) => re.into(),
            },
            WasmerError::Error::RuntimeError(re) => re.into(),
            WasmerError::Error::CompileError(_)
            | WasmerError::Error::LinkError(_)
            | WasmerError::Error::ResolveError(_)
            | WasmerError::Error::CreationError(_) => default_msg,
        }
    }
}

impl From<RuntimeError> for Error {
    fn from(e: RuntimeError) -> Self {
        Error::Runtime(e)
    }
}

/// Returned data from the method.
#[derive(Clone)]
pub enum ReturnData {
    /// Method returned some value or data.
    Value(Vec<u8>),

    /// Method returned a promise.
    Promise(PromiseId),

    /// Method hasn't returned any data or promise.
    None,
}

impl ReturnData {
    pub fn to_result(&self) -> Option<Vec<u8>> {
        match self {
            ReturnData::Value(v) => Some(v.clone()),
            _ => Some(vec![]),
        }
    }
}

impl fmt::Debug for ReturnData {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            ReturnData::Value(v) => {
                f.debug_tuple("Value").field(&format_args!("{}", logging::pretty_utf8(&v))).finish()
            }
            ReturnData::Promise(promise_id) => f.debug_tuple("Promise").field(&promise_id).finish(),
            ReturnData::None => write!(f, "None"),
        }
    }
}

// TODO: Extract it to the root of the crate
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Config {
    /// Gas cost of a growing memory by single page.
    pub grow_mem_cost: u32,

    /// Gas cost of a regular operation.
    pub regular_op_cost: u32,

    /// Gas cost per one byte returned.
    pub return_data_per_byte_cost: u32,

    /// Gas cost of the contract call.
    pub contract_call_cost: Balance,

    /// How tall the stack is allowed to grow?
    ///
    /// See https://wiki.parity.io/WebAssembly-StackHeight to find out
    /// how the stack frame cost is calculated.
    pub max_stack_height: u32,

    // The initial number of memory pages.
    pub initial_memory_pages: u32,

    /// What is the maximal memory pages amount is allowed to have for
    /// a contract.
    pub max_memory_pages: u32,

    /// Gas limit of the one contract call
    pub usage_limit: u64,
}

impl Default for Config {
    fn default() -> Config {
        Config {
            grow_mem_cost: 1,
            regular_op_cost: 1,
            return_data_per_byte_cost: 1,
            contract_call_cost: 0,
            max_stack_height: 64 * 1024,
            initial_memory_pages: 17,
            max_memory_pages: 32,
            usage_limit: 1024 * 1024 * 1024,
        }
    }
}

/// Context for the WASM contract execution.
#[derive(Default, Clone, Debug)]
pub struct RuntimeContext {
    /// Initial balance is the balance of the account before the
    /// received_amount is added.
    pub initial_balance: Balance,
    /// The amount sent by the Sender.
    pub received_amount: Balance,
    /// Originator's Account ID.
    pub originator_id: AccountId,
    /// Current Account ID.
    pub account_id: AccountId,
    /// Storage that the account is already using.
    pub storage_usage: StorageUsage,
    /// Currently produced block index
    pub block_index: BlockIndex,
    /// Initial seed for randomness
    pub random_seed: Vec<u8>,
    /// Whether the execution should not charge any costs.
    pub free_of_charge: bool,
}

impl RuntimeContext {
    pub fn new(
        initial_balance: Balance,
        received_amount: Balance,
        sender_id: &AccountId,
        account_id: &AccountId,
        storage_usage: StorageUsage,
        block_index: BlockIndex,
        random_seed: Vec<u8>,
        free_of_charge: bool,
    ) -> RuntimeContext {
        RuntimeContext {
            initial_balance,
            received_amount,
            originator_id: sender_id.clone(),
            account_id: account_id.clone(),
            storage_usage,
            block_index,
            random_seed,
            free_of_charge,
        }
    }
}

#[derive(Serialize, Deserialize)]
pub struct ContractCode {
    code: Vec<u8>,
    hash: CryptoHash,
}

impl ContractCode {
    pub fn new(code: Vec<u8>) -> ContractCode {
        let hash = hash(&code);
        ContractCode { code, hash }
    }

    pub fn get_hash(&self) -> CryptoHash {
        self.hash
    }

    pub fn get_code(&self) -> &Vec<u8> {
        &self.code
    }
}

'''
'''--- rustfmt.toml ---
use_small_heuristics = "Max"
# fn_args_density = "Compressed"
# overflow_delimited_expr = "true"

'''
'''--- scripts/build_wasm.sh ---
#!/bin/bash
set -ex

cd tests/hello
rm -rf node_modules
npm install
npm run build

'''
'''--- scripts/coverage.sh ---
#!/bin/sh

wget https://github.com/SimonKagstrom/kcov/archive/master.tar.gz
tar xzf master.tar.gz
cd kcov-master
mkdir build
cd build
cmake ..
make
make install DESTDIR=../../kcov-build
cd ../..
rm -rf kcov-master

# Remove binaries
rm -rf target/debug/deps/test*
rm -rf target/debug/deps/nearcore*
rm -rf target/debug/deps/alphanet*
rm -rf target/debug/deps/near
rm -rf target/debug/deps/near-*

for file in target/debug/deps/*
do
  if [ -f $file ] && [ -x $file ]; then
    mkdir -p "target/cov/$(basename $file)"
    ./kcov-build/usr/local/bin/kcov --exclude-pattern=/.cargo,/usr/lib --verify "target/cov/$(basename $file)" "$file"
  fi
done

curl -s https://codecov.io/bash | bash
echo "Uploaded code coverage"

'''
'''--- scripts/generate_js_transaction_proto.sh ---
#!/usr/bin/env bash
PARENT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )/.." >/dev/null && pwd )"
${PARENT_DIR}/nearlib/node_modules/.bin/pbjs \
	-t static-module \
	-w commonjs \
	-o ${PARENT_DIR}/nearlib/protos.js \
	${PARENT_DIR}/protos/protos/signed_transaction.proto

'''
'''--- scripts/kill_devnet.sh ---
kill -9 `pgrep -f tendermint`
kill -9 `pgrep -f nearmint`
exit 0

'''
'''--- scripts/kill_near.sh ---
#!/bin/bash

kill -9 `pgrep -f near`
exit 0

'''
'''--- scripts/run_clippy.sh ---
#!/bin/bash
cargo clippy --all  -- -A clippy::type-complexity -A clippy::needless-pass-by-value -A clippy::while-let-loop -A clippy::too-many-arguments -A clippy::unit_arg -A clippy::if_same_then_else -A clippy::collapsible_if -A clippy::useless-let-if-seq -A clippy::map-entry -D warnings -A clippy::implicit-hasher -A clippy::ptr-arg -A renamed-and-removed-lints -A clippy::needless-range-loop

'''
'''--- scripts/setup_hooks.sh ---
#!/bin/bash
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
HOOK_DIR=$(git rev-parse --show-toplevel)/.git/hooks
ln -s -f ${DIR}/pre-commit ${HOOK_DIR}

'''
'''--- scripts/start_near.sh ---
#!/bin/bash
set -ex

cargo run -p near -- init --test-seed alice.near
cargo run -p near -- --verbose run --produce-empty-blocks=false

'''
'''--- scripts/start_nearmint.sh ---
#!/bin/bash
set -ex

cargo run --package keystore keygen --tendermint --test-seed "alice.near" -p ~/.tendermint/config/
cargo build --package nearmint --release
./target/release/nearmint --devnet & tendermint node --rpc.laddr "tcp://0.0.0.0:3030" --consensus.create_empty_blocks=false

'''
'''--- scripts/test_nearlib.sh ---
#!/bin/bash
set -ex

# Must start binary outside of this script.
./scripts/waitonserver.sh
./scripts/build_wasm.sh

# Run nearlib tests
rm -rf nearlib
git clone https://github.com/nearprotocol/nearlib.git nearlib
git checkout origin/nightshade
export NEAR_PROTOS_DIR="../nearcore/core/protos/protos"
export HELLO_WASM_PATH="../nearcore/tests/hello.wasm"
npm install
npm test
npm run build
npm run doc
cd ..

# Try creating and building new project using NEAR CLI tools
<<COMMENT
git clone https://git@github.com/nearprotocol/near-shell.git near-shell
git checkout origin/nightshade
cd near-shell
npm install
npm test
cd ..
COMMENT

./scripts/kill_near.sh

'''
'''--- scripts/waitonserver.sh ---
#!/bin/bash

echo 'waiting on healthcheck' >&2

for _ in {1..100}; do
    if [[ "$(curl -s -o /dev/null -w '%{http_code}' http://localhost:3030/status)" == "200" ]]; then
        exit 0
    fi
    sleep 5
done

echo 'ERROR: waiting timeout' >&2
exit 1

'''
'''--- test-utils/keystore/Cargo.toml ---
[package]
name = "keystore"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
clap = "2.32.0"
serde = "1.0"
serde_derive = "1.0"
serde_json = "1.0"
hex = "0.3"

near-primitives = { path = "../../core/primitives" }

'''
'''--- test-utils/keystore/src/main.rs ---
#[macro_use]
extern crate serde_derive;

use std::fs;
use std::path::{Path, PathBuf};
use std::process;

use clap::{App, Arg, ArgMatches, SubCommand};

use near_primitives::crypto::signature::{sign, PublicKey, SecretKey};
use near_primitives::crypto::signer::{
    get_key_file, write_block_producer_key_file, InMemorySigner,
};
use near_primitives::hash::hash;
use near_primitives::serialize::{from_base, to_base, BaseEncode};

#[derive(Serialize)]
struct TypeValue {
    #[serde(rename = "type")]
    type_field: String,
    value: String,
}

#[derive(Serialize)]
struct TendermintKeyFile {
    address: String,
    pub_key: TypeValue,
    priv_key: TypeValue,
}

fn write_tendermint_key_file(key_store_path: &Path, public_key: PublicKey, secret_key: SecretKey) {
    if !key_store_path.exists() {
        fs::create_dir_all(key_store_path).unwrap();
    }

    let address_bytes = hash(public_key.as_ref()).as_ref()[..20].to_vec();
    let address = hex::encode(&address_bytes);
    let key_file = TendermintKeyFile {
        address,
        pub_key: TypeValue {
            type_field: "tendermint/PubKeyEd25519".to_string(),
            value: public_key.to_base(),
        },
        priv_key: TypeValue {
            type_field: "tendermint/PrivKeyEd25519".to_string(),
            value: secret_key.to_base(),
        },
    };
    let key_file_path = key_store_path.join(Path::new("priv_validator_key.json"));
    let serialized = serde_json::to_string(&key_file).unwrap();
    fs::write(key_file_path, serialized).unwrap();
}

fn get_key_store_path(matches: &ArgMatches) -> PathBuf {
    matches.value_of("key_store_path").map(PathBuf::from).unwrap()
}

fn sign_data(matches: &ArgMatches) {
    let key_store_path = get_key_store_path(matches);

    let public_key = matches.value_of("public_key").map(String::from);
    let key_file = get_key_file(&key_store_path, public_key);

    let data = matches.value_of("data").unwrap();
    let bytes = from_base(data).unwrap();
    let signature = sign(&bytes, &key_file.secret_key);
    let encoded = to_base(&signature);
    print!("{}", encoded);
}

fn generate_key(matches: &ArgMatches) {
    let key_store_path = get_key_store_path(matches);
    let signer = InMemorySigner::from_seed("not_used", matches.value_of("test_seed").unwrap());
    write_block_producer_key_file(&key_store_path.as_path(), signer.public_key, signer.secret_key);
}

fn generate_tendermint_key(matches: &ArgMatches) {
    let key_store_path = get_key_store_path(matches);
    let signer = InMemorySigner::from_seed("not_used", matches.value_of("test_seed").unwrap());
    write_tendermint_key_file(&key_store_path.as_path(), signer.public_key, signer.secret_key);
}

fn get_public_key(matches: &ArgMatches) {
    let key_store_path = get_key_store_path(matches);
    let public_key = None;
    let key_file = get_key_file(&key_store_path, public_key);
    print!("{}", key_file.public_key);
}

fn main() {
    let key_store_path_arg = &Arg::with_name("key_store_path")
        .short("p")
        .long("keystore-path")
        .value_name("KEY_STORE_PATH")
        .help("Sets a directory location for key store")
        .default_value("keystore")
        .required(true)
        .takes_value(true);
    let matches = App::new("keystore")
        .subcommand(
            SubCommand::with_name("keygen")
                .arg(key_store_path_arg)
                .arg(
                    Arg::with_name("test_seed")
                        .long("test-seed")
                        .value_name("TEST_SEED")
                        .help(
                            "Specify a seed for generating a key pair.\
                             This should only be used for deterministically \
                             creating key pairs during tests.",
                        )
                        .takes_value(true),
                )
                .arg(Arg::with_name("tendermint").long("tendermint").takes_value(false)),
        )
        .subcommand(SubCommand::with_name("get_public_key").arg(key_store_path_arg))
        .subcommand(
            SubCommand::with_name("sign")
                .arg(key_store_path_arg)
                .arg(
                    Arg::with_name("data")
                        .short("d")
                        .long("data")
                        .value_name("DATA")
                        .help("base64 encoded bytes")
                        .required(true)
                        .takes_value(true),
                )
                .arg(
                    Arg::with_name("public_key")
                        .short("k")
                        .long("public-key")
                        .value_name("PUBLIC_KEY")
                        .help(
                            "Sets public key to sign with, \
                             can be omitted with 1 file in keystore",
                        )
                        .takes_value(true),
                ),
        )
        .get_matches();

    if let Some(sub) = matches.subcommand_matches("keygen") {
        if sub.is_present("tendermint") {
            generate_tendermint_key(sub);
        } else {
            generate_key(sub);
        }
    } else if let Some(sub) = matches.subcommand_matches("sign") {
        sign_data(sub);
    } else if let Some(sub) = matches.subcommand_matches("get_public_key") {
        get_public_key(sub);
    } else {
        println!("Incorrect usage. See usage with: keystore --help");
        process::exit(1);
    }
}

'''
'''--- test-utils/loadtester/Cargo.toml ---
[package]
name = "loadtester"
version = "0.0.1"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
clap = "2.32"
log = "0.4"
env_logger = "0.6.0"
rand = "0.6"
rand_xorshift = "0.1"
hex = "0.3"
futures = "0.1.25"
tokio = "0.1"
protobuf = { version = "2.2.4", features = ["with-bytes"] }
serde_json = "1.0.0"

near-primitives = { path = "../../core/primitives" }
near-protos = { path = "../../core/protos" }
node-runtime = { path = "../../runtime/runtime" }
testlib = { path = "../testlib" }
near = { path = "../../near" }

[dependencies.reqwest]
version = "0.9"
features = ["rustls-tls", "trust-dns"]

'''
'''--- test-utils/loadtester/README.md ---
# Load testing tool

This tool can be used to test a local or remote set of nodes. It submits transactions at a given rate and monitors
the output TPS by periodically requesting the most recent block from the leading nodes.

## Example

The following is an example of how to crash a locally running TestNet by saturating it with transactions.
As of 2019-04-16, this has not been fixed.

Start the local TestNet:
```bash
./ops/local_alphanet.sh
```

Host machine needs to have keys that nodes use for their associated accounts. Generate the keys like this:

```bash
cargo run --package keystore --bin keystore keygen --test-seed near.0 -p /tmp/keys/
cargo run --package keystore --bin keystore keygen --test-seed near.1 -p /tmp/keys/
cargo run --package keystore --bin keystore keygen --test-seed near.2 -p /tmp/keys/
cargo run --package keystore --bin keystore keygen --test-seed near.3 -p /tmp/keys/
```

Make sure the load tester is configured to send 700 TPS of monetary transactions. See the `main.rs` file:
```rust
 Executor::spawn(nodes, TransactionType::Monetary, None, None, 700, TrafficType::Regular);
```

Launch the load tester:
```bash
cargo run --package loadtester --bin loadtester -- --key-files-path /tmp/keys \
--addresses 127.0.0.1:3030 127.0.0.1:3031 127.0.0.1:3032 127.0.0.1:3033 \
--public-keys 82M8LNM7AzJHhHKn6hymVW1jBzSwFukHp1dycVcU7MD CTVkQMjLyr4QzoXrTDVzfCUp95sCJPwLJZ34JTiekxMV EJ1DMa6s2ngC5GtZb3Z2DZzat2xFZ34j15VLY37dcdXX 3DToePHssYc75SsxZgzgVLwXE8XQXKjdpdL7CT7D34UE \
--account-ids near.0 near.1 near.2 near.3 2>&1  | tee /tmp/out2.txt
```

Observe that the TestNet produces up to 700 TPS and then after a random amount of time it stops creating new blocks.

## Benchmark NEAR (1 node)

Here how you can run benchmarking for one local node:

```
cargo build --release -p near
cargo build --release -p loadtester

# Start NEAR node
./target/release/near init
./target/release/near run

# Run load tester
mkdir /tmp/keys
cp ~/.near/validator_key.json /tmp/keys/
# Get public key to use for next command.
cat ~/.near/validator_key.json

./target/release/loadtester --key-files-path /tmp/keys \
 --address 127.0.0.1:3030 \
 --public-keys <PUBLIC KEY> \
 --account-ids test.near 2>&1 | tee /tmp/out.txt
```

'''
'''--- test-utils/loadtester/src/main.rs ---
use std::net::SocketAddr;
use std::str::FromStr;
use std::time::Duration;

use env_logger::Builder;

use near::config::GenesisConfig;
use remote_node::RemoteNode;

use crate::transactions_executor::Executor;
use crate::transactions_generator::TransactionType;

pub mod remote_node;
pub mod sampler;
pub mod stats;
pub mod transactions_executor;
pub mod transactions_generator;

#[allow(dead_code)]
fn configure_logging(log_level: log::LevelFilter) {
    let internal_targets = vec!["observer"];
    let mut builder = Builder::from_default_env();
    internal_targets.iter().for_each(|internal_targets| {
        builder.filter(Some(internal_targets), log_level);
    });
    builder.default_format_timestamp_nanos(true);
    builder.try_init().unwrap();
}

fn main() {
    configure_logging(log::LevelFilter::Debug);
    let genesis_config = GenesisConfig::testing_spec(400, 10);
    let accounts: Vec<_> = genesis_config.accounts.into_iter().map(|t| t.account_id).collect();

    let addrs = [
        "35.236.106.188:3030",
        "35.235.115.64:3030",
        "35.235.75.161:3030",
        "35.236.113.178:3030",
        "35.236.42.186:3030",
        "35.236.29.55:3030",
        "35.235.84.221:3030",
        "35.236.44.50:3030",
        "35.236.84.38:3030",
        "35.236.37.104:3030",
    ];

    let num_nodes = addrs.len();
    let accounts_per_node = accounts.len() / num_nodes;
    let mut nodes = vec![];
    for (i, addr) in addrs.iter().enumerate() {
        let node = RemoteNode::new(
            SocketAddr::from_str(addr).unwrap(),
            &accounts[(i * accounts_per_node)..((i + 1) * accounts_per_node)],
        );
        nodes.push(node);
    }

    // Start the executor.
    let handle = Executor::spawn(nodes, Some(Duration::from_secs(10)), 1600, TransactionType::Set);
    handle.join().unwrap();
}

'''
'''--- test-utils/loadtester/src/remote_node.rs ---
use std::net::SocketAddr;
use std::sync::{Arc, RwLock};
use std::thread;
use std::time::{Duration, Instant};

use futures::Future;
use protobuf::Message;
use reqwest::r#async::Client as AsyncClient;
use reqwest::Client as SyncClient;

use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::serialize::from_base;
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::{AccountId, Nonce};
use node_runtime::state_viewer::AccountViewCallResult;

const CONNECT_TIMEOUT: Duration = Duration::from_secs(10);
/// Maximum number of blocks that can be fetched through a single RPC request.
pub const MAX_BLOCKS_FETCH: u64 = 20;
const VALUE_NOT_STR_ERR: &str = "Value is not str";
const VALUE_NOT_ARR_ERR: &str = "Value is not array";

/// Maximum number of times we retry a single RPC.
const MAX_RETRIES_PER_RPC: usize = 10;
const MAX_RETRIES_REACHED_ERR: &str = "Exceeded maximum number of retries per RPC";

/// Maximum time we wait for the given RPC.
const MAX_WAIT_RPC: Duration = Duration::from_secs(60);
const MAX_WAIT_REACHED_ERR: &str = "Exceeded maximum wait on RPC";

pub struct RemoteNode {
    pub addr: SocketAddr,
    pub signers: Vec<Arc<InMemorySigner>>,
    pub nonces: Vec<Nonce>,
    pub url: String,
    async_client: Arc<AsyncClient>,
    sync_client: SyncClient,
}

pub fn wait<F, T>(mut f: F) -> T
where
    F: FnMut() -> Result<T, Box<dyn std::error::Error>>,
{
    let started = Instant::now();
    loop {
        match f() {
            Ok(r) => return r,
            Err(err) => {
                if Instant::now().duration_since(started) > MAX_WAIT_RPC {
                    panic!("{}: {}", MAX_WAIT_REACHED_ERR, err);
                } else {
                    thread::sleep(Duration::from_millis(100));
                }
            }
        }
    }
}

pub fn try_wait<F, T>(mut f: F) -> Result<T, Box<dyn std::error::Error>>
where
    F: FnMut() -> Result<T, Box<dyn std::error::Error>>,
{
    let started = Instant::now();
    loop {
        match f() {
            Ok(r) => return Ok(r),
            Err(err) => {
                if Instant::now().duration_since(started) > MAX_WAIT_RPC {
                    return Err(err);
                } else {
                    thread::sleep(Duration::from_millis(100));
                }
            }
        }
    }
}

pub fn get_result<F, T>(f: F) -> T
where
    F: Fn() -> Result<T, Box<dyn std::error::Error>>,
{
    let mut curr = 0;
    loop {
        match f() {
            Ok(r) => return r,
            Err(err) => {
                if curr == MAX_RETRIES_PER_RPC - 1 {
                    panic!("{}: {}", MAX_RETRIES_REACHED_ERR, err);
                } else {
                    curr += 1;
                }
            }
        };
    }
}

impl RemoteNode {
    pub fn new(addr: SocketAddr, signers_accs: &[AccountId]) -> Arc<RwLock<Self>> {
        let url = format!("http://{}", addr);
        let signers: Vec<_> = signers_accs
            .iter()
            .map(|s| Arc::new(InMemorySigner::from_seed(s.as_str(), s.as_str())))
            .collect();
        let nonces = vec![0; signers.len()];
        let async_client = Arc::new(
            AsyncClient::builder()
                .use_rustls_tls()
                .connect_timeout(CONNECT_TIMEOUT)
                .build()
                .unwrap(),
        );

        let sync_client = SyncClient::builder()
            .use_rustls_tls()
            .connect_timeout(CONNECT_TIMEOUT)
            .build()
            .unwrap();
        let mut result = Self { addr, signers, nonces, url, async_client, sync_client };

        // Wait for the node to be up.
        wait(|| result.health_ok());

        // Collect nonces.
        result.get_nonces(signers_accs);
        Arc::new(RwLock::new(result))
    }

    /// Get nonces for the given list of signers.
    fn get_nonces(&mut self, signers: &[AccountId]) {
        let nonces: Vec<Nonce> =
            signers.iter().map(|s| get_result(|| self.view_account(s)).nonce).collect();
        self.nonces = nonces;
    }

    fn health_ok(&self) -> Result<(), Box<dyn std::error::Error>> {
        let url = format!("{}{}", self.url, "/status");
        Ok(self.sync_client.post(url.as_str()).send().map(|_| ())?)
    }

    fn view_account(
        &self,
        account_id: &AccountId,
    ) -> Result<AccountViewCallResult, Box<dyn std::error::Error>> {
        let url = format!("{}{}", self.url, "/abci_query");
        let response: serde_json::Value = self
            .sync_client
            .post(url.as_str())
            .form(&[("path", format!("\"account/{}\"", account_id))])
            .send()?
            .json()?;
        let bytes = from_base(
            response["result"]["response"]["value"].as_str().ok_or(VALUE_NOT_STR_ERR)?,
        )?;
        let s = std::str::from_utf8(&bytes)?;
        Ok(serde_json::from_str(s)?)
    }

    /// Sends transaction using `broadcast_tx_sync` using non-blocking Futures.
    pub fn add_transaction_async(
        &self,
        transaction: SignedTransaction,
    ) -> Box<dyn Future<Item = (), Error = String> + Send> {
        let transaction: near_protos::signed_transaction::SignedTransaction = transaction.into();
        let tx_bytes = transaction.write_to_bytes().expect("write to bytes failed");
        let url = format!("{}{}", self.url, "/broadcast_tx_sync");
        let response = self
            .async_client
            .post(url.as_str())
            .form(&[("tx", format!("0x{}", hex::encode(&tx_bytes)))])
            .send()
            .map(|_| ())
            .map_err(|err| format!("{}", err));
        Box::new(response)
    }

    /// Sends transactions using `broadcast_tx_sync` using blocking code. Return hash of
    /// the transaction.
    pub fn add_transaction(
        &self,
        transaction: SignedTransaction,
    ) -> Result<String, Box<dyn std::error::Error>> {
        let transaction: near_protos::signed_transaction::SignedTransaction = transaction.into();
        let tx_bytes = transaction.write_to_bytes().expect("write to bytes failed");
        let url = format!("{}{}", self.url, "/broadcast_tx_sync");
        let result: serde_json::Value = self
            .sync_client
            .post(url.as_str())
            .form(&[("tx", format!("0x{}", hex::encode(&tx_bytes)))])
            .send()?
            .json()?;
        Ok(result["result"]["hash"].as_str().ok_or(VALUE_NOT_STR_ERR)?.to_owned())
    }

    /// Returns block height if transaction is committed to a block.
    pub fn transaction_committed(&self, hash: &String) -> Result<u64, Box<dyn std::error::Error>> {
        let url = format!("{}{}", self.url, "/tx");
        let response: serde_json::Value = self
            .sync_client
            .post(url.as_str())
            .form(&[("hash", format!("0x{}", hash))])
            .send()?
            .json()?;
        Ok(response["result"]["height"].as_str().ok_or(VALUE_NOT_STR_ERR)?.parse()?)
    }

    pub fn get_current_height(&self) -> Result<u64, Box<dyn std::error::Error>> {
        let url = format!("{}{}", self.url, "/status");
        let response: serde_json::Value = self.sync_client.post(url.as_str()).send()?.json()?;
        Ok(response["result"]["sync_info"]["latest_block_height"]
            .as_str()
            .ok_or(VALUE_NOT_STR_ERR)?
            .parse()?)
    }

    // This does not work because Tendermint RPC returns garbage: https://pastebin.com/RUbEdqt6
    pub fn block_result_codes(
        &self,
        height: u64,
    ) -> Result<Vec<(u32, String)>, Box<dyn std::error::Error>> {
        let url = format!("{}{}", self.url, "/block_results");
        let response: serde_json::Value = self
            .sync_client
            .post(url.as_str())
            .form(&[("height", format!("{}", height))])
            .send()?
            .json()?;

        let mut results = vec![];
        for result in response["result"]["results"].as_array().ok_or(VALUE_NOT_ARR_ERR)? {
            results.push((
                result["code"].as_str().ok_or(VALUE_NOT_STR_ERR)?.parse::<u32>()?,
                result["data"].as_str().ok_or(VALUE_NOT_STR_ERR)?.to_owned(),
            ));
        }
        Ok(results)
    }

    pub fn get_transactions(
        &self,
        min_height: u64,
        max_height: u64,
    ) -> Result<u64, Box<dyn std::error::Error>> {
        assert!(max_height - min_height <= MAX_BLOCKS_FETCH, "Too many blocks to fetch");
        let url = format!("{}{}", self.url, "/blockchain");
        let response: serde_json::Value = self
            .sync_client
            .post(url.as_str())
            .form(&[
                ("minHeight", format!("{}", min_height)),
                ("maxHeight", format!("{}", max_height)),
            ])
            .send()?
            .json()?;
        let mut result = 0u64;
        for block_meta in response["result"]["block_metas"].as_array().ok_or(VALUE_NOT_ARR_ERR)? {
            result += block_meta["header"]["num_txs"]
                .as_str()
                .ok_or(VALUE_NOT_STR_ERR)?
                .parse::<u64>()?;
        }

        Ok(result)
    }
}

'''
'''--- test-utils/loadtester/src/sampler.rs ---
//! Functions to sample a collection of objects. The functions that accept predicate optimize not
//! for the runtime complexity but for how many times it runs the predicate. It is useful for
//! predicates that do expensive invocations, e.g. querying a node.
use rand::seq::SliceRandom;
use rand::thread_rng;
use std::collections::HashSet;

const EMPTY_COLLECTION: &str = "Collection is expected to be non-empty";
const COLLECTION_TOO_SMALL: &str = "Collection size is less than sample size";
const COLLECTION_EXHAUSTED: &str =
    "Not enough elements in the collection that satisfy the predicate";

/// Get one item from the collection.
pub fn sample_one<T>(collection: &[T]) -> &T {
    collection.choose(&mut thread_rng()).expect(EMPTY_COLLECTION)
}

/// Get one item from the collection that satisfy the given predicate.
pub fn sample_one_fn<T, F>(collection: &[T], f: F) -> &T
where
    F: Fn(&T) -> bool,
{
    let mut attempted_indices = HashSet::new();
    let mut i;
    let mut res;
    loop {
        i = rand::random::<usize>() % collection.len();
        // Check if already attempted.
        if attempted_indices.contains(&i) {
            continue;
        };

        res = &collection[i];
        if f(res) {
            break;
        } else {
            attempted_indices.insert(i);
            assert!(attempted_indices.len() < collection.len(), COLLECTION_EXHAUSTED);
        }
    }
    res
}

/// Get several items from the collections.
pub fn sample<T>(collection: &[T], sample_size: usize) -> Vec<&T> {
    assert!(collection.len() >= sample_size, COLLECTION_TOO_SMALL);
    collection.choose_multiple(&mut thread_rng(), sample_size).collect()
}

/// Get several items from the collection that satisfy the given predicate.
pub fn sample_fn<T, F>(collection: &[T], sample_size: usize, f: F) -> Vec<&T>
where
    F: Fn(&T) -> bool,
{
    let mut attempted_indices = HashSet::new();
    let mut i;
    let mut res = vec![];
    loop {
        i = rand::random::<usize>() % collection.len();
        // Check if already attempted.
        if attempted_indices.contains(&i) {
            continue;
        };

        let el = &collection[i];
        if f(el) {
            res.push(el);
            if res.len() == sample_size {
                break;
            }
        }
        attempted_indices.insert(i);
        assert!(attempted_indices.len() < collection.len(), COLLECTION_EXHAUSTED);
    }
    res
}

/// Binds a tuple to a vector.
/// # Examples:
///
/// ```
/// let v = vec![1,2,3];
/// tuplet!((a,b,c) = v);
/// assert_eq!(a, &1);
/// assert_eq!(b, &2);
/// assert_eq!(c, &3);
/// ```
macro_rules! tuplet {
    { ($y:ident $(, $x:ident)*) = $v:expr } => {
        let ($y, $($x),*) = tuplet!($v ; 1 ; ($($x),*) ; (&$v[0]) );
    };
    { $v:expr ; $j:expr ; ($y:ident $(, $x:ident)*) ; ($($a:expr),*) } => {
        tuplet!( $v ; $j+1 ; ($($x),*) ; ($($a),*,&$v[$j]) )
    };
    { $v:expr ; $j:expr ; () ; $accu:expr } => {
        $accu
    }
}

/// Sample two elements from the slice.
pub fn sample_two<T>(collection: &[T]) -> (&T, &T) {
    tuplet!((a, b) = sample(collection, 2));
    (a, b)
}

/// Sample two elements from the slice that satisfy the predicate.
pub fn sample_two_fn<T, F>(collection: &[T], f: F) -> (&T, &T)
where
    F: Fn(&T) -> bool,
{
    tuplet!((a, b) = sample_fn(collection, 2, &f));
    (a, b)
}

/// Sample three elements from the slice.
pub fn sample_three<T>(collection: &[T]) -> (&T, &T, &T) {
    tuplet!((a, b, c) = sample(collection, 3));
    (a, b, c)
}

/// Sample three elements from the slice that satisfy the predicate.
pub fn sample_three_fn<T, F>(collection: &[T], f: F) -> (&T, &T, &T)
where
    F: Fn(&T) -> bool,
{
    tuplet!((a, b, c) = sample_fn(collection, 3, &f));
    (a, b, c)
}

#[cfg(test)]
mod tests {
    use crate::sampler::{
        sample, sample_fn, sample_one, sample_one_fn, sample_three, sample_three_fn, sample_two,
        sample_two_fn,
    };

    #[test]
    fn test_sample_one() {
        let c = vec![1];
        assert_eq!(*sample_one(&c), 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_one_panics() {
        let c: Vec<usize> = vec![];
        sample_one(&c);
    }

    #[test]
    fn test_sample_one_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_one(&c);
        }
    }

    #[test]
    fn test_sample_one_fn() {
        let c = vec![1, 2];
        assert_eq!(*sample_one_fn(&c, |el| *el == 1), 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_one_fn_panics() {
        let c = vec![1, 2];
        sample_one_fn(&c, |_| false);
    }

    #[test]
    fn test_sample_one_fn_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_one_fn(&c, |el| *el % 2 == 0);
        }
    }

    #[test]
    fn test_sample() {
        let c = vec![1, 2, 3];
        let mut res = sample(&c, 3);
        res.sort();
        assert_eq!(res, c.iter().collect::<Vec<_>>());
    }

    #[test]
    #[should_panic]
    fn test_sample_panic1() {
        let c = vec![1, 2, 3];
        sample(&c, 4);
    }

    #[test]
    #[should_panic]
    fn test_sample_panic2() {
        let c: Vec<usize> = vec![];
        sample(&c, 1);
    }

    #[test]
    fn test_sample_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            let mut res = sample(&c, len);
            res.sort();
            assert_eq!(res, c.iter().collect::<Vec<_>>());
        }
    }

    #[test]
    fn test_sample_fn() {
        let c = vec![1, 2, 3];
        let mut res = sample_fn(&c, 2, |e| *e > 1);
        res.sort();
        assert_eq!(res, c[1..].iter().collect::<Vec<_>>());
    }

    #[test]
    #[should_panic]
    fn test_sample_fn_panic1() {
        let c = vec![1, 2, 3];
        sample_fn(&c, 3, |e| *e > 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_fn_panic2() {
        let c: Vec<usize> = vec![];
        sample_fn(&c, 1, |_| true);
    }

    #[test]
    fn test_sample_fn_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_fn(&c, (len + 1) / 2, |e| (*e) % 2 == 0);
        }
    }

    #[test]
    fn test_sample_two() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 2;
            let c: Vec<usize> = (0..len).collect();
            sample_two(&c);
        }
    }

    #[test]
    fn test_sample_two_fn() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 3;
            let c: Vec<usize> = (0..len).collect();
            sample_two_fn(&c, |e| *e > 0);
        }
    }

    #[test]
    fn test_sample_three() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 3;
            let c: Vec<usize> = (0..len).collect();
            sample_three(&c);
        }
    }

    #[test]
    fn test_sample_three_fn() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 4;
            let c: Vec<usize> = (0..len).collect();
            sample_three_fn(&c, |e| *e > 0);
        }
    }
}

'''
'''--- test-utils/loadtester/src/stats.rs ---
use crate::remote_node::{get_result, RemoteNode, MAX_BLOCKS_FETCH};
use std::cmp::min;
use std::sync::atomic::{AtomicU64, Ordering};
use std::time::Instant;

/// Stats measured while executing load testing on the node.
pub struct Stats {
    /// Block height at the beginning of the testing.
    pub from_height: Option<u64>,
    /// Timestamp at the beginning of the testing.
    pub from_timestamp: Option<Instant>,
    /// Block height at the end of the testing.
    pub to_height: Option<u64>,
    /// Timestamp at the end of the testing.
    pub to_timestamp: Option<Instant>,
    /// Counter for outgoing transactions.
    pub out_tx_counter: AtomicU64,
    pub out_tx_counter_frozen: Option<u64>,
    /// Number of committed transactions.
    pub committed_transacionts: Option<u64>,
}

impl std::fmt::Display for Stats {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> Result<(), std::fmt::Error> {
        let from_height = self.from_height.unwrap();
        let to_height = self.to_height.unwrap();
        let blocks_passed = to_height - from_height + 1;
        let time_passed =
            self.to_timestamp.unwrap().duration_since(self.from_timestamp.unwrap()).as_secs();
        let bps = (blocks_passed as f64) / (time_passed as f64);
        let total_txs = self.committed_transacionts.unwrap();

        write!(f, "Start block:\t{}\n", from_height)?;
        write!(f, "End block:\t{}\n", to_height)?;
        write!(f, "Time passed:\t{} secs\n", time_passed)?;
        write!(f, "Blocks per second:\t{:.2}\n", bps)?;
        write!(f, "Transactions per second:\t{}\n", total_txs / time_passed)?;
        write!(
            f,
            "Outgoing transactions per second:\t{}\n",
            self.out_tx_counter_frozen.unwrap() / time_passed
        )?;
        write!(f, "Transactions per block:\t{}", total_txs / blocks_passed)?;
        Ok(())
    }
}

impl Stats {
    pub fn new() -> Self {
        Self {
            from_height: None,
            from_timestamp: None,
            to_height: None,
            to_timestamp: None,
            out_tx_counter: AtomicU64::new(0),
            out_tx_counter_frozen: None,
            committed_transacionts: None,
        }
    }

    /// Count one outgoing transaction.
    pub fn inc_out_tx(&self) {
        self.out_tx_counter.fetch_add(1, Ordering::SeqCst);
    }

    /// Measure stats from this moment.
    pub fn measure_from(&mut self, node: &RemoteNode) {
        self.from_height = Some(get_result(|| node.get_current_height()));
        self.from_timestamp = Some(Instant::now());
    }

    /// Measure stats to this moment.
    pub fn measure_to(&mut self, node: &RemoteNode) {
        self.to_height = Some(get_result(|| node.get_current_height()));
        self.to_timestamp = Some(Instant::now());
        self.out_tx_counter_frozen = Some(self.out_tx_counter.load(Ordering::SeqCst));
    }

    /// Measures number of transactions that were committed.
    pub fn collect_transactions(&mut self, node: &RemoteNode) {
        let mut curr_height = self.from_height.unwrap() + 1;
        let mut total_tx = 0u64;
        loop {
            total_tx += get_result(|| {
                node.get_transactions(
                    curr_height,
                    min(curr_height + MAX_BLOCKS_FETCH, self.to_height.unwrap()),
                )
            });
            curr_height += MAX_BLOCKS_FETCH + 1;
            if curr_height > self.to_height.unwrap() {
                break;
            }
        }
        self.committed_transacionts = Some(total_tx);
    }
}

'''
'''--- test-utils/loadtester/src/transactions_executor.rs ---
//! Executes a single transaction or a list of transactions on a set of nodes.

use crate::remote_node::{try_wait, wait, RemoteNode};
use crate::stats::Stats;
use crate::transactions_generator::{Generator, TransactionType};
use futures::future::Future;
use futures::sink::Sink;
use futures::stream::Stream;
use std::sync::{Arc, RwLock};
use std::thread;
use std::thread::JoinHandle;
use std::time::{Duration, Instant};
use tokio::timer::Interval;
use tokio::util::FutureExt;

pub struct Executor {
    /// Nodes that can be used to generate nonces
    pub nodes: Vec<Arc<RwLock<RemoteNode>>>,
}

impl Executor {
    /// Deploys test contract to each account of each node and waits for it to be committed.
    #[allow(dead_code)]
    fn deploy_contract(nodes: &Vec<Arc<RwLock<RemoteNode>>>) {
        for n in nodes {
            // Create deploy contract transactions.
            let transactions = Generator::deploy_test_contract(n);
            let mut hashes = vec![];
            // Submit deploy contract transactions.
            for tx in transactions {
                hashes.push(wait(|| n.write().unwrap().add_transaction(tx.clone())));
            }
            // Wait for them to propagate.
            wait(|| {
                for h in &hashes {
                    try_wait(|| n.write().unwrap().transaction_committed(h))?;
                }
                Ok(())
            });
        }
    }

    pub fn spawn(
        nodes: Vec<Arc<RwLock<RemoteNode>>>,
        timeout: Option<Duration>,
        tps: u64,
        transaction_type: TransactionType,
    ) -> JoinHandle<()> {
        // Deploy the testing contract, if needed.
        if let TransactionType::Set | TransactionType::HeavyStorageBlock = transaction_type {
            //            Executor::deploy_contract(&nodes);
        }
        let stats = Arc::new(RwLock::new(Stats::new()));
        thread::spawn(move || {
            tokio::run(futures::lazy(move || {
                // Channels into which we can signal to send a transaction.
                let mut signal_tx = vec![];
                let all_account_ids: Vec<_> = nodes
                    .iter()
                    .map(|n| {
                        n.read()
                            .unwrap()
                            .signers
                            .iter()
                            .map(|s| s.account_id.clone())
                            .collect::<Vec<_>>()
                    })
                    .flatten()
                    .collect();

                for node in &nodes {
                    for (signer_ind, _) in node.read().unwrap().signers.iter().enumerate() {
                        let stats = stats.clone();
                        let node = node.clone();
                        let all_account_ids = all_account_ids.to_vec();
                        let (tx, rx) = tokio::sync::mpsc::channel(1024);
                        signal_tx.push(tx);
                        // Spawn a task that sends transactions only from the given account making
                        // sure the nonces are correct.
                        tokio::spawn(
                            rx.map_err(|_| ())
                                .for_each(move |_| {
                                    let stats = stats.clone();
                                    let t = match transaction_type {
                                        TransactionType::SendMoney => Generator::send_money(
                                            &node,
                                            signer_ind,
                                            &all_account_ids,
                                        ),
                                        TransactionType::Set => {
                                            Generator::call_set(&node, signer_ind)
                                        }
                                        TransactionType::HeavyStorageBlock => {
                                            Generator::call_heavy_storage_blocks(&node, signer_ind)
                                        }
                                    };
                                    let f = { node.write().unwrap().add_transaction_async(t) };
                                    f.map_err(|_| ())
                                        .timeout(Duration::from_secs(1))
                                        .map(move |_| {
                                            stats.read().unwrap().inc_out_tx();
                                        })
                                        .or_else(|_| Ok(())) // Ignore errors.
                                        .map_err(|_: ()| ())
                                })
                                .map(|_| ())
                                .map_err(|_| ()),
                        );
                    }
                }

                // Spawn the task that sets the tps.
                let interval =
                    Duration::from_nanos((Duration::from_secs(1).as_nanos() as u64) / tps);
                let timeout = timeout.map(|t| Instant::now() + t);
                let task = Interval::new_interval(interval)
                    .take_while(move |_| {
                        if let Some(t_limit) = timeout {
                            if t_limit <= Instant::now() {
                                // We hit timeout.
                                return Ok(false);
                            }
                        }
                        Ok(true)
                    })
                    .map_err(|_| ())
                    .for_each(move |_| {
                        let ind = rand::random::<usize>() % signal_tx.len();
                        let tx = signal_tx[ind].clone();
                        tx.send(()).map(|_| ()).map_err(|_| ())
                    })
                    .map(|_| ())
                    .map_err(|_| ());

                let node = nodes[0].clone();
                stats.write().unwrap().measure_from(&*node.write().unwrap());
                tokio::spawn(
                    task.then(move |_| {
                        futures::future::lazy(move || {
                            let mut stats = stats.write().unwrap();
                            stats.measure_to(&*node.write().unwrap());
                            stats.collect_transactions(&*node.write().unwrap());
                            println!("{}", stats);
                            Ok(())
                        })
                    })
                    .map_err(|_: ()| ()),
                );
                Ok(())
            }));
        })
    }
}

'''
'''--- test-utils/loadtester/src/transactions_generator.rs ---
//! Set of methods that construct transactions of various kind.

use std::sync::{Arc, RwLock};

use near_primitives::transaction::{
    DeployContractTransaction, FunctionCallTransaction, SignedTransaction, TransactionBody,
};

use crate::remote_node::RemoteNode;

#[derive(Clone, Copy)]
pub enum TransactionType {
    SendMoney,
    Set,
    HeavyStorageBlock,
}

pub struct Generator {}

impl Generator {
    /// Create send money transaction.
    pub fn send_money(
        node: &Arc<RwLock<RemoteNode>>,
        signer_ind: usize,
        all_accounts: &Vec<String>,
    ) -> SignedTransaction {
        let (signer_from, nonce) = {
            let mut node = node.write().unwrap();
            node.nonces[signer_ind] += 1;
            (node.signers[signer_ind].clone(), node.nonces[signer_ind])
        };

        let acc_from = signer_from.account_id.clone();
        let acc_to = loop {
            let ind = rand::random::<usize>() % all_accounts.len();
            if all_accounts[ind] != acc_from {
                break all_accounts[ind].clone();
            }
        };

        TransactionBody::send_money(nonce, acc_from.as_str(), acc_to.as_str(), 1)
            .sign(&*signer_from)
    }

    /// Returns transactions that deploy test contract to an every account used by the node.
    pub fn deploy_test_contract(node: &Arc<RwLock<RemoteNode>>) -> Vec<SignedTransaction> {
        let wasm_binary: &[u8] = include_bytes!("../../../tests/hello.wasm");
        let mut res = vec![];
        let mut node = node.write().unwrap();
        for ind in 0..node.signers.len() {
            node.nonces[ind] += 1;
            let nonce = node.nonces[ind];
            let signer = node.signers[ind].clone();
            let contract_id = signer.account_id.clone();
            let t = DeployContractTransaction {
                nonce,
                contract_id,
                wasm_byte_array: wasm_binary.to_vec(),
            };
            res.push(TransactionBody::DeployContract(t).sign(&*signer));
        }
        res
    }

    /// Create set key/value transaction.
    pub fn call_set(node: &Arc<RwLock<RemoteNode>>, signer_ind: usize) -> SignedTransaction {
        let (signer_from, nonce) = {
            let mut node = node.write().unwrap();
            node.nonces[signer_ind] += 1;
            (node.signers[signer_ind].clone(), node.nonces[signer_ind])
        };
        let acc_from = signer_from.account_id.clone();

        let key = rand::random::<usize>() % 1_000;
        let value = rand::random::<usize>() % 1_000;
        let t = FunctionCallTransaction {
            nonce,
            originator: acc_from.clone(),
            contract_id: acc_from,
            method_name: b"setKeyValue".to_vec(),
            args: format!("{{\"key\":\"{}\", \"value\":\"{}\"}}", key, value).as_bytes().to_vec(),
            amount: 1,
        };
        TransactionBody::FunctionCall(t).sign(&*signer_from)
    }

    /// Returns a transaction that calls `heavy_storage_blocks` on a contract.
    pub fn call_heavy_storage_blocks(
        node: &Arc<RwLock<RemoteNode>>,
        signer_ind: usize,
    ) -> SignedTransaction {
        let (signer_from, nonce) = {
            let mut node = node.write().unwrap();
            node.nonces[signer_ind] += 1;
            (node.signers[signer_ind].clone(), node.nonces[signer_ind])
        };
        let acc_from = signer_from.account_id.clone();

        let t = FunctionCallTransaction {
            nonce,
            originator: acc_from.clone(),
            contract_id: acc_from,
            method_name: b"heavy_storage_blocks".to_vec(),
            args: "{\"n\":1000}".as_bytes().to_vec(),
            amount: 1,
        };
        TransactionBody::FunctionCall(t).sign(&*signer_from)
    }
}

'''
'''--- test-utils/state-viewer/Cargo.toml ---
[package]
name = "state-viewer"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2018"

[dependencies]
clap = "2.32.0"
hex = "0.3"

near-primitives = { path = "../../core/primitives" }
near-store = { path = "../../core/store" }
node-runtime = { path = "../../runtime/runtime" }
near-chain = { path = "../../chain/chain" }
near = { path = "../../near" }
'''
'''--- test-utils/state-viewer/src/main.rs ---
use std::convert::TryFrom;
use std::path::PathBuf;

use clap::{App, Arg};

use near::config::GenesisConfig;
use near::{get_store_path, NightshadeRuntime};
use near_chain::{ChainStore, ChainStoreAccess};
use near_primitives::account::{AccessKey, Account};
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::hash;
use near_primitives::serialize::Decode;
use near_primitives::test_utils::init_integration_logger;
use near_primitives::transaction::Callback;
use near_primitives::utils::col;
use near_store::{create_store, DBValue, TrieIterator};
use node_runtime::ext::ACCOUNT_DATA_SEPARATOR;

const DEFAULT_BASE_PATH: &str = "";

fn to_printable(blob: &[u8]) -> String {
    if blob.len() > 60 {
        format!("{} bytes, hash: {}", blob.len(), hash(blob))
    } else {
        let ugly = blob.iter().find(|&&x| x < b' ').is_some();
        if ugly {
            return format!("0x{}", hex::encode(blob));
        }
        match String::from_utf8(blob.to_vec()) {
            Ok(v) => format!(" {}", v),
            Err(_e) => format!("0x{}", hex::encode(blob)),
        }
    }
}

fn print_state_entry(key: Vec<u8>, value: DBValue) {
    let column = &key[0..1];
    match column {
        col::ACCOUNT => {
            let separator = (1..key.len()).find(|&x| key[x] == ACCOUNT_DATA_SEPARATOR[0]);
            if let Some(separator) = separator {
                let account_name = to_printable(&key[1..separator]);
                let contract_key = to_printable(&key[(separator + 1)..]);
                println!(
                    "Storage {:?},{:?}: {:?}",
                    account_name,
                    contract_key,
                    to_printable(&value)
                );
            } else {
                let account: Account = Decode::decode(&value).unwrap();
                let account_name = to_printable(&key[1..]);
                println!("Account {:?}: {:?}", account_name, account);
            }
        }
        col::CALLBACK => {
            let _callback: Callback = Decode::decode(&value).unwrap();
            let callback_id = to_printable(&key[1..]);
            println!("Callback {}: {}", callback_id, to_printable(&value));
        }
        col::CODE => {
            let account_name = to_printable(&key[1..]);
            println!("Code for {:?}: {}", account_name, to_printable(&value));
        }
        col::ACCESS_KEY => {
            let separator = (1..key.len()).find(|&x| key[x] == col::ACCESS_KEY[0]).unwrap();
            let access_key: AccessKey = Decode::decode(&value).unwrap();
            let account_name = to_printable(&key[1..separator]);
            let public_key = PublicKey::try_from(&key[(separator + 1)..]).unwrap();
            println!("Access key {:?},{:?}: {:?}", account_name, public_key, access_key);
        }
        _ => {
            println!(
                "Unknown column {}, {:?}: {:?}",
                column[0],
                to_printable(&key[1..]),
                to_printable(&value)
            );
        }
    }
}

fn main() {
    init_integration_logger();
    let matches = App::new("state-viewer")
        .args(&[
            Arg::with_name("base_path")
                .short("d")
                .long("base-path")
                .value_name("PATH")
                .help("Specify a base path for persisted files.")
                .default_value(DEFAULT_BASE_PATH)
                .takes_value(true),
            Arg::with_name("genesis")
                .short("c")
                .long("chain-spec-file")
                .value_name("CHAIN_SPEC")
                .help("Specify a file location to read a custom chain spec.")
                .takes_value(true),
            Arg::with_name("devnet")
                .long("devnet")
                .help("Run with DevNet validator configuration (single alice.near validator)")
                .takes_value(false),
        ])
        .get_matches();
    let base_path = matches.value_of("base_path").map(PathBuf::from).unwrap();
    let genesis_config = if matches.is_present("devnet") {
        GenesisConfig::legacy_test(vec!["alice.near", "bob.near", "carol.near"], 1)
    } else {
        let chain_spec_path = matches.value_of("chain_spec_file").map(PathBuf::from);
        if let Some(path) = chain_spec_path {
            GenesisConfig::from_file(&path)
        } else {
            GenesisConfig::testing_spec(3, 2)
        }
    };

    let store = create_store(&get_store_path(&base_path));
    let mut chain_store = ChainStore::new(store.clone());

    let runtime = NightshadeRuntime::new(&base_path, store, genesis_config);
    let head = chain_store.head().unwrap();
    let last_header = chain_store.get_block_header(&head.last_block_hash).unwrap().clone();
    let state_root = chain_store.get_post_state_root(&head.last_block_hash).unwrap();
    let trie = TrieIterator::new(&runtime.trie, state_root).unwrap();

    println!("Storage root is {}, block height is {}", state_root, last_header.height);
    for item in trie {
        let (key, value) = item.unwrap();
        print_state_entry(key, value);
    }
}

'''
'''--- test-utils/testcgo/Cargo.toml ---
[package]
name = "testcgo"
version = "0.1.0"
authors = ["luomijie <zhiwei-luo@hotmail.com>"]
edition = "2018"

build = "src/build.rs"

[build-dependencies]
dunce = "0.1.1"

[dependencies]
'''
'''--- test-utils/testcgo/src/build.rs ---
extern crate dunce;
use std::{env, path::PathBuf};

fn main() {
    let library_name = "test";
    let library_format = "format";

    let root = PathBuf::from(env::var_os("CARGO_MANIFEST_DIR").unwrap());
    let library_dir = dunce::canonicalize(root.join("src")).unwrap();
    println!("cargo:rustc-link-lib=static={}", library_name);
    println!("cargo:rustc-link-lib=static={}", library_format);
    println!("cargo:rustc-link-search=native={}", env::join_paths(&[library_dir]).unwrap().to_str().unwrap());
}
'''
'''--- test-utils/testcgo/src/main.rs ---
fn main() {

}
'''
'''--- test-utils/testlib/Cargo.toml ---
[package]
name = "testlib"
version = "0.1.0"
edition = "2018"

[[bin]]
name = "run-nodes"
path = "src/run_nodes.rs"

[dependencies]
actix = "0.8.2"
clap = "2.32"
log = "0.4"
rand = "0.6"
rand_xorshift = "0.1"
serde = "1.0"
serde_json = "1.0.0"
tokio = "0.1"
futures = "0.1.25"
lazy_static = "1.3"
byteorder = "1.2"
tempdir = "0.3"
tokio-signal = "0.2"
protobuf = "2.4"

near-primitives = { path = "../../core/primitives" }
near-protos = { path = "../../core/protos" }
near-store = { path = "../../core/store" }
node-runtime = { path = "../../runtime/runtime" }
near-chain = { path = "../../chain/chain" }
near-client = { path = "../../chain/client" }
near-jsonrpc = { path = "../../chain/jsonrpc" }
near = { path = "../../near" }

[dependencies.reqwest]
version = "0.9"
features = ["rustls-tls", "trust-dns"]

'''
'''--- test-utils/testlib/src/actix_utils.rs ---
use std::sync::mpsc;

use actix::System;

pub struct ShutdownableThread {
    pub join: Option<std::thread::JoinHandle<()>>,
    pub actix_system: System,
}

impl ShutdownableThread {
    pub fn start<F>(name: &'static str, f: F) -> ShutdownableThread
    where
        F: FnOnce() + Send + 'static,
    {
        let (tx, rx) = mpsc::channel();
        let join = std::thread::spawn(move || {
            let system = System::new(name);
            f();
            tx.send(System::current()).unwrap();
            system.run().unwrap();
            ()
        });

        let actix_system = rx.recv().unwrap();
        ShutdownableThread { join: Some(join), actix_system }
    }

    pub fn shutdown(&self) {
        self.actix_system.stop();
    }
}

impl Drop for ShutdownableThread {
    fn drop(&mut self) {
        self.shutdown();
        self.join.take().unwrap().join().unwrap();
    }
}

'''
'''--- test-utils/testlib/src/generate_test_spec.rs ---
///! Generate a ChainSpec that can be used for running alphanet.
///! The account names created during generation are: near.0, near.1, etc.
use clap::{App, Arg};
use node_runtime::chain_spec::{AuthorityRotation, ChainSpec, DefaultIdType};
use std::path::PathBuf;

fn main() {
    let chain_spec_path_arg = &Arg::with_name("chain_spec_file")
        .short("c")
        .long("chain-spec-file")
        .value_name("CHAIN-SPEC-FILE")
        .help("Sets file location for chain spec")
        .default_value("node/configs/res/alphanet_chain.json")
        .required(true)
        .takes_value(true);
    let num_accounts_arg = &Arg::with_name("number_of_accounts")
        .short("n")
        .long("number-of-accounts")
        .value_name("NUMBER-OF-ACCOUNTS")
        .help("Sets the number of accounts to be generated in the chainspec.")
        .default_value("4")
        .required(true)
        .takes_value(true);
    let num_init_auth_arg = &Arg::with_name("number_of_init_authorities")
        .short("a")
        .long("number-of-init_authorities")
        .value_name("NUMBER-OF-INIT_AUTHORITIES")
        .help("Sets the number of initial authorities to be generated in the chainspec.")
        .default_value("4")
        .required(true)
        .takes_value(true);
    let matches = App::new("keystore")
        .arg(chain_spec_path_arg)
        .arg(num_accounts_arg)
        .arg(num_init_auth_arg)
        .get_matches();

    let chain_spec_file = matches.value_of("chain_spec_file").map(PathBuf::from).unwrap();
    let num_accounts =
        matches.value_of("number_of_accounts").map(|x| x.parse::<usize>().unwrap()).unwrap();
    let num_init_auth = matches
        .value_of("number_of_init_authorities")
        .map(|x| x.parse::<usize>().unwrap())
        .unwrap();
    let (chain_spec, _) = ChainSpec::testing_spec(
        DefaultIdType::Enumerated,
        num_accounts,
        num_init_auth,
        AuthorityRotation::ProofOfAuthority,
    );
    chain_spec.write_to_file(&chain_spec_file);
}

'''
'''--- test-utils/testlib/src/lib.rs ---
pub mod actix_utils;
pub mod node;
pub mod runtime_utils;
pub mod standard_test_cases;
pub mod test_helpers;
pub mod user;

'''
'''--- test-utils/testlib/src/node/mod.rs ---
use std::panic;
use std::sync::Arc;
use std::sync::RwLock;

use near::config::{
    create_testnet_configs, create_testnet_configs_from_seeds, Config, GenesisConfig,
};
use near::NearConfig;
use near_primitives::crypto::signer::{EDSigner, InMemorySigner};
use near_primitives::serialize::to_base;
use near_primitives::transaction::SignedTransaction;
use near_primitives::types::{AccountId, Balance};
use node_runtime::state_viewer::AccountViewCallResult;

pub use crate::node::process_node::ProcessNode;
pub use crate::node::runtime_node::RuntimeNode;
pub use crate::node::thread_node::ThreadNode;
use crate::user::{AsyncUser, User};

mod process_node;
mod runtime_node;
mod thread_node;

pub const TEST_BLOCK_FETCH_LIMIT: u64 = 5;
pub const TEST_BLOCK_MAX_SIZE: u32 = 1000;

pub fn configure_chain_spec() -> GenesisConfig {
    GenesisConfig::test(vec!["alice.near", "bob.near"])
}

/// Config that can be used to start a node or connect to an existing node.
#[allow(clippy::large_enum_variant)]
pub enum NodeConfig {
    /// A node with only runtime and state that is used to run runtime tests.
    Runtime { account_id: AccountId },
    /// A complete node with network, RPC, client, consensus and all tasks running in a thead.
    /// Should be the default choice for the tests, since it provides the most control through the
    /// internal access.
    Thread(NearConfig),
    /// A complete noe running in a subprocess. Can be started and stopped, but besides that all
    /// interactions are limited to what is exposed through RPC.
    Process(NearConfig),
}

pub trait Node: Send + Sync {
    fn account_id(&self) -> Option<AccountId>;

    fn start(&mut self);

    fn kill(&mut self);

    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        self.user().view_account(account_id)
    }

    fn view_balance(&self, account_id: &AccountId) -> Result<Balance, String> {
        self.user().view_balance(account_id)
    }

    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        self.user().add_transaction(transaction)
    }

    fn get_account_nonce(&self, account_id: &AccountId) -> Option<u64> {
        self.user().get_account_nonce(account_id)
    }

    fn signer(&self) -> Arc<dyn EDSigner>;

    fn is_running(&self) -> bool;

    fn user(&self) -> Box<dyn User>;

    fn async_user(&self) -> Box<dyn AsyncUser> {
        unimplemented!()
    }

    fn as_thread_ref(&self) -> &ThreadNode {
        unimplemented!()
    }

    fn as_thread_mut(&mut self) -> &mut ThreadNode {
        unimplemented!()
    }

    fn as_process_ref(&self) -> &ProcessNode {
        unimplemented!()
    }

    fn as_process_mut(&mut self) -> &mut ProcessNode {
        unimplemented!()
    }
}

impl dyn Node {
    pub fn new_sharable(config: NodeConfig) -> Arc<RwLock<dyn Node>> {
        match config {
            NodeConfig::Runtime { account_id } => {
                Arc::new(RwLock::new(RuntimeNode::new(&account_id)))
            }
            NodeConfig::Thread(config) => Arc::new(RwLock::new(ThreadNode::new(config))),
            NodeConfig::Process(config) => Arc::new(RwLock::new(ProcessNode::new(config))),
        }
    }

    pub fn new(config: NodeConfig) -> Box<dyn Node> {
        match config {
            NodeConfig::Runtime { account_id } => Box::new(RuntimeNode::new(&account_id)),
            NodeConfig::Thread(config) => Box::new(ThreadNode::new(config)),
            NodeConfig::Process(config) => Box::new(ProcessNode::new(config)),
        }
    }
}

fn near_configs_to_node_configs(
    configs: Vec<Config>,
    signers: Vec<InMemorySigner>,
    network_signers: Vec<InMemorySigner>,
    genesis_config: GenesisConfig,
) -> Vec<NodeConfig> {
    let mut result = vec![];
    for i in 0..configs.len() {
        result.push(NodeConfig::Thread(NearConfig::new(
            configs[i].clone(),
            &genesis_config,
            network_signers[i].clone().into(),
            Some(&signers[i].clone().into()),
        )))
    }
    result
}

pub fn create_nodes(num_nodes: usize, prefix: &str) -> Vec<NodeConfig> {
    let (configs, signers, network_signers, genesis_config) =
        create_testnet_configs(num_nodes, 0, prefix, true);
    near_configs_to_node_configs(configs, signers, network_signers, genesis_config)
}

pub fn create_nodes_from_seeds(seeds: Vec<String>) -> Vec<NodeConfig> {
    let code =
        to_base(include_bytes!("../../../../runtime/wasm/runtest/res/wasm_with_mem.wasm").as_ref());
    let contracts = seeds.iter().map(|seed| (seed.clone(), code.clone())).collect::<Vec<_>>();
    let (configs, signers, network_signers, mut genesis_config) =
        create_testnet_configs_from_seeds(seeds, 0, true);
    genesis_config.contracts = contracts;
    near_configs_to_node_configs(configs, signers, network_signers, genesis_config)
}

pub fn sample_two_nodes(num_nodes: usize) -> (usize, usize) {
    let i = rand::random::<usize>() % num_nodes;
    // Should be a different node.
    let mut j = rand::random::<usize>() % (num_nodes - 1);
    if j >= i {
        j += 1;
    }
    (i, j)
}

/// Sample a node for sending a transaction/checking balance
pub fn sample_queryable_node(nodes: &[Arc<RwLock<dyn Node>>]) -> usize {
    let num_nodes = nodes.len();
    let mut k = rand::random::<usize>() % num_nodes;
    while !nodes[k].read().unwrap().is_running() {
        k = rand::random::<usize>() % num_nodes;
    }
    k
}

'''
'''--- test-utils/testlib/src/node/process_node.rs ---
use std::path::Path;
use std::process::{Child, Command};
use std::sync::Arc;
use std::time::Duration;
use std::{env, thread};

use log::error;
use rand::Rng;

use near::config::NearConfig;
use near_primitives::crypto::signer::EDSigner;
use near_primitives::types::AccountId;

use crate::node::Node;
use crate::user::rpc_user::RpcUser;
use crate::user::User;

pub enum ProcessNodeState {
    Stopped,
    Running(Child),
}

pub struct ProcessNode {
    pub work_dir: String,
    pub config: NearConfig,
    pub state: ProcessNodeState,
}

impl Node for ProcessNode {
    fn account_id(&self) -> Option<AccountId> {
        match &self.config.block_producer {
            Some(bp) => Some(bp.account_id.clone()),
            None => None,
        }
    }

    fn start(&mut self) {
        match self.state {
            ProcessNodeState::Stopped => {
                let child =
                    self.get_start_node_command().spawn().expect("start node command failed");
                self.state = ProcessNodeState::Running(child);
                thread::sleep(Duration::from_secs(3));
            }
            ProcessNodeState::Running(_) => panic!("Node is already running"),
        }
    }

    fn kill(&mut self) {
        match self.state {
            ProcessNodeState::Running(ref mut child) => {
                child.kill().expect("kill failed");
                thread::sleep(Duration::from_secs(1));
                self.state = ProcessNodeState::Stopped;
            }
            ProcessNodeState::Stopped => panic!("Invalid state"),
        }
    }

    fn signer(&self) -> Arc<dyn EDSigner> {
        self.config.block_producer.clone().unwrap().signer.clone()
    }

    fn is_running(&self) -> bool {
        match self.state {
            ProcessNodeState::Stopped => false,
            ProcessNodeState::Running(_) => true,
        }
    }

    fn user(&self) -> Box<dyn User> {
        Box::new(RpcUser::new(&self.config.rpc_config.addr))
    }

    fn as_process_ref(&self) -> &ProcessNode {
        self
    }

    fn as_process_mut(&mut self) -> &mut ProcessNode {
        self
    }
}

impl ProcessNode {
    /// Side effect: reset_storage
    pub fn new(config: NearConfig) -> ProcessNode {
        let mut rng = rand::thread_rng();
        let work_dir = format!(
            "{}process_node_{}",
            env::temp_dir().as_path().to_str().unwrap(),
            rng.gen::<u64>()
        );
        let result = ProcessNode { config, work_dir, state: ProcessNodeState::Stopped };
        result.reset_storage();
        result
    }

    /// Clear storage directory and run keygen
    pub fn reset_storage(&self) {
        Command::new("rm").args(&["-r", &self.work_dir]).spawn().unwrap().wait().unwrap();
        self.config.save_to_dir(Path::new(&self.work_dir));
    }

    /// Side effect: writes chain spec file
    pub fn get_start_node_command(&self) -> Command {
        let mut command = Command::new("cargo");
        command.args(&["run", "-p", "near", "--", "--home", &self.work_dir, "run"]);
        command
    }
}

impl Drop for ProcessNode {
    fn drop(&mut self) {
        match self.state {
            ProcessNodeState::Running(ref mut child) => {
                let _ = child.kill().map_err(|_| error!("child process died"));
                std::fs::remove_dir_all(self.work_dir.clone()).unwrap();
            }
            ProcessNodeState::Stopped => {}
        }
    }
}

'''
'''--- test-utils/testlib/src/node/remote_node.rs ---
use crate::node::Node;
use crate::user::rpc_user::RpcUser;
use crate::user::{AsyncUser, User};
use primitives::crypto::signer::InMemorySigner;
use std::net::SocketAddr;
use std::sync::Arc;

pub struct RemoteNode {
    pub addr: SocketAddr,
    pub signer: Arc<InMemorySigner>,
}

impl RemoteNode {
    pub fn new(addr: SocketAddr, signer: Arc<InMemorySigner>) -> Self {
        Self { addr, signer }
    }
}

impl Node for RemoteNode {
    fn account_id(&self) -> Option<&String> {
        Some(&self.signer.account_id)
    }

    fn start(&mut self) {
        unimplemented!()
    }

    fn kill(&mut self) {
        unimplemented!()
    }

    fn signer(&self) -> Arc<InMemorySigner> {
        self.signer.clone()
    }

    fn is_running(&self) -> bool {
        self.user().get_best_block_index().is_some()
    }

    fn user(&self) -> Box<dyn User> {
        Box::new(RpcUser::new(self.addr))
    }

    fn async_user(&self) -> Box<dyn AsyncUser> {
        Box::new(RpcUser::new(self.addr))
    }
}

'''
'''--- test-utils/testlib/src/node/runtime_node.rs ---
use std::sync::{Arc, RwLock};

use near_primitives::crypto::signer::{EDSigner, InMemorySigner};
use near_primitives::transaction::{FunctionCallTransaction, TransactionBody};
use near_primitives::types::{AccountId, Balance};

use crate::node::Node;
use crate::runtime_utils::get_runtime_and_trie;
use crate::user::runtime_user::MockClient;
use crate::user::{RuntimeUser, User};

pub struct RuntimeNode {
    pub client: Arc<RwLock<MockClient>>,
    pub signer: Arc<InMemorySigner>,
}

impl RuntimeNode {
    pub fn new(account_id: &AccountId) -> Self {
        let signer = Arc::new(InMemorySigner::from_seed(account_id, account_id));
        let (runtime, trie, root) = get_runtime_and_trie();
        let client = Arc::new(RwLock::new(MockClient { runtime, trie, state_root: root }));
        RuntimeNode { signer, client }
    }

    pub fn send_money(&self, account_id: &AccountId, amount: Balance) {
        let nonce = self.get_account_nonce(&self.account_id().unwrap()).unwrap_or_default() + 1;
        let transaction =
            TransactionBody::send_money(nonce, &self.account_id().unwrap(), account_id, amount)
                .sign(&*self.signer());
        self.user().add_transaction(transaction).unwrap();
    }

    pub fn call_function(
        &self,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        amount: Balance,
    ) {
        let account_id = self.account_id().unwrap();
        let nonce = self.get_account_nonce(&account_id).unwrap_or_default() + 1;
        let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
            nonce,
            originator: account_id.to_string(),
            contract_id: contract_id.to_string(),
            method_name: method_name.as_bytes().to_vec(),
            args,
            amount,
        })
        .sign(&*self.signer());
        self.user().add_transaction(transaction).unwrap();
    }
}

impl Node for RuntimeNode {
    fn account_id(&self) -> Option<AccountId> {
        Some(self.signer.account_id.clone())
    }

    fn start(&mut self) {}

    fn kill(&mut self) {}

    fn signer(&self) -> Arc<dyn EDSigner> {
        self.signer.clone()
    }

    fn is_running(&self) -> bool {
        true
    }

    fn user(&self) -> Box<dyn User> {
        Box::new(RuntimeUser::new(&self.signer.account_id, self.client.clone()))
    }
}

#[cfg(test)]
mod tests {
    use crate::node::runtime_node::RuntimeNode;
    use crate::node::Node;

    #[test]
    pub fn test_send_money() {
        let node = RuntimeNode::new(&"alice.near".to_string());
        node.send_money(&"bob.near".to_string(), 1);
        let (alice1, bob1) = (
            node.view_balance(&"alice.near".to_string()).unwrap(),
            node.view_balance(&"bob.near".to_string()).unwrap(),
        );
        node.send_money(&"bob.near".to_string(), 1);
        let (alice2, bob2) = (
            node.view_balance(&"alice.near".to_string()).unwrap(),
            node.view_balance(&"bob.near".to_string()).unwrap(),
        );
        assert_eq!(alice2, alice1 - 1);
        assert_eq!(bob2, bob1 + 1);
    }

}

'''
'''--- test-utils/testlib/src/node/shard_client_node.rs ---
use crate::node::{Node, ProcessNode, ThreadNode, TEST_BLOCK_MAX_SIZE};
use crate::user::{ShardClientUser, User};
use configs::ClientConfig;
use primitives::crypto::signer::InMemorySigner;
use primitives::types::AccountId;
use shard::ShardClient;
use std::sync::Arc;
use storage::test_utils::create_beacon_shard_storages;

pub struct ShardClientNode {
    pub client: Arc<ShardClient>,
    pub signer: Arc<InMemorySigner>,
}

impl ShardClientNode {
    pub fn new(config: ClientConfig) -> Self {
        let account_id = &config.account_id.unwrap();
        let signer = Arc::new(InMemorySigner::from_seed(account_id, account_id));
        let (_, shard_storage) = create_beacon_shard_storages();

        let chain_spec = &config.chain_spec;
        let shard_client =
            ShardClient::new(Some(signer.clone()), chain_spec, shard_storage, TEST_BLOCK_MAX_SIZE);
        ShardClientNode { client: Arc::new(shard_client), signer }
    }
}

impl Node for ShardClientNode {
    fn account_id(&self) -> Option<&AccountId> {
        Some(&self.signer.account_id)
    }

    fn start(&mut self) {}

    fn kill(&mut self) {}

    fn signer(&self) -> Arc<InMemorySigner> {
        self.signer.clone()
    }

    fn as_process_mut(&mut self) -> &mut ProcessNode {
        unimplemented!()
    }

    fn as_thread_mut(&mut self) -> &mut ThreadNode {
        unimplemented!()
    }

    fn is_running(&self) -> bool {
        true
    }

    fn user(&self) -> Box<dyn User> {
        Box::new(ShardClientUser::new(self.client.clone()))
    }
}

'''
'''--- test-utils/testlib/src/node/thread_node.rs ---
use std::sync::Arc;

use near::{start_with_config, NearConfig};
use near_primitives::crypto::signer::EDSigner;
use near_primitives::types::AccountId;

use crate::actix_utils::ShutdownableThread;
use crate::node::Node;
use crate::user::rpc_user::RpcUser;
use crate::user::User;

pub enum ThreadNodeState {
    Stopped,
    Running(ShutdownableThread),
}

pub struct ThreadNode {
    pub config: NearConfig,
    pub state: ThreadNodeState,
}

fn start_thread(config: NearConfig) -> ShutdownableThread {
    ShutdownableThread::start("test", move || {
        let tmp_dir = tempdir::TempDir::new("thread_node").unwrap();
        start_with_config(tmp_dir.path(), config);
    })
}

impl Node for ThreadNode {
    fn account_id(&self) -> Option<AccountId> {
        match &self.config.block_producer {
            Some(bp) => Some(bp.account_id.clone()),
            None => None,
        }
    }

    fn start(&mut self) {
        let handle = start_thread(self.config.clone());
        self.state = ThreadNodeState::Running(handle);
    }

    fn kill(&mut self) {
        let state = std::mem::replace(&mut self.state, ThreadNodeState::Stopped);
        match state {
            ThreadNodeState::Stopped => panic!("Node is not running"),
            ThreadNodeState::Running(handle) => {
                handle.shutdown();
            }
        }
    }

    fn signer(&self) -> Arc<dyn EDSigner> {
        self.config.block_producer.clone().unwrap().signer.clone()
    }

    fn is_running(&self) -> bool {
        match self.state {
            ThreadNodeState::Stopped => false,
            ThreadNodeState::Running(_) => true,
        }
    }

    fn user(&self) -> Box<dyn User> {
        Box::new(RpcUser::new(&self.config.rpc_config.addr))
    }

    fn as_thread_ref(&self) -> &ThreadNode {
        self
    }

    fn as_thread_mut(&mut self) -> &mut ThreadNode {
        self
    }
}

impl ThreadNode {
    /// Side effects: create storage, open database, lock database
    pub fn new(config: NearConfig) -> ThreadNode {
        ThreadNode { config, state: ThreadNodeState::Stopped }
    }
}

'''
'''--- test-utils/testlib/src/nodes_monitor.rs ---
//! A struct that monitors the state of a group of nodes and answers:
//! * Whether nodes are online;
//! * Whether nodes are in sync;
//! * Whether any node is stuck
//! * Transaction throughput of the nodes.

use log::info;

use crate::node::Node;
use crate::sampler::sample_one;
use node_http::types::GetBlocksByIndexRequest;
use std::sync::{Arc, RwLock};
use std::thread;
use std::time::{Duration, Instant};

#[derive(Clone)]
pub enum NodeState {
    NotConnected,
    BestBlock(u64),
}

/// Stats about the block.
#[derive(Clone, Debug)]
pub struct BlockStats {
    /// When this block was observed. Note, ideally we want this to be a timestamp of when the block
    /// was produced, but we do not store such timestamp.
    timestamp: Instant,
    /// Number of transactions that this block contains.
    num_transactions: usize,
    /// The upper bound on the time it took to produce this block.
    time_since_prev: Option<Duration>,
    /// Index of the block.
    block_index: u64,
}

impl NodeState {
    pub fn is_running(&self) -> bool {
        match self {
            NodeState::BestBlock(_) => true,
            _ => false,
        }
    }
}

pub struct NodesMonitor {
    /// Nodes to monitor.
    nodes: Vec<Arc<RwLock<dyn Node>>>,
    /// States of the nodes.
    states: Arc<RwLock<Vec<NodeState>>>,
    /// Stats of the blocks.
    block_stats: Arc<RwLock<Vec<BlockStats>>>,
    /// How frequently should be check the state of the nodes.
    state_check_delay: Duration,
    /// How frequently we check for new blocks. We query only one node per update, also the update
    /// is pretty heavy, so `block_check_delay` can be less frequent than `state_check_delay`.
    block_check_delay: Duration,
    /// A variable indicating whether the background thread should shutdown.
    shutdown: Arc<RwLock<bool>>,
}

impl NodesMonitor {
    pub fn new(
        nodes: Vec<Arc<RwLock<dyn Node>>>,
        state_check_delay: Duration,
        block_check_delay: Duration,
    ) -> Self {
        let num_nodes = nodes.len();
        Self {
            nodes,
            states: Arc::new(RwLock::new(vec![NodeState::NotConnected; num_nodes])),
            block_stats: Default::default(),
            state_check_delay,
            block_check_delay,
            shutdown: Arc::new(RwLock::new(false)),
        }
    }

    /// Starts a background thread that updates the internal metrics.
    pub fn start(&self) {
        self.start_state_observer();
        self.start_block_observer();
    }

    fn start_state_observer(&self) {
        let shutdown = self.shutdown.clone();
        let state_check_delay = self.state_check_delay;
        let nodes = self.nodes.to_vec();
        let states = self.states.clone();
        thread::spawn(move || {
            while !*shutdown.read().unwrap() {
                for (node_ind, n) in nodes.iter().enumerate() {
                    let node_state = match n.read().unwrap().user().get_best_block_index() {
                        None => NodeState::NotConnected,
                        Some(block_ind) => NodeState::BestBlock(block_ind),
                    };
                    states.write().unwrap()[node_ind] = node_state;
                }
                thread::sleep(state_check_delay);
            }
        });
    }

    fn start_block_observer(&self) {
        let shutdown = self.shutdown.clone();
        let block_check_delay = self.block_check_delay;
        let nodes = self.nodes.to_vec();
        let states = self.states.clone();
        let block_stats = self.block_stats.clone();
        thread::spawn(move || {
            while !*shutdown.read().unwrap() {
                thread::sleep(block_check_delay);

                let leading_node = Self::leading_node(&nodes, &states);
                if leading_node.is_none() {
                    continue;
                }
                let leading_node = leading_node.unwrap();
                let leader_guard = leading_node.read().unwrap();
                info!(target: "observer", "Leader: {}", leader_guard.account_id().unwrap());

                // Get best block index from the leading node.
                let best_index = leader_guard.user().get_best_block_index();
                if best_index.is_none() {
                    continue;
                }
                let best_index = best_index.unwrap();
                info!(target: "observer", "Best index: {}", best_index);

                let mut block_stats_guard = block_stats.write().unwrap();
                let block_request = if block_stats_guard.is_empty() {
                    // If we have no stats then we just starting. Request the most recent block, only.
                    info!(target: "observer", "Requesting: {}..{}", best_index, best_index + 1);
                    GetBlocksByIndexRequest { start: Some(best_index), limit: Some(1) }
                } else {
                    // If we have stats then request all missing blocks.
                    let prev_block_index =
                        block_stats_guard.iter().map(|b| b.block_index).max().unwrap();
                    if prev_block_index >= best_index {
                        continue;
                    }
                    info!(target: "observer", "Requesting: {}..", prev_block_index + 1);
                    GetBlocksByIndexRequest { start: Some(prev_block_index + 1), limit: None }
                };

                // Request the blocks.
                let blocks = leader_guard.user().get_shard_blocks_by_index(block_request);
                if blocks.is_err() {
                    continue;
                }
                let blocks = blocks.unwrap();
                let now = Instant::now();
                let time_since_prev =
                    block_stats_guard.last().map(|prev| now.duration_since(prev.timestamp));

                for b in &blocks.blocks {
                    info!(target: "observer", "Got block: {} #tx={}", b.body.header.index, b.body.transactions.len());
                    block_stats_guard.push(BlockStats {
                        num_transactions: b.body.transactions.len(),
                        timestamp: now,
                        block_index: b.body.header.index,
                        time_since_prev,
                    });
                }
            }
        });
    }

    /// Computes average tps based on the current block stats.
    pub fn average_tps(&self, window: Duration) -> Option<u64> {
        let block_stats = self.block_stats.read().unwrap();
        // Check if there is enough blocks to compute tps.
        let enough_blocks =
            block_stats.last().map(|b| b.time_since_prev.is_some()).unwrap_or(false);
        if !enough_blocks {
            return None;
        }
        let end_timestamp = block_stats.last().unwrap().timestamp;

        // Cut off everything outside the window and compute number of transactions in that window.
        let window_transactions: usize = block_stats
            .iter()
            .filter(|s| s.timestamp + window >= end_timestamp && s.time_since_prev.is_some())
            .map(|s| s.num_transactions)
            .sum();
        let scale = Duration::from_secs(1).as_micros();
        Some(((scale as f64) * (window_transactions as f64) / (window.as_micros() as f64)) as u64)
    }

    /// Get a node that has the most up-to-date block index.
    fn leading_node(
        nodes: &[Arc<RwLock<dyn Node>>],
        states: &Arc<RwLock<Vec<NodeState>>>,
    ) -> Option<Arc<RwLock<dyn Node>>> {
        let guard = states.read().unwrap();
        let blocks: Vec<_> = guard
            .iter()
            .zip(nodes.iter())
            .filter_map(|(s, n)| match s {
                NodeState::NotConnected => None,
                NodeState::BestBlock(i) => Some((i, n.clone())),
            })
            .collect();
        if blocks.is_empty() {
            return None;
        }
        let max = blocks.iter().map(|(i, _)| *i).max().unwrap();
        let leading_blocks: Vec<_> =
            blocks.into_iter().filter_map(|(i, n)| if i == max { Some(n) } else { None }).collect();
        Some(sample_one(&leading_blocks).clone())
    }

    pub fn all_nodes_running(&self) -> bool {
        self.states.read().unwrap().iter().all(NodeState::is_running)
    }

    /// Returns if all nodes are in sync.
    /// Args:
    /// * `block_ind_tolerance`: maximum number of blocks a single node is allowed to be behind the
    /// leader, typically should be equal to 1.
    pub fn all_nodes_in_sync(&self, block_ind_tolerance: u64) -> bool {
        let guard = self.states.read().unwrap();
        let mut indices = vec![];
        for n in &*guard {
            indices.push(match n {
                NodeState::NotConnected => return false,
                NodeState::BestBlock(i) => i,
            });
        }
        let max = *indices.iter().cloned().max().unwrap();
        let min = *indices.iter().cloned().min().unwrap();
        min + block_ind_tolerance >= max
    }
}

impl Drop for NodesMonitor {
    fn drop(&mut self) {
        *self.shutdown.write().unwrap() = true;
    }
}

'''
'''--- test-utils/testlib/src/run_nodes.rs ---
///! Runs given number of nodes from scratch for testing / integration / load testing purposes.

use std::thread;
use std::time::Duration;

use clap::{App, Arg};

use near_primitives::test_utils::init_integration_logger;
use testlib::node::{create_nodes, Node, NodeConfig};

fn main() {
    init_integration_logger();

    let matches = App::new("run-nodes")
        .arg(Arg::with_name("num_nodes").short("n").long("num-nodes").value_name("NUM_NODES").required(true).default_value("7").takes_value(true))
        .get_matches();

    let num_nodes = matches.value_of("num_nodes").map(|x| x.parse::<usize>().unwrap()).unwrap();

    let mut nodes = create_nodes(num_nodes, "test");

    print!("Connect via RPC to: ");
    for i in 0..num_nodes {
        match &nodes[i] {
            NodeConfig::Thread(cfg) => print!("{}, ", cfg.rpc_config.addr),
            _ => (),
        }
    }
    println!();

    let nodes: Vec<_> = nodes.drain(..).map(|cfg| Node::new_sharable(cfg)).collect();

    // Start nodes.
    for i in 0..num_nodes {
        nodes[i].write().unwrap().start();
    }

    // Loop infinitely.
    loop {
        thread::sleep(Duration::from_secs(1))
    }
}

'''
'''--- test-utils/testlib/src/runtime_utils.rs ---
use std::sync::{Arc, Mutex};

use byteorder::{ByteOrder, LittleEndian};
use tempdir::TempDir;

use near::GenesisConfig;
use near_primitives::hash::{CryptoHash, hash};
use near_primitives::types::{AccountId, MerkleHash};
use near_store::{Trie, TrieUpdate};
use near_store::test_utils::create_trie;
use node_runtime::{Runtime, state_viewer::TrieViewer};
use node_runtime::ethereum::EthashProvider;

pub fn alice_account() -> AccountId {
    "alice.near".to_string()
}
pub fn bob_account() -> AccountId {
    "bob.near".to_string()
}
pub fn eve_account() -> AccountId {
    "eve.near".to_string()
}

pub fn default_code_hash() -> CryptoHash {
    let genesis_wasm = include_bytes!("../../../runtime/wasm/runtest/res/wasm_with_mem.wasm");
    hash(genesis_wasm)
}

pub fn get_runtime_and_trie_from_genesis(
    genesis_config: &GenesisConfig,
) -> (Runtime, Arc<Trie>, MerkleHash) {
    let trie = create_trie();
    let dir = TempDir::new("ethash_test").unwrap();
    let ethash_provider = Arc::new(Mutex::new(EthashProvider::new(dir.path())));
    let runtime = Runtime::new(ethash_provider);
    let trie_update = TrieUpdate::new(trie.clone(), MerkleHash::default());
    let (store_update, genesis_root) = runtime.apply_genesis_state(
        trie_update,
        &genesis_config.accounts.iter().map(|account_info| (account_info.account_id.clone(), account_info.public_key.clone(), account_info.amount)).collect::<Vec<_>>(),
        &genesis_config.validators.iter().map(|account_info| (account_info.account_id.clone(), account_info.public_key.clone(), account_info.amount)).collect::<Vec<_>>(),
        &genesis_config.contracts,
    );
    store_update.commit().unwrap();
    (runtime, trie, genesis_root)
}

pub fn get_runtime_and_trie() -> (Runtime, Arc<Trie>, MerkleHash) {
    let genesis_config = GenesisConfig::test(vec![&alice_account(), &bob_account(), "carol.near"]);
    get_runtime_and_trie_from_genesis(&genesis_config)
}

pub fn get_test_trie_viewer() -> (TrieViewer, TrieUpdate) {
    let (_, trie, root) = get_runtime_and_trie();
    let dir = TempDir::new("ethash_test").unwrap();
    let ethash_provider = Arc::new(Mutex::new(EthashProvider::new(dir.path())));
    let trie_viewer = TrieViewer::new(ethash_provider);
    let state_update = TrieUpdate::new(trie, root);
    (trie_viewer, state_update)
}

pub fn encode_int(val: i32) -> [u8; 4] {
    let mut tmp = [0u8; 4];
    LittleEndian::write_i32(&mut tmp, val);
    tmp
}

'''
'''--- test-utils/testlib/src/sampler.rs ---
//! Functions to sample a collection of objects. The functions that accept predicate optimize not
//! for the runtime complexity but for how many times it runs the predicate. It is useful for
//! predicates that do expensive invocations, e.g. querying a node.
use rand::seq::SliceRandom;
use rand::thread_rng;
use std::collections::HashSet;

const EMPTY_COLLECTION: &str = "Collection is expected to be non-empty";
const COLLECTION_TOO_SMALL: &str = "Collection size is less than sample size";
const COLLECTION_EXHAUSTED: &str =
    "Not enough elements in the collection that satisfy the predicate";

/// Get one item from the collection.
pub fn sample_one<T>(collection: &[T]) -> &T {
    collection.choose(&mut thread_rng()).expect(EMPTY_COLLECTION)
}

/// Get one item from the collection that satisfy the given predicate.
pub fn sample_one_fn<T, F>(collection: &[T], f: F) -> &T
where
    F: Fn(&T) -> bool,
{
    let mut attempted_indices = HashSet::new();
    let mut i;
    let mut res;
    loop {
        i = rand::random::<usize>() % collection.len();
        // Check if already attempted.
        if attempted_indices.contains(&i) {
            continue;
        };

        res = &collection[i];
        if f(res) {
            break;
        } else {
            attempted_indices.insert(i);
            assert!(attempted_indices.len() < collection.len(), COLLECTION_EXHAUSTED);
        }
    }
    res
}

/// Get several items from the collections.
pub fn sample<T>(collection: &[T], sample_size: usize) -> Vec<&T> {
    assert!(collection.len() >= sample_size, COLLECTION_TOO_SMALL);
    collection.choose_multiple(&mut thread_rng(), sample_size).collect()
}

/// Get several items from the collection that satisfy the given predicate.
pub fn sample_fn<T, F>(collection: &[T], sample_size: usize, f: F) -> Vec<&T>
where
    F: Fn(&T) -> bool,
{
    let mut attempted_indices = HashSet::new();
    let mut i;
    let mut res = vec![];
    loop {
        i = rand::random::<usize>() % collection.len();
        // Check if already attempted.
        if attempted_indices.contains(&i) {
            continue;
        };

        let el = &collection[i];
        if f(el) {
            res.push(el);
            if res.len() == sample_size {
                break;
            }
        }
        attempted_indices.insert(i);
        assert!(attempted_indices.len() < collection.len(), COLLECTION_EXHAUSTED);
    }
    res
}

/// Binds a tuple to a vector.
/// # Examples:
///
/// ```
/// let v = vec![1,2,3];
/// tuplet!((a,b,c) = v);
/// assert_eq!(a, &1);
/// assert_eq!(b, &2);
/// assert_eq!(c, &3);
/// ```
macro_rules! tuplet {
    { ($y:ident $(, $x:ident)*) = $v:expr } => {
        let ($y, $($x),*) = tuplet!($v ; 1 ; ($($x),*) ; (&$v[0]) );
    };
    { $v:expr ; $j:expr ; ($y:ident $(, $x:ident)*) ; ($($a:expr),*) } => {
        tuplet!( $v ; $j+1 ; ($($x),*) ; ($($a),*,&$v[$j]) )
    };
    { $v:expr ; $j:expr ; () ; $accu:expr } => {
        $accu
    }
}

/// Sample two elements from the slice.
pub fn sample_two<T>(collection: &[T]) -> (&T, &T) {
    tuplet!((a, b) = sample(collection, 2));
    (a, b)
}

/// Sample two elements from the slice that satisfy the predicate.
pub fn sample_two_fn<T, F>(collection: &[T], f: F) -> (&T, &T)
where
    F: Fn(&T) -> bool,
{
    tuplet!((a, b) = sample_fn(collection, 2, &f));
    (a, b)
}

/// Sample three elements from the slice.
pub fn sample_three<T>(collection: &[T]) -> (&T, &T, &T) {
    tuplet!((a, b, c) = sample(collection, 3));
    (a, b, c)
}

/// Sample three elements from the slice that satisfy the predicate.
pub fn sample_three_fn<T, F>(collection: &[T], f: F) -> (&T, &T, &T)
where
    F: Fn(&T) -> bool,
{
    tuplet!((a, b, c) = sample_fn(collection, 3, &f));
    (a, b, c)
}

#[cfg(test)]
mod tests {
    use crate::sampler::{
        sample, sample_fn, sample_one, sample_one_fn, sample_three, sample_three_fn, sample_two,
        sample_two_fn,
    };

    #[test]
    fn test_sample_one() {
        let c = vec![1];
        assert_eq!(*sample_one(&c), 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_one_panics() {
        let c: Vec<usize> = vec![];
        sample_one(&c);
    }

    #[test]
    fn test_sample_one_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_one(&c);
        }
    }

    #[test]
    fn test_sample_one_fn() {
        let c = vec![1, 2];
        assert_eq!(*sample_one_fn(&c, |el| *el == 1), 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_one_fn_panics() {
        let c = vec![1, 2];
        sample_one_fn(&c, |_| false);
    }

    #[test]
    fn test_sample_one_fn_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_one_fn(&c, |el| *el % 2 == 0);
        }
    }

    #[test]
    fn test_sample() {
        let c = vec![1, 2, 3];
        let mut res = sample(&c, 3);
        res.sort();
        assert_eq!(res, c.iter().collect::<Vec<_>>());
    }

    #[test]
    #[should_panic]
    fn test_sample_panic1() {
        let c = vec![1, 2, 3];
        sample(&c, 4);
    }

    #[test]
    #[should_panic]
    fn test_sample_panic2() {
        let c: Vec<usize> = vec![];
        sample(&c, 1);
    }

    #[test]
    fn test_sample_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            let mut res = sample(&c, len);
            res.sort();
            assert_eq!(res, c.iter().collect::<Vec<_>>());
        }
    }

    #[test]
    fn test_sample_fn() {
        let c = vec![1, 2, 3];
        let mut res = sample_fn(&c, 2, |e| *e > 1);
        res.sort();
        assert_eq!(res, c[1..].iter().collect::<Vec<_>>());
    }

    #[test]
    #[should_panic]
    fn test_sample_fn_panic1() {
        let c = vec![1, 2, 3];
        sample_fn(&c, 3, |e| *e > 1);
    }

    #[test]
    #[should_panic]
    fn test_sample_fn_panic2() {
        let c: Vec<usize> = vec![];
        sample_fn(&c, 1, |_| true);
    }

    #[test]
    fn test_sample_fn_many() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 10 + 1;
            let c: Vec<usize> = (0..len).collect();
            sample_fn(&c, (len + 1) / 2, |e| (*e) % 2 == 0);
        }
    }

    #[test]
    fn test_sample_two() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 2;
            let c: Vec<usize> = (0..len).collect();
            sample_two(&c);
        }
    }

    #[test]
    fn test_sample_two_fn() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 3;
            let c: Vec<usize> = (0..len).collect();
            sample_two_fn(&c, |e| *e > 0);
        }
    }

    #[test]
    fn test_sample_three() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 3;
            let c: Vec<usize> = (0..len).collect();
            sample_three(&c);
        }
    }

    #[test]
    fn test_sample_three_fn() {
        for _ in 0..100 {
            let len = rand::random::<usize>() % 4 + 4;
            let c: Vec<usize> = (0..len).collect();
            sample_three_fn(&c, |e| *e > 0);
        }
    }
}

'''
'''--- test-utils/testlib/src/standard_test_cases.rs ---
use near::config::{TESTING_INIT_BALANCE, TESTING_INIT_STAKE};
use near_primitives::account::AccessKey;
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::hash::{hash, CryptoHash};
use near_primitives::serialize::Decode;
use near_primitives::transaction::{
    AddKeyTransaction, AsyncCall, Callback, CallbackInfo, CallbackResult, CreateAccountTransaction,
    DeleteKeyTransaction, DeployContractTransaction, FinalTransactionStatus,
    FunctionCallTransaction, ReceiptBody, ReceiptTransaction, SwapKeyTransaction, TransactionBody,
    TransactionStatus,
};
use near_primitives::types::Balance;
use near_primitives::utils::key_for_callback;
use near_store::set;
use node_runtime::state_viewer::AccountViewCallResult;

use crate::node::{Node, RuntimeNode};
use crate::runtime_utils::{bob_account, default_code_hash, encode_int, eve_account};
use crate::test_helpers::wait;
use crate::user::User;

/// The amount to send with function call.
const FUNCTION_CALL_AMOUNT: Balance = 1_000_000_000_000;

/// validate transaction result in the case that it is successful and generates given number of receipts
/// recursively.
pub fn validate_tx_result(
    node_user: Box<dyn User>,
    root: CryptoHash,
    hash: &CryptoHash,
    receipt_depth: usize,
) {
    let mut transaction_result = node_user.get_transaction_result(&hash);
    if transaction_result.status != TransactionStatus::Completed {
        println!("Tx failed: {:?}", transaction_result);
    }
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    for _ in 0..receipt_depth {
        assert_eq!(transaction_result.receipts.len(), 1);
        transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
        if transaction_result.status != TransactionStatus::Completed {
            println!("Tx failed: {:?}", transaction_result);
        }
        assert_eq!(transaction_result.status, TransactionStatus::Completed);
    }
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

/// Adds given access key to the given account_id using signer2. Ruturns account_id and signer.
#[allow(clippy::borrowed_box)]
fn add_access_key(
    node: &impl Node,
    node_user: &Box<dyn User>,
    access_key: &AccessKey,
    signer2: &InMemorySigner,
) {
    let root = node_user.get_state_root();
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::AddKey(AddKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_key: signer2.public_key.0[..].to_vec(),
        access_key: Some(access_key.clone()),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);
    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

/// Wait until transaction finishes (either succeeds or fails).
#[allow(clippy::borrowed_box)]
pub fn wait_for_transaction(node_user: &Box<dyn User>, hash: &CryptoHash) {
    wait(
        || match node_user.get_transaction_final_result(hash).status {
            FinalTransactionStatus::Unknown | FinalTransactionStatus::Started => false,
            _ => true,
        },
        500,
        60000,
    );
}

pub fn test_smart_contract_simple(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: b"run_test".to_vec(),
        args: vec![],
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    validate_tx_result(node_user, root, &hash, 2);
}

pub fn test_smart_contract_bad_method_name(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: b"_run_test".to_vec(),
        args: vec![],
        amount: 0,
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_smart_contract_empty_method_name_with_no_tokens(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: vec![],
        args: vec![],
        amount: 0,
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_smart_contract_empty_method_name_with_tokens(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: vec![],
        args: vec![],
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    validate_tx_result(node_user, root, &hash, 1);
}

pub fn test_smart_contract_with_args(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: b"run_test".to_vec(),
        args: (2..4).flat_map(|x| encode_int(x).to_vec()).collect(),
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    validate_tx_result(node_user, root, &hash, 2);
}

pub fn test_async_call_with_no_callback(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let nonce = hash(&[1, 2, 3]);
    let receipt = ReceiptTransaction {
        originator: account_id.clone(),
        receiver: bob_account(),
        nonce,
        body: ReceiptBody::NewCall(AsyncCall::new(
            b"run_test".to_vec(),
            vec![],
            FUNCTION_CALL_AMOUNT,
            account_id.clone(),
        )),
    };

    let node_user = node.user();
    let hash = receipt.nonce;
    let root = node_user.get_state_root();
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_async_call_with_callback(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let args = (7..9).flat_map(|x| encode_int(x).to_vec()).collect();
    let refund_account = account_id;
    let mut callback = Callback::new(
        b"sum_with_input".to_vec(),
        args,
        FUNCTION_CALL_AMOUNT,
        refund_account.clone(),
    );
    callback.results.resize(1, None);
    let callback_id = [0; 32].to_vec();
    let mut async_call =
        AsyncCall::new(b"run_test".to_vec(), vec![], FUNCTION_CALL_AMOUNT, refund_account.clone());
    let callback_info = CallbackInfo::new(callback_id.clone(), 0, account_id.clone());
    async_call.callback = Some(callback_info.clone());
    let receipt = ReceiptTransaction::new(
        account_id.clone(),
        bob_account(),
        hash(&[1, 2, 3]),
        ReceiptBody::NewCall(async_call),
    );

    let node_user = node.user();
    let hash = receipt.nonce;
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.result, Some(encode_int(10).to_vec()));
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 2);

    let receipt_info = node_user.get_receipt_info(&transaction_result.receipts[0]).unwrap();
    assert_eq!(receipt_info.receipt.originator, bob_account());
    assert_eq!(receipt_info.receipt.receiver, account_id.clone());
    let callback_res = CallbackResult::new(callback_info.clone(), Some(encode_int(10).to_vec()));
    assert_eq!(receipt_info.receipt.body, ReceiptBody::Callback(callback_res));

    let receipt_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(receipt_result.receipts.len(), 0);

    let receipt_info = node_user.get_receipt_info(&transaction_result.receipts[1]).unwrap();
    assert_eq!(receipt_info.receipt.originator, bob_account());
    assert_eq!(receipt_info.receipt.receiver, account_id.clone());
    // TODO: Check refund receipt.
}

pub fn test_async_call_with_logs(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let nonce = hash(&[1, 2, 3]);
    let receipt = ReceiptTransaction {
        originator: account_id.clone(),
        receiver: bob_account(),
        nonce,
        body: ReceiptBody::NewCall(AsyncCall::new(
            b"log_something".to_vec(),
            vec![],
            FUNCTION_CALL_AMOUNT,
            account_id.clone(),
        )),
    };

    let node_user = node.user();
    let hash = receipt.nonce;
    let root = node_user.get_state_root();
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    assert_eq!(transaction_result.logs[0], "LOG: hello".to_string());
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_deposit_with_callback(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let args = (7..9).flat_map(|x| encode_int(x).to_vec()).collect();
    let refund_account = account_id;
    let mut callback = Callback::new(b"sum_with_input".to_vec(), args, 0, refund_account.clone());
    callback.results.resize(1, None);
    let callback_id = [0; 32].to_vec();
    let mut async_call = AsyncCall::new(vec![], vec![], 0, refund_account.clone());
    let callback_info = CallbackInfo::new(callback_id.clone(), 0, account_id.clone());
    async_call.callback = Some(callback_info.clone());
    let receipt = ReceiptTransaction::new(
        account_id.clone(),
        bob_account(),
        hash(&[1, 2, 3]),
        ReceiptBody::NewCall(async_call),
    );

    let node_user = node.user();
    let hash = receipt.nonce;
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.result, Some(vec![]));

    let receipt_info = node_user.get_receipt_info(&transaction_result.receipts[0]).unwrap();
    assert_eq!(receipt_info.receipt.originator, bob_account());
    assert_eq!(receipt_info.receipt.receiver, account_id.clone());
    let callback_res = CallbackResult::new(callback_info.clone(), Some(vec![]));
    assert_eq!(receipt_info.receipt.body, ReceiptBody::Callback(callback_res));
}

// This test only works with RuntimeNode because it requires modifying state.
pub fn test_callback(node: RuntimeNode) {
    let account_id = &node.account_id().unwrap();
    let refund_account = account_id;
    let mut callback = Callback::new(
        b"run_test_with_storage_change".to_vec(),
        vec![],
        FUNCTION_CALL_AMOUNT,
        refund_account.clone(),
    );
    callback.results.resize(1, None);
    let callback_id = [0; 32].to_vec();

    let mut state_update = node.client.read().unwrap().get_state_update();
    set(&mut state_update, key_for_callback(&callback_id), &callback);
    let (transaction, root) =
        state_update.finalize().unwrap().into(node.client.read().unwrap().trie.clone()).unwrap();
    {
        let mut client = node.client.write().unwrap();
        client.state_root = root;
        transaction.commit().unwrap();
    }

    let callback_info = CallbackInfo::new(callback_id.clone(), 0, account_id.clone());
    let receipt = ReceiptTransaction::new(
        account_id.clone(),
        bob_account(),
        hash(&[1, 2, 3]),
        ReceiptBody::Callback(CallbackResult::new(callback_info, None)),
    );

    let hash = receipt.nonce;
    let node_user = node.user();
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    let callback: Option<Callback> = node_user
        .view_state(account_id)
        .unwrap()
        .values
        .get(&key_for_callback(&callback_id))
        .and_then(|data| Decode::decode(&data).ok());
    assert!(callback.is_none());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_callback_failure(node: RuntimeNode) {
    let account_id = &node.account_id().unwrap();
    let refund_account = account_id;
    let mut callback = Callback::new(
        b"a_function_that_does_not_exist".to_vec(),
        vec![],
        0,
        refund_account.clone(),
    );
    callback.results.resize(1, None);
    let callback_id = [0; 32].to_vec();
    let mut state_update = node.client.read().unwrap().get_state_update();
    set(&mut state_update, key_for_callback(&callback_id.clone()), &callback);
    let (transaction, root) =
        state_update.finalize().unwrap().into(node.client.read().unwrap().trie.clone()).unwrap();
    {
        let mut client = node.client.write().unwrap();
        client.state_root = root;
        transaction.commit().unwrap();
    }

    let callback_info = CallbackInfo::new(callback_id.clone(), 0, account_id.clone());
    let receipt = ReceiptTransaction::new(
        account_id.clone(),
        bob_account(),
        hash(&[1, 2, 3]),
        ReceiptBody::Callback(CallbackResult::new(callback_info, None)),
    );

    let hash = receipt.nonce;
    let node_user = node.user();
    node_user.add_receipt(receipt).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    let callback: Option<Callback> = node_user
        .view_state(account_id)
        .unwrap()
        .values
        .get(&key_for_callback(&callback_id))
        .and_then(|data| Decode::decode(&data).ok());
    assert!(callback.is_none());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_nonce_update_when_deploying_contract(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let wasm_binary = include_bytes!("../../../runtime/wasm/runtest/res/wasm_with_mem.wasm");
    let transaction = TransactionBody::DeployContract(DeployContractTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        contract_id: account_id.clone(),
        wasm_byte_array: wasm_binary.to_vec(),
    })
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(node_user.get_account_nonce(account_id).unwrap(), 1);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_nonce_updated_when_tx_failed(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let transaction = TransactionBody::send_money(
        node.get_account_nonce(account_id).unwrap_or_default() + 1,
        account_id,
        &bob_account(),
        TESTING_INIT_BALANCE + 1,
    )
    .sign(&*node.signer());

    let node_user = node.user();
    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);

    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(node_user.get_account_nonce(account_id).unwrap(), 1);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
}

pub fn test_upload_contract(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: eve_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: 10,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let wasm_binary = include_bytes!("../../../runtime/wasm/runtest/res/wasm_with_mem.wasm");
    let transaction = TransactionBody::DeployContract(DeployContractTransaction {
        nonce: 1,
        contract_id: eve_account(),
        wasm_byte_array: wasm_binary.to_vec(),
    })
    .sign(&*node.signer());

    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let account = node_user.view_account(&eve_account()).unwrap();
    assert_eq!(account.code_hash, hash(wasm_binary));
}

pub fn test_redeploy_contract(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let test_binary = b"test_binary";
    let transaction = TransactionBody::DeployContract(DeployContractTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        contract_id: account_id.clone(),
        wasm_byte_array: test_binary.to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.code_hash, hash(test_binary));
}

pub fn test_send_money(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let money_used = 10;
    let transaction = TransactionBody::send_money(
        node.get_account_nonce(account_id).unwrap_or_default() + 1,
        account_id,
        &bob_account(),
        money_used,
    )
    .sign(&*node.signer());

    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE - money_used,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
    let result2 = node_user.view_account(&bob_account()).unwrap();
    let public_keys = result2.public_keys.clone();
    assert_eq!(
        result2,
        AccountViewCallResult {
            nonce: 0,
            account_id: bob_account(),
            public_keys,
            amount: TESTING_INIT_BALANCE + money_used,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
}

pub fn test_send_money_over_balance(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let money_used = TESTING_INIT_BALANCE + 1;
    let transaction = TransactionBody::send_money(
        node.get_account_nonce(account_id).unwrap_or_default() + 1,
        account_id,
        &bob_account(),
        money_used,
    )
    .sign(&*node.signer());

    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
    let result2 = node_user.view_account(&bob_account()).unwrap();
    let public_keys = result2.public_keys.clone();
    assert_eq!(
        result2,
        AccountViewCallResult {
            nonce: 0,
            account_id: bob_account(),
            public_keys,
            amount: TESTING_INIT_BALANCE,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
}

pub fn test_refund_on_send_money_to_non_existent_account(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let money_used = 10;
    let transaction = TransactionBody::send_money(
        node.get_account_nonce(account_id).unwrap_or_default() + 1,
        account_id,
        &eve_account(),
        money_used,
    )
    .sign(&*node.signer());

    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 1);
    wait_for_transaction(&node_user, &transaction_result.receipts[0]);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
    let result2 = node_user.view_account(&eve_account());
    assert!(result2.is_err());
}

pub fn test_create_account(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let money_used = 10;
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: eve_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: money_used,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE - money_used,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );

    let result2 = node_user.view_account(&eve_account()).unwrap();
    let public_keys = result2.public_keys.clone();
    assert_eq!(
        result2,
        AccountViewCallResult {
            nonce: 0,
            account_id: eve_account(),
            public_keys,
            amount: money_used,
            stake: 0,
            code_hash: hash(b""),
        }
    );
}

pub fn test_create_account_again(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let money_used = 10;
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: eve_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: money_used,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE - money_used,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );

    let result2 = node_user.view_account(&eve_account()).unwrap();
    let public_keys = result2.public_keys.clone();
    assert_eq!(
        result2,
        AccountViewCallResult {
            nonce: 0,
            account_id: eve_account(),
            public_keys,
            amount: money_used,
            stake: 0,
            code_hash: hash(b""),
        }
    );

    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: eve_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: money_used,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 1);
    wait_for_transaction(&node_user, &transaction_result.receipts[0]);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 2,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE - money_used,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
}

pub fn test_create_account_failure_invalid_name(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let mut root = node_user.get_state_root();
    let money_used = 10;
    for (counter, invalid_account_name) in [
        "eve",                               // too short
        "Alice.near",                        // capital letter
        "alice(near)",                       // brackets are invalid
        "long_of_the_name_for_real_is_hard", // too long
        "qq@qq*qq",                          // * is invalid
    ]
    .iter()
    .enumerate()
    {
        let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
            nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
            originator: account_id.clone(),
            new_account_id: invalid_account_name.to_string(),
            public_key: node.signer().public_key().0[..].to_vec(),
            amount: money_used,
        })
        .sign(&*node.signer());
        let tx_hash = transaction.get_hash();
        node_user.add_transaction(transaction).unwrap();
        wait_for_transaction(&node_user, &tx_hash);

        let new_root = node_user.get_state_root();
        assert_ne!(root, new_root);
        root = new_root;
        let transaction_result = node_user.get_transaction_result(&tx_hash);
        assert_eq!(transaction_result.status, TransactionStatus::Failed);
        let account = node_user.view_account(account_id).unwrap();
        assert_eq!(
            account,
            AccountViewCallResult {
                nonce: counter as u64 + 1,
                account_id: account_id.clone(),
                public_keys: vec![node.signer().public_key()],
                amount: TESTING_INIT_BALANCE,
                stake: TESTING_INIT_STAKE,
                code_hash: default_code_hash(),
            }
        );
    }
}

pub fn test_create_account_failure_already_exists(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let money_used = 10;
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: bob_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: money_used,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 1);
    wait_for_transaction(&node_user, &transaction_result.receipts[0]);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let result1 = node_user.view_account(account_id);
    assert_eq!(
        result1.unwrap(),
        AccountViewCallResult {
            nonce: 1,
            account_id: account_id.clone(),
            public_keys: vec![node.signer().public_key()],
            amount: TESTING_INIT_BALANCE,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );

    let result2 = node_user.view_account(&bob_account()).unwrap();
    let public_keys = result2.public_keys.clone();
    assert_eq!(
        result2,
        AccountViewCallResult {
            nonce: 0,
            account_id: bob_account(),
            public_keys,
            amount: TESTING_INIT_BALANCE,
            stake: TESTING_INIT_STAKE,
            code_hash: default_code_hash(),
        }
    );
}

pub fn test_swap_key(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let money_used = 10;
    let transaction = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_account_id: eve_account(),
        public_key: node.signer().public_key().0[..].to_vec(),
        amount: money_used,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);
    let transaction = TransactionBody::SwapKey(SwapKeyTransaction {
        nonce: node.get_account_nonce(&eve_account()).unwrap_or_default() + 1,
        originator: eve_account(),
        cur_key: node.signer().public_key().0[..].to_vec(),
        new_key: signer2.public_key.0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root1 = node_user.get_state_root();
    assert_ne!(new_root, new_root1);

    let account = node_user.view_account(&eve_account()).unwrap();
    assert_eq!(account.public_keys, vec![signer2.public_key]);
}

pub fn test_add_key(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let transaction = TransactionBody::AddKey(AddKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_key: signer2.public_key.0[..].to_vec(),
        access_key: None,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 2);
    assert_eq!(account.public_keys[1], signer2.public_key);
}

pub fn test_add_existing_key(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let transaction = TransactionBody::AddKey(AddKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_key: node.signer().public_key().0[..].to_vec(),
        access_key: None,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
}

pub fn test_delete_key(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let node_user = node.user();
    let root = node_user.get_state_root();
    let transaction = TransactionBody::AddKey(AddKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        new_key: signer2.public_key.0[..].to_vec(),
        access_key: None,
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(root, new_root);

    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: node.signer().public_key().0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root1 = node_user.get_state_root();
    assert_ne!(new_root1, new_root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
    assert_eq!(account.public_keys[0], signer2.public_key);
}

pub fn test_delete_key_not_owned(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let node_user = node.user();
    let root = node_user.get_state_root();

    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: signer2.public_key.0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(new_root, root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
}

pub fn test_delete_key_last(node: impl Node) {
    let account_id = &node.account_id().unwrap();
    let node_user = node.user();
    let root = node_user.get_state_root();

    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: node.signer().public_key().0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(new_root, root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 0);
}

pub fn test_add_access_key(node: impl Node) {
    let node_user = node.user();
    let access_key =
        AccessKey { amount: 0, balance_owner: None, contract_id: None, method_name: None };
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);

    let view_access_key = node_user.get_access_key(account_id, &signer2.public_key).unwrap();
    assert_eq!(view_access_key, Some(access_key));
}

pub fn test_delete_access_key(node: impl Node) {
    let node_user = node.user();
    let access_key =
        AccessKey { amount: 0, balance_owner: None, contract_id: None, method_name: None };
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let root = node_user.get_state_root();
    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: signer2.public_key.0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(new_root, root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
    assert_eq!(account.public_keys[0], node.signer().public_key());

    let view_access_key = node_user.get_access_key(account_id, &signer2.public_key).unwrap();
    assert_eq!(view_access_key, None);
}

pub fn test_add_access_key_with_funding(node: impl Node) {
    let access_key =
        AccessKey { amount: 10, balance_owner: None, contract_id: None, method_name: None };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let account = node_user.view_account(account_id).unwrap();
    let initial_balance = account.amount;
    add_access_key(&node, &node_user, &access_key, &signer2);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
    assert_eq!(account.amount, initial_balance - 10);

    let view_access_key = node_user.get_access_key(account_id, &signer2.public_key).unwrap();
    assert_eq!(view_access_key, Some(access_key));
}

pub fn test_delete_access_key_with_owner_refund(node: impl Node) {
    let access_key =
        AccessKey { amount: 10, balance_owner: None, contract_id: None, method_name: None };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let account = node_user.view_account(account_id).unwrap();
    let initial_balance = account.amount;
    add_access_key(&node, &node_user, &access_key, &signer2);

    let root = node_user.get_state_root();
    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: signer2.public_key.0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_ne!(new_root, root);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
    assert_eq!(account.public_keys[0], node.signer().public_key());
    assert_eq!(account.amount, initial_balance);

    let view_access_key = node_user.get_access_key(account_id, &signer2.public_key).unwrap();
    assert_eq!(view_access_key, None);
}

pub fn test_delete_access_key_with_bob_refund(node: impl Node) {
    let access_key = AccessKey {
        amount: 10,
        balance_owner: Some(bob_account()),
        contract_id: None,
        method_name: None,
    };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    let account = node_user.view_account(account_id).unwrap();
    let initial_balance = account.amount;
    let bob_account_result = node_user.view_account(&bob_account()).unwrap();
    let bobs_initial_balance = bob_account_result.amount;
    add_access_key(&node, &node_user, &access_key, &signer2);

    let root = node_user.get_state_root();
    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: signer2.public_key.0[..].to_vec(),
    })
    .sign(&*node.signer());
    let tx_hash = transaction.get_hash();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &tx_hash);

    let transaction_result = node_user.get_transaction_result(&tx_hash);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert_eq!(transaction_result.receipts.len(), 1);

    let account = node_user.view_account(account_id).unwrap();
    assert_eq!(account.public_keys.len(), 1);
    assert_eq!(account.public_keys[0], node.signer().public_key());
    assert_eq!(account.amount, initial_balance - 10);

    let view_access_key = node_user.get_access_key(account_id, &signer2.public_key).unwrap();
    assert_eq!(view_access_key, None);

    wait_for_transaction(&node_user, &transaction_result.receipts[0]);
    let transaction_result = node_user.get_transaction_result(&transaction_result.receipts[0]);
    assert_eq!(transaction_result.status, TransactionStatus::Completed);
    assert!(transaction_result.receipts.is_empty());
    let new_root = node_user.get_state_root();
    assert_ne!(new_root, root);

    let bob_account_result = node_user.view_account(&bob_account()).unwrap();
    assert_eq!(bob_account_result.amount, bobs_initial_balance + 10);
}

pub fn test_access_key_smart_contract(node: impl Node) {
    let access_key = AccessKey {
        amount: FUNCTION_CALL_AMOUNT,
        balance_owner: None,
        contract_id: Some(bob_account()),
        method_name: None,
    };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: b"run_test".to_vec(),
        args: vec![],
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&signer2);

    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    validate_tx_result(node_user, root, &hash, 2);
}

pub fn test_access_key_smart_contract_reject_method_name(node: impl Node) {
    let access_key = AccessKey {
        amount: 0,
        balance_owner: None,
        contract_id: Some(bob_account()),
        method_name: Some(b"log_something".to_vec()),
    };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: bob_account(),
        method_name: b"run_test".to_vec(),
        args: vec![],
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&signer2);

    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_eq!(root, new_root);
}

pub fn test_access_key_smart_contract_reject_contract_id(node: impl Node) {
    let access_key = AccessKey {
        amount: 0,
        balance_owner: None,
        contract_id: Some(bob_account()),
        method_name: None,
    };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let transaction = TransactionBody::FunctionCall(FunctionCallTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        contract_id: eve_account(),
        method_name: b"run_test".to_vec(),
        args: vec![],
        amount: FUNCTION_CALL_AMOUNT,
    })
    .sign(&signer2);

    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_eq!(root, new_root);
}

pub fn test_access_key_reject_non_function_call(node: impl Node) {
    let access_key =
        AccessKey { amount: 0, balance_owner: None, contract_id: None, method_name: None };
    let node_user = node.user();
    let account_id = &node.account_id().unwrap();
    let signer2 = InMemorySigner::from_random();
    add_access_key(&node, &node_user, &access_key, &signer2);

    let transaction = TransactionBody::DeleteKey(DeleteKeyTransaction {
        nonce: node.get_account_nonce(account_id).unwrap_or_default() + 1,
        originator: account_id.clone(),
        cur_key: node.signer().public_key().0[..].to_vec(),
    })
    .sign(&signer2);

    let hash = transaction.get_hash();
    let root = node_user.get_state_root();
    node_user.add_transaction(transaction).unwrap();
    wait_for_transaction(&node_user, &hash);
    let transaction_result = node_user.get_transaction_result(&hash);
    assert_eq!(transaction_result.status, TransactionStatus::Failed);
    assert_eq!(transaction_result.receipts.len(), 0);
    let new_root = node_user.get_state_root();
    assert_eq!(root, new_root);
}

'''
'''--- test-utils/testlib/src/test_helpers.rs ---
use crate::node::Node;
use lazy_static::lazy_static;
use std::process::Output;
use std::sync::{Arc, Mutex, RwLock};
use std::thread;
use std::time::Duration;

lazy_static! {
    static ref HEAVY_TESTS_LOCK: Mutex<()> = Mutex::new(());
}

pub fn heavy_test<F>(f: F)
where
    F: FnOnce() -> (),
{
    let _guard = HEAVY_TESTS_LOCK.lock();
    f();
}

pub fn check_result(output: Output) -> Result<String, String> {
    let mut result = String::from_utf8_lossy(output.stdout.as_slice());
    if !output.status.success() {
        if result.is_empty() {
            result = String::from_utf8_lossy(output.stderr.as_slice());
        }
        return Err(result.to_owned().to_string());
    }
    Ok(result.to_owned().to_string())
}

pub fn wait<F>(mut f: F, check_interval_ms: u64, max_wait_ms: u64)
where
    F: FnMut() -> bool,
{
    let mut ms_slept = 0;
    while !f() {
        thread::sleep(Duration::from_millis(check_interval_ms));
        ms_slept += check_interval_ms;
        if ms_slept > max_wait_ms {
            println!("BBBB Slept {}; max_wait_ms {}", ms_slept, max_wait_ms);
            panic!("Timed out waiting for the condition");
        }
    }
}

/// TODO it makes sense to have three types of wait checks:
/// Wait until sufficient number of nodes is caught up (> 2/3). This can be checked by looking at the block indices and verifying that the blocks are produced;
/// Wait until a certain node is caught up and participating in a consensus. Check first-layer BLS signatures;
/// Wait until all nodes are more-or-less caught up. Check that the max_block_index - min_block_index < threshold;
///
pub fn wait_for_catchup(nodes: &[Arc<RwLock<dyn Node>>]) {
    wait(
        || {
            let tips: Vec<_> = nodes
                .iter()
                .filter(|node| node.read().unwrap().is_running())
                .map(|node| node.read().unwrap().user().get_best_block_index())
                .collect();
            tips.iter().min() == tips.iter().max()
        },
        1000,
        10000,
    );
}

'''
'''--- test-utils/testlib/src/transactions_executor.rs ---
//! Executes a single transaction or a list of transactions on a set of nodes.

use crate::node::Node;
use crate::sampler::sample_one;
use crate::transactions_generator::{Generator, TransactionType};
use futures::future::Future;
use futures::stream::Stream;
use futures::sync::mpsc::{channel, Sender};
use primitives::transaction::SignedTransaction;
use primitives::types::AccountId;
use rand::distributions::{Distribution, Exp};
use std::collections::vec_deque::VecDeque;
use std::collections::HashMap;
use std::sync::{Arc, Mutex, RwLock};
use std::thread;
use std::thread::JoinHandle;
use std::time::{Duration, Instant};
use tokio::timer::{Delay, Interval};
use tokio::util::FutureExt;

/// How the messages should be sent to the nodes.
pub enum TrafficType {
    /// Messages are sent one after another.
    Regular,
    /// Submit transactions with random delay, following exponential distribution, which is commonly
    /// used to imitate network lag.
    ImitateLag {
        /// Mean latency.
        mean_delay: Duration,
    },
}

pub struct Executor {
    /// Nodes that can be used to generate nonces
    pub nodes: Vec<Arc<RwLock<dyn Node>>>,
}

impl Executor {
    /// Spawn executor in a separate thread.
    /// Args:
    /// * `nodes`: nodes to run on;
    /// * `transaction_type`: type of transaction to send;
    /// * `timeout`: if specified will terminate after the given time;
    /// * `transactions_limit`: if specified will terminate after submitting the given number of
    /// transactions;
    /// * `tps`: transactions-per-second;
    /// * `traffic_type`: how messages should be sent.
    pub fn spawn(
        nodes: Vec<Arc<RwLock<dyn Node>>>,
        transaction_type: TransactionType,
        timeout: Option<Duration>,
        transactions_limit: Option<usize>,
        tps: u64,
        traffic_type: TrafficType,
    ) -> JoinHandle<()> {
        let (tx_sender, tx_receiver) = channel(1000);
        Self::spawn_producer(nodes.to_vec(), tx_sender, transaction_type);

        // Schedule submission of transactions with random delays and given tps.
        // We use tokio because it allows to spawn a large number of tasks that will be resolved
        // some time in the future.
        thread::spawn(move || {
            let interval = Duration::from_nanos((Duration::from_secs(1).as_nanos() as u64) / tps);
            let timeout = timeout.map(|t| Instant::now() + t);
            #[allow(clippy::mutex_atomic)]
            let messages_sent = Arc::new(Mutex::new(0usize));
            tokio::run(
                Interval::new_interval(interval)
                    .take_while(move |_| {
                        let mut guard = messages_sent.lock().unwrap();
                        *guard += 1;
                        if let Some(t_limit) = transactions_limit {
                            if t_limit <= *guard {
                                // We hit transaction limit.
                                return Ok(false);
                            }
                        }

                        if let Some(t_limit) = timeout {
                            if t_limit > Instant::now() {
                                // We hit timeout.
                                return Ok(false);
                            }
                        }
                        Ok(true)
                    })
                    .map_err(|_| ()) // Timer errors are irrelevant.
                    .zip(tx_receiver)
                    .map(|(_, t)| t)
                    .for_each(move |t| {
                        let instant = match traffic_type {
                            TrafficType::Regular => Instant::now(),
                            TrafficType::ImitateLag { mean_delay } => {
                                Instant::now() + Self::sample_exp(mean_delay)
                            }
                        };
                        let node = sample_one(&nodes).clone();
                        tokio::spawn(
                            Delay::new(instant)
                                .map_err(|_| format!("Timer error"))
                                .and_then(move |_| {
                                    node.write().unwrap()
                                        .async_user().add_transaction(t)
                                        .timeout(Duration::from_secs(1))
                                        .map(|_| ())
                                        .map_err(|err| format!("Error sending transaction {}", err))
                                })
                                .map_err(|_| ())
                        );
                        Ok(())
                    })
                    .map(|_| ())
                    .map_err(|_| ()),
            );
        })
    }

    /// Get random duration according to exponential distribution.
    fn sample_exp(mean: Duration) -> Duration {
        let lambda = 1.0f64 / (mean.as_micros() as f64);
        let exp = Exp::new(lambda);
        Duration::from_micros(exp.sample(&mut rand::thread_rng()) as u64)
    }

    /// Spawn task that produces transactions.
    /// Args:
    /// * `nodes`: nodes with accounts that generate transactions;
    /// * `sender`: where to send the produced transactions;
    /// * `transaction_type`: what kind of transactions to send.
    fn spawn_producer(
        nodes: Vec<Arc<RwLock<dyn Node>>>,
        mut sender: Sender<SignedTransaction>,
        transaction_type: TransactionType,
    ) {
        thread::spawn(move || {
            let nonces = Self::get_nonces(&nodes);
            let mut generator = Generator::new(nodes, nonces).iter(transaction_type);
            let mut backlog = VecDeque::new();
            loop {
                if backlog.is_empty() {
                    backlog.push_back(generator.next().unwrap());
                }

                match sender.try_send(backlog.front().cloned().unwrap()) {
                    // The transaction was successfully processed. Pop it from the backlog.
                    Ok(()) => {
                        backlog.pop_front();
                    }
                    Err(err) => {
                        if err.is_disconnected() {
                            // The channel disconnected, we stop producing transactions.
                            break;
                        }
                        if err.is_full() {
                            // The channel is full, we wait a bit.
                            thread::sleep(Duration::from_millis(50));
                        }
                    }
                }
            }
        });
    }

    fn get_nonces(nodes: &Vec<Arc<RwLock<dyn Node>>>) -> RwLock<HashMap<AccountId, u64>> {
        let mut res = HashMap::new();
        for node in nodes {
            let guard = node.read().unwrap();
            let account_id = guard.account_id().unwrap().clone();
            let nonce = guard.user().view_account(&account_id).unwrap().nonce;
            // Since the first set of transactions is used for initialization (e.g. contract
            // deployment) we want them to get through, so we shift the nonces by 100 in case
            // there are other transactions that are send over to the testnet while we are computing
            // their nonces.
            res.insert(account_id, nonce + 100);
        }
        RwLock::new(res)
    }

    /// Submits transaction to a random node.
    pub fn submit_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        let node = sample_one(&self.nodes);
        node.write().unwrap().add_transaction(transaction)
    }
}

'''
'''--- test-utils/testlib/src/transactions_generator.rs ---
//! Set of methods that construct transactions of various kind.

use crate::node::Node;
use crate::sampler::{sample_one, sample_two};
use primitives::crypto::signer::InMemorySigner;
use primitives::transaction::{
    DeployContractTransaction, FunctionCallTransaction, SignedTransaction, TransactionBody,
};
use primitives::types::AccountId;
use std::collections::HashMap;
use std::iter::repeat_with;
use std::sync::{Arc, RwLock};

/// Keeps the context that is needed to generate a random transaction.
pub struct Generator {
    /// Nodes that can be used to generate nonces
    pub nodes: Vec<Arc<RwLock<dyn Node>>>,
    /// Tracks nonces for the accounts.
    nonces: RwLock<HashMap<AccountId, u64>>,
}

/// Type of transaction to generate.
pub enum TransactionType {
    Monetary,
    SetGet,
    HeavyStorage,
}

impl Generator {
    pub fn new(nodes: Vec<Arc<RwLock<dyn Node>>>, nonces: RwLock<HashMap<AccountId, u64>>) -> Self {
        Self { nodes, nonces }
    }

    /// Increments nonce and returns it.
    fn nonce(&self, node: &Arc<RwLock<dyn Node>>) -> u64 {
        *self
            .nonces
            .write()
            .unwrap()
            .entry(Self::account_id(node))
            .and_modify(|e| *e += 1)
            .or_insert(1)
    }

    /// Get account id of the given node.
    fn account_id(node: &Arc<RwLock<dyn Node>>) -> AccountId {
        node.read().unwrap().account_id().unwrap().clone()
    }

    /// Get in-memory-signer of the given node.
    fn signer(node: &Arc<RwLock<dyn Node>>) -> Arc<InMemorySigner> {
        node.read().unwrap().signer()
    }

    /// Create send money transaction.
    pub fn send_money(&mut self) -> SignedTransaction {
        let (alice, bob) = sample_two(&self.nodes);
        let nonce = self.nonce(alice);
        TransactionBody::send_money(
            nonce,
            Self::account_id(alice).as_str(),
            Self::account_id(bob).as_str(),
            1,
        )
        .sign(&*Self::signer(alice))
    }

    /// Returns transactions that deploy test contract to an account of every node.
    pub fn deploy_test_contract(&mut self) -> Vec<SignedTransaction> {
        let wasm_binary: &[u8] = include_bytes!("../../../tests/hello.wasm");
        let mut res = vec![];
        for node in &self.nodes {
            let t = DeployContractTransaction {
                nonce: self.nonce(node),
                contract_id: Self::account_id(node),
                wasm_byte_array: wasm_binary.to_vec(),
            };
            res.push(TransactionBody::DeployContract(t).sign(&*Self::signer(node)));
        }
        res
    }

    /// Returns a transaction that calls `setKeyValue` on a random contract from a random account.
    pub fn call_set(&mut self) -> SignedTransaction {
        let node = sample_one(&self.nodes);
        let key = rand::random::<usize>() % 1_000;
        let value = rand::random::<usize>() % 1_000;
        let t = FunctionCallTransaction {
            nonce: self.nonce(node),
            originator: Self::account_id(node),
            contract_id: Self::account_id(node),
            method_name: b"setKeyValue".to_vec(),
            args: format!("{{\"key\":\"{}\", \"value\":\"{}\"}}", key, value).as_bytes().to_vec(),
            amount: 1,
        };
        TransactionBody::FunctionCall(t).sign(&*Self::signer(node))
    }

    /// Returns a transaction that calls `setKeyValue` on a random contract.
    pub fn call_get(&mut self) -> SignedTransaction {
        let node = sample_one(&self.nodes);
        let key = rand::random::<usize>() % 1_000;
        let t = FunctionCallTransaction {
            nonce: self.nonce(node),
            originator: Self::account_id(node),
            contract_id: Self::account_id(node),
            method_name: b"getValueByKey".to_vec(),
            args: format!("{{\"key\":\"{}\"}}", key).as_bytes().to_vec(),
            amount: 1,
        };
        TransactionBody::FunctionCall(t).sign(&*Self::signer(node))
    }

    /// Returns a transaction that calls `heavy_storage_blocks` on a random contract.
    pub fn call_benchmark_storage(&mut self) -> SignedTransaction {
        let node = sample_one(&self.nodes);
        let t = FunctionCallTransaction {
            nonce: self.nonce(node),
            originator: Self::account_id(node),
            contract_id: Self::account_id(node),
            method_name: b"heavy_storage_blocks".to_vec(),
            args: "{\"n\":1000}".as_bytes().to_vec(),
            amount: 1,
        };
        TransactionBody::FunctionCall(t).sign(&*Self::signer(node))
    }

    /// Endlessly generates transactions of the given type.
    pub fn iter(
        mut self,
        transaction_type: TransactionType,
    ) -> impl Iterator<Item = SignedTransaction> {
        // Create transactions that do initialization for other transactions to be successful.
        let initialization_transactions = match &transaction_type {
            TransactionType::SetGet | TransactionType::HeavyStorage => self.deploy_test_contract(),
            _ => vec![],
        };
        // Create transactions that constitute the main load.
        let transactions = repeat_with(move || {
            match transaction_type {
                TransactionType::HeavyStorage => self.call_benchmark_storage(),
                TransactionType::Monetary => self.send_money(),
                TransactionType::SetGet => {
                    // Randomly execute set and get operators.
                    if rand::random::<bool>() {
                        self.call_set()
                    } else {
                        self.call_get()
                    }
                }
            }
        });
        initialization_transactions.into_iter().chain(transactions)
    }
}

'''
'''--- test-utils/testlib/src/user/mod.rs ---
use futures::Future;

use near_chain::Block;
use near_primitives::account::AccessKey;
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::CryptoHash;
use near_primitives::receipt::ReceiptInfo;
use near_primitives::transaction::{
    FinalTransactionResult, ReceiptTransaction, SignedTransaction, TransactionResult,
};
use near_primitives::types::{AccountId, Balance, MerkleHash};
use node_runtime::state_viewer::{AccountViewCallResult, ViewStateResult};

pub use crate::user::runtime_user::RuntimeUser;

pub mod rpc_user;
pub mod runtime_user;

const POISONED_LOCK_ERR: &str = "The lock was poisoned.";

pub trait User {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String>;

    fn view_balance(&self, account_id: &AccountId) -> Result<Balance, String> {
        Ok(self.view_account(account_id)?.amount)
    }

    fn view_state(&self, account_id: &AccountId) -> Result<ViewStateResult, String>;

    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String>;

    fn commit_transaction(
        &self,
        transaction: SignedTransaction,
    ) -> Result<FinalTransactionResult, String>;

    fn add_receipt(&self, receipt: ReceiptTransaction) -> Result<(), String>;

    fn get_account_nonce(&self, account_id: &AccountId) -> Option<u64>;

    fn get_best_block_index(&self) -> Option<u64>;

    fn get_block(&self, index: u64) -> Option<Block>;

    fn get_transaction_result(&self, hash: &CryptoHash) -> TransactionResult;

    fn get_transaction_final_result(&self, hash: &CryptoHash) -> FinalTransactionResult;

    fn get_state_root(&self) -> MerkleHash;

    fn get_receipt_info(&self, hash: &CryptoHash) -> Option<ReceiptInfo>;

    fn get_access_key(
        &self,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, String>;
}

/// Same as `User` by provides async API that can be used inside tokio.
pub trait AsyncUser: Send + Sync {
    fn view_account(
        &self,
        account_id: &AccountId,
    ) -> Box<dyn Future<Item = AccountViewCallResult, Error = String>>;

    fn view_balance(
        &self,
        account_id: &AccountId,
    ) -> Box<dyn Future<Item = Balance, Error = String>> {
        Box::new(self.view_account(account_id).map(|acc| acc.amount))
    }

    fn view_state(
        &self,
        account_id: &AccountId,
    ) -> Box<dyn Future<Item = ViewStateResult, Error = String>>;

    fn add_transaction(
        &self,
        transaction: SignedTransaction,
    ) -> Box<dyn Future<Item = (), Error = String> + Send>;

    fn add_receipt(
        &self,
        receipt: ReceiptTransaction,
    ) -> Box<dyn Future<Item = (), Error = String>>;

    fn get_account_nonce(
        &self,
        account_id: &AccountId,
    ) -> Box<dyn Future<Item = u64, Error = String>>;

    fn get_best_block_index(&self) -> Box<dyn Future<Item = u64, Error = String>>;

    fn get_transaction_result(
        &self,
        hash: &CryptoHash,
    ) -> Box<dyn Future<Item = TransactionResult, Error = String>>;

    fn get_transaction_final_result(
        &self,
        hash: &CryptoHash,
    ) -> Box<dyn Future<Item = FinalTransactionResult, Error = String>>;

    fn get_state_root(&self) -> Box<dyn Future<Item = MerkleHash, Error = String>>;

    fn get_receipt_info(
        &self,
        hash: &CryptoHash,
    ) -> Box<dyn Future<Item = ReceiptInfo, Error = String>>;

    fn get_access_key(
        &self,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Box<dyn Future<Item = Option<AccessKey>, Error = String>>;
}

'''
'''--- test-utils/testlib/src/user/rpc_user.rs ---
use std::sync::RwLock;

use actix::System;
use protobuf::Message;

use near_chain::Block;
use near_client::StatusResponse;
use near_jsonrpc::client::{new_client, JsonRpcClient};
use near_primitives::account::AccessKey;
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::CryptoHash;
use near_primitives::receipt::ReceiptInfo;
use near_primitives::serialize::{to_base, BaseEncode};
use near_primitives::transaction::{
    FinalTransactionResult, ReceiptTransaction, SignedTransaction, TransactionResult,
};
use near_primitives::types::{AccountId, MerkleHash};
use near_protos::signed_transaction as transaction_proto;
use node_runtime::state_viewer::{AccountViewCallResult, ViewStateResult};

use crate::user::User;

pub struct RpcUser {
    client: RwLock<JsonRpcClient>,
}

impl RpcUser {
    pub fn new(addr: &str) -> RpcUser {
        RpcUser { client: RwLock::new(new_client(&format!("http://{}", addr))) }
    }

    pub fn get_status(&self) -> Option<StatusResponse> {
        System::new("actix").block_on(self.client.write().unwrap().status()).ok()
    }

    pub fn query<T: serde::de::DeserializeOwned>(
        &self,
        path: String,
        data: Vec<u8>,
    ) -> Result<T, String> {
        let response =
            System::new("actix").block_on(self.client.write().unwrap().query(path, to_base(&data)))?;
        serde_json::from_slice(&response.value).map_err(|err| err.to_string())
    }
}

impl User for RpcUser {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        self.query(format!("account/{}", account_id), vec![])
    }

    fn view_state(&self, account_id: &AccountId) -> Result<ViewStateResult, String> {
        self.query(format!("contract/{}", account_id), vec![])
    }

    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        let proto: transaction_proto::SignedTransaction = transaction.into();
        let bytes = to_base(&proto.write_to_bytes().unwrap());
        let _ = System::new("actix")
            .block_on(self.client.write().unwrap().broadcast_tx_async(bytes))?;
        Ok(())
    }

    fn commit_transaction(&self, transaction: SignedTransaction) -> Result<FinalTransactionResult, String> {
        let proto: transaction_proto::SignedTransaction = transaction.into();
        let bytes = to_base(&proto.write_to_bytes().unwrap());
        System::new("actix")
            .block_on(self.client.write().unwrap().broadcast_tx_commit(bytes))
    }

    fn add_receipt(&self, _receipt: ReceiptTransaction) -> Result<(), String> {
        // TDDO: figure out if rpc will support this
        unimplemented!()
    }

    fn get_account_nonce(&self, account_id: &String) -> Option<u64> {
        self.view_account(account_id).ok().map(|acc| acc.nonce)
    }

    fn get_best_block_index(&self) -> Option<u64> {
        self.get_status().map(|status| status.sync_info.latest_block_height)
    }

    fn get_block(&self, index: u64) -> Option<Block> {
        System::new("actix").block_on(self.client.write().unwrap().block(index)).ok()
    }

    fn get_transaction_result(&self, hash: &CryptoHash) -> TransactionResult {
        System::new("actix").block_on(self.client.write().unwrap().tx_details(hash.into())).unwrap()
    }

    fn get_transaction_final_result(&self, hash: &CryptoHash) -> FinalTransactionResult {
        System::new("actix").block_on(self.client.write().unwrap().tx(hash.into())).unwrap()
    }

    fn get_state_root(&self) -> MerkleHash {
        self.get_status().map(|status| status.sync_info.latest_state_root).unwrap()
    }

    fn get_receipt_info(&self, _hash: &CryptoHash) -> Option<ReceiptInfo> {
        // TDDO: figure out if rpc will support this
        unimplemented!()
    }

    fn get_access_key(
        &self,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, String> {
        self.query(format!("access_key/{}/{}", account_id, public_key.to_base()), vec![])
    }
}

'''
'''--- test-utils/testlib/src/user/runtime_user.rs ---
use std::cell::RefCell;
use std::collections::HashMap;
use std::sync::{Arc, Mutex, RwLock};

use lazy_static::lazy_static;
use tempdir::TempDir;

use near_chain::Block;
use near_primitives::account::AccessKey;
use near_primitives::crypto::signature::PublicKey;
use near_primitives::hash::CryptoHash;
use near_primitives::receipt::ReceiptInfo;
use near_primitives::transaction::{
    FinalTransactionResult, FinalTransactionStatus, ReceiptTransaction, SignedTransaction,
    TransactionLogs, TransactionResult, TransactionStatus,
};
use near_primitives::types::{AccountId, MerkleHash};
use near_store::{Trie, TrieUpdate};
use node_runtime::ethereum::EthashProvider;
use node_runtime::state_viewer::{AccountViewCallResult, TrieViewer, ViewStateResult};
use node_runtime::{ApplyState, Runtime};

use crate::user::{User, POISONED_LOCK_ERR};

/// Mock client without chain, used in RuntimeUser and RuntimeNode
pub struct MockClient {
    pub runtime: Runtime,
    // Arc here because get_runtime_and_trie returns Arc<Trie> and
    // TrieUpdate takes Arc<Trie>.
    pub trie: Arc<Trie>,
    pub state_root: MerkleHash,
}

impl MockClient {
    pub fn get_state_update(&self) -> TrieUpdate {
        TrieUpdate::new(self.trie.clone(), self.state_root)
    }
}

pub struct RuntimeUser {
    pub account_id: AccountId,
    pub trie_viewer: TrieViewer,
    pub client: Arc<RwLock<MockClient>>,
    // Store results of applying transactions/receipts
    pub transaction_results: RefCell<HashMap<CryptoHash, TransactionResult>>,
    // store receipts generated when applying transactions
    pub receipts: RefCell<HashMap<CryptoHash, ReceiptTransaction>>,
}

lazy_static! {
    static ref TEST_ETHASH_PROVIDER: Arc<Mutex<EthashProvider>> = Arc::new(Mutex::new(
        EthashProvider::new(TempDir::new("runtime_user_test_ethash").unwrap().path())
    ));
}

impl RuntimeUser {
    pub fn new(account_id: &str, client: Arc<RwLock<MockClient>>) -> Self {
        let ethash_provider = TEST_ETHASH_PROVIDER.clone();
        RuntimeUser {
            trie_viewer: TrieViewer::new(ethash_provider),
            account_id: account_id.to_string(),
            client,
            transaction_results: Default::default(),
            receipts: Default::default(),
        }
    }

    pub fn apply_all(
        &self,
        apply_state: ApplyState,
        prev_receipts: Vec<Vec<ReceiptTransaction>>,
        transactions: Vec<SignedTransaction>,
    ) {
        let mut cur_apply_state = apply_state;
        let mut receipts = prev_receipts;
        let mut txs = transactions;
        loop {
            let mut client = self.client.write().expect(POISONED_LOCK_ERR);
            let state_update = TrieUpdate::new(client.trie.clone(), cur_apply_state.root);
            let mut apply_result =
                client.runtime.apply(state_update, &cur_apply_state, &receipts, &txs).unwrap();
            let mut counter = 0;
            for (i, receipt) in receipts.iter().flatten().enumerate() {
                counter += 1;
                let transaction_result = apply_result.tx_result[i].clone();
                self.transaction_results.borrow_mut().insert(receipt.nonce, transaction_result);
            }
            for (i, tx) in txs.iter().enumerate() {
                let transaction_result = apply_result.tx_result[i + counter].clone();
                self.transaction_results.borrow_mut().insert(tx.get_hash(), transaction_result);
            }
            apply_result.trie_changes.into(client.trie.clone()).unwrap().0.commit().unwrap();
            if apply_result.new_receipts.is_empty() {
                client.state_root = apply_result.root;
                return;
            }
            cur_apply_state = ApplyState {
                root: apply_result.root,
                shard_id: cur_apply_state.shard_id,
                block_index: cur_apply_state.block_index,
                parent_block_hash: cur_apply_state.parent_block_hash,
            };
            let new_receipts: Vec<_> =
                apply_result.new_receipts.drain().flat_map(|(_, v)| v).collect();
            for receipt in new_receipts.iter() {
                self.receipts.borrow_mut().insert(receipt.nonce, receipt.clone());
            }
            receipts = vec![new_receipts];
            txs = vec![];
        }
    }

    fn collect_transaction_final_result(
        &self,
        transaction_result: &TransactionResult,
        logs: &mut Vec<TransactionLogs>,
    ) -> FinalTransactionStatus {
        match transaction_result.status {
            TransactionStatus::Unknown => FinalTransactionStatus::Unknown,
            TransactionStatus::Failed => FinalTransactionStatus::Failed,
            TransactionStatus::Completed => {
                for r in transaction_result.receipts.iter() {
                    let receipt_result = self.get_transaction_result(&r);
                    logs.push(TransactionLogs {
                        hash: *r,
                        lines: receipt_result.logs.clone(),
                        receipts: receipt_result.receipts.clone(),
                        result: receipt_result.result.clone(),
                    });
                    match self.collect_transaction_final_result(&receipt_result, logs) {
                        FinalTransactionStatus::Failed => return FinalTransactionStatus::Failed,
                        FinalTransactionStatus::Completed => {}
                        _ => return FinalTransactionStatus::Started,
                    };
                }
                FinalTransactionStatus::Completed
            }
        }
    }
}

impl User for RuntimeUser {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        let state_update = self.client.read().expect(POISONED_LOCK_ERR).get_state_update();
        self.trie_viewer.view_account(&state_update, account_id).map_err(|err| err.to_string())
    }

    fn view_state(&self, account_id: &AccountId) -> Result<ViewStateResult, String> {
        let state_update = self.client.read().expect(POISONED_LOCK_ERR).get_state_update();
        self.trie_viewer.view_state(&state_update, account_id).map_err(|err| err.to_string())
    }

    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        let apply_state = ApplyState {
            root: self.client.read().expect(POISONED_LOCK_ERR).state_root,
            shard_id: 0,
            parent_block_hash: CryptoHash::default(),
            block_index: 0,
        };
        self.apply_all(apply_state, vec![], vec![transaction]);
        Ok(())
    }

    fn commit_transaction(&self, transaction: SignedTransaction) -> Result<FinalTransactionResult, String> {
        let apply_state = ApplyState {
            root: self.client.read().expect(POISONED_LOCK_ERR).state_root,
            shard_id: 0,
            parent_block_hash: CryptoHash::default(),
            block_index: 0,
        };
        self.apply_all(apply_state, vec![], vec![transaction.clone()]);
        Ok(self.get_transaction_final_result(&transaction.get_hash()))
    }

    fn add_receipt(&self, receipt: ReceiptTransaction) -> Result<(), String> {
        let apply_state = ApplyState {
            root: self.client.read().expect(POISONED_LOCK_ERR).state_root,
            shard_id: 0,
            parent_block_hash: CryptoHash::default(),
            block_index: 0,
        };
        self.apply_all(apply_state, vec![vec![receipt]], vec![]);
        Ok(())
    }

    fn get_account_nonce(&self, account_id: &AccountId) -> Option<u64> {
        self.view_account(account_id).ok().map(|account| account.nonce)
    }

    fn get_best_block_index(&self) -> Option<u64> {
        unimplemented!("get_best_block_index should not be implemented for RuntimeUser");
    }

    fn get_block(&self, _index: u64) -> Option<Block> {
        unimplemented!("get_block should not be implemented for RuntimeUser");
    }

    fn get_transaction_result(&self, hash: &CryptoHash) -> TransactionResult {
        self.transaction_results.borrow().get(hash).cloned().unwrap()
    }

    fn get_transaction_final_result(&self, hash: &CryptoHash) -> FinalTransactionResult {
        let transaction_result = self.get_transaction_result(hash);
        let mut result = FinalTransactionResult {
            status: FinalTransactionStatus::Unknown,
            logs: vec![TransactionLogs {
                hash: *hash,
                lines: transaction_result.logs.clone(),
                receipts: transaction_result.receipts.clone(),
                result: transaction_result.result.clone(),
            }],
        };
        result.status =
            self.collect_transaction_final_result(&transaction_result, &mut result.logs);
        result
    }

    fn get_state_root(&self) -> MerkleHash {
        self.client.read().expect(POISONED_LOCK_ERR).state_root
    }

    fn get_receipt_info(&self, hash: &CryptoHash) -> Option<ReceiptInfo> {
        let receipt = self.receipts.borrow().get(hash).cloned()?;
        let transaction_result = self.transaction_results.borrow().get(hash).cloned()?;
        Some(ReceiptInfo { receipt, result: transaction_result, block_index: Default::default() })
    }

    fn get_access_key(
        &self,
        account_id: &AccountId,
        public_key: &PublicKey,
    ) -> Result<Option<AccessKey>, String> {
        let state_update = self.client.read().expect(POISONED_LOCK_ERR).get_state_update();
        self.trie_viewer
            .view_access_key(&state_update, account_id, public_key)
            .map_err(|err| err.to_string())
    }
}

'''
'''--- test-utils/testlib/src/user/shard_client_user.rs ---
use crate::runtime_utils::to_receipt_block;
use crate::user::{User, POISONED_LOCK_ERR};
use node_http::types::{GetBlocksByIndexRequest, SignedShardBlocksResponse};
use node_runtime::state_viewer::{AccountViewCallResult, ViewStateResult};
use primitives::block_traits::SignedBlock;
use primitives::hash::CryptoHash;
use primitives::transaction::{
    FinalTransactionResult, ReceiptTransaction, SignedTransaction, TransactionResult,
};
use primitives::types::{AccountId, MerkleHash};
use shard::{ReceiptInfo, ShardClient};
use std::sync::Arc;
use storage::storages::GenericStorage;

pub struct ShardClientUser {
    pub client: Arc<ShardClient>,
}

impl ShardClientUser {
    pub fn new(client: Arc<ShardClient>) -> ShardClientUser {
        ShardClientUser { client }
    }

    /// unified way of submitting transaction or receipt. Pool
    /// must not be empty.
    fn add_payload(&self) -> Result<(), String> {
        let payload = {
            let mempool = self.client.pool.clone().unwrap();
            let mut pool = mempool.write().expect(POISONED_LOCK_ERR);
            assert!(!pool.is_empty());
            let snapshot = pool.snapshot_payload();
            pool.pop_payload_snapshot(&snapshot).unwrap()
        };
        let mut transactions = payload.transactions;
        let mut receipts = payload.receipts;

        loop {
            let last_block_hash = *self
                .client
                .storage
                .write()
                .expect(POISONED_LOCK_ERR)
                .blockchain_storage_mut()
                .best_block_hash()
                .map_err(|e| format!("{}", e))?
                .unwrap();
            let (block, block_extra) =
                self.client.prepare_new_block(last_block_hash, receipts, transactions.clone());
            let index = block.index();
            let has_new_receipts = block_extra.new_receipts.is_empty();
            self.client.insert_block(
                &block,
                block_extra.db_changes,
                block_extra.tx_results,
                block_extra.largest_tx_nonce,
                block_extra.new_receipts,
            );
            if has_new_receipts {
                break;
            }
            transactions.clear();
            receipts = vec![self
                .client
                .get_receipt_block(index, 0)
                .ok_or_else(|| "Receipt does not exist".to_string())?];
        }
        Ok(())
    }
}

impl User for ShardClientUser {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        let state_update = self.client.get_state_update();
        self.client.trie_viewer.view_account(&state_update, account_id)
    }

    fn view_state(&self, account_id: &AccountId) -> Result<ViewStateResult, String> {
        let state_update = self.client.get_state_update();
        self.client.trie_viewer.view_state(&state_update, account_id)
    }

    /// First adding transaction to the mempool and then simulate how payload are extracted from
    /// mempool and executed in runtime.
    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        self.client
            .pool
            .clone()
            .unwrap()
            .write()
            .expect(POISONED_LOCK_ERR)
            .add_transaction(transaction)
            .unwrap();
        self.add_payload()
    }

    fn add_receipt(&self, receipt: ReceiptTransaction) -> Result<(), String> {
        let receipt_block = to_receipt_block(vec![receipt]);
        self.client
            .pool
            .clone()
            .unwrap()
            .write()
            .expect(POISONED_LOCK_ERR)
            .add_receipt(receipt_block)?;
        self.add_payload()
    }

    fn get_account_nonce(&self, account_id: &AccountId) -> Option<u64> {
        self.client.get_account_nonce(account_id.clone())
    }

    fn get_best_block_index(&self) -> Option<u64> {
        Some(self.client.chain.best_index())
    }

    fn get_transaction_result(&self, hash: &CryptoHash) -> TransactionResult {
        self.client.get_transaction_result(hash)
    }

    fn get_transaction_final_result(&self, hash: &CryptoHash) -> FinalTransactionResult {
        self.client.get_transaction_final_result(hash)
    }

    fn get_state_root(&self) -> MerkleHash {
        self.client.chain.best_header().body.merkle_root_state
    }

    fn get_receipt_info(&self, hash: &CryptoHash) -> Option<ReceiptInfo> {
        self.client.get_receipt_info(hash)
    }

    fn get_shard_blocks_by_index(
        &self,
        r: GetBlocksByIndexRequest,
    ) -> Result<SignedShardBlocksResponse, String> {
        let start = r.start.unwrap_or_else(|| self.client.chain.best_index());
        let limit = r.limit.unwrap_or(25);
        let blocks = self.client.chain.get_blocks_by_indices(start, limit);
        Ok(SignedShardBlocksResponse {
            blocks: blocks.into_iter().map(std::convert::Into::into).collect(),
        })
    }
}

'''
'''--- test-utils/testlib/src/user/thread_user.rs ---
use crate::runtime_utils::to_receipt_block;
use crate::user::{User, POISONED_LOCK_ERR};
use client::Client;
use node_http::types::{GetBlocksByIndexRequest, SignedShardBlocksResponse};
use node_runtime::state_viewer::{AccountViewCallResult, ViewStateResult};
use primitives::crypto::signer::InMemorySigner;
use primitives::hash::CryptoHash;
use primitives::transaction::{
    FinalTransactionResult, ReceiptTransaction, SignedTransaction, TransactionResult,
};
use primitives::types::{AccountId, MerkleHash};
use shard::ReceiptInfo;
use std::sync::Arc;

pub struct ThreadUser {
    pub client: Arc<Client<InMemorySigner>>,
}

impl ThreadUser {
    pub fn new(client: Arc<Client<InMemorySigner>>) -> ThreadUser {
        ThreadUser { client }
    }
}

impl User for ThreadUser {
    fn view_account(&self, account_id: &AccountId) -> Result<AccountViewCallResult, String> {
        let state_update = self.client.shard_client.get_state_update();
        self.client.shard_client.trie_viewer.view_account(&state_update, account_id)
    }

    fn view_state(&self, account_id: &AccountId) -> Result<ViewStateResult, String> {
        let state_update = self.client.shard_client.get_state_update();
        self.client.shard_client.trie_viewer.view_state(&state_update, account_id)
    }

    fn add_transaction(&self, transaction: SignedTransaction) -> Result<(), String> {
        self.client
            .shard_client
            .pool
            .clone()
            .expect("Must have pool")
            .write()
            .expect(POISONED_LOCK_ERR)
            .add_transaction(transaction)
    }

    fn add_receipt(&self, receipt: ReceiptTransaction) -> Result<(), String> {
        let receipt_block = to_receipt_block(vec![receipt]);
        self.client
            .shard_client
            .pool
            .clone()
            .expect("Must have pool")
            .write()
            .expect(POISONED_LOCK_ERR)
            .add_receipt(receipt_block)
    }

    fn get_account_nonce(&self, account_id: &String) -> Option<u64> {
        self.client.shard_client.get_account_nonce(account_id.clone())
    }

    fn get_best_block_index(&self) -> Option<u64> {
        Some(self.client.beacon_client.chain.best_index())
    }

    fn get_transaction_result(&self, hash: &CryptoHash) -> TransactionResult {
        self.client.shard_client.get_transaction_result(hash)
    }

    fn get_transaction_final_result(&self, hash: &CryptoHash) -> FinalTransactionResult {
        self.client.shard_client.get_transaction_final_result(hash)
    }

    fn get_state_root(&self) -> MerkleHash {
        self.client.shard_client.chain.best_header().body.merkle_root_state
    }

    fn get_receipt_info(&self, hash: &CryptoHash) -> Option<ReceiptInfo> {
        self.client.shard_client.get_receipt_info(hash)
    }

    fn get_shard_blocks_by_index(
        &self,
        r: GetBlocksByIndexRequest,
    ) -> Result<SignedShardBlocksResponse, String> {
        let start = r.start.unwrap_or_else(|| self.client.shard_client.chain.best_index());
        let limit = r.limit.unwrap_or(25);
        let blocks = self.client.shard_client.chain.get_blocks_by_indices(start, limit);
        Ok(SignedShardBlocksResponse {
            blocks: blocks.into_iter().map(std::convert::Into::into).collect(),
        })
    }
}

'''
'''--- test-utils/txflow-test-gen/README.md ---
Visual test gen for TxFlow
==========================

This is a visual editor for TxFlow graphs.

It contains an alternative naive implementation of TxFlow in JavaScript, that always DFSes from scratch without precaching to reduce the chance of errors.

Generated TxFlow graphs annotated with the alternative TxFlow implementation can then be converted into Rust unit tests.

# How to use:

Open index.html in the browser.

On top there are four buttons represnting four users. Pressing on the button creates a new message for the user and selects it.

Clicking on an existing message selects or deselects it. When a new message is created, all the selected messages become it's parents.

Whenever any number of messages is selected, the TxFlow graph is traversed from the selected messages, and annotated with epochs,
representatives, kickouts and endorsements.

The kickout messages are marked with bold letter 'K';

The representative messages are marked in a form 'R5(A,B)' where 5 is what epoch the representative message is for (it might be different
from the message epoch, if the representative message was not created via an epoch increase) and A and B are endorsements.

# Comments, Serializing / Deserializing

Use the `comment` text area to provide a short description of the test.

The `Serialized` text area contains JSON of the txflow. It is autoupdated whenever the graph is changed.

To save the serialialized JSON just copy-paste it from the textarea.

To restore to previously saved JSON copy-paste it back to the textarea and press `Deserialize`.

# Generating Rust test cases

Enter a function name for the test into the textbox under the `Serialized` textarea, and press `Gen Rust Test`.

Presently it only tests epochs, representative and kickout, but not endorsements.

'''
'''--- test-utils/txflow-test-gen/beacon.js ---
var STATE_INIT = 0;
var STATE_PREVDF = 1;
var STATE_BLOCK = 2;
var STATE_COMMIT = 3;
var STATE_SIGNATURE = 4;
var STATE_FINAL = 5;

var STATE_NAMES = ['init', 'pre', 'blk', 'com', 'sig', 'fin'];

var PAYLOAD_NONE = 0;
var PAYLOAD_PREVBLOCK = 1;
var PAYLOAD_VDF = 2;
var PAYLOAD_COMMIT = 3;
var PAYLOAD_SIGNATURE = 4;

var NUM_SUBSTATES = 2;

var state_eq = function(n1, n2) { return n1.state == n2.state && n1.substate == n2.substate; }
var state_gt = function(n1, n2) { return n1.state > n2.state || n1.state == n2.state && n1.substate > n2.substate; }

var add_beacon_annotations = function(nodes, annotations, num_users) {
    var mapping = {};

    for (var a of annotations) {
        mapping[a.node.uid] = a;
    }

    for (var node of nodes) {
        var a = mapping[node.uid];

        if (a === undefined) continue;

        var largest_state = {};
        var visited = {};
        
        var saw_invalid = false;
        var dfs_largest_state = function(n, first) {
            if (visited[n.uid] !== undefined) return;
            visited[n.uid] = true;

            for (var p of n.parents) dfs_largest_state(p, false);

            if (first) return;

            var a = mapping[n.uid];
            if (!a.valid) {
                saw_invalid = true;
                return;
            }
            if (largest_state[n.owner] === undefined || state_gt(a, largest_state[n.owner])) largest_state[n.owner] = a;
        }

        dfs_largest_state(node, true);

        var state_increase = false;
        if (largest_state[node.owner] !== undefined) {
            a.state = largest_state[node.owner].state;
            a.substate = largest_state[node.owner].substate;
        }
        else {
            state_increase = true;
            a.state = STATE_INIT;
            a.substate = 0;
        }

        if (a.state == STATE_PREVDF) {
            var increment = node.payload_type == PAYLOAD_VDF;
            if (!increment) {
                var num_vdfs = 0;
                for (var key in largest_state) {
                    if (largest_state[key].state >= STATE_BLOCK) {
                        ++ num_vdfs;
                    }
                }
                if (num_vdfs > Math.floor(num_users * 2 / 3)) {
                    increment = true;
                }
            }
            if (increment) {
                state_increase = true;
                a.state = STATE_BLOCK;
                a.substate = 0;
            }
        }
        else if (a.state == STATE_FINAL) {
            // can't increase the final state
        }
        else {
            var increment = false;
            var num_same = 0;
            for (var key in largest_state) {
                if (!state_gt(a, largest_state[key])) {
                    ++ num_same;
                }
            }
            if (num_same > Math.floor(num_users * 2 / 3)) {
                if (a.substate == NUM_SUBSTATES - 1) {
                    a.ready_to_increment = true;
                    var increment = false;
                    var visited = {};
                    var nas = compute_annotations([node], num_users);
                    for (var na of nas) {
                        // note that for `ready_to_incrememt` we need to use annotations from the outer scope
                        var pa = mapping[na.node.uid];
                        if (pa.state == a.state && pa.substate == a.substate && pa.ready_to_increment && na.epoch_block) {
                            increment = true;
                        }
                    }
                    if (increment) {
                        state_increase = true;
                        ++ a.state;
                        a.substate = 0;
                    }
                }
                else {
                    ++ a.substate;
                }
            }
        }

        a.valid = !saw_invalid;
        if (state_increase) {
            if (a.state == STATE_INIT && node.payload_type != PAYLOAD_PREVBLOCK) a.valid = false;
            if (a.state == STATE_COMMIT && node.payload_type != PAYLOAD_COMMIT) a.valid = false;
            if (a.state == STATE_SIGNATURE && node.payload_type != PAYLOAD_SIGNATURE) a.valid = false;
        }
    }
}

var compute_beacon_chain_observation = function(node, num_users) {
    var annotations = compute_annotations([node], num_users)
    var toposorted = toposort([node]);
    add_beacon_annotations(toposorted, annotations, num_users);

    ret = {};
    for (var a of annotations) {
        var node = a.node;

        if (a.epoch_block && a.state != STATE_PREVDF && a.state != STATE_FINAL) {
            var key = STATE_NAMES[a.state + 1];
            if (ret[key] === undefined || ret[key] > a.representative) {
                ret[key] = a.representative;
            }
        }
    }

    return ret;
}

'''
'''--- test-utils/txflow-test-gen/common_rust_code_for_tests.txt ---
/// Creates HashMap.
/// # Examples:
///
/// ```
/// let m = map!{0 => 1, 2 => 3};
/// assert_eq!(m.len(), 2);
/// ```
#[allow(unused_macros)]
macro_rules! map(
        { $($key:expr => $value:expr),+ } => {
            {
                let mut m = ::std::collections::HashMap::new();
                $(
                    m.insert($key, $value);
                )+
                m
            }
        };
    );

/// Creates HashSet.
/// # Examples:
///
/// ```
/// let s = set!{2, 1};
/// assert_eq!(s.len(), 2);
/// ```
#[allow(unused_macros)]
macro_rules! set(
        { $($el:expr),+ } => {
            {
                let mut s = ::std::collections::HashSet::new();
                $(
                    s.insert($el);
                )+
                s
            }
        };
    );

/// Binds a tuple to a vector.
/// # Examples:
///
/// ```
/// let v = vec![1,2,3];
/// tuplet!((a,b,c) = v);
/// assert_eq!(a, &1);
/// assert_eq!(b, &2);
/// assert_eq!(c, &3);
/// ```
#[allow(unused_macros)]
macro_rules! tuplet {
    { ($y:ident $(, $x:ident)*) = $v:expr } => {
        let ($y, $($x),*) = tuplet!($v ; 1 ; ($($x),*) ; (&$v[0]) );
    };
    { $v:expr ; $j:expr ; ($y:ident $(, $x:ident)*) ; ($($a:expr),*) } => {
        tuplet!( $v ; $j+1 ; ($($x),*) ; ($($a),*,&$v[$j]) )
    };
    { $v:expr ; $j:expr ; () ; $accu:expr } => {
        $accu
    }
}

#[cfg(test)]
mod tests {
    use near_primitives::traits::{Payload, WitnessSelector};
    use near_primitives::types::UID;
    use std::collections::HashSet;
    use typed_arena::Arena;
    use dag::message::Message;

    struct FakeNonContinuousWitnessSelector {
        num_users: u64,
        users: HashSet<UID>,
    }

    impl FakeNonContinuousWitnessSelector {
        fn new(num_users: u64) -> Self {
            let mut users = set!{0};
            for i in 1..num_users {
                users.insert(i);
            }
            Self { num_users, users }
        }
    }

    impl WitnessSelector for FakeNonContinuousWitnessSelector {
        fn epoch_witnesses(&self, _epoch: u64) -> &HashSet<UID> {
            &self.users
        }
        fn epoch_leader(&self, epoch: u64) -> UID {
            epoch % self.num_users
        }
        fn random_witnesses(&self, _epoch: u64, _sample_size: usize) -> HashSet<UID> {
            unimplemented!()
        }
    }

    fn make_assertions<P: Payload>(messages: &[Option<&Message<P>>], assertions: &[(u64, Option<u64>, bool, u64)]) {
        for it in messages.iter().zip(assertions.iter()) {
            let (msg, a) = it;
            if let Some(msg) = msg.as_ref() {
                // If this assert triggers, the last element of tuples indicates the node uid
                assert_eq!((a.0, a.1, a.2, a.3), (msg.computed_epoch, msg.computed_is_representative, msg.computed_is_kickout, a.3));
            }
        }
    }

    fn epoch_representative_approved_by<P: Payload>(message: &Message<P>, epoch: u64, owner: u64) -> bool {
       message.approved_endorsements.contains_any_approval(epoch, owner) ||
           (owner == message.data.body.owner_uid && message.computed_endorsements.contains_epoch(epoch)) ||
           (owner == message.data.body.owner_uid && Some(epoch) == message.computed_is_representative)
    }

    fn test_endorsements<P: Payload>(message: &Message<P>, endorsements: &[Vec<u64>], num_users: u64) {
        for epoch in 0..endorsements.len() {
            let who = &endorsements[epoch];
            let mut lst = 0;

            for i in 0..num_users {
                if lst < who.len() && who[lst] == i {
                    assert!(epoch_representative_approved_by(message, epoch as u64, i), "epoch: {}, i: {}, {:?}", epoch, i, message.computed_endorsements);
                    lst += 1;
                }
                else {
                    assert!(!epoch_representative_approved_by(message, epoch as u64, i), "epoch: {}, i: {}", epoch, i);
                }
            }
        }
    }
'''
'''--- test-utils/txflow-test-gen/gen_tests.js ---
var lineReader = require('readline').createInterface({
    input: require('fs').createReadStream('tests.jsonl')
});

var txflow = require('./txflow.js');

lineReader.on('line', function (line) {
    if (!line.trim()) return

    var j = JSON.parse(line);
    var graph = txflow.deserialize_txflow(j.s);
    var num_users = j.n;

    console.log(txflow.gen_rust(graph, num_users, j.f, j.c, JSON.stringify(j)));
});

'''
'''--- test-utils/txflow-test-gen/index.html ---
<meta charset="UTF-8">
<html>
<head>
<script src=txflow.js></script>
<script src=utils.js></script>
<script src=beacon.js></script>
<style>
body {
    font-family: Helvetica;
    font-size: 10px;
}
</style>
</head>

<body>
<br>
<div id='buttons' style='z-index: 5; position: absolute; left: 0px; top: 0px'></div>
<canvas id='here' style='position: absolute; top: 60px;'></canvas>
<div id='serializer_holder' style='position: fixed; top: 60px;'>
<button onclick='delete_node()'>Delete Node</button> &nbsp; <input type='checkbox' id='chk_beacon' onchange='beacon_mode=document.getElementById("chk_beacon").checked; refresh(); serialize();'> Beacon Mode &nbsp; <a href='#' onclick='z = document.getElementById("more_actions").style; z.display = (z.display == "") ? "none" : "";'>More actions</a>
<div id='more_actions' style='display: none; text-align: center'>
    <br>
    <button style="width: 200px" onclick='if (num_users < 26) num_users ++; refresh(); serialize();'>Add User</button><br>
    <button style="width: 200px" onclick='if (num_users > 1) num_users --; refresh(); serialize();'>Remove User</button><br>
    <button style="width: 200px" onclick='alert(stress_epoch_blocks(nodes, num_users))'>Stress Epoch Blocks</button><br>
    <button style="width: 200px" onclick='alert(stress_beacon(nodes, num_users))' id='btn_stress_beacon'>Stress Beacon</button><br>
    <input id='random_graph_num_malicious' style='width:75px' placeholder='Malicious'><input id='random_graph_num_nodes' style='width: 75px' placeholder='Nodes'><button style="width: 50px" onclick='generate_random_graph(num_users, parseInt(document.getElementById("random_graph_num_malicious").value), parseInt(document.getElementById("random_graph_num_nodes").value), beacon_mode)'>rnd</button><br>
</div><br><br>
<div id='comment_holder'>
<b>Comment:</b><br>
<textarea id='comment' rows=8 cols=40 onkeyup='serialize()'></textarea><br>
</div>
<div id='beacon_settings_holder' style='display:none'>
<b>Node Payload</b><br>
<select id='beacon_payload' onchange='var si = document.getElementById("beacon_payload").selectedIndex; selected_node.payload_type = si; if (si == 1) selected_node.prevblock = "0"; else delete selected_node.prevblock; refresh();'>
    <option>None</option>
    <option>Prev Block</option>
    <option>VDF Output</option>
    <option>Commit</option>
    <option>Signature</option>
</select><br>
<div id='beacon_prevblock_holder'>Prevblock: <input id='beacon_prevblock' onchange='selected_node.prevblock = document.getElementById("beacon_prevblock").value; refresh();'></div>
</div>
<b>Serialized:</b><br>
<textarea id='serializer' rows=8 cols=40></textarea><br>
<table cellspacing=0 cellpadding=0 width=100%><tr><td>
<button onclick='deserialize()'>Deserialize</button></td><td align=right>
<input id='rust_fn_name' placeholder='Fn name' style='width:70px' onkeyup='serialize()'>
<button onclick='show_rust()'>Gen Rust Test</button></td></tr></table>
</div>
<div id='annot' style='position: absolute; top: 60px; pointer-events: none'></div>
</body>

<script>

var PIXEL_RATIO = (function () {
    var ctx = document.createElement("canvas").getContext("2d"),
        dpr = window.devicePixelRatio || 1,
        bsr = ctx.webkitBackingStorePixelRatio ||
              ctx.mozBackingStorePixelRatio ||
              ctx.msBackingStorePixelRatio ||
              ctx.oBackingStorePixelRatio ||
              ctx.backingStorePixelRatio || 1;
    return dpr / bsr;
})();

var beacon_mode = false;
var selected_node = null;

var names = ['Alice', 'Bob', 'Carol', 'Dave', 'Elaine', 'Frank', 'George', 'Hans', 'Irene', 'Jason', 'Kate', 'Lance', 'Matthew', 'Nancy', 'Oliver', 'Peter', 'QQ', 'Ralph', 'Sarah', 'Tim', 'Usman', 'Victor', 'Whitney', 'Xavier', 'Yasmine', 'Zach'];
var num_users = 4;
var graph = [];
var nodes = undefined;

var set_click_listener = function(btn, owner_id) {
    btn.onclick = function() {
        var new_graph = [];
        var parents = [];
        for (var i = 0; i < graph.length; ++ i) {
            if (!graph[i].selected) {
                new_graph.push(graph[i]);
            }
        }
        for (var i = 0; i < nodes.length; ++ i) {
            if (nodes[i].selected) {
                parents.push(nodes[i]);
                nodes[i].selected = false;
            }
        }
        var new_node = create_node(owner_id, parents);
        new_node.selected = true;
        new_graph.push(new_node);
        graph = new_graph;
        refresh();
        window.scroll(0, 1e9);
    };
}

var here = document.getElementById('here');
var annot = document.getElementById('annot');
here.onclick = function(e) {
    var x = e.pageX - here.offsetLeft;
    var y = e.pageY - here.offsetTop;

    var the_only_one = get_only_selected_node(nodes);
    var multi = e.shiftKey || e.ctrlKey || e.metaKey;

    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];
        var coords = node.coords;

        if (x >= coords.l && x <= coords.l + coords.w && y >= coords.t && y <= coords.t + coords.h) {
            if (multi || node == the_only_one) {
                node.selected = !node.selected;
            }
            else {
                node.selected = true;
            }
        }
        else if (!multi) {
            node.selected = false;
        }
    }

    refresh();
    return;
}

var refresh = function() {
    document.getElementById('buttons').innerHTML = '';
    var buttons = [];
    for (var i = 0; i < num_users; ++ i) {
        var btn = document.createElement('button');
        btn.innerHTML = names[i];
        document.getElementById('buttons').appendChild(btn);
        buttons.push(btn);
    }

    var selected = [];

    nodes = toposort(graph);

    var user_l = render_graph(here, graph, num_users);

    for (var i = 0; i < nodes.length; ++ i) {
        if (nodes[i].selected) {
            selected.push(nodes[i]);
        }
    }
    var annotations = selected.length == 0 ? [] : compute_annotations(selected, num_users);

    if (beacon_mode) {
        add_beacon_annotations(nodes, annotations, num_users);
    }

    annot.innerHTML = '';
    for (var annotation_idx in annotations) {
        var annotation = annotations[annotation_idx];

        var node = annotation.node;
        var a = document.createElement('div');
        a.style.position = 'absolute';
        a.style.left = node.coords.l + 1 + 'px';
        a.style.top = node.coords.t + 1 + 'px';
        a.style.width = node.coords.w - 1 + 'px';
        a.style.height = node.coords.h - 1 + 'px';

        var title = '<u>' + names[node.owner] + '</u>';
        if (beacon_mode) {
            var title = '<u>' + names[node.owner][0] + '</u> ';
            if (node.payload_type) {
                if (node.payload_type == 1) {
                    title += '<font color="blue">PB(' + node.prevblock + ')</font>';
                }
                else if (node.payload_type == 2) {
                    title += '<font color="green">VDF</font>';
                }
                else if (node.payload_type == 3) {
                    title += '<font color="darkred">C</font>';
                }
                else if (node.payload_type == 4) {
                    title += '<font color="purple">S</font>';
                }
            }
            title += '</b>';
        }

        var flags = "";
        if (annotation.representative >= 0) {
            flags += "<b>R" + annotation.representative + "</b><small>(";
            var first = true;
            for (var key in annotation.endorsements) {
                if (!first) flags += ',';
                first = false;
                flags += names[key][0];
            }
            flags += ")</small> ";
        }
        if (annotation.epoch_block) a.style.backgroundColor = '#D0FFD0';
        if (annotation.kickout) flags += "<b>K</b>";
        var extra = beacon_mode ? '<small><b>' + STATE_NAMES[annotation.state] + '</b>.' + annotation.substate + (annotation.substate == NUM_SUBSTATES - 1 && annotation.ready_to_increment ? '*' : '') + '</small>' + ((annotation.valid) ? '<b><font color=green>v</font></b>' : '<b><font color=red>x</font></b>')
                                : 'E: ' + annotation.epoch + " / K: " + annotation.largest_kickout_promise + "<br>" + flags;
        a.innerHTML = '<small>(v' + node.uid + ')</small> ' + title + '<br>' + extra;

        annot.appendChild(a);
    }

    for (var i = 0; i < num_users; ++ i) {
        var btn = buttons[i];
        btn.style.position = 'fixed';
        btn.style.top = '5px';
        btn.style.left = user_l[i] + 'px';

        set_click_listener(btn, i);
    }

    if (document.getElementById('chk_beacon').checked != beacon_mode) {
        document.getElementById('chk_beacon').checked = beacon_mode;
    }

    if (beacon_mode) {
        document.getElementById('btn_stress_beacon').style.display = '';
        selected_node = get_only_selected_node(nodes);
        var settings_holder = document.getElementById('beacon_settings_holder');
        var comment_holder = document.getElementById('comment_holder');

        if (selected_node) {
            if (settings_holder.style.display == 'none') {
                settings_holder.style.width = comment_holder.offsetWidth + 'px';
                settings_holder.style.height = comment_holder.offsetHeight + 'px';
            }
            settings_holder.style.display = '';
            comment_holder.style.display = 'none';

            var payload_select = document.getElementById('beacon_payload');
            if (payload_select.selectedIndex != selected_node.payload_type) {
                payload_select.selectedIndex = selected_node.payload_type;
            }

            var prevblock_holder = document.getElementById('beacon_prevblock_holder');
            var prevblock_control = document.getElementById('beacon_prevblock');

            prevblock_holder.style.display = (selected_node.payload_type == 1) ? '' : 'none';
            if (prevblock_control.value != selected_node.prevblock) {
                prevblock_control.value = selected_node.prevblock;
            }
        }
        else {
            settings_holder.style.display = 'none';
            comment_holder.style.display = '';
        }
    }
    else {
        document.getElementById('btn_stress_beacon').style.display = 'none';
    }

    serialize();
    document.getElementById('serializer_holder').style.left = here.offsetWidth + 'px';
}
 
var delete_node = function() {
    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];
        if (!node.selected) continue;

        for (var child_idx = 0; child_idx < node.children.length; ++ child_idx) {
            var idx = node.children[child_idx].parents.indexOf(node);
            node.children[child_idx].parents.splice(idx, 1);
        }
        for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
            var idx = node.parents[parent_idx].children.indexOf(node);
            node.parents[parent_idx].children.splice(idx, 1);
            if (node.parents[parent_idx].children.length == 0) {
                graph.push(node.parents[parent_idx]);
            }
        }
        var idx = graph.indexOf(node);
        if (idx >= 0) {
            graph.splice(idx, 1);
        }
    }
    refresh();
}

var serialize = function() {
    var content = {'s': serialize_txflow(graph, beacon_mode), 'n': num_users, 'c': document.getElementById('comment').value, 'f': document.getElementById('rust_fn_name').value};
    if (beacon_mode) content.b = true;
    document.getElementById('serializer').value = JSON.stringify(content);
}

var deserialize = function() {
    var s = JSON.parse(document.getElementById('serializer').value);
    beacon_mode = !!s.b;
    graph = deserialize_txflow(s.s, beacon_mode);
    num_users = s.n;
    document.getElementById('comment').value = s.c;
    document.getElementById('rust_fn_name').value = s.f;
    refresh();
}

var show_rust = function() {
    var s = gen_rust(graph, num_users, document.getElementById('rust_fn_name').value, document.getElementById('comment').value, document.getElementById('serializer').value);
    var txt = document.createElement('textarea');

    txt.style.position = 'fixed';
    txt.style.left = '20px';
    txt.style.top = '20px';
    txt.style.width = '600px';
    txt.style.height = '400px';
    txt.style.zIndex = 10;

    txt.value = s;

    document.body.appendChild(txt);
    txt.focus();

    txt.onblur = function() { document.body.removeChild(txt); }
}

refresh();

</script>

</html>

'''
'''--- test-utils/txflow-test-gen/nighty_gen.js ---
var txflow = require('./txflow.js');
var utils = require('./utils.js');
const fs = require('fs');
const path = require('path');

maxUsers = 25;
maxNodes = 100;

function getRandomInt(max) {
    return Math.floor((Math.random()) * Math.floor(max)) + 1;
}

common_for_tests = fs.readFileSync(path.resolve(__dirname, 'common_rust_code_for_tests.txt'), 'utf8');

failed_rust = false;

while (true) {
    totalUsers = getRandomInt(maxUsers);
    maliciousUsers = getRandomInt(totalUsers / 3 - 1);
    totalNodes = getRandomInt(maxNodes);
    console.log("totalUsers: " + totalUsers + " maliciousUsers: " + maliciousUsers + " totalNodes: " + totalNodes);
    timeStamp = Math.floor(Date.now() / 1000);
    fn_name = "nightly_generated_test.rs";
    comment = "Test generated @" + timeStamp;
    serialized = false;
    beaconMode = false;
    graph = utils.generate_random_graph(totalUsers, maliciousUsers, totalNodes, beaconMode, show_html = false);
    result = utils.stress_epoch_blocks(txflow.toposort(graph), totalUsers);
    console.log(result);

    if (!result.includes('PASSED!')) {
        console.error("totalUsers: " + totalUsers + " maliciousUsers: " + maliciousUsers + " totalNodes: " + totalNodes);
        console.error(result);
        console.error(graph);
    }

    if (!failed_rust) {
        rust_test = txflow.gen_rust(graph, totalUsers, timeStamp, comment, serialized)

        fs.writeFileSync(path.resolve(__dirname, '../../core/txflow/src/dag/message/' + fn_name), common_for_tests + '\n' + rust_test + '}');

        const execSync = require('child_process').execSync;
        try {
            code = execSync('cargo test -p txflow dag::message::nightly_generated_test').toString();
            console.log("Rust Passed!");

        } catch (ex) {
            failed_rust = true;
            console.error("totalUsers: " + totalUsers + " maliciousUsers: " + maliciousUsers + " totalNodes: " + totalNodes);
            console.error(ex.output.toString());
        }
    }
}
'''
'''--- test-utils/txflow-test-gen/txflow.js ---
// Any functions that has an argument `nodes` expects nodes to be toposorted

var last_node_uid = 0;
var NODE_W = 72;
var NODE_H = 40;
var NODE_S = 16;
var NODE_US = 32;

var create_node = function(owner, parents) {
    var node = {};
    node.uid = last_node_uid;
    ++ last_node_uid;

    node.owner = owner;
    node.parents = parents;
    node.children = [];

    for (var parent_idx = 0; parent_idx < parents.length; ++ parent_idx) {
        parents[parent_idx].children.push(node);
    }

    return node;
}

var toposort = function(graph) {
    var ret = [];

    var q = [];
    var npr = {};

    var all_nodes = [];
    var visited = {};

    var dfs = function(node) {
        if (visited[node.uid] !== undefined) {
            return;
        }
        visited[node.uid] = true;

        for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
            dfs(node.parents[parent_idx]);
        }

        all_nodes.push(node);
        npr[node.uid] = node.parents.length;
    };

    for (var i = 0; i < graph.length; ++ i) {
        dfs(graph[i]);
    }

    for (var i = 0; i < all_nodes.length; ++ i) {
        if (npr[all_nodes[i].uid] == 0) {
            q.push(all_nodes[i]);
        }
    }

    for (var i = 0; i < q.length; ++ i) {
        var node = q[i];
        for (var ch_idx = 0; ch_idx < node.children.length; ++ ch_idx) {
            var child = node.children[ch_idx];
            npr[child.uid] --;
            if (npr[child.uid] == 0) {
                q.push(child);
            }
        }
    }

    if (q.length != all_nodes.length) {
        console.error(all_nodes);
        console.error("q.length = " + q.length + ", all_nodes.length = " + all_nodes.length);
    }

    return q;
}

var annotate_user_levels = function(nodes) {
    var ret = {};
    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var fixed_node = nodes[node_idx];
        var user_id = fixed_node.owner;
        fixed_node.owner_level = 0;
        var visited = {};
        var dfs = function(node) {
            if (visited[node.uid] !== undefined) {
                return;
            }
            visited[node.uid] = true;

            for (var idx = 0; idx < node.parents.length; ++ idx) {
                dfs(node.parents[idx]);
            }

            if (node != fixed_node && node.owner == fixed_node.owner) {
                if (node.owner_level + 1 > fixed_node.owner_level) {
                    fixed_node.owner_level = node.owner_level + 1;
                }
            }
        }
        dfs(fixed_node);
        if (ret[user_id] === undefined) {
            ret[user_id] = [];
        }
        if (fixed_node.owner_level >= ret[user_id].length) {
            ret[user_id].push([]);
        }
        fixed_node.owner_level_nodes = ret[user_id][fixed_node.owner_level];
        fixed_node.owner_level_ord = ret[user_id][fixed_node.owner_level].length;
        ret[user_id][fixed_node.owner_level].push(fixed_node);
    }
    
    return ret;
}

var render_nodes_cb = function(nodes, user_l, cb) {
    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];
        var w = NODE_W;
        var h = NODE_H;
        var l = user_l[node.owner] + (NODE_W + NODE_S) * node.owner_level_ord;
        var t = (NODE_H + NODE_S) * node.level;

        node.coords = {'l': l, 't': t, 'w': w, 'h': h};

        cb(node, l, t, w, h);
    }
}

var compute_annotations = function(graph, num_users) {
    var nodes = toposort(graph);
    annotate_user_levels(nodes);
    var annotations = [];
    var mapping = {};

    // This list contains objects of form [epoch, node] to enable easy sorting
    var epoch_blocks_endorsed = [];

    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];
        var owner = node.owner;
        var a = {'node' : node, 'endorsements': {}, 'largest_kickout_promise': -1};

        annotations.push(a);
        mapping[node.uid] = a;

        var largest_epoch = [];
        var largest_kickout = [];
        for (var i = 0; i < num_users; ++ i) {
            largest_epoch[i] = -1;
            largest_kickout[i] = -1;
        }
        var largest_representative = -1;
        var largest_previous_kickout_promise = -1;

        var visited = {};
        var dfs = function(node) {
            if (visited[node.uid] !== undefined) {
                return;
            }
            visited[node.uid] = 1;

            for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
                var parent_ = node.parents[parent_idx];
                dfs(parent_);

                if (largest_kickout[parent_.owner] > largest_kickout[node.owner]) {
                    largest_kickout[node.owner] = largest_kickout[parent_.owner];
                }
            }

            var a = mapping[node.uid];
            if (a.epoch > largest_epoch[node.owner]) {
                largest_epoch[node.owner] = a.epoch;
            }

            if (a.representative > largest_representative) {
                largest_representative = a.representative;
            }

            if (a.kickout) {
                if (a.epoch > largest_kickout[node.owner]) {
                    largest_kickout[node.owner] = a.epoch;
                }
            }

            if (node.owner == owner && a.largest_kickout_promise > largest_previous_kickout_promise) {
                largest_previous_kickout_promise = a.largest_kickout_promise;
            }
        }
        dfs(node);
        
        var same_epoch = 0;
        for (var i = 0; i < num_users; ++ i) {
            if (largest_epoch[i] >= largest_epoch[node.owner]) {
                ++ same_epoch;
            }
        }

        a.epoch = largest_epoch[node.owner];
        a.representative = -1;
        a.kickout = false;
        if (same_epoch > Math.floor(num_users * 2 / 3)) {
            a.epoch ++;
            if (a.epoch % num_users == node.owner) {
                if (largest_representative == a.epoch - 1 || a.epoch == 0) {
                    a.representative = a.epoch;
                }
                else if (largest_representative < a.epoch) {
                    a.kickout = true;

                    if (a.epoch > largest_kickout[owner]) {
                        largest_kickout[owner] = a.epoch;
                    }
                }
            }
        }

        if (largest_representative < largest_kickout[node.owner]) {
            // There are some kickout votes happening. Let's see if one
            //    of them is for the owner
            // TODO: consider the case when a full cycle of validators rotate
            //    without producing a single block
            var my_skipped_epoch = -1;
            for (var r = largest_representative + 1; r <= largest_kickout[node.owner]; ++ r) {
                if (r % num_users == node.owner && a.epoch >= r) {
                    // node.epoch >= r means the owner definitely posted
                    //    the kickout message
                    my_skipped_epoch = r;
                    break;
                }
            }
        
            if (my_skipped_epoch > -1) {
                // the user has posted the kickout, no representative was published since then
                //     the epoch increases if either 2/3 of participants approved the kickout message,
                //     or the previous representative is reachable
                if (largest_representative == my_skipped_epoch - 1) {
                    a.representative = my_skipped_epoch;
                }
                else {
                    total_kickouts = 0;
                    for (var i = 0; i < num_users; ++ i) {
                        if (largest_kickout[i] >= my_skipped_epoch) {
                            // approving a kickout for an epoch indicates
                            //     an intent to kickout all previous msgs too
                            ++ total_kickouts;
                        }
                    }
                    if (total_kickouts > Math.floor(num_users * 2 / 3)) {
                        a.representative = my_skipped_epoch;
                    }
                }
            }
        }

        var dfs_endorse = function(node) {
            if (visited[node.uid] !== 1) {
                return;
            }
            visited[node.uid] = 2;

            for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
                var parent_ = node.parents[parent_idx];
                dfs_endorse(parent_);
            }

            if (mapping[node.uid].representative > -1) {
                var ok = largest_previous_kickout_promise <= mapping[node.uid].representative;
                for (var idx = 0; idx < node.owner_level_nodes.length; ++ idx ) {
                    var conflict_node = node.owner_level_nodes[idx];
                    if (conflict_node.uid != node.uid && visited[conflict_node.uid]) {
                        ok = false;
                    }
                }

                if (ok) {
                    var num_endorsements = 0;
                    for (var endorser in mapping[node.uid].endorsements) {
                        ++ num_endorsements;
                    }
                    var was_epoch_block = num_endorsements > Math.floor(num_users * 2 / 3);

                    if (mapping[node.uid].endorsements[owner] === undefined) {
                        ++ num_endorsements;
                    }
                    var is_epoch_block = num_endorsements > Math.floor(num_users * 2 / 3);

                    if (is_epoch_block && !was_epoch_block) {
                        epoch_blocks_endorsed.push([mapping[node.uid].representative, node]);
                    }

                    mapping[node.uid].endorsements[owner] = true;
                }
            }
        }
        dfs_endorse(node);

        a.largest_kickout_promise = largest_kickout[owner];
    }

    var last_epoch_block = -1;
    epoch_blocks_endorsed.sort((x, y) => x[0] < y[0] ? -1 : x[0] > y[0] ? 1 : 0);
    for (var i = 0; i < epoch_blocks_endorsed.length; ++ i) {
        var epoch = epoch_blocks_endorsed[i][0];
        var node = epoch_blocks_endorsed[i][1];
        var a = mapping[node.uid];

        a.epoch_block = true;

        var visited = {};
        var dfs_epoch = function(node) {
            var ret = [-1, null]
            if (visited[node.uid] !== undefined) {
                return visited[node.uid];
            }

            for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
                var parent_ = node.parents[parent_idx];
                var cand = dfs_epoch(parent_);
                if (cand[0] > ret[0]) ret = cand;
            }
            
            if (mapping[node.uid].representative > last_epoch_block && !mapping[node.uid].epoch_block) {
                if (mapping[node.uid].representative > ret[0]) {
                    ret = [mapping[node.uid].representative, node];
                }
            }

            visited[node.uid] = ret;
            return ret;
        }

        var dfs_from = node;
        var iter = 0;
        while (dfs_from) {
            mapping[dfs_from.uid].epoch_block = true;
            var mp = dfs_epoch(dfs_from);
            visited = {};
            dfs_from = mp[1];
            ++ iter;
            if (iter > 1000) {
                console.error("Annotating epochs blocks entered an infinite loop?");
                break;
            }
        }

        last_epoch_block = epoch;
    }

    return annotations;
}

var render_graph = function(canvas, graph, num_users) {
    var ctx = canvas.getContext('2d');

    var nodes = toposort(graph);
    annotate_user_levels(nodes);

    var user_w = {};
    var user_l = {};

    for (var i = 0; i < num_users; ++ i) { user_w[i] = 1; }

    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];

        if (user_w[node.owner] < node.owner_level_nodes.length) {
            user_w[node.owner] = node.owner_level_nodes.length;
        }
        
        node.level = 0;
        for (var cg_idx = 0; cg_idx < node.owner_level_nodes.length; ++ cg_idx) {
            var cg_node = node.owner_level_nodes[cg_idx];
            for (var cg_parent_idx = 0; cg_parent_idx < cg_node.parents.length; ++ cg_parent_idx) {
                var cg_parent = cg_node.parents[cg_parent_idx];
                if (cg_parent.level + 1 > node.level) {
                    node.level = cg_parent.level + 1;
                }
            }
        }
    }

    user_l[0] = 0;
    for (var i = 1; i <= num_users; ++ i) { user_l[i] = user_l[i - 1] + user_w[i - 1] * (NODE_W + NODE_S) + NODE_US; }

    var W = 0;
    var H = 0;
    render_nodes_cb(nodes, user_l, function(node, x, y, w, h) { if (x + w > W) W = x + w; if (y + h > H) H = y + h; } );

    W = user_l[num_users];

    canvas.style.width = W + 10 + "px";
    canvas.style.height = H + 200 + "px";
    canvas.width = PIXEL_RATIO * (W + 10);
    canvas.height = PIXEL_RATIO * (H + 200);

	ctx.setTransform(PIXEL_RATIO, 0, 0, PIXEL_RATIO, 0, 0);

    ctx.clearRect(0, 0, W, H);

    ctx.strokeStyle = "black";

    render_nodes_cb(nodes, user_l, function(node, x, y, w, h) {
        ctx.fillStyle = (node.selected) ? "silver" : "white";
        ctx.fillRect(x + 0.5, y + 0.5, w, h);
        ctx.strokeRect(x + 0.5, y + 0.5, w, h);

        for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
            var parent_ = node.parents[parent_idx];

            ctx.beginPath();
            ctx.moveTo(node.coords.l + Math.floor(node.coords.w / 2) + 0.5, node.coords.t + 0.5);
            ctx.lineTo(parent_.coords.l + Math.floor(parent_.coords.w / 2) + 0.5, parent_.coords.t + parent_.coords.h + 0.5);
            ctx.stroke();
        }
    });

    return user_l;
}

var serialize_txflow = function(graph, beacon_mode) {
    var nodes = toposort(graph);

    var s = [];
    var mapping = {};
    for (var node_idx = 0; node_idx < nodes.length; ++ node_idx) {
        var node = nodes[node_idx];
        var snode = {};
        snode.owner = node.owner
        snode.parents = [];
        for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
            snode.parents.push(mapping[node.parents[parent_idx].uid]);
        }

        if (beacon_mode) {
            snode.payload_type = node.payload_type || 0;
            if (snode.payload_type == 1) {
                snode.prevblock = node.prevblock || 0;
            }
        }

        s.push(snode);

        mapping[node.uid] = node_idx;
    }
    return s;
}

var deserialize_txflow = function(s, beacon_mode) {
    last_node_uid = 0;
    var nodes = [];
    for (var i = 0; i < s.length; ++ i) {
        var snode = s[i];
        var parents = [];
        for (var j = 0; j < snode.parents.length; ++ j) {
            parents.push(nodes[snode.parents[j]]);
        }
        var node = create_node(snode.owner, parents);
        if (beacon_mode) {
            node.payload_type = snode.payload_type;
            if (node.payload_type == 1) {
                node.prevblock = snode.prevblock;
            }
        }
        nodes.push(node);
    }
    var graph = [];
    for (var i = 0; i < nodes.length; ++ i) {
        if (nodes[i].children.length == 0) {
            graph.push(nodes[i]);
        }
    }
    return graph;
}

var gen_rust_endorsements = function(node, num_users) {
    var annotations = compute_annotations([node], num_users);
    var nodes = toposort([node]);

    var a_mapping = {};

    for (var aidx = 0; aidx < annotations.length; ++ aidx) {
        a_mapping[annotations[aidx].node.uid] = annotations[aidx];
    }

    var ret = [];

    for (var i = 0; i < nodes.length; ++ i) {
        var node = nodes[i];
        var a = a_mapping[node.uid];

        if (a.representative > -1) {
            for (var e in a.endorsements) {
                while (ret.length <= a.representative) ret.push([]);
                ret[a.representative].push(e);
            }
        }
    }

    var gen_list = function(arr) {
        arr.sort();
        var ret = [];
        for (var i = 0; i < arr.length; ++ i) {
            if (i == 0 || arr[i] != arr[i - 1]) {
                ret.push(arr[i]);
            }
        }
        return ret;
    }

    return '&[' + ret.map(x => "vec![" + gen_list(x).join(', ') + "]").join(', ') + ']';
}

var gen_rust = function(graph, num_users, fn_name, comment, serialized) {
    var annotations = compute_annotations(graph, num_users);
    var nodes = toposort(graph);

    var a_mapping = {};

    for (var aidx = 0; aidx < annotations.length; ++ aidx) {
        a_mapping[annotations[aidx].node.uid] = annotations[aidx];
    }

    var indent = "         ";
    var var_names = [];
    for (var i = 0; i < nodes.length; ++ i) {
        var_names.push("v" + nodes[i].uid);
    }
    var s = "    #[test]\n    fn generated_" + fn_name + "() {\n" + indent + "/* " + comment + " */\n\n" + indent + "/* " + serialized + " */\n"  + indent + "let arena = Arena::new();\n" + indent + "let selector = FakeNonContinuousWitnessSelector::new(" + num_users + ");\n"
    if (var_names.length > 1) {
        s += indent + "let (" + var_names.join(',') + ");\n";
    }
    else {
        s += indent + "let " + var_names[0] + ";\n";
    }
    s += indent + "let mut v = [None; " + var_names.length + "];\n";
    var nf = function(node) {
        var a = a_mapping[node.uid];
        var repr = a.representative < 0 ? 'None' : `Some(${a.representative})`;
        return `(${a.epoch}, ${repr}, ${a.kickout}, ${node.uid})`;
    };
    s += indent + 'let test = |v:&[_]| make_assertions(&v, &[' + nodes.map(nf).join(', ') + ']);\n';
    for (var i = 0; i < nodes.length; ++ i) {
        var node = nodes[i];
        s += indent + 'simple_messages!(0, &selector, arena [';
        if (node.parents.length > 0) {
            var parent_names = [];
            for (var parent_idx = 0; parent_idx < node.parents.length; ++ parent_idx) {
                parent_names.push('=> v' + node.parents[parent_idx].uid + '; ');
            }
            s += '[' + parent_names.join('') + '] => ';
        }
        // use 0 for epoch, and `true` to recompute the epochs
        s += node.owner + ', 0, true => ' + var_names[i] + ';]); v[' + i + '] = Some(' + var_names[i] + ');\n'
        s += indent + 'test(&v);\n';

        s += indent + 'test_endorsements(' + var_names[i] + ', ' + gen_rust_endorsements(node, num_users) + ', ' + num_users + ');\n';
    }

    s += "    }\n"
    return s;
}

if (typeof module !== 'undefined') {
    module.exports.deserialize_txflow = deserialize_txflow;
    module.exports.gen_rust = gen_rust;
    module.exports.create_node = create_node;
    module.exports.compute_annotations = compute_annotations;
    module.exports.toposort = toposort;
}

'''
'''--- test-utils/txflow-test-gen/utils.js ---
var txflow = require('./txflow.js');

var _rand_int = function(n) {
    return Math.floor(Math.random() * n);
}

var get_only_selected_node = function(nodes) {
    var ret = null;

    for (var node of nodes) {
        if (node.selected) {
            if (ret) return null;
            ret = node;
        }
    }

    return ret;
}

var _select_random_nodes = function(nodes) {
    if (nodes.length == 0) return [];

    if (_rand_int(2) == 0) {
        var ret = [];
        var prob = _rand_int(10);
        for (var i = 0; i < nodes.length; ++ i) {
            if (_rand_int(prob) == 0) {
                ret.push(nodes[i]);
            }
        }

        if (ret.length) return ret;
        return _select_random_nodes(nodes);
    }
    else {
        return [nodes[_rand_int(nodes.length)]];
    }
}

var stress_epoch_blocks = function(nodes, num_users, seconds) {
    if (nodes.length == 0) return "No nodes";
    seconds = seconds || 2;

    var started = new Date().getTime();
    var iter = 0;
    var longest_epoch_blocks = [];
    var longest_selected_node_ids = [];
    while (new Date().getTime() - started < seconds * 1000) {
        var selected_nodes = _select_random_nodes(nodes);
        var annotations = txflow.compute_annotations(selected_nodes, num_users);
        var epoch_blocks = [];
        var selected_node_ids = selected_nodes.map(x => x.uid);

        for (var a_idx = 0; a_idx < annotations.length; ++ a_idx) {
            var a = annotations[a_idx];
            if (a.epoch_block) {
                epoch_blocks.push([a.representative, 'v' + a.node.uid]);
            }
        }

        epoch_blocks.sort((x, y) => x[0] < y[0] ? -1 : x[0] > y[0] ? 1 : 0);

        var smaller = Math.min(longest_epoch_blocks.length, epoch_blocks.length);

        for (var i = 0; i < smaller; ++ i) {
            var left = longest_epoch_blocks[i];
            var right = epoch_blocks[i];

            if (left[0] != right[0] || left[1] != right[1]) {
                return `FAILED!\nLeft: nodes: ${longest_selected_node_ids}, epoch blocks: ${longest_epoch_blocks}\nRight: nodes: ${selected_node_ids}, epoch blocks: ${epoch_blocks}`;
            }
        }

        if (epoch_blocks.length > longest_epoch_blocks.length) {
            longest_epoch_blocks = epoch_blocks;
            longest_selected_node_ids = selected_node_ids;
        }

        ++ iter;
    }

    return `PASSED!\nRan stress for ${seconds} seconds. Completed ${iter} iterations.\nLongest epoch blocks: ${longest_epoch_blocks}`;
}

var stress_beacon = function(nodes, num_users, seconds) {
    seconds = seconds || 2;
    var started = new Date().getTime();
    var iter = 0;
    var existing_report = null;
    var existing_reporter = -1;
    while (new Date().getTime() - started < seconds * 1000) {
        var selected_node = nodes[_rand_int(nodes.length)];
        var beacon_chain_observation = compute_beacon_chain_observation(selected_node, num_users);

        var new_report = false;

        for (var key in beacon_chain_observation) {
            if (existing_report === null || existing_report[key] === undefined) {
                new_report = true;
            }
            else {
                if (existing_report[key] != beacon_chain_observation[key]) {
                    return `FAILED\nLeft node: ${existing_reporter}, Right node: ${selected_node.uid}\nLeft report: ${existing_report}\nRight report: ${beacon_chain_observation}`;
                }
            }
        }

        if (new_report) {
            existing_report = beacon_chain_observation;
            existing_reporter = selected_node.uid;
        }
        
        ++ iter;
    }
    return `PASSED!\nRan stress for ${seconds} seconds. Completed ${iter} iterations.\nLargest report: ${JSON.stringify(existing_report)}`;
}

var generate_random_graph = function(num_users, num_malicious, num_nodes, beacon_mode, show_html=true) {
    last_node_uid = 0;

    var mode_users_hanging = _rand_int(2);
    var mode_prefer_non_repr = _rand_int(2);

    var all_nodes = [];
    var nodes_as_seen = [];
    var users_hanging = [];
    var _random_user = function() {
        if (mode_users_hanging) {
            for (var i = 0; i < num_users; ++ i) {
                if (!users_hanging[i] && _rand_int(latencies[i] * 2) == 0) users_hanging[i] = true;
                if (users_hanging[i] && _rand_int(latencies[i] * 3) == 0) users_hanging[i] = false;
            }
        }
        var ret = _rand_int(num_users);
        if (users_hanging[ret]) return _random_user();
        return ret;
    }

    var _get_roots = function(nodes_with_ts, ts) {
        var mark = {};
        for (var pair of nodes_with_ts) {
            if (pair[1] <= ts) {
                for (var parent_ of pair[0].parents) mark[parent_.uid] = 1;
            }
        }
        var ret = [];
        for (var pair of nodes_with_ts) {
            if (pair[1] <= ts) {
                if (mark[pair[0].uid] === undefined) ret.push(pair[0]);
            }
        }
        return ret;
    }
    var _get_parents = function(user_id, ts) {
        if (user_id < num_malicious && _rand_int(3) == 0) {
            return _select_random_nodes(nodes_as_seen[user_id].map(x => x[0]));
        }
        else {
            return _get_roots(nodes_as_seen[user_id], ts);
        }
    }

    var latencies = [];
    var max_latency = Math.max(_rand_int(num_users * 5), _rand_int(num_users * 3));

    for (var i = 0; i < num_users; ++ i) {
        latencies.push(Math.max(_rand_int(max_latency + 1), _rand_int(max_latency + 1)));
        nodes_as_seen.push([]);
        users_hanging.push(false);
    }

    for (var i = 0; i < num_nodes; ++ i) {
        var user_id = _random_user();
        var parents = _get_parents(user_id, i);

        var node = txflow.create_node(user_id, parents);
        if (mode_prefer_non_repr && _rand_int(3) != 0) {
            var annotations = txflow.compute_annotations([node], num_users)
            var skip = false;
            for (var a of annotations) {
                if (a.node.uid == node.uid && a.representative != -1) {
                    skip = true;
                }
            }
            if (skip) { --i; continue; }
        }
        all_nodes.push([node, 0]);
        for (var j = 0; j < num_users; ++ j) {
            var latency = Math.max(_rand_int(latencies[j] + 1), _rand_int(latencies[j] + 1));
            if (j == user_id) latency = 0;
            nodes_as_seen[j].push([node, i + latency]);
        }
    }

    graph = _get_roots(all_nodes, 0);
    for (var node of graph) node.selected = true;

    if (beacon_mode) {
        var changed = true;
        var iters = 0;
        while (changed) {
            changed = false;
            ++ iters;
            if (iters >= 30) {
                console.error("Beacon mode randgen entered an infinite loop");
                break;
            }

            var beacon_states = [];
            for (var i = 0; i < num_users; ++ i) {
                beacon_states.push(-1);
            }

            var annotations = txflow.compute_annotations(graph, num_users)
            var toposorted = txflow.toposort(graph);
            add_beacon_annotations(toposorted, annotations, num_users);

            for (var a of annotations) {
                var node = a.node;
                if (a.state > beacon_states[node.owner]) {
                    var old_payload = node.payload_type || PAYLOAD_NONE;
                    beacon_states[node.owner] = a.state;
                    if (a.state == STATE_INIT) {
                        node.payload_type = PAYLOAD_PREVBLOCK;
                        node.prevblock = _rand_int(10);
                    }
                    else if (a.state == STATE_PREVDF) {
                        if (_rand_int(3) == 1) {
                            node.payload_type = PAYLOAD_VDF;
                        }
                        else {
                            -- beacon_states[node.owner];
                        }
                    }
                    else if (a.state == STATE_COMMIT) {
                        node.payload_type = PAYLOAD_COMMIT;
                    }
                    else if (a.state == STATE_SIGNATURE) {
                        node.payload_type = PAYLOAD_SIGNATURE;
                    }
                    var new_payload = node.payload_type || PAYLOAD_NONE;
                    if (new_payload != old_payload) {
                        changed = true;
                    }
                }
            }
        }
    }
    if (show_html) {
        refresh();
        serialize();
        alert(stress_epoch_blocks(all_nodes.map(x => x[0]), num_users, 0.5));
    }
    return graph;
}

if (typeof module !== 'undefined') {
    module.exports.generate_random_graph = generate_random_graph;
    module.exports.stress_epoch_blocks = stress_epoch_blocks;
}

'''
'''--- tests/hello/assembly/main.ts ---
import "allocator/arena";
export { memory };

import { context, storage, ContractPromise, ContractPromiseResult, near } from "./near";

import { PromiseArgs, InputPromiseArgs, MyCallbackResult, MyContractPromiseResult } from "./model.near";

export function hello(name: string): string {

  return "hello " + name;
}

export function setKeyValue(key: string, value: string): void {
  storage.setItem(key, value);
}

export function getValueByKey(key: string): string {
  return storage.getItem(key);
}

export function setValue(value: string): string {
  storage.setItem("name", value);
  return value;
}

export function getValue(): string {
  return storage.getItem("name");
}

export function getAllKeys(): string[] {
  let keys = storage.keys("n");
  assert(keys.length == 1);
  assert(keys[0] == "name");
  return keys;
}

export function benchmark(): string[] {
  let i = 0;
  while (i < 10) {
    storage.setItem(i.toString(), "123123");
    i += 1;
  }
  return storage.keys("");
}

export function benchmark_storage(n: i32): string {
  let i = 0;
  while (i < n) {
    storage.setItem(i.toString(), i.toString());
    i += 1;
  }
  i = 0;
  let sum: u64 = 0;
  while (i < n) {
    let item = I32.parseInt(storage.getItem(i.toString()));
    sum += item;
    i += 1;
  }
  return sum.toString()
}

export function limited_storage(max_storage: u64): string {
  let i = 0;
  while (context.storageUsage <= max_storage) {
    i += 1;
    storage.setItem(i.toString(), i.toString());
  }
  if (context.storageUsage > max_storage) {
    storage.removeItem(i.toString());
  }
  return i.toString()
}

export function benchmark_sum_n(n: i32): string {
  let i = 0;
  let sum: u64 = 0;
  while (i < n) {
    sum += i;
    i += 1;
  }
  return sum.toString()
}

export function generateLogs(): void {
  storage.setItem("item", "value");
  near.log("log1");
  near.log("log2");
}

export function returnHiWithLogs(): string {
  near.log("loooog1");
  near.log("loooog2");
  return "Hi"
}

export function triggerAssert(): void {
  near.log("log before assert");
  assert(false, "expected to fail");
}

export function testSetRemove(value: string): void {
  storage.setItem("test", value);
  storage.removeItem("test");
  assert(storage.getItem("test") == null, "Item must be empty");
}

function buildString(n: i32): string {
  assert(n >= 0);
  let result = "";
  for (let i = 20; i >= 0; --i) {
    result = result + result;
    if ((n >> i) & 1) {
      result += "a";
    }
  }
  return result;
}

export function insertStrings(from: i32, to: i32): void {
  let str = buildString(to);
  for (let i = from; i < to; i++) {
    storage.setItem(str.substr(to - i) + "b", "x");
  }
}

export function deleteStrings(from: i32, to: i32): void {
  let str = buildString(to);
  for (let i = to - 1; i >= from; i--) {
    storage.removeItem(str.substr(to - i) + "b");
  }
}

export function recurse(n: i32): i32 {
  if (n <= 0) {
    return n;
  }
  return recurse(n - 1) + 1;
}

// For testing promises

export function callPromise(args: PromiseArgs): void {
  let inputArgs: InputPromiseArgs = { args: args.args };
  near.log('1');
  let promise = ContractPromise.create(
      args.receiver,
      args.methodName,
      inputArgs.encode(),
      args.balance);
  near.log('2');
  if (args.callback) {
    inputArgs.args = args.callbackArgs;
    promise = promise.then(
        args.callback,
        inputArgs.encode(),
        args.callbackBalance);
  }
  near.log('3');
  promise.returnAsResult();
}

function strFromBytes(buffer: Uint8Array): string {
  return String.fromUTF8(buffer.buffer.data, buffer.byteLength);
}

export function callbackWithName(args: PromiseArgs): MyCallbackResult {
  let contractResults = ContractPromise.getResults();
  let allRes = new Array<MyContractPromiseResult>(contractResults.length);
  for (let i = 0; i < contractResults.length; ++i) {
    allRes[i] = new MyContractPromiseResult();
    allRes[i].ok = contractResults[i].success;
    if (allRes[i].ok && contractResults[i].buffer != null && contractResults[i].buffer.length > 0) {
      allRes[i].r = MyCallbackResult.decode(contractResults[i].buffer);
    }
  } 
  let result: MyCallbackResult = {
    rs: allRes,
    n: context.contractName,
  }
  let bytes = result.encode();
  near.log(strFromBytes(bytes));
  storage.setBytes("lastResult", bytes);
  return result;
}

export function getLastResult(): MyCallbackResult {
  return MyCallbackResult.decode(storage.getBytes("lastResult"));
}

'''
'''--- tests/hello/assembly/model.ts ---
export class PromiseArgs {
    receiver: string;
    methodName: string;
    args: PromiseArgs;
    balance: i32;
    callback: string;
    callbackArgs: PromiseArgs;
    callbackBalance: i32;
}

export class InputPromiseArgs {
    args: PromiseArgs;
}

export class MyContractPromiseResult {
    ok: bool;
    r: MyCallbackResult;
  }

export class MyCallbackResult {
    rs: MyContractPromiseResult[];
    n: string;
}

'''
'''--- tests/hello/assembly/tsconfig.json ---
{
  "extends": "../node_modules/assemblyscript/std/assembly.json",
  "include": [
    "./**/*.ts"
  ]
}

'''
'''--- tests/hello/gulpfile.js ---
const gulp = require("gulp");
const nearUtils = require("near-shell/gulp-utils");

gulp.task("build:model", callback => {
  nearUtils.generateBindings("model.ts", "../out/model.near.ts", callback);
});

gulp.task("build:bindings", ["build:model"], callback => {
  nearUtils.generateBindings("main.ts", "../out/main.near.ts", callback);
});

gulp.task("build", ["build:bindings"], callback => {
  nearUtils.compile("../out/main.near.ts", "../out/main.wasm", callback);
});

gulp.task("default", ["build"]);

// TODO: Extract all following boilerplate into library

// This task is not required when running the project locally. Its purpose is to set up the
// AssemblyScript compiler when a new project has been loaded in WebAssembly Studio.
gulp.task("project:load", () => {
  const utils = require("@wasm/studio-utils");
  utils.eval(utils.project.getFile("setup.js").getData(), {
    logLn,
    project,
    monaco,
    fileTypeForExtension,
  });
});

'''
'''--- tests/hello/package.json ---
{
    "name": "hello-wasm",
    "version": "0.1.0",
    "dependencies": {
        "assemblyscript-json": "github:nearprotocol/assemblyscript-json",
        "near-runtime-ts": "github:nearprotocol/near-runtime-ts#nightshade",
        "nearlib": "github:nearprotocol/nearlib#nightshade"
    },
    "scripts": {
        "build": "mkdir -p ./out && near build && cp ./out/main.wasm ../hello.wasm"
    },
    "devDependencies": {
        "gulp": "^3.0.0",
        "near-shell": "github:nearprotocol/near-shell#nightshade"
    }
}

'''
'''--- tests/test_cases_runtime.rs ---
#[cfg(test)]
mod test {
    use testlib::node::RuntimeNode;
    use testlib::runtime_utils::alice_account;
    use testlib::standard_test_cases::*;

    fn create_runtime_node() -> RuntimeNode {
        RuntimeNode::new(&alice_account())
    }

    #[test]
    fn test_smart_contract_simple_runtime() {
        let node = create_runtime_node();
        test_smart_contract_simple(node);
    }

    #[test]
    fn test_smart_contract_bad_method_name_runtime() {
        let node = create_runtime_node();
        test_smart_contract_bad_method_name(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_no_tokens_runtime() {
        let node = create_runtime_node();
        test_smart_contract_empty_method_name_with_no_tokens(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_tokens_runtime() {
        let node = create_runtime_node();
        test_smart_contract_empty_method_name_with_tokens(node);
    }

    #[test]
    fn test_smart_contract_with_args_runtime() {
        let node = create_runtime_node();
        test_smart_contract_with_args(node);
    }

    #[test]
    fn test_async_call_with_no_callback_runtime() {
        let node = create_runtime_node();
        test_async_call_with_no_callback(node);
    }

    #[test]
    fn test_async_call_with_callback_runtime() {
        let node = create_runtime_node();
        test_async_call_with_callback(node);
    }

    #[test]
    fn test_async_call_with_logs_runtime() {
        let node = create_runtime_node();
        test_async_call_with_logs(node);
    }

    #[test]
    fn test_callback_runtime() {
        let node = create_runtime_node();
        test_callback(node);
    }

    #[test]
    fn test_callback_failure_runtime() {
        let node = create_runtime_node();
        test_callback_failure(node);
    }

    #[test]
    fn test_deposit_with_callback_runtime() {
        let node = create_runtime_node();
        test_deposit_with_callback(node);
    }

    #[test]
    fn test_nonce_update_when_deploying_contract_runtime() {
        let node = create_runtime_node();
        test_nonce_update_when_deploying_contract(node);
    }

    #[test]
    fn test_nonce_updated_when_tx_failed_runtime() {
        let node = create_runtime_node();
        test_nonce_updated_when_tx_failed(node);
    }

    #[test]
    fn test_upload_contract_runtime() {
        let node = create_runtime_node();
        test_upload_contract(node);
    }

    #[test]
    fn test_redeploy_contract_runtime() {
        let node = create_runtime_node();
        test_redeploy_contract(node);
    }

    #[test]
    fn test_send_money_runtime() {
        let node = create_runtime_node();
        test_send_money(node);
    }

    #[test]
    fn test_send_money_over_balance_runtime() {
        let node = create_runtime_node();
        test_send_money_over_balance(node);
    }

    #[test]
    fn test_refund_on_send_money_to_non_existent_account_runtime() {
        let node = create_runtime_node();
        test_refund_on_send_money_to_non_existent_account(node);
    }

    #[test]
    fn test_create_account_runtime() {
        let node = create_runtime_node();
        test_create_account(node);
    }

    #[test]
    fn test_create_account_again_runtime() {
        let node = create_runtime_node();
        test_create_account_again(node);
    }

    #[test]
    fn test_create_account_failure_invalid_name_runtime() {
        let node = create_runtime_node();
        test_create_account_failure_invalid_name(node);
    }

    #[test]
    fn test_create_account_failure_already_exists_runtime() {
        let node = create_runtime_node();
        test_create_account_failure_already_exists(node);
    }

    #[test]
    fn test_swap_key_runtime() {
        let node = create_runtime_node();
        test_swap_key(node);
    }

    #[test]
    fn test_add_key_runtime() {
        let node = create_runtime_node();
        test_add_key(node);
    }

    #[test]
    fn test_add_existing_key_runtime() {
        let node = create_runtime_node();
        test_add_existing_key(node);
    }

    #[test]
    fn test_delete_key_runtime() {
        let node = create_runtime_node();
        test_delete_key(node);
    }

    #[test]
    fn test_delete_key_not_owned_runtime() {
        let node = create_runtime_node();
        test_delete_key_not_owned(node);
    }

    #[test]
    fn test_delete_key_last_runtime() {
        let node = create_runtime_node();
        test_delete_key_last(node);
    }

    #[test]
    fn test_add_access_key_runtime() {
        let node = create_runtime_node();
        test_add_access_key(node);
    }

    #[test]
    fn test_delete_access_key_runtime() {
        let node = create_runtime_node();
        test_delete_access_key(node);
    }

    #[test]
    fn test_add_access_key_with_funding_runtime() {
        let node = create_runtime_node();
        test_add_access_key_with_funding(node);
    }

    #[test]
    fn test_delete_access_key_with_owner_refund_runtime() {
        let node = create_runtime_node();
        test_delete_access_key_with_owner_refund(node);
    }

    #[test]
    fn test_delete_access_key_with_bob_refund_runtime() {
        let node = create_runtime_node();
        test_delete_access_key_with_bob_refund(node);
    }

    #[test]
    fn test_access_key_smart_contract_runtime() {
        let node = create_runtime_node();
        test_access_key_smart_contract(node);
    }

    #[test]
    fn test_access_key_smart_contract_reject_method_name_runtime() {
        let node = create_runtime_node();
        test_access_key_smart_contract_reject_method_name(node);
    }

    #[test]
    fn test_access_key_smart_contract_reject_contract_id_runtime() {
        let node = create_runtime_node();
        test_access_key_smart_contract_reject_contract_id(node);
    }

    #[test]
    fn test_access_key_reject_non_function_call_runtime() {
        let node = create_runtime_node();
        test_access_key_reject_non_function_call(node);
    }
}

'''
'''--- tests/test_cases_runtime_shard.rs ---
#[cfg(test)]
mod test {
    use configs::ClientConfig;
    use node_runtime::chain_spec::{AuthorityRotation, ChainSpec, DefaultIdType};
    use testlib::node::runtime_node::RuntimeNode;
    use testlib::node::shard_client_node::ShardClientNode;
    use testlib::runtime_utils::alice_account;
    use testlib::standard_test_cases::*;

    fn test_chain_spec() -> ChainSpec {
        ChainSpec::testing_spec(DefaultIdType::Named, 3, 3, AuthorityRotation::ProofOfAuthority).0
    }

    fn create_shard_client_node() -> ShardClientNode {
        let mut client_cfg = ClientConfig::default_devnet();
        client_cfg.chain_spec = test_chain_spec();
        ShardClientNode::new(client_cfg)
    }

    fn create_runtime_node() -> RuntimeNode {
        RuntimeNode::new(&alice_account())
    }

    #[test]
    fn test_smart_contract_simple_runtime() {
        let node = create_runtime_node();
        test_smart_contract_simple(node);
    }

    #[test]
    fn test_smart_contract_simple_shard_client() {
        let node = create_shard_client_node();
        test_smart_contract_simple(node);
    }

    #[test]
    fn test_smart_contract_bad_method_name_runtime() {
        let node = create_runtime_node();
        test_smart_contract_bad_method_name(node);
    }

    #[test]
    fn test_smart_contract_bad_method_name_shard_client() {
        let node = create_shard_client_node();
        test_smart_contract_bad_method_name(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_no_tokens_runtime() {
        let node = create_runtime_node();
        test_smart_contract_empty_method_name_with_no_tokens(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_no_tokens_shard_client() {
        let node = create_shard_client_node();
        test_smart_contract_empty_method_name_with_no_tokens(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_tokens_runtime() {
        let node = create_runtime_node();
        test_smart_contract_empty_method_name_with_tokens(node);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_tokens_shard_client() {
        let node = create_shard_client_node();
        test_smart_contract_empty_method_name_with_tokens(node);
    }

    #[test]
    fn test_smart_contract_with_args_runtime() {
        let node = create_runtime_node();
        test_smart_contract_with_args(node);
    }

    #[test]
    fn test_smart_contract_with_args_shard_client() {
        let node = create_shard_client_node();
        test_smart_contract_with_args(node);
    }

    #[test]
    fn test_async_call_with_no_callback_runtime() {
        let node = create_runtime_node();
        test_async_call_with_no_callback(node);
    }

    #[test]
    fn test_async_call_with_no_callback_shard_client() {
        let node = create_shard_client_node();
        test_async_call_with_no_callback(node);
    }

    #[test]
    fn test_async_call_with_callback_runtime() {
        let node = create_runtime_node();
        test_async_call_with_callback(node);
    }

    #[test]
    fn test_async_call_with_callback_shard_client() {
        let node = create_shard_client_node();
        test_async_call_with_callback(node);
    }

    #[test]
    fn test_async_call_with_logs_runtime() {
        let node = create_runtime_node();
        test_async_call_with_logs(node);
    }

    #[test]
    fn test_async_call_with_logs_shard_client() {
        let node = create_shard_client_node();
        test_async_call_with_logs(node);
    }

    #[test]
    fn test_callback_runtime() {
        let node = create_runtime_node();
        test_callback(node);
    }

    #[test]
    fn test_callback_failure_runtime() {
        let node = create_runtime_node();
        test_callback_failure(node);
    }

    #[test]
    fn test_deposit_with_callback_runtime() {
        let node = create_runtime_node();
        test_deposit_with_callback(node);
    }

    #[test]
    fn test_deposit_with_callback_shard_client() {
        let node = create_shard_client_node();
        test_deposit_with_callback(node);
    }

    #[test]
    fn test_nonce_update_when_deploying_contract_runtime() {
        let node = create_runtime_node();
        test_nonce_update_when_deploying_contract(node);
    }

    #[test]
    fn test_nonce_update_when_deploying_contract_shard_client() {
        let node = create_shard_client_node();
        test_nonce_update_when_deploying_contract(node);
    }

    #[test]
    fn test_nonce_updated_when_tx_failed_runtime() {
        let node = create_runtime_node();
        test_nonce_updated_when_tx_failed(node);
    }

    #[test]
    fn test_nonce_updated_when_tx_failed_shard_client() {
        let node = create_shard_client_node();
        test_nonce_updated_when_tx_failed(node);
    }

    #[test]
    fn test_upload_contract_runtime() {
        let node = create_runtime_node();
        test_upload_contract(node);
    }

    #[test]
    fn test_upload_contract_shard_client() {
        let node = create_shard_client_node();
        test_upload_contract(node);
    }

    #[test]
    fn test_redeploy_contract_runtime() {
        let node = create_runtime_node();
        test_redeploy_contract(node);
    }

    #[test]
    fn test_redeploy_contract_shard_client() {
        let node = create_shard_client_node();
        test_redeploy_contract(node);
    }

    #[test]
    fn test_send_money_runtime() {
        let node = create_runtime_node();
        test_send_money(node);
    }

    #[test]
    fn test_send_money_shard_client() {
        let node = create_shard_client_node();
        test_send_money(node);
    }

    #[test]
    fn test_send_money_over_balance_runtime() {
        let node = create_runtime_node();
        test_send_money_over_balance(node);
    }

    #[test]
    fn test_send_money_over_balance_shard_client() {
        let node = create_shard_client_node();
        test_send_money_over_balance(node);
    }

    #[test]
    fn test_refund_on_send_money_to_non_existent_account_runtime() {
        let node = create_runtime_node();
        test_refund_on_send_money_to_non_existent_account(node);
    }

    #[test]
    fn test_refund_on_send_money_to_non_existent_account_shard_client() {
        let node = create_shard_client_node();
        test_refund_on_send_money_to_non_existent_account(node);
    }

    #[test]
    fn test_create_account_runtime() {
        let node = create_runtime_node();
        test_create_account(node);
    }

    #[test]
    fn test_create_account_shard_client() {
        let node = create_shard_client_node();
        test_create_account(node);
    }

    #[test]
    fn test_create_account_again_runtime() {
        let node = create_runtime_node();
        test_create_account_again(node);
    }

    #[test]
    fn test_create_account_again_shard_client() {
        let node = create_shard_client_node();
        test_create_account_again(node);
    }

    #[test]
    fn test_create_account_failure_invalid_name_runtime() {
        let node = create_runtime_node();
        test_create_account_failure_invalid_name(node);
    }

    #[test]
    fn test_create_account_failure_invalid_name_shard_client() {
        let node = create_shard_client_node();
        test_create_account_failure_invalid_name(node);
    }

    #[test]
    fn test_create_account_failure_already_exists_runtime() {
        let node = create_runtime_node();
        test_create_account_failure_already_exists(node);
    }

    #[test]
    fn test_create_account_failure_already_exists_shard_client() {
        let node = create_shard_client_node();
        test_create_account_failure_already_exists(node);
    }

    #[test]
    fn test_swap_key_runtime() {
        let node = create_runtime_node();
        test_swap_key(node);
    }

    #[test]
    fn test_swap_key_shard_client() {
        let node = create_shard_client_node();
        test_swap_key(node);
    }

    #[test]
    fn test_add_key_runtime() {
        let node = create_runtime_node();
        test_add_key(node);
    }

    #[test]
    fn test_add_key_shard_client() {
        let node = create_shard_client_node();
        test_add_key(node);
    }

    #[test]
    fn test_add_existing_key_runtime() {
        let node = create_runtime_node();
        test_add_existing_key(node);
    }

    #[test]
    fn test_add_existing_key_shard_client() {
        let node = create_shard_client_node();
        test_add_existing_key(node);
    }

    #[test]
    fn test_delete_key_runtime() {
        let node = create_runtime_node();
        test_delete_key(node);
    }

    #[test]
    fn test_delete_key_shard_client() {
        let node = create_shard_client_node();
        test_delete_key(node);
    }

    #[test]
    fn test_delete_key_not_owned_runtime() {
        let node = create_runtime_node();
        test_delete_key_not_owned(node);
    }

    #[test]
    fn test_delete_key_not_owned_shard_client() {
        let node = create_shard_client_node();
        test_delete_key_not_owned(node);
    }

    #[test]
    fn test_delete_key_no_key_left_runtime() {
        let node = create_runtime_node();
        test_delete_key_no_key_left(node);
    }

    #[test]
    fn test_delete_key_no_key_left_shard_client() {
        let node = create_shard_client_node();
        test_delete_key_no_key_left(node);
    }
}

'''
'''--- tests/test_cases_testnet_direct.rs ---
//! Runs standard test cases against TestNet with several nodes running in separate threads.
//! The communication is performed through `ThreadUser` that performs direct communication with
//! internals of nodes.
#[cfg(feature = "old_tests")]
#[cfg(feature = "expensive_tests")]
#[cfg(test)]
mod test {
    use testlib::standard_test_cases::*;

    use node_runtime::chain_spec::DefaultIdType;
    use std::sync::atomic::{AtomicU16, Ordering};
    use testlib::node::thread_node::ThreadNode;
    use testlib::node::{
        create_nodes_with_id_type, Node, NodeConfig, TEST_BLOCK_FETCH_LIMIT, TEST_BLOCK_MAX_SIZE,
    };
    use testlib::runtime_utils::alice_account;
    use testlib::test_helpers::heavy_test;
    const NUM_TEST_NODE: usize = 4;
    static TEST_PORT: AtomicU16 = AtomicU16::new(6000);

    fn create_thread_nodes(test_prefix: &str, test_port: u16) -> Vec<ThreadNode> {
        let (_, account_names, nodes) = create_nodes_with_id_type(
            NUM_TEST_NODE,
            test_prefix,
            test_port,
            TEST_BLOCK_FETCH_LIMIT,
            TEST_BLOCK_MAX_SIZE,
            vec![],
            DefaultIdType::Named,
        );
        assert_eq!(account_names[0], alice_account());
        let mut nodes: Vec<_> = nodes
            .into_iter()
            .map(|cfg| match cfg {
                NodeConfig::Thread(config) => ThreadNode::new(config),
                _ => unreachable!(),
            })
            .collect();
        for i in 0..NUM_TEST_NODE {
            nodes[i].start();
        }
        nodes
    }

    /// Macro for running testnet test. Increment the atomic global counter for port,
    /// and get the test_prefix from the test name.
    macro_rules! run_testnet_test {
        ($f:expr) => {
            let port = TEST_PORT.fetch_add(NUM_TEST_NODE as u16, Ordering::SeqCst);
            let test_prefix = stringify!($f);
            let mut nodes = create_thread_nodes(test_prefix, port);
            let node = nodes.pop().unwrap();
            heavy_test(|| $f(node));
        };
    }

    #[test]
    fn test_smart_contract_simple_testnet() {
        run_testnet_test!(test_smart_contract_simple);
    }

    #[test]
    fn test_smart_contract_bad_method_name_testnet() {
        run_testnet_test!(test_smart_contract_bad_method_name);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_no_tokens_testnet() {
        run_testnet_test!(test_smart_contract_empty_method_name_with_no_tokens);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_tokens_testnet() {
        run_testnet_test!(test_smart_contract_empty_method_name_with_tokens);
    }

    #[test]
    fn test_smart_contract_with_args_testnet() {
        run_testnet_test!(test_smart_contract_with_args);
    }

    #[test]
    fn test_async_call_with_no_callback_testnet() {
        run_testnet_test!(test_async_call_with_no_callback);
    }

    #[test]
    fn test_async_call_with_callback_testnet() {
        run_testnet_test!(test_async_call_with_callback);
    }

    #[test]
    fn test_async_call_with_logs_testnet() {
        run_testnet_test!(test_async_call_with_logs);
    }

    #[test]
    fn test_deposit_with_callback_testnet() {
        run_testnet_test!(test_deposit_with_callback);
    }

    #[test]
    fn test_nonce_update_when_deploying_contract_testnet() {
        run_testnet_test!(test_nonce_update_when_deploying_contract);
    }

    #[test]
    fn test_nonce_updated_when_tx_failed_testnet() {
        run_testnet_test!(test_nonce_updated_when_tx_failed);
    }

    #[test]
    fn test_upload_contract_testnet() {
        run_testnet_test!(test_upload_contract);
    }

    #[test]
    fn test_redeploy_contract_testnet() {
        run_testnet_test!(test_redeploy_contract);
    }

    #[test]
    fn test_send_money_testnet() {
        run_testnet_test!(test_send_money);
    }

    #[test]
    fn test_send_money_over_balance_testnet() {
        run_testnet_test!(test_send_money_over_balance);
    }

    #[test]
    fn test_refund_on_send_money_to_non_existent_account_testnet() {
        run_testnet_test!(test_refund_on_send_money_to_non_existent_account);
    }

    #[test]
    fn test_create_account_testnet() {
        run_testnet_test!(test_create_account);
    }

    #[test]
    fn test_create_account_again_testnet() {
        run_testnet_test!(test_create_account_again);
    }

    #[test]
    fn test_create_account_failure_invalid_name_testnet() {
        run_testnet_test!(test_create_account_failure_invalid_name);
    }

    #[test]
    fn test_create_account_failure_already_exists_testnet() {
        run_testnet_test!(test_create_account_failure_already_exists);
    }

    #[test]
    fn test_swap_key_testnet() {
        run_testnet_test!(test_swap_key);
    }

    #[test]
    fn test_add_key_testnet() {
        run_testnet_test!(test_add_key);
    }

    #[test]
    fn test_add_existing_key_testnet() {
        run_testnet_test!(test_add_existing_key);
    }

    #[test]
    fn test_delete_key_testnet() {
        run_testnet_test!(test_delete_key);
    }

    #[test]
    fn test_delete_key_not_owned_testnet() {
        run_testnet_test!(test_delete_key_not_owned);
    }

    #[test]
    fn test_delete_key_last_testnet() {
        run_testnet_test!(test_delete_key_last);
    }

    #[test]
    fn test_add_access_key_testnet() {
        run_testnet_test!(test_add_access_key);
    }

    #[test]
    fn test_delete_access_key_testnet() {
        run_testnet_test!(test_delete_access_key);
    }

    #[test]
    fn test_add_access_key_with_funding_testnet() {
        run_testnet_test!(test_add_access_key_with_funding);
    }

    #[test]
    fn test_delete_access_key_with_owner_refund_testnet() {
        run_testnet_test!(test_delete_access_key_with_owner_refund);
    }

    #[test]
    fn test_delete_access_key_with_bob_refund_testnet() {
        run_testnet_test!(test_delete_access_key_with_bob_refund);
    }

    #[test]
    fn test_access_key_smart_contract_testnet() {
        run_testnet_test!(test_access_key_smart_contract);
    }

    #[test]
    fn test_access_key_smart_contract_reject_method_name_testnet() {
        run_testnet_test!(test_access_key_smart_contract_reject_method_name);
    }

    #[test]
    fn test_access_key_smart_contract_reject_contract_id_testnet() {
        run_testnet_test!(test_access_key_smart_contract_reject_contract_id);
    }

    #[test]
    fn test_access_key_reject_non_function_call_testnet() {
        run_testnet_test!(test_access_key_reject_non_function_call);
    }
}

'''
'''--- tests/test_cases_testnet_rpc.rs ---
//! Runs standard test cases against TestNet with several nodes running in separate threads.
//! The communication is performed through `RPCUser` that uses the standard RPC API to communicate.
#[cfg(feature = "expensive_tests")]
#[cfg(test)]
mod test {
    use std::thread;
    use std::time::Duration;

    use near_primitives::test_utils::init_test_module_logger;
    use testlib::node::{create_nodes_from_seeds, Node, NodeConfig, ThreadNode};
    use testlib::runtime_utils::alice_account;
    use testlib::standard_test_cases::*;
    use testlib::test_helpers::heavy_test;

    fn create_thread_nodes_rpc() -> Vec<ThreadNode> {
        init_test_module_logger("runtime");
        let mut nodes = create_nodes_from_seeds(vec![
            "alice.near".to_string(),
            "bob.near".to_string(),
            "carol.near".to_string(),
            "dan.near".to_string(),
        ]);
        let mut nodes: Vec<_> = nodes
            .drain(..)
            .map(|cfg| match cfg {
                NodeConfig::Thread(config) => ThreadNode::new(config),
                _ => unreachable!(),
            })
            .collect();
        let account_names: Vec<_> = nodes.iter().map(|node| node.account_id().unwrap()).collect();

        assert_eq!(account_names[0], alice_account());
        for i in 0..nodes.len() {
            nodes[i].start();
        }
        // Let the nodes boot up a bit.
        for _ in 0..100 {
            let block_index = nodes[0].user().get_best_block_index();
            if block_index.is_some() && block_index.unwrap() > 1 {
                break;
            }
            thread::sleep(Duration::from_millis(100));
        }

        nodes
    }

    /// Macro for running testnet tests using ThreadNode and RPCUser.
    /// Guard each test with heavy_test mutex.
    macro_rules! run_testnet_test {
        ($f:expr) => {
            heavy_test(|| {
                let mut nodes = create_thread_nodes_rpc();
                let node = nodes.pop().unwrap();
                $f(node)
            });
        };
    }

    #[test]
    fn test_smart_contract_simple_testnet() {
        run_testnet_test!(test_smart_contract_simple);
    }

    #[test]
    fn test_smart_contract_bad_method_name_testnet() {
        run_testnet_test!(test_smart_contract_bad_method_name);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_no_tokens_testnet() {
        run_testnet_test!(test_smart_contract_empty_method_name_with_no_tokens);
    }

    #[test]
    fn test_smart_contract_empty_method_name_with_tokens_testnet() {
        run_testnet_test!(test_smart_contract_empty_method_name_with_tokens);
    }

    #[test]
    fn test_smart_contract_with_args_testnet() {
        run_testnet_test!(test_smart_contract_with_args);
    }

    #[test]
    fn test_nonce_update_when_deploying_contract_testnet() {
        run_testnet_test!(test_nonce_update_when_deploying_contract);
    }

    #[test]
    fn test_nonce_updated_when_tx_failed_testnet() {
        run_testnet_test!(test_nonce_updated_when_tx_failed);
    }

    #[test]
    fn test_upload_contract_testnet() {
        run_testnet_test!(test_upload_contract);
    }

    #[test]
    fn test_redeploy_contract_testnet() {
        run_testnet_test!(test_redeploy_contract);
    }

    #[test]
    fn test_send_money_testnet() {
        run_testnet_test!(test_send_money);
    }

    #[test]
    fn test_send_money_over_balance_testnet() {
        run_testnet_test!(test_send_money_over_balance);
    }

    #[test]
    fn test_refund_on_send_money_to_non_existent_account_testnet() {
        run_testnet_test!(test_refund_on_send_money_to_non_existent_account);
    }

    #[test]
    fn test_create_account_testnet() {
        run_testnet_test!(test_create_account);
    }

    #[test]
    fn test_create_account_again_testnet() {
        run_testnet_test!(test_create_account_again);
    }

    #[test]
    fn test_create_account_failure_invalid_name_testnet() {
        run_testnet_test!(test_create_account_failure_invalid_name);
    }

    #[test]
    fn test_create_account_failure_already_exists_testnet() {
        run_testnet_test!(test_create_account_failure_already_exists);
    }

    #[test]
    fn test_swap_key_testnet() {
        run_testnet_test!(test_swap_key);
    }

    #[test]
    fn test_add_key_testnet() {
        run_testnet_test!(test_add_key);
    }

    #[test]
    fn test_add_existing_key_testnet() {
        run_testnet_test!(test_add_existing_key);
    }

    #[test]
    fn test_delete_key_testnet() {
        run_testnet_test!(test_delete_key);
    }

    #[test]
    fn test_delete_key_not_owned_testnet() {
        run_testnet_test!(test_delete_key_not_owned);
    }

    #[test]
    fn test_delete_key_last_testnet() {
        run_testnet_test!(test_delete_key_last);
    }

    #[test]
    fn test_add_access_key_testnet() {
        run_testnet_test!(test_add_access_key);
    }

    #[test]
    fn test_delete_access_key_testnet() {
        run_testnet_test!(test_delete_access_key);
    }

    #[test]
    fn test_add_access_key_with_funding_testnet() {
        run_testnet_test!(test_add_access_key_with_funding);
    }

    #[test]
    fn test_delete_access_key_with_owner_refund_testnet() {
        run_testnet_test!(test_delete_access_key_with_owner_refund);
    }

    #[test]
    fn test_delete_access_key_with_bob_refund_testnet() {
        run_testnet_test!(test_delete_access_key_with_bob_refund);
    }

    #[test]
    fn test_access_key_smart_contract_testnet() {
        run_testnet_test!(test_access_key_smart_contract);
    }
}

'''
'''--- tests/test_catchup.rs ---
//! Checks that late validator can catch-up and start validating.
#[test]
#[cfg(feature = "expensive_tests")]
fn test_catchup() {
    use std::time::Duration;

    use std::sync::{Arc, RwLock};
    use testlib::node::{create_nodes, Node};
    use testlib::test_helpers::{heavy_test, wait};

    /// Creates a network of `num_nodes` nodes, but starts only `num_nodes - 1`. After
    /// `num_blocks_to_wait` starts the last node and verifies that it can start validating within
    /// `catchup_timeout`.
    fn run_multiple_nodes(
        num_nodes: usize,
        num_blocks_to_wait: usize,
        catchup_timeout: Duration,
        block_generation_timeout: Duration,
        test_prefix: &str,
    ) {
        let mut nodes = create_nodes(num_nodes, test_prefix);

        let mut nodes: Vec<Arc<RwLock<dyn Node>>> =
            nodes.drain(..).map(|cfg| Node::new_sharable(cfg)).collect();

        let late_node = nodes.pop().unwrap();
        // Start all but one.
        for node in &mut nodes {
            node.write().unwrap().start();
        }

        // Wait for the blocks to be produced.
        wait(
            || {
                if let Some(ind) = nodes[0].read().unwrap().user().get_best_block_index() {
                    ind > (num_blocks_to_wait as u64)
                } else {
                    false
                }
            },
            100,
            block_generation_timeout.as_millis() as u64,
        );

        // Start the late node.
        late_node.write().unwrap().start();

        // Wait for it to have the same block index as other nodes.
        wait(
            || {
                if let ind @ Some(_) = nodes[0].read().unwrap().user().get_best_block_index() {
                    late_node.read().unwrap().user().get_best_block_index() == ind
                } else {
                    false
                }
            },
            400,
            catchup_timeout.as_millis() as u64,
        );
    }

    heavy_test(|| {
        run_multiple_nodes(4, 20, Duration::from_secs(120), Duration::from_secs(60), "4_20")
    });
}

'''
'''--- tests/test_custom_handler.rs ---
#[cfg(feature = "old_tests")]
#[cfg(test)]
mod test {
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;

    use network::proxy::predicate::FnProxyHandler;
    use network::proxy::ProxyHandler;
    use primitives::transaction::TransactionBody;
    use testlib::node::{
        create_nodes, sample_two_nodes, Node, TEST_BLOCK_FETCH_LIMIT, TEST_BLOCK_MAX_SIZE,
    };
    use testlib::test_helpers::wait;

    fn run_multiple_nodes(num_nodes: usize, num_trials: usize, test_prefix: &str, test_port: u16) {
        // Add proxy handlers to the pipeline.

        // Custom handler example
        let fn_proxy_handler = Arc::new(FnProxyHandler::new(|package| {
            // Logic here...

            // Return None to dismiss this channel,
            // or Some(package) for passing to the next handler. Note that returned package don't need to be the
            // same as the received package.
            Some(package)
        }));

        let proxy_handlers: Vec<Arc<ProxyHandler>> = vec![fn_proxy_handler];

        let (init_balance, account_names, mut nodes) = create_nodes(
            num_nodes,
            test_prefix,
            test_port,
            TEST_BLOCK_FETCH_LIMIT,
            TEST_BLOCK_MAX_SIZE,
            proxy_handlers,
        );

        let nodes: Vec<_> = nodes.drain(..).map(|cfg| Node::new_sharable(cfg)).collect();
        for i in 0..num_nodes {
            nodes[i].write().unwrap().start();
        }

        thread::sleep(Duration::from_millis(1000));

        // Execute N trials. In each trial we submit a transaction to a random node i, that sends
        // 1 token to a random node j. We send transaction to node Then we wait for the balance change to propagate by checking
        // the balance of j on node k.
        let mut expected_balances = vec![init_balance; num_nodes];
        let trial_duration = 10000;
        for _ in 0..num_trials {
            let (i, j) = sample_two_nodes(num_nodes);
            let (k, r) = sample_two_nodes(num_nodes);
            let nonce =
                nodes[i].read().unwrap().get_account_nonce(&account_names[i]).unwrap_or_default()
                    + 1;
            let transaction = TransactionBody::send_money(
                nonce,
                account_names[i].as_str(),
                account_names[j].as_str(),
                1,
            )
            .sign(&*nodes[i].read().unwrap().signer());
            nodes[k].read().unwrap().add_transaction(transaction).unwrap();
            expected_balances[i] -= 1;
            expected_balances[j] += 1;

            wait(
                || {
                    expected_balances[j]
                        == nodes[r].read().unwrap().view_balance(&account_names[j]).unwrap()
                },
                1000,
                trial_duration,
            );
            thread::sleep(Duration::from_millis(500));
        }
    }

    /// Similar to `test_alphanet::test_4_10_multiple_nodes` to show custom proxy handlers usage.
    #[test]
    fn test_custom_handler() {
        run_multiple_nodes(3, 1, "custom_handler", 3200);
    }
}

'''
'''--- tests/test_errors.rs ---
use near::config::TESTING_INIT_BALANCE;
use near::{load_test_config, GenesisConfig};
use near_network::test_utils::open_port;
use near_primitives::crypto::signer::InMemorySigner;
use near_primitives::test_utils::init_integration_logger;
use near_primitives::transaction::{CreateAccountTransaction, TransactionBody};
use testlib::node::{Node, ThreadNode};

fn start_node() -> ThreadNode {
    init_integration_logger();
    let genesis_config = GenesisConfig::legacy_test(vec!["alice.near", "bob.near"], 1);
    let mut near_config = load_test_config("alice.near", open_port(), &genesis_config);
    near_config.client_config.skip_sync_wait = true;

    let mut node = ThreadNode::new(near_config);
    node.start();
    node
}

#[test]
fn test_check_tx_error_log() {
    let node = start_node();
    let signer = InMemorySigner::from_seed("alice.near", "alice.near");
    let tx = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: 1,
        originator: "bob.near".to_string(),
        new_account_id: "test.near".to_string(),
        amount: 1_000,
        public_key: signer.public_key.0[..].to_vec(),
    })
    .sign(&signer);

    let tx_result = node.user().commit_transaction(tx);
    assert_eq!(
        tx_result,
        Err("RpcError { code: -32000, message: \"Server error\", data: Some(String(\"Transaction is not signed with a public key of the originator \\\"bob.near\\\"\")) }".to_string())
    );
}

#[test]
fn test_deliver_tx_error_log() {
    let node = start_node();
    let signer = InMemorySigner::from_seed("alice.near", "alice.near");
    let tx = TransactionBody::CreateAccount(CreateAccountTransaction {
        nonce: 1,
        originator: "alice.near".to_string(),
        new_account_id: "test.near".to_string(),
        amount: TESTING_INIT_BALANCE + 1,
        public_key: signer.public_key.0[..].to_vec(),
    })
    .sign(&signer);

    let tx_result = node.user().commit_transaction(tx).unwrap();
    assert_eq!(
        tx_result.logs[0].lines[0],
        "Runtime error: Account alice.near tries to create new account with 1000000000000001, but only has 1000000000000000"
    );
}

'''
'''--- tests/test_rejoin.rs ---
//! Tests whether nodes can leave and rejoin the consensus.
#[cfg(test)]
#[cfg(feature = "expensive_tests")]
mod test {
    use std::process::Command;
    use std::sync::{Arc, RwLock};
    use std::thread;
    use std::time::Duration;

    use near_primitives::transaction::TransactionBody;
    use near_primitives::types::AccountId;
    use testlib::node::{create_nodes, sample_queryable_node, sample_two_nodes, Node, NodeConfig};
    use testlib::test_helpers::{heavy_test, wait, wait_for_catchup};

    fn warmup() {
        Command::new("cargo").args(&["build", "-p", "near"]).spawn().expect("warmup failed").wait().unwrap();
    }

    // DISCLAIMER. These tests are very heavy and somehow manage to interfere with each other.
    // If you add multiple tests and they start failing consider splitting it into several *.rs files
    // to ensure they are not run in parallel.

    fn send_transaction(
        nodes: &Vec<Arc<RwLock<Node>>>,
        account_names: &Vec<AccountId>,
        nonces: &Vec<u64>,
        from: usize,
        to: usize,
    ) {
        let k = sample_queryable_node(nodes);
        nodes[k]
            .read()
            .unwrap()
            .add_transaction(
                TransactionBody::send_money(
                    nonces[from],
                    account_names[from].as_str(),
                    account_names[to].as_str(),
                    1000,
                )
                .sign(&*nodes[from].read().unwrap().signer()),
            )
            .unwrap();
    }

    fn test_kill_1(num_nodes: usize, num_trials: usize, test_prefix: &str) {
        warmup();
        // Start all nodes, crash node#2, proceed, restart node #2 but crash node #3
        let crash1 = 2;
        let crash2 = 3;
        let nodes = create_nodes(num_nodes, test_prefix);
        // Convert some of the thread nodes into processes.
        let nodes: Vec<_> = nodes
            .into_iter()
            .map(|node_cfg| {
                if rand::random::<bool>() {
                    if let NodeConfig::Thread(cfg) = node_cfg {
                        NodeConfig::Process(cfg)
                    } else {
                        unimplemented!()
                    }
                } else {
                    node_cfg
                }
            })
            .collect();

        let nodes: Vec<_> = nodes.into_iter().map(|cfg| Node::new_sharable(cfg)).collect();
        let account_names: Vec<_> =
            nodes.iter().map(|node| node.read().unwrap().account_id().unwrap()).collect();

        for i in 0..num_nodes {
            nodes[i].write().unwrap().start();
        }

        let mut expected_balances = vec![0; num_nodes];
        let mut nonces = vec![1; num_nodes];
        for i in 0..num_nodes {
            let account = nodes[0].read().unwrap().view_account(&account_names[i]).unwrap();
            nonces[i] = account.nonce + 1;
            expected_balances[i] = account.amount;
        }
        let trial_duration = 60000;
        for trial in 0..num_trials {
            println!("TRIAL #{}", trial);
            if trial % 10 == 3 {
                println!("Killing node {}", crash1);
                nodes[crash1].write().unwrap().kill();
                thread::sleep(Duration::from_secs(2));
            }
            if trial % 10 == 6 {
                println!("Restarting node {}", crash1);
                nodes[crash1].write().unwrap().start();
                wait_for_catchup(&nodes);
                println!("Killing node {}", crash2);
                nodes[crash2].write().unwrap().kill();
            }
            if trial % 10 == 9 {
                println!("Restarting node {}", crash2);
                nodes[crash2].write().unwrap().start();
            }

            let (i, j) = sample_two_nodes(num_nodes);
            send_transaction(&nodes, &account_names, &nonces, i, j);
            nonces[i] += 1;
            expected_balances[i] -= 1000;
            expected_balances[j] += 1000;
            let t = sample_queryable_node(&nodes);
            wait(
                || {
                    let amt = nodes[t].read().unwrap().view_balance(&account_names[j]).unwrap();
                    expected_balances[j] <= amt
                },
                1000,
                trial_duration,
            );
        }
    }

    fn test_kill_2(num_nodes: usize, num_trials: usize, test_prefix: &str) {
        warmup();
        // Start all nodes, crash nodes 2 and 3, restart node 2, proceed, restart node 3
        let (crash1, crash2) = (2, 3);
        let nodes = create_nodes(num_nodes, test_prefix);

        // Convert some of the thread nodes into processes.
        let nodes: Vec<_> = nodes
            .into_iter()
            .map(|node_cfg| {
                if rand::random::<bool>() {
                    if let NodeConfig::Thread(cfg) = node_cfg {
                        NodeConfig::Process(cfg)
                    } else {
                        unimplemented!()
                    }
                } else {
                    node_cfg
                }
            })
            .collect();
        let nodes: Vec<Arc<RwLock<Node>>> =
            nodes.into_iter().map(|cfg| Node::new_sharable(cfg)).collect();
        let account_names: Vec<_> =
            nodes.iter().map(|node| node.read().unwrap().account_id().unwrap()).collect();

        for i in 0..num_nodes {
            nodes[i].write().unwrap().start();
        }

        let mut expected_balances = vec![0; num_nodes];
        let mut nonces = vec![1; num_nodes];
        for i in 0..num_nodes {
            let account = nodes[0].read().unwrap().view_account(&account_names[i]).unwrap();
            nonces[i] = account.nonce + 1;
            expected_balances[i] = account.amount;
        }

        let trial_duration = 20000;
        for trial in 0..num_trials {
            println!("TRIAL #{}", trial);
            let (i, j) = sample_two_nodes(num_nodes);
            if trial % 5 == 2 {
                // Here we kill two nodes, make sure transactions stop going through,
                // then restart one of the nodes
                println!("Killing nodes {}, {}", crash1, crash2);
                nodes[crash1].write().unwrap().kill();
                nodes[crash2].write().unwrap().kill();

                send_transaction(&nodes, &account_names, &nonces, i, j);
                thread::sleep(Duration::from_secs(2));
                let t = sample_queryable_node(&nodes);
                assert_eq!(
                    nodes[t].read().unwrap().view_balance(&account_names[j]).unwrap(),
                    expected_balances[j]
                );

                println!("Restarting node {}", crash1);
                nodes[crash1].write().unwrap().start();
            } else {
                send_transaction(&nodes, &account_names, &nonces, i, j);
                if trial % 5 == 4 {
                    // Restart the second of the nodes killed earlier
                    println!("Restarting node {}", crash2);
                    nodes[crash2].write().unwrap().start();
                }
            }
            nonces[i] += 1;
            expected_balances[i] -= 100;
            expected_balances[j] += 100;
            let t = sample_queryable_node(&nodes);
            wait(
                || {
                    let amt = nodes[t].read().unwrap().view_balance(&account_names[j]).unwrap();
                    expected_balances[j] <= amt
                },
                1000,
                trial_duration,
            );
        }
    }

    #[test]
    fn test_4_20_kill1() {
        heavy_test(|| test_kill_1(4, 10, "4_10_kill1"));
    }

    #[test]
    #[ignore]
    fn test_4_20_kill2() {
        heavy_test(|| test_kill_2(4, 5, "4_10_kill2"));
    }
}

'''
'''--- tests/test_simple.rs ---
//! Simply starts and runs TestNet for a while.
#[cfg(test)]
#[cfg(feature = "expensive_tests")]
mod test {
    use near_primitives::test_utils::init_integration_logger;
    use near_primitives::transaction::TransactionBody;
    use testlib::node::{create_nodes, sample_two_nodes, Node};
    use testlib::test_helpers::{heavy_test, wait};

    fn run_multiple_nodes(num_nodes: usize, num_trials: usize, test_prefix: &str) {
        init_integration_logger();

        let mut nodes = create_nodes(num_nodes, test_prefix);
        let nodes: Vec<_> = nodes.drain(..).map(|cfg| Node::new_sharable(cfg)).collect();
        let account_names: Vec<_> =
            nodes.iter().map(|node| node.read().unwrap().account_id().unwrap()).collect();

        for i in 0..num_nodes {
            nodes[i].write().unwrap().start();
        }

        // Execute N trials. In each trial we submit a transaction to a random node i, that sends
        // 1 token to a random node j. We send transaction to node Then we wait for the balance change to propagate by checking
        // the balance of j on node k.
        let trial_duration = 60_000;
        let amount_to_send = 100;
        for trial in 0..num_trials {
            println!("TRIAL #{}", trial);
            let (i, j) = sample_two_nodes(num_nodes);
            let (k, r) = sample_two_nodes(num_nodes);
            let account_i = nodes[k].read().unwrap().view_account(&account_names[i]).unwrap();
            let account_j = nodes[k].read().unwrap().view_account(&account_names[j]).unwrap();
            let transaction = TransactionBody::send_money(
                account_i.nonce + 1,
                account_names[i].as_str(),
                account_names[j].as_str(),
                amount_to_send,
            )
            .sign(&*nodes[i].read().unwrap().signer());
            nodes[k].read().unwrap().add_transaction(transaction).unwrap();

            wait(
                || {
                    account_j.amount
                        < nodes[r].read().unwrap().view_balance(&account_names[j]).unwrap()
                },
                100,
                trial_duration,
            );
        }
    }

    #[test]
    fn test_2_10_multiple_nodes() {
        heavy_test(|| run_multiple_nodes(2, 10, "2_10"));
    }

    #[test]
    fn test_4_10_multiple_nodes() {
        heavy_test(|| run_multiple_nodes(4, 10, "4_10"));
    }

    #[test]
    fn test_7_10_multiple_nodes() {
        heavy_test(|| run_multiple_nodes(7, 10, "7_10"));
    }
}

'''
'''--- tests/test_tps_regression.rs ---
//! Measures the input and the output transactions-per-seconds, compares it with the expected tps,
//! and verifies that the output tps is not much different from the input tps (makes sure there is
//! no choking on transactions). The input tps -- is how fast the nodes can be accepting
//! transactions. The output tps -- is how fast the nodes propagate transactions into the blocks.
#[cfg(any(feature = "expensive_tests", feature = "regression_tests"))]
#[cfg(test)]
mod test {
    use std::io::stdout;
    use std::io::Write;
    use std::sync::{Arc, RwLock};
    use std::thread;
    use std::time::{Duration, Instant};

    use near_primitives::transaction::TransactionBody;
    use testlib::node::{create_nodes, sample_queryable_node, sample_two_nodes, Node};
    use testlib::test_helpers::heavy_test;

    /// Creates and sends a random transaction.
    /// Args:
    /// `nodes`: node to submit to;
    /// `nonces`: tracker of the nonces for the corresponding accounts.
    /// `submitted_transactions`: (number of transactions, when these transactions were submitted).
    fn send_transaction(
        nodes: Vec<Arc<RwLock<dyn Node>>>,
        nonces: Arc<RwLock<Vec<u64>>>,
        submitted_transactions: Arc<RwLock<Vec<(u64, Instant)>>>,
    ) {
        let (money_sender, money_receiver) = sample_two_nodes(nodes.len());
        let tx_receiver = sample_queryable_node(&nodes);
        // Update nonces.
        let mut nonces = nonces.write().unwrap();
        nonces[money_sender] += 1;
        let nonce = nonces[money_sender];

        let sender_acc = nodes[money_sender].read().unwrap().account_id().unwrap();
        let receiver_acc = nodes[money_receiver].read().unwrap().account_id().unwrap();
        let transaction =
            TransactionBody::send_money(nonce, sender_acc.as_str(), receiver_acc.as_str(), 1)
                .sign(&*nodes[money_sender].read().unwrap().signer());
        nodes[tx_receiver].read().unwrap().add_transaction(transaction).unwrap();
        submitted_transactions.write().unwrap().push((1, Instant::now()));
    }

    /// Iterates over the given records of transactions, bucketizes them, and computes the tps.
    /// Can be used for debugging this test.
    fn bucketize_tps(
        recorded_transactions: &Arc<RwLock<Vec<(u64, Instant)>>>,
        bucket_size: Duration,
    ) -> Vec<u64> {
        let mut bucket_start = recorded_transactions.read().unwrap()[0].1;
        let mut buckets = vec![0u64];
        for b in &*recorded_transactions.read().unwrap() {
            if bucket_start + bucket_size >= b.1 {
                *buckets.last_mut().unwrap() += b.0;
            } else {
                *buckets.last_mut().unwrap() /= bucket_size.as_secs() as u64;
                buckets.push(b.0);
                bucket_start += Duration::from_nanos(
                    ((b.1 - bucket_start).as_nanos() as u64) / (bucket_size.as_nanos() as u64)
                        * (bucket_size.as_nanos() as u64),
                );
            }
        }
        // Pop the last bucket because it might be incomplete.
        buckets
    }

    /// Creates a network of nodes and submits a large number of transactions to them.
    /// Args:
    /// * `num_nodes`: number of nodes to create;
    /// * `tps`: transactions-per-second rate with which we submit transactions at even intervals;
    /// * `target_tps`: the target output transactions-per-seconds of the network;
    /// * `timeout`: how long this test should run.
    fn run_multiple_nodes(
        num_nodes: usize,
        tps: usize,
        target_tps: usize,
        timeout: Duration,
        test_prefix: &str,
    ) {
        let mut nodes = create_nodes(num_nodes, test_prefix);

        let nodes: Vec<Arc<RwLock<dyn Node>>> =
            nodes.drain(..).map(|cfg| Node::new_sharable(cfg)).collect();
        for i in 0..num_nodes {
            nodes[i].write().unwrap().start();
        }

        // Collection that stores #num of transactions -> when these transaction were submitted.
        let submitted_transactions = Arc::new(RwLock::new(vec![]));

        // Create thread that submits transactions with high tps.
        let transaction_handler = {
            // Delay between transactions.
            let tx_delay =
                Duration::from_nanos((Duration::from_secs(1).as_nanos() as u64) / (tps as u64));
            let timeout = Instant::now() + timeout;
            let nodes = nodes.to_vec();
            let submitted_transactions = submitted_transactions.clone();

            thread::spawn(move || {
                let nonces = vec![0u64; nodes.len()];
                let nonces = Arc::new(RwLock::new(nonces));
                while Instant::now() < timeout {
                    {
                        let nodes = nodes.to_vec();
                        let nonces = nonces.clone();
                        let submitted_transactions = submitted_transactions.clone();
                        thread::spawn(move || {
                            send_transaction(nodes, nonces, submitted_transactions)
                        });
                    }
                    thread::sleep(tx_delay);
                }
            })
        };

        // Delay between checking the nodes.
        let check_delay = Duration::from_millis(100);
        // Collection that stores #num of transactions in a block -> when this block was observed.
        let observed_transactions = Arc::new(RwLock::new(vec![]));

        // Create thread that observes new blocks and counts new transactions in them.
        let observer_handler = {
            let timeout = Instant::now() + timeout;
            let observed_transactions = observed_transactions.clone();
            thread::spawn(move || {
                let mut prev_ind = 0;
                while Instant::now() < timeout {
                    // Get random node.
                    let node = &nodes[sample_queryable_node(&nodes)];
                    if let Some(new_ind) = node.read().unwrap().user().get_best_block_index() {
                        if new_ind > prev_ind {
                            let blocks = ((prev_ind + 1)..=new_ind)
                                .map(|idx| node.read().unwrap().user().get_block(idx).unwrap())
                                .collect::<Vec<_>>();
                            for b in &blocks {
                                observed_transactions
                                    .write()
                                    .unwrap()
                                    .push((b.transactions.len() as u64, Instant::now()));
                            }
                            prev_ind = new_ind;
                        }
                    }
                    thread::sleep(check_delay);
                }
            })
        };
        transaction_handler.join().unwrap();
        observer_handler.join().unwrap();

        let bucket_size = Duration::from_secs(10);

        let bucketed_submitted_xacts = bucketize_tps(&submitted_transactions, bucket_size);
        let mut bucketed_observed_xacts = bucketize_tps(&observed_transactions, bucket_size);

        let _ = stdout().write(
            format!("Submitted transactions tps: {:?}; ", bucketed_submitted_xacts).as_bytes(),
        );
        let _ = stdout()
            .write(format!("Observed transactions tps: {:?}", bucketed_observed_xacts).as_bytes());
        let _ = stdout().flush();

        // Test that the network does not choke. The choke can be observed when the number of submitted
        // transactions is not approx. the same the number of observed.

        let submitted_num: f64 =
            submitted_transactions.read().unwrap().iter().map(|(n, _)| *n as f64).sum();
        let observed_num: f64 =
            observed_transactions.read().unwrap().iter().map(|(n, _)| *n as f64).sum();
        // The difference is within 20%.
        assert!((submitted_num - observed_num).abs() < f64::max(submitted_num, observed_num) * 0.2);

        // Also verify that the median tps is within 20% of the target. We use median to discard
        // anomalies that happens when nodes start and stop.
        bucketed_observed_xacts.sort();
        let median = bucketed_observed_xacts[bucketed_observed_xacts.len() / 2];
        assert!((target_tps as f64) * 0.8 < (median as f64));
    }

    #[test]
    fn test_highload() {
        // Run 4 nodes with 20 input tps and check the output tps to be 20.
        heavy_test(|| run_multiple_nodes(4, 20, 20, Duration::from_secs(120), "4_20"));
    }
}

'''