*GitHub Repository "pinocchio338/rust_api"*

'''--- .devcontainer/devcontainer.json ---
// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:
// https://github.com/microsoft/vscode-dev-containers/tree/v0.187.0/containers/javascript-node
{
	"name": "Beacon Server",
	"build": {
		"dockerfile": "Near-Dockerfile"
	},

	// Set *default* container specific settings.json values on container create.
	"settings": {},

	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [],

	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	"remoteUser": "root"
}

'''
'''--- .github/ISSUE_TEMPLATE/backlog_item.md ---
---
name: Backlog Item
about: Issue that has enough reasoning, research and information to be implemented
title: ''
labels: 'needs triage'
assignees: ''

---

<!--- Provide a general summary of the issue in the Title above -->

## Implementation details
<!-- Enter description of implementation that may help dev team  -->

## Testing details
<!-- Enter description of special test-cases-->

## Acceptance Criteria
<!-- Enter the conditions of satisfaction here. That is, the conditions that will satisfy the user/persona that the goal/benefit/value has been achieved -->

'''
'''--- .github/ISSUE_TEMPLATE/bug_issue.md ---
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: 'bug'
assignees: ''

---

## Describe the bug
<!-- A clear and concise description of what the bug is. -->

- 

## Expected Behavior

<!---

If you're describing a bug, tell us what should happen.

If you're suggesting a change/improvement, tell us how it should work.

-->

-

## Current Behavior

<!---

If describing a bug, tell us what happens instead of the expected behavior.

If suggesting a change or an improvement, explain the difference between your
suggestion and current behavior.

-->

-

## Possible Solution

<!---

Not obligatory, but this is the place to suggest the underlying cause and
possible fix for the bug, if you have one, or ideas on how to implement the
fix. We'll be sure to credit your ideas in the commit log, or better yet,
submit a PR and you'll get credit for the whole thing.

-->

-

## To Reproduce
Steps to reproduce the behavior:

1. 
2. 
3. 

## Log output
<!-- Please paste the log output derived from the error. -->
<details>
  <summary>Log Output</summary>
  
  ```Paste log output here
  paste log output...
  ```
</details> 
</br>

## Specification

<!---

Example specification (feel free to copy and paste if applicable or delete the
specification section if a specification is not applicable):

- rustc version: ``
- pint version: `development`
- commit tag: NA
- commit hash: NA
- operating system: Ubuntu 19.10
- additional links: NA

-->

- rustc version:
- pint version:
- commit tag:
- commit hash:
- operating system:
- additional links:

<!-- Thank you 🙏 -->

'''
'''--- .github/ISSUE_TEMPLATE/config.yml ---
blank_issues_enabled: true

'''
'''--- .github/ISSUE_TEMPLATE/general_issue.md ---
---
name: General issue
about: General purpose issue template
title: ''
labels: 'needs triage'
assignees: ''

---

## Issue summary
<!-- A clear and concise description of what the task is. -->
- 

## Other information and links
<!-- Add any other context or screenshots about the issue here. -->
- 

<!-- Thank you 🙏 -->

'''
'''--- .github/pull_request_template.md ---
## Changes

<!--

Please provide a brief but specific list of changes made, describe the changes
in functionality rather than the changes in code.

-->

-
-
-

## Tests

<!--

Details on how to run tests relevant to the changes within this pull request.

-->

```

```

## Issues

<!--

Please link any issues that this pull request is related to and use the GitHub
supported format for automatically closing issues (ie, closes #123, fixes #123)

-->

-

'''
'''--- .github/workflows/tests.yml ---
name: Tests

on:
  push:
    branches:
      - "main"
  pull_request:
    branches:
      - '**'

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          target: wasm32-unknown-unknown
          toolchain: stable
          override: true
      - run: cargo b --all --release
      - run: cargo t --all --release

  fmt:
    name: Rustfmt
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          target: wasm32-unknown-unknown
          toolchain: stable
          override: true
      - run: rustup component add rustfmt
      - uses: actions-rs/cargo@v1
        with:
          command: fmt
          args: --all -- --check

  clippy:
    name: Clippy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          target: wasm32-unknown-unknown
          toolchain: stable
          override: true
      - run: rustup component add clippy
      - uses: actions-rs/cargo@v1
        with:
          command: clippy
          args: -- -D warnings

'''
'''--- Cargo.toml ---
[workspace]
members = [
    "common",
    "near/contract",
]
exclude = [
]

'''
'''--- README.md ---
# API3-Rust
This is the repo for RUST implementation of API3's Beacon Server

## Common
Common package used for all the subsequent chain implementations.
To run all test
```
cd common
cargo test
```

## Solana
Read up on anchors https://book.anchor-lang.com/.
To build the solana code, do the following in docker container (.devcontainer/Solana-Dockerfile):
```
cd solana/beacon-server
anchor build
solana-keygen new
anchor test
```

Instead of docker, you can follow installation commands from docker image.

## Near
### Prerequisite
Read up on Near from these links:
- Get started: `https://docs.near.org/docs/develop/contracts/overview`
- Create account: `https://docs.near.org/docs/develop/basics/create-account#creating-a-testnet-account`
- Cross contract call: `https://docs.near.org/docs/tutorials/contracts/xcc-receipts`
- End to end test: `https://docs.near.org/docs/develop/contracts/rust/testing-rust-contracts#end-to-end-tests`
After reading the above, you should be able to know:
- The basic syntax of writing a Near contract using rust
- How to create test accounts
- How and why we need cross contract call
- How end to end test with javascript is written and tested

### Dev
To setup the dev env, checkout the dockerfile in `.devcontainer/Near-Dockerfile`, build and launch the docker. Alternatively,
we recommend you use vscode remote docker plugin, you can open this folder in remote docker, then you can have the same dev 
env.
Once in the docker, you can follow the subsection accordingly.

#### Compile
- go to the near contract folder: `cd near/contract`
- compile: `cargo build --target wasm32-unknown-unknown --release`
Once done you should be able to see, relative to the repo root folder, `target/wasm32-unknown-unknown/release/dapi_server.wasm`.

#### Create test accounts
You need to create 3 accounts for testing:
```
CONTRACT_ACCOUNT: the account for the dapiServer contract.
ADMIN_ACCOUNT: the default admin of the contract.
USER_ACCOUNT: test util account, mainly for reading data points with unlimited access for data verification.
```
Now go to near testnet and create the above accounts, you can choose your own names. Remember to define the above env variables with the account 
names, i.e. for our dev env, it's:
```
export CONTRACT_ACCOUNT=dapi-contract1.testnet
export ADMIN_ACCOUNT=mocha-test1.testnet
export USER_ACCOUNT=user-test1.testnet
```

#### Login on CLI
Once the acconts are created, you need to login from CLI:
```
near login --account-id ${CONTRACT_ACCOUNT}
near login --account-id ${ADMIN_ACCOUNT}
near login --account-id ${USER_ACCOUNT}
```

#### Deploy the contracts
In the root folder, deploy the `api3-contract` using:
```
near deploy --wasmFile ./target/wasm32-unknown-unknown/release/dapi_server.wasm --accountId=${CONTRACT_ACCOUNT}
```
If you get error on not enough balance. Run `near dev-deploy ...` and delete generated dev-xxxx account in favour of your account: `near delete dev-xxxx ${CONTRACT_ACCOUNT}`

Once you have deployed the contract, perform some santiy checks to ensure proper deployment, such as:
```bash
# This should pass with no problem
near call <CONTRACT_ACCOUNT> grant_role '{"role":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"who":"user-test1.testnet"}' --accountId <ADMIN_ACCOUNT>
# This should return true
near view <CONTRACT_ACCOUNT> has_role '{"role":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"who":"user-test1.testnet"}'
# This should pass with no problem
near call <CONTRACT_ACCOUNT> revoke_role '{"role":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"who":"user-test1.testnet"}' --accountId <ADMIN_ACCOUNT>
# This should return false
near view <CONTRACT_ACCOUNT> has_role '{"role":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"who":"user-test1.testnet"}'
```

#### Run tests
The tests are located in `near/client-test`, the `main` for tests is `near/client-test/tests/test.spec.js`. Use `npm install` if you have not setup before.

To run the test: `cd near/client-test && yarn jest`. Please note that the tests will take around 10 minutes to finish. At the same time, it is also running against a live network, sometimes there will be timeout errors, but near would retry automatically.

When the contract reverts execution, the near client would log the contract execution error with `console.warn`. The tests would capture the exceptions thrown and check the expected error name appears in the error message. If you want to disable the warn logs, use `yarn jest --silent`.

#### Clean up
To clean up, just delete the accounts using `near delete ... ...`. See `https://docs.near.org/docs/tools/near-cli#near-delete`.
'''
'''--- common/Cargo.toml ---
[package]
name = "api3-common"
version = "0.0.1"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[features]
default = ["dummy"]
dummy = []

[dependencies]
borsh = "0.8.2" # need to match with near-sdk borsh version
derive_more = "0.99.17"
serde = "1"
uint = { version = "0.9.0" }
hex = "0.4.3"
tiny-keccak = { version = "2.0.2", features = ["keccak"] }
thiserror = "1"

[dev-dependencies]
hex-literal = "0.3"
ethereum-types = "0.13.1"
libsecp256k1 = "0.6.0"
web3 = "0.18.0"
rand = "0.8.5"
ethabi = { version = "17.0.0" }

'''
'''--- common/README.md ---
# API3 Common Crate
This is the common crate for porting solidity API3 contracts to Rust based chains. As for different chains, the same processing 
logic would be applied, it is natural to abstract common processes.
The main design is as follows:
* Common data types
  * DataPoint: The datapoint struct used in the original solidity contracts.
  * Role: Some of the roles known at dev time are modelled using enum
* Common methods: In `common/src/beacon.rs`, it contains all the methods used in the original `DapiServer.sol`. 
All the methods are implemented the same as in the solidity contracts. To ensure everything works in the respective chains, 
the chain specific operations are abstracted into traits so that each chain could have its own implementation. The following traits 
are implemented:
  * Storage<T>: `common/src/beacon::Storage`handles the load/save of item type T in the chain
  * Whitelist: `common/src/whitelist.rs:20` handles the whitelist functions in the specific chain
  * AccessControlRegistry: `common/src/access::AccessControlRegistry` handles the access control related function in the specific chain
  * SignatureManger: `common/src/beacon::SignatureManger` handles the onchain signature verification
'''
'''--- common/src/abi/decode.rs ---
//! ABI decoder.

use crate::abi::{ParamType, Token, Word};
use crate::Error;

#[derive(Debug)]
struct DecodeResult {
    token: Token,
    new_offset: usize,
}

fn as_usize(slice: &Word) -> Result<usize, Error> {
    if !slice[..28].iter().all(|x| *x == 0) {
        return Err(Error::InvalidData);
    }

    let result = ((slice[28] as usize) << 24)
        + ((slice[29] as usize) << 16)
        + ((slice[30] as usize) << 8)
        + (slice[31] as usize);

    Ok(result)
}

/// Decodes ABI compliant vector of bytes into vector of tokens described by types param.
pub fn decode(types: &[ParamType], data: &[u8]) -> Result<Vec<Token>, Error> {
    let is_empty_bytes_valid_encoding = types.iter().all(|t| t.is_empty_bytes_valid_encoding());
    if !is_empty_bytes_valid_encoding && data.is_empty() {
        return Err(Error::InvalidName(
            "please ensure the contract and method you're calling exist! \
			 failed to decode empty bytes. if you're using jsonrpc this is \
			 likely due to jsonrpc returning `0x` in case contract or method \
			 don't exist"
                .into(),
        ));
    }

    let mut tokens = vec![];
    let mut offset = 0;

    for param in types {
        let res = decode_param(param, data, offset)?;
        offset = res.new_offset;
        tokens.push(res.token);
    }

    Ok(tokens)
}

fn peek(data: &[u8], offset: usize, len: usize) -> Result<&[u8], Error> {
    if offset + len > data.len() {
        Err(Error::InvalidData)
    } else {
        Ok(&data[offset..(offset + len)])
    }
}

fn peek_32_bytes(data: &[u8], offset: usize) -> Result<Word, Error> {
    peek(data, offset, 32).map(|x| {
        let mut out: Word = [0u8; 32];
        out.copy_from_slice(&x[0..32]);
        out
    })
}

fn take_bytes(data: &[u8], offset: usize, len: usize) -> Result<Vec<u8>, Error> {
    if offset + len > data.len() {
        Err(Error::InvalidData)
    } else {
        Ok((data[offset..(offset + len)]).to_vec())
    }
}

fn decode_param(param: &ParamType, data: &[u8], offset: usize) -> Result<DecodeResult, Error> {
    match *param {
        ParamType::Address => {
            let slice = peek_32_bytes(data, offset)?;
            let mut address = [0u8; 20];
            address.copy_from_slice(&slice[12..]);
            let result = DecodeResult {
                token: Token::Address(address),
                new_offset: offset + 32,
            };
            Ok(result)
        }
        ParamType::Uint(_) => {
            let slice = peek_32_bytes(data, offset)?;
            let result = DecodeResult {
                token: Token::Uint(slice.into()),
                new_offset: offset + 32,
            };
            Ok(result)
        }
        ParamType::Int(_) => {
            let slice = peek_32_bytes(data, offset)?;
            let result = DecodeResult {
                token: Token::Int(slice.into()),
                new_offset: offset + 32,
            };
            Ok(result)
        }
        ParamType::FixedBytes(len) => {
            // FixedBytes is anything from bytes1 to bytes32. These values
            // are padded with trailing zeros to fill 32 bytes.
            let bytes = take_bytes(data, offset, len)?;
            let result = DecodeResult {
                token: Token::FixedBytes(bytes),
                new_offset: offset + 32,
            };
            Ok(result)
        }
        ParamType::Bytes => {
            let dynamic_offset = as_usize(&peek_32_bytes(data, offset)?)?;
            let len = as_usize(&peek_32_bytes(data, dynamic_offset)?)?;
            let bytes = take_bytes(data, dynamic_offset + 32, len)?;
            let result = DecodeResult {
                token: Token::Bytes(bytes),
                new_offset: offset + 32,
            };
            Ok(result)
        }
        ParamType::String => {
            let dynamic_offset = as_usize(&peek_32_bytes(data, offset)?)?;
            let len = as_usize(&peek_32_bytes(data, dynamic_offset)?)?;
            let bytes = take_bytes(data, dynamic_offset + 32, len)?;
            let result = DecodeResult {
                // NOTE: We're decoding strings using lossy UTF-8 decoding to
                // prevent invalid strings written into contracts by either users or
                // Solidity bugs from causing graph-node to fail decoding event
                // data.
                token: Token::String(String::from_utf8_lossy(&*bytes).into()),
                new_offset: offset + 32,
            };
            Ok(result)
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::abi::decode::decode;
    use crate::abi::types::ParamType;
    use crate::abi::{Token, Uint};
    use hex_literal::hex;

    #[test]
    fn decode_from_empty_byte_slice() {
        // these can NOT be decoded from empty byte slice
        assert!(decode(&[ParamType::Address], &[]).is_err());
        assert!(decode(&[ParamType::Bytes], &[]).is_err());
        assert!(decode(&[ParamType::String], &[]).is_err());
        assert!(decode(&[ParamType::FixedBytes(1)], &[]).is_err());
        // these are the only ones that can be decoded from empty byte slice
        assert!(decode(&[ParamType::FixedBytes(0)], &[]).is_ok());
    }

    #[test]
    fn decode_data_with_size_that_is_not_a_multiple_of_32() {
        let encoded = hex!(
            "
            0000000000000000000000000000000000000000000000000000000000000000
            00000000000000000000000000000000000000000000000000000000000000a0
            0000000000000000000000000000000000000000000000000000000000000152
            0000000000000000000000000000000000000000000000000000000000000001
            000000000000000000000000000000000000000000000000000000000054840d
            0000000000000000000000000000000000000000000000000000000000000092
            3132323033393637623533326130633134633938306235616566666231373034
            3862646661656632633239336139353039663038656233633662306635663866
            3039343265376239636337366361353163636132366365353436393230343438
            6533303866646136383730623565326165313261323430396439343264653432
            3831313350373230703330667073313678390000000000000000000000000000
            0000000000000000000000000000000000103933633731376537633061363531
            3761
        "
        );

        assert_eq!(
            decode(
                &[
                    ParamType::Uint(256),
                    ParamType::String,
                    ParamType::String,
                    ParamType::Uint(256),
                    ParamType::Uint(256),
                ],
                &encoded,
            ).unwrap(),
            &[
                Token::Uint(Uint::from(0u128)),
                Token::String(String::from("12203967b532a0c14c980b5aeffb17048bdfaef2c293a9509f08eb3c6b0f5f8f0942e7b9cc76ca51cca26ce546920448e308fda6870b5e2ae12a2409d942de428113P720p30fps16x9")),
                Token::String(String::from("93c717e7c0a6517a")),
                Token::Uint(Uint::from(1u128)),
                Token::Uint(Uint::from(5538829u128))
            ]
        );
    }

    #[test]
    fn decode_after_fixed_bytes_with_less_than_32_bytes() {
        let encoded = hex!(
            "
			0000000000000000000000008497afefdc5ac170a664a231f6efb25526ef813f
			0000000000000000000000000000000000000000000000000000000000000000
			0000000000000000000000000000000000000000000000000000000000000000
			0000000000000000000000000000000000000000000000000000000000000080
			000000000000000000000000000000000000000000000000000000000000000a
			3078303030303030314600000000000000000000000000000000000000000000
		"
        );

        assert_eq!(
            decode(
                &[
                    ParamType::Address,
                    ParamType::FixedBytes(32),
                    ParamType::FixedBytes(4),
                    ParamType::String,
                ],
                &encoded,
            )
            .unwrap(),
            &[
                Token::Address(hex!("8497afefdc5ac170a664a231f6efb25526ef813f").into()),
                Token::FixedBytes([0u8; 32].to_vec()),
                Token::FixedBytes([0u8; 4].to_vec()),
                Token::String("0x0000001F".into()),
            ]
        )
    }

    #[test]
    fn decode_broken_utf8() {
        let encoded = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000020
			0000000000000000000000000000000000000000000000000000000000000004
			e4b88de500000000000000000000000000000000000000000000000000000000
        "
        );

        assert_eq!(
            decode(&[ParamType::String,], &encoded).unwrap(),
            &[Token::String("不�".into())]
        );
    }
}

'''
'''--- common/src/abi/encode.rs ---
//! ABI encoder.

use crate::abi::types::{Token, Word};
use crate::Bytes;

/// Converts a u32 to a right aligned array of 32 bytes.
pub fn pad_u32(value: u32) -> Word {
    let mut padded = [0u8; 32];
    padded[28..32].copy_from_slice(&value.to_be_bytes());
    padded
}

fn pad_bytes(bytes: &[u8]) -> Vec<Word> {
    let mut result = vec![pad_u32(bytes.len() as u32)];
    result.extend(pad_fixed_bytes(bytes));
    result
}

fn pad_fixed_bytes(bytes: &[u8]) -> Vec<Word> {
    let len = (bytes.len() + 31) / 32;
    let mut result = Vec::with_capacity(len);
    for i in 0..len {
        let mut padded = [0u8; 32];

        let to_copy = match i == len - 1 {
            false => 32,
            true => match bytes.len() % 32 {
                0 => 32,
                x => x,
            },
        };

        let offset = 32 * i;
        padded[..to_copy].copy_from_slice(&bytes[offset..offset + to_copy]);
        result.push(padded);
    }

    result
}

#[derive(Debug)]
enum Mediate {
    Raw(Vec<Word>),
    Prefixed(Vec<Word>),
}

impl Mediate {
    fn head_len(&self) -> u32 {
        match *self {
            Mediate::Raw(ref raw) => 32 * raw.len() as u32,
            Mediate::Prefixed(_) => 32,
        }
    }

    fn tail_len(&self) -> u32 {
        match *self {
            Mediate::Raw(_) => 0,
            Mediate::Prefixed(ref pre) => pre.len() as u32 * 32,
        }
    }

    fn head(&self, suffix_offset: u32) -> Vec<Word> {
        match *self {
            Mediate::Raw(ref raw) => raw.clone(),
            Mediate::Prefixed(_) => vec![pad_u32(suffix_offset)],
        }
    }

    fn tail(&self) -> Vec<Word> {
        match *self {
            Mediate::Raw(_) => vec![],
            Mediate::Prefixed(ref raw) => raw.clone(),
        }
    }
}

fn encode_head_tail(mediates: &[Mediate]) -> Vec<Word> {
    let heads_len = mediates.iter().fold(0, |acc, m| acc + m.head_len());

    let (mut result, len) = mediates.iter().fold(
        (Vec::with_capacity(heads_len as usize), heads_len),
        |(mut acc, offset), m| {
            acc.extend(m.head(offset));
            (acc, offset + m.tail_len())
        },
    );

    let tails = mediates.iter().fold(
        Vec::with_capacity((len - heads_len) as usize),
        |mut acc, m| {
            acc.extend(m.tail());
            acc
        },
    );

    result.extend(tails);
    result
}

/// Encodes vector of tokens into ABI compliant vector of bytes.
pub fn encode(tokens: &[Token]) -> Bytes {
    let mediates = &tokens.iter().map(encode_token).collect::<Vec<_>>();

    encode_head_tail(mediates)
        .iter()
        .flat_map(|word| word.to_vec())
        .collect()
}

fn encode_token(token: &Token) -> Mediate {
    match token {
        Token::Address(ref address) => {
            let mut padded = [0u8; 32];
            padded[12..].copy_from_slice(address);
            Mediate::Raw(vec![padded])
        }
        Token::Bytes(ref bytes) => Mediate::Prefixed(pad_bytes(bytes)),
        Token::String(ref s) => Mediate::Prefixed(pad_bytes(s.as_bytes())),
        Token::FixedBytes(ref bytes) => Mediate::Raw(pad_fixed_bytes(bytes)),
        Token::Uint(uint) => Mediate::Raw(vec![(*uint).into()]),
        Token::Int(int) => Mediate::Raw(vec![(*int).into()]),
    }
}

#[cfg(test)]
mod tests {
    use crate::abi::encode::{encode, pad_u32};
    use crate::abi::Token;
    use hex_literal::hex;

    #[test]
    fn encode_address() {
        let address = Token::Address([0x11u8; 20].into());
        let encoded = encode(&[address]);
        let expected = hex!("0000000000000000000000001111111111111111111111111111111111111111");
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_two_addresses() {
        let address1 = Token::Address([0x11u8; 20].into());
        let address2 = Token::Address([0x22u8; 20].into());
        let encoded = encode(&[address1, address2]);
        let expected = hex!(
            "
			0000000000000000000000001111111111111111111111111111111111111111
			0000000000000000000000002222222222222222222222222222222222222222
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_bytes() {
        let bytes = Token::Bytes(vec![0x12, 0x34]);
        let encoded = encode(&[bytes]);
        let expected = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000020
			0000000000000000000000000000000000000000000000000000000000000002
			1234000000000000000000000000000000000000000000000000000000000000
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_fixed_bytes() {
        let bytes = Token::FixedBytes(vec![0x12, 0x34]);
        let encoded = encode(&[bytes]);
        let expected = hex!("1234000000000000000000000000000000000000000000000000000000000000");
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_string() {
        let s = Token::String("gavofyork".to_owned());
        let encoded = encode(&[s]);
        let expected = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000020
			0000000000000000000000000000000000000000000000000000000000000009
			6761766f66796f726b0000000000000000000000000000000000000000000000
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_bytes2() {
        let bytes = Token::Bytes(
            hex!("10000000000000000000000000000000000000000000000000000000000002").to_vec(),
        );
        let encoded = encode(&[bytes]);
        let expected = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000020
			000000000000000000000000000000000000000000000000000000000000001f
			1000000000000000000000000000000000000000000000000000000000000200
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_bytes3() {
        let bytes = Token::Bytes(
            hex!(
                "
			1000000000000000000000000000000000000000000000000000000000000000
			1000000000000000000000000000000000000000000000000000000000000000
		"
            )
            .to_vec(),
        );
        let encoded = encode(&[bytes]);
        let expected = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000020
			0000000000000000000000000000000000000000000000000000000000000040
			1000000000000000000000000000000000000000000000000000000000000000
			1000000000000000000000000000000000000000000000000000000000000000
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_two_bytes() {
        let bytes1 = Token::Bytes(
            hex!("10000000000000000000000000000000000000000000000000000000000002").to_vec(),
        );
        let bytes2 = Token::Bytes(
            hex!("0010000000000000000000000000000000000000000000000000000000000002").to_vec(),
        );
        let encoded = encode(&[bytes1, bytes2]);
        let expected = hex!(
            "
			0000000000000000000000000000000000000000000000000000000000000040
			0000000000000000000000000000000000000000000000000000000000000080
			000000000000000000000000000000000000000000000000000000000000001f
			1000000000000000000000000000000000000000000000000000000000000200
			0000000000000000000000000000000000000000000000000000000000000020
			0010000000000000000000000000000000000000000000000000000000000002
		"
        )
        .to_vec();
        assert_eq!(encoded, expected);
    }

    #[test]
    fn encode_uint() {
        let mut uint = [0u8; 32];
        uint[31] = 4;
        let encoded = encode(&[Token::Uint(uint.into())]);
        let expected = hex!("0000000000000000000000000000000000000000000000000000000000000004");
        assert_eq!(encoded, expected);
    }

    #[test]
    fn test_pad_u32() {
        // this will fail if endianess is not supported
        assert_eq!(pad_u32(0x1)[31], 1);
        assert_eq!(pad_u32(0x100)[30], 1);
    }
}

'''
'''--- common/src/abi/mod.rs ---
mod decode;
mod encode;
mod types;

use tiny_keccak::{Hasher, Keccak};

pub use crate::abi::decode::*;
pub use crate::abi::encode::*;
pub use crate::abi::types::{Address, FixedBytes, Int, ParamType, Token, Uint, Word, U256};
use crate::{Bytes, Bytes32};

/// Rust implementation of solidity abi.encodePacked(...)
pub fn encode_packed(items: &[Token]) -> (Bytes, String) {
    let res = items.iter().fold(Vec::new(), |mut acc, i| {
        let pack = pack(i);
        acc.push(pack);
        acc
    });
    let res = res.join(&[][..]);
    let hexed = hex::encode(&res);
    (res, hexed)
}

/// Pack a single `Token` into bytes
fn pack(t: &Token) -> Vec<u8> {
    let mut res = Vec::new();
    match t {
        Token::String(s) => res.extend(s.as_bytes()),
        Token::Address(a) => res.extend(a),
        Token::Uint(n) => {
            let mut v = vec![0u8; 32];
            n.to_big_endian(&mut v);
            res.extend(v);
        }
        Token::Int(n) => {
            let mut v = vec![0u8; 32];
            n.to_big_endian(&mut v);
            res.extend(v);
        }
        Token::Bytes(b) | Token::FixedBytes(b) => res.extend(b),
    };
    res
}

pub fn keccak256(x: &[u8]) -> Bytes32 {
    let mut keccak = Keccak::v256();
    keccak.update(x);
    let mut out = [0u8; 32];
    keccak.finalize(&mut out);
    out
}

pub fn to_eth_signed_message_hash(s: &[u8]) -> Bytes32 {
    let (bytes, _) = encode_packed(&[
        Token::String("\x19Ethereum Signed Message:\n".parse().unwrap()),
        Token::String(s.len().to_string()),
        Token::Bytes(s.to_vec()),
    ]);
    keccak256(&bytes)
}

#[cfg(test)]
mod tests {
    use crate::abi::{encode_packed, keccak256, to_eth_signed_message_hash, Token};
    use crate::abi::{Address, Uint};
    use hex_literal::hex;

    #[test]
    fn encode_packed_works() {
        let (_, hex_str) = encode_packed(&[Token::String("hello_world".parse().unwrap())]);
        assert_eq!(hex_str, "68656c6c6f5f776f726c64");

        let mut u256 = [0u8; 32];
        u256[0] = 8;
        u256[1] = 10;
        let (_, hex_str) = encode_packed(&[Token::Uint(Uint::from(u256))]);
        assert_eq!(
            hex_str,
            "080a000000000000000000000000000000000000000000000000000000000000"
        );

        let mut h160 = [0u8; 20];
        h160.copy_from_slice(&hex::decode("85B0c8b91707B68C0B23388001B9dC7aab3f6A81").unwrap());
        let (_, hex_str) = encode_packed(&[
            Token::String("hello_world".parse().unwrap()),
            Token::Address(Address::from(h160)),
        ]);
        assert_eq!(
            hex_str,
            "68656c6c6f5f776f726c6485b0c8b91707b68c0b23388001b9dc7aab3f6a81"
        );
    }

    #[test]
    fn keccak_works() {
        let bytes = keccak256(&vec![1, 2, 3]);
        assert_eq!(
            hex::encode(bytes),
            "f1885eda54b7a053318cd41e2093220dab15d65381b1157a3633a83bfd5c9239"
        );
    }

    #[test]
    fn more_complex_test() {
        let mut bytes32 = vec![0; 32];
        bytes32[0] = 8;
        bytes32[1] = 10;

        let mut bytes = vec![0; 36];
        bytes[0] = 18;
        bytes[1] = 120;

        let p1 = Token::FixedBytes(bytes32);
        let p2 = Token::Uint(Uint::from(100));
        let p3 = Token::Bytes(bytes);

        let (b, _) = encode_packed(&[p1, p2, p3]);
        assert_eq!(b, hex!("080a0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000064127800000000000000000000000000000000000000000000000000000000000000000000"));
        assert_eq!(
            keccak256(&b),
            hex!("f3f0d971e5307ceec7ca3d9b762780778c4efe8383f0e17015a2cf8ac8dbc179")
        );
    }

    #[test]
    fn to_eth_signed_message_hash_works() {
        let mut bytes32 = vec![0; 32];
        bytes32[0] = 8;
        bytes32[1] = 10;

        let mut bytes = vec![0; 36];
        bytes[0] = 18;
        bytes[1] = 120;

        let p1 = Token::FixedBytes(bytes32);
        let p2 = Token::Uint(Uint::from(100));
        let p3 = Token::Bytes(bytes);

        let (b, _) = encode_packed(&[p1, p2, p3]);
        assert_eq!(b, hex!("080a0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000064127800000000000000000000000000000000000000000000000000000000000000000000"));

        let b = keccak256(&b);
        assert_eq!(
            b,
            hex!("f3f0d971e5307ceec7ca3d9b762780778c4efe8383f0e17015a2cf8ac8dbc179")
        );

        let b = to_eth_signed_message_hash(&b);
        assert_eq!(
            b,
            hex!("ff0d3be602bd7ed7c0454766464e6a1a9130a63cd505e629ae133db5c3b9f149")
        );
    }
}

'''
'''--- common/src/abi/types.rs ---
#![allow(clippy::assign_op_pattern)]
#![allow(clippy::ptr_offset_with_cast)]

use crate::{Bytes, Bytes32};
use borsh::{BorshDeserialize, BorshSerialize};
use std::io;
use uint::construct_uint;

pub type Address = [u8; 20];
pub type FixedBytes = Vec<u8>;
pub type Uint = U256;
pub type Word = [u8; 32];
pub type Int = Uint;

construct_uint! {
    pub struct U256(4);
}

impl BorshDeserialize for U256 {
    fn deserialize(bytes: &mut &[u8]) -> Result<Self, io::Error> {
        let values: [u8; 32] = BorshDeserialize::deserialize(bytes)?;
        Ok(U256::from_big_endian(&values))
    }
}

impl BorshSerialize for U256 {
    fn serialize<W>(&self, writer: &mut W) -> Result<(), io::Error>
    where
        W: io::Write,
    {
        let mut v = [0u8; 32];
        self.to_big_endian(&mut v);
        BorshSerialize::serialize(&v, writer)
    }
}

impl From<&U256> for Bytes32 {
    fn from(u: &U256) -> Self {
        let mut v = Bytes32::default();
        u.to_big_endian(&mut v);
        v
    }
}

#[derive(Debug, PartialEq, Clone)]
pub enum Token {
    /// Address.
    ///
    /// solidity name: address
    /// Encoded to left padded [0u8; 32].
    Address(Address),
    /// Vector of bytes with known size.
    ///
    /// solidity name eg.: bytes8, bytes32, bytes64, bytes1024
    /// Encoded to right padded [0u8; ((N + 31) / 32) * 32].
    FixedBytes(FixedBytes),
    /// Vector of bytes of unknown size.
    ///
    /// solidity name: bytes
    /// Encoded in two parts.
    /// Init part: offset of 'closing part`.
    /// Closing part: encoded length followed by encoded right padded bytes.
    Bytes(Bytes),
    /// Unsigned integer.
    ///
    /// solidity name: uint
    Uint(Uint),
    /// Signed integer.
    ///
    /// solidity name: int
    Int(Int),
    /// String.
    ///
    /// solidity name: string
    /// Encoded in the same way as bytes. Must be utf8 compliant.
    String(String),
}

/// Function and event param types.
#[derive(PartialEq)]
pub enum ParamType {
    /// Address
    Address,
    /// Bytes
    Bytes,
    /// Unsigned integer
    Uint(usize),
    /// Signed integer
    Int(usize),
    /// String
    String,
    /// Vector of bytes with fixed size
    FixedBytes(usize),
}

impl ParamType {
    /// returns whether a zero length byte slice (`0x`) is
    /// a valid encoded form of this param type
    pub fn is_empty_bytes_valid_encoding(&self) -> bool {
        match self {
            ParamType::FixedBytes(len) => *len == 0,
            _ => false,
        }
    }
}

'''
'''--- common/src/access.rs ---
use crate::abi::Token;
use crate::{ensure, keccak_packed, Bytes32, Error, Zero};

/// Roles that are known at dev time.
pub enum StaticRole {
    UnlimitedReaderRole,
    NameSetterRole,
}

pub trait AccessControlRegistryAdminnedWithManager {
    type Address: AsRef<[u8]> + Zero + PartialEq;

    /// Get the manager of this registry
    fn manager(&self) -> &Self::Address;
    /// Admin role description
    fn admin_role_description(&self) -> String;
    /// Admin role description hash
    fn admin_role_description_hash(&self) -> Bytes32;
    /// Admin role
    fn admin_role(&self) -> Bytes32;
}

/// The access control registry interface in the solidity contract
pub trait AccessControlRegistry: AccessControlRegistryAdminnedWithManager {
    /// Default admin role, align with Openzepplin's definition
    const DEFAULT_ADMIN_ROLE: Bytes32 = [0; 32];
    const NAME_SETTER_ROLE_DESCRIPTION: &'static str = "Name setter";
    const UNLIMITED_READER_ROLE_DESCRIPTION: &'static str = "Unlimited reader";

    /// Find the role by its name. Not in the original solidity contract
    /// Just for making it work in Rust
    fn find_static_role(&self, role: StaticRole) -> Bytes32 {
        match role {
            StaticRole::UnlimitedReaderRole => self.derive_role(
                self.derive_admin_role(self.manager()),
                Self::UNLIMITED_READER_ROLE_DESCRIPTION.parse().unwrap(),
            ),
            StaticRole::NameSetterRole => self.derive_role(
                self.derive_admin_role(self.manager()),
                Self::NAME_SETTER_ROLE_DESCRIPTION.parse().unwrap(),
            ),
        }
    }
    /// Checks that an account has a specific role. Reverts
    /// with a standardized message including the required role.
    /// `role` The role to check
    /// `msg_sender` The address to check
    fn only_role(&self, role: &Bytes32, msg_sender: &Self::Address) -> Result<(), Error> {
        ensure!(
            self.has_role(
                &self.get_role_admin(role).ok_or(Error::RoleAdminNotFound)?,
                msg_sender
            ),
            Error::NotAuthorized
        )
    }
    /// Checks if user has a particular role
    /// `role` The role to check
    /// `who` The address to check
    fn has_role(&self, role: &Bytes32, who: &Self::Address) -> bool;
    /// Grant role for the user
    /// `role` The role to grant
    /// `who` The address to grant role
    fn grant_role(&mut self, role: &Bytes32, who: &Self::Address) -> Result<(), Error>;
    /// Get the admin role of role
    /// `role` The role to check
    fn get_role_admin(&self, role: &Bytes32) -> Option<Bytes32>;
    /// Set the role admin for a role
    /// `role` The role to grant
    /// `role_admin` The role admin
    fn set_role_admin(&mut self, role: &Bytes32, role_admin: Bytes32) -> Result<(), Error>;
    /// Called by the account to renounce the role
    /// Override to disallow managers to renounce their root roles.
    /// `role` Role to be renounced
    /// `account` Account to renounce the role
    fn renounce_role(&mut self, role: &Bytes32, account: &Self::Address) -> Result<(), Error>;
    /// Called by the role admin to renounce the role
    /// Override to disallow managers to renounce their root roles.
    /// `role` Role to be renounced
    /// `account` Account to renounce the role
    fn revoke_role(&mut self, role: &Bytes32, account: &Self::Address) -> Result<(), Error>;
    /// Initializes the manager by initializing its root role and
    /// granting it to them
    /// Anyone can initialize a manager. An uninitialized manager
    /// attempting to initialize a role will be initialized automatically.
    /// Once a manager is initialized, subsequent initializations have no
    /// effect.
    /// `manager` Manager address to be initialized
    fn initialize_manager(&mut self, manager: &Self::Address) -> Result<(), Error> {
        ensure!(!manager.is_zero(), Error::InvalidAddress)?;
        let root_role = RoleDeriver::derive_root_role(manager.as_ref());
        if !self.has_role(&root_role, manager) {
            self.grant_role(&root_role, manager)?;
        }
        Ok(())
    }
    /// Initializes a role by setting its admin role and grants it to
    /// the sender
    /// If the sender should not have the initialized role, they should
    /// explicitly renounce it after initializing it.
    /// Once a role is initialized, subsequent initializations have no effect
    /// other than granting the role to the sender.
    /// The sender must be a member of `admin_role`. `admin_role` value is not
    /// validated because the sender cannot have the `bytes32(0)` role.
    /// If the sender is an uninitialized manager that is initializing a role
    /// directly under their root role, manager initialization will happen
    /// automatically, which will grant the sender `admin_role` and allow them
    /// to initialize the role.
    /// `admin_role` Admin role to be assigned to the initialized role
    /// `description` Human-readable description of the initialized role
    /// `msg_sender` The message sender address
    fn initialize_role_and_grant_to_sender(
        &mut self,
        admin_role: Bytes32,
        description: String,
        msg_sender: &Self::Address,
    ) -> Result<Bytes32, Error> {
        ensure!(!description.is_empty(), Error::RoleDescriptionEmpty)?;
        let role = self.derive_role(admin_role, description);

        // AccessControl roles have `DEFAULT_ADMIN_ROLE` (i.e., `bytes32(0)`)
        // as their `admin_role` by default. No account in AccessControlRegistry
        // can possibly have that role, which means all initialized roles will
        // have non-default admin roles, and vice versa.
        if self.get_role_admin(&role) == Some(Self::DEFAULT_ADMIN_ROLE) {
            if admin_role == self.derive_root_role(msg_sender) {
                self.initialize_manager(msg_sender)?;
            }
            self.set_role_admin(&role, admin_role)?;
        }
        self.grant_role(&role, msg_sender)?;
        Ok(role)
    }
    /// Derives the admin role of the manager
    /// `manager` Manager address
    fn derive_admin_role(&self, manager: &Self::Address) -> Bytes32 {
        self.derive_role(
            self.derive_root_role(manager),
            self.admin_role_description(),
        )
    }
    /// Derives the root role of the manager
    /// `manager` Manager address
    fn derive_root_role(&self, manager: &Self::Address) -> Bytes32 {
        RoleDeriver::derive_root_role(manager.as_ref())
    }
    /// Derives the role using its admin role and description
    ///
    /// This implies that roles adminned by the same role cannot have the
    /// same description
    /// `admin_role` Admin role
    /// `description` Human-readable description of the role
    fn derive_role(&self, admin_role: Bytes32, description: String) -> Bytes32 {
        RoleDeriver::derive_role(admin_role, description)
    }
}

/// Contract that implements the AccessControlRegistry role derivation logic
///
/// If a contract interfaces with AccessControlRegistry and needs to
/// derive roles, it should inherit this contract instead of re-implementing
/// the logic
pub struct RoleDeriver;

impl RoleDeriver {
    /// Derives the root role of the manager
    /// `manager` Manager address
    /// `rootRole` Root role
    pub fn derive_root_role(manager: &[u8]) -> Bytes32 {
        keccak_packed(&[Token::FixedBytes(manager.to_vec())])
    }

    /// Derives the role using its admin role and description
    ///
    /// This implies that roles adminned by the same role cannot have the
    /// same description
    /// `admin_role` Admin role
    /// `description` Human-readable description of the role
    pub fn derive_role(admin_role: Bytes32, description: String) -> Bytes32 {
        Self::derive_role_with_hash(admin_role, keccak_packed(&[Token::String(description)]))
    }

    /// Derives the role using its admin role and description hash
    ///
    /// This implies that roles adminned by the same role cannot have the
    /// same description
    /// `admin_role` Admin role
    /// `description` Hash of the human-readable description of the role
    pub fn derive_role_with_hash(admin_role: Bytes32, description_hash: Bytes32) -> Bytes32 {
        keccak_packed(&[
            Token::FixedBytes(admin_role.to_vec()),
            Token::FixedBytes(description_hash.to_vec()),
        ])
    }
}

#[cfg(test)]
mod tests {}

'''
'''--- common/src/agg.rs ---
use crate::abi::Int;
use crate::DataPoint;
use std::ops::Div;

/// The Manager for handling multiple datapoints
pub struct Aggregator;

impl Aggregator {
    pub fn agg(datapoints: &[DataPoint]) -> DataPoint {
        let value = Int::from(0);
        let timestamp = 0u32;
        for d in datapoints {
            value.checked_add(d.value).expect("value overflow");
            timestamp
                .checked_add(d.timestamp)
                .expect("timestamp overflow");
        }
        let l = datapoints.len();
        DataPoint::new(value.div(l), timestamp / l as u32)
    }
}

'''
'''--- common/src/beacon.rs ---
use crate::abi::{decode, encode, encode_packed, keccak256, Int, ParamType, Token, Uint, U256};
use crate::access::AccessControlRegistry;
use crate::whitelist::Whitelist;
use crate::{ensure, keccak_packed, median, Bytes, Bytes32, DataPoint, Error, StaticRole, Zero};

const ONE_HOUR_IN_SECONDS: u32 = 3600;
const FIFTEEN_MINUTES_IN_SECONDS: u32 = 900;

/// Generic storage trait. Used for the common processing logic so that each chain could
/// have their own implementation.
pub trait Storage<T> {
    fn get(&self, key: &Bytes32) -> Option<T>;
    fn store(&mut self, key: Bytes32, t: T);
}

/// Public trait that handles signature verification across different chains
pub trait SignatureManger {
    /// Verifies the signature against the message and public key
    /// Returns if the signature is valid
    ///
    /// # Arguments
    ///
    /// * `key` - The public key of the signer
    /// * `message` - The message to verify
    /// * `signature` - The signature to verify
    fn verify(key: &[u8], message: &[u8], signature: &[u8]) -> bool;
}

/// Public trait that handles timestamp fetching across different chains
pub trait TimestampChecker {
    fn current_timestamp(&self) -> u32;

    /// Returns if the timestamp used in the signature is valid
    /// Returns `false` if the timestamp is not at most 1 hour old to
    /// prevent replays. Returns `false` if the timestamp is not from the past,
    /// with some leeway to accomodate for some benign time drift. These values
    /// are appropriate in most cases, but you can adjust them if you are aware
    /// of the implications.
    ///
    /// # Arguments
    ///
    /// * `timestamp` Timestamp used in the signature
    fn is_valid(&self, timestamp: u32) -> bool {
        let c = self.current_timestamp();
        timestamp
            .checked_add(ONE_HOUR_IN_SECONDS)
            .expect("Invalid timestamp")
            > c
            && timestamp < c + FIFTEEN_MINUTES_IN_SECONDS
    }
}

/// Reads the data point with ID
/// Returns tuple containing (DataPoint.value, DataPoint.timestamp).
///
/// # Arguments
///
/// * `datapoint_id` Data point ID
/// * `msg_sender` Address of who sent the transaction
/// * `datapoint_storage` Data point storage that links `datapoint_id` to `Datapoint`
/// * `access` The access control registry used
/// * `whitelist` The whitelist implementation used
pub fn read_with_data_point_id<
    D: Storage<DataPoint>,
    A: AccessControlRegistry,
    W: Whitelist<Address = A::Address>,
>(
    datapoint_id: &Bytes32,
    msg_sender: &A::Address,
    datapoint_storage: &D,
    access: &A,
    whitelist: &W,
) -> Result<(Int, u32), Error> {
    ensure!(
        reader_can_read_data_point(datapoint_id, msg_sender, access, whitelist),
        Error::AccessDenied
    )?;
    let data_point = datapoint_storage
        .get(datapoint_id)
        .ok_or(Error::BeaconDataNotFound)?;
    Ok((data_point.value, data_point.timestamp))
}

/// Reads the data point with name
/// The read data point may belong to a Beacon or dAPI. The reader
/// must be whitelisted for the hash of the data point name.
/// Returns tuple containing (DataPoint.value, DataPoint.timestamp).
///
/// # Arguments
///
/// * `name` Data point name
/// * `msg_sender` Address of who sent the transaction
/// * `datapoint_storage` Data point storage that links `datapoint_id` to `Datapoint`
/// * `name_storage` Name to Datapoint Id storage used
/// * `access` The access control registry used
/// * `whitelist` The whitelist implementation used
pub fn read_with_name<
    D: Storage<DataPoint>,
    H: Storage<Bytes32>,
    A: AccessControlRegistry,
    W: Whitelist<Address = A::Address>,
>(
    name: Bytes32,
    msg_sender: &A::Address,
    datapoint_storage: &D,
    name_storage: &H,
    access: &A,
    whitelist: &W,
) -> Result<(Int, u32), Error> {
    let name_hash = keccak_packed(&[Token::FixedBytes(name.to_vec())]);
    ensure!(
        reader_can_read_data_point(&name_hash, msg_sender, access, whitelist),
        Error::AccessDenied
    )?;
    let key = name_storage
        .get(&name_hash)
        .ok_or(Error::NameHashNotFound)?;
    let data_point = datapoint_storage
        .get(&key)
        .ok_or(Error::BeaconDataNotFound)?;
    Ok((data_point.value, data_point.timestamp))
}

/// Returns if a reader can read the data point
///
/// # Arguments
///
/// * `data_point_id` Data point ID
/// * `reader` The reader that is trying to read the datapoint
/// * `access` The access control registry used
/// * `whitelist` The whitelist implementation used
pub fn reader_can_read_data_point<A: AccessControlRegistry, W: Whitelist<Address = A::Address>>(
    data_point_id: &Bytes32,
    reader: &A::Address,
    access: &A,
    whitelist: &W,
) -> bool {
    let role = access.find_static_role(StaticRole::UnlimitedReaderRole);
    reader.is_zero()
        || whitelist.user_is_whitelisted(data_point_id, reader)
        || access.has_role(&role, reader)
}

/// Updates the dAPI that is specified by the beacon IDs.
/// Returns the dAPI ID.
///
/// # Arguments
///
/// * `beacon_ids` is the list of beacon ids to perform aggregation
pub fn update_dapi_with_beacons<D: Storage<DataPoint>>(
    d: &mut D,
    beacon_ids: &[Bytes32],
) -> Result<Bytes32, Error> {
    let beacon_count = beacon_ids.len();
    ensure!(beacon_count > 1, Error::LessThanTwoBeacons)?;

    let mut values = Vec::with_capacity(beacon_count);
    let mut accumulated_timestamp = U256::from(0);

    for beacon_id in beacon_ids {
        let data_point = d.get(beacon_id).ok_or(Error::BeaconDataNotFound)?;
        values.push(data_point.value);
        accumulated_timestamp += U256::from(data_point.timestamp);
    }

    let dapi_id = derive_dapi_id(beacon_ids);
    let dapi_datapoint = d.get(&dapi_id).ok_or(Error::BeaconDataNotFound)?;

    let updated_timestamp = (accumulated_timestamp / beacon_count).as_u32();
    ensure!(
        updated_timestamp >= dapi_datapoint.timestamp,
        Error::UpdatedValueOutdated
    )?;
    let updated_value = median(&values);
    let datapoint = DataPoint::new(updated_value, updated_timestamp);

    d.store(dapi_id, datapoint);
    Ok(dapi_id)
}

/// Updates a dAPI using data signed by the respective Airnodes
/// without requiring a request or subscription. The beacons for which the
/// signature is omitted will be read from the storage.
/// Returns the dAPI ID.
///
/// # Arguments
///
/// * `datapoint_storage` The datapoint storage trait implementation to use
/// * `timestamp_checker` The timestamp checker/validator to use
/// * `airnodes` Airnode addresses
/// * `template_ids` Template IDs
/// * `timestamps` Timestamps used in the signatures
/// * `data` Response data (an `int256` encoded in contract ABI per Beacon)
/// * `signatures` Template ID, a timestamp and the response data signed by the respective Airnode address per Beacon
#[allow(clippy::too_many_arguments)]
pub fn update_dapi_with_signed_data<
    D: Storage<DataPoint>,
    S: SignatureManger,
    T: TimestampChecker,
>(
    datapoint_storage: &mut D,
    timestamp_checker: &T,
    airnodes: Vec<Bytes>,
    template_ids: Vec<[u8; 32]>,
    timestamps: Vec<[u8; 32]>,
    data: Vec<Bytes>,
    signatures: Vec<Bytes>,
) -> Result<Bytes32, Error> {
    let beacon_count = template_ids.len();

    ensure!(
        beacon_count == template_ids.len()
            && beacon_count == timestamps.len()
            && beacon_count == data.len()
            && beacon_count == signatures.len(),
        Error::ParameterLengthMismatch
    )?;

    ensure!(beacon_count > 1, Error::LessThanTwoBeacons)?;

    let mut beacon_ids = Vec::with_capacity(beacon_count);
    let mut values = Vec::with_capacity(beacon_count);
    let mut accumulated_timestamp = U256::from(0);

    for ind in 0..beacon_count {
        if !signatures[ind].is_empty() {
            let timestamp = U256::from_big_endian(&timestamps[ind]);
            let timestamp_u32 = timestamp.as_u32();
            ensure!(
                timestamp_checker.is_valid(timestamp_u32),
                Error::InvalidTimestamp
            )?;

            let message = keccak_packed(&[
                Token::FixedBytes(template_ids[ind].clone().to_vec()),
                Token::Uint(timestamp),
                Token::Bytes(data[ind].clone()),
            ]);
            ensure!(
                S::verify(&airnodes[ind], &message, &signatures[ind]),
                Error::InvalidSignature
            )?;

            values.push(decode_fulfillment_data(&data[ind])?);

            // Timestamp validity is already checked, which means it will
            // be small enough to be typecast into `uint32`
            accumulated_timestamp += timestamp;
            beacon_ids.push(derive_beacon_id(airnodes[ind].clone(), template_ids[ind]));
        } else {
            let beacon_id = derive_beacon_id(airnodes[ind].clone(), template_ids[ind]);
            let data_point = datapoint_storage
                .get(&beacon_id)
                .ok_or(Error::BeaconDataNotFound)?;
            values.push(data_point.value);
            accumulated_timestamp += U256::from(data_point.timestamp);
            beacon_ids.push(beacon_id);
        }
    }
    let dapi_id = derive_dapi_id(&beacon_ids);
    let updated_timestamp = (accumulated_timestamp / beacon_count).as_u32();
    let dapi_datapoint = datapoint_storage
        .get(&dapi_id)
        .ok_or(Error::BeaconDataNotFound)?;
    ensure!(
        updated_timestamp >= dapi_datapoint.timestamp,
        Error::UpdatedValueOutdated
    )?;
    let updated_value = median(&values);
    let datapoint = DataPoint::new(updated_value, updated_timestamp);
    datapoint_storage.store(dapi_id, datapoint);
    Ok(dapi_id)
}

/// Sets the data point ID the name points to
/// While a data point ID refers to a specific Beacon or dAPI, names
/// provide a more abstract interface for convenience. This means a name
/// that was pointing at a Beacon can be pointed to a dAPI, then another
/// dAPI, etc.
///
/// # Arguments
///
/// * `name` Human-readable name
/// * `datapoint_id` Data point ID the name will point to
/// * `msg_sender` Address of who sent the transaction
/// * `access` Access control implementation to use
/// * `storage` Storage implementation to use for linking name and datapoint_id
pub fn set_name<D: Storage<Bytes32>, A: AccessControlRegistry>(
    name: Bytes32,
    datapoint_id: Bytes32,
    msg_sender: &A::Address,
    access: &A,
    storage: &mut D,
) -> Result<(), Error> {
    ensure!(name != Bytes32::default(), Error::InvalidData)?;
    ensure!(datapoint_id != Bytes32::default(), Error::InvalidData)?;
    let role = access.find_static_role(StaticRole::NameSetterRole);
    ensure!(access.has_role(&role, msg_sender), Error::AccessDenied)?;

    storage.store(
        keccak_packed(&[Token::FixedBytes(name.to_vec())]),
        datapoint_id,
    );

    Ok(())
}

/// Derives the beacon id based on the `airnode` and `templated_id`
/// Returns the beacon id
///
/// # Arguments
///
/// * `airnode` Airnode address
/// * `template_id` Template ID
pub fn derive_beacon_id(airnode: Bytes, template_id: Bytes32) -> Bytes32 {
    ensure!(not_zero(&airnode), Error::AirnodeIdZero).unwrap();
    ensure!(not_zero(&template_id), Error::TemplateIdZero).unwrap();
    let (encoded, _) = encode_packed(&[
        Token::Bytes(airnode),
        Token::FixedBytes(template_id.to_vec()),
    ]);
    keccak256(&encoded)
}

/// Derives the dAPI ID from the beacon IDs
/// Notice that `encode()` is used over `encode_packed()`
/// Returns the derived dapi id
///
/// # Arguments
///
/// * `beacon_ids` Beacon IDs
pub fn derive_dapi_id(beacon_ids: &[Bytes32]) -> Bytes32 {
    let tokens: Vec<Token> = beacon_ids
        .iter()
        .map(|b| Token::FixedBytes(b.to_vec()))
        .collect();
    let encoded = encode(&tokens);
    keccak256(&encoded)
}

/// Decode the encoded data to the respective data types.
/// Returns the `Result` of decoding fulfillment data.
///
/// # Arguments
///
/// * `data` Fulfillment data (an `int256` encoded in contract ABI)
pub fn decode_fulfillment_data(data: &Bytes) -> Result<Int, Error> {
    ensure!(data.len() == 32, Error::InvalidDataLength)?;

    let tokens = decode(&[ParamType::Int(0)], data)?;
    ensure!(tokens.len() == 1, Error::InvalidDataLength)?;

    if let Token::Int(i) = tokens[0] {
        Ok(i)
    } else {
        Err(Error::InvalidDataType)
    }
}

/// Called privately to process the Beacon update.
/// Returns the updated Beacon value.
///
/// # Arguments
///
/// * `storage` The storage between `beacon_id` to `Datapoint`
/// * `beacon_id` The Beacon ID
/// * `timestamp` Timestamp used in the signature
/// * `data` Fulfillment data (an `int256` encoded in contract ABI)
pub fn process_beacon_update<D: Storage<DataPoint>>(
    storage: &mut D,
    beacon_id: Bytes32,
    timestamp: Uint,
    data: Bytes,
) -> Result<(), Error> {
    let updated_beacon_value = decode_fulfillment_data(&data)?;

    let beacon = storage.get(&beacon_id).ok_or(Error::BeaconDataNotFound)?;
    ensure!(
        timestamp.as_u32() > beacon.timestamp,
        Error::FulfillmentOlderThanBeacon
    )?;

    // Timestamp validity is already checked by `onlyValidTimestamp`, which
    // means it will be small enough to be typecast into `uint32`

    let datapoint = DataPoint::new(updated_beacon_value, timestamp.as_u32());
    storage.store(beacon_id, datapoint);

    Ok(())
}

fn not_zero(bytes: &[u8]) -> bool {
    let mut count = 0;
    for i in bytes {
        if *i == 0u8 {
            count += 1;
        }
    }
    count != bytes.len()
}

#[cfg(test)]
mod tests {
    use crate::beacon::not_zero;
    use crate::derive_beacon_id;

    #[test]
    fn not_zero_works() {
        assert!(!not_zero(&[0; 12]));
        let mut v = [0; 12];
        v[2] = 1;
        assert!(not_zero(&v));
    }

    #[test]
    fn encode_packed_works() {
        let raw_template_id =
            hex::decode("0000000000000000000000000000000000000000000000000000000000000001")
                .unwrap();
        let airnode =
            hex::decode("1d73899cc9fc3ad06a2c7f5bf26c8a4a76b42de905cb9b6ae96390355441a0ca")
                .unwrap();
        let mut template_id = [0; 32];
        template_id.copy_from_slice(&raw_template_id);
        let beacon_id = derive_beacon_id(airnode, template_id);
        assert_eq!(
            hex::encode(beacon_id),
            "ad1b5c75a8b8e0d7dbc56c1e28aee9fabe285ad8fb61a256ddabd4523bfb284a"
        );
    }
}

'''
'''--- common/src/datapoint.rs ---
use crate::abi::Int;
use crate::error;

/// The data point struct in the original API3 beacon server contract
#[derive(Clone, Default)]
pub struct DataPoint {
    pub value: Int,
    pub timestamp: u32,
}

impl DataPoint {
    /// Len of the data point as bytes, value is 32 bytes and timestamp is 4 bytes
    const LEN: usize = 36;

    pub fn new(value: Int, timestamp: u32) -> Self {
        Self { value, timestamp }
    }

    pub fn from(raw: Vec<u8>) -> Result<Self, error::Error> {
        if raw.len() != Self::LEN {
            Err(error::Error::CannotDeserializeDataPoint)
        } else {
            let value = Int::from_big_endian(&raw[0..32]);
            Ok(Self {
                value,
                timestamp: u32::from_be_bytes([raw[32], raw[33], raw[34], raw[35]]),
            })
        }
    }
}

impl From<DataPoint> for Vec<u8> {
    fn from(d: DataPoint) -> Self {
        let mut v = vec![0u8; DataPoint::LEN];
        d.value.to_big_endian(&mut v[0..32]);
        v[32..].copy_from_slice(&d.timestamp.to_be_bytes());
        v
    }
}

impl From<DataPoint> for [u8; 36] {
    fn from(d: DataPoint) -> Self {
        let mut v = [0u8; DataPoint::LEN];
        d.value.to_big_endian(&mut v[0..32]);
        v[32..].copy_from_slice(&d.timestamp.to_be_bytes());
        v
    }
}

'''
'''--- common/src/dummy.rs ---
//! A collection of default implementations

use crate::abi::U256;
use crate::{
    AccessControlRegistry, AccessControlRegistryAdminnedWithManager, Bytes32, Error, Whitelist,
    WhitelistRoles, WhitelistRolesWithManager, WhitelistWithManager, Zero,
};

pub struct DummyWhitelist<Address: AsRef<[u8]> + Zero + Default + PartialEq> {
    manager: Address,
}

impl<Address: AsRef<[u8]> + Zero + Default + PartialEq> Default for DummyWhitelist<Address> {
    fn default() -> Self {
        Self {
            manager: Address::default(),
        }
    }
}

impl<Address> Whitelist for DummyWhitelist<Address>
where
    Address: AsRef<[u8]> + Zero + Default + PartialEq,
{
    type Address = Address;
    fn user_is_whitelisted(&self, _service_id: &Bytes32, _user: &Self::Address) -> bool {
        false
    }
    fn extend_whitelist_expiration(
        &mut self,
        _service_id: &Bytes32,
        _user: &Self::Address,
        _expiration_timestamp: u64,
    ) {
    }

    fn set_whitelist_expiration(
        &mut self,
        _service_id: &Bytes32,
        _user: &Self::Address,
        _expiration_timestamp: u64,
    ) {
    }

    fn set_indefinite_whitelist_status(
        &mut self,
        _service_id: &Bytes32,
        _user: &Self::Address,
        _status: bool,
    ) -> U256 {
        U256::from(0u8)
    }

    fn revoke_indefinite_whitelist_status(
        &mut self,
        _service_id: &Bytes32,
        _user: &Self::Address,
        _setter: &Self::Address,
    ) -> (bool, U256) {
        (true, U256::from(0u8))
    }
}

impl<Address> WhitelistRoles for DummyWhitelist<Address> where
    Address: AsRef<[u8]> + Default + PartialEq + Zero
{
}

impl<Address> WhitelistRolesWithManager for DummyWhitelist<Address>
where
    Address: AsRef<[u8]> + Default + PartialEq + Zero,
{
    fn has_whitelist_expiration_extender_role_or_is_manager(
        &self,
        _account: &Self::Address,
    ) -> bool {
        true
    }

    fn has_indefinite_whitelister_role_or_is_manager(&self, _account: &Self::Address) -> bool {
        true
    }

    fn has_whitelist_expiration_setter_role_or_is_manager(&self, _account: &Self::Address) -> bool {
        true
    }
}

impl<Address> AccessControlRegistryAdminnedWithManager for DummyWhitelist<Address>
where
    Address: AsRef<[u8]> + Default + PartialEq + Zero,
{
    type Address = Address;

    fn manager(&self) -> &Self::Address {
        &self.manager
    }

    fn admin_role_description(&self) -> String {
        String::from("")
    }

    fn admin_role_description_hash(&self) -> Bytes32 {
        Bytes32::default()
    }

    fn admin_role(&self) -> Bytes32 {
        Bytes32::default()
    }
}

impl<Address> WhitelistWithManager for DummyWhitelist<Address>
where
    Address: AsRef<[u8]> + Zero + Default + PartialEq,
{
    fn extend_whitelist_expiration(
        &mut self,
        _service_id: &Bytes32,
        _user: &<Self as Whitelist>::Address,
        _expiration_timestamp: u64,
    ) {
    }

    fn set_whitelist_expiration(
        &mut self,
        _service_id: &Bytes32,
        _user: &<Self as Whitelist>::Address,
        _expiration_timestamp: u64,
    ) {
    }

    fn set_indefinite_whitelist_status(
        &mut self,
        _service_id: &Bytes32,
        _user: &<Self as Whitelist>::Address,
        _status: bool,
    ) -> U256 {
        U256::from(0u8)
    }

    fn revoke_indefinite_whitelist_status(
        &mut self,
        _service_id: &Bytes32,
        _user: &<Self as Whitelist>::Address,
        _setter: &<Self as Whitelist>::Address,
    ) -> (bool, U256) {
        (false, U256::from(0u8))
    }
}

pub struct DummyAccess<Address: AsRef<[u8]> + Zero + Default + PartialEq> {
    manager: Address,
}

impl<Address: AsRef<[u8]> + Zero + Default + PartialEq> Default for DummyAccess<Address> {
    fn default() -> Self {
        Self {
            manager: Address::default(),
        }
    }
}

impl<Address> AccessControlRegistryAdminnedWithManager for DummyAccess<Address>
where
    Address: AsRef<[u8]> + Zero + Default + PartialEq,
{
    type Address = Address;
    fn manager(&self) -> &Self::Address {
        &self.manager
    }
    fn admin_role_description(&self) -> String {
        String::from("")
    }
    fn admin_role_description_hash(&self) -> Bytes32 {
        Bytes32::default()
    }
    fn admin_role(&self) -> Bytes32 {
        Bytes32::default()
    }
}

impl<Address> AccessControlRegistry for DummyAccess<Address>
where
    Address: AsRef<[u8]> + Zero + Default + PartialEq,
{
    fn has_role(&self, _role: &Bytes32, _who: &Self::Address) -> bool {
        true
    }
    fn grant_role(&mut self, _role: &Bytes32, _who: &Self::Address) -> Result<(), Error> {
        Ok(())
    }
    fn get_role_admin(&self, _role: &Bytes32) -> Option<Bytes32> {
        Some(Bytes32::default())
    }
    fn set_role_admin(&mut self, _role: &Bytes32, _role_admin: Bytes32) -> Result<(), Error> {
        Ok(())
    }
    fn renounce_role(&mut self, _role: &Bytes32, _account: &Self::Address) -> Result<(), Error> {
        Ok(())
    }

    fn revoke_role(&mut self, _role: &Bytes32, _account: &Self::Address) -> Result<(), Error> {
        Ok(())
    }
}

'''
'''--- common/src/error.rs ---
use std::fmt::Debug;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum Error {
    #[error("")]
    CannotDeserializeDataPoint,
    #[error("")]
    InvalidData,
    #[error("Data length not correct")]
    InvalidDataLength,
    #[error("Invalid data type")]
    InvalidDataType,
    #[error("Beacon data not found")]
    BeaconDataNotFound,
    #[error("Fulfillment older than Beacon")]
    FulfillmentOlderThanBeacon,
    #[error("Invalid name: {0}")]
    InvalidName(String),
    #[error("Parameter length mismatch")]
    ParameterLengthMismatch,
    #[error("Specified less than two Beacons")]
    LessThanTwoBeacons,
    #[error("Timestamp not valid")]
    InvalidTimestamp,
    #[error("Signature mismatch")]
    InvalidSignature,
    #[error("Updated value outdated")]
    UpdatedValueOutdated,
    #[error("Does not extend expiration")]
    DoesNotExtendExpiration,
    #[error("Access Denied")]
    AccessDenied,
    #[error("NameHash Not Found")]
    NameHashNotFound,
    #[error("Role description Empty")]
    RoleDescriptionEmpty,
    #[error("Service ID zero")]
    ServiceIdZero,
    #[error("User address zero")]
    UserAddressZero,
    #[error("Invalid Address")]
    InvalidAddress,
    #[error("Only Renounce roles for self")]
    OnlyRenounceRolesForSelf,
    #[error("Not authorized to perform this action")]
    NotAuthorized,
    #[error("Role admin not found")]
    RoleAdminNotFound,
    #[error("Contract already initialized")]
    AlreadyInitialized,
    #[error("Cannot set indefinite status")]
    CannotSetIndefiniteStatus,
    #[error("Template id cannot be zero")]
    TemplateIdZero,
    #[error("Airnode id cannot be zero")]
    AirnodeIdZero,
    #[error("Setter can set indefinite status")]
    SetterCanSetIndefiniteStatus,
}

impl From<Error> for u32 {
    fn from(e: Error) -> Self {
        match e {
            Error::CannotDeserializeDataPoint => 0,
            Error::InvalidData => 1,
            Error::InvalidDataLength => 2,
            Error::InvalidDataType => 3,
            Error::BeaconDataNotFound => 4,
            Error::FulfillmentOlderThanBeacon => 5,
            Error::InvalidName(_) => 6,
            Error::ParameterLengthMismatch => 9,
            Error::LessThanTwoBeacons => 10,
            Error::InvalidTimestamp => 11,
            Error::InvalidSignature => 12,
            Error::UpdatedValueOutdated => 13,
            Error::AccessDenied => 14,
            Error::NameHashNotFound => 15,
            Error::RoleDescriptionEmpty => 16,
            Error::DoesNotExtendExpiration => 17,
            Error::ServiceIdZero => 18,
            Error::UserAddressZero => 19,
            Error::InvalidAddress => 20,
            Error::OnlyRenounceRolesForSelf => 21,
            Error::NotAuthorized => 22,
            Error::RoleAdminNotFound => 23,
            Error::AlreadyInitialized => 24,
            Error::CannotSetIndefiniteStatus => 25,
            Error::TemplateIdZero => 26,
            Error::AirnodeIdZero => 27,
            Error::SetterCanSetIndefiniteStatus => 28,
        }
    }
}

'''
'''--- common/src/lib.rs ---
pub mod abi;
mod access;
mod agg;
mod beacon;
mod datapoint;
#[cfg(feature = "dummy")]
pub mod dummy;
mod error;
pub mod util;
mod whitelist;

pub use access::*;
pub use agg::Aggregator;
pub use beacon::*;
pub use datapoint::DataPoint;
pub use error::Error;
pub use util::*;
pub use whitelist::*;

pub type Bytes = Vec<u8>;
pub type Bytes32 = [u8; 32];
pub const BYTES32_ZERO: Bytes32 = [0u8; 32];

#[macro_export]
macro_rules! ensure {
    ( $x:expr, $y:expr ) => {{
        if !$x {
            Err($y)
        } else {
            Ok(())
        }
    }};
}

/// Checks if the address is zero
pub trait Zero {
    fn is_zero(&self) -> bool;
}

impl Zero for Bytes32 {
    fn is_zero(&self) -> bool {
        (*self) == BYTES32_ZERO
    }
}

'''
'''--- common/src/util.rs ---
use crate::abi::{encode_packed, keccak256, Token};
use crate::Bytes32;
pub use median::median;
pub use median::median_wrapped_u256;
pub use sort::sort;

mod median;
mod sort;

pub fn keccak_packed(tokens: &[Token]) -> Bytes32 {
    let (encoded, _) = encode_packed(tokens);
    keccak256(&encoded)
}

'''
'''--- common/src/util/median.rs ---
use super::sort;
use crate::abi::U256;

/// get the median from an array of U256
pub fn median(array: &[U256]) -> U256 {
    let len = array.len();
    let array = sort(array);
    let mid: usize = len / 2;
    if len % 2 == 1 {
        array[mid]
    } else {
        (array[mid - 1] + array[mid]) / 2
    }
}

/// TODO: find a way to unify this with the non-wrapped one
pub fn median_wrapped_u256(array: &[U256]) -> U256 {
    let len = array.len();
    let array = sort(array);
    let mid: usize = len / 2;
    if len % 2 == 1 {
        array[mid]
    } else {
        (array[mid - 1] + array[mid]) / 2
    }
}

#[test]
fn ideal_median() {
    let numbers = vec![U256::from(1_i128), U256::from(2_i128), U256::from(3_i128)];
    let result = median(&numbers);
    assert_eq!(result, U256::from(2_i128));
}

#[test]
fn even_length() {
    let numbers = vec![
        U256::from(2_u128),
        U256::from(3_u128),
        U256::from(5_u128),
        U256::from(9_u128),
    ];
    let result = median(&numbers);
    assert_eq!(result, U256::from(4_i128));
}

'''
'''--- common/src/util/sort.rs ---
use std::cmp::Ord;

/// sort an array of U256
pub fn sort<T>(array: &[T]) -> Vec<T>
where
    T: Clone + Ord,
{
    let mut array = array.to_vec();
    array.sort();
    array
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::abi::U256;

    #[test]
    fn already_sorted() {
        let numbers = vec![U256::from(1_i128), U256::from(2_i128), U256::from(3_i128)];
        let result = sort(&numbers);
        assert_eq!(result, numbers);
    }

    #[test]
    fn unsorted() {
        let numbers = vec![U256::from(2_i128), U256::from(1_i128), U256::from(3_i128)];
        let result = sort(&numbers);
        let expected = vec![U256::from(1_i128), U256::from(2i128), U256::from(3_i128)];
        assert_eq!(result, expected);
    }

    #[test]
    fn large_numbers() {
        let numbers = vec![
            U256::from(212837128371931812_u128),
            U256::from(u128::MAX),
            U256::from(51623219381273_u128),
        ];
        let result = sort(&numbers);
        let expected = vec![
            U256::from(51623219381273_u128),
            U256::from(212837128371931812_u128),
            U256::from(u128::MAX),
        ];
        assert_eq!(result, expected);
    }

    #[test]
    fn max_numbers() {
        let numbers = vec![U256::MAX, U256::from([u8::MAX; 32])];
        let result = sort(&numbers);
        let expected = vec![U256::from([u8::MAX; 32]), U256::MAX];
        assert_eq!(result, expected);
    }
}

'''
'''--- common/src/whitelist.rs ---
#![allow(unused)]
use crate::abi::{Token, U256};
use crate::Error;
use crate::{ensure, keccak_packed, AccessControlRegistryAdminnedWithManager, RoleDeriver};
use crate::{Bytes32, Zero};

/// Trait that implements temporary and permanent whitelists for
/// multiple services identified with a hash
///
/// This trait implements two kinds of whitelisting:
///   (1) Temporary, ends when the expiration timestamp is in the past
///   (2) Indefinite, ends when the indefinite whitelist count is zero
/// Multiple senders can indefinitely whitelist/unwhitelist independently. The
/// user will be considered whitelisted as long as there is at least one active
/// indefinite whitelisting.
///
/// The interface of this contract is not implemented. It should be
/// inherited and its functions should be exposed with a sort of an
/// authorization scheme.
pub trait Whitelist {
    /// The address type for the chain
    type Address: AsRef<[u8]> + Zero;

    /// Returns if the user is whitelised to use the service
    ///
    /// # Argument
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    fn user_is_whitelisted(&self, service_id: &Bytes32, user: &Self::Address) -> bool;

    /// Extends the expiration of the temporary whitelist of the user
    /// for the service
    ///
    /// # Argument
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    fn extend_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        expiration_timestamp: u64,
    );

    /// Sets the expiration of the temporary whitelist of `user` to be
    /// able to use the service with `serviceId` if the sender has the
    /// whitelist expiration setter role
    ///
    /// # Argument
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    fn set_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        expiration_timestamp: u64,
    );

    /// Sets the indefinite whitelist status of `user` to be able to
    /// use the service with `serviceId` if the sender has the indefinite
    /// whitelister role
    ///
    /// # Argument
    ///
    /// `service_id` Service ID
    /// `user` User address
    /// `status` Indefinite whitelist status
    fn set_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        status: bool,
    ) -> U256;

    /// Revokes the indefinite whitelist status granted to the user for
    /// the service by a specific account
    ///
    /// # Argument
    ///
    /// `service_id` Service ID
    /// `user` User address
    /// `setter` Setter of the indefinite whitelist status
    fn revoke_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        setter: &Self::Address,
    ) -> (bool, U256);
}

pub trait WhitelistRoles {
    fn whitelist_expiration_extender_role_description() -> String {
        String::from("Whitelist expiration extender")
    }

    fn whitelist_expiration_setter_role_description() -> String {
        String::from("Whitelist expiration setter")
    }

    fn indefinite_whitelister_role_description() -> String {
        String::from("Indefinite whitelister")
    }
}

pub trait WhitelistRolesWithManager:
    WhitelistRoles + AccessControlRegistryAdminnedWithManager
{
    /// Returns if the account has the whitelist expiration extender role
    /// or is the manager
    ///
    /// # Arguments
    ///
    /// * `account` Account address
    fn has_whitelist_expiration_extender_role_or_is_manager(&self, account: &Self::Address)
        -> bool;

    /// Returns if the account has the indefinite whitelister role or is the
    /// manager
    ///
    /// # Arguments
    ///
    /// * `account` Account address
    fn has_indefinite_whitelister_role_or_is_manager(&self, account: &Self::Address) -> bool;

    /// Returns if the account has the whitelist expriation setter role or
    /// is the manager
    ///
    /// # Arguments
    ///
    /// * `account` Account address
    fn has_whitelist_expiration_setter_role_or_is_manager(&self, account: &Self::Address) -> bool;

    fn whitelist_expiration_extender_role(&self) -> Bytes32 {
        RoleDeriver::derive_role(
            self.admin_role(),
            Self::whitelist_expiration_extender_role_description(),
        )
    }

    fn whitelist_expiration_setter_role(&self) -> Bytes32 {
        RoleDeriver::derive_role(
            self.admin_role(),
            Self::whitelist_expiration_setter_role_description(),
        )
    }

    fn indefinite_whitelister_role(&self) -> Bytes32 {
        RoleDeriver::derive_role(
            self.admin_role(),
            Self::indefinite_whitelister_role_description(),
        )
    }
}

/// Whitelist contract that is controlled by a manager
pub trait WhitelistWithManager: Whitelist + WhitelistRolesWithManager {
    /// Extends the expiration of the temporary whitelist of `user` to
    /// be able to use the service with `service_id` if the sender has the
    /// whitelist expiration extender role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    fn extend_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        expiration_timestamp: u64,
    );

    /// Sets the expiration of the temporary whitelist of `user` to be
    /// able to use the service with `service_id` if the sender has the
    /// whitelist expiration setter role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    fn set_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        expiration_timestamp: u64,
    );

    /// Sets the indefinite whitelist status of `user` to be able to
    /// use the service with `service_id` if the sender has the indefinite whitelister role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `status` Indefinite whitelist status
    fn set_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        status: bool,
    ) -> U256;

    /// Revokes the indefinite whitelist status granted to the user for
    /// the service by a specific account
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `setter` Setter address
    fn revoke_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        setter: &<Self as Whitelist>::Address,
    ) -> (bool, U256);
}

'''
'''--- near/client-test/package.json ---
{
  "name": "api3-near-client",
  "description": "",
  "version": "0.0.1",
  "license": "MIT",
  "type":"module",
  "scripts": {
    "test": "NEAR_NO_LOGS=true jest --runInBand"
  },
  "devDependencies": {
    "@types/jest": "^27.5.0",
    "@types/node": "^17.0.31",
    "env-cmd": "^10.1.0",
    "gh-pages": "~3.2.3",
    "jest": "~27.3.1",
    "jest-environment-node": "~27.3.1",
    "near-cli": "^2.1.1",
    "nodemon": "~2.0.14",
    "parcel-bundler": "~1.12.5"
  },
  "jest": {
    "testTimeout": 40000
  },
  "dependencies": {
    "ethers": "^5.6.5",
    "near-api-js": "^0.45.1",
    "regenerator-runtime": "^0.13.9",
    "tweetnacl": "^1.0.3"
  }
}

'''
'''--- near/client-test/src/client.js ---
const { toBuffer, bufferU64BE, encodeData } = require("./util");

class DapiServer {
    contract;

    constructor(contract) {
        this.contract = contract;
    }

    async hasRole(role, who) {
        return await this.contract.has_role({ role: [...role], who});
    }

    async grantRole(role, who) {
        return await this.contract.grant_role({ args: { role: [...role], who } });
    }

    async revokeRole(role, who) {
        return await this.contract.revoke_role( { args: { role: [...role], who} });
    }

    async renounceRole(role, who) {
        return await this.contract.renounce_role( { args: { role: [...role], who} });
    }

    async readDataFeedWithId(dataPointId) {
        const data = await this.contract.read_with_data_point_id( { args: {data_point_id: [...dataPointId]} });
        return {
            value: data[0],
            timestamp: data[1]
        };
    }

    async readDataFeedWithDapiName(name) {
        const data = await this.contract.read_with_name( { args: {name: [...name]} });
        return {
            value: data[0],
            timestamp: data[1]
        };
    }

    async updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature) {
        const pubKeyBuf = toBuffer(airnodeAddress);
        const bufferedTimestamp = bufferU64BE(timestamp);
        const bufferedTemplateId = Buffer.from(templateId, 'hex');
        const buf = toBuffer(signature);

        await this.contract.update_beacon_with_signed_data(
            {
                args: {
                  airnode: [...pubKeyBuf],
                  template_id: [...bufferedTemplateId],
                  timestamp: [...bufferedTimestamp],
                  data: [...data],
                  signature: [...buf]
                }
            }
        );
    }

    async updateBeaconSetWithBeacons(beaconIds) {
        await this.contract.update_dapi_with_beacons(
            {
                args: {
                    beacon_ids: beaconIds
                }
            }
        );
    }

    async updateBeaconSetWithSignedData(airnodes, templateIds, timestamps, data, signatures) {
        await this.contract.update_dapi_with_signed_data(
            {
                args: {
                    airnodes: airnodes.map(r => [...r]),
                    template_ids: templateIds.map(t => [...t]),
                    timestamps: timestamps.map(r => [...bufferU64BE(r)]),
                    data,
                    signatures
                }
            }
        );
    }

    async setDapiName(name, datapointId) {
        await this.contract.set_name(
            {
                args: {
                    name: [...name],
                    datapoint_id: [...datapointId]
                }
            }
        );
    }

    async deriveBeaconId(airnode, templateId) {
        return await this.contract.derive_beacon_id(
            {
                airnode: [...airnode],
                template_id: [...templateId]
            }
        );
    }

    async deriveBeaconSetId(beaconIds) {
        return await this.contract.derive_beacon_set_id(
            {
                beacon_ids: beaconIds
            }
        );
    }

    async dapiNameToDataFeedId(name) {
        return await this.contract.name_to_data_point_id(
            {
                name: [...name]
            }
        );
    }

    async readerCanReadDataFeed(datapoint, reader) {
        return await this.contract.reader_can_read_data_point(
            {
                data_point_id: [...datapoint],
                reader
            }
        );
    }

    async whitelistExpirationSetterRole() {
        return await this.contract.whitelist_expiration_setter_role({});
    }

    async whitelistExpirationExtenderRole() {
        return await this.contract.whitelist_expiration_extender_role({});
    }

    async indefiniteWhitelisterRole() {
        return await this.contract.indefinite_whitelister_role({});
    }

    async setIndefiniteWhitelistStatus(serviceId, user, status) {
        return await this.contract.set_indefinite_whitelist_status(
            {
                args: {
                    service_id: [...serviceId],
                    user,
                    status
                }
            }
        );
    }

    async setWhitelistExpiration(serviceId, user, expirationTimestamp) {
        return await this.contract.set_whitelist_expiration(
            {
                args: {
                    service_id: [...serviceId],
                    user,
                    expiration_timestamp: expirationTimestamp
                }
            }
        );
    }

    async revokeIndefiniteWhitelistStatus(serviceId, user, setter) {
        return await this.contract.revoke_indefinite_whitelist_status(
            {
                args: {
                    service_id: [...serviceId],
                    user,
                    setter
                }
            }
        );
    }

    async extendWhitelistExpiration(serviceId, user, expirationTimestamp) {
        return await this.contract.extend_whitelist_expiration(
            {
                args: {
                    service_id: [...serviceId],
                    user,
                    expiration_timestamp: expirationTimestamp
                }
            }
        );
    }

    async dataFeedIdToReaderToWhitelistStatus(dataFeedId, reader) {
        return await this.contract.data_feed_id_to_whitelist_status(
            {
                data_feed_id: [...dataFeedId],
                reader
            }
        );
    }

    async dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(dataFeedId, reader, setter) {
        return await this.contract.data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status(
            {
                data_feed_id: [...dataFeedId],
                reader,
                setter
            }
        );
    }
}

module.exports = { DapiServer }
'''
'''--- near/client-test/src/config.js ---
const CONTRACT_NAME = process.env.CONTRACT_NAME || 'mochacha.testnet'; /* TODO: change this to your account */
console.log("contract name: ", CONTRACT_NAME);

function getConfig (env) {
  switch (env) {
    case 'production':
    case 'mainnet':
      return {
        networkId: 'mainnet',
        nodeUrl: 'https://rpc.mainnet.near.org',
        contractName: CONTRACT_NAME,
        walletUrl: 'https://wallet.near.org',
        helperUrl: 'https://helper.mainnet.near.org'
      }
    case 'development':
    case 'test':
    case 'testnet':
      return {
        networkId: 'testnet',
        nodeUrl: 'https://rpc.testnet.near.org',
        contractName: CONTRACT_NAME,
        walletUrl: 'https://wallet.testnet.near.org',
        helperUrl: 'https://helper.testnet.near.org',
        // masterAccount: CONTRACT_NAME
      }
    default:
      throw Error(`Unconfigured environment '${env}'. Can be configured in src/config.js.`)
  }
}

module.exports = getConfig

'''
'''--- near/client-test/src/util.js ---
const ethers = require("ethers");

function deriveBeaconId(airnodeKey, templateId) {
    return keccak256Packed(["bytes", "bytes32"], [airnodeKey, templateId]);
}

function encodeData(decodedData) {
    const hex = ethers.utils.defaultAbiCoder.encode(['int256'], [decodedData]);
    return Buffer.from(hex.substr(2), "hex");
}

const delay = ms => new Promise(resolve => setTimeout(resolve, ms))

function prepareMessage(
    templateId,
    timestamp,
    data,
) {
    const bufferedTemplate = toBuffer(Buffer.from(templateId, 'hex'));
    const bufferedTimestamp = bufferU64BE(timestamp);
    const encodedData = encodeData(data);
    return keccak256Packed(
        ["bytes32", "uint256", "bytes"],
        [bufferedTemplate, bufferedTimestamp, encodedData]
    )
}

function keccak256Packed(types, data) {
    let hex = ethers.utils.solidityPack(types, data).substr(2); // remove starting "0x"
    const buf = Buffer.from(hex, "hex");
    hex = ethers.utils.keccak256(buf).substr(2); // remove starting "0x"
    return Buffer.from(hex, "hex");
}

function currentTimestamp() {
    return Math.floor(Date.now() / 1000);
}

async function encodeAndSignData(decodedData, requestHash, timestamp, signer) {
    const data = encodeData(decodedData);
    const signature = await signer.sign(prepareMessage(requestHash, timestamp, data));
    return [data, signature.signature];
}

function bufferU64BE(value) {
    const buffer = Buffer.alloc(32);
    buffer.writeBigUInt64BE(BigInt(value), 24);
    return buffer;
}

function toBuffer(ab) {
    const buf = Buffer.alloc(ab.byteLength);
    const view = new Uint8Array(ab);
    for (let i = 0; i < buf.length; ++i) {
        buf[i] = view[i];
    }
    return buf;
}

function generateRandomBytes32() {
    while (true) {
        const r = ethers.utils.randomBytes(32);

        let zeroCount = 0;
        for (const i of r) {
            if (i === 0) { zeroCount++; }
        }

        if (zeroCount !== 32) { return r; }
    }
}

function deriveDApiId(beaconIds) {
    const types = beaconIds.map(_ => "bytes32");
    return keccak256Packed(types, beaconIds);
}

module.exports = {
    keccak256Packed, currentTimestamp, encodeData, prepareMessage,
    generateRandomBytes32, toBuffer, bufferU64BE, encodeAndSignData,
    deriveBeaconId, deriveDApiId, delay
};
'''
'''--- near/client-test/tests/test.spec.js ---
const { DapiServer } = require("../src/client");
const { 
  updateBeacon, dataNotFresherThanBeacon, dataLengthNotCorrect,
  timestampNotValid, signatureNotValid
} = require("./utils/updateBeaconWithSignedData");
const { 
  updatesBeaconSet, lessThanTwoBeacons

} = require("./utils/updateBeaconSetWithBeacons");
const { 
  senderNotNameSetter, setsDAPIName, dAPINameZero
} = require("./utils/setName");
const {
  derivesBeaconId, templateIdZero, airnodeZero, derivesBeaconSetId,
} = require("./utils/derive");
const { generateRandomBytes32, toBuffer, currentTimestamp, deriveBeaconId, deriveDApiId, delay, encodeAndSignData, encodeData } = require("../src/util");
const fs = require("fs");
const ethers = require("ethers");
const nearAPI = require("near-api-js");
const { keyStores } = require("near-api-js");
const path = require("path");
const { updatesBeaconSetWithSignedData, updatedSetValueOutdated, lengthNotCorrect, notAllSignaturesValid, parameterLengthMismatch } = require("./utils/updateBeaconSetWithSignedData");
const { readerZeroAddress, readerNotWhitelisted, readerWhitelisted, readerUnlimitedReaderRole } = require("./utils/readerCanReadDataFeed");
const { dataFeedIdToReaderToWhitelistStatus, dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus } = require("./utils/whitelist");
const { revokeRole, renounceRole } = require("./utils/role");
const { WithExtenderRole } = require("./utils/extendWhitelistExpiration");
const { WithSetterRole } = require("./utils/setWhitelistExpiration");
const { WithIndefiniteWhitelisterSetterRole } = require("./utils/setIndefiniteWhitelistStatus");
const { revokesIndefiniteWhitelistStatus, setterHasIndefiniteWhitelisterRole } = require("./utils/revokeIndefiniteWhitelistStatus");
const { readerNotPermitted, readerUnlimitedReaderReads, readerWhitelistedReads } = require("./utils/readDataFeedWithId");
const { readerWhitelistedReadsByName, unlimitedReaderReadsWithName, readerNotPermittedWithName } = require("./utils/readDataFeedWithDapiName");
const homedir = require("os").homedir();
const CREDENTIALS_DIR = ".near-credentials";
const credentialsPath = path.join(homedir, CREDENTIALS_DIR);
const keyStore = new keyStores.UnencryptedFileSystemKeyStore(credentialsPath);

const contractAccount = process.env.CONTRACT_ACCOUNT;
const adminAccount = process.env.ADMIN_ACCOUNT;
const userAccount = process.env.USER_ACCOUNT;

const config = {
  keyStore,
  networkId: "testnet",
  nodeUrl: "https://rpc.testnet.near.org",
};

// Network can get unpredictable, set timeout to a large value just in case
jest.setTimeout(120_000);

describe('Token', function () {
  let contract;
  let userContract;
  let near;

  const templateId = generateRandomBytes32();
  const beaconSetTemplateIds = [
    generateRandomBytes32(),
    generateRandomBytes32(),
    generateRandomBytes32(),
  ];

  let beaconSetId;

  // This is the actual dapi client
  let client;
  // This is just a test util contract with propoer reading access, for data checking purposes
  let userClient;

  let keyPair;
  beforeAll(async function () {
    near = await nearAPI.connect(config);
    const admin = await near.account(adminAccount);
    contract = new nearAPI.Contract(admin, contractAccount, {
      viewMethods: [
        'has_role',
        'roles',
        'name_to_data_point_id',
        'derive_beacon_id',
        'derive_beacon_set_id',
        'reader_can_read_data_point',
        'data_feed_id_to_whitelist_status',
        'data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status',
        'whitelist_expiration_setter_role',
        'whitelist_expiration_extender_role',
        'indefinite_whitelister_role',
        'read_with_data_point_id',
        'read_with_name',
      ],
      changeMethods: [
        'initialize',
        'grant_role',
        'renounce_role',
        'revoke_role',
        'update_beacon_with_signed_data',
        'update_dapi_with_beacons',
        'update_dapi_with_signed_data',
        'get_data_point',
        'set_name',
        'set_indefinite_whitelist_status',
        'set_whitelist_expiration',
        'extend_whitelist_expiration',
        'revoke_indefinite_whitelist_status',
      ],
    });
    client = new DapiServer(contract);
    const user = await near.account(userAccount);
    userContract = new nearAPI.Contract(user, contractAccount, {
      viewMethods: [
        'roles',
        'name_to_data_point_id',
        'derive_beacon_id',
        'derive_beacon_set_id',
        'reader_can_read_data_point',
        'data_feed_id_to_whitelist_status',
        'data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status',
        'whitelist_expiration_setter_role',
        'whitelist_expiration_extender_role',
        'indefinite_whitelister_role'
      ],
      changeMethods: [
        'get_data_point',
        'read_with_data_point_id',
        'read_with_name',
        'set_indefinite_whitelist_status',
        'set_whitelist_expiration',
        'extend_whitelist_expiration',
        'revoke_indefinite_whitelist_status'
      ],
    });
    userClient = new DapiServer(userContract);

    const key = `${admin.connection.signer.keyStore.keyDir}/testnet/${admin.accountId}.json`;
    const data = JSON.parse(fs.readFileSync(key));
    keyPair = nearAPI.KeyPair.fromString(data.private_key);

    beaconSetId = deriveDApiId(beaconSetTemplateIds.map(r => deriveBeaconId(keyPair.getPublicKey().data, r)));

    const reader = userAccount;
    const unlimitedReaderRole = (await contract.roles())[0];
    await client.grantRole([...unlimitedReaderRole], reader);
  });

  describe('updateBeaconWithSignedData', function () {
    let roles;

    beforeAll(async () => {
      roles = await contract.roles();
      await client.grantRole(
        roles[0],
        userAccount
      );
    });

    afterAll(async () => {
      await client.revokeRole(
        roles[0],
        userAccount
      );
    })

    it('updateBeacon', async function () {
      const timestamp = currentTimestamp() + 1;
      await updateBeacon(client, keyPair, keyPair.getPublicKey().data, templateId, 123, timestamp, userClient);
    });

    it('dataNotFresherThanBeacon', async function () {
      await dataNotFresherThanBeacon(client, keyPair, keyPair.getPublicKey().data, templateId);
    });

    it('dataLengthNotCorrect', async function () {
      await dataLengthNotCorrect(client, keyPair, keyPair.getPublicKey().data, templateId);
    });

    it('timestampNotValid', async function () {
      await timestampNotValid(client, keyPair, keyPair.getPublicKey().data);
    });

    it('signatureNotValid', async function () {
      await signatureNotValid(client, keyPair, keyPair.getPublicKey().data, templateId);
    });
  });

  describe('updateBeaconSetWithBeacons', function () {
    let roles;

    beforeAll(async () => {
      roles = await contract.roles();
      await client.grantRole(
        roles[0],
        userAccount
      );
    });

    afterAll(async () => {
      await client.revokeRole(
        roles[0],
        userAccount
      );
    })

    it('updatesBeaconSet', async function () {
      const beaconIds = [];
      const beaconData = [123, 456, 789];
      let expectedTimestamp = 0;
      for (let ind = 0; ind < beaconData.length; ind++) {
        const timestamp = currentTimestamp() + 1;
        await updateBeacon(
          client,
          keyPair,
          keyPair.getPublicKey().data,
          beaconSetTemplateIds[ind],
          beaconData[ind],
          timestamp,
          userClient
        );
        beaconIds.push([...deriveBeaconId(keyPair.getPublicKey().data, beaconSetTemplateIds[ind])]);
        expectedTimestamp += timestamp;
      }
      await updatesBeaconSet(client, beaconIds, 456, Math.floor(expectedTimestamp / beaconData.length), userClient);
    });

    it('lessThanTwoBeacons', async function () {
      await lessThanTwoBeacons(client);
    });
  });

  describe('updateBeaconSetWithSignedData', function () {
    let roles;

    beforeAll(async () => {
      roles = await contract.roles();
      await client.grantRole(
        roles[0],
        userAccount
      );
    });

    afterAll(async () => {
      await client.revokeRole(
        roles[0],
        userAccount
      );
    });

    it('updatesBeaconSetWithSignedData', async function () {
      await updatesBeaconSetWithSignedData(client, keyPair, keyPair.getPublicKey().data, beaconSetTemplateIds, userClient);
    });

    it('updatedSetValueOutdated', async function () {
      await updatedSetValueOutdated(client, keyPair, keyPair.getPublicKey().data, beaconSetTemplateIds);
    });

    it.skip('dataValueExceedingRange', async function () {
      // TODO: we are using U256 internally, not sure if this is still needed  
    });

    it('lengthNotCorrect', async function () {
      await lengthNotCorrect(client, keyPair, keyPair.getPublicKey().data, beaconSetTemplateIds);
    });

    it('notAllSignaturesValid', async function () {
      await notAllSignaturesValid(client, keyPair, keyPair.getPublicKey().data, beaconSetTemplateIds);
    });

    it('lessThanTwoBeacons', async function () {
      await lessThanTwoBeacons(client);
    });

    it('parameterLengthMismatch', async function () {
      await parameterLengthMismatch(client, keyPair.getPublicKey().data, beaconSetTemplateIds);
    });
  });
  
  describe('setName', function () {
    it('setsDAPIName', async function () {
      const roles = await contract.roles();
      await client.grantRole(
        roles[1],
        adminAccount
      );
      const dapiName = Buffer.from(ethers.utils.formatBytes32String('My dAPI').substring(2), "hex");
      await setsDAPIName(client, dapiName, beaconSetId);
    });

    it('senderNotNameSetter', async function () {
      const roles = await contract.roles();
      await client.revokeRole(
        roles[1],
        adminAccount
      );
      const dapiName = Buffer.from(ethers.utils.formatBytes32String('My dAPI').substring(2), "hex");
      await senderNotNameSetter(client, dapiName, beaconSetId);
    });

    it('dAPINameZero', async function () {
      await dAPINameZero(client);
    });
  });

  describe('deriveBeaconId', function () {
    it('derivesBeaconId', async function () {
      await derivesBeaconId(client, keyPair.getPublicKey().data, templateId);
    });

    it('templateIdZero', async function () {
      await templateIdZero(client, keyPair.getPublicKey().data);
    });

    it('airnodeZero', async function () {
      await airnodeZero(client, templateId);
    });
  });

  describe('deriveBeaconSetId', function () {
    it('derivesBeaconSetId', async function () {
      await derivesBeaconSetId(client, [[...generateRandomBytes32()], [...generateRandomBytes32()]]);
    });
  });

  describe('readerCanReadDataFeed', function () {
    it('readerZeroAddress', async function () {
      await readerZeroAddress(client);
    });

    it('readerNotWhitelisted', async function () {
      await readerNotWhitelisted(client, adminAccount);
    });

    it('readerWhitelisted', async function () {
      await readerWhitelisted(client, generateRandomBytes32(), adminAccount);
    });

    it('readerUnlimitedReaderRole', async function () {
      const roles = await contract.roles();
      await readerUnlimitedReaderRole(client, adminAccount, roles[0]);
    });
  });

  describe('role', function () {
    it('revokeRole', async function () {
      await revokeRole(client, [...generateRandomBytes32()]);
    });

    it('renounceRole', async function () {
      await renounceRole(client, [...generateRandomBytes32()], adminAccount);
    });
  });

  describe('whitelist', function () {
    it('dataFeedIdToReaderToWhitelistStatus', async function () {
      await dataFeedIdToReaderToWhitelistStatus(client);
    });

    it('dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus', async function () {
      await dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(client, adminAccount);
    });
  });

  describe('extendWhitelistExpiration', function () {
    describe('Sender has whitelist expiration extender role', function () {
      beforeAll(async function () {
        await WithExtenderRole.setup(client, userAccount, userClient);
      });

      it('cannotExtendWhitelistExpiration', async function () {
        await WithExtenderRole.cannotExtendWhitelistExpiration(client, userAccount, userClient);
      });

      it('extendsWhitelistExpiration', async function () {
        await WithExtenderRole.extendsWhitelistExpiration(userClient);
      });

      it('doesNotExtendExpiration', async function () {
        await WithExtenderRole.doesNotExtendExpiration(userClient);
      });

      it('readerZeroAddress', async function () {
        await WithExtenderRole.readerZeroAddress(userClient);
      });

      it('dataFeedIdZero', async function () {
        await WithExtenderRole.dataFeedIdZero(userClient);
      });

      afterAll(async function () {
        await WithExtenderRole.tearDown(client, userAccount);
      });
    });

    describe('Sender is the manager', function () {
      it('extendsWhitelistExpiration', async function () {
        await WithExtenderRole.extendsWhitelistExpiration(client);
      });

      it('doesNotExtendExpiration', async function () {
        await WithExtenderRole.doesNotExtendExpiration(client);
      });

      it('readerZeroAddress', async function () {
        await WithExtenderRole.readerZeroAddress(client);
      });

      it('dataFeedIdZero', async function () {
        await WithExtenderRole.dataFeedIdZero(client);
      });
    });
  });

  describe('setWhitelistExpiration', function () {
    describe('Sender has whitelist expiration setter role', function () {
      beforeAll(async function () {
        await WithSetterRole.setup(client, userAccount, userClient);
      });

      it('setsWhitelistExpiration', async function () {
        await WithSetterRole.setsWhitelistExpiration(userClient);
      });

      it('readerZeroAddress', async function () {
        await WithSetterRole.readerZeroAddress(userClient);
      });

      it('dataFeedIdZero', async function () {
        await WithSetterRole.dataFeedIdZero(userClient);
      });

      afterAll(async function () {
        await WithSetterRole.tearDown(client, userAccount);
      });
    });

    describe('Sender is the manager', function () {
      it('setsWhitelistExpiration', async function () {
        await WithSetterRole.setsWhitelistExpiration(client);
      });

      it('readerZeroAddress', async function () {
        await WithSetterRole.readerZeroAddress(client);
      });

      it('dataFeedIdZero', async function () {
        await WithSetterRole.dataFeedIdZero(client);
      });
    });
  });

  describe('setIndefiniteWhitelistStatus', function () {
    describe('Sender has whitelist expiration setter role', function () {
      beforeAll(async function () {
        await WithIndefiniteWhitelisterSetterRole.setup(client, userAccount, userClient);
      });

      it('setIndefiniteWhitelistStatus', async function () {
        await WithIndefiniteWhitelisterSetterRole.setIndefiniteWhitelistStatus(
          userClient,
          userAccount
        );
      });

      it('readerZeroAddress', async function () {
        await WithIndefiniteWhitelisterSetterRole.readerZeroAddress(userClient);
      });

      it('dataFeedIdZero', async function () {
        await WithIndefiniteWhitelisterSetterRole.dataFeedIdZero(userClient);
      });

      afterAll(async function () {
        await WithIndefiniteWhitelisterSetterRole.tearDown(client, userAccount);
      });
    });

    describe('Sender is the manager', function () {
      it('setIndefiniteWhitelistStatus', async function () {
        await WithIndefiniteWhitelisterSetterRole.setIndefiniteWhitelistStatus(
          client, adminAccount
        );
      });

      it('readerZeroAddress', async function () {
        await WithIndefiniteWhitelisterSetterRole.readerZeroAddress(client);
      });

      it('dataFeedIdZero', async function () {
        await WithIndefiniteWhitelisterSetterRole.dataFeedIdZero(client);
      });
    });
  });

  describe('revokeIndefiniteWhitelistStatus', function () {
    it('setIndefiniteWhitelistStatus', async function () {
      await revokesIndefiniteWhitelistStatus(
        client,
        userClient,
        userAccount,
        client
      );
    });

    it('setterHasIndefiniteWhitelisterRole', async function () {
      await setterHasIndefiniteWhitelisterRole(
        client,
        userClient,
        userAccount,
      );
    });
  });

  describe('readDataFeedWithId', function () {
    let role;

    beforeAll(async () => {
      role = (await contract.roles())[0];
    });

    it('readerNotPermitted', async function () {
      await readerNotPermitted(
        client,
        userClient,
        role,
        userAccount,
      );
    });

    it('readerUnlimitedReaderReads', async function () {
      await readerUnlimitedReaderReads(
        client,
        userAccount,
        role,
        userClient,
      );
    });

    it('readerWhitelistedReads', async function () {
      await readerWhitelistedReads(
        client,
        userAccount,
        userClient,
      );
    });
  });

  describe('readDataFeedWithName', function () {
    let name;
    let expected;
    let roles;

    beforeAll(async () => {
      const value = 456;
      const template = generateRandomBytes32();
      const timestamp = currentTimestamp();
      const airnodeAddress = keyPair.getPublicKey().data;
      const [data, signature] = await encodeAndSignData(value, template, timestamp, keyPair);
      await client.updateBeaconWithSignedData(airnodeAddress, template, timestamp, data, signature);

      const beaconId = deriveBeaconId(
        toBuffer(airnodeAddress),
        template
      );

      expected = {
        value: [...encodeData(value)],
        timestamp 
      };

      roles = await contract.roles();
      await client.grantRole(
        roles[1],
        adminAccount
      );
      name = Buffer.from(ethers.utils.formatBytes32String('My dAPI 2').substring(2), "hex");
      await setsDAPIName(client, name, beaconId);
    });

    it('readerWhitelistedReadsByName', async function () {
      await readerWhitelistedReadsByName(
        client,
        name,
        userAccount,
        userClient,
        expected
      );
    });

    it('unlimitedReaderReadsWithName', async function () {
      await unlimitedReaderReadsWithName(
        client,
        name,
        userAccount,
        roles[0],
        userClient,
        expected
      );
    });

    it('readerNotPermittedWithName', async function () {
      await readerNotPermittedWithName(
        client,
        name,
        userClient,
        roles[0],
        userAccount,
      );
    });

    afterAll(async () => {
      await client.revokeRole(
        roles[1],
        adminAccount
      );
    });
  });
});

'''
'''--- near/client-test/tests/utils/derive.js ---
const {deriveBeaconId, deriveDApiId } = require("../../src/util");

async function derivesBeaconId(client, airnode, templateId) {
  const beaconId = await client.deriveBeaconId(airnode, templateId);
  const expected = deriveBeaconId(airnode, templateId);
  expect(beaconId).toEqual([...expected])
}

async function templateIdZero(client, airnode) {
  await expect(client.deriveBeaconId(airnode, [...Buffer.alloc(32, 0)])).rejects.toThrow("TemplateIdZero");
}

async function airnodeZero(client, templateId) {
  await expect(client.deriveBeaconId([...Buffer.alloc(32, 0)], templateId)).rejects.toThrow("AirnodeIdZero");
}

async function derivesBeaconSetId(client, beaconIds) {
  const id = await client.deriveBeaconSetId(beaconIds);
  const expected = deriveDApiId(beaconIds);
  expect(id).toEqual([...expected])
}

module.exports = { 
  derivesBeaconId, templateIdZero, airnodeZero, derivesBeaconSetId
};
'''
'''--- near/client-test/tests/utils/extendWhitelistExpiration.js ---
const { execPath } = require("process");
const { generateRandomBytes32, currentTimestamp, delay } = require("../../src/util");

class WithExtenderRole {
    static async setup(client, userAccount) {
        const whitelistExpirationExtenderRole = await client.whitelistExpirationExtenderRole();
        const hasRole = await client.hasRole(whitelistExpirationExtenderRole, userAccount);
        if (!hasRole) {
            await client.grantRole(whitelistExpirationExtenderRole, userAccount);
        }
    }

    static async tearDown(client, userAccount) {
        const whitelistExpirationExtenderRole = await client.whitelistExpirationExtenderRole();
        await client.revokeRole(whitelistExpirationExtenderRole, userAccount);
    }

    static async cannotExtendWhitelistExpiration(client, userAccount, userClient) {
        const whitelistExpirationExtenderRole = await client.whitelistExpirationExtenderRole();
        const hasRole = await client.hasRole(whitelistExpirationExtenderRole, userAccount);

        await client.revokeRole(whitelistExpirationExtenderRole, userAccount);
        await delay(1000);

        const timestamp = currentTimestamp();
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await expect(userClient.extendWhitelistExpiration(beaconId, reader, timestamp)).rejects.toThrow("AccessDenied")

        // recover to its starting condition
        if (hasRole) {
            await client.grantRole(whitelistExpirationExtenderRole, userAccount);
        }
    }

    static async extendsWhitelistExpiration(client) {
        const timestamp = currentTimestamp();
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await client.extendWhitelistExpiration(beaconId, reader, timestamp);
        const r = await client.dataFeedIdToReaderToWhitelistStatus(
            beaconId,
            reader
        );
        const expected = Buffer.alloc(32, 0);
        expect(r[0]).toEqual(timestamp);
        expect(r[1]).toEqual([...expected]);
    }

    static async doesNotExtendExpiration(client) {
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];

        await expect(client.extendWhitelistExpiration(beaconId, reader, 0)).rejects.toThrow("DoesNotExtendExpiration")
    }

    static async readerZeroAddress(client) {
        const timestamp = currentTimestamp();
        const beaconId = [...generateRandomBytes32()];
        await expect(client.extendWhitelistExpiration(beaconId, "", timestamp)).rejects.toThrow("UserAddressZero")
    }

    static async dataFeedIdZero(client) {
        const timestamp = currentTimestamp();
        await expect(client.extendWhitelistExpiration([...Buffer.alloc(32, 0)], generateRandomBytes32().toString(), timestamp)).rejects.toThrow("ServiceIdZero")
    }
}

module.exports = {
    WithExtenderRole
};
'''
'''--- near/client-test/tests/utils/readDataFeedWithDapiName.js ---
const { keccak256Packed } = require("../../src/util");

async function readerWhitelistedReadsByName(client, name, reader, userClient, expected) {
    const datapoint = keccak256Packed(['bytes32'], [name]);
    await client.setIndefiniteWhitelistStatus(datapoint, reader, true);

    const r = await userClient.readDataFeedWithDapiName([...name]);
    expect(r.value).toEqual(expected.value);
    expect(r.timestamp).toEqual(expected.timestamp);

    await client.setIndefiniteWhitelistStatus(datapoint, reader, true);
}

async function unlimitedReaderReadsWithName(client, name, reader, role, userClient, expected) {
    await client.grantRole(role, reader);

    const r = await userClient.readDataFeedWithDapiName([...name]);
    expect(r.value).toEqual(expected.value);
    expect(r.timestamp).toEqual(expected.timestamp);

    await client.revokeRole(role, reader);
}

async function readerNotPermittedWithName(client, name, userClient, role, userAccount) {
    await client.revokeRole(role, userAccount);
    const datapoint = keccak256Packed(['bytes32'], [name]);
    await client.setIndefiniteWhitelistStatus(datapoint, userAccount, false);
    await expect(userClient.readDataFeedWithDapiName([...datapoint])).rejects.toThrow("AccessDenied")
}

module.exports = { 
  readerWhitelistedReadsByName, readerNotPermittedWithName, unlimitedReaderReadsWithName
};
'''
'''--- near/client-test/tests/utils/readDataFeedWithId.js ---
const { generateRandomBytes32, delay } = require("../../src/util");

async function readerWhitelistedReads(client, reader, userClient) {
    const datapoint = generateRandomBytes32();

    await client.setIndefiniteWhitelistStatus(datapoint, reader, true);
    await delay(1000);

    // we are testing the access here, dont care about the return results
    // other tests should have this covered already
    await userClient.readDataFeedWithId([...datapoint]);

    await client.setIndefiniteWhitelistStatus(datapoint, reader, true);
}

async function readerUnlimitedReaderReads(client, reader, role, userClient) {
    await client.grantRole(role, reader);
    await delay(1000);

    const datapoint = generateRandomBytes32();

    // we are testing the access here, dont care about the return results
    // other tests should have this covered already
    await userClient.readDataFeedWithId([...datapoint]);

    await client.revokeRole(role, reader);
}

async function readerNotPermitted(client, userClient, role, userAccount) {
    await client.revokeRole(role, userAccount);
    const datapoint = generateRandomBytes32();
    await client.setIndefiniteWhitelistStatus(datapoint, userAccount, false);
    await delay(1000);

    await expect(userClient.readDataFeedWithId([...datapoint])).rejects.toThrow("AccessDenied")
}

module.exports = { 
    readerWhitelistedReads, readerNotPermitted, readerUnlimitedReaderReads
};
'''
'''--- near/client-test/tests/utils/readerCanReadDataFeed.js ---
const { generateRandomBytes32 } = require("../../src/util");

async function readerZeroAddress(client) {
  const r = await client.readerCanReadDataFeed([...Buffer.alloc(32, 0)], "");;
  expect(r).toBe(true);
}

async function readerWhitelisted(client, datapoint, reader) {
  await client.setIndefiniteWhitelistStatus(datapoint, reader, false);
  let canRead = await client.readerCanReadDataFeed([...datapoint], reader);
  expect(canRead).toBe(false);

  await client.setIndefiniteWhitelistStatus(datapoint, reader, true);
  canRead = await client.readerCanReadDataFeed([...datapoint], reader);
  expect(canRead).toBe(true)
}

async function readerUnlimitedReaderRole(client, reader, role) {
    await client.grantRole(role, reader);
    const datapoint = generateRandomBytes32();

    let canRead = await client.readerCanReadDataFeed([...datapoint], reader);
    expect(canRead).toBe(true)

    await client.revokeRole(role, reader);
    canRead = await client.readerCanReadDataFeed([...datapoint], reader);
    expect(canRead).toBe(false)
}

async function readerNotWhitelisted(client, reader) {
  const r = await client.readerCanReadDataFeed([...generateRandomBytes32()], reader);
  expect(r).toBe(false)
}

module.exports = { 
    readerZeroAddress, readerWhitelisted, readerNotWhitelisted, readerUnlimitedReaderRole
};
'''
'''--- near/client-test/tests/utils/revokeIndefiniteWhitelistStatus.js ---
const { ensure, generateRandomBytes32, delay } = require("../../src/util");

async function revokesIndefiniteWhitelistStatus(client, listerClient, listerAccount, randomClient) {
    const reader = generateRandomBytes32().toString();
    const beaconId = [...generateRandomBytes32()];

    const indefiniteWhitelisterRole = await client.indefiniteWhitelisterRole();
    
    await client.grantRole(indefiniteWhitelisterRole, listerAccount);
    await delay(1000);

    await listerClient.setIndefiniteWhitelistStatus(beaconId, reader, true);
    await client.revokeRole(indefiniteWhitelisterRole, listerAccount);
    await delay(1000);

    await randomClient.revokeIndefiniteWhitelistStatus(
        beaconId,
        reader,
        listerAccount
    );

    const r = await client.dataFeedIdToReaderToWhitelistStatus(
        beaconId,
        reader
    );
    expect(r[0]).toEqual(0)
    expect(r[1]).toEqual([...Buffer.alloc(32, 0)])

    const s = await client.dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(
        beaconId,
        reader,
        listerAccount
    );
    expect(s).toBe(false)

    await randomClient.revokeIndefiniteWhitelistStatus(
        beaconId,
        reader,
        listerAccount
    );
}

async function setterHasIndefiniteWhitelisterRole(client, listerClient, listerAccount) {
    const reader = generateRandomBytes32().toString();
    const beaconId = [...generateRandomBytes32()];

    const indefiniteWhitelisterRole = await client.indefiniteWhitelisterRole();
    
    await client.grantRole(indefiniteWhitelisterRole, listerAccount);
    await delay(1000);
    
    await expect(listerClient.revokeIndefiniteWhitelistStatus(
        beaconId,
        reader,
        listerAccount
    )).rejects.toThrow("SetterCanSetIndefiniteStatus")
}

module.exports = {
    revokesIndefiniteWhitelistStatus, setterHasIndefiniteWhitelisterRole
};
'''
'''--- near/client-test/tests/utils/role.js ---
const { generateRandomBytes32, delay } = require("../../src/util");

async function revokeRole(client, role) {
    const who = generateRandomBytes32().toString();
    await expect(client.hasRole(role, who)).resolves.toEqual(false);
    await client.grantRole(role, who);
    await delay(1000);
    await expect(client.hasRole(role, who)).resolves.toEqual(true);
    await client.revokeRole(role, who);
    await delay(1000);
    await expect(client.hasRole(role, who)).resolves.toEqual(false);
}

async function renounceRole(client, role, who) {
    await expect(client.hasRole(role, who)).resolves.toEqual(false);
    await client.grantRole(role, who);
    await delay(1000);
    await expect(client.hasRole(role, who)).resolves.toEqual(true);
    await client.renounceRole(role, who);
    await delay(1000);
    await expect(client.hasRole(role, who)).resolves.toEqual(false);
}

module.exports = {
    revokeRole, renounceRole
}

'''
'''--- near/client-test/tests/utils/setIndefiniteWhitelistStatus.js ---
const { generateRandomBytes32, delay } = require("../../src/util");

class WithIndefiniteWhitelisterSetterRole {
    static async setup(client, userAccount, userClient) {
        const indefiniteWhitelisterRole = await client.indefiniteWhitelisterRole();
        await client.revokeRole(indefiniteWhitelisterRole, userAccount);
        await delay(5000);
        await WithIndefiniteWhitelisterSetterRole.cannotSetIndefiniteWhitelistStatus(userClient);
        await client.grantRole(indefiniteWhitelisterRole, userAccount);
        await delay(3000);
    }

    static async tearDown(client, userAccount) {
        const indefiniteWhitelisterRole = await client.indefiniteWhitelisterRole();
        await client.revokeRole(indefiniteWhitelisterRole, userAccount);
        await delay(3000);
    }

    static async setIndefiniteWhitelistStatus(client, listerAccount) {
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await client.setIndefiniteWhitelistStatus(beaconId, reader, true);
        const r = await client.dataFeedIdToReaderToWhitelistStatus(
            beaconId,
            reader
        );
        const expected = Buffer.alloc(32, 0);
        expected.writeUint8(1, 31);

        expect(r[0]).toEqual(0)
        expect(r[1]).toEqual([...expected])

        const s = await client.dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(
            beaconId,
            reader,
            listerAccount
        );
        expect(s).toBe(true)
    }

    static async cannotSetIndefiniteWhitelistStatus(client) {
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await expect(client.setIndefiniteWhitelistStatus(beaconId, reader, true)).rejects.toThrow("AccessDenied")
    }

    static async readerZeroAddress(client) {
        const beaconId = [...generateRandomBytes32()];
        await expect(client.setIndefiniteWhitelistStatus(beaconId, "", true)).rejects.toThrow("UserAddressZero")
    }

    static async dataFeedIdZero(client) {
        await expect(client.setIndefiniteWhitelistStatus([...Buffer.alloc(32, 0)], generateRandomBytes32().toString(), true)).rejects.toThrow("ServiceIdZero")
    }
}

module.exports = {
    WithIndefiniteWhitelisterSetterRole
};
'''
'''--- near/client-test/tests/utils/setName.js ---
async function dAPINameZero(client) {
  await expect(client.setDapiName(Buffer.alloc(32, 0), Buffer.alloc(32, 0))).rejects.toThrow("InvalidData")
}

async function setsDAPIName(client, name, datapointId) {
  await client.setDapiName(name, datapointId);
  const id = await client.dapiNameToDataFeedId(name);
  expect([...id]).toEqual([...datapointId])
}

async function senderNotNameSetter(client, name, beaconId) {
  await expect(client.setDapiName(name, beaconId)).rejects.toThrow("AccessDenied")
}

module.exports = { 
  senderNotNameSetter, setsDAPIName, dAPINameZero
};
'''
'''--- near/client-test/tests/utils/setWhitelistExpiration.js ---
const { generateRandomBytes32, currentTimestamp } = require("../../src/util");

class WithSetterRole {
    static async setup(client, userAccount, userClient) {
        const whitelistExpirationSetterRole = await client.whitelistExpirationSetterRole();
        await expect(client.hasRole(whitelistExpirationSetterRole, userAccount)).resolves.toBe(false);
        await WithSetterRole.cannotSetWhitelistExpiration(userClient);
        await client.grantRole(whitelistExpirationSetterRole, userAccount);
    }

    static async tearDown(client, userAccount) {
        const whitelistExpirationSetterRole = await client.whitelistExpirationSetterRole();
        await client.revokeRole(whitelistExpirationSetterRole, userAccount);
    }

    static async setsWhitelistExpiration(client) {
        const timestamp = currentTimestamp();
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await client.setWhitelistExpiration(beaconId, reader, timestamp);
        const r = await client.dataFeedIdToReaderToWhitelistStatus(
            beaconId,
            reader
        );
        const expected = Buffer.alloc(32, 0);
        expect(r[0]).toEqual(timestamp)
        expect(r[1]).toEqual([...expected])
    }

    static async cannotSetWhitelistExpiration(client) {
        const timestamp = currentTimestamp();
        const reader = generateRandomBytes32().toString();
        const beaconId = [...generateRandomBytes32()];
        await expect(client.setWhitelistExpiration(beaconId, reader, timestamp)).rejects.toThrow("AccessDenied")
    }

    static async readerZeroAddress(client) {
        const timestamp = currentTimestamp();
        const beaconId = [...generateRandomBytes32()];
        await expect(client.setWhitelistExpiration(beaconId, "", timestamp)).rejects.toThrow("UserAddressZero")
    }

    static async dataFeedIdZero(client) {
        const timestamp = currentTimestamp();
        await expect(client.setWhitelistExpiration([...Buffer.alloc(32, 0)], generateRandomBytes32().toString(), timestamp)).rejects.toThrow("ServiceIdZero")
    }
}

module.exports = {
    WithSetterRole
};
'''
'''--- near/client-test/tests/utils/updateBeaconSetWithBeacons.js ---
const { deriveDApiId, encodeData } = require("../../src/util");

async function updatesBeaconSet(client, beaconIds, expectedValue, expectedTimestamp, readerClient) {
    await client.updateBeaconSetWithBeacons(beaconIds);
    const expectedId = deriveDApiId(beaconIds);

    const beacon = await readerClient.readDataFeedWithId(expectedId);
    expect(beacon.timestamp).toEqual(expectedTimestamp)
    expect(beacon.value).toEqual([...encodeData(expectedValue)])
}

async function lessThanTwoBeacons(client) {
  await expect(client.updateBeaconSetWithBeacons([])).rejects.toThrow("LessThanTwoBeacons")
}

module.exports = { 
  updatesBeaconSet, lessThanTwoBeacons
};
'''
'''--- near/client-test/tests/utils/updateBeaconSetWithSignedData.js ---
const { 
  toBuffer, currentTimestamp, bufferU64BE, deriveBeaconId,
  encodeAndSignData, delay, encodeData, keccak256Packed, deriveDApiId
} = require("../../src/util");

async function updatesBeaconSetWithSignedData(client, signer, airnodeAddress, beaconSetTemplateIds, readerClient) {
    let timestamp = currentTimestamp();
    timestamp++;
    
    const beaconIds = [];

    const [d1, d2, d3] = [100, 101, 102];
    const [data, signature] = await encodeAndSignData(d1, beaconSetTemplateIds[0], timestamp, signer);
    beaconIds.push([...deriveBeaconId(airnodeAddress, beaconSetTemplateIds[0])]);
    await client.updateBeaconWithSignedData(airnodeAddress, beaconSetTemplateIds[0], timestamp, data, signature);
    await delay(1000);

    // Sign data for the next two beacons
    beaconIds.push([...deriveBeaconId(airnodeAddress, beaconSetTemplateIds[1])]);
    const [data1, signature1] = await encodeAndSignData(d2, beaconSetTemplateIds[1], timestamp, signer);
    beaconIds.push([...deriveBeaconId(airnodeAddress, beaconSetTemplateIds[2])]);
    const [data2, signature2] = await encodeAndSignData(d3, beaconSetTemplateIds[2], timestamp, signer);

    await client.updateBeaconSetWithSignedData(
      [airnodeAddress, airnodeAddress, airnodeAddress],
      beaconSetTemplateIds,
      [0, timestamp, timestamp],
      [[], [...data1], [...data2]],
      [[], [...signature1], [...signature2]]
    );

    const beacon = await readerClient.readDataFeedWithId([...deriveDApiId(beaconIds)]);
    expect(beacon.value).toEqual([...encodeData(d2)])
    expect(beacon.timestamp).toEqual(timestamp)
}

async function updatedSetValueOutdated(client, signer, airnodeAddress, beaconSetTemplateIds) {
    let timestamp = currentTimestamp();
    timestamp++;
    
    const [data, signature] = await encodeAndSignData(100, beaconSetTemplateIds[0], timestamp, signer);
    await client.updateBeaconWithSignedData(airnodeAddress, beaconSetTemplateIds[0], timestamp, data, signature);
    await delay(1000);

    // Sign data for the next two beacons
    let [data1, signature1] = await encodeAndSignData(105, beaconSetTemplateIds[1], timestamp, signer);
    let [data2, signature2] = await encodeAndSignData(110, beaconSetTemplateIds[2], timestamp, signer);

    await client.updateBeaconSetWithSignedData(
      [airnodeAddress, airnodeAddress, airnodeAddress],
      beaconSetTemplateIds,
      [0, timestamp, timestamp],
      [[], [...data1], [...data2]],
      [[], [...signature1], [...signature2]]
    );
    await delay(1000);

    [data1, signature1] = await encodeAndSignData(105, beaconSetTemplateIds[1], timestamp-5, signer);
    [data2, signature2] = await encodeAndSignData(110, beaconSetTemplateIds[2], timestamp-5, signer);
    await expect(client.updateBeaconSetWithSignedData(
      [airnodeAddress, airnodeAddress, airnodeAddress],
      beaconSetTemplateIds,
      [0, timestamp-5, timestamp-5],
      [[], [...data1], [...data2]],
      [[], [...signature1], [...signature2]]
    )).rejects.toThrow("UpdatedValueOutdated")
}

async function lengthNotCorrect(client, signer, airnodeAddress, beaconSetTemplateIds) {
  const timestamp = currentTimestamp();

  const data = Buffer.allocUnsafe(21);
  const bufferedTemplate = toBuffer(Buffer.from(beaconSetTemplateIds[1], 'hex'));
  const bufferedTimestamp = bufferU64BE(timestamp);
  const message = keccak256Packed(
    ["bytes32", "uint256", "bytes"],
    [bufferedTemplate, bufferedTimestamp, data]
  );
  const signature = await signer.sign(message);
  await expect(client.updateBeaconSetWithSignedData(
    [airnodeAddress, airnodeAddress],
    [beaconSetTemplateIds[0], beaconSetTemplateIds[1]],
    [0, timestamp],
    [[], [...data]],
    [[], [...signature.signature]]
  )).rejects.toThrow("InvalidDataLength")
}

async function notAllSignaturesValid(client, signer, airnodeAddress, beaconSetTemplateIds) {
  const timestamp = currentTimestamp();

  const data = Buffer.alloc(21, 0);
  await expect(client.updateBeaconSetWithSignedData(
    [airnodeAddress, airnodeAddress],
    [beaconSetTemplateIds[0], beaconSetTemplateIds[1]],
    [0, timestamp],
    [[], [...data]],
    [[], [...Buffer.alloc(64)]]
  )).rejects.toThrow("InvalidSignature") 
}

async function lessThanTwoBeacons(client) {
  await expect(client.updateBeaconSetWithSignedData(
    [airnodeAddress],
    [beaconSetTemplateIds[0]],
    [0],
    [[]],
    [[]]
  )).rejects.toThrow("LessThanTwoBeacons")
}

async function parameterLengthMismatch(client, airnodeAddress, beaconSetTemplateIds) {
  await expect(client.updateBeaconSetWithSignedData(
    [airnodeAddress],
    [beaconSetTemplateIds[0]],
    [0, 123],
    [[]],
    [[]]
  )).rejects.toThrow("ParameterLengthMismatch")
}

module.exports = { 
  updatesBeaconSetWithSignedData, updatedSetValueOutdated, lengthNotCorrect,
  lessThanTwoBeacons, notAllSignaturesValid, parameterLengthMismatch
};
'''
'''--- near/client-test/tests/utils/updateBeaconWithSignedData.js ---
const { ethers } = require("ethers");
const { 
  currentTimestamp, encodeAndSignData, encodeData, toBuffer, deriveBeaconId,
  generateRandomBytes32,
  bufferU64BE,
  keccak256Packed,
  delay,
 } = require("../../src/util");

async function updateBeacon(client, signer, airnodeAddress, templateId, value, timestamp, readerClient) {
    const [data, signature] = await encodeAndSignData(value, templateId, timestamp, signer);
    await client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature);

    const beaconId = deriveBeaconId(
      toBuffer(airnodeAddress),
      templateId
    );
    const beacon = await readerClient.readDataFeedWithId(beaconId);
    expect(beacon.value).toEqual([...encodeData(value)])
    expect(beacon.timestamp).toEqual(timestamp)

}

async function dataNotFresherThanBeacon(client, signer, airnodeAddress, templateId) {
    const timestamp = currentTimestamp() - 1000;
    const [data, signature] = await encodeAndSignData(123, templateId, timestamp, signer);
    await expect(client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature)).rejects.toThrow("FulfillmentOlderThanBeacon")
}

async function dataLengthNotCorrect(client, signer, airnodeAddress, templateId) {
    const timestamp = currentTimestamp();
    const data = ethers.utils.randomBytes(30);

    // prepare signature
    const bufferedTemplate = toBuffer(Buffer.from(templateId, 'hex'));
    const bufferedTimestamp = bufferU64BE(timestamp);
    const message = keccak256Packed(
        ["bytes32", "uint256", "bytes"],
        [bufferedTemplate, bufferedTimestamp, data]
    );
    const {signature} = await signer.sign(message);

    await expect(client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature)).rejects.toThrow("InvalidDataLength")
}

async function timestampNotValid(client, signer, airnodeAddress) {
  // we are using a randon templated id for now
  const templateId = generateRandomBytes32();

  // we update once first, ensure there is some data.
  let timestamp = currentTimestamp();
  let [data, signature] = await encodeAndSignData(1234, templateId, timestamp, signer);
  await client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature);

  // mimic some other operation
  await delay(1000);

  // now update with an older timestamp
  timestamp = timestamp - 1;
  [data, signature] = await encodeAndSignData(123, templateId, timestamp, signer);
  await expect(client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, signature)).rejects.toThrow("FulfillmentOlderThanBeacon")
}

async function signatureNotValid(client, signer, airnodeAddress, templateId) {
  const timestamp = currentTimestamp();
  const [data, ] = await encodeAndSignData(123, templateId, timestamp, signer);
  await expect(client.updateBeaconWithSignedData(airnodeAddress, templateId, timestamp, data, Buffer.allocUnsafe(64))).rejects.toThrow("InvalidSignature")
}

module.exports = { 
  updateBeacon, dataNotFresherThanBeacon, dataLengthNotCorrect, timestampNotValid,
  signatureNotValid
};
'''
'''--- near/client-test/tests/utils/whitelist.js ---
const { generateRandomBytes32, delay } = require("../../src/util");

async function dataFeedIdToReaderToWhitelistStatus(client) {
    const reader = generateRandomBytes32().toString();
    const beaconId = [...generateRandomBytes32()];
    await client.setIndefiniteWhitelistStatus(beaconId, reader, true);
    await client.setWhitelistExpiration(beaconId, reader, 123456);
    const r = await client.dataFeedIdToReaderToWhitelistStatus(
      beaconId,
      reader
    );
    const expected = Buffer.alloc(32, 0);
    expected.writeUint8(1, 31);
    expect(r[0]).toEqual(123456)
    expect(r[1]).toEqual([...expected])
}

async function dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(client, setter) {
    const reader = generateRandomBytes32().toString();
    const beaconId = [...generateRandomBytes32()];

    let r = await client.dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(
      beaconId,
      reader,
      setter
    );
    expect(r).toEqual(false)

    await client.setIndefiniteWhitelistStatus(beaconId, reader, true);
    await delay(1000);

    r = await client.dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus(
      beaconId,
      reader,
      setter
    );
    expect(r).toEqual(true)
}

module.exports = { 
  dataFeedIdToReaderToWhitelistStatus, dataFeedIdToReaderToSetterToIndefiniteWhitelistStatus
};
'''
'''--- near/contract/Cargo.toml ---
[package]
name = "dapi-server"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
near-sdk = "3.1.0"
serde = { version = "1"}
api3-common = { verion = "0.0.1", path = "../../common", features = ["dummy"] }
ed25519-dalek = { version = "1.0.1", default-features = false, features = ["std"] }
hex = "0.4.3"

[dev-dependencies]
near-sdk-sim = "3.1.0"

[profile.release]
codegen-units = 1
# Tell `rustc` to optimize for small code size.
opt-level = "z"
lto = true
debug = false
panic = "abort"
# Opt into extra safety checks on arithmetic operations https://stackoverflow.com/a/64136471/249801
overflow-checks = true

'''
'''--- near/contract/src/lib.rs ---
mod types;
mod utils;
mod whitelist;

use crate::types::{Address, NearDataPoint};
use crate::utils::{
    msg_sender, Bytes32HashMap, DatapointHashMap, NearAccessControlRegistry, NearClock,
    SignatureVerify,
};
use crate::whitelist::{NearWhitelist, WhitelistStatus};
use api3_common::abi::{Token, Uint};
use api3_common::{
    keccak_packed, process_beacon_update, AccessControlRegistry, Bytes, Bytes32, Error,
    SignatureManger, StaticRole, WhitelistRolesWithManager, WhitelistWithManager,
};
use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};
use near_sdk::{collections::LookupMap, near_bindgen};
use std::fmt::Debug;

near_sdk::setup_alloc!();

#[near_bindgen]
#[derive(BorshDeserialize, BorshSerialize)]
pub struct DapiServer {
    /// Data point related storage
    data_points: LookupMap<Bytes32, NearDataPoint>,
    name_hash_to_data_point_id: LookupMap<Bytes32, Bytes32>,

    /// Access control related storage
    manager: Address,
    admin_role_description: String,
    role_membership: LookupMap<Bytes32, bool>,
    role_admin: LookupMap<Bytes32, Bytes32>,

    service_id_to_user_to_whitelist_status: LookupMap<Bytes32, WhitelistStatus>,
    service_id_to_user_to_setter_to_indefinite_whitelist_status: LookupMap<Bytes32, bool>,
}

impl Default for DapiServer {
    fn default() -> Self {
        let data_points = LookupMap::new(b'd');
        let name_hash_to_data_point_id = LookupMap::new(b'n');

        let mut role_membership = LookupMap::new(b'm');
        let mut role_admin = LookupMap::new(b'a');

        let service_id_to_user_to_whitelist_status = LookupMap::new(b's');
        let service_id_to_user_to_setter_to_indefinite_whitelist_status = LookupMap::new(b'b');

        let manager = msg_sender();
        let admin_role_description = String::from("admin role");
        let mut access = NearAccessControlRegistry::requires_write(
            manager.clone(),
            admin_role_description.clone(),
            &mut role_membership,
            &mut role_admin,
        );
        access
            .grant_role(&NearAccessControlRegistry::DEFAULT_ADMIN_ROLE, &manager)
            .expect("initialization failed");
        Self {
            data_points,
            name_hash_to_data_point_id,
            manager,
            admin_role_description,
            role_membership,
            role_admin,
            service_id_to_user_to_whitelist_status,
            service_id_to_user_to_setter_to_indefinite_whitelist_status,
        }
    }
}

#[near_bindgen]
impl DapiServer {
    // ================== Access Control ====================
    pub fn roles(&self) -> (Bytes32, Bytes32) {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        (
            access.find_static_role(StaticRole::UnlimitedReaderRole),
            access.find_static_role(StaticRole::NameSetterRole),
        )
    }

    /// Renounce `role` to `who`
    pub fn renounce_role(&mut self, role: Bytes32, who: String) {
        let mut access = NearAccessControlRegistry::requires_write(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &mut self.role_membership,
            &mut self.role_admin,
        );
        let r = access.renounce_role(&role, &Address(who.as_bytes().to_vec()));
        near_check_result(r)
    }

    /// Revoke `role` to `who`
    pub fn revoke_role(&mut self, role: Bytes32, who: String) {
        let mut access = NearAccessControlRegistry::requires_write(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &mut self.role_membership,
            &mut self.role_admin,
        );

        let role_admin = access
            .get_role_admin(&role)
            .unwrap_or(NearAccessControlRegistry::DEFAULT_ADMIN_ROLE);

        ensure!(
            access.only_role(&role_admin, &msg_sender()).is_ok(),
            Error::NotAuthorized
        );

        let r = access.revoke_role(&role, &Address(who.as_bytes().to_vec()));
        near_check_result(r)
    }

    /// Grants `role` to `who`
    pub fn grant_role(&mut self, role: Bytes32, who: String) {
        let mut access = NearAccessControlRegistry::requires_write(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &mut self.role_membership,
            &mut self.role_admin,
        );

        ensure!(
            access
                .only_role(
                    &NearAccessControlRegistry::DEFAULT_ADMIN_ROLE,
                    &msg_sender()
                )
                .is_ok(),
            Error::NotAuthorized
        );

        let r = access.grant_role(&role, &Address(who.as_bytes().to_vec()));
        near_check_result(r)
    }

    /// Checks if `who` has `role`
    pub fn has_role(&self, role: Bytes32, who: String) -> bool {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        access.has_role(&role, &Address(who.as_bytes().to_vec()))
    }

    // ================== Datapoint ====================
    /// Updates a Beacon using data signed by the respective Airnode,
    /// without requiring a request or subscription
    ///
    /// # Arguments
    ///
    /// * `airnode` Airnode public key
    /// * `template_id` Template ID
    /// * `timestamp` Timestamp used in the signature
    /// * `data` Response data (an `int256` encoded in contract ABI)
    /// * `signature` Template ID, a timestamp and the response data signed by the Airnode address
    pub fn update_beacon_with_signed_data(
        &mut self,
        airnode: Bytes,
        template_id: Bytes32,
        timestamp: Bytes32,
        data: Vec<u8>,
        signature: Vec<u8>,
    ) {
        // create the utility structs
        let mut storage = DatapointHashMap::requires_write(&mut self.data_points);

        // perform signature verification
        let message = keccak_packed(&[
            Token::FixedBytes(template_id.to_vec()),
            Token::Uint(Uint::from_big_endian(&timestamp)),
            Token::Bytes(data.clone()),
        ]);

        if !SignatureVerify::verify(&airnode, &message, &signature) {
            near_sdk::env::panic("InvalidSignature".as_ref());
        }

        let beacon_id = api3_common::derive_beacon_id(airnode.to_vec(), template_id);
        let r = process_beacon_update(
            &mut storage,
            beacon_id,
            Uint::from_big_endian(&timestamp),
            data,
        );
        near_check_result(r)
    }

    /// Updates the dAPI that is specified by the beacon IDs
    ///
    /// # Arguments
    ///
    /// * `beacon_ids` Beacon IDs
    pub fn update_dapi_with_beacons(&mut self, beacon_ids: Vec<Bytes32>) -> Bytes32 {
        let mut storage = DatapointHashMap::requires_write(&mut self.data_points);
        let r = api3_common::update_dapi_with_beacons(&mut storage, &beacon_ids);
        near_check_result(r)
    }

    /// Updates a dAPI using data signed by the respective Airnodes
    /// without requiring a request or subscription. The beacons for which the
    /// signature is omitted will be read from the storage.
    ///
    /// # Arguments
    ///
    /// * `airnodes` Airnode public addresses
    /// * `template_ids` Template IDs
    /// * `timestamps` Timestamps used in the signatures
    /// * `data` Response data (an `int256` encoded in contract ABI per Beacon)
    /// * `signatures` Template ID, a timestamp and the response data signed by the respective Airnode address per Beacon
    pub fn update_dapi_with_signed_data(
        &mut self,
        airnodes: Vec<Bytes>,
        template_ids: Vec<Bytes32>,
        timestamps: Vec<Bytes32>,
        data: Vec<Bytes>,
        signatures: Vec<Bytes>,
    ) -> Bytes32 {
        let mut storage = DatapointHashMap::requires_write(&mut self.data_points);
        let clock = NearClock::new(nanoseconds_to_seconds(near_sdk::env::block_timestamp()));

        let r = api3_common::update_dapi_with_signed_data::<_, SignatureVerify, _>(
            &mut storage,
            &clock,
            airnodes,
            template_ids,
            timestamps,
            data,
            signatures,
        );
        near_check_result(r)
    }

    /// Sets the data point ID the name points to.
    /// While a data point ID refers to a specific Beacon or dAPI, names
    /// provide a more abstract interface for convenience. This means a name
    /// that was pointing at a Beacon can be pointed to a dAPI, then another
    /// dAPI, etc.
    ///
    /// # Arguments
    ///
    /// * `name` Human-readable name
    /// * `datapoint_id` Data point ID the name will point to
    pub fn set_name(&mut self, name: Bytes32, datapoint_id: Bytes32) {
        let mut storage = Bytes32HashMap::requires_write(&mut self.name_hash_to_data_point_id);
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let r = api3_common::set_name(name, datapoint_id, &msg_sender(), &access, &mut storage);
        near_check_result(r)
    }

    /// Returns the data point ID the name is set to
    /// `name` Name
    pub fn name_to_data_point_id(&self, name: Bytes32) -> Option<Bytes32> {
        self.name_hash_to_data_point_id
            .get(&keccak_packed(&[Token::FixedBytes(name.to_vec())]))
    }

    /// Derives the beacon set ID from the beacon IDs
    /// Notice that `encode()` is used over `encode_packed()`
    /// Returns the derived dapi id
    ///
    /// # Arguments
    ///
    /// * `beacon_ids` Beacon IDs
    pub fn derive_beacon_set_id(&self, beacon_ids: Vec<Bytes32>) -> Bytes32 {
        api3_common::derive_dapi_id(&beacon_ids)
    }

    /// Derives the beacon id based on the `airnode` and `templated_id`
    /// Returns the beacon id
    ///
    /// # Arguments
    ///
    /// * `airnode` Airnode address
    /// * `template_id` Template ID
    pub fn derive_beacon_id(&self, airnode: Bytes, template_id: Bytes32) -> Bytes32 {
        api3_common::derive_beacon_id(airnode, template_id)
    }

    /// Reads the data point with ID
    ///
    /// # Arguments
    ///
    /// * `data_point_id` Data point ID
    pub fn read_with_data_point_id(&self, data_point_id: Bytes32) -> (Bytes32, u32) {
        let storage = DatapointHashMap::read_only(&self.data_points);
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );

        let r = api3_common::read_with_data_point_id(
            &data_point_id,
            &msg_sender(),
            &storage,
            &access,
            &whitelist,
        )
        .map(|(a, n)| {
            let mut v = [0u8; 32];
            a.to_big_endian(&mut v);
            (v, n)
        });
        near_check_result(r)
    }

    /// Reads the data point with name
    /// The read data point may belong to a Beacon or dAPI. The reader
    /// must be whitelisted for the hash of the data point name.
    ///
    /// # Arguments
    ///
    /// * `name` Data point name
    pub fn read_with_name(&self, name: Bytes32) -> (Bytes32, u32) {
        let dp_s = DatapointHashMap::read_only(&self.data_points);
        let nh_s = Bytes32HashMap::read_only(&self.name_hash_to_data_point_id);
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        let r = api3_common::read_with_name(name, &msg_sender(), &dp_s, &nh_s, &access, &whitelist)
            .map(|(a, n)| {
                let mut v = [0u8; 32];
                a.to_big_endian(&mut v);
                (v, n)
            });
        near_check_result(r)
    }

    /// Returns if a reader can read the data point
    ///
    /// # Arguments
    ///
    /// * `data_point_id` Data point ID (or data point name hash)
    /// * `reader` Reader address as raw bytes
    pub fn reader_can_read_data_point(&self, data_point_id: Bytes32, reader: String) -> bool {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        let reader = Address(reader.as_bytes().to_vec());
        api3_common::reader_can_read_data_point(&data_point_id, &reader, &access, &whitelist)
    }

    pub fn data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status(
        &self,
        data_feed_id: Bytes32,
        reader: String,
        setter: String,
    ) -> bool {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist
            .data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status(
                &data_feed_id,
                reader.as_bytes(),
                setter.as_bytes(),
            )
            .unwrap_or(false)
    }

    /// Returns the detailed whitelist status of the reader for the data feed
    ///
    /// # Arguments
    ///
    /// * `data_feed_id` The data feed id
    /// * `reader` Reader address
    pub fn data_feed_id_to_whitelist_status(
        &self,
        data_feed_id: Bytes32,
        reader: String,
    ) -> Option<(u64, Bytes32)> {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.data_feed_id_to_whitelist_status(&data_feed_id, reader.as_bytes())
    }

    /// Extends the expiration of the temporary whitelist of `user` to
    /// be able to use the service with `service_id` if the sender has the
    /// whitelist expiration extender role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    pub fn extend_whitelist_expiration(
        &mut self,
        service_id: Bytes32,
        user: String,
        expiration_timestamp: u64,
    ) {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let mut whitelist = NearWhitelist::requires_write(
            &access,
            &mut self.service_id_to_user_to_whitelist_status,
            &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.extend_whitelist_expiration(
            &service_id,
            &Address(user.as_bytes().to_vec()),
            expiration_timestamp,
        )
    }

    /// Sets the expiration of the temporary whitelist of `user` to be
    /// able to use the service with `service_id` if the sender has the
    /// whitelist expiration setter role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `expiration_timestamp` Timestamp at which the temporary whitelist will expire
    pub fn set_whitelist_expiration(
        &mut self,
        service_id: Bytes32,
        user: String,
        expiration_timestamp: u64,
    ) {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let mut whitelist = NearWhitelist::requires_write(
            &access,
            &mut self.service_id_to_user_to_whitelist_status,
            &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.set_whitelist_expiration(
            &service_id,
            &Address(user.as_bytes().to_vec()),
            expiration_timestamp,
        )
    }

    /// Sets the indefinite whitelist status of `user` to be able to
    /// use the service with `service_id` if the sender has the indefinite whitelister role
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `status` Indefinite whitelist status
    pub fn set_indefinite_whitelist_status(
        &mut self,
        service_id: Bytes32,
        user: String,
        status: bool,
    ) -> Bytes32 {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let mut whitelist = NearWhitelist::requires_write(
            &access,
            &mut self.service_id_to_user_to_whitelist_status,
            &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        let r = whitelist.set_indefinite_whitelist_status(
            &service_id,
            &Address(user.as_bytes().to_vec()),
            status,
        );
        Bytes32::from(r)
    }

    /// Revokes the indefinite whitelist status granted to the user for
    /// the service by a specific account
    ///
    /// # Arguments
    ///
    /// * `service_id` Service ID
    /// * `user` User address
    /// * `setter` Setter address
    pub fn revoke_indefinite_whitelist_status(
        &mut self,
        service_id: Bytes32,
        user: String,
        setter: String,
    ) -> (bool, Bytes32) {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let mut whitelist = NearWhitelist::requires_write(
            &access,
            &mut self.service_id_to_user_to_whitelist_status,
            &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        let (revoked, r) = whitelist.revoke_indefinite_whitelist_status(
            &service_id,
            &Address(user.as_bytes().to_vec()),
            &Address(setter.as_bytes().to_vec()),
        );
        (revoked, Bytes32::from(r))
    }

    pub fn whitelist_expiration_extender_role(&self) -> Bytes32 {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.whitelist_expiration_extender_role()
    }

    pub fn whitelist_expiration_setter_role(&self) -> Bytes32 {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.whitelist_expiration_setter_role()
    }

    pub fn indefinite_whitelister_role(&self) -> Bytes32 {
        let access = NearAccessControlRegistry::read_only(
            self.manager.clone(),
            self.admin_role_description.clone(),
            &self.role_membership,
            &self.role_admin,
        );
        let whitelist = NearWhitelist::read_only(
            &access,
            &self.service_id_to_user_to_whitelist_status,
            &self.service_id_to_user_to_setter_to_indefinite_whitelist_status,
        );
        whitelist.indefinite_whitelister_role()
    }
}

fn nanoseconds_to_seconds(nano: u64) -> u32 {
    (nano / (1e9 as u64)) as u32
}

fn near_check_result<T: Debug>(r: Result<T, Error>) -> T {
    if let Ok(v) = r {
        v
    } else {
        near_sdk::env::panic(format!("Invalid request: {:?}", r.unwrap_err()).as_ref())
    }
}

'''
'''--- near/contract/src/types.rs ---
use api3_common::abi::{Int, U256};
use api3_common::{DataPoint, Zero};
use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};

#[derive(BorshDeserialize, BorshSerialize, PartialEq, Clone, Default)]
pub struct Address(pub Vec<u8>);

impl Zero for Address {
    fn is_zero(&self) -> bool {
        self.0.is_empty()
    }
}

impl AsRef<[u8]> for Address {
    fn as_ref(&self) -> &[u8] {
        self.0.as_ref()
    }
}

#[derive(BorshDeserialize, BorshSerialize, Clone)]
pub(crate) struct NearDataPoint {
    pub value: U256,
    pub timestamp: u32,
}

impl NearDataPoint {
    pub fn new(value: U256, timestamp: u32) -> Self {
        NearDataPoint { value, timestamp }
    }
}

impl From<NearDataPoint> for DataPoint {
    fn from(t: NearDataPoint) -> Self {
        let mut v = [0u8; 32];
        t.value.to_big_endian(&mut v);
        DataPoint::new(Int::from_big_endian(&v), t.timestamp)
    }
}

impl From<DataPoint> for NearDataPoint {
    fn from(t: DataPoint) -> Self {
        let mut v = [0u8; 32];
        t.value.to_big_endian(&mut v);
        NearDataPoint::new(U256::from_big_endian(&v), t.timestamp)
    }
}

'''
'''--- near/contract/src/utils.rs ---
use crate::types::{Address, NearDataPoint};
use api3_common::abi::Token;
use api3_common::{
    keccak_packed, AccessControlRegistry, AccessControlRegistryAdminnedWithManager, Bytes32,
    DataPoint, Error, RoleDeriver, SignatureManger, Storage, TimestampChecker,
};
use ed25519_dalek::Verifier;
use near_sdk::collections::LookupMap;

/// Read write privilege
pub(crate) enum ReadWrite<'a, T> {
    ReadOnly(&'a T),
    Write(&'a mut T),
}

/// The utility struct for handling Near storage so that
/// we can use the code in `api3_common` for all the processing
pub(crate) struct DatapointHashMap<'account> {
    map: ReadWrite<'account, LookupMap<Bytes32, NearDataPoint>>,
}

impl<'account> DatapointHashMap<'account> {
    pub fn requires_write(map: &'account mut LookupMap<Bytes32, NearDataPoint>) -> Self {
        Self {
            map: ReadWrite::Write(map),
        }
    }

    pub fn read_only(map: &'account LookupMap<Bytes32, NearDataPoint>) -> Self {
        Self {
            map: ReadWrite::ReadOnly(map),
        }
    }
}

impl<'account> Storage<DataPoint> for DatapointHashMap<'account> {
    fn get(&self, k: &Bytes32) -> Option<DataPoint> {
        match &self.map {
            ReadWrite::ReadOnly(a) => match (*a).get(k) {
                Some(d) => Some(d.into()),
                None => Some(DataPoint::default()),
            },
            ReadWrite::Write(a) => match (*a).get(k) {
                Some(d) => Some(d.into()),
                None => Some(DataPoint::default()),
            },
        }
    }

    fn store(&mut self, k: Bytes32, datapoint: DataPoint) {
        let m = match &mut self.map {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };
        if (*m).contains_key(&k) {
            (*m).remove(&k);
        }
        (*m).insert(&k, &NearDataPoint::from(datapoint));
    }
}

/// The utility struct for handling Near storage so that
/// we can use the code in `api3_common` for all the processing
pub(crate) struct Bytes32HashMap<'account> {
    map: ReadWrite<'account, LookupMap<Bytes32, Bytes32>>,
}

impl<'account> Bytes32HashMap<'account> {
    pub fn requires_write(map: &'account mut LookupMap<Bytes32, Bytes32>) -> Self {
        Self {
            map: ReadWrite::Write(map),
        }
    }

    pub fn read_only(map: &'account LookupMap<Bytes32, Bytes32>) -> Self {
        Self {
            map: ReadWrite::ReadOnly(map),
        }
    }
}

impl<'account> Storage<Bytes32> for Bytes32HashMap<'account> {
    fn get(&self, k: &Bytes32) -> Option<Bytes32> {
        match &self.map {
            ReadWrite::ReadOnly(a) => (*a).get(k),
            ReadWrite::Write(a) => (*a).get(k),
        }
    }

    fn store(&mut self, k: Bytes32, data: Bytes32) {
        let m = match &mut self.map {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };
        if (*m).contains_key(&k) {
            (*m).remove(&k);
        }
        (*m).insert(&k, &data);
    }
}

/// Utility function for signature verification for Near so that we can use
/// `api3_common` package for the functions
pub(crate) struct SignatureVerify;

impl SignatureManger for SignatureVerify {
    fn verify(key: &[u8], message: &[u8], signature: &[u8]) -> bool {
        if let Ok(signature) = ed25519_dalek::Signature::try_from(signature) {
            if let Ok(public_key) = ed25519_dalek::PublicKey::from_bytes(key) {
                return public_key.verify(message, &signature).is_ok();
            }
        }
        false
    }
}

pub(crate) struct NearClock {
    current_timestamp: u32,
}

impl NearClock {
    pub fn new(current_timestamp: u32) -> Self {
        Self { current_timestamp }
    }
}

impl TimestampChecker for NearClock {
    fn current_timestamp(&self) -> u32 {
        self.current_timestamp
    }
}

pub(crate) fn msg_sender() -> Address {
    let sender = near_sdk::env::predecessor_account_id().as_bytes().to_vec();
    Address(sender)
}

pub(crate) struct NearAccessControlRegistry<'a> {
    manager: Address,
    admin_role_description: String,
    role_membership: ReadWrite<'a, LookupMap<Bytes32, bool>>,
    role_admin: ReadWrite<'a, LookupMap<Bytes32, Bytes32>>,
}

impl<'a> NearAccessControlRegistry<'a> {
    pub fn requires_write(
        manager: Address,
        admin_role_description: String,
        role_membership: &'a mut LookupMap<Bytes32, bool>,
        role_admin: &'a mut LookupMap<Bytes32, Bytes32>,
    ) -> Self {
        Self {
            manager,
            admin_role_description,
            role_membership: ReadWrite::Write(role_membership),
            role_admin: ReadWrite::Write(role_admin),
        }
    }

    pub fn read_only(
        manager: Address,
        admin_role_description: String,
        role_membership: &'a LookupMap<Bytes32, bool>,
        role_admin: &'a LookupMap<Bytes32, Bytes32>,
    ) -> Self {
        Self {
            manager,
            admin_role_description,
            role_membership: ReadWrite::ReadOnly(role_membership),
            role_admin: ReadWrite::ReadOnly(role_admin),
        }
    }

    fn hash_membership(role: &Bytes32, who: &Address) -> Bytes32 {
        keccak_packed(&[
            Token::FixedBytes(role.to_vec()),
            Token::FixedBytes(who.as_ref().to_vec()),
        ])
    }
}

impl<'a> AccessControlRegistryAdminnedWithManager for NearAccessControlRegistry<'a> {
    type Address = Address;

    fn manager(&self) -> &Self::Address {
        &self.manager
    }

    fn admin_role_description(&self) -> String {
        self.admin_role_description.clone()
    }

    fn admin_role_description_hash(&self) -> Bytes32 {
        keccak_packed(&[Token::String(self.admin_role_description())])
    }

    fn admin_role(&self) -> Bytes32 {
        RoleDeriver::derive_role(
            RoleDeriver::derive_root_role(&self.manager.0),
            self.admin_role_description(),
        )
    }
}

impl<'a> AccessControlRegistry for NearAccessControlRegistry<'a> {
    fn has_role(&self, role: &Bytes32, who: &Self::Address) -> bool {
        let hash = Self::hash_membership(role, who);
        match &self.role_membership {
            ReadWrite::ReadOnly(m) => m.contains_key(&hash),
            ReadWrite::Write(m) => m.contains_key(&hash),
        }
    }

    fn grant_role(&mut self, role: &Bytes32, who: &Self::Address) -> Result<(), Error> {
        let hash = Self::hash_membership(role, who);
        match &mut self.role_membership {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => {
                (*m).remove(&hash);
                (*m).insert(&hash, &true);
            }
        };
        Ok(())
    }

    fn get_role_admin(&self, role: &Bytes32) -> Option<Bytes32> {
        if *role == Self::DEFAULT_ADMIN_ROLE {
            return Some(Self::DEFAULT_ADMIN_ROLE);
        }
        match &self.role_admin {
            ReadWrite::ReadOnly(a) => (*a).get(role),
            ReadWrite::Write(a) => (*a).get(role),
        }
    }

    fn set_role_admin(&mut self, role: &Bytes32, role_admin: Bytes32) -> Result<(), Error> {
        let a = match &mut self.role_admin {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(a) => a,
        };
        (*a).remove(role);
        (*a).insert(role, &role_admin);
        Ok(())
    }

    fn renounce_role(&mut self, role: &Bytes32, account: &Self::Address) -> Result<(), Error> {
        let sender = msg_sender();
        api3_common::ensure!(*account == sender, Error::NotAuthorized)?;
        self.revoke_role(role, account)
    }

    fn revoke_role(&mut self, role: &Bytes32, account: &Self::Address) -> Result<(), Error> {
        let hash = Self::hash_membership(role, account);

        let m = match &mut self.role_membership {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };
        (*m).remove(&hash);
        Ok(())
    }
}

/// NEAR contract calls on the panic interface for errors
#[macro_export]
macro_rules! ensure {
    ( $x:expr, $y:expr ) => {{
        if !$x {
            near_sdk::env::panic(format!("{:?}", $y).as_bytes())
        }
    }};
}

/// a convenient way to call to the NEAR's blockchain panic
#[macro_export]
macro_rules! error_panic {
    ( $y:expr ) => {{
        near_sdk::env::panic(format!("{}", $y).as_bytes())
    }};
}

'''
'''--- near/contract/src/whitelist.rs ---
use crate::utils::ReadWrite;
use crate::{msg_sender, near_check_result, Address};
use api3_common::abi::{Token, U256};
use api3_common::{
    ensure, keccak_packed, AccessControlRegistry, AccessControlRegistryAdminnedWithManager,
    Bytes32, Error, Whitelist, WhitelistRoles, WhitelistRolesWithManager, WhitelistWithManager,
    Zero, BYTES32_ZERO,
};
use near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};
use near_sdk::collections::LookupMap;
use std::ops::{Add, Sub};

#[derive(BorshDeserialize, BorshSerialize)]
pub struct WhitelistStatus {
    expiration_timestamp: u64,
    /// originally uint192, that is u128 and u64 combined
    indefinite_whitelist_count: Bytes32,
}

impl Default for WhitelistStatus {
    fn default() -> Self {
        Self {
            expiration_timestamp: 0,
            indefinite_whitelist_count: BYTES32_ZERO,
        }
    }
}

pub struct NearWhitelist<'a, Access: AccessControlRegistry<Address = Address>> {
    access: &'a Access,
    service_id_to_user_to_whitelist_status: ReadWrite<'a, LookupMap<Bytes32, WhitelistStatus>>,
    service_id_to_user_to_setter_to_indefinite_whitelist_status:
        ReadWrite<'a, LookupMap<Bytes32, bool>>,
}

impl<'a, Access: AccessControlRegistry<Address = Address>> NearWhitelist<'a, Access> {
    pub fn requires_write(
        access: &'a Access,
        service_id_to_user_to_whitelist_status: &'a mut LookupMap<Bytes32, WhitelistStatus>,
        service_id_to_user_to_setter_to_indefinite_whitelist_status: &'a mut LookupMap<
            Bytes32,
            bool,
        >,
    ) -> Self {
        Self {
            access,
            service_id_to_user_to_whitelist_status: ReadWrite::Write(
                service_id_to_user_to_whitelist_status,
            ),
            service_id_to_user_to_setter_to_indefinite_whitelist_status: ReadWrite::Write(
                service_id_to_user_to_setter_to_indefinite_whitelist_status,
            ),
        }
    }

    pub fn read_only(
        access: &'a Access,
        service_id_to_user_to_whitelist_status: &'a LookupMap<Bytes32, WhitelistStatus>,
        service_id_to_user_to_setter_to_indefinite_whitelist_status: &'a LookupMap<Bytes32, bool>,
    ) -> Self {
        Self {
            access,
            service_id_to_user_to_whitelist_status: ReadWrite::ReadOnly(
                service_id_to_user_to_whitelist_status,
            ),
            service_id_to_user_to_setter_to_indefinite_whitelist_status: ReadWrite::ReadOnly(
                service_id_to_user_to_setter_to_indefinite_whitelist_status,
            ),
        }
    }

    pub fn data_feed_id_to_reader_to_setter_to_indefinite_whitelist_status(
        &self,
        data_feed_id: &Bytes32,
        reader: &[u8],
        setter: &[u8],
    ) -> Option<bool> {
        let key = Self::triple_hash(data_feed_id, reader, setter);
        let indefinite = match &self.service_id_to_user_to_setter_to_indefinite_whitelist_status {
            ReadWrite::ReadOnly(m) => *m,
            ReadWrite::Write(m) => *m,
        };
        indefinite.get(&key)
    }

    pub fn data_feed_id_to_whitelist_status(
        &self,
        data_feed_id: &Bytes32,
        reader: &[u8],
    ) -> Option<(u64, Bytes32)> {
        let key = Self::double_hash(data_feed_id, reader);
        let s = match &self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(s) => *s,
            ReadWrite::Write(s) => *s,
        };
        s.get(&key)
            .map(|w| (w.expiration_timestamp, w.indefinite_whitelist_count))
    }

    fn double_hash(service_id: &Bytes32, address: &[u8]) -> Bytes32 {
        keccak_packed(&[
            Token::FixedBytes(service_id.to_vec()),
            Token::FixedBytes(address.to_vec()),
        ])
    }

    fn triple_hash(service_id: &Bytes32, address0: &[u8], address1: &[u8]) -> Bytes32 {
        keccak_packed(&[
            Token::FixedBytes(service_id.to_vec()),
            Token::FixedBytes(address0.to_vec()),
            Token::FixedBytes(address1.to_vec()),
        ])
    }
}

impl<'a, Access: AccessControlRegistry<Address = Address>> Whitelist for NearWhitelist<'a, Access> {
    type Address = Address;

    /// Returns if the user is whitelisted to use the service
    /// `service_id` Service ID
    /// `user` User address
    fn user_is_whitelisted(&self, service_id: &Bytes32, user: &Address) -> bool {
        let hash = Self::double_hash(service_id, &user.0);
        let s = match &self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(s) => *s,
            ReadWrite::Write(s) => *s,
        };
        s.get(&hash)
            .map(|status| {
                let count = U256::from_big_endian(&status.indefinite_whitelist_count);
                count > U256::from(0)
                    || status.expiration_timestamp > near_sdk::env::block_timestamp()
            })
            .unwrap_or(false)
    }

    fn extend_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        expiration_timestamp: u64,
    ) {
        let m = match &mut self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };

        let hash = Self::double_hash(service_id, &user.0);

        let mut whitelist_status = (*m).remove(&hash).unwrap_or_default();
        near_check_result(ensure!(
            expiration_timestamp > whitelist_status.expiration_timestamp,
            Error::DoesNotExtendExpiration
        ));

        whitelist_status.expiration_timestamp = expiration_timestamp;
        (*m).insert(&hash, &whitelist_status);
    }

    fn set_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        expiration_timestamp: u64,
    ) {
        let m = match &mut self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };
        let hash = Self::double_hash(service_id, &user.0);
        let mut whitelist_status = (*m).remove(&hash).unwrap_or_default();
        whitelist_status.expiration_timestamp = expiration_timestamp;
        (*m).insert(&hash, &whitelist_status);
    }

    fn set_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        status: bool,
    ) -> U256 {
        let w_hash = Self::double_hash(service_id, &user.0);
        let i_hash = Self::triple_hash(service_id, &user.0, &msg_sender().0);

        let whitelist = match &mut self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };
        let indefinite = match &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status
        {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };

        let mut indefinite_count = whitelist
            .get(&w_hash)
            .map(|f| U256::from_big_endian(&f.indefinite_whitelist_count))
            .unwrap_or_else(|| U256::from(0u32));
        let indefinite_status = indefinite.get(&i_hash).unwrap_or(false);

        if status && !indefinite_status {
            indefinite.remove(&i_hash);
            indefinite.insert(&i_hash, &true);
            let mut whitelist_status = whitelist.remove(&w_hash).unwrap_or_default();
            indefinite_count = indefinite_count.add(U256::from(1u8));
            whitelist_status.indefinite_whitelist_count = Bytes32::from(&indefinite_count);
            whitelist.insert(&w_hash, &whitelist_status);
        } else if !status && indefinite_status {
            indefinite.remove(&i_hash);
            indefinite.insert(&i_hash, &false);
            let mut whitelist_status = whitelist.remove(&w_hash).unwrap_or_default();
            indefinite_count = indefinite_count.sub(U256::from(1u8));
            whitelist_status.indefinite_whitelist_count = Bytes32::from(&indefinite_count);
            whitelist.insert(&w_hash, &whitelist_status);
        }

        indefinite_count
    }

    fn revoke_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &Self::Address,
        setter: &Self::Address,
    ) -> (bool, U256) {
        let user_hash = Self::double_hash(service_id, &user.0);
        let setter_hash = Self::triple_hash(service_id, &user.0, &setter.0);

        let indefinite = match &mut self.service_id_to_user_to_setter_to_indefinite_whitelist_status
        {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };

        let whitelist = match &mut self.service_id_to_user_to_whitelist_status {
            ReadWrite::ReadOnly(_) => panic!("wrong privilege"),
            ReadWrite::Write(m) => m,
        };

        let mut indefinite_count = whitelist
            .get(&user_hash)
            .map(|f| U256::from_big_endian(&f.indefinite_whitelist_count))
            .unwrap_or_else(|| U256::from(0u32));

        let indefinite_status = indefinite.get(&setter_hash).unwrap_or(false);
        if indefinite_status {
            indefinite.remove(&setter_hash);
            indefinite.insert(&setter_hash, &false);

            let mut whitelist_status = whitelist.remove(&user_hash).unwrap_or_default();
            indefinite_count = indefinite_count.sub(U256::from(1u8));
            whitelist_status.indefinite_whitelist_count = Bytes32::from(&indefinite_count);
            whitelist.insert(&user_hash, &whitelist_status);
            (true, indefinite_count)
        } else {
            (false, indefinite_count)
        }
    }
}

impl<'a, Access: AccessControlRegistry<Address = Address>> WhitelistRolesWithManager
    for NearWhitelist<'a, Access>
{
    fn has_whitelist_expiration_extender_role_or_is_manager(
        &self,
        account: &Self::Address,
    ) -> bool {
        self.manager() == account
            || self
                .access
                .has_role(&self.whitelist_expiration_extender_role(), account)
    }

    fn has_indefinite_whitelister_role_or_is_manager(&self, account: &Self::Address) -> bool {
        self.manager() == account
            || self
                .access
                .has_role(&self.indefinite_whitelister_role(), account)
    }

    fn has_whitelist_expiration_setter_role_or_is_manager(&self, account: &Self::Address) -> bool {
        self.manager() == account
            || self
                .access
                .has_role(&self.whitelist_expiration_setter_role(), account)
    }
}

impl<'a, Access: AccessControlRegistry<Address = Address>> WhitelistRoles
    for NearWhitelist<'a, Access>
{
}

impl<'a, Access: AccessControlRegistry<Address = Address>> AccessControlRegistryAdminnedWithManager
    for NearWhitelist<'a, Access>
{
    type Address = Address;

    fn manager(&self) -> &Self::Address {
        self.access.manager()
    }

    fn admin_role_description(&self) -> String {
        self.access.admin_role_description()
    }

    fn admin_role_description_hash(&self) -> Bytes32 {
        self.access.admin_role_description_hash()
    }

    fn admin_role(&self) -> Bytes32 {
        self.access.admin_role()
    }
}

impl<'a, Access: AccessControlRegistry<Address = Address>> WhitelistWithManager
    for NearWhitelist<'a, Access>
{
    fn extend_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        expiration_timestamp: u64,
    ) {
        near_check_result(ensure!(
            self.has_whitelist_expiration_extender_role_or_is_manager(&msg_sender()),
            Error::AccessDenied
        ));
        near_check_result(ensure!(!service_id.is_zero(), Error::ServiceIdZero));
        near_check_result(ensure!(!user.is_zero(), Error::UserAddressZero));
        Whitelist::extend_whitelist_expiration(self, service_id, user, expiration_timestamp);
    }

    fn set_whitelist_expiration(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        expiration_timestamp: u64,
    ) {
        near_check_result(ensure!(
            self.has_whitelist_expiration_setter_role_or_is_manager(&msg_sender()),
            Error::AccessDenied
        ));

        near_check_result(ensure!(!service_id.is_zero(), Error::ServiceIdZero));
        near_check_result(ensure!(!user.is_zero(), Error::UserAddressZero));

        Whitelist::set_whitelist_expiration(self, service_id, user, expiration_timestamp)
    }

    fn set_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        status: bool,
    ) -> U256 {
        near_check_result(ensure!(
            self.has_indefinite_whitelister_role_or_is_manager(&msg_sender()),
            Error::AccessDenied
        ));

        near_check_result(ensure!(!service_id.is_zero(), Error::ServiceIdZero));
        near_check_result(ensure!(!user.is_zero(), Error::UserAddressZero));

        Whitelist::set_indefinite_whitelist_status(self, service_id, user, status)
    }

    fn revoke_indefinite_whitelist_status(
        &mut self,
        service_id: &Bytes32,
        user: &<Self as Whitelist>::Address,
        setter: &<Self as Whitelist>::Address,
    ) -> (bool, U256) {
        near_check_result(ensure!(
            !self.has_indefinite_whitelister_role_or_is_manager(setter),
            Error::SetterCanSetIndefiniteStatus
        ));
        Whitelist::revoke_indefinite_whitelist_status(self, service_id, user, setter)
    }
}

'''
'''--- solana/beacon-server/Anchor.toml ---
[features]
seeds = false
[programs.localnet]
beacon_server = "FRoo7m8Sf6ZAirGgnn3KopQymDtujWx818kcnRxzi23b"

[registry]
url = "https://anchor.projectserum.com"

[provider]
cluster = "localnet"
wallet = "~/.config/solana/id.json"

[scripts]
test = "yarn run test"

'''
'''--- solana/beacon-server/Cargo.toml ---
[workspace]
members = [
    "programs/*"
]

'''
'''--- solana/beacon-server/migrations/deploy.ts ---
// Migrations are an early feature. Currently, they're nothing more than this
// single deploy script that's invoked from the CLI, injecting a provider
// configured from the workspace's Anchor.toml.

const anchor = require("@project-serum/anchor");

module.exports = async function (provider) {
  // Configure client to use the provider.
  anchor.setProvider(provider);

  // Add your deploy script here.
};

'''
'''--- solana/beacon-server/package.json ---
{
    "dependencies": {
        "@project-serum/anchor": "^0.23.0",
        "ethers": "^5.6.2"
    },
    "scripts": {
        "test": "mocha -r ts-node/register -t 10000 tests/**/*.spec.ts"
    },
    "devDependencies": {
        "@types/chai": "^4.3.0",
        "@types/mocha": "^9.0.0",
        "chai": "^4.3.4",
        "mocha": "^9.0.3",
        "ts-node": "^10.8.1",
        "typescript": "^4.3.5"
    }
}

'''
'''--- solana/beacon-server/programs/beacon-server/Cargo.toml ---
[package]
name = "beacon-server"
version = "0.0.1"
description = "Created with Anchor"
edition = "2021"

[lib]
crate-type = ["cdylib", "lib"]
name = "beacon_server"

[features]
no-entrypoint = []
no-idl = []
no-log-ix-name = []
cpi = ["no-entrypoint"]
default = []

[dependencies]
anchor-lang = { version = "0.23.0", features = ["init-if-needed"] }
api3-common = { version = "0.0.1", path = "../../../../common", features = ["dummy"] }
hex = "0.4.3"

'''
'''--- solana/beacon-server/programs/beacon-server/Xargo.toml ---
[target.bpfel-unknown-unknown.dependencies.std]
features = []

'''
'''--- solana/beacon-server/programs/beacon-server/src/lib.rs ---
mod utils;

use crate::utils::{DatapointHashMap, DummySignatureManger, NameHashHashMap, SolanaClock};
use anchor_lang::{prelude::borsh::maybestd::collections::HashMap, prelude::*};
use api3_common::{abi::U256, derive_beacon_id, ensure, process_beacon_update, DataPoint};

declare_id!("FRoo7m8Sf6ZAirGgnn3KopQymDtujWx818kcnRxzi23b");

// a bunch of error codes
const ERROR_INVALID_BEACON_ID_KEY: u64 = 1u64;
const ERROR_INVALID_SYSVAR_INSTRUCTIONS_KEY: u64 = 2u64;
const ERROR_SIGNATURES_NOT_VALIDATED: u64 = 3u64;
const ERROR_SIGNATURES_MORE_THAN_DATA: u64 = 4u64;
const ERROR_NOT_ENOUGH_ACCOUNT: u64 = 5u64;
const ERROR_INVALID_NAME_HASH: u64 = 6u64;
const ERROR_DATA_LENGTH_NOT_MATCH: u64 = 7u64;
const ERROR_INVALID_DERIVED_DAPI_ID_KEY: u64 = 8u64;
const ERROR_INVALID_SYSTEM_PROGRAM_ID: u64 = 9u64;

fn map_error(e: api3_common::Error) -> anchor_lang::error::Error {
    anchor_lang::error::Error::from(ProgramError::Custom(e.into()))
}

/// The DAPI server implementation.
///
/// Note that for solana there is no need to perform signature verification as we are
/// asking the chain to perform signature verification for us. What's required is to check
/// the results of the verification are correct.
///
/// All the read related functions can be implemented in client.
#[program]
pub mod beacon_server {
    use super::*;

    /// Updates a Beacon using data signed by the respective Airnode,
    /// without requiring a request or subscription.
    ///
    ///
    /// `datapoint_key` The PDA of the datapoint account
    /// `template_id` Template ID
    /// `timestamp` Timestamp used in the signature
    /// `data` Response data (an `int256` encoded in contract ABI)
    pub fn update_beacon_with_signed_data(
        ctx: Context<DataPointAccount>,
        datapoint_key: [u8; 32],
        template_id: [u8; 32],
        timestamp: [u8; 32],
        data: Vec<u8>,
    ) -> Result<()> {
        let airnode = ctx.accounts.user.key.to_bytes().to_vec();
        let beacon_id = derive_beacon_id(airnode, template_id);
        ensure!(
            beacon_id == datapoint_key,
            Error::from(ProgramError::from(ERROR_INVALID_BEACON_ID_KEY))
        )?;
        utils::check_sys_program(ctx.accounts.system_program.key)?;

        let timestamp = U256::from(&timestamp);
        let mut s = DatapointHashMap::new(
            vec![(beacon_id, &mut ctx.accounts.datapoint)],
            HashMap::new(),
        );
        process_beacon_update(&mut s, beacon_id, timestamp, data).map_err(map_error)?;

        Ok(())
    }

    /// Update a new beacon data point with signed data.
    /// The beacon id is used as the seed to generate pda for the Beacon data account.
    pub fn update_dapi_with_beacons(
        ctx: Context<DataPointAccount>,
        datapoint_key: [u8; 32],
        beacon_ids: Vec<[u8; 32]>,
    ) -> Result<()> {
        assert!(
            !ctx.remaining_accounts.is_empty(),
            "must provide beacon accounts"
        );
        utils::check_sys_program(ctx.accounts.system_program.key)?;

        let beacon_id_tuples = ctx
            .remaining_accounts
            .iter()
            .map(|item| -> Result<(Pubkey, Account<WrappedDataPoint>)> {
                Account::try_from_unchecked(item).map(|i| (*item.key, i))
            })
            .collect::<Result<Vec<(Pubkey, Account<WrappedDataPoint>)>>>()?;

        let keys = beacon_id_tuples.iter().map(|a| a.0).collect::<Vec<_>>();
        utils::check_beacon_ids(&beacon_ids, &keys, ctx.program_id)?;
        utils::check_dapi_id(&datapoint_key, &beacon_ids)?;

        // Step 2. Prepare the accounts
        let mut idx = 0;
        let write = vec![(datapoint_key, &mut ctx.accounts.datapoint)];
        let mut read = HashMap::new();
        for (_, wrapped) in beacon_id_tuples {
            let datapoint =
                DataPoint::from(wrapped.raw_datapoint.clone()).expect("cannot parse datapoint");
            read.insert(beacon_ids[idx], datapoint);
            idx += 1;
        }

        ensure!(
            idx == beacon_ids.len(),
            Error::from(ProgramError::from(ERROR_NOT_ENOUGH_ACCOUNT))
        )?;

        let mut s = DatapointHashMap::new(write, read);
        api3_common::update_dapi_with_beacons(&mut s, &beacon_ids).map_err(map_error)?;
        Ok(())
    }

    /// Updates a dAPI using data signed by the respective Airnodes
    /// without requiring a request or subscription. The beacons for which the
    /// signature is omitted will be read from the storage.
    pub fn update_dapi_with_signed_data<'b>(
        ctx: Context<'_, '_, '_, 'b, DataPointAccount<'b>>,
        datapoint_key: [u8; 32],
        airnodes: Vec<Vec<u8>>,
        beacon_ids: Vec<[u8; 32]>,
        template_ids: Vec<[u8; 32]>,
        timestamps: Vec<[u8; 32]>,
        data: Vec<Vec<u8>>,
    ) -> Result<()> {
        // Step 1. Check signature
        let account_iter = &mut ctx.remaining_accounts.iter();
        let instruction_acc = account_iter
            .next()
            .ok_or_else(|| Error::from(ProgramError::from(ERROR_NOT_ENOUGH_ACCOUNT)))?;
        let sig_count = ensure_batch_signed(instruction_acc, &data)?;

        utils::check_sys_program(ctx.accounts.system_program.key)?;

        // Step 2. Check the beacon id accounts are correct
        let mut idx = 0usize;
        let keys = account_iter
            .clone()
            .map(|item| -> Pubkey {
                idx += 1;
                *item.key
            })
            .collect::<Vec<Pubkey>>();

        utils::check_beacon_ids(&beacon_ids, &keys, ctx.program_id)?;
        utils::check_dapi_id(&datapoint_key, &beacon_ids)?;

        // Step 3. Extract and prepare the data for beacon ids from storage
        let mut idx = 0;
        let write = vec![(datapoint_key, &mut ctx.accounts.datapoint)];
        let mut read = HashMap::new();
        for account in account_iter {
            let beacon_offset = idx + sig_count;
            let wrapped: Account<WrappedDataPoint> = Account::try_from(account)?;
            let datapoint =
                DataPoint::from(wrapped.raw_datapoint.clone()).expect("cannot parse datapoint");
            read.insert(beacon_ids[beacon_offset], datapoint);
            idx += 1;
        }
        idx += sig_count;

        ensure!(
            idx == beacon_ids.len(),
            Error::from(ProgramError::from(ERROR_NOT_ENOUGH_ACCOUNT))
        )?;

        // Step 4. Execute update_dapi_with_signed_data process
        let mut s = DatapointHashMap::new(write, read);
        let clock = SolanaClock::new(Clock::get().unwrap().unix_timestamp as u32);

        let mut sig = (0..sig_count).into_iter().map(|_| vec![0]).collect::<Vec<_>>();
        (sig_count..idx).into_iter().for_each(|_| sig.push(vec![]));
        api3_common::update_dapi_with_signed_data::<_, DummySignatureManger, _>(
            &mut s,
            &clock,
            airnodes,
            template_ids,
            timestamps,
            data,
            sig,
        )
        .map_err(map_error)?;
        Ok(())
    }

    /// Sets the data point ID the name points to
    /// While a data point ID refers to a specific Beacon or dAPI, names
    /// provide a more abstract interface for convenience. This means a name
    /// that was pointing at a Beacon can be pointed to a dAPI, then another
    /// dAPI, etc.
    pub fn set_name(
        ctx: Context<DataPointIdAccount>,
        name_hash: [u8; 32],
        name: [u8; 32],
        datapoint_id: [u8; 32],
    ) -> Result<()> {
        let access = api3_common::dummy::DummyAccess::default();
        let msg_sender = ctx.accounts.user.key.to_bytes();

        utils::check_sys_program(ctx.accounts.system_program.key)?;
        utils::check_name_hash(&name, &name_hash)?;

        let mut storage = NameHashHashMap::new(vec![(name_hash, &mut ctx.accounts.hash)]);
        api3_common::set_name(name, datapoint_id, &msg_sender, &access, &mut storage)
            .map_err(map_error)
    }
}

#[derive(Accounts)]
#[instruction(name_hash: [u8; 32])]
pub struct DataPointIdAccount<'info> {
    #[account(
        init_if_needed,
        payer = user,
        space = 8 + 33,
        seeds = [b"hashed-name", name_hash.as_ref()],
        bump
    )]
    pub hash: Account<'info, WrappedDataPointId>,
    #[account(mut)]
    pub user: Signer<'info>,
    pub system_program: Program<'info, System>,
}

#[derive(Accounts)]
#[instruction(datapoint_key: [u8; 32])]
pub struct DataPointAccount<'info> {
    #[account(
        init_if_needed,
        payer = user,
        space = 8 + 41,
        seeds = [b"datapoint", datapoint_key.as_ref()],
        bump
    )]
    pub datapoint: Account<'info, WrappedDataPoint>,
    #[account(mut)]
    pub user: Signer<'info>,
    pub system_program: Program<'info, System>,
}

#[account]
pub struct WrappedDataPoint {
    pub raw_datapoint: Vec<u8>,
    pub bump: u8,
}

#[account]
pub struct WrappedDataPointId {
    pub datapoint_id: [u8; 32],
    pub bump: u8,
}

fn ensure_batch_signed(instruction_acc: &AccountInfo, data: &[Vec<u8>]) -> Result<usize> {
    ensure!(
        *instruction_acc.key == anchor_lang::solana_program::sysvar::instructions::id(),
        Error::from(ProgramError::from(ERROR_INVALID_SYSVAR_INSTRUCTIONS_KEY))
    )?;

    let r = anchor_lang::solana_program::sysvar::instructions::load_instruction_at_checked(
        0,
        instruction_acc,
    )?;
    ensure!(
        r.program_id == anchor_lang::solana_program::ed25519_program::id(),
        Error::from(ProgramError::from(ERROR_SIGNATURES_NOT_VALIDATED))
    )?;

    let sig_count = r.data[0] as usize;
    ensure!(
        sig_count <= data.len(),
        Error::from(ProgramError::from(ERROR_SIGNATURES_MORE_THAN_DATA))
    )?;

    Ok(sig_count)
}

'''
'''--- solana/beacon-server/programs/beacon-server/src/utils.rs ---
use crate::{
    WrappedDataPoint, WrappedDataPointId, ERROR_DATA_LENGTH_NOT_MATCH, ERROR_INVALID_BEACON_ID_KEY,
    ERROR_INVALID_DERIVED_DAPI_ID_KEY, ERROR_INVALID_NAME_HASH, ERROR_INVALID_SYSTEM_PROGRAM_ID,
};
use anchor_lang::accounts::account::Account;
use anchor_lang::prelude::borsh::maybestd::collections::HashMap;
use anchor_lang::prelude::*;
use api3_common::abi::Token;
use api3_common::{
    ensure, keccak_packed, Bytes32, DataPoint, SignatureManger, Storage, TimestampChecker,
};

const DATAPOINT_SEED: &str = "datapoint";

pub type NameHashAccountRef<'info> = Account<'info, WrappedDataPointId>;
pub(crate) struct NameHashHashMap<'info, 'account> {
    write: HashMap<Bytes32, &'account mut NameHashAccountRef<'info>>,
}

impl<'info, 'account> NameHashHashMap<'info, 'account> {
    pub fn new(accounts: Vec<(Bytes32, &'account mut NameHashAccountRef<'info>)>) -> Self {
        let mut write = HashMap::new();
        for (key, aref) in accounts {
            write.insert(key, aref);
        }
        Self { write }
    }
}

impl<'info, 'account> Storage<Bytes32> for NameHashHashMap<'info, 'account> {
    fn get(&self, k: &Bytes32) -> Option<Bytes32> {
        self.write.get(k).map(|a| a.datapoint_id)
    }

    fn store(&mut self, k: Bytes32, datapoint_id: Bytes32) {
        let a = self.write.get_mut(&k).expect("cannot load from datapoint");
        (*a).datapoint_id = datapoint_id;
        // panic!("datapoint id: {:?}", a.datapoint_id);
    }
}

pub type DatapointAccountRef<'info> = Account<'info, WrappedDataPoint>;
pub(crate) struct DatapointHashMap<'info, 'account> {
    write: HashMap<Bytes32, &'account mut DatapointAccountRef<'info>>,
    read: HashMap<Bytes32, DataPoint>,
}

impl<'info, 'account> DatapointHashMap<'info, 'account> {
    pub fn new(
        accounts: Vec<(Bytes32, &'account mut DatapointAccountRef<'info>)>,
        read: HashMap<Bytes32, DataPoint>,
    ) -> Self {
        let mut write = HashMap::new();
        for (key, aref) in accounts {
            write.insert(key, aref);
        }
        Self { write, read }
    }
}

impl<'info, 'account> Storage<DataPoint> for DatapointHashMap<'info, 'account> {
    fn get(&self, k: &Bytes32) -> Option<DataPoint> {
        match self.read.get(k) {
            Some(d) => Some(d.clone()),
            None => self.write.get(k).map(|a| {
                if a.raw_datapoint.is_empty() {
                    DataPoint::default()
                } else {
                    DataPoint::from(a.raw_datapoint.clone()).expect("cannot load datapoint")
                }
            }),
        }
    }

    fn store(&mut self, k: Bytes32, datapoint: DataPoint) {
        let a = self.write.get_mut(&k).expect("cannot load from datapoint");
        (*a).raw_datapoint = Vec::from(datapoint);
    }
}

pub(crate) struct SolanaClock {
    current_timestamp: u32,
}

impl SolanaClock {
    pub fn new(current_timestamp: u32) -> Self {
        Self { current_timestamp }
    }
}

impl TimestampChecker for SolanaClock {
    fn current_timestamp(&self) -> u32 {
        self.current_timestamp
    }
}

/// The dummy signature checker for solana. Reason we don't really need signature validation
/// here is because solana has done this for us. The implementation should have asked solana
/// to validate the signatures before hand. All this needs to do is just tracking the number
/// of signatures
pub(crate) struct DummySignatureManger;
impl SignatureManger for DummySignatureManger {
    /// Solana should have already verified the signature for us, return true by default
    fn verify(_key: &[u8], _message: &[u8], _signature: &[u8]) -> bool {
        true
    }
}

pub(crate) fn check_beacon_ids(
    beacon_ids: &[Bytes32],
    pdas: &[Pubkey],
    program_id: &Pubkey,
) -> Result<()> {
    ensure!(
        beacon_ids.len() >= pdas.len(),
        Error::from(ProgramError::from(ERROR_DATA_LENGTH_NOT_MATCH))
    )?;
    let diff = beacon_ids.len() - pdas.len();
    for i in 0..pdas.len() {
        ensure!(
            derive_datapoint_pubkey(&beacon_ids[diff + i], program_id) == pdas[i],
            Error::from(ProgramError::from(ERROR_INVALID_BEACON_ID_KEY))
        )?;
    }
    Ok(())
}

/// Checks the dapis_id passed as parameter is actually derived from beacon_ids.
pub(crate) fn check_dapi_id(dapi_id: &Bytes32, beacon_ids: &[Bytes32]) -> Result<()> {
    ensure!(
        *dapi_id == api3_common::derive_dapi_id(beacon_ids),
        Error::from(ProgramError::from(ERROR_INVALID_DERIVED_DAPI_ID_KEY))
    )?;
    Ok(())
}

/// Checks the dapis_id passed as parameter is actually derived from beacon_ids.
pub(crate) fn check_name_hash(name: &Bytes32, name_hash: &Bytes32) -> Result<()> {
    let derived_hash = keccak_packed(&[Token::FixedBytes(name.to_vec())]);
    ensure!(
        *name_hash == derived_hash,
        Error::from(ProgramError::from(ERROR_INVALID_NAME_HASH))
    )
}

pub(crate) fn check_sys_program(program_id: &Pubkey) -> Result<()> {
    ensure!(
        *program_id == anchor_lang::solana_program::system_program::id(),
        Error::from(ProgramError::from(ERROR_INVALID_SYSTEM_PROGRAM_ID))
    )
}

fn derive_datapoint_pubkey(datapoint_key: &[u8], program_id: &Pubkey) -> Pubkey {
    let (key, _) =
        Pubkey::find_program_address(&[DATAPOINT_SEED.as_bytes(), datapoint_key], program_id);
    key
}

'''
'''--- solana/beacon-server/tests/beacon-server.spec.ts ---
import * as anchor from "@project-serum/anchor";
import {SendTransactionError} from "@solana/web3.js";
import { expect } from "chai";
import nacl from 'tweetnacl';
import * as fs from "fs";
import { 
  bufferU64BE, getRandomInt, median, prepareMessage, relayTxn
} from "./utils";
import { DapiClient } from "./client";

const delay = ms => new Promise(resolve => setTimeout(resolve, ms))

describe("beacon-server", () => {
  // Configure the client to use the local cluster.
  const provider = anchor.Provider.env();
  anchor.setProvider(provider);

  const idl = JSON.parse(
    fs.readFileSync("./target/idl/beacon_server.json", "utf8")
  );
  const programId = new anchor.web3.PublicKey("FRoo7m8Sf6ZAirGgnn3KopQymDtujWx818kcnRxzi23b");
  const program = new anchor.Program(idl, programId);

  const airnode1 = anchor.web3.Keypair.generate();
  const airnode2 = anchor.web3.Keypair.generate();
  const airnode3 = anchor.web3.Keypair.generate();
  const airnode4 = anchor.web3.Keypair.generate();
  const messageRelayer = anchor.web3.Keypair.generate();

  // define all the data
  const templateId1 = 1;
  const timestamp1 = Math.floor(Date.now() / 1000);    
  const data1 = getRandomInt(10000000);

  const templateId2 = 2;
  const timestamp2 = Math.floor(Date.now() / 1000) - getRandomInt(500);
  const data2 = getRandomInt(10000000);

  const templateId3 = 3;
  let timestamp3 = Math.floor(Date.now() / 1000) - getRandomInt(500);
  let data3 = getRandomInt(10000000);

  const templateId4 = 4;
  const timestamp4 = Math.floor(Date.now() / 1000) - getRandomInt(500);
  const data4 = getRandomInt(10000000);

  const name = bufferU64BE(123);
  
  const dapiClient = new DapiClient(program, provider);

  before(async () => {
    // fund the accounts one shot
    await provider.connection.confirmTransaction(await provider.connection.requestAirdrop(airnode1.publicKey, anchor.web3.LAMPORTS_PER_SOL));
    await provider.connection.confirmTransaction(await provider.connection.requestAirdrop(airnode2.publicKey, anchor.web3.LAMPORTS_PER_SOL));
    await provider.connection.confirmTransaction(await provider.connection.requestAirdrop(airnode3.publicKey, anchor.web3.LAMPORTS_PER_SOL));
    await provider.connection.confirmTransaction(await provider.connection.requestAirdrop(airnode4.publicKey, anchor.web3.LAMPORTS_PER_SOL));
    await provider.connection.confirmTransaction(await provider.connection.requestAirdrop(messageRelayer.publicKey, anchor.web3.LAMPORTS_PER_SOL));
  }) 

  describe("update beacon with signed data", () => {
    it("should work - template 3", async () => {
      // 1. Airnode create the txn    
      const [airnodeSignature, airnodeTxn] = await dapiClient.newUpdateBeaconWithSignedDataTxn(
        templateId3,
        timestamp3,
        data3,
        airnode3,
        messageRelayer.publicKey
      );
  
      // 2. Relay the transaction
      const offlineTxn = await relayTxn(airnodeTxn, airnodeSignature, airnode3.publicKey, messageRelayer);
  
      // 3. Send transaction
      const signature = await provider.connection.sendRawTransaction(offlineTxn);

      await provider.connection.confirmTransaction(signature)
  
      // Check test response
      const beaconId = dapiClient.deriveBeaconId(airnode3.publicKey.toBytes(), templateId3);
      const datapoint = await dapiClient.readWithDataPointId(beaconId);
  
      // construct expected
      expect(datapoint.value).to.deep.eq(data3);
      expect(datapoint.timestamp).to.deep.eq(timestamp3);
    });

    it("should work - template 4", async () => {
      // Create the datapoint 4 
      const [airnodeSignature, airnodeTxn] =  await dapiClient.newUpdateBeaconWithSignedDataTxn(
        templateId4,
        timestamp4,
        data4,
        airnode4,
        messageRelayer.publicKey
      );
      const offlineTxn = await relayTxn(airnodeTxn, airnodeSignature, airnode4.publicKey, messageRelayer);
      const signature = await provider.connection.sendRawTransaction(offlineTxn);
  
      // wait for the transaction to take effect
      await provider.connection.confirmTransaction(signature)

      const beaconId4 = dapiClient.deriveBeaconId(airnode4.publicKey.toBytes(), templateId4);
      const datapoint = await dapiClient.readWithDataPointId(beaconId4);
      expect(datapoint.value).to.deep.eq(data4);
      expect(datapoint.timestamp).to.deep.eq(timestamp4);

      // now test updateDapiWithBeacons
      const beaconId3 = dapiClient.deriveBeaconId(airnode3.publicKey.toBytes(), templateId3);
      const beaconIds = [beaconId3, beaconId4];
      const dataPointId = dapiClient.deriveDapiId(beaconIds);
      
      await dapiClient.updateDapiWithBeacons(beaconIds, messageRelayer);
      const dapi = await dapiClient.readWithDataPointId(dataPointId);
      expect(dapi.timestamp).to.eq(Math.floor((timestamp3 + timestamp4) / 2));
      expect(dapi.value).to.eq(Math.floor((data3 + data4) / 2));
    });

    it("overwrite old data", async () => {
      // 1. Airnode create the txn
      timestamp3 = Math.floor(Date.now() / 1000) + getRandomInt(100);
      data3 = getRandomInt(10000000);
      const [airnodeSignature, airnodeTxn] = await dapiClient.newUpdateBeaconWithSignedDataTxn(
        templateId3,
        timestamp3,
        data3,
        airnode3,
        messageRelayer.publicKey
      );
  
      // 2. Relay the transaction
      const offlineTxn = await relayTxn(airnodeTxn, airnodeSignature, airnode3.publicKey, messageRelayer);
  
      // 3. Send transaction
      const signature = await provider.connection.sendRawTransaction(offlineTxn);
  
      // wait for the transaction to take effect
      await provider.connection.confirmTransaction(signature)
  
      // Check test response
      const beaconId = dapiClient.deriveBeaconId(airnode3.publicKey.toBytes(), templateId3);
      const datapoint = await dapiClient.readWithDataPointId(beaconId);
  
      // construct expected
      expect(datapoint.value).to.deep.eq(data3);
      expect(datapoint.timestamp).to.deep.eq(timestamp3);
    });

    it("invalid signature", async () => {
      // 1. Airnode create the txn    
      const [_, airnodeTxn] = await dapiClient.newUpdateBeaconWithSignedDataTxn(
        templateId3,
        timestamp3,
        data3,
        airnode3,
        messageRelayer.publicKey
      );
  
      // 2. Relay the transaction with wrong signature
      try {
        await relayTxn(airnodeTxn, Buffer.allocUnsafe(32), airnode3.publicKey, messageRelayer);
        expect(false, "should not make it here");
      } catch (e) {
        expect(true, "should fail");
      }
    });
  });

  describe("update Dapi with signed data", async () => {
    it("should work", async () => {
      // Step 1. Airnode1 create the data
      const message1 = prepareMessage(templateId1, timestamp1, data1);
      const sig1 = nacl.sign.detached(message1, airnode1.secretKey);
  
      // Step 2. Airnode2 create the data
      const message2 = prepareMessage(templateId2, timestamp2, data2);
      const sig2 = nacl.sign.detached(message2, airnode2.secretKey);
      
      const newTimestamp = timestamp3 + 10000;
      const newData = data3 + 10;

      await dapiClient.updateDapiWithSignedData(
        [airnode1.publicKey, airnode2.publicKey, airnode3.publicKey],
        [templateId1, templateId2, templateId3],
        [timestamp1, timestamp2, newTimestamp],
        [data1, data2, newData],
        [
          { publicKey: airnode1.publicKey.toBytes(), message: message1, signature: sig1 },
          { publicKey: airnode2.publicKey.toBytes(), message: message2, signature: sig2 }
        ],
        messageRelayer
      );

      const beaconId1 = dapiClient.deriveBeaconId(airnode1.publicKey.toBytes(), templateId1);
      const beaconId2 = dapiClient.deriveBeaconId(airnode2.publicKey.toBytes(), templateId2);
      const beaconId3 = dapiClient.deriveBeaconId(airnode3.publicKey.toBytes(), templateId3);
      const beaconIds = [beaconId1, beaconId2, beaconId3];
      const dapi = dapiClient.deriveDapiId(beaconIds);
      
      const datapoint = await dapiClient.readWithDataPointId(dapi);
      // newData and newTimestamp are not reflected here
      expect(datapoint.value).to.eq(median([data1, data2, data3]));
      expect(datapoint.timestamp).to.eq(Math.floor((timestamp1 + timestamp2 + timestamp3) / 3));
    });

    it("wrong signature", async () => {
      // Step 1. Airnode1 create the data
      const message1 = prepareMessage(templateId1, timestamp1, data1);
  
      // Step 2. Airnode2 create the data
      const message2 = prepareMessage(templateId2, timestamp2, data2);
      const sig2 = nacl.sign.detached(message2, airnode2.secretKey);
            
      try {
        await dapiClient.updateDapiWithSignedData(
          [airnode1.publicKey, airnode2.publicKey, airnode3.publicKey],
          [templateId1, templateId2, templateId3],
          [timestamp1, timestamp2, timestamp3],
          [data1, data2, data1],
          [
            { publicKey: airnode1.publicKey.toBytes(), message: message1, signature: Buffer.allocUnsafe(sig2.length) },
            { publicKey: airnode2.publicKey.toBytes(), message: message2, signature: sig2 }
          ],
          messageRelayer
        );
        expect(false, "should not be here");
      } catch (err) {
        expect(err).to.be.instanceOf(SendTransactionError);
        expect(err.message).to.be.equal("failed to send transaction: Transaction precompile verification failure InvalidAccountIndex")
      }
    });
  });

  describe("setName", () => {
    it("should work", async () => {
      const beaconId = dapiClient.deriveBeaconId(airnode3.publicKey.toBytes(), templateId3);

      const signature = await dapiClient.setName(name, beaconId, provider.wallet.publicKey);
  
      await provider.connection.confirmTransaction(signature);
  
      const datapointId = await dapiClient.nameToDataPointId(name);
      expect([...beaconId]).to.deep.eq([...datapointId]);

      const datapoint = await dapiClient.readWithName(name);
      expect(datapoint.timestamp).to.eq(timestamp3);
      expect(datapoint.value).to.eq(data3);
    });
  });

  describe("deriveDApiId", () => {
    it("should work", async () => {
      const publicKey1 = [
        6,  78, 207,   9,  71, 108, 155, 104,
        161, 183, 128,  28, 210, 228,  71, 204,
        102, 174, 178, 254, 233,  61,  63,  16,
        76, 210,  51, 189,  74,  91,  76, 129
      ];
      const publicKey2 = [
        5,  78, 207,   9,  71, 108, 155, 104,
        3, 183, 4,  28, 12, 33,  71, 204,
        102, 174, 178, 53, 25,  61,  63,  16,
        76, 210,  51, 189,  74,  91,  76, 129
      ];
      const beaconId1 = dapiClient.deriveBeaconId(Buffer.from(publicKey1), 1);
      const beaconId2 = dapiClient.deriveBeaconId(Buffer.from(publicKey2), 1);
      const dapiId = dapiClient.deriveDapiId([beaconId1, beaconId2]);
      const expected = [
        110,  19,  32, 193, 151,  76, 132,
        243, 209, 249, 115,  27, 118, 162,
         62, 179, 168, 118, 111, 106, 159,
        213, 112, 120, 131, 222, 247,  10,
         29,  52, 167,  73
      ];
      expect([...dapiId]).to.deep.eq(expected);
    });
  });

  describe("deriveBeaconId", () => {
    it("should work", async () => {
      const publicKey = [
        6,  78, 207,   9,  71, 108, 155, 104,
        161, 183, 128,  28, 210, 228,  71, 204,
        102, 174, 178, 254, 233,  61,  63,  16,
        76, 210,  51, 189,  74,  91,  76, 129
      ];
      const beaconId = dapiClient.deriveBeaconId(Buffer.from(publicKey), 1);
      const expected = [
        29, 240, 119, 252, 172, 145, 146, 209,
       118, 116, 187,   7,  80, 114, 122,  33,
        67, 238, 197, 149,  19, 223, 191, 129,
        96,  40, 222,   6, 132,  43,  31, 189
      ];
      expect([...beaconId]).to.deep.eq(expected);
    });
  });
});

'''
'''--- solana/beacon-server/tests/client.ts ---
import * as anchor from "@project-serum/anchor";
import { 
    bufferU64BE, Datapoint, deriveBeaconId, deriveDApiId,
    deriveDatapointPDA, deriveNameHashPDA, encodeData, keccak256Packed
} from "./utils";
import nacl from 'tweetnacl';
import { createInstructionWithPublicKey, SignatureParam } from "./sig";

export class DapiClient {
    private program: anchor.Program;
    private provider: anchor.Provider;

    constructor(program: anchor.Program, provider: anchor.Provider) {
        this.program = program;
        this.provider = provider;
    }

    /**
     * Reads the data point with ID
     * @param datapointId The datapoint id to read
     * @returns The Datapoint class
     */
    public async readWithDataPointId(datapointId: Buffer): Promise<Datapoint> {
        const pda = await deriveDatapointPDA(datapointId, this.program.programId);
        const wrappedDataPoint = await this.program.account.wrappedDataPoint.fetch(pda);
        return Datapoint.deserialize(wrappedDataPoint.rawDatapoint);
    }

    /**
     * Create a new offline UpdateBeaconWithSignedData transasction
     * 
     * @param templateID 
     * @param timestamp 
     * @param data
     * @param storageFunderKey 
     * @param txnRelayerKey 
     * @returns The serialized offline transaction buffer
     */
    public async newUpdateBeaconWithSignedDataTxn(
        templateID: number,
        timestamp: number,
        data: number,
        storageFunder: anchor.web3.Keypair,
        txnRelayerKey: anchor.web3.PublicKey,
    ): Promise<[Uint8Array, Buffer]> {
        const beaconId = deriveBeaconId(storageFunder.publicKey.toBytes(), templateID);
        const beaconIdPDA = await deriveDatapointPDA(beaconId, this.program.programId);
    
        const bufferedTimestamp = bufferU64BE(timestamp);
        const encodedData = encodeData(data);
      
        const method = this.program.instruction.updateBeaconWithSignedData(
          beaconId,
          bufferU64BE(templateID),
          bufferedTimestamp,
          encodedData,
          {
            accounts: {
              datapoint: beaconIdPDA,
              user: storageFunder.publicKey,
              systemProgram: anchor.web3.SystemProgram.programId,
            }
          }
        );
        
        const tx = new anchor.web3.Transaction().add(method);
        tx.recentBlockhash = (await this.program.provider.connection.getLatestBlockhash()).blockhash;
        tx.feePayer = txnRelayerKey;
      
        const rawTxn = tx.serializeMessage();
        const signature = nacl.sign.detached(rawTxn, storageFunder.secretKey);
        return [signature, rawTxn];
    }

    public async updateDapiWithBeacons(beaconIds: Buffer[], sender: anchor.web3.Keypair) {
      const dataPointId = deriveDApiId(beaconIds);
      const dapiPDA = await deriveDatapointPDA(dataPointId, this.program.programId);

      const remainingAccounts = [];
      for (const b of beaconIds) {
        remainingAccounts.push(
          { isSigner: false, isWritable: false, pubkey: await deriveDatapointPDA(b, this.program.programId) }
        );
      }
      const updateInstruction = await this.program.instruction.updateDapiWithBeacons(
        dataPointId,
        beaconIds,
        {
          accounts: {
            datapoint: dapiPDA,
            user: sender.publicKey,
            systemProgram: anchor.web3.SystemProgram.programId,
          },
          remainingAccounts
        }
      );
  
      const tx = new anchor.web3.Transaction();
      tx.add(updateInstruction);
      await anchor.web3.sendAndConfirmTransaction(
        this.provider.connection,
        tx,
        [sender],
      );
    }

    public async updateDapiWithSignedData(
      airnodes: anchor.web3.PublicKey[],
      templateIds: number[],
      timstamps: number[],
      datas: number[],
      sigWithMessages: SignatureParam[],
      sender: anchor.web3.Keypair
    ) {
      const sigVerify = createInstructionWithPublicKey(sigWithMessages, 0);

      const beaconIds = [];
      for (let i = 0; i < airnodes.length; i++) {
        beaconIds.push(deriveBeaconId(airnodes[i].toBytes(), templateIds[i]));
      }

      const dataPointId = deriveDApiId(beaconIds);
      const dapiPDA = await deriveDatapointPDA(dataPointId, this.program.programId);

      const remainingAccounts = [{ isSigner: false, isWritable: false, pubkey: anchor.web3.SYSVAR_INSTRUCTIONS_PUBKEY }];
      for (let i = sigWithMessages.length; i < beaconIds.length; i++) {
        const id = beaconIds[i];
        const pda = await deriveDatapointPDA(id, this.program.programId);
        remainingAccounts.push({ isSigner: false, isWritable: false, pubkey: pda });
      }
  
      const updateInstruction = this.program.instruction.updateDapiWithSignedData(
        dataPointId,
        airnodes.map(t => t.toBytes()),
        beaconIds,
        templateIds.map(t => bufferU64BE(t)),
        timstamps.map(t => bufferU64BE(t)),
        datas.map(t => encodeData(t)),
        {
          accounts: {
            datapoint: dapiPDA,
            user: sender.publicKey,
            systemProgram: anchor.web3.SystemProgram.programId,
          },
          remainingAccounts,
        }
      );
  
      const tx = new anchor.web3.Transaction();
      tx.add(sigVerify);
      tx.add(updateInstruction);
  
      await anchor.web3.sendAndConfirmTransaction(
        this.provider.connection,
        tx,
        [sender],
      );
    }

    public deriveBeaconId(airnodeKey: Uint8Array, templateId: number): Buffer {
      return deriveBeaconId(airnodeKey, templateId);
    }

    public deriveDapiId(beaconIds: Buffer[]): Buffer {
      return deriveDApiId(beaconIds);
    }

    public async setName(name: Buffer, datapointId: Buffer, sender: anchor.web3.PublicKey) {
      const nameHash = keccak256Packed(["bytes32"], [name]);
      const nameHashPDA = await deriveNameHashPDA(nameHash, this.program.programId);
      return await this.program.rpc.setName(
        nameHash,
        name,
        datapointId,
        {
          accounts: {
            hash: nameHashPDA,
            user: sender,
            systemProgram: anchor.web3.SystemProgram.programId,
          },
        }
      );
    }

    public async nameToDataPointId(name: Buffer): Promise<Buffer> {
      const nameHash = keccak256Packed(["bytes32"], [name]);
      const nameHashPDA = await deriveNameHashPDA(nameHash, this.program.programId);
      const wrappedDataPointId = await this.program.account.wrappedDataPointId.fetch(nameHashPDA);
      return wrappedDataPointId.datapointId as Buffer;
    }

    public async readWithName(name: Buffer): Promise<Datapoint> {
      const nameHash = keccak256Packed(["bytes32"], [name]);
      const nameHashPDA = await deriveNameHashPDA(nameHash, this.program.programId);
      const wrappedDataPointId = await this.program.account.wrappedDataPointId.fetch(nameHashPDA);
      return this.readWithDataPointId(wrappedDataPointId.datapointId);
    }
}

'''
'''--- solana/beacon-server/tests/sig.ts ---
import {Buffer} from 'buffer';
import * as anchor from '@project-serum/anchor';

type TransactionInstruction = anchor.web3.TransactionInstruction;

const PUBLIC_KEY_BYTES = 32;
const SIGNATURE_BYTES = 64;
const SIGNATURE_OFFSETS_SERIALIZED_SIZE = 14;
// bytemuck requires structures to be aligned
const SIGNATURE_OFFSETS_START = 2;

/**
 * Params for creating an ed25519 instruction using a public key
 */
export type SignatureParam = {
  publicKey: Uint8Array;
  message: Uint8Array;
  signature: Uint8Array;
};

/**
 * Params for creating an ed25519 instruction using a private key
 */
export type CreateEd25519InstructionWithPrivateKeyParams = {
  privateKey: Uint8Array;
  message: Uint8Array;
  instructionIndex?: number;
};

function encodeSignature(
    instructionData: Buffer,
    param: SignatureParam,
    nextPubKeyIndex: number,
    nextSignatureOffsetIndex: number,
    index: number
): [number, number] {
    // calculate the offsets 
    const nextSignatureIndex = nextPubKeyIndex + PUBLIC_KEY_BYTES;
    const nextMessageIndex = nextSignatureIndex + SIGNATURE_BYTES;
    
    // write the offset
    instructionData.writeUint16LE(nextSignatureIndex, nextSignatureOffsetIndex);        // signatureOffset
    instructionData.writeUint16LE(index, nextSignatureOffsetIndex + 2);                 // signatureInstructionIndex
    instructionData.writeUint16LE(nextPubKeyIndex, nextSignatureOffsetIndex + 4);       // nextPubKeyIndex
    instructionData.writeUint16LE(index, nextSignatureOffsetIndex + 6);                 // publicKeyInstructionIndex
    instructionData.writeUint16LE(nextMessageIndex, nextSignatureOffsetIndex + 8);      // messageDataOffset
    instructionData.writeUint16LE(param.message.length, nextSignatureOffsetIndex + 10); // messageDataSize
    instructionData.writeUint16LE(index, nextSignatureOffsetIndex + 12);                // messageInstructionIndex

    instructionData.fill(param.publicKey, nextPubKeyIndex);
    instructionData.fill(param.signature, nextSignatureIndex);
    instructionData.fill(param.message, nextMessageIndex);

    return [
        nextMessageIndex + param.message.length,
        nextSignatureOffsetIndex + SIGNATURE_OFFSETS_SERIALIZED_SIZE
    ];
}

export function createInstructionWithPublicKey(
    params: SignatureParam[],
    instructionIndex?: number,
): TransactionInstruction {
    const dataOffset = SIGNATURE_OFFSETS_START + SIGNATURE_OFFSETS_SERIALIZED_SIZE * params.length;
    let totalSize = dataOffset + (PUBLIC_KEY_BYTES + SIGNATURE_BYTES) * params.length;
    params.forEach(p => totalSize += p.message.length);

    // assert(
    //   publicKey.length === PUBLIC_KEY_BYTES,
    //   `Public Key must be ${PUBLIC_KEY_BYTES} bytes but received ${publicKey.length} bytes`,
    // );

    // assert(
    //   signature.length === SIGNATURE_BYTES,
    //   `Signature must be ${SIGNATURE_BYTES} bytes but received ${signature.length} bytes`,
    // );

    const instructionData = Buffer.alloc(totalSize);
    const numSignatures = params.length;
    const index =
      instructionIndex == null
        ? 0xffff // An index of `u16::MAX` makes it default to the current instruction.
        : instructionIndex;
    
    // write the number of signatures
    instructionData.writeUInt8(numSignatures);
    instructionData.writeUint8(0, 1); // padding byte

    // process all the signatures
    let nextPubKey = dataOffset;
    let nextSignatureOffset = SIGNATURE_OFFSETS_START;
    for (const p of params) {
        [nextPubKey, nextSignatureOffset] = encodeSignature(
            instructionData,
            p,
            nextPubKey,
            nextSignatureOffset,
            index
        );
    }

    return new anchor.web3.TransactionInstruction({
      keys: [],
      programId,
      data: instructionData,
    });
}

const programId: anchor.web3.PublicKey = new anchor.web3.PublicKey(
    'Ed25519SigVerify111111111111111111111111111',
);
'''
'''--- solana/beacon-server/tests/utils.ts ---
import { ethers } from "ethers";
import * as anchor from "@project-serum/anchor";
import nacl from "tweetnacl";

export async function relayTxn(
    rawTxn: Buffer,
    storageSignature: Uint8Array,
    storageFunderKey: anchor.web3.PublicKey,
    relayer: anchor.web3.Keypair,
  ): Promise<Buffer> {
    const relayerSignature = nacl.sign.detached(rawTxn, relayer.secretKey);
    let recoverTx = anchor.web3.Transaction.populate(anchor.web3.Message.from(rawTxn));
    recoverTx.addSignature(relayer.publicKey, Buffer.from(relayerSignature));
    recoverTx.addSignature(storageFunderKey, Buffer.from(storageSignature));
  
    return recoverTx.serialize();
}

export class Datapoint {
    public value: number;
    public timestamp: number;

    constructor(value: number, timestamp: number) {
        this.timestamp = timestamp;
        this.value = value;
    }

    public static deserialize(bytes: Buffer): Datapoint {
        return new Datapoint(
            Number(BigInt(`0x${bytes.slice(0, 32).toString("hex")}`)),
            Number(bytes.readUInt32BE(32))
        )
    }
}

export function createRawDatapointBuffer(data: number, timestamp: number): Buffer {
    const expected = Buffer.allocUnsafe(36);
    expected.writeBigInt64BE(BigInt(0), 0);
    expected.writeBigInt64BE(BigInt(0), 8);
    expected.writeBigInt64BE(BigInt(0), 16);
    expected.writeBigInt64BE(BigInt(data), 24);
    expected.writeUInt32BE(timestamp, 32);
    return expected;
}

export function prepareMessage(
    templateId: number,
    timestamp: number,
    data: number,
): Buffer {
    const bufferedTemplate = bufferU64BE(templateId);
    const bufferedTimestamp = bufferU64BE(timestamp);
    const encodedData = encodeData(data);
    return keccak256Packed(
        ["bytes32", "uint256", "bytes"],
        [bufferedTemplate, bufferedTimestamp, encodedData]
    )
}

export function keccak256Packed(types: string[], data: any[]): Buffer {
    let hex = ethers.utils.solidityPack(types, data).substr(2); // remove starting "0x"
    const buf = Buffer.from(hex, "hex");
    hex = ethers.utils.keccak256(buf).substr(2); // remove starting "0x"
    return Buffer.from(hex, "hex");
}

export function deriveBeaconId(airnodeKey: Uint8Array, templateId: number): Buffer {
    const bufferedTemplate = bufferU64BE(templateId);
    return keccak256Packed(["bytes", "bytes32"], [airnodeKey, bufferedTemplate]);
    // let hex = ethers.utils.solidityPack(["bytes", "bytes32"], [airnodeKey, templateId]).substr(2); // remove starting "0x"
    // const buf = Buffer.from(hex, "hex");
    // hex = ethers.utils.keccak256(buf).substr(2); // remove starting "0x"
    // return Buffer.from(hex, "hex");
}

export function deriveDApiId(beaconIds: Buffer[]): Buffer {
    const types = beaconIds.map(_ => "bytes32");
    return keccak256Packed(types, beaconIds);
}

export function encodeData(decodedData: number): Buffer {
    const hex = ethers.utils.defaultAbiCoder.encode(['int256'], [decodedData]);
    return Buffer.from(hex.substr(2), "hex");
}

export function bufferU64BE(value: number): Buffer {
    const buffer = Buffer.alloc(32);
    buffer.writeBigUInt64BE(BigInt(value), 24);
    return buffer;
}

export async function deriveDatapointPDA(dataPointId: Buffer, programId: anchor.web3.PublicKey): Promise<anchor.web3.PublicKey> {
    const [pda] = await anchor.web3.PublicKey.findProgramAddress(
        [
          Buffer.from(anchor.utils.bytes.utf8.encode("datapoint")),
          dataPointId
        ],
        programId
    );
    return pda;
}

export async function deriveNameHashPDA(nameHash: Buffer, programId: anchor.web3.PublicKey): Promise<anchor.web3.PublicKey> {
    const [pda] = await anchor.web3.PublicKey.findProgramAddress(
        [
          Buffer.from(anchor.utils.bytes.utf8.encode("hashed-name")),
          nameHash
        ],
        programId
    );
    return pda;
}

export function median(values: number[]): number {
    if(values.length ===0) throw new Error("No inputs");
  
    values.sort(function(a,b){
      return a-b;
    });
  
    var half = Math.floor(values.length / 2);
    
    if (values.length % 2)
      return values[half];
    
    return Math.floor((values[half - 1] + values[half]) / 2);
}

export function getRandomInt(max: number): number {
    return Math.floor(Math.random() * max);
}
'''
'''--- solana/beacon-server/tsconfig.json ---
{
  "compilerOptions": {
    "types": ["mocha", "chai"],
    "typeRoots": ["./node_modules/@types"],
    "lib": ["es2015"],
    "module": "commonjs",
    "target": "es6",
    "esModuleInterop": true
  }
}

'''