*GitHub Repository "kuutamolabs/hyper-staticfile"*

'''--- .github/workflows/check.yml ---
name: Check

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  CARGO_TERM_COLOR: always

jobs:
  check:
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        rust: [1.46, stable]
    runs-on: ${{ matrix.os }}
    steps:

    - name: Checkout
      uses: actions/checkout@v3

    - name: Install Rust
      uses: actions-rs/toolchain@v1
      with:
        profile: minimal
        toolchain: ${{ matrix.rust }}
        components: rustfmt

    - name: Build
      run: cargo build --verbose

    - name: Run tests
      run: cargo test --verbose

    - name: Check style
      run: cargo fmt -- --check

'''
'''--- Cargo.toml ---
[package]
name = "hyper-staticfile"
version = "0.10.0-alpha.7"
authors = ["hyper-staticfile contributors"]
description = "Static file serving for Hyper 1.0"
repository = "https://github.com/stephank/hyper-staticfile"
license = "MIT"
readme = "README.md"
documentation = "https://docs.rs/hyper-staticfile"
keywords = ["hyper", "web", "http", "file", "static"]
categories = ["web-programming::http-server"]
edition = "2018"

[dependencies]
futures-util = "0.3.1"
http = "0.2.0"
httpdate = "1.0.1"
http-range = "0.1.4"
hyper = "1.0.0-rc.4"
mime_guess = "2.0.1"
percent-encoding = "2.1.0"
rand = "0.8.4"
tokio = { version = "1.0.0", features = ["fs"] }
url = "2.1.0"

[dev-dependencies]
hyper = { version = "1.0.0-rc.4", features = ["http1", "server"] }
hyper-util = { path = "../hyper-util" }
http-body-util = "0.1.0-rc.3"
tempfile = "3"
tokio = { version = "1.0.0", features = ["macros", "rt-multi-thread", "net", "io-util"] }

[target.'cfg(windows)'.dependencies]
winapi = { version = "0.3.6", features = ["winbase"] }

'''
'''--- README.md ---
# hyper-staticfile

[![Docs](https://docs.rs/hyper-staticfile/badge.svg)](https://docs.rs/hyper-staticfile)
[![Crate](https://img.shields.io/crates/v/hyper-staticfile.svg)](https://crates.io/crates/hyper-staticfile)
[![Build Status](https://travis-ci.org/stephank/hyper-staticfile.svg?branch=master)](https://travis-ci.org/stephank/hyper-staticfile)

Static file-serving for [Hyper 1.0](https://github.com/hyperium/hyper).

See [`examples/doc_server.rs`](examples/doc_server.rs) for a complete example that you can compile.

## [Documentation](http://docs.rs/hyper-staticfile)

'''
'''--- examples/doc_server.rs ---
// This example serves the docs from `target/doc/`.
//
// Run `cargo doc && cargo run --example doc_server`, then
// point your browser to http://localhost:3000/

use std::io::Error as IoError;
use std::net::SocketAddr;
use std::path::Path;

use http::response::Builder as ResponseBuilder;
use http::{header, StatusCode};
use hyper::service::service_fn;
use hyper::{Request, Response};
use hyper_staticfile::{Body, Static};
use hyper_util::rt::TokioIo;
use tokio::net::TcpListener;

async fn handle_request<B>(req: Request<B>, static_: Static) -> Result<Response<Body>, IoError> {
    if req.uri().path() == "/" {
        let res = ResponseBuilder::new()
            .status(StatusCode::MOVED_PERMANENTLY)
            .header(header::LOCATION, "/hyper_staticfile/")
            .body(Body::Empty)
            .expect("unable to build response");
        Ok(res)
    } else {
        static_.clone().serve(req).await
    }
}

#[tokio::main]
async fn main() {
    let static_ = Static::new(Path::new("target/doc/"));

    let addr: SocketAddr = ([127, 0, 0, 1], 3000).into();
    let listener = TcpListener::bind(addr)
        .await
        .expect("Failed to create TCP listener");
    eprintln!("Doc server running on http://{}/", addr);
    loop {
        let (stream, _) = listener
            .accept()
            .await
            .expect("Failed to accept TCP connection");

        let static_ = static_.clone();
        tokio::spawn(async move {
            if let Err(err) = hyper::server::conn::http1::Builder::new()
                .serve_connection(
                    TokioIo::new(stream),
                    service_fn(move |req| handle_request(req, static_.clone())),
                )
                .await
            {
                eprintln!("Error serving connection: {:?}", err);
            }
        });
    }
}

'''
'''--- rustfmt.toml ---
edition = "2018"

'''
'''--- src/body.rs ---
use std::{
    io::Error as IoError,
    pin::Pin,
    task::{ready, Context, Poll},
};

use futures_util::stream::Stream;
use hyper::body::{Bytes, Frame};

use crate::{
    util::{FileBytesStream, FileBytesStreamMultiRange, FileBytesStreamRange},
    vfs::{FileAccess, TokioFileAccess},
};

/// Hyper Body implementation for the various types of streams used in static serving.
pub enum Body<F = TokioFileAccess> {
    /// No response body.
    Empty,
    /// Serve a complete file.
    Full(FileBytesStream<F>),
    /// Serve a range from a file.
    Range(FileBytesStreamRange<F>),
    /// Serve multiple ranges from a file.
    MultiRange(FileBytesStreamMultiRange<F>),
}

impl<F: FileAccess> hyper::body::Body for Body<F> {
    type Data = Bytes;
    type Error = IoError;

    fn poll_frame(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Option<Result<Frame<Bytes>, IoError>>> {
        let opt = ready!(match *self {
            Body::Empty => return Poll::Ready(None),
            Body::Full(ref mut stream) => Pin::new(stream).poll_next(cx),
            Body::Range(ref mut stream) => Pin::new(stream).poll_next(cx),
            Body::MultiRange(ref mut stream) => Pin::new(stream).poll_next(cx),
        });
        Poll::Ready(opt.map(|res| res.map(Frame::data)))
    }
}

'''
'''--- src/lib.rs ---
#![crate_name = "hyper_staticfile"]
#![deny(missing_docs)]

//! Static file-serving for [Hyper 1.0](https://github.com/hyperium/hyper).
//!
//! This library exports a high-level interface `Static` for simple file-serving, and lower-level
//! interfaces for more control over responses.
//!
//! ## Basic usage
//!
//! The `Static` type is essentially a struct containing some settings, and a `serve` method to
//! handle the request. It follows the builder pattern, and also implements the `hyper::Service`
//! trait. It can be used as:
//!
//! ```rust
//! // Instance of `Static` containing configuration. Can be cheaply cloned.
//! let static_ = hyper_staticfile::Static::new("my/doc/root/");
//!
//! // A dummy request, but normally obtained from Hyper.
//! let request = http::Request::get("/foo/bar.txt")
//!     .body(())
//!     .unwrap();
//!
//! // Serve the request. Returns a future for a `hyper::Response`.
//! let response_future = static_.serve(request);
//! ```
//!
//! Typically, you'd store the `Static` instance somewhere, such as in your own `hyper::Service`
//! implementation.
//!
//! ## Advanced usage
//!
//! The `Static` type is a simple wrapper for `Resolver` and `ResponseBuilder`. You can achieve the
//! same by doing something similar to the following:
//!
//! ```rust
//! use std::path::Path;
//!
//! #[tokio::main]
//! async fn main() {
//!     // Create a resolver. This can be cheaply cloned.
//!     let resolver = hyper_staticfile::Resolver::new("my/doc/root/");
//!
//!     // A dummy request, but normally obtained from Hyper.
//!     let request = http::Request::get("/foo/bar.txt")
//!         .body(())
//!         .unwrap();
//!
//!     // First, resolve the request. Returns a future for a `ResolveResult`.
//!     let result = resolver.resolve_request(&request).await.unwrap();
//!
//!     // Then, build a response based on the result.
//!     // The `ResponseBuilder` is typically a short-lived, per-request instance.
//!     let response = hyper_staticfile::ResponseBuilder::new()
//!         .request(&request)
//!         .build(result)
//!         .unwrap();
//! }
//! ```
//!
//! The `resolve_request` method tries to find the file in the document root, and returns a future
//! for the `ResolveResult` enum, which determines what kind of response should be sent. The
//! `ResponseBuilder` is then used to create a default response. It holds some settings, and can be
//! constructed using the builder pattern.
//!
//! It's useful to sit between these two steps to implement custom 404 pages, for example. Your
//! custom logic can override specific cases of `ResolveResult`, and fall back to the default
//! behavior using `ResponseBuilder` if necessary.

mod body;
mod resolve;
mod response_builder;
mod service;

/// Lower level utilities.
pub mod util;
/// Types to implement a custom (virtual) filesystem to serve files from.
pub mod vfs;

pub use crate::body::Body;
pub use crate::resolve::*;
pub use crate::response_builder::*;
pub use crate::service::*;

'''
'''--- src/resolve.rs ---
use std::{
    io::{Error as IoError, ErrorKind as IoErrorKind},
    ops::BitAnd,
    path::PathBuf,
    sync::Arc,
    time::SystemTime,
};

use http::{header, HeaderValue, Method, Request};
use mime_guess::MimeGuess;
use tokio::fs::File;

use crate::{
    util::RequestedPath,
    vfs::{FileOpener, FileWithMetadata, TokioFileOpener},
};

/// Struct containing all the required data to serve a file.
#[derive(Debug)]
pub struct ResolvedFile<F = File> {
    /// Open file handle.
    pub handle: F,
    /// The resolved and sanitized path to the file.
    /// For directory indexes, this includes `index.html`.
    /// For pre-encoded files, this will include the compressed extension. (`.gz` or `.br`)
    pub path: PathBuf,
    /// Size in bytes.
    pub size: u64,
    /// Last modification time.
    pub modified: Option<SystemTime>,
    /// MIME type / 'Content-Type' value.
    pub content_type: Option<String>,
    /// 'Content-Encoding' value.
    pub encoding: Option<Encoding>,
}

impl<F> ResolvedFile<F> {
    fn new(
        file: FileWithMetadata<F>,
        path: PathBuf,
        content_type: Option<String>,
        encoding: Option<Encoding>,
    ) -> Self {
        Self {
            handle: file.handle,
            path,
            size: file.size,
            modified: file.modified,
            content_type,
            encoding,
        }
    }
}

/// Resolves request paths to files.
///
/// This struct resolves files based on the request path. The path is first sanitized, then mapped
/// to a file on the filesystem. If the path corresponds to a directory, it will try to look for a
/// directory index.
///
/// Cloning this struct is a cheap operation.
pub struct Resolver<O = TokioFileOpener> {
    /// The (virtual) filesystem used to open files.
    pub opener: Arc<O>,

    /// Encodings the client is allowed to request with `Accept-Encoding`.
    ///
    /// This only supports pre-encoded files, that exist adjacent to the original file, but with an
    /// additional `.br` or `.gz` suffix (after the original extension).
    ///
    /// Typically initialized with `AcceptEncoding::all()` or `AcceptEncoding::none()`.
    pub allowed_encodings: AcceptEncoding,

    /// Only serve this type of files, and also will try file without extension.
    pub file_extension: Option<&'static str>,
}

/// The result of `Resolver` methods.
///
/// Covers all the possible 'normal' scenarios encountered when serving static files.
#[derive(Debug)]
pub enum ResolveResult<F = File> {
    /// The request was not `GET` or `HEAD` request,
    MethodNotMatched,
    /// The requested file does not exist.
    NotFound,
    /// The requested file could not be accessed.
    PermissionDenied,
    /// A directory was requested as a file.
    IsDirectory {
        /// Path to redirect to.
        redirect_to: String,
    },
    /// The requested file was found.
    Found(ResolvedFile<F>),
}

/// Some IO errors are expected when serving files, and mapped to a regular result here.
fn map_open_err<F>(err: IoError) -> Result<ResolveResult<F>, IoError> {
    match err.kind() {
        IoErrorKind::NotFound => Ok(ResolveResult::NotFound),
        IoErrorKind::PermissionDenied => Ok(ResolveResult::PermissionDenied),
        _ => Err(err),
    }
}

impl Resolver<TokioFileOpener> {
    /// Create a resolver that resolves files inside a root directory on the regular filesystem.
    pub fn new(root: impl Into<PathBuf>) -> Self {
        Self::with_opener(TokioFileOpener::new(root))
    }
}

impl<O: FileOpener> Resolver<O> {
    /// Create a resolver with a custom file opener.
    pub fn with_opener(opener: O) -> Self {
        Self {
            opener: Arc::new(opener),
            allowed_encodings: AcceptEncoding::none(),
            file_extension: None,
        }
    }

    /// Set up the file type by extension for resolving, it also will try to resolve the path
    /// without extensions with this file type
    pub fn set_extension(&mut self, extension: &'static str) {
        self.file_extension = Some(extension);
    }

    /// Resolve the request by trying to find the file in the root.
    ///
    /// The returned future may error for unexpected IO errors, passing on the `std::io::Error`.
    /// Certain expected IO errors are handled, though, and simply reflected in the result. These are
    /// `NotFound` and `PermissionDenied`.
    pub async fn resolve_request<B>(
        &self,
        req: &Request<B>,
    ) -> Result<ResolveResult<O::File>, IoError> {
        // Handle only `GET`/`HEAD` and absolute paths.
        match *req.method() {
            Method::HEAD | Method::GET => {}
            _ => {
                return Ok(ResolveResult::MethodNotMatched);
            }
        }

        // Parse `Accept-Encoding` header.
        let accept_encoding = self.allowed_encodings
            & req
                .headers()
                .get(header::ACCEPT_ENCODING)
                .map(AcceptEncoding::from_header_value)
                .unwrap_or(AcceptEncoding::none());

        self.resolve_path(req.uri().path(), accept_encoding).await
    }

    /// Resolve the request path by trying to find the file in the given root.
    ///
    /// The returned future may error for unexpected IO errors, passing on the `std::io::Error`.
    /// Certain expected IO errors are handled, though, and simply reflected in the result. These are
    /// `NotFound` and `PermissionDenied`.
    ///
    /// Note that, unlike `resolve_request`, it is up to the caller to check the request method and
    /// optionally the 'Accept-Encoding' header.
    pub async fn resolve_path(
        &self,
        request_path: &str,
        accept_encoding: AcceptEncoding,
    ) -> Result<ResolveResult<O::File>, IoError> {
        // Sanitize input path.
        let RequestedPath {
            sanitized: mut path,
            is_dir_request,
        } = RequestedPath::resolve(request_path, self.file_extension);

        // Try to open the file.
        let file = match self.opener.open(&path).await {
            Ok(pair) => pair,
            Err(err) => return map_open_err(err),
        };

        // The resolved path doesn't contain the trailing slash anymore, so we may
        // have opened a file for a directory request, which we treat as 'not found'.
        if is_dir_request && !file.is_dir {
            return Ok(ResolveResult::NotFound);
        }

        // We may have opened a directory for a file request, in which case we redirect.
        if !is_dir_request && file.is_dir {
            // Build the redirect path. On Windows, we can't just append the entire path, because
            // it contains Windows path separators. Instead, append each component separately.
            let mut target = String::with_capacity(path.as_os_str().len() + 2);
            target.push('/');
            for component in path.components() {
                target.push_str(&component.as_os_str().to_string_lossy());
                target.push('/');
            }

            return Ok(ResolveResult::IsDirectory {
                redirect_to: target,
            });
        }

        // If not a directory, serve this file.
        if !is_dir_request {
            return self.resolve_final(file, path, accept_encoding).await;
        }

        // Resolve the directory index.
        path.push("index.html");
        let file = match self.opener.open(&path).await {
            Ok(pair) => pair,
            Err(err) => return map_open_err(err),
        };

        // The directory index cannot itself be a directory.
        if file.is_dir {
            return Ok(ResolveResult::NotFound);
        }

        // Serve this file.
        self.resolve_final(file, path, accept_encoding).await
    }

    // Found a file, perform final resolution steps.
    async fn resolve_final(
        &self,
        file: FileWithMetadata<O::File>,
        path: PathBuf,
        accept_encoding: AcceptEncoding,
    ) -> Result<ResolveResult<O::File>, IoError> {
        // Determine MIME-type. This needs to happen before we resolve a pre-encoded file.
        let mime = MimeGuess::from_path(&path)
            .first()
            .map(|mime| mime.to_string());

        // Resolve pre-encoded files.
        if accept_encoding.br {
            let mut br_path = path.clone().into_os_string();
            br_path.push(".br");
            if let Ok(file) = self.opener.open(br_path.as_ref()).await {
                return Ok(ResolveResult::Found(ResolvedFile::new(
                    file,
                    br_path.into(),
                    mime,
                    Some(Encoding::Br),
                )));
            }
        }
        if accept_encoding.gzip {
            let mut gzip_path = path.clone().into_os_string();
            gzip_path.push(".gz");
            if let Ok(file) = self.opener.open(gzip_path.as_ref()).await {
                return Ok(ResolveResult::Found(ResolvedFile::new(
                    file,
                    gzip_path.into(),
                    mime,
                    Some(Encoding::Gzip),
                )));
            }
        }

        // No pre-encoded file found, serve the original.
        Ok(ResolveResult::Found(ResolvedFile::new(
            file, path, mime, None,
        )))
    }
}

impl<O> Clone for Resolver<O> {
    fn clone(&self) -> Self {
        Self {
            opener: self.opener.clone(),
            allowed_encodings: self.allowed_encodings,
            file_extension: self.file_extension.clone()
        }
    }
}

/// Type of response encoding.
#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum Encoding {
    /// Response body is encoded with gzip.
    Gzip,
    /// Response body is encoded with brotli.
    Br,
}

impl Encoding {
    /// Create a `HeaderValue` for this encoding.
    pub fn to_header_value(&self) -> HeaderValue {
        HeaderValue::from_static(match self {
            Encoding::Gzip => "gzip",
            Encoding::Br => "br",
        })
    }
}

/// Flags for which encodings to resolve.
#[derive(Debug, Copy, Clone)]
pub struct AcceptEncoding {
    /// Look for `.gz` files.
    pub gzip: bool,
    /// Look for `.br` files.
    pub br: bool,
}

impl AcceptEncoding {
    /// Return an `AcceptEncoding` with all flags set.
    pub const fn all() -> Self {
        Self {
            gzip: true,
            br: true,
        }
    }

    /// Return an `AcceptEncoding` with no flags set.
    pub const fn none() -> Self {
        Self {
            gzip: false,
            br: false,
        }
    }

    /// Fill an `AcceptEncoding` struct from a header value.
    pub fn from_header_value(value: &HeaderValue) -> Self {
        let mut res = Self::none();
        if let Ok(value) = value.to_str() {
            for enc in value.split(',') {
                // TODO: Handle weights (q=)
                match enc.split(';').next().unwrap().trim() {
                    "gzip" => res.gzip = true,
                    "br" => res.br = true,
                    _ => {}
                }
            }
        }
        res
    }
}

impl BitAnd for AcceptEncoding {
    type Output = Self;
    fn bitand(self, rhs: Self) -> Self {
        Self {
            gzip: self.gzip && rhs.gzip,
            br: self.br && rhs.br,
        }
    }
}

'''
'''--- src/response_builder.rs ---
use http::{
    header, response::Builder as HttpResponseBuilder, HeaderMap, Method, Request, Response, Result,
    StatusCode, Uri,
};

use crate::{resolve::ResolveResult, util::FileResponseBuilder, vfs::IntoFileAccess, Body};

/// Utility to build the default response for a `resolve` result.
///
/// This struct allows direct access to its fields, but these fields are typically initialized by
/// the accessors, using the builder pattern. The fields are basically a bunch of settings that
/// determine the response details.
#[derive(Clone, Debug, Default)]
pub struct ResponseBuilder<'a> {
    /// The request path.
    pub path: &'a str,
    /// The request query string.
    pub query: Option<&'a str>,
    /// Inner file response builder.
    pub file_response_builder: FileResponseBuilder,
}

impl<'a> ResponseBuilder<'a> {
    /// Create a new builder with a default configuration.
    pub fn new() -> Self {
        Self::default()
    }

    /// Apply parameters based on a request.
    pub fn request<B>(&mut self, req: &'a Request<B>) -> &mut Self {
        self.request_parts(req.method(), req.uri(), req.headers());
        self
    }

    /// Apply parameters based on request parts.
    pub fn request_parts(
        &mut self,
        method: &Method,
        uri: &'a Uri,
        headers: &'a HeaderMap,
    ) -> &mut Self {
        self.request_uri(uri);
        self.file_response_builder.request_parts(method, headers);
        self
    }

    /// Apply parameters based on a request URI.
    pub fn request_uri(&mut self, uri: &'a Uri) -> &mut Self {
        self.path(uri.path());
        self.query(uri.query());
        self
    }

    /// Add cache headers to responses for the given lifespan.
    pub fn cache_headers(&mut self, value: Option<u32>) -> &mut Self {
        self.file_response_builder.cache_headers(value);
        self
    }

    /// Set the request path.
    pub fn path(&mut self, value: &'a str) -> &mut Self {
        self.path = value;
        self
    }

    /// Set the request query string.
    pub fn query(&mut self, value: Option<&'a str>) -> &mut Self {
        self.query = value;
        self
    }

    /// Build a response for the given request and `resolve` result.
    ///
    /// This function may error if it response could not be constructed, but this should be a
    /// seldom occurrence.
    pub fn build<F: IntoFileAccess>(
        &self,
        result: ResolveResult<F>,
    ) -> Result<Response<Body<F::Output>>> {
        match result {
            ResolveResult::MethodNotMatched => HttpResponseBuilder::new()
                .status(StatusCode::BAD_REQUEST)
                .body(Body::Empty),
            ResolveResult::NotFound => HttpResponseBuilder::new()
                .status(StatusCode::NOT_FOUND)
                .body(Body::Empty),
            ResolveResult::PermissionDenied => HttpResponseBuilder::new()
                .status(StatusCode::FORBIDDEN)
                .body(Body::Empty),
            ResolveResult::IsDirectory {
                redirect_to: mut target,
            } => {
                // Preserve any query string from the original request.
                if let Some(query) = self.query {
                    target.push('?');
                    target.push_str(query);
                }

                HttpResponseBuilder::new()
                    .status(StatusCode::MOVED_PERMANENTLY)
                    .header(header::LOCATION, target)
                    .body(Body::Empty)
            }
            ResolveResult::Found(file) => self.file_response_builder.build(file),
        }
    }
}

'''
'''--- src/service.rs ---
use std::{future::Future, io::Error as IoError, path::PathBuf, pin::Pin};

use http::{Request, Response};
use hyper::service::Service;

use crate::{
    vfs::{FileOpener, IntoFileAccess, TokioFileOpener},
    AcceptEncoding, Body, Resolver, ResponseBuilder,
};

/// High-level interface for serving static files.
///
/// This services serves files based on the request path. The path is first sanitized, then mapped
/// to a file on the filesystem. If the path corresponds to a directory, it will try to look for a
/// directory index.
///
/// This struct allows direct access to its fields, but these fields are typically initialized by
/// the accessors, using the builder pattern. The fields are basically a bunch of settings that
/// determine the response details.
///
/// This struct also implements the `hyper::Service` trait, which simply wraps `Static::serve`.
/// Note that using the trait currently involves an extra `Box`.
///
/// Cloning this struct is a cheap operation.
pub struct Static<O = TokioFileOpener> {
    /// The resolver instance used to open files.
    pub resolver: Resolver<O>,
    /// Whether to send cache headers, and what lifespan to indicate.
    pub cache_headers: Option<u32>,
}

impl Static<TokioFileOpener> {
    /// Create a new instance of `Static` with a given root path.
    ///
    /// The path may be absolute or relative. If `Path::new("")` is used, files will be served from
    /// the current directory.
    pub fn new(root: impl Into<PathBuf>) -> Self {
        Self {
            resolver: Resolver::new(root),
            cache_headers: None,
        }
    }
}

impl<O: FileOpener> Static<O> {
    /// Create a new instance of `Static` with the given root directory.
    pub fn with_opener(opener: O) -> Self {
        Self {
            resolver: Resolver::with_opener(opener),
            cache_headers: None,
        }
    }

    /// Add cache headers to responses for the given lifespan.
    pub fn cache_headers(&mut self, value: Option<u32>) -> &mut Self {
        self.cache_headers = value;
        self
    }

    /// Set the encodings the client is allowed to request via the `Accept-Encoding` header.
    pub fn allowed_encodings(&mut self, allowed_encodings: AcceptEncoding) -> &mut Self {
        self.resolver.allowed_encodings = allowed_encodings;
        self
    }

    /// Serve a request.
    pub async fn serve<B>(
        self,
        request: Request<B>,
    ) -> Result<Response<Body<<O::File as IntoFileAccess>::Output>>, IoError> {
        let Self {
            resolver,
            cache_headers,
        } = self;
        resolver.resolve_request(&request).await.map(|result| {
            ResponseBuilder::new()
                .request(&request)
                .cache_headers(cache_headers)
                .build(result)
                .expect("unable to build response")
        })
    }

    /// Set up the files by extension for serving, it also will try to resolve the path without
    /// extensions with this file type
    ///
    /// This supports to response `file.html` when request on `/path/to/file`, `/path/to/file.htm`,
    /// or `/path/to/file.html`.
    pub async fn serve_files_by_extension<B>(
        mut self,
        request: Request<B>,
        file_extension: &'static str,
    ) -> Result<Response<Body<<O::File as IntoFileAccess>::Output>>, IoError> {
        self.resolver.set_extension(file_extension);
        self.serve(request).await
    }
}

impl<O> Clone for Static<O> {
    fn clone(&self) -> Self {
        Self {
            resolver: self.resolver.clone(),
            cache_headers: self.cache_headers,
        }
    }
}

impl<O, B> Service<Request<B>> for Static<O>
where
    O: FileOpener,
    B: Send + Sync + 'static,
{
    type Response = Response<Body<<O::File as IntoFileAccess>::Output>>;
    type Error = IoError;
    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;

    fn call(&self, request: Request<B>) -> Self::Future {
        Box::pin(self.clone().serve(request))
    }
}

'''
'''--- src/util/file_bytes_stream.rs ---
use std::{
    fmt::Write,
    io::{Error as IoError, SeekFrom},
    pin::Pin,
    task::{Context, Poll},
    vec,
};

use futures_util::stream::Stream;
use http_range::HttpRange;
use hyper::body::Bytes;

use crate::vfs::{FileAccess, TokioFileAccess};

/// Wraps a `FileAccess` and implements a stream of `Bytes`s.
pub struct FileBytesStream<F = TokioFileAccess> {
    file: F,
    remaining: u64,
}

impl<F> FileBytesStream<F> {
    /// Create a new stream from the given file.
    pub fn new(file: F) -> Self {
        Self {
            file,
            remaining: u64::MAX,
        }
    }

    /// Create a new stream from the given file, reading up to `limit` bytes.
    pub fn new_with_limit(file: F, limit: u64) -> Self {
        Self {
            file,
            remaining: limit,
        }
    }
}

impl<F: FileAccess> Stream for FileBytesStream<F> {
    type Item = Result<Bytes, IoError>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {
        let Self {
            ref mut file,
            ref mut remaining,
        } = *self;

        match Pin::new(file).poll_read(cx, *remaining as usize) {
            Poll::Ready(Ok(buf)) => {
                *remaining -= buf.len() as u64;
                if buf.is_empty() {
                    Poll::Ready(None)
                } else {
                    Poll::Ready(Some(Ok(buf)))
                }
            }
            Poll::Ready(Err(e)) => Poll::Ready(Some(Err(e))),
            Poll::Pending => Poll::Pending,
        }
    }
}

#[derive(PartialEq, Eq)]
enum FileSeekState {
    NeedSeek,
    Seeking,
    Reading,
}

/// Wraps a `FileAccess` and implements a stream of `Bytes`s reading a portion of the file.
pub struct FileBytesStreamRange<F = TokioFileAccess> {
    file_stream: FileBytesStream<F>,
    seek_state: FileSeekState,
    start_offset: u64,
}

impl<F> FileBytesStreamRange<F> {
    /// Create a new stream from the given file and range.
    pub fn new(file: F, range: HttpRange) -> Self {
        Self {
            file_stream: FileBytesStream::new_with_limit(file, range.length),
            seek_state: FileSeekState::NeedSeek,
            start_offset: range.start,
        }
    }

    fn without_initial_range(file: F) -> Self {
        Self {
            file_stream: FileBytesStream::new_with_limit(file, 0),
            seek_state: FileSeekState::NeedSeek,
            start_offset: 0,
        }
    }
}

impl<F: FileAccess> Stream for FileBytesStreamRange<F> {
    type Item = Result<Bytes, IoError>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {
        let Self {
            ref mut file_stream,
            ref mut seek_state,
            start_offset,
        } = *self;
        if *seek_state == FileSeekState::NeedSeek {
            *seek_state = FileSeekState::Seeking;
            if let Err(e) =
                Pin::new(&mut file_stream.file).start_seek(SeekFrom::Start(start_offset))
            {
                return Poll::Ready(Some(Err(e)));
            }
        }
        if *seek_state == FileSeekState::Seeking {
            match Pin::new(&mut file_stream.file).poll_complete(cx) {
                Poll::Ready(Ok(..)) => *seek_state = FileSeekState::Reading,
                Poll::Ready(Err(e)) => return Poll::Ready(Some(Err(e))),
                Poll::Pending => return Poll::Pending,
            }
        }
        Pin::new(file_stream).poll_next(cx)
    }
}

/// Wraps a `FileAccess` and implements a stream of `Bytes`s providing multiple ranges of the file
/// contents in HTTP chunked transfer encoding.
pub struct FileBytesStreamMultiRange<F = TokioFileAccess> {
    file_range: FileBytesStreamRange<F>,
    range_iter: vec::IntoIter<HttpRange>,
    is_first_boundary: bool,
    completed: bool,
    boundary: String,
    content_type: String,
    file_length: u64,
}

impl<F> FileBytesStreamMultiRange<F> {
    /// Create a new stream from the given file, ranges, boundary and file length.
    ///
    /// A boundary is required to separate the chunked components and therefore needs to be
    /// unlikely to be in any file.
    pub fn new(file: F, ranges: Vec<HttpRange>, boundary: String, file_length: u64) -> Self {
        Self {
            file_range: FileBytesStreamRange::without_initial_range(file),
            range_iter: ranges.into_iter(),
            boundary,
            is_first_boundary: true,
            completed: false,
            content_type: String::new(),
            file_length,
        }
    }

    /// Set the Content-Type header in the multipart/byteranges chunks.
    pub fn set_content_type(&mut self, content_type: &str) {
        self.content_type = content_type.to_string();
    }

    /// Computes the length of the body for the multi-range response being produced by this
    /// `FileBytesStreamMultiRange`.
    pub fn compute_length(&self) -> u64 {
        let Self {
            ref range_iter,
            ref boundary,
            ref content_type,
            file_length,
            ..
        } = *self;

        let mut total_length = 0;
        let mut is_first = true;
        for range in range_iter.as_slice() {
            let header =
                render_multipart_header(boundary, content_type, *range, is_first, file_length);

            is_first = false;
            total_length += header.as_bytes().len() as u64;
            total_length += range.length;
        }

        let header = render_multipart_header_end(boundary);
        total_length += header.as_bytes().len() as u64;

        total_length
    }
}

fn render_multipart_header(
    boundary: &str,
    content_type: &str,
    range: HttpRange,
    is_first: bool,
    file_length: u64,
) -> String {
    let mut buf = String::with_capacity(128);
    if !is_first {
        buf.push_str("\r\n");
    }
    write!(
        &mut buf,
        "--{boundary}\r\nContent-Range: bytes {}-{}/{file_length}\r\n",
        range.start,
        range.start + range.length - 1,
    )
    .expect("buffer write failed");

    if !content_type.is_empty() {
        write!(&mut buf, "Content-Type: {content_type}\r\n").expect("buffer write failed");
    }

    buf.push_str("\r\n");
    buf
}

fn render_multipart_header_end(boundary: &str) -> String {
    format!("\r\n--{boundary}--\r\n")
}

impl<F: FileAccess> Stream for FileBytesStreamMultiRange<F> {
    type Item = Result<Bytes, IoError>;

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {
        let Self {
            ref mut file_range,
            ref mut range_iter,
            ref mut is_first_boundary,
            ref mut completed,
            ref boundary,
            ref content_type,
            file_length,
        } = *self;

        if *completed {
            return Poll::Ready(None);
        }

        if file_range.file_stream.remaining == 0 {
            let range = match range_iter.next() {
                Some(r) => r,
                None => {
                    *completed = true;

                    let header = render_multipart_header_end(boundary);
                    return Poll::Ready(Some(Ok(header.into())));
                }
            };

            file_range.seek_state = FileSeekState::NeedSeek;
            file_range.start_offset = range.start;
            file_range.file_stream.remaining = range.length;

            let cur_is_first = *is_first_boundary;
            *is_first_boundary = false;

            let header =
                render_multipart_header(boundary, content_type, range, cur_is_first, file_length);
            return Poll::Ready(Some(Ok(header.into())));
        }

        Pin::new(file_range).poll_next(cx)
    }
}

'''
'''--- src/util/file_response_builder.rs ---
use std::time::{Duration, SystemTime, UNIX_EPOCH};

use http::{
    header, response::Builder as ResponseBuilder, HeaderMap, Method, Request, Response, Result,
    StatusCode,
};
use http_range::{HttpRange, HttpRangeParseError};
use rand::prelude::{thread_rng, SliceRandom};

use crate::{
    util::{FileBytesStream, FileBytesStreamMultiRange, FileBytesStreamRange},
    vfs::IntoFileAccess,
    Body, ResolvedFile,
};

/// Minimum duration since Unix epoch we accept for file modification time.
///
/// This is intended to discard invalid times, specifically:
///  - Zero values on any Unix system.
///  - 'Epoch + 1' on NixOS.
const MIN_VALID_MTIME: Duration = Duration::from_secs(2);

const BOUNDARY_LENGTH: usize = 60;
const BOUNDARY_CHARS: &[u8] = b"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";

/// Utility to build responses for serving a file.
///
/// This struct allows direct access to its fields, but these fields are typically initialized by
/// the accessors, using the builder pattern. The fields are basically a bunch of settings that
/// determine the response details.
#[derive(Clone, Debug, Default)]
pub struct FileResponseBuilder {
    /// Whether to send cache headers, and what lifespan to indicate.
    pub cache_headers: Option<u32>,
    /// Whether this is a `HEAD` request, with no response body.
    pub is_head: bool,
    /// The parsed value of the `If-Modified-Since` request header.
    pub if_modified_since: Option<SystemTime>,
    /// The file ranges to read, if any, otherwise we read from the beginning.
    pub range: Option<String>,
    /// The unparsed value of the `If-Range` request header. May match etag or last-modified.
    pub if_range: Option<String>,
}

impl FileResponseBuilder {
    /// Create a new builder with a default configuration.
    pub fn new() -> Self {
        Self::default()
    }

    /// Apply parameters based on a request.
    pub fn request<B>(&mut self, req: &Request<B>) -> &mut Self {
        self.request_parts(req.method(), req.headers())
    }

    /// Apply parameters based on request parts.
    pub fn request_parts(&mut self, method: &Method, headers: &HeaderMap) -> &mut Self {
        self.request_method(method);
        self.request_headers(headers);
        self
    }

    /// Apply parameters based on a request method.
    pub fn request_method(&mut self, method: &Method) -> &mut Self {
        self.is_head = *method == Method::HEAD;
        self
    }

    /// Apply parameters based on request headers.
    pub fn request_headers(&mut self, headers: &HeaderMap) -> &mut Self {
        self.if_modified_since_header(headers.get(header::IF_MODIFIED_SINCE));
        self.range_header(headers.get(header::RANGE));
        self.if_range(headers.get(header::IF_RANGE));
        self
    }

    /// Add cache headers to responses for the given lifespan.
    pub fn cache_headers(&mut self, value: Option<u32>) -> &mut Self {
        self.cache_headers = value;
        self
    }

    /// Set whether this is a `HEAD` request, with no response body.
    pub fn is_head(&mut self, value: bool) -> &mut Self {
        self.is_head = value;
        self
    }

    /// Build responses for the given `If-Modified-Since` date-time.
    pub fn if_modified_since(&mut self, value: Option<SystemTime>) -> &mut Self {
        self.if_modified_since = value;
        self
    }

    /// Build responses for the given `If-Modified-Since` request header value.
    pub fn if_modified_since_header(&mut self, value: Option<&header::HeaderValue>) -> &mut Self {
        self.if_modified_since = value
            .and_then(|v| v.to_str().ok())
            .and_then(|v| httpdate::parse_http_date(v).ok());
        self
    }

    /// Build responses for the given `If-Range` request header value.
    pub fn if_range(&mut self, value: Option<&header::HeaderValue>) -> &mut Self {
        if let Some(s) = value.and_then(|s| s.to_str().ok()) {
            self.if_range = Some(s.to_string());
        }
        self
    }

    /// Build responses for the given `Range` request header value.
    pub fn range_header(&mut self, value: Option<&header::HeaderValue>) -> &mut Self {
        self.range = value.and_then(|v| v.to_str().ok()).map(|v| v.to_string());
        self
    }

    /// Build a response for the given resolved file.
    pub fn build<F: IntoFileAccess>(
        &self,
        file: ResolvedFile<F>,
    ) -> Result<Response<Body<F::Output>>> {
        let mut res = ResponseBuilder::new();

        // Set `Last-Modified` and check `If-Modified-Since`.
        let modified = file.modified.filter(|v| {
            v.duration_since(UNIX_EPOCH)
                .ok()
                .filter(|v| v >= &MIN_VALID_MTIME)
                .is_some()
        });

        // default to false when specified, either the etag or last_modified will set
        // it to true later.
        let mut range_cond_ok = self.if_range.is_none();
        if let Some(modified) = modified {
            if let Ok(modified_unix) = modified.duration_since(UNIX_EPOCH) {
                // Compare whole seconds only, because the HTTP date-time
                // format also does not contain a fractional part.
                if let Some(Ok(ims_unix)) =
                    self.if_modified_since.map(|v| v.duration_since(UNIX_EPOCH))
                {
                    if modified_unix.as_secs() <= ims_unix.as_secs() {
                        return ResponseBuilder::new()
                            .status(StatusCode::NOT_MODIFIED)
                            .body(Body::Empty);
                    }
                }

                let etag = format!(
                    "W/\"{0:x}-{1:x}.{2:x}\"",
                    file.size,
                    modified_unix.as_secs(),
                    modified_unix.subsec_nanos()
                );
                if let Some(ref v) = self.if_range {
                    if *v == etag {
                        range_cond_ok = true;
                    }
                }

                res = res.header(header::ETAG, etag);
            }

            let last_modified_formatted = httpdate::fmt_http_date(modified);
            if let Some(ref v) = self.if_range {
                if *v == last_modified_formatted {
                    range_cond_ok = true;
                }
            }

            res = res
                .header(header::LAST_MODIFIED, last_modified_formatted)
                .header(header::ACCEPT_RANGES, "bytes");
        }

        // Build remaining headers.
        if let Some(seconds) = self.cache_headers {
            res = res.header(
                header::CACHE_CONTROL,
                format!("public, max-age={}", seconds),
            );
        }

        if self.is_head {
            res = res.header(header::CONTENT_LENGTH, format!("{}", file.size));
            return res.status(StatusCode::OK).body(Body::Empty);
        }

        let ranges = self.range.as_ref().filter(|_| range_cond_ok).and_then(|r| {
            match HttpRange::parse(r, file.size) {
                Ok(r) => Some(Ok(r)),
                Err(HttpRangeParseError::NoOverlap) => Some(Err(())),
                Err(HttpRangeParseError::InvalidRange) => None,
            }
        });

        if let Some(ranges) = ranges {
            let ranges = match ranges {
                Ok(r) => r,
                Err(()) => {
                    return res
                        .status(StatusCode::RANGE_NOT_SATISFIABLE)
                        .body(Body::Empty);
                }
            };

            if ranges.len() == 1 {
                let single_span = ranges[0];
                res = res
                    .header(
                        header::CONTENT_RANGE,
                        content_range_header(&single_span, file.size),
                    )
                    .header(header::CONTENT_LENGTH, format!("{}", single_span.length));

                let body_stream =
                    FileBytesStreamRange::new(file.handle.into_file_access(), single_span);
                return res
                    .status(StatusCode::PARTIAL_CONTENT)
                    .body(Body::Range(body_stream));
            } else if ranges.len() > 1 {
                let mut boundary_tmp = [0u8; BOUNDARY_LENGTH];

                let mut rng = thread_rng();
                for v in boundary_tmp.iter_mut() {
                    // won't panic since BOUNDARY_CHARS is non-empty
                    *v = *BOUNDARY_CHARS.choose(&mut rng).unwrap();
                }

                // won't panic because boundary_tmp is guaranteed to be all ASCII
                let boundary = std::str::from_utf8(&boundary_tmp[..]).unwrap().to_string();

                res = res.header(
                    hyper::header::CONTENT_TYPE,
                    format!("multipart/byteranges; boundary={}", boundary),
                );

                let mut body_stream = FileBytesStreamMultiRange::new(
                    file.handle.into_file_access(),
                    ranges,
                    boundary,
                    file.size,
                );
                if let Some(content_type) = file.content_type.as_ref() {
                    body_stream.set_content_type(content_type);
                }

                res = res.header(
                    hyper::header::CONTENT_LENGTH,
                    format!("{}", body_stream.compute_length()),
                );

                return res
                    .status(StatusCode::PARTIAL_CONTENT)
                    .body(Body::MultiRange(body_stream));
            }
        }

        res = res.header(header::CONTENT_LENGTH, format!("{}", file.size));
        if let Some(content_type) = file.content_type {
            res = res.header(header::CONTENT_TYPE, content_type);
        }
        if let Some(encoding) = file.encoding {
            res = res.header(header::CONTENT_ENCODING, encoding.to_header_value());
        }

        // Stream the body.
        res.status(StatusCode::OK)
            .body(Body::Full(FileBytesStream::new_with_limit(
                file.handle.into_file_access(),
                file.size,
            )))
    }
}

fn content_range_header(r: &HttpRange, total_length: u64) -> String {
    format!(
        "bytes {}-{}/{}",
        r.start,
        r.start + r.length - 1,
        total_length
    )
}

'''
'''--- src/util/mod.rs ---
mod file_bytes_stream;
mod file_response_builder;
mod requested_path;

pub use self::file_bytes_stream::*;
pub use self::file_response_builder::*;

pub(crate) use self::requested_path::*;

'''
'''--- src/util/requested_path.rs ---
use std::path::{Component, Path, PathBuf};

#[inline]
fn decode_percents(string: &str) -> String {
    percent_encoding::percent_decode_str(string)
        .decode_utf8_lossy()
        .into_owned()
}

fn sanitize_path(path: &Path) -> PathBuf {
    path.components()
        .fold(PathBuf::new(), |mut result, p| match p {
            Component::Normal(x) => {
                // Parse again to prevent a malicious component containing
                // a Windows drive letter, e.g.: `/anypath/c:/windows/win.ini`
                if Path::new(&x)
                    .components()
                    .all(|c| matches!(c, Component::Normal(_)))
                {
                    result.push(x);
                }
                result
            }
            Component::ParentDir => {
                result.pop();
                result
            }
            _ => result,
        })
}

/// Processed request path.
pub struct RequestedPath {
    /// Sanitized path of the request.
    pub sanitized: PathBuf,
    /// Whether a directory was requested. (The input ended with a slash.)
    pub is_dir_request: bool,
}

impl RequestedPath {
    /// Process a request path.
    pub fn resolve(request_path: &str, default_extension: Option<&'static str>) -> Self {
        let is_dir_request = request_path.as_bytes().last() == Some(&b'/');
        let mut request_path = PathBuf::from(decode_percents(request_path));
        if let Some(extension) = default_extension {
            request_path.set_extension(extension);
        }
        RequestedPath {
            sanitized: sanitize_path(&request_path),
            is_dir_request,
        }
    }
}

'''
'''--- src/vfs.rs ---
use std::{
    cmp::min,
    collections::HashMap,
    fs::OpenOptions,
    future::Future,
    io::{Cursor, Error, ErrorKind},
    mem::MaybeUninit,
    path::{Component, Path, PathBuf},
    pin::Pin,
    task::{Context, Poll},
    time::SystemTime,
};

use futures_util::future::{ready, Ready};
use hyper::body::Bytes;
use tokio::{
    fs::{self, File},
    io::{AsyncRead, AsyncSeek, ReadBuf},
    task::{spawn_blocking, JoinHandle},
};

#[cfg(windows)]
use std::os::windows::fs::OpenOptionsExt;
#[cfg(windows)]
use winapi::um::winbase::FILE_FLAG_BACKUP_SEMANTICS;

const TOKIO_READ_BUF_SIZE: usize = 8 * 1024;

/// Open file handle with metadata.
///
/// This struct exists because we want to abstract away tokio `File`, but need to use
/// `File`-specific operations to find the metadata and fill the additional fields here.
///
/// This struct is eventually converted to a `ResolvedFile`.
#[derive(Debug)]
pub struct FileWithMetadata<F = File> {
    /// Open file handle.
    pub handle: F,
    /// Size in bytes.
    pub size: u64,
    /// Last modification time.
    pub modified: Option<SystemTime>,
    /// Whether this is a directory.
    pub is_dir: bool,
}

/// Trait for a simple virtual filesystem layer.
///
/// There is only the `open` operation, hence the name `FileOpener`. In practice, `open` must also
/// collect some file metadata. (See the `FileWithMetadata` struct.)
pub trait FileOpener: Send + Sync + 'static {
    /// File handle type.
    type File: IntoFileAccess;

    /// Future type that `open` returns.
    type Future: Future<Output = Result<FileWithMetadata<Self::File>, Error>> + Send;

    /// Open a file and return a `FileWithMetadata`.
    ///
    /// It can be assumed the path is already sanitized at this point.
    fn open(&self, path: &Path) -> Self::Future;
}

/// Trait that converts a file handle into something that implements `FileAccess`.
///
/// This trait is called when streaming starts, and exists as a separate step so that buffer
/// allocation doesn't have to happen until that point.
pub trait IntoFileAccess: Send + Unpin + 'static {
    /// Target type that implements `FileAccess`.
    type Output: FileAccess;

    /// Convert into a type that implements `FileAccess`.
    fn into_file_access(self) -> Self::Output;
}

/// Trait that implements all the necessary file access methods used for serving files.
///
/// This trait exists as an alternative to `AsyncRead` that returns a `Bytes` directly, potentially
/// eliminating a copy. Unlike `AsyncRead`, this does mean the implementation is responsible for
/// providing the read buffer.
pub trait FileAccess: AsyncSeek + Send + Unpin + 'static {
    /// Attempts to read from the file.
    ///
    /// If no data is available for reading, the method returns `Poll::Pending` and arranges for
    /// the current task (via `cx.waker()`) to receive a notification when the object becomes
    /// readable or is closed.
    ///
    /// An empty `Bytes` return value indicates EOF.
    fn poll_read(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        len: usize,
    ) -> Poll<Result<Bytes, Error>>;
}

//
// Tokio File implementation
//

impl IntoFileAccess for File {
    type Output = TokioFileAccess;

    fn into_file_access(self) -> Self::Output {
        TokioFileAccess::new(self)
    }
}

/// Struct that wraps a tokio `File` to implement `FileAccess`.
pub struct TokioFileAccess {
    file: File,
    read_buf: Box<[MaybeUninit<u8>; TOKIO_READ_BUF_SIZE]>,
}

impl TokioFileAccess {
    /// Create a new `TokioFileAccess` for a `File`.
    pub fn new(file: File) -> Self {
        TokioFileAccess {
            file,
            read_buf: Box::new([MaybeUninit::uninit(); TOKIO_READ_BUF_SIZE]),
        }
    }
}

impl AsyncSeek for TokioFileAccess {
    fn start_seek(mut self: Pin<&mut Self>, position: std::io::SeekFrom) -> std::io::Result<()> {
        Pin::new(&mut self.file).start_seek(position)
    }

    fn poll_complete(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<std::io::Result<u64>> {
        Pin::new(&mut self.file).poll_complete(cx)
    }
}

impl FileAccess for TokioFileAccess {
    fn poll_read(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        len: usize,
    ) -> Poll<Result<Bytes, Error>> {
        let Self {
            ref mut file,
            ref mut read_buf,
        } = *self;

        let len = min(len, read_buf.len()) as usize;
        let mut read_buf = ReadBuf::uninit(&mut read_buf[..len]);
        match Pin::new(file).poll_read(cx, &mut read_buf) {
            Poll::Ready(Ok(())) => {
                let filled = read_buf.filled();
                if filled.is_empty() {
                    Poll::Ready(Ok(Bytes::new()))
                } else {
                    Poll::Ready(Ok(Bytes::copy_from_slice(filled)))
                }
            }
            Poll::Ready(Err(e)) => Poll::Ready(Err(e)),
            Poll::Pending => Poll::Pending,
        }
    }
}

/// Filesystem implementation that uses `tokio::fs`.
pub struct TokioFileOpener {
    /// The virtual root directory to use when opening files.
    ///
    /// The path may be absolute or relative.
    pub root: PathBuf,
}

impl TokioFileOpener {
    /// Create a new `TokioFileOpener` for the given root path.
    ///
    /// The path may be absolute or relative.
    pub fn new(root: impl Into<PathBuf>) -> Self {
        Self { root: root.into() }
    }
}

impl FileOpener for TokioFileOpener {
    type File = File;
    type Future = TokioFileFuture;

    fn open(&self, path: &Path) -> Self::Future {
        let mut full_path = self.root.clone();
        full_path.extend(path);

        // Small perf gain: we do open + metadata in one go. If we used the tokio async functions
        // here, that'd amount to two `spawn_blocking` calls behind the scenes.
        let inner = spawn_blocking(move || {
            let mut opts = OpenOptions::new();
            opts.read(true);

            // On Windows, we need to set this flag to be able to open directories.
            #[cfg(windows)]
            opts.custom_flags(FILE_FLAG_BACKUP_SEMANTICS);

            let handle = opts.open(full_path)?;
            let metadata = handle.metadata()?;
            Ok(FileWithMetadata {
                handle: File::from_std(handle),
                size: metadata.len(),
                modified: metadata.modified().ok(),
                is_dir: metadata.is_dir(),
            })
        });

        TokioFileFuture { inner }
    }
}

/// Future type produced by `TokioFileOpener`.
///
/// This type mostly exists just to prevent a `Box<dyn Future>`.
pub struct TokioFileFuture {
    inner: JoinHandle<Result<FileWithMetadata<File>, Error>>,
}

impl Future for TokioFileFuture {
    type Output = Result<FileWithMetadata<File>, Error>;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        // The task produces a result, but so does the `JoinHandle`, so this is a
        // `Result<Result<..>>`. We map the `JoinHandle` error to an IO error, so that we can
        // flatten the results. This is similar to what tokio does, but that just uses `Map` and
        // async functions (with an anonymous future type).
        match Pin::new(&mut self.inner).poll(cx) {
            Poll::Ready(Ok(res)) => Poll::Ready(res),
            Poll::Ready(Err(_)) => {
                Poll::Ready(Err(Error::new(ErrorKind::Other, "background task failed")))
            }
            Poll::Pending => Poll::Pending,
        }
    }
}

//
// In-memory implementation
//

type MemoryFileMap = HashMap<PathBuf, FileWithMetadata<Bytes>>;

impl IntoFileAccess for Cursor<Bytes> {
    type Output = Self;

    fn into_file_access(self) -> Self::Output {
        // No read buffer required. We can simply create subslices.
        self
    }
}

impl FileAccess for Cursor<Bytes> {
    fn poll_read(
        self: Pin<&mut Self>,
        _cx: &mut Context<'_>,
        len: usize,
    ) -> Poll<Result<Bytes, Error>> {
        let pos = self.position();
        let slice = (*self).get_ref();

        // The position could technically be out of bounds, so don't panic...
        if pos > slice.len() as u64 {
            return Poll::Ready(Ok(Bytes::new()));
        }

        let start = pos as usize;
        let amt = min(slice.len() - start, len);
        // Add won't overflow because of pos check above.
        let end = start + amt;
        Poll::Ready(Ok(slice.slice(start..end)))
    }
}

/// An in-memory virtual filesystem.
///
/// This type implements `FileOpener`, and can be directly used in `Static::with_opener`, for example.
pub struct MemoryFs {
    files: MemoryFileMap,
}

impl Default for MemoryFs {
    fn default() -> Self {
        let mut files = MemoryFileMap::new();

        // Create a top-level directory entry.
        files.insert(
            PathBuf::new(),
            FileWithMetadata {
                handle: Bytes::new(),
                size: 0,
                modified: None,
                is_dir: true,
            },
        );

        Self { files }
    }
}

impl MemoryFs {
    /// Initialize a `MemoryFs` from a directory.
    ///
    /// This loads all files and their contents into memory. Symlinks are followed.
    pub async fn from_dir(path: impl AsRef<Path>) -> Result<Self, Error> {
        let mut fs = Self::default();

        // Pending directories to scan, as: `(real path, virtual path)`
        let mut dirs = vec![(path.as_ref().to_path_buf(), PathBuf::new())];
        while let Some((dir, base)) = dirs.pop() {
            let mut iter = fs::read_dir(dir).await?;
            while let Some(entry) = iter.next_entry().await? {
                let metadata = entry.metadata().await?;

                // Build the virtual path.
                let mut out_path = base.to_path_buf();
                out_path.push(entry.file_name());

                if metadata.is_dir() {
                    // Add to pending stack,
                    dirs.push((entry.path(), out_path));
                } else if metadata.is_file() {
                    // Read file contents and create an entry.
                    let data = fs::read(entry.path()).await?;
                    fs.add(out_path, data.into(), metadata.modified().ok());
                }
            }
        }

        Ok(fs)
    }

    /// Add a file to the `MemoryFs`.
    ///
    /// This automatically creates directory entries leading up to the path. Any existing entries
    /// are overwritten.
    pub fn add(
        &mut self,
        path: impl Into<PathBuf>,
        data: Bytes,
        modified: Option<SystemTime>,
    ) -> &mut Self {
        let path = path.into();

        // Create directory entries.
        let mut components: Vec<_> = path.components().collect();
        components.pop();
        let mut dir_path = PathBuf::new();
        for component in components {
            if let Component::Normal(x) = component {
                dir_path.push(x);
                self.files.insert(
                    dir_path.clone(),
                    FileWithMetadata {
                        handle: Bytes::new(),
                        size: 0,
                        modified: None,
                        is_dir: true,
                    },
                );
            }
        }

        // Create the file entry.
        let size = data.len() as u64;
        self.files.insert(
            path,
            FileWithMetadata {
                handle: data,
                size,
                modified,
                is_dir: false,
            },
        );

        self
    }
}

impl FileOpener for MemoryFs {
    type File = Cursor<Bytes>;
    type Future = Ready<Result<FileWithMetadata<Self::File>, Error>>;

    fn open(&self, path: &Path) -> Self::Future {
        ready(
            self.files
                .get(path)
                .map(|file| FileWithMetadata {
                    handle: Cursor::new(file.handle.clone()),
                    size: file.size,
                    modified: file.modified,
                    is_dir: file.is_dir,
                })
                .ok_or_else(|| Error::new(ErrorKind::NotFound, "Not found")),
        )
    }
}

'''
'''--- tests/hyper.rs ---
use std::path::Path;

use hyper_staticfile::Static;

use hyper_util::rt::TokioIo;

// This test currently only demonstrates that a `Static` instance can be used
// as a hyper service directly.
#[tokio::test]
async fn test_usable_as_hyper_service() {
    let static_ = Static::new(Path::new("target/doc/"));

    let (stream, _) = tokio::io::duplex(2);
    let fut =
        hyper::server::conn::http1::Builder::new().serve_connection(TokioIo::new(stream), static_);

    // It's enough to show that this builds, so no need to execute anything.
    drop(fut);
}

'''
'''--- tests/static.rs ---
use std::{
    fs,
    future::Future,
    io::{Cursor, Error as IoError, Read, Write},
    process::Command,
    str,
    time::{Duration, SystemTime},
};

use http::{header, Request, StatusCode};
use http_body_util::BodyExt;
use httpdate::fmt_http_date;
use hyper::body::Buf;
use hyper_staticfile::{
    vfs::{FileAccess, MemoryFs},
    AcceptEncoding, Body, Encoding, Static,
};
use tempfile::TempDir;

type Response = hyper::Response<Body>;
type ResponseResult = Result<Response, IoError>;

struct Harness {
    dir: TempDir,
    static_: Static,
}
impl Harness {
    fn new(files: Vec<(&str, &str)>) -> Harness {
        let dir = Self::create_temp_dir(files);

        let mut static_ = Static::new(dir.path());
        static_
            .cache_headers(Some(3600))
            .allowed_encodings(AcceptEncoding::all());

        Harness { dir, static_ }
    }

    fn create_temp_dir(files: Vec<(&str, &str)>) -> TempDir {
        let dir = TempDir::new().unwrap();
        for (subpath, contents) in files {
            let fullpath = dir.path().join(subpath);
            fs::create_dir_all(fullpath.parent().unwrap())
                .and_then(|_| fs::File::create(fullpath))
                .and_then(|mut file| file.write_all(contents.as_bytes()))
                .expect("failed to write fixtures");
        }
        dir
    }

    fn append(&self, subpath: &str, content: &str) {
        let path = self.dir.path().join(subpath);
        let mut f = fs::File::options()
            .append(true)
            .open(path)
            .expect("failed to append to fixture");
        f.write_all(content.as_bytes())
            .expect("failed to append to fixture");
    }

    fn request<B>(&self, req: Request<B>) -> impl Future<Output = ResponseResult> {
        self.static_.clone().serve(req)
    }

    fn get(&self, path: &str) -> impl Future<Output = ResponseResult> {
        let req = Request::builder()
            .uri(path)
            .body(())
            .expect("unable to build request");
        self.request(req)
    }
}

async fn read_body<F: FileAccess>(res: hyper::Response<Body<F>>) -> String {
    let mut body = String::new();
    res.into_body()
        .collect()
        .await
        .unwrap()
        .aggregate()
        .reader()
        .read_to_string(&mut body)
        .unwrap();
    body
}

#[tokio::test]
async fn serves_non_default_file_from_absolute_root_path() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/file1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn serves_default_file_from_absolute_root_path() {
    let harness = Harness::new(vec![("index.html", "this is index")]);

    let res = harness.get("/index.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is index");
}

#[tokio::test]
async fn serves_default_file_from_empty_root_path() {
    let harness = Harness::new(vec![("index.html", "this is index")]);

    let res = harness.get("/").await.unwrap();
    assert_eq!(read_body(res).await, "this is index");
}

#[tokio::test]
async fn returns_404_if_file_not_found() {
    let harness = Harness::new(vec![]);

    let res = harness.get("/").await.unwrap();
    assert_eq!(res.status(), StatusCode::NOT_FOUND);
}

#[tokio::test]
async fn redirects_if_trailing_slash_is_missing() {
    let harness = Harness::new(vec![("foo/bar/index.html", "this is index")]);

    let res = harness.get("/foo/bar").await.unwrap();
    assert_eq!(res.status(), StatusCode::MOVED_PERMANENTLY);

    let url = res.headers().get(header::LOCATION).unwrap();
    assert_eq!(url, "/foo/bar/");
}

#[tokio::test]
async fn redirects_to_sanitized_path() {
    let harness = Harness::new(vec![("foo.org/bar/index.html", "this is index")]);

    // Previous versions would base the redirect on the request path, but that is user input, and
    // the user could construct a schema-relative redirect this way.
    let res = harness.get("//foo.org/bar").await.unwrap();
    assert_eq!(res.status(), StatusCode::MOVED_PERMANENTLY);

    let url = res.headers().get(header::LOCATION).unwrap();
    // TODO: The request path is apparently parsed differently on Windows, but at least the
    // resulting redirect is still safe, and that's the important part.
    if cfg!(target_os = "windows") {
        assert_eq!(url, "/");
    } else {
        assert_eq!(url, "/foo.org/bar/");
    }
}

#[tokio::test]
async fn decodes_percent_notation() {
    let harness = Harness::new(vec![("has space.html", "file with funky chars")]);

    let res = harness.get("/has%20space.html").await.unwrap();
    assert_eq!(read_body(res).await, "file with funky chars");
}

#[tokio::test]
async fn normalizes_path() {
    let harness = Harness::new(vec![("index.html", "this is index")]);

    let res = harness.get("/xxx/../index.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is index");
}

#[tokio::test]
async fn normalizes_percent_encoded_path() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/xxx/..%2ffile1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn prevents_from_escaping_root() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/../file1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");

    let res = harness.get("/..%2ffile1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");

    let res = harness.get("/xxx/..%2f..%2ffile1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn sends_headers() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/file1.html").await.unwrap();
    assert_eq!(res.status(), StatusCode::OK);
    assert_eq!(res.headers().get(header::CONTENT_LENGTH).unwrap(), "13");
    assert!(res.headers().get(header::LAST_MODIFIED).is_some());
    assert!(res.headers().get(header::ETAG).is_some());
    assert_eq!(
        res.headers().get(header::CACHE_CONTROL).unwrap(),
        "public, max-age=3600"
    );
    assert_eq!(
        res.headers().get(header::CONTENT_TYPE),
        Some(&header::HeaderValue::from_static("text/html"))
    );

    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn content_length() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/file1.html").await.unwrap();
    harness.append("file1.html", "more content");
    assert_eq!(res.headers().get(header::CONTENT_LENGTH).unwrap(), "13");
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn changes_content_type_on_extension() {
    let harness = Harness::new(vec![("file1.gif", "this is file1")]);

    let res = harness.get("/file1.gif").await.unwrap();
    assert_eq!(
        res.headers().get(header::CONTENT_TYPE),
        Some(&header::HeaderValue::from_static("image/gif"))
    );
}

#[tokio::test]
async fn serves_file_with_old_if_modified_since() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let if_modified = SystemTime::now() - Duration::from_secs(3600);
    let req = Request::builder()
        .uri("/file1.html")
        .header(header::IF_MODIFIED_SINCE, fmt_http_date(if_modified))
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn serves_file_with_new_if_modified_since() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let if_modified = SystemTime::now() + Duration::from_secs(3600);
    let req = Request::builder()
        .uri("/file1.html")
        .header(header::IF_MODIFIED_SINCE, fmt_http_date(if_modified))
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(res.status(), StatusCode::NOT_MODIFIED);
}

#[cfg(target_family = "unix")]
#[tokio::test]
async fn last_modified_is_gmt() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let mut file_path = harness.dir.path().to_path_buf();
    file_path.push("file1.html");
    let status = Command::new("touch")
        .args(&["-t", "198510260122.00"])
        .arg(file_path)
        .env("TZ", "UTC")
        .status()
        .unwrap();
    assert!(status.success());

    let res = harness.get("/file1.html").await.unwrap();
    assert_eq!(
        res.headers()
            .get(header::LAST_MODIFIED)
            .map(|val| val.to_str().unwrap()),
        Some("Sat, 26 Oct 1985 01:22:00 GMT")
    );
}

#[cfg(target_family = "unix")]
#[tokio::test]
async fn no_headers_for_invalid_mtime() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let mut file_path = harness.dir.path().to_path_buf();
    file_path.push("file1.html");
    let status = Command::new("touch")
        .args(&["-t", "197001010000.01"])
        .arg(file_path)
        .env("TZ", "UTC")
        .status()
        .unwrap();
    assert!(status.success());

    let res = harness.get("/file1.html").await.unwrap();
    assert!(res.headers().get(header::ETAG).is_none());
}

#[tokio::test]
async fn serves_file_ranges_beginning() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=0-3")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(read_body(res).await, "this");
}

#[tokio::test]
async fn serves_file_ranges_end() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=5-")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(read_body(res).await, "is file1");
}

#[tokio::test]
async fn serves_file_ranges_multi() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=0-3, 5-")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    let content_type = res
        .headers()
        .get(header::CONTENT_TYPE)
        .unwrap()
        .to_str()
        .unwrap();
    assert!(content_type.starts_with("multipart/byteranges; boundary="));
    let boundary = &content_type[31..];

    let mut body_expectation = Cursor::new(Vec::new());
    write!(&mut body_expectation, "--{}\r\n", boundary).unwrap();
    write!(&mut body_expectation, "Content-Range: bytes 0-3/13\r\n").unwrap();
    write!(&mut body_expectation, "Content-Type: text/html\r\n").unwrap();
    write!(&mut body_expectation, "\r\n").unwrap();
    write!(&mut body_expectation, "this\r\n").unwrap();

    write!(&mut body_expectation, "--{}\r\n", boundary).unwrap();
    write!(&mut body_expectation, "Content-Range: bytes 5-12/13\r\n").unwrap();
    write!(&mut body_expectation, "Content-Type: text/html\r\n").unwrap();
    write!(&mut body_expectation, "\r\n").unwrap();
    write!(&mut body_expectation, "is file1\r\n").unwrap();
    write!(&mut body_expectation, "--{}--\r\n", boundary).unwrap();
    let body_expectation = String::from_utf8(body_expectation.into_inner()).unwrap();
    assert_eq!(read_body(res).await, body_expectation);
}

#[tokio::test]
async fn serves_file_ranges_multi_assert_content_length_correct() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=0-3, 5-")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();

    let content_length: usize = res
        .headers()
        .get(header::CONTENT_LENGTH)
        .unwrap()
        .to_str()
        .unwrap()
        .parse()
        .unwrap();

    assert_eq!(read_body(res).await.len(), content_length);
}

#[tokio::test]
async fn serves_file_ranges_if_range_negative() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=5-")
        .header(header::IF_RANGE, "Sat, 26 Oct 1985 01:22:00 GMT")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    // whole thing comes back since If-Range didn't match
    assert_eq!(read_body(res).await, "this is file1");
}

#[tokio::test]
async fn serves_file_ranges_if_range_etag_positive() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    // first request goes out without etag to fetch etag
    let req = Request::builder()
        .uri("/file1.html")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    let etag_value = res.headers().get(header::ETAG).unwrap();

    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=5-")
        .header(header::IF_RANGE, etag_value)
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(read_body(res).await, "is file1");
}

#[tokio::test]
async fn serves_requested_range_not_satisfiable_when_at_end() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);
    let req = Request::builder()
        .uri("/file1.html")
        .header(header::RANGE, "bytes=13-")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(res.status(), hyper::StatusCode::RANGE_NOT_SATISFIABLE);
}

#[tokio::test]
async fn serves_gzip() {
    let harness = Harness::new(vec![
        ("file1.html", "this is file1"),
        ("file1.html.gz", "fake gzip compression"),
    ]);
    let req = Request::builder()
        .uri("/file1.html")
        .header(header::ACCEPT_ENCODING, "gzip")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(
        res.headers().get(header::CONTENT_ENCODING),
        Some(&Encoding::Gzip.to_header_value())
    );
    assert_eq!(read_body(res).await, "fake gzip compression");
}

#[tokio::test]
async fn serves_br() {
    let harness = Harness::new(vec![
        ("file1.html", "this is file1"),
        ("file1.html.br", "fake brotli compression"),
        ("file1.html.gz", "fake gzip compression"),
    ]);
    let req = Request::builder()
        .uri("/file1.html")
        .header(header::ACCEPT_ENCODING, "br;q=1.0, gzip;q=0.5")
        .body(())
        .expect("unable to build request");

    let res = harness.request(req).await.unwrap();
    assert_eq!(
        res.headers().get(header::CONTENT_ENCODING),
        Some(&Encoding::Br.to_header_value())
    );
    assert_eq!(read_body(res).await, "fake brotli compression");
}

#[tokio::test]
async fn test_memory_fs() {
    let dir = Harness::create_temp_dir(vec![
        ("index.html", "root index"),
        ("nested/index.html", "nested index"),
    ]);
    let fs = MemoryFs::from_dir(dir.path())
        .await
        .expect("MemoryFs failed");
    dir.close().expect("tempdir cleanup failed");

    let static_ = Static::with_opener(fs);

    let req = Request::builder()
        .uri("/")
        .body(())
        .expect("unable to build request");
    let res = static_.clone().serve(req).await.unwrap();
    assert_eq!(read_body(res).await, "root index");

    let req = Request::builder()
        .uri("/nested/")
        .body(())
        .expect("unable to build request");
    let res = static_.serve(req).await.unwrap();
    assert_eq!(read_body(res).await, "nested index");
}

#[cfg(target_os = "windows")]
#[tokio::test]
async fn ignore_windows_drive_letter() {
    let harness = Harness::new(vec![("file1.html", "this is file1")]);

    let res = harness.get("/c:/file1.html").await.unwrap();
    assert_eq!(read_body(res).await, "this is file1");
}

'''