*GitHub Repository "nearprotocol/_archived_js-ipfs"*

'''--- .aegir.js ---
'use strict'

const IPFSFactory = require('ipfsd-ctl')
const parallel = require('async/parallel')
const MockPreloadNode = require('./test/utils/mock-preload-node')

const ipfsdServer = IPFSFactory.createServer()
const preloadNode = MockPreloadNode.createNode()

module.exports = {
  webpack: {
    resolve: {
      mainFields: ['browser', 'main']
    }
  },
  karma: {
    files: [{
      pattern: 'node_modules/interface-ipfs-core/js/test/fixtures/**/*',
      watched: false,
      served: true,
      included: false
    }],
    browserNoActivityTimeout: 100 * 1000,
    singleRun: true
  },
  hooks: {
    node: {
      pre: (cb) => preloadNode.start(cb),
      post: (cb) => preloadNode.stop(cb)
    },
    browser: {
      pre: (cb) => {
        parallel([
          (cb) => {
            ipfsdServer.start()
            cb()
          },
          (cb) => preloadNode.start(cb)
        ], cb)
      },
      post: (cb) => {
        parallel([
          (cb) => {
            ipfsdServer.stop()
            cb()
          },
          (cb) => preloadNode.stop(cb)
        ], cb)
      }
    }
  }
}

'''
'''--- CHANGELOG.md ---
<a name="0.34.4"></a>
## [0.34.4](https://github.com/ipfs/js-ipfs/compare/v0.34.3...v0.34.4) (2019-01-24)

### Features

* support _dnslink subdomain specified dnslinks ([#1843](https://github.com/ipfs/js-ipfs/issues/1843)) ([a17253e](https://github.com/ipfs/js-ipfs/commit/a17253e))

<a name="0.34.3"></a>
## [0.34.3](https://github.com/ipfs/js-ipfs/compare/v0.34.2...v0.34.3) (2019-01-24)

### Bug Fixes

* add cors support for preload-mock-server and update aegir ([#1839](https://github.com/ipfs/js-ipfs/issues/1839)) ([2d45c9d](https://github.com/ipfs/js-ipfs/commit/2d45c9d))

<a name="0.34.2"></a>
## [0.34.2](https://github.com/ipfs/js-ipfs/compare/v0.34.1...v0.34.2) (2019-01-21)

### Bug Fixes

* race condition causing Database is not open error ([#1834](https://github.com/ipfs/js-ipfs/issues/1834)) ([6066c97](https://github.com/ipfs/js-ipfs/commit/6066c97))

### Features

* use ws-star-multi instead of ws-star ([#1793](https://github.com/ipfs/js-ipfs/issues/1793)) ([21fd4d1](https://github.com/ipfs/js-ipfs/commit/21fd4d1))

<a name="0.34.1"></a>
## [0.34.1](https://github.com/ipfs/js-ipfs/compare/v0.34.0...v0.34.1) (2019-01-21)

### Features

* pipe to add ([#1833](https://github.com/ipfs/js-ipfs/issues/1833)) ([ea53071](https://github.com/ipfs/js-ipfs/commit/ea53071))

<a name="0.34.0"></a>
# [0.34.0](https://github.com/ipfs/js-ipfs/compare/v0.34.0-rc.1...v0.34.0) (2019-01-17)

<a name="0.34.0-rc.1"></a>
# [0.34.0-rc.1](https://github.com/ipfs/js-ipfs/compare/v0.34.0-rc.0...v0.34.0-rc.1) (2019-01-15)

### Bug Fixes

* sharness tests ([#1787](https://github.com/ipfs/js-ipfs/issues/1787)) ([48d3e2b](https://github.com/ipfs/js-ipfs/commit/48d3e2b))

### Code Refactoring

* switch to bignumber.js ([#1803](https://github.com/ipfs/js-ipfs/issues/1803)) ([6de6adf](https://github.com/ipfs/js-ipfs/commit/6de6adf))

### Features

* update to Web UI v2.3.2 ([#1807](https://github.com/ipfs/js-ipfs/issues/1807)) ([8ca6471](https://github.com/ipfs/js-ipfs/commit/8ca6471))
* update Web UI to v2.3.0 ([#1786](https://github.com/ipfs/js-ipfs/issues/1786)) ([7bcc496](https://github.com/ipfs/js-ipfs/commit/7bcc496))

### BREAKING CHANGES

* All API methods that returned [`big.js`](https://github.com/MikeMcl/big.js/) instances now return [`bignumber.js`](https://github.com/MikeMcl/bignumber.js/) instances.

License: MIT
Signed-off-by: Alan Shaw <alan.shaw@protocol.ai>

<a name="0.34.0-rc.0"></a>
# [0.34.0-rc.0](https://github.com/ipfs/js-ipfs/compare/v0.34.0-pre.0...v0.34.0-rc.0) (2018-12-18)

### Bug Fixes

* link to Github profile for David Dias ([3659d7e](https://github.com/ipfs/js-ipfs/commit/3659d7e))
* streaming cat over http api ([#1760](https://github.com/ipfs/js-ipfs/issues/1760)) ([3ded576](https://github.com/ipfs/js-ipfs/commit/3ded576))

### Features

* add `addFromFs` method ([#1777](https://github.com/ipfs/js-ipfs/issues/1777)) ([7315aa1](https://github.com/ipfs/js-ipfs/commit/7315aa1))
* add from url/stream ([#1773](https://github.com/ipfs/js-ipfs/issues/1773)) ([b6a7ab6](https://github.com/ipfs/js-ipfs/commit/b6a7ab6))
* add slient option ([#1712](https://github.com/ipfs/js-ipfs/issues/1712)) ([593334b](https://github.com/ipfs/js-ipfs/commit/593334b))
* cid base option ([#1552](https://github.com/ipfs/js-ipfs/issues/1552)) ([6d46e2e](https://github.com/ipfs/js-ipfs/commit/6d46e2e)), closes [/github.com/ipfs/go-ipfs/issues/5349#issuecomment-445104823](https://github.com//github.com/ipfs/go-ipfs/issues/5349/issues/issuecomment-445104823)

<a name="0.34.0-pre.0"></a>
# [0.34.0-pre.0](https://github.com/ipfs/js-ipfs/compare/v0.33.1...v0.34.0-pre.0) (2018-12-07)

### Bug Fixes

* add dash case to pin cli ([#1719](https://github.com/ipfs/js-ipfs/issues/1719)) ([eacd580](https://github.com/ipfs/js-ipfs/commit/eacd580))
* add missing dependencies ([#1663](https://github.com/ipfs/js-ipfs/issues/1663)) ([4bcf4a7](https://github.com/ipfs/js-ipfs/commit/4bcf4a7))
* allow disabling mfs preload from config ([#1733](https://github.com/ipfs/js-ipfs/issues/1733)) ([5f66538](https://github.com/ipfs/js-ipfs/commit/5f66538))
* better error message when pubsub is not enabled ([#1729](https://github.com/ipfs/js-ipfs/issues/1729)) ([5237dd9](https://github.com/ipfs/js-ipfs/commit/5237dd9))
* examples after files API refactor ([#1740](https://github.com/ipfs/js-ipfs/issues/1740)) ([34ec036](https://github.com/ipfs/js-ipfs/commit/34ec036))
* ipns datastore key ([#1741](https://github.com/ipfs/js-ipfs/issues/1741)) ([a39770e](https://github.com/ipfs/js-ipfs/commit/a39770e))
* make circuit relay test ([#1710](https://github.com/ipfs/js-ipfs/issues/1710)) ([345ce91](https://github.com/ipfs/js-ipfs/commit/345ce91))
* remove electron-webrtc and wrtc for now ([#1718](https://github.com/ipfs/js-ipfs/issues/1718)) ([b6b50d5](https://github.com/ipfs/js-ipfs/commit/b6b50d5))

### Code Refactoring

* files API ([#1720](https://github.com/ipfs/js-ipfs/issues/1720)) ([a82a5dc](https://github.com/ipfs/js-ipfs/commit/a82a5dc))
* object APIs write methods now return CIDs ([#1730](https://github.com/ipfs/js-ipfs/issues/1730)) ([ac5fa8e](https://github.com/ipfs/js-ipfs/commit/ac5fa8e)), closes [/github.com/ipfs/interface-ipfs-core/pull/388#pullrequestreview-173866270](https://github.com//github.com/ipfs/interface-ipfs-core/pull/388/issues/pullrequestreview-173866270)

### Features

* ipns over dht ([#1725](https://github.com/ipfs/js-ipfs/issues/1725)) ([1a943f8](https://github.com/ipfs/js-ipfs/commit/1a943f8))
* ipns over pubsub ([#1559](https://github.com/ipfs/js-ipfs/issues/1559)) ([8712542](https://github.com/ipfs/js-ipfs/commit/8712542))
* Web UI updated to v2.2.0 ([#1711](https://github.com/ipfs/js-ipfs/issues/1711)) ([b2158bc](https://github.com/ipfs/js-ipfs/commit/b2158bc))

### Performance Improvements

* lazy load IPLD formats ([#1704](https://github.com/ipfs/js-ipfs/issues/1704)) ([aefb261](https://github.com/ipfs/js-ipfs/commit/aefb261))

### BREAKING CHANGES

* Object API refactor.

Object API methods that write DAG nodes now return a [CID](https://www.npmjs.com/package/cids) instead of a DAG node. Affected methods:

* `ipfs.object.new`
* `ipfs.object.patch.addLink`
* `ipfs.object.patch.appendData`
* `ipfs.object.patch.rmLink`
* `ipfs.object.patch.setData`
* `ipfs.object.put`

Example:

```js
// Before
const dagNode = await ipfs.object.new()
```

```js
// After
const cid = await ipfs.object.new() // now returns a CID
const dagNode = await ipfs.object.get(cid) // fetch the DAG node that was created
```

IMPORTANT: `DAGNode` instances, which are part of the IPLD dag-pb format have been refactored.

These instances no longer have `multihash`, `cid` or `serialized` properties.

This effects the following API methods that return these types of objects:

* `ipfs.object.get`
* `ipfs.dag.get`

See https://github.com/ipld/js-ipld-dag-pb/pull/99 for more information.

License: MIT
Signed-off-by: Alan Shaw <alan.shaw@protocol.ai>
* Files API methods `add*`, `cat*`, `get*` have moved from `files` to the root namespace.

Specifically, the following changes have been made:

* `ipfs.files.add` => `ipfs.add`
* `ipfs.files.addPullStream` => `ipfs.addPullStream`
* `ipfs.files.addReadableStream` => `ipfs.addReadableStream`
* `ipfs.files.cat` => `ipfs.cat`
* `ipfs.files.catPullStream` => `ipfs.catPullStream`
* `ipfs.files.catReadableStream` => `ipfs.catReadableStream`
* `ipfs.files.get` => `ipfs.get`
* `ipfs.files.getPullStream` => `ipfs.getPullStream`
* `ipfs.files.getReadableStream` => `ipfs.getReadableStream`

License: MIT
Signed-off-by: Alan Shaw <alan.shaw@protocol.ai>

<a name="0.33.1"></a>
## [0.33.1](https://github.com/ipfs/js-ipfs/compare/v0.33.0...v0.33.1) (2018-11-05)

### Bug Fixes

* over eager preload ([#1693](https://github.com/ipfs/js-ipfs/issues/1693)) ([f14c20d](https://github.com/ipfs/js-ipfs/commit/f14c20d))

<a name="0.33.0"></a>
# [0.33.0](https://github.com/ipfs/js-ipfs/compare/v0.33.0-rc.4...v0.33.0) (2018-11-01)

<a name="0.33.0-rc.4"></a>
# [0.33.0-rc.4](https://github.com/ipfs/js-ipfs/compare/v0.33.0-rc.3...v0.33.0-rc.4) (2018-11-01)

### Bug Fixes

* remove accidentally committed code ([66fa8ef](https://github.com/ipfs/js-ipfs/commit/66fa8ef))
* remove local option from global commands ([#1648](https://github.com/ipfs/js-ipfs/issues/1648)) ([8e963f9](https://github.com/ipfs/js-ipfs/commit/8e963f9))
* remove npm script ([df32ac4](https://github.com/ipfs/js-ipfs/commit/df32ac4))
* remove unused deps ([f7189fb](https://github.com/ipfs/js-ipfs/commit/f7189fb))
* use class is function on ipns ([#1617](https://github.com/ipfs/js-ipfs/issues/1617)) ([c240d49](https://github.com/ipfs/js-ipfs/commit/c240d49)), closes [js-peer-id#84](https://github.com/js-peer-id/issues/84) [interface-datastore#24](https://github.com/interface-datastore/issues/24) [#1615](https://github.com/ipfs/js-ipfs/issues/1615)

### Chores

* remove ipld formats re-export ([#1626](https://github.com/ipfs/js-ipfs/issues/1626)) ([3ee7b5e](https://github.com/ipfs/js-ipfs/commit/3ee7b5e))
* update to js-ipld 0.19 ([#1668](https://github.com/ipfs/js-ipfs/issues/1668)) ([74edafd](https://github.com/ipfs/js-ipfs/commit/74edafd))

### Features

* add support to pass config in the init cmd ([#1662](https://github.com/ipfs/js-ipfs/issues/1662)) ([588891c](https://github.com/ipfs/js-ipfs/commit/588891c))
* get Ping to work properly ([27d5a57](https://github.com/ipfs/js-ipfs/commit/27d5a57))

### BREAKING CHANGES

* dag-cbor nodes now represent links as CID objects

The API for [dag-cbor](https://github.com/ipld/js-ipld-dag-cbor) changed.
Links are no longer represented as JSON objects (`{"/": "base-encoded-cid"}`,
but as [CID objects](https://github.com/ipld/js-cid). `ipfs.dag.get()` and now always return links as CID objects. `ipfs.dag.put()` also expects links to be represented as CID objects. The old-style JSON objects representation is still
supported, but deprecated.

Prior to this change:

```js
const cid = new CID('QmXed8RihWcWFXRRmfSRG9yFjEbXNxu1bDwgCFAN8Dxcq5')
// Link as JSON object representation
const putCid = await ipfs.dag.put({link: {'/': cid.toBaseEncodedString()}})
const result = await ipfs.dag.get(putCid)
console.log(result.value)

```

Output:

```js
{ link:
   { '/':
      <Buffer 12 20 8a…> } }
```

Now:

```js
const cid = new CID('QmXed8RihWcWFXRRmfSRG9yFjEbXNxu1bDwgCFAN8Dxcq5')
// Link as CID object
const putCid = await ipfs.dag.put({link: cid})
const result = await ipfs.dag.get(putCid)
console.log(result.value)
```

Output:

```js
{ link:
   CID {
     codec: 'dag-pb',
     version: 0,
     multihash:
      <Buffer 12 20 8a…> } }
```

See https://github.com/ipld/ipld/issues/44 for more information on why this
change was made.
* remove `types.dagCBOR` and `types.dagPB` from public API

If you need the `ipld-dag-cbor` or `ipld-dag-pb` module in the Browser,
you need to bundle them yourself.

<a name="0.33.0-rc.3"></a>
# [0.33.0-rc.3](https://github.com/ipfs/js-ipfs/compare/v0.33.0-rc.2...v0.33.0-rc.3) (2018-10-24)

<a name="0.33.0-rc.2"></a>
# [0.33.0-rc.2](https://github.com/ipfs/js-ipfs/compare/v0.33.0-rc.1...v0.33.0-rc.2) (2018-10-23)

<a name="0.33.0-rc.1"></a>
# [0.33.0-rc.1](https://github.com/ipfs/js-ipfs/compare/v0.32.3...v0.33.0-rc.1) (2018-10-19)

### Bug Fixes

* make ipfs.ping() options optional ([#1627](https://github.com/ipfs/js-ipfs/issues/1627)) ([08f06b6](https://github.com/ipfs/js-ipfs/commit/08f06b6)), closes [#1616](https://github.com/ipfs/js-ipfs/issues/1616)

### Features

* **gateway:** X-Ipfs-Path, Etag, Cache-Control, Suborigin ([#1537](https://github.com/ipfs/js-ipfs/issues/1537)) ([fc5bef7](https://github.com/ipfs/js-ipfs/commit/fc5bef7))
* add cid command ([#1560](https://github.com/ipfs/js-ipfs/issues/1560)) ([a22c791](https://github.com/ipfs/js-ipfs/commit/a22c791))
* show Web UI url in daemon output ([#1595](https://github.com/ipfs/js-ipfs/issues/1595)) ([9a82b05](https://github.com/ipfs/js-ipfs/commit/9a82b05))
* update to Web UI 2.0 ([#1647](https://github.com/ipfs/js-ipfs/issues/1647)) ([aea85aa](https://github.com/ipfs/js-ipfs/commit/aea85aa))

<a name="0.32.3"></a>
## [0.32.3](https://github.com/ipfs/js-ipfs/compare/v0.32.2...v0.32.3) (2018-09-28)

### Bug Fixes

* allow null/undefined options ([#1581](https://github.com/ipfs/js-ipfs/issues/1581)) ([c73bd2f](https://github.com/ipfs/js-ipfs/commit/c73bd2f)), closes [#1574](https://github.com/ipfs/js-ipfs/issues/1574)
* block.put with non default options ([#1600](https://github.com/ipfs/js-ipfs/issues/1600)) ([4ba0a24](https://github.com/ipfs/js-ipfs/commit/4ba0a24))
* ipns datastore get not found ([#1558](https://github.com/ipfs/js-ipfs/issues/1558)) ([4e99cf5](https://github.com/ipfs/js-ipfs/commit/4e99cf5))
* report correct size for raw dag nodes ([#1591](https://github.com/ipfs/js-ipfs/issues/1591)) ([549f2f6](https://github.com/ipfs/js-ipfs/commit/549f2f6)), closes [#1585](https://github.com/ipfs/js-ipfs/issues/1585)
* revert libp2p records being signed for ipns ([#1570](https://github.com/ipfs/js-ipfs/issues/1570)) ([855b3bd](https://github.com/ipfs/js-ipfs/commit/855b3bd))

<a name="0.32.2"></a>
## [0.32.2](https://github.com/ipfs/js-ipfs/compare/v0.32.1...v0.32.2) (2018-09-19)

### Bug Fixes

* coerce key gen size to number ([#1582](https://github.com/ipfs/js-ipfs/issues/1582)) ([25d820d](https://github.com/ipfs/js-ipfs/commit/25d820d))

<a name="0.32.1"></a>
## [0.32.1](https://github.com/ipfs/js-ipfs/compare/v0.32.0...v0.32.1) (2018-09-18)

### Bug Fixes

* add libp2p-crypto to deps list ([#1572](https://github.com/ipfs/js-ipfs/issues/1572)) ([7eaf571](https://github.com/ipfs/js-ipfs/commit/7eaf571)), closes [#1571](https://github.com/ipfs/js-ipfs/issues/1571)
* enable tests in node that were not being included ([#1499](https://github.com/ipfs/js-ipfs/issues/1499)) ([2585431](https://github.com/ipfs/js-ipfs/commit/2585431))
* fix `block rm` command ([#1576](https://github.com/ipfs/js-ipfs/issues/1576)) ([af30ea5](https://github.com/ipfs/js-ipfs/commit/af30ea5))
* mfs preload test ([#1551](https://github.com/ipfs/js-ipfs/issues/1551)) ([7c7a5a6](https://github.com/ipfs/js-ipfs/commit/7c7a5a6))

### Performance Improvements

* faster startup time ([#1542](https://github.com/ipfs/js-ipfs/issues/1542)) ([2790e6d](https://github.com/ipfs/js-ipfs/commit/2790e6d))

<a name="0.32.0"></a>
# [0.32.0](https://github.com/ipfs/js-ipfs/compare/v0.32.0-rc.2...v0.32.0) (2018-09-11)

### Bug Fixes

* ipns publish resolve option overwritten ([#1556](https://github.com/ipfs/js-ipfs/issues/1556)) ([ef7d2c8](https://github.com/ipfs/js-ipfs/commit/ef7d2c8))

### Features

* Added `ipfs.name.publish` and `ipfs.name.resolve`. This only works on your local node for the moment until the DHT lands. [API docs can be found here](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md).
* Added `ipfs.resolve` API. Note that this is a partial implementation allowing you to resolve IPFS paths like `/ipfs/QmRootHash/path/to/file` to `/ipfs/QmFileHash`. It does not support IPNS yet.
* `ipfs.files.add*` now supports a `chunker` option, see [the API docs](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesadd) for details

<a name="0.31.7"></a>
## [0.31.7](https://github.com/ipfs/js-ipfs/compare/v0.31.6...v0.31.7) (2018-08-20)

### Bug Fixes

* fails to start when preload disabled ([#1516](https://github.com/ipfs/js-ipfs/issues/1516)) ([511ab47](https://github.com/ipfs/js-ipfs/commit/511ab47)), closes [#1514](https://github.com/ipfs/js-ipfs/issues/1514)
* npm publishes examples folder ([#1513](https://github.com/ipfs/js-ipfs/issues/1513)) ([4a68ac1](https://github.com/ipfs/js-ipfs/commit/4a68ac1))

<a name="0.31.6"></a>
## [0.31.6](https://github.com/ipfs/js-ipfs/compare/v0.31.5...v0.31.6) (2018-08-17)

### Features

* adds data-encoding argument to control data encoding ([#1420](https://github.com/ipfs/js-ipfs/issues/1420)) ([1eb8485](https://github.com/ipfs/js-ipfs/commit/1eb8485))

<a name="0.31.5"></a>
## [0.31.5](https://github.com/ipfs/js-ipfs/compare/v0.31.4...v0.31.5) (2018-08-17)

### Bug Fixes

* add missing space after emoji ([5cde7c1](https://github.com/ipfs/js-ipfs/commit/5cde7c1))
* improper input validation ([#1506](https://github.com/ipfs/js-ipfs/issues/1506)) ([91a482b](https://github.com/ipfs/js-ipfs/commit/91a482b))
* object.patch.rmLink not working ([#1508](https://github.com/ipfs/js-ipfs/issues/1508)) ([afd3255](https://github.com/ipfs/js-ipfs/commit/afd3255))
* stub out call to fetch for ipfs.dns test in browser ([#1512](https://github.com/ipfs/js-ipfs/issues/1512)) ([86c3d81](https://github.com/ipfs/js-ipfs/commit/86c3d81))

<a name="0.31.4"></a>
## [0.31.4](https://github.com/ipfs/js-ipfs/compare/v0.31.3...v0.31.4) (2018-08-09)

### Bug Fixes

* consistent badge style in docs ([#1494](https://github.com/ipfs/js-ipfs/issues/1494)) ([4a72e23](https://github.com/ipfs/js-ipfs/commit/4a72e23))
* files.ls and files.read*Stream tests ([#1493](https://github.com/ipfs/js-ipfs/issues/1493)) ([a0bc79b](https://github.com/ipfs/js-ipfs/commit/a0bc79b))

<a name="0.31.3"></a>
## [0.31.3](https://github.com/ipfs/js-ipfs/compare/v0.31.2...v0.31.3) (2018-08-09)

### Bug Fixes

* failing tests in master ([#1488](https://github.com/ipfs/js-ipfs/issues/1488)) ([e607560](https://github.com/ipfs/js-ipfs/commit/e607560))
* **dag:** check dag.put options for plain object ([#1480](https://github.com/ipfs/js-ipfs/issues/1480)) ([d0b671b](https://github.com/ipfs/js-ipfs/commit/d0b671b)), closes [#1479](https://github.com/ipfs/js-ipfs/issues/1479)
* **dht:** allow for options object in `findProvs()` API ([#1457](https://github.com/ipfs/js-ipfs/issues/1457)) ([99911b1](https://github.com/ipfs/js-ipfs/commit/99911b1)), closes [#1322](https://github.com/ipfs/js-ipfs/issues/1322)

<a name="0.31.2"></a>
## [0.31.2](https://github.com/ipfs/js-ipfs/compare/v0.31.1...v0.31.2) (2018-08-02)

### Bug Fixes

* fix content-type by doing a fall-back using extensions ([#1482](https://github.com/ipfs/js-ipfs/issues/1482)) ([d528b3f](https://github.com/ipfs/js-ipfs/commit/d528b3f))

<a name="0.31.1"></a>
## [0.31.1](https://github.com/ipfs/js-ipfs/compare/v0.31.0...v0.31.1) (2018-07-29)

### Bug Fixes

* logo link ([a9219ad](https://github.com/ipfs/js-ipfs/commit/a9219ad))
* XMLHTTPRequest is deprecated and unavailable in service workers ([#1478](https://github.com/ipfs/js-ipfs/issues/1478)) ([7d6f0ca](https://github.com/ipfs/js-ipfs/commit/7d6f0ca))

<a name="0.31.0"></a>
# [0.31.0](https://github.com/ipfs/js-ipfs/compare/v0.30.1...v0.31.0) (2018-07-29)

### Bug Fixes

* emit boot error only once ([#1472](https://github.com/ipfs/js-ipfs/issues/1472)) ([45b80a0](https://github.com/ipfs/js-ipfs/commit/45b80a0))

### Features

* preload content ([#1464](https://github.com/ipfs/js-ipfs/issues/1464)) ([bffe080](https://github.com/ipfs/js-ipfs/commit/bffe080)), closes [#1459](https://github.com/ipfs/js-ipfs/issues/1459)
* preload on content fetch requests ([#1475](https://github.com/ipfs/js-ipfs/issues/1475)) ([649b755](https://github.com/ipfs/js-ipfs/commit/649b755)), closes [#1473](https://github.com/ipfs/js-ipfs/issues/1473)
* remove decomissioned bootstrappers ([e3868f4](https://github.com/ipfs/js-ipfs/commit/e3868f4))
* rm decomissioned bootstrappers - nodejs ([90e9f68](https://github.com/ipfs/js-ipfs/commit/90e9f68))
* support --raw-leaves ([#1454](https://github.com/ipfs/js-ipfs/issues/1454)) ([1f63e8c](https://github.com/ipfs/js-ipfs/commit/1f63e8c))

### Reverts

* docs: add migration note about upgrading from < 0.30.0 ([#1450](https://github.com/ipfs/js-ipfs/issues/1450)) ([#1456](https://github.com/ipfs/js-ipfs/issues/1456)) ([f4344b0](https://github.com/ipfs/js-ipfs/commit/f4344b0))

<a name="0.30.1"></a>
## [0.30.1](https://github.com/ipfs/js-ipfs/compare/v0.30.0...v0.30.1) (2018-07-17)

### Bug Fixes

* aegir docs fails if outer funtion is called pin ([#1429](https://github.com/ipfs/js-ipfs/issues/1429)) ([a08a17d](https://github.com/ipfs/js-ipfs/commit/a08a17d))
* double pre start ([#1437](https://github.com/ipfs/js-ipfs/issues/1437)) ([e6ad63e](https://github.com/ipfs/js-ipfs/commit/e6ad63e))
* fixing circuit-relaying example ([#1443](https://github.com/ipfs/js-ipfs/issues/1443)) ([a681fc5](https://github.com/ipfs/js-ipfs/commit/a681fc5)), closes [#1423](https://github.com/ipfs/js-ipfs/issues/1423)

<a name="0.30.0"></a>
# [0.30.0](https://github.com/ipfs/js-ipfs/compare/v0.29.3...v0.30.0) (2018-07-09)

### Bug Fixes

* allow put empty block & add X-Stream-Output header on get ([#1408](https://github.com/ipfs/js-ipfs/issues/1408)) ([52f7aa7](https://github.com/ipfs/js-ipfs/commit/52f7aa7))
* broken contributing links ([#1386](https://github.com/ipfs/js-ipfs/issues/1386)) ([cd449ff](https://github.com/ipfs/js-ipfs/commit/cd449ff))
* do not stringify output of object data ([#1398](https://github.com/ipfs/js-ipfs/issues/1398)) ([4e51a69](https://github.com/ipfs/js-ipfs/commit/4e51a69))
* **dag:** fix default hash algorithm for put() api ([#1419](https://github.com/ipfs/js-ipfs/issues/1419)) ([1a36375](https://github.com/ipfs/js-ipfs/commit/1a36375))
* **dag:** make options in `put` API optional ([#1415](https://github.com/ipfs/js-ipfs/issues/1415)) ([d299ed7](https://github.com/ipfs/js-ipfs/commit/d299ed7)), closes [#1395](https://github.com/ipfs/js-ipfs/issues/1395)
* **tests:** loosen assertion for bitswap.stat test ([#1404](https://github.com/ipfs/js-ipfs/issues/1404)) ([4290256](https://github.com/ipfs/js-ipfs/commit/4290256))
* update hlsjs-ipfs-loader version ([#1422](https://github.com/ipfs/js-ipfs/issues/1422)) ([6b14812](https://github.com/ipfs/js-ipfs/commit/6b14812))

### Features

* (BREAKING CHANGE) new libp2p configuration ([#1401](https://github.com/ipfs/js-ipfs/issues/1401)) ([9c60909](https://github.com/ipfs/js-ipfs/commit/9c60909))
* expose libp2p connection manager configuration options ([#1410](https://github.com/ipfs/js-ipfs/issues/1410)) ([2615f76](https://github.com/ipfs/js-ipfs/commit/2615f76))
* implement bitswap.wantlist peerid and bitswap.unwant ([#1349](https://github.com/ipfs/js-ipfs/issues/1349)) ([45b705d](https://github.com/ipfs/js-ipfs/commit/45b705d))
* mfs implementation ([#1360](https://github.com/ipfs/js-ipfs/issues/1360)) ([871d24e](https://github.com/ipfs/js-ipfs/commit/871d24e)), closes [#1425](https://github.com/ipfs/js-ipfs/issues/1425)
* modular interface tests ([#1389](https://github.com/ipfs/js-ipfs/issues/1389)) ([18888be](https://github.com/ipfs/js-ipfs/commit/18888be))
* pin API ([#1045](https://github.com/ipfs/js-ipfs/issues/1045)) ([2a5cc5e](https://github.com/ipfs/js-ipfs/commit/2a5cc5e)), closes [#1249](https://github.com/ipfs/js-ipfs/issues/1249)

### Performance Improvements

* use lodash ([#1414](https://github.com/ipfs/js-ipfs/issues/1414)) ([5637330](https://github.com/ipfs/js-ipfs/commit/5637330))

### BREAKING CHANGES

* libp2p configuration has changed

    * old: `libp2p.modules.discovery`
    * new: `libp2p.modules.peerDiscovery`

License: MIT
Signed-off-by: David Dias <mail@daviddias.me>

License: MIT
Signed-off-by: Alan Shaw <alan@tableflip.io>

<a name="0.29.3"></a>
## [0.29.3](https://github.com/ipfs/js-ipfs/compare/v0.29.2...v0.29.3) (2018-06-04)

### Bug Fixes

* **repo:** do not hang on calls to repo gc ([9fff46f](https://github.com/ipfs/js-ipfs/commit/9fff46f))

<a name="0.29.2"></a>
## [0.29.2](https://github.com/ipfs/js-ipfs/compare/v0.29.1...v0.29.2) (2018-06-01)

### Bug Fixes

* adds missing breaking changes for 0.29 to changelog ([#1370](https://github.com/ipfs/js-ipfs/issues/1370)) ([61ba99e](https://github.com/ipfs/js-ipfs/commit/61ba99e))
* dont fail on uninitialized repo ([#1374](https://github.com/ipfs/js-ipfs/issues/1374)) ([6f0a95b](https://github.com/ipfs/js-ipfs/commit/6f0a95b))

<a name="0.29.1"></a>
## [0.29.1](https://github.com/ipfs/js-ipfs/compare/v0.29.0...v0.29.1) (2018-05-30)

### Bug Fixes

* check for repo uninitialized error ([dcf5ea5](https://github.com/ipfs/js-ipfs/commit/dcf5ea5))
* update ipfs-repo errors require ([4d1318d](https://github.com/ipfs/js-ipfs/commit/4d1318d))

<a name="0.29.0"></a>
# [0.29.0](https://github.com/ipfs/js-ipfs/compare/v0.28.2...v0.29.0) (2018-05-29)

### Bug Fixes

* Add ipfs path to cli help ([64c3bfb](https://github.com/ipfs/js-ipfs/commit/64c3bfb))
* change ^ to ~ on 0.x.x deps ([#1345](https://github.com/ipfs/js-ipfs/issues/1345)) ([de95989](https://github.com/ipfs/js-ipfs/commit/de95989))
* change default config from JSON file to JS module to prevent having it doubly used ([#1324](https://github.com/ipfs/js-ipfs/issues/1324)) ([c3d2d1e](https://github.com/ipfs/js-ipfs/commit/c3d2d1e)), closes [#1316](https://github.com/ipfs/js-ipfs/issues/1316)
* changes peer prop in return value from swarm.peers to be a PeerId  ([#1252](https://github.com/ipfs/js-ipfs/issues/1252)) ([e174866](https://github.com/ipfs/js-ipfs/commit/e174866))
* configure webpack to not use esmodules in dependencies ([4486acc](https://github.com/ipfs/js-ipfs/commit/4486acc))
* Display error when using unkown cli option ([a849d2f](https://github.com/ipfs/js-ipfs/commit/a849d2f))
* docker init script sed in non existent file ([#1246](https://github.com/ipfs/js-ipfs/issues/1246)) ([75d47c3](https://github.com/ipfs/js-ipfs/commit/75d47c3))
* files.add with pull streams ([0e601a7](https://github.com/ipfs/js-ipfs/commit/0e601a7))
* make pubsub.unsubscribe async and alter pubsub.subscribe signature ([a115829](https://github.com/ipfs/js-ipfs/commit/a115829))
* remove unused var ([#1273](https://github.com/ipfs/js-ipfs/issues/1273)) ([c1e8db1](https://github.com/ipfs/js-ipfs/commit/c1e8db1))
* typo ([#1367](https://github.com/ipfs/js-ipfs/issues/1367)) ([2679129](https://github.com/ipfs/js-ipfs/commit/2679129))
* use async/setImmediate vs process.nextTick ([af55608](https://github.com/ipfs/js-ipfs/commit/af55608))

### Features

* .stats.bw* - Bandwidth Stats ([#1230](https://github.com/ipfs/js-ipfs/issues/1230)) ([9694925](https://github.com/ipfs/js-ipfs/commit/9694925))
* add ability to files.cat with a cid instance ([2e332c8](https://github.com/ipfs/js-ipfs/commit/2e332c8))
* Add support for specifying hash algorithms in files.add ([a2954cb](https://github.com/ipfs/js-ipfs/commit/a2954cb))
* allow dht to be enabled via cli arg ([#1340](https://github.com/ipfs/js-ipfs/issues/1340)) ([7bb838f](https://github.com/ipfs/js-ipfs/commit/7bb838f))
* Allows for byte offsets when using ipfs.files.cat and friends to request slices of files ([a93971a](https://github.com/ipfs/js-ipfs/commit/a93971a))
* Circuit Relay ([#1063](https://github.com/ipfs/js-ipfs/issues/1063)) ([f7eaa43](https://github.com/ipfs/js-ipfs/commit/f7eaa43))
* cli: add IPFS_PATH info to init command help ([#1274](https://github.com/ipfs/js-ipfs/issues/1274)) ([e189b72](https://github.com/ipfs/js-ipfs/commit/e189b72))
* handle SIGHUP ([7a817cf](https://github.com/ipfs/js-ipfs/commit/7a817cf))
* ipfs.ping cli, http-api and core ([#1342](https://github.com/ipfs/js-ipfs/issues/1342)) ([b8171b1](https://github.com/ipfs/js-ipfs/commit/b8171b1))
* jsipfs add --only-hash ([#1233](https://github.com/ipfs/js-ipfs/issues/1233)) ([#1266](https://github.com/ipfs/js-ipfs/issues/1266)) ([bddc5b4](https://github.com/ipfs/js-ipfs/commit/bddc5b4))
* Provide access to bundled libraries when in browser ([#1297](https://github.com/ipfs/js-ipfs/issues/1297)) ([4905c2d](https://github.com/ipfs/js-ipfs/commit/4905c2d))
* use class-is for type checks ([5b2cf8c](https://github.com/ipfs/js-ipfs/commit/5b2cf8c))
* wrap with directory ([#1329](https://github.com/ipfs/js-ipfs/issues/1329)) ([47285a7](https://github.com/ipfs/js-ipfs/commit/47285a7))

### Performance Improvements

* **cli:** load only sub-system modules and inline require ipfs ([3820be0](https://github.com/ipfs/js-ipfs/commit/3820be0))

### BREAKING CHANGES

1. Argument order for `pubsub.subscribe` has changed:
    * Old: `pubsub.subscribe(topic, [options], handler, [callback]): Promise`
    * New: `pubsub.subscribe(topic, handler, [options], [callback]): Promise`
2. The `pubsub.unsubscribe` method has become async meaning that it now takes a callback or returns a promise:
    * Old: `pubsub.unsubscribe(topic, handler): undefined`
    * New: `pubsub.unsubscribe(topic, handler, [callback]): Promise`
3. Property names on response objects for `ping` are now lowered:
    * Old: `{ Success, Time, Text }`
    * New: `{ success, time, text }`
4. In the CLI, `jsipfs object data` no longer returns a newline after the end of the returned data

<a name="0.28.2"></a>
## [0.28.2](https://github.com/ipfs/js-ipfs/compare/v0.28.1...v0.28.2) (2018-03-14)

### Bug Fixes

* match error if repo doesnt exist ([#1262](https://github.com/ipfs/js-ipfs/issues/1262)) ([aea69d3](https://github.com/ipfs/js-ipfs/commit/aea69d3))
* reinstates the non local block check in dht.provide ([#1250](https://github.com/ipfs/js-ipfs/issues/1250)) ([5b736a8](https://github.com/ipfs/js-ipfs/commit/5b736a8))

### Features

* add config validation ([#1239](https://github.com/ipfs/js-ipfs/issues/1239)) ([a32dce7](https://github.com/ipfs/js-ipfs/commit/a32dce7))

<a name="0.28.1"></a>
## [0.28.1](https://github.com/ipfs/js-ipfs/compare/v0.28.0...v0.28.1) (2018-03-09)

### Bug Fixes

* **gateway:** catch stream2 error ([#1243](https://github.com/ipfs/js-ipfs/issues/1243)) ([5b40b41](https://github.com/ipfs/js-ipfs/commit/5b40b41))
* accept objects in file.add ([#1257](https://github.com/ipfs/js-ipfs/issues/1257)) ([d32dad9](https://github.com/ipfs/js-ipfs/commit/d32dad9))

<a name="0.28.0"></a>
# [0.28.0](https://github.com/ipfs/js-ipfs/compare/v0.27.7...v0.28.0) (2018-03-01)

### Bug Fixes

* **cli:** show help for subcommands ([8c63f8f](https://github.com/ipfs/js-ipfs/commit/8c63f8f))
* (cli/init) use cross-platform path separator ([bbb7cc5](https://github.com/ipfs/js-ipfs/commit/bbb7cc5))
* **dag:** print data in a readable way if it is JSON ([42545dc](https://github.com/ipfs/js-ipfs/commit/42545dc))
* bootstrap ([d527b45](https://github.com/ipfs/js-ipfs/commit/d527b45))
* now properly fix bootstrap in core ([9f39a6f](https://github.com/ipfs/js-ipfs/commit/9f39a6f))
* Remove scape characteres from error message. ([68e7b5a](https://github.com/ipfs/js-ipfs/commit/68e7b5a))
* Return swarm http errors as json ([d3a0ae1](https://github.com/ipfs/js-ipfs/commit/d3a0ae1)), closes [#1176](https://github.com/ipfs/js-ipfs/issues/1176)
* stats tests ([a0fd355](https://github.com/ipfs/js-ipfs/commit/a0fd355))
* use "ipld" instead of "ipld-resolver" ([e7f0432](https://github.com/ipfs/js-ipfs/commit/e7f0432))

### Features

* `ipfs version` flags + `ipfs repo version` ([#1181](https://github.com/ipfs/js-ipfs/issues/1181)) ([#1188](https://github.com/ipfs/js-ipfs/issues/1188)) ([494da7f](https://github.com/ipfs/js-ipfs/commit/494da7f))
* Add /ip6 addresses to bootstrap ([3bca165](https://github.com/ipfs/js-ipfs/commit/3bca165)), closes [#706](https://github.com/ipfs/js-ipfs/issues/706)
* all pubsub tests passing with libp2p pubsub ([6fe015f](https://github.com/ipfs/js-ipfs/commit/6fe015f))
* Bootstrap API compliance ([#1218](https://github.com/ipfs/js-ipfs/issues/1218)) ([9a445d1](https://github.com/ipfs/js-ipfs/commit/9a445d1))
* Implementation of the ipfs.key API ([#1133](https://github.com/ipfs/js-ipfs/issues/1133)) ([d945fce](https://github.com/ipfs/js-ipfs/commit/d945fce))
* improved multiaddr validation. ([d9744a1](https://github.com/ipfs/js-ipfs/commit/d9744a1))
* ipfs shutdown ([#1200](https://github.com/ipfs/js-ipfs/issues/1200)) ([95365fa](https://github.com/ipfs/js-ipfs/commit/95365fa))
* jsipfs ls -r (Recursive list directory) ([#1222](https://github.com/ipfs/js-ipfs/issues/1222)) ([0f1e00f](https://github.com/ipfs/js-ipfs/commit/0f1e00f))
* latest libp2p + other deps. Fix bugs in tests along the way ([4b79066](https://github.com/ipfs/js-ipfs/commit/4b79066))
* reworking tests with new ipfsd-ctl ([#1167](https://github.com/ipfs/js-ipfs/issues/1167)) ([d16a129](https://github.com/ipfs/js-ipfs/commit/d16a129))
* stats API (stats.bitswap and stats.repo) ([#1198](https://github.com/ipfs/js-ipfs/issues/1198)) ([905bdc0](https://github.com/ipfs/js-ipfs/commit/905bdc0))
* support Jenkins ([bc66e9f](https://github.com/ipfs/js-ipfs/commit/bc66e9f))
* use PubSub API directly from libp2p ([6b9fc95](https://github.com/ipfs/js-ipfs/commit/6b9fc95))
* use reduces keysize ([#1232](https://github.com/ipfs/js-ipfs/issues/1232)) ([7f69628](https://github.com/ipfs/js-ipfs/commit/7f69628))

<a name="0.27.7"></a>
## [0.27.7](https://github.com/ipfs/js-ipfs/compare/v0.27.6...v0.27.7) (2018-01-16)

### Features

* /api/v0/dns ([#1172](https://github.com/ipfs/js-ipfs/issues/1172)) ([639024c](https://github.com/ipfs/js-ipfs/commit/639024c))

<a name="0.27.6"></a>
## [0.27.6](https://github.com/ipfs/js-ipfs/compare/v0.27.5...v0.27.6) (2018-01-07)

### Bug Fixes

* cli files on Windows ([#1159](https://github.com/ipfs/js-ipfs/issues/1159)) ([1b98fa1](https://github.com/ipfs/js-ipfs/commit/1b98fa1))

<a name="0.27.5"></a>
## [0.27.5](https://github.com/ipfs/js-ipfs/compare/v0.27.4...v0.27.5) (2017-12-18)

### Bug Fixes

* cat: test file existence after filtering ([#1148](https://github.com/ipfs/js-ipfs/issues/1148)) ([34f28ef](https://github.com/ipfs/js-ipfs/commit/34f28ef)), closes [#1142](https://github.com/ipfs/js-ipfs/issues/1142)
* ipfs.ls: allow any depth ([#1152](https://github.com/ipfs/js-ipfs/issues/1152)) ([279af78](https://github.com/ipfs/js-ipfs/commit/279af78)), closes [#1079](https://github.com/ipfs/js-ipfs/issues/1079)
* use new bitswap stats ([#1151](https://github.com/ipfs/js-ipfs/issues/1151)) ([e223888](https://github.com/ipfs/js-ipfs/commit/e223888))
* **files.add:** directory with odd name ([#1155](https://github.com/ipfs/js-ipfs/issues/1155)) ([058c674](https://github.com/ipfs/js-ipfs/commit/058c674))

<a name="0.27.4"></a>
## [0.27.4](https://github.com/ipfs/js-ipfs/compare/v0.27.3...v0.27.4) (2017-12-13)

### Bug Fixes

* files.cat: detect and handle rrors when unknown path and cat dir ([#1143](https://github.com/ipfs/js-ipfs/issues/1143)) ([120d291](https://github.com/ipfs/js-ipfs/commit/120d291))
* fix bug introduced by 1143 ([#1146](https://github.com/ipfs/js-ipfs/issues/1146)) ([12cdc08](https://github.com/ipfs/js-ipfs/commit/12cdc08))

<a name="0.27.3"></a>
## [0.27.3](https://github.com/ipfs/js-ipfs/compare/v0.27.2...v0.27.3) (2017-12-10)

### Bug Fixes

* config handler should check if value is null ([#1134](https://github.com/ipfs/js-ipfs/issues/1134)) ([0444c42](https://github.com/ipfs/js-ipfs/commit/0444c42))
* **pubsub:** subscribe promises ([#1141](https://github.com/ipfs/js-ipfs/issues/1141)) ([558017d](https://github.com/ipfs/js-ipfs/commit/558017d))

<a name="0.27.2"></a>
## [0.27.2](https://github.com/ipfs/js-ipfs/compare/v0.27.1...v0.27.2) (2017-12-09)

<a name="0.27.1"></a>
## [0.27.1](https://github.com/ipfs/js-ipfs/compare/v0.27.0...v0.27.1) (2017-12-07)

### Bug Fixes

* **pubsub.peers:** remove the requirement for a topic ([#1125](https://github.com/ipfs/js-ipfs/issues/1125)) ([5601c26](https://github.com/ipfs/js-ipfs/commit/5601c26))

<a name="0.27.0"></a>
# [0.27.0](https://github.com/ipfs/js-ipfs/compare/v0.26.0...v0.27.0) (2017-12-04)

### Bug Fixes

* fix the welcome message and throw error when trying to cat a non-exis… ([#1032](https://github.com/ipfs/js-ipfs/issues/1032)) ([25fb390](https://github.com/ipfs/js-ipfs/commit/25fb390)), closes [#1031](https://github.com/ipfs/js-ipfs/issues/1031)
* make offline error retain stack ([#1056](https://github.com/ipfs/js-ipfs/issues/1056)) ([dce6a49](https://github.com/ipfs/js-ipfs/commit/dce6a49))
* pre 1.0.0 deps should be always installed with ~ and not ^ ([c672af7](https://github.com/ipfs/js-ipfs/commit/c672af7))
* progress bar flakiness ([#1042](https://github.com/ipfs/js-ipfs/issues/1042)) ([d7732c3](https://github.com/ipfs/js-ipfs/commit/d7732c3))
* promisify .block (get, put, rm, stat) ([#1085](https://github.com/ipfs/js-ipfs/issues/1085)) ([cafa52b](https://github.com/ipfs/js-ipfs/commit/cafa52b))
* **files.add:** glob needs a POSIX path ([#1108](https://github.com/ipfs/js-ipfs/issues/1108)) ([9c29a23](https://github.com/ipfs/js-ipfs/commit/9c29a23))
* promisify node.stop ([#1082](https://github.com/ipfs/js-ipfs/issues/1082)) ([9b385ae](https://github.com/ipfs/js-ipfs/commit/9b385ae))
* pubsub message fields ([#1077](https://github.com/ipfs/js-ipfs/issues/1077)) ([9de6f4c](https://github.com/ipfs/js-ipfs/commit/9de6f4c))
* removed error handler that was hiding errors ([#1120](https://github.com/ipfs/js-ipfs/issues/1120)) ([58ded8d](https://github.com/ipfs/js-ipfs/commit/58ded8d))
* Typo ([#1044](https://github.com/ipfs/js-ipfs/issues/1044)) ([179b6a4](https://github.com/ipfs/js-ipfs/commit/179b6a4))
* update *-star multiaddrs to explicity say that they need tcp and a port ([#1117](https://github.com/ipfs/js-ipfs/issues/1117)) ([9eda8a8](https://github.com/ipfs/js-ipfs/commit/9eda8a8))

### Features

* accept additional transports ([6613aa6](https://github.com/ipfs/js-ipfs/commit/6613aa6))
* add circuit relay and aegir 12 (+ big refactor) ([104ef1e](https://github.com/ipfs/js-ipfs/commit/104ef1e))
* add WebUI Path ([#1124](https://github.com/ipfs/js-ipfs/issues/1124)) ([8041b48](https://github.com/ipfs/js-ipfs/commit/8041b48))
* adding appveyor support ([#1054](https://github.com/ipfs/js-ipfs/issues/1054)) ([b92bdfe](https://github.com/ipfs/js-ipfs/commit/b92bdfe))
* agent version with package number ([#1121](https://github.com/ipfs/js-ipfs/issues/1121)) ([550f955](https://github.com/ipfs/js-ipfs/commit/550f955))
* cli --api option ([#1087](https://github.com/ipfs/js-ipfs/issues/1087)) ([1b1fa05](https://github.com/ipfs/js-ipfs/commit/1b1fa05))
* complete PubSub implementation  ([ac95601](https://github.com/ipfs/js-ipfs/commit/ac95601))
* implement "ipfs file ls" ([#1078](https://github.com/ipfs/js-ipfs/issues/1078)) ([6db3fb8](https://github.com/ipfs/js-ipfs/commit/6db3fb8))
* implementing the new streaming interfaces ([#1086](https://github.com/ipfs/js-ipfs/issues/1086)) ([2c4b8b3](https://github.com/ipfs/js-ipfs/commit/2c4b8b3))
* ipfs.ls ([#1073](https://github.com/ipfs/js-ipfs/issues/1073)) ([35687cb](https://github.com/ipfs/js-ipfs/commit/35687cb))
* make js-ipfs daemon stop with same SIG as go-ipfs ([#1067](https://github.com/ipfs/js-ipfs/issues/1067)) ([7dd4e01](https://github.com/ipfs/js-ipfs/commit/7dd4e01))
* WebSocketStar ([#1090](https://github.com/ipfs/js-ipfs/issues/1090)) ([33e9949](https://github.com/ipfs/js-ipfs/commit/33e9949))
* windows interop ([#1065](https://github.com/ipfs/js-ipfs/issues/1065)) ([d8197f9](https://github.com/ipfs/js-ipfs/commit/d8197f9))

<a name="0.26.0"></a>
# [0.26.0](https://github.com/ipfs/js-ipfs/compare/v0.25.4...v0.26.0) (2017-09-13)

### Bug Fixes

* strips trailing slash from path ([#985](https://github.com/ipfs/js-ipfs/issues/985)) ([bfc58d6](https://github.com/ipfs/js-ipfs/commit/bfc58d6))

### Features

* Add --cid-version option to ipfs files add +  decodeURIComponent for file and directory names ([7544b7b](https://github.com/ipfs/js-ipfs/commit/7544b7b))
* add gateway to ipfs daemon ([9f2006e](https://github.com/ipfs/js-ipfs/commit/9f2006e)), closes [#1006](https://github.com/ipfs/js-ipfs/issues/1006) [#1008](https://github.com/ipfs/js-ipfs/issues/1008) [#1009](https://github.com/ipfs/js-ipfs/issues/1009)
* adds quiet flags ([#1001](https://github.com/ipfs/js-ipfs/issues/1001)) ([d21b492](https://github.com/ipfs/js-ipfs/commit/d21b492))
* complete the migration to p2p-webrtc-star ([#984](https://github.com/ipfs/js-ipfs/issues/984)) ([1e5dd2c](https://github.com/ipfs/js-ipfs/commit/1e5dd2c))

<a name="0.25.4"></a>
## [0.25.4](https://github.com/ipfs/js-ipfs/compare/v0.25.3...v0.25.4) (2017-09-01)

### Features

* add multiaddrs for bootstrapers gateway  ([a15bee9](https://github.com/ipfs/js-ipfs/commit/a15bee9))

<a name="0.25.3"></a>
## [0.25.3](https://github.com/ipfs/js-ipfs/compare/v0.25.2...v0.25.3) (2017-09-01)

### Bug Fixes

* config, dangling comma ([4eb63c5](https://github.com/ipfs/js-ipfs/commit/4eb63c5))
* only show connected addrs for peers in swarm.peers ([d939323](https://github.com/ipfs/js-ipfs/commit/d939323))
* remove shutdown bootstrapers from bootstrappers list ([5ec27a3](https://github.com/ipfs/js-ipfs/commit/5ec27a3))

### Features

* add instrumentation ([8f0254e](https://github.com/ipfs/js-ipfs/commit/8f0254e))

<a name="0.25.2"></a>
## [0.25.2](https://github.com/ipfs/js-ipfs/compare/v0.25.1...v0.25.2) (2017-08-26)

<a name="0.25.1"></a>
## [0.25.1](https://github.com/ipfs/js-ipfs/compare/v0.25.0...v0.25.1) (2017-07-26)

### Bug Fixes

* js-ipfs daemon config params ([#914](https://github.com/ipfs/js-ipfs/issues/914)) ([e00b96f](https://github.com/ipfs/js-ipfs/commit/e00b96f)), closes [#868](https://github.com/ipfs/js-ipfs/issues/868)
* remove non existent commands ([#925](https://github.com/ipfs/js-ipfs/issues/925)) ([b7e8e88](https://github.com/ipfs/js-ipfs/commit/b7e8e88))
* stream issue, do not use isstream, use is-stream ([#937](https://github.com/ipfs/js-ipfs/issues/937)) ([da66b1f](https://github.com/ipfs/js-ipfs/commit/da66b1f))

### Features

* new print func for the CLI ([#931](https://github.com/ipfs/js-ipfs/issues/931)) ([a5e75e0](https://github.com/ipfs/js-ipfs/commit/a5e75e0))
* no more need for webcrypto-ossl ([bc8ffee](https://github.com/ipfs/js-ipfs/commit/bc8ffee))

<a name="0.25.0"></a>
# [0.25.0](https://github.com/ipfs/js-ipfs/compare/v0.24.1...v0.25.0) (2017-07-12)

### Bug Fixes

* **bootstrap:add:** prevent duplicate inserts ([#893](https://github.com/ipfs/js-ipfs/issues/893)) ([ce504cd](https://github.com/ipfs/js-ipfs/commit/ce504cd))
* **swarm:** move isConnected filter from addrs to peers ([#901](https://github.com/ipfs/js-ipfs/issues/901)) ([e2f371b](https://github.com/ipfs/js-ipfs/commit/e2f371b))
* circle ci, thanks victor! ([b074966](https://github.com/ipfs/js-ipfs/commit/b074966))
* do not let lodash mess with libp2p modules ([1f68b9b](https://github.com/ipfs/js-ipfs/commit/1f68b9b))
* is online is only online if libp2p is online ([#891](https://github.com/ipfs/js-ipfs/issues/891)) ([8b0f996](https://github.com/ipfs/js-ipfs/commit/8b0f996))
* issue [#905](https://github.com/ipfs/js-ipfs/issues/905) ([#906](https://github.com/ipfs/js-ipfs/issues/906)) ([cbcf90e](https://github.com/ipfs/js-ipfs/commit/cbcf90e))
* setImmediate polyfilled in node.id() ([#909](https://github.com/ipfs/js-ipfs/issues/909)) ([ebaf9a0](https://github.com/ipfs/js-ipfs/commit/ebaf9a0))
* succeed when stopping already stopped ([74f3185](https://github.com/ipfs/js-ipfs/commit/74f3185))

### Features

* adapted to new ipfs-repo API ([#887](https://github.com/ipfs/js-ipfs/issues/887)) ([4e39d2c](https://github.com/ipfs/js-ipfs/commit/4e39d2c))
* block get pipe fix ([#903](https://github.com/ipfs/js-ipfs/issues/903)) ([8063f6b](https://github.com/ipfs/js-ipfs/commit/8063f6b))

<a name="0.24.1"></a>
## [0.24.1](https://github.com/ipfs/js-ipfs/compare/0.24.1...v0.24.1) (2017-05-29)

<a name="0.24.0"></a>
# [0.24.0](https://github.com/ipfs/js-ipfs/compare/v0.23.1...v0.24.0) (2017-05-24)

### Bug Fixes

* cli flag typos ([c5bb0b9](https://github.com/ipfs/js-ipfs/commit/c5bb0b9))
* example, now files from datatransfer is a FileList which is not an array ([d7c9eec](https://github.com/ipfs/js-ipfs/commit/d7c9eec))
* issue-858 ([481933a](https://github.com/ipfs/js-ipfs/commit/481933a))
* last touches for dns websockets bootstrapers ([3b680a7](https://github.com/ipfs/js-ipfs/commit/3b680a7))
* linting ([68ee42e](https://github.com/ipfs/js-ipfs/commit/68ee42e))
* make start an async event ([78ba1e8](https://github.com/ipfs/js-ipfs/commit/78ba1e8))
* missing import ([6aa914d](https://github.com/ipfs/js-ipfs/commit/6aa914d))
* options to the HTTP API ([f1eb595](https://github.com/ipfs/js-ipfs/commit/f1eb595))
* removed hard-coded timeout on test and liting fixes ([0a3bbcb](https://github.com/ipfs/js-ipfs/commit/0a3bbcb))
* run webworker tests ([23c84f6](https://github.com/ipfs/js-ipfs/commit/23c84f6))
* **object.get:** treat ipfs hash strings as default base58 encoded ([7b3caef](https://github.com/ipfs/js-ipfs/commit/7b3caef))
* update bootstrapers ([7e7d9eb](https://github.com/ipfs/js-ipfs/commit/7e7d9eb))

### Features

* add dns ws bootstrappers ([a856578](https://github.com/ipfs/js-ipfs/commit/a856578))
* add WebRTC by default as a multiaddr ([4ea1571](https://github.com/ipfs/js-ipfs/commit/4ea1571))
* add websocket bootstrapers to the config ([602d033](https://github.com/ipfs/js-ipfs/commit/602d033))
* DHT integration PART I ([860165c](https://github.com/ipfs/js-ipfs/commit/860165c))
* new libp2p-api ([7bf75d1](https://github.com/ipfs/js-ipfs/commit/7bf75d1))
* update to new libp2p events for peers ([ca88706](https://github.com/ipfs/js-ipfs/commit/ca88706))
* update to the latest libp2p ([aca4297](https://github.com/ipfs/js-ipfs/commit/aca4297))

<a name="0.23.1"></a>
## [0.23.1](https://github.com/ipfs/js-ipfs/compare/v0.23.0...v0.23.1) (2017-03-27)

### Bug Fixes

* added backpressure to the add stream ([#810](https://github.com/ipfs/js-ipfs/issues/810)) ([31dbabc](https://github.com/ipfs/js-ipfs/commit/31dbabc))

<a name="0.23.0"></a>
# [0.23.0](https://github.com/ipfs/js-ipfs/compare/v0.22.1...v0.23.0) (2017-03-24)

### Bug Fixes

* **files.add:** error on invalid input ([#782](https://github.com/ipfs/js-ipfs/issues/782)) ([c851ca0](https://github.com/ipfs/js-ipfs/commit/c851ca0))
* give the daemon time to spawn ([2bf32cd](https://github.com/ipfs/js-ipfs/commit/2bf32cd))
* linting on transfer-files example ([f876171](https://github.com/ipfs/js-ipfs/commit/f876171))
* offer an init event to monitor when repo is there and avoid setTimeout ([c4130b9](https://github.com/ipfs/js-ipfs/commit/c4130b9))
* pull-stream-to-stream replaced with duplex stream ([#809](https://github.com/ipfs/js-ipfs/issues/809)) ([4b064a1](https://github.com/ipfs/js-ipfs/commit/4b064a1))

### Features

* bootstrap is enabled by default now ([64cde5d](https://github.com/ipfs/js-ipfs/commit/64cde5d))
* bootstrap is enabled by default now ([2642417](https://github.com/ipfs/js-ipfs/commit/2642417))
* datastore, ipfs-block and all the deps that were updated ([68d92b6](https://github.com/ipfs/js-ipfs/commit/68d92b6))
* no need anymore to append ipfs/Qmhash to webrtc-star multiaddrs ([a77ae3c](https://github.com/ipfs/js-ipfs/commit/a77ae3c))

<a name="0.22.1"></a>
## [0.22.1](https://github.com/ipfs/js-ipfs/compare/v0.22.0...v0.22.1) (2017-02-24)

### Bug Fixes

* interop tests with multiplex passing ([cb109fc](https://github.com/ipfs/js-ipfs/commit/cb109fc))

### Features

* **core:** allow IPFS object to be created without supplying configOpts ([f620d71](https://github.com/ipfs/js-ipfs/commit/f620d71))
* **deps:** update multiplex libp2p-ipfs deps ([5605148](https://github.com/ipfs/js-ipfs/commit/5605148))

<a name="0.22.0"></a>
# [0.22.0](https://github.com/ipfs/js-ipfs/compare/v0.21.8...v0.22.0) (2017-02-15)

### Bug Fixes

* lint ([ffc120a](https://github.com/ipfs/js-ipfs/commit/ffc120a))
* make sure all deps are up to date, expose Buffer type ([7eb630d](https://github.com/ipfs/js-ipfs/commit/7eb630d))
* readable-stream needs to be 1.1.14 ([e999f05](https://github.com/ipfs/js-ipfs/commit/e999f05))
* tidy dag cli up ([b90ba76](https://github.com/ipfs/js-ipfs/commit/b90ba76))

### Features

* **breaking change:** experimental config options ([#749](https://github.com/ipfs/js-ipfs/issues/749)) ([69fa802](https://github.com/ipfs/js-ipfs/commit/69fa802))
* **dag:** basics (get, put) ([#746](https://github.com/ipfs/js-ipfs/issues/746)) ([e5ec0cf](https://github.com/ipfs/js-ipfs/commit/e5ec0cf))
* **dag:** Resolve API ([#751](https://github.com/ipfs/js-ipfs/issues/751)) ([4986908](https://github.com/ipfs/js-ipfs/commit/4986908))
* merge of get and resolve ([#761](https://github.com/ipfs/js-ipfs/issues/761)) ([b081e35](https://github.com/ipfs/js-ipfs/commit/b081e35))

<a name="0.21.8"></a>
## [0.21.8](https://github.com/ipfs/js-ipfs/compare/v0.21.7...v0.21.8) (2017-01-31)

### Features

* add CLI support for different hash func and type ([#748](https://github.com/ipfs/js-ipfs/issues/748)) ([a6c522f](https://github.com/ipfs/js-ipfs/commit/a6c522f))

<a name="0.21.7"></a>
## [0.21.7](https://github.com/ipfs/js-ipfs/compare/v0.21.6...v0.21.7) (2017-01-30)

### Bug Fixes

* default config file ([01ef4b5](https://github.com/ipfs/js-ipfs/commit/01ef4b5))

<a name="0.21.6"></a>
## [0.21.6](https://github.com/ipfs/js-ipfs/compare/v0.21.5...v0.21.6) (2017-01-29)

### Features

* bootstrap as an option ([#735](https://github.com/ipfs/js-ipfs/issues/735)) ([03362a3](https://github.com/ipfs/js-ipfs/commit/03362a3))

<a name="0.21.5"></a>
## [0.21.5](https://github.com/ipfs/js-ipfs/compare/v0.21.4...v0.21.5) (2017-01-29)

### Bug Fixes

* differenciate default config in browser and in node ([#734](https://github.com/ipfs/js-ipfs/issues/734)) ([17ccc8b](https://github.com/ipfs/js-ipfs/commit/17ccc8b))

<a name="0.21.4"></a>
## [0.21.4](https://github.com/ipfs/js-ipfs/compare/v0.21.3...v0.21.4) (2017-01-28)

### Bug Fixes

* ipfs.id does not double append ipfs/<id> anymore ([#732](https://github.com/ipfs/js-ipfs/issues/732)) ([718394a](https://github.com/ipfs/js-ipfs/commit/718394a))

<a name="0.21.3"></a>
## [0.21.3](https://github.com/ipfs/js-ipfs/compare/v0.21.2...v0.21.3) (2017-01-25)

<a name="0.21.2"></a>
## [0.21.2](https://github.com/ipfs/js-ipfs/compare/v0.21.1...v0.21.2) (2017-01-23)

<a name="0.21.1"></a>
## [0.21.1](https://github.com/ipfs/js-ipfs/compare/v0.21.0...v0.21.1) (2017-01-23)

<a name="0.21.0"></a>
# [0.21.0](https://github.com/ipfs/js-ipfs/compare/v0.20.4...v0.21.0) (2017-01-17)

### Bug Fixes

* point to a specific go-ipfs version (still waiting for another 0.4.5 pre release though ([19dbb1e](https://github.com/ipfs/js-ipfs/commit/19dbb1e))

<a name="0.20.4"></a>
## [0.20.4](https://github.com/ipfs/js-ipfs/compare/v0.20.2...v0.20.4) (2016-12-26)

### Bug Fixes

* bitswap wantlist http endpoint ([58f0885](https://github.com/ipfs/js-ipfs/commit/58f0885))
* bitswap wantlist stats ([9db86f5](https://github.com/ipfs/js-ipfs/commit/9db86f5))
* change default values of js-ipfs to avoid clash with go-ipfs + clean the browserify example ([6d52e1c](https://github.com/ipfs/js-ipfs/commit/6d52e1c))
* npm scripts ([eadcec0](https://github.com/ipfs/js-ipfs/commit/eadcec0))
* pass a first arg to bitswap to be removed after new bitswap is merged, so that tests pass now ([bddcee7](https://github.com/ipfs/js-ipfs/commit/bddcee7))

### Features

* **init:** add empty unixfs dir to match go-ipfs ([a967bb0](https://github.com/ipfs/js-ipfs/commit/a967bb0))
* **object:** add template option to object.new ([9058118](https://github.com/ipfs/js-ipfs/commit/9058118))
* add multicastdns to the mix ([c2ddefb](https://github.com/ipfs/js-ipfs/commit/c2ddefb))

<a name="0.20.2"></a>
## [0.20.2](https://github.com/ipfs/js-ipfs/compare/v0.20.1...v0.20.2) (2016-12-09)

### Bug Fixes

* **cli:** Tell user to init repo if not initialized when starting daemon ([fa7e275](https://github.com/ipfs/js-ipfs/commit/fa7e275))

<a name="0.20.1"></a>
## [0.20.1](https://github.com/ipfs/js-ipfs/compare/v0.19.0...v0.20.1) (2016-11-28)

<a name="0.19.0"></a>
# [0.19.0](https://github.com/ipfs/js-ipfs/compare/v0.18.0...v0.19.0) (2016-11-26)

### Bug Fixes

* addLink and rmLink ([7fad4d8](https://github.com/ipfs/js-ipfs/commit/7fad4d8))
* apply CR ([698f708](https://github.com/ipfs/js-ipfs/commit/698f708))
* **lint:** install missing plugin ([20e3d2e](https://github.com/ipfs/js-ipfs/commit/20e3d2e))
* **lint:** use eslint directly ([443dd9e](https://github.com/ipfs/js-ipfs/commit/443dd9e))
* **lint and polish:** add a little more comments ([d6ce83d](https://github.com/ipfs/js-ipfs/commit/d6ce83d))

### Features

* **cli:** migrate to awesome-dag-pb ([3bb3ba8](https://github.com/ipfs/js-ipfs/commit/3bb3ba8))
* **core:** migrate to awesome dag-pb ([db550a1](https://github.com/ipfs/js-ipfs/commit/db550a1))
* **examples:** add a getting-started example ([7485ac5](https://github.com/ipfs/js-ipfs/commit/7485ac5))
* **http:** migrate to awesome dag-pb ([ca9935f](https://github.com/ipfs/js-ipfs/commit/ca9935f))
* **swarm:** update swarm.peers to new api ([265a77a](https://github.com/ipfs/js-ipfs/commit/265a77a))

<a name="0.18.0"></a>
# [0.18.0](https://github.com/ipfs/js-ipfs/compare/v0.17.0...v0.18.0) (2016-11-12)

### Bug Fixes

* async .key ([2d2185b](https://github.com/ipfs/js-ipfs/commit/2d2185b))
* don't break backwards compatibility on the Block API ([3674b8e](https://github.com/ipfs/js-ipfs/commit/3674b8e))
* **cli:** alias add, cat and get to top-level cli ([6ad325b](https://github.com/ipfs/js-ipfs/commit/6ad325b))

### Features

* block API uses CIDs ([2eeea35](https://github.com/ipfs/js-ipfs/commit/2eeea35))
* migrate cli to use new async DAGNode interface ([1b0b22d](https://github.com/ipfs/js-ipfs/commit/1b0b22d))
* migrate core to use new async DAGNode interface ([254afdc](https://github.com/ipfs/js-ipfs/commit/254afdc))
* migrate files to use IPLD Resolver ([0fb1a1a](https://github.com/ipfs/js-ipfs/commit/0fb1a1a))
* migrate http-api to use new async DAGNode interface ([01e56ec](https://github.com/ipfs/js-ipfs/commit/01e56ec))
* migrate init to IPLD resolver ([61d1084](https://github.com/ipfs/js-ipfs/commit/61d1084))
* object API internals updated to use CID ([5cb10cc](https://github.com/ipfs/js-ipfs/commit/5cb10cc))
* update cli and http to support new ipld block api with IPLD ([5dbb799](https://github.com/ipfs/js-ipfs/commit/5dbb799))
* **http:** better error messages ([cd7f77d](https://github.com/ipfs/js-ipfs/commit/cd7f77d))
* **http:** set default headers for browsers ([6a21cd0](https://github.com/ipfs/js-ipfs/commit/6a21cd0))

<a name="0.17.0"></a>
# [0.17.0](https://github.com/ipfs/js-ipfs/compare/v0.16.0...v0.17.0) (2016-10-10)

### Bug Fixes

* **cli:** Fix issue with right cwd not being set ([e5f5e1b](https://github.com/ipfs/js-ipfs/commit/e5f5e1b))
* **deps:** move blob stores to dependencies ([8f33d11](https://github.com/ipfs/js-ipfs/commit/8f33d11))
* **files.get:** fix the command ([7015586](https://github.com/ipfs/js-ipfs/commit/7015586))

### Features

* **http-api:** add joi validation to bootstrap ([028a98c](https://github.com/ipfs/js-ipfs/commit/028a98c))

<a name="0.16.0"></a>
# [0.16.0](https://github.com/ipfs/js-ipfs/compare/v0.15.0...v0.16.0) (2016-09-15)

### Bug Fixes

* **cli:** add output for cli init ([29c9793](https://github.com/ipfs/js-ipfs/commit/29c9793))
* always use files.cat ([5b8da13](https://github.com/ipfs/js-ipfs/commit/5b8da13))
* **cli:** make ipfs files add work online and offline ([3edc2b9](https://github.com/ipfs/js-ipfs/commit/3edc2b9)), closes [#480](https://github.com/ipfs/js-ipfs/issues/480)
* **cli:** pipe content to the cli from cat it is a stream ([3e4e2fd](https://github.com/ipfs/js-ipfs/commit/3e4e2fd))
* **cli:** use right argument for cli .cat ([2bf49ea](https://github.com/ipfs/js-ipfs/commit/2bf49ea))
* **cli:** use right argument for cli .cat ([dd3fe88](https://github.com/ipfs/js-ipfs/commit/dd3fe88))
* **config:** better http-api and interface-ipfs-core compliant ([2beac9c](https://github.com/ipfs/js-ipfs/commit/2beac9c))
* **http:** get handler reads the stream ([b0a6db9](https://github.com/ipfs/js-ipfs/commit/b0a6db9))
* **swarm:** fix cli commands and enable tests ([6effa19](https://github.com/ipfs/js-ipfs/commit/6effa19))
* **version:** better http-api and interface-ipfs-core compliant ([0ee7215](https://github.com/ipfs/js-ipfs/commit/0ee7215))

### Features

* **add:** add the http endpoint for files.add ([e29f429](https://github.com/ipfs/js-ipfs/commit/e29f429))
* **files:** get interface-ipfs-core files tests pass through http-api ([11cb4ca](https://github.com/ipfs/js-ipfs/commit/11cb4ca))
* **files:** interface-ipfs-core tests over ipfs-api ([001a6eb](https://github.com/ipfs/js-ipfs/commit/001a6eb))
* **swarm:** interface-ipfs-core swarm compatibility ([3b32dfd](https://github.com/ipfs/js-ipfs/commit/3b32dfd))
* **swarm:** make interface-ipfs-core compliant ([ef729bb](https://github.com/ipfs/js-ipfs/commit/ef729bb)), closes [#439](https://github.com/ipfs/js-ipfs/issues/439)
* **tests:** waste less time generating keys ([cb10ab7](https://github.com/ipfs/js-ipfs/commit/cb10ab7))

<a name="0.15.0"></a>
# [0.15.0](https://github.com/ipfs/js-ipfs/compare/v0.14.3...v0.15.0) (2016-09-09)

### Bug Fixes

* **cli:** fix the files API commands ([138f519](https://github.com/ipfs/js-ipfs/commit/138f519))
* **config:** support null values (0 or empty string) on get and set ([a3d98a8](https://github.com/ipfs/js-ipfs/commit/a3d98a8))
* **repo:** init does not break if no opts are passed. Fixes [#349](https://github.com/ipfs/js-ipfs/issues/349) ([ca700cc](https://github.com/ipfs/js-ipfs/commit/ca700cc))
* **style:** apply CR ([97af048](https://github.com/ipfs/js-ipfs/commit/97af048))
* **test:** make the version test fetch the version from package.json instead of a hardcoded value ([50c9f7c](https://github.com/ipfs/js-ipfs/commit/50c9f7c))

### Features

* **bitswap tests, config, id:** cope with the nuances of the config API (.replace) and make necessary changes to make it all work again ([cc0c8fd](https://github.com/ipfs/js-ipfs/commit/cc0c8fd))
* **block-core:** add compliance with interface-ipfs-core on block-API ([5e6387d](https://github.com/ipfs/js-ipfs/commit/5e6387d))
* **block-http:** tests passing according with compliance ([a4071f0](https://github.com/ipfs/js-ipfs/commit/a4071f0))
* **config:** make the config impl spec compliant ([76b6670](https://github.com/ipfs/js-ipfs/commit/76b6670))
* **config-http:** return error if value is invalid ([f7a668d](https://github.com/ipfs/js-ipfs/commit/f7a668d))
* **factory:** add ipfs factory to files ([eba0398](https://github.com/ipfs/js-ipfs/commit/eba0398))
* **factory:** add ipfs factory, verify it works with object tests ([3db096e](https://github.com/ipfs/js-ipfs/commit/3db096e))
* **files.add:** update API to conform latest interface-ipfs-core updates ([28b0bb7](https://github.com/ipfs/js-ipfs/commit/28b0bb7))
* **http:** Refactor inject tests, made them all pass again ([31f673d](https://github.com/ipfs/js-ipfs/commit/31f673d))
* **http:** refactor ipfs-api tests and make them all pass again ([56904fd](https://github.com/ipfs/js-ipfs/commit/56904fd))
* **object-http:** support protobuf encoded values ([5f02303](https://github.com/ipfs/js-ipfs/commit/5f02303))
* **roadmap:** update ([418660f](https://github.com/ipfs/js-ipfs/commit/418660f))
* **roadmap:** update roadmap ms2 with extra added goals ([ac5352e](https://github.com/ipfs/js-ipfs/commit/ac5352e))
* disable PhantomJS ([921b11e](https://github.com/ipfs/js-ipfs/commit/921b11e))
* **tests:** all tests running ([44dba6c](https://github.com/ipfs/js-ipfs/commit/44dba6c))
* **tests:** factory-http ([08a4b19](https://github.com/ipfs/js-ipfs/commit/08a4b19))

<a name="0.14.3"></a>
## [0.14.3](https://github.com/ipfs/js-ipfs/compare/v0.14.2...v0.14.3) (2016-08-10)

### Features

* **interface:** update interface-ipfs-core to v0.6.0 ([d855740](https://github.com/ipfs/js-ipfs/commit/d855740))

<a name="0.14.2"></a>
## [0.14.2](https://github.com/ipfs/js-ipfs/compare/v0.14.1...v0.14.2) (2016-08-09)

### Bug Fixes

* upgrade aegir and ensure glob is mocked ([3c70eaa](https://github.com/ipfs/js-ipfs/commit/3c70eaa)), closes [#354](https://github.com/ipfs/js-ipfs/issues/354) [#353](https://github.com/ipfs/js-ipfs/issues/353)
* **cli:** replace ronin with yargs ([cba42ca](https://github.com/ipfs/js-ipfs/commit/cba42ca)), closes [#331](https://github.com/ipfs/js-ipfs/issues/331)
* **version:** return actual js-ipfs version ([6377ab2](https://github.com/ipfs/js-ipfs/commit/6377ab2)), closes [#377](https://github.com/ipfs/js-ipfs/issues/377)
* use static version of package.json ([3ffdc27](https://github.com/ipfs/js-ipfs/commit/3ffdc27))

### Features

* update all dependencies ([b90747e](https://github.com/ipfs/js-ipfs/commit/b90747e))

<a name="0.14.1"></a>
## [0.14.1](https://github.com/ipfs/js-ipfs/compare/v0.14.0...v0.14.1) (2016-06-29)

<a name="0.14.0"></a>
# [0.14.0](https://github.com/ipfs/js-ipfs/compare/v0.13.0...v0.14.0) (2016-06-27)

<a name="0.13.0"></a>
# [0.13.0](https://github.com/ipfs/js-ipfs/compare/v0.12.0...v0.13.0) (2016-06-07)

<a name="0.12.0"></a>
# [0.12.0](https://github.com/ipfs/js-ipfs/compare/v0.11.1...v0.12.0) (2016-06-06)

### Bug Fixes

* handle new wantlist format ([7850dbb](https://github.com/ipfs/js-ipfs/commit/7850dbb))

<a name="0.11.1"></a>
## [0.11.1](https://github.com/ipfs/js-ipfs/compare/v0.11.0...v0.11.1) (2016-05-30)

<a name="0.11.0"></a>
# [0.11.0](https://github.com/ipfs/js-ipfs/compare/v0.10.3...v0.11.0) (2016-05-27)

<a name="0.10.3"></a>
## [0.10.3](https://github.com/ipfs/js-ipfs/compare/v0.10.2...v0.10.3) (2016-05-26)

<a name="0.10.2"></a>
## [0.10.2](https://github.com/ipfs/js-ipfs/compare/v0.10.1...v0.10.2) (2016-05-26)

### Bug Fixes

* use passed in repo location in the browser ([4b55102](https://github.com/ipfs/js-ipfs/commit/4b55102))

<a name="0.10.1"></a>
## [0.10.1](https://github.com/ipfs/js-ipfs/compare/v0.10.0...v0.10.1) (2016-05-25)

<a name="0.10.0"></a>
# [0.10.0](https://github.com/ipfs/js-ipfs/compare/v0.9.0...v0.10.0) (2016-05-24)

<a name="0.9.0"></a>
# [0.9.0](https://github.com/ipfs/js-ipfs/compare/v0.8.0...v0.9.0) (2016-05-24)

<a name="0.8.0"></a>
# [0.8.0](https://github.com/ipfs/js-ipfs/compare/v0.7.0...v0.8.0) (2016-05-23)

<a name="0.7.0"></a>
# [0.7.0](https://github.com/ipfs/js-ipfs/compare/v0.6.1...v0.7.0) (2016-05-21)

<a name="0.6.1"></a>
## [0.6.1](https://github.com/ipfs/js-ipfs/compare/v0.6.0...v0.6.1) (2016-05-19)

<a name="0.6.0"></a>
# [0.6.0](https://github.com/ipfs/js-ipfs/compare/v0.5.0...v0.6.0) (2016-05-19)

<a name="0.5.0"></a>
# [0.5.0](https://github.com/ipfs/js-ipfs/compare/v0.4.10...v0.5.0) (2016-05-16)

### Bug Fixes

* **files:add:** simplify checkPath ([46d9e6a](https://github.com/ipfs/js-ipfs/commit/46d9e6a))
* **files:get:** simplify checkArgs ([7f89bfb](https://github.com/ipfs/js-ipfs/commit/7f89bfb))
* **http:object:** proper handling of empty args ([9763f86](https://github.com/ipfs/js-ipfs/commit/9763f86))

### Features

* integrate libp2p-ipfs-browser ([6022b46](https://github.com/ipfs/js-ipfs/commit/6022b46))
* make core/object satisfy interface-ipfs-core ([96013bb](https://github.com/ipfs/js-ipfs/commit/96013bb))

<a name="0.4.10"></a>
## [0.4.10](https://github.com/ipfs/js-ipfs/compare/v0.4.9...v0.4.10) (2016-05-08)

### Bug Fixes

* **cli:** self host cmds listing ([a415dc1](https://github.com/ipfs/js-ipfs/commit/a415dc1))
* **core:** consistent repo.exists checks ([3d1e6b0](https://github.com/ipfs/js-ipfs/commit/3d1e6b0))

<a name="0.4.9"></a>
## [0.4.9](https://github.com/ipfs/js-ipfs/compare/v0.4.8...v0.4.9) (2016-04-28)

<a name="0.4.8"></a>
## [0.4.8](https://github.com/ipfs/js-ipfs/compare/v0.4.7...v0.4.8) (2016-04-28)

<a name="0.4.7"></a>
## [0.4.7](https://github.com/ipfs/js-ipfs/compare/v0.4.6...v0.4.7) (2016-04-25)

<a name="0.4.6"></a>
## [0.4.6](https://github.com/ipfs/js-ipfs/compare/v0.4.4...v0.4.6) (2016-04-22)

<a name="0.4.4"></a>
## [0.4.4](https://github.com/ipfs/js-ipfs/compare/v0.4.3...v0.4.4) (2016-03-22)

<a name="0.4.3"></a>
## [0.4.3](https://github.com/ipfs/js-ipfs/compare/v0.4.2...v0.4.3) (2016-03-21)

<a name="0.4.2"></a>
## [0.4.2](https://github.com/ipfs/js-ipfs/compare/v0.4.1...v0.4.2) (2016-03-21)

<a name="0.4.1"></a>
## [0.4.1](https://github.com/ipfs/js-ipfs/compare/v0.4.0...v0.4.1) (2016-03-16)

<a name="0.4.0"></a>
# [0.4.0](https://github.com/ipfs/js-ipfs/compare/v0.3.1...v0.4.0) (2016-02-23)

<a name="0.3.1"></a>
## [0.3.1](https://github.com/ipfs/js-ipfs/compare/v0.3.0...v0.3.1) (2016-02-19)

<a name="0.3.0"></a>
# [0.3.0](https://github.com/ipfs/js-ipfs/compare/v0.2.3...v0.3.0) (2016-02-03)

<a name="0.2.3"></a>
## [0.2.3](https://github.com/ipfs/js-ipfs/compare/v0.2.2...v0.2.3) (2016-01-31)

<a name="0.2.2"></a>
## [0.2.2](https://github.com/ipfs/js-ipfs/compare/v0.2.1...v0.2.2) (2016-01-28)

<a name="0.2.1"></a>
## [0.2.1](https://github.com/ipfs/js-ipfs/compare/v0.2.0...v0.2.1) (2016-01-28)

<a name="0.2.0"></a>
# [0.2.0](https://github.com/ipfs/js-ipfs/compare/v0.0.3...v0.2.0) (2016-01-27)

<a name="0.0.3"></a>
## [0.0.3](https://github.com/ipfs/js-ipfs/compare/v0.0.2...v0.0.3) (2016-01-15)

<a name="0.0.2"></a>
## 0.0.2 (2016-01-11)

'''
'''--- CODE_OF_CONDUCT.md ---
# Contributor Code of Conduct

The `js-ipfs` project follows the [`IPFS Community Code of Conduct`](https://github.com/ipfs/community/blob/master/code-of-conduct.md)

'''
'''--- CONTRIBUTING.md ---
# Contributing guidelines

IPFS as a project, including js-ipfs and all of its modules, follows the [standard IPFS Community contributing guidelines](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md).

We also adhere to the [IPFS JavaScript Community contributing guidelines](https://github.com/ipfs/community/blob/master/CONTRIBUTING_JS.md) which provide additional information of how to collaborate and contribute in the JavaScript implementation of IPFS.

We appreciate your time and attention for going over these. Please open an issue on [ipfs/community](https://github.com/ipfs/community) if you have any question.

Thank you.

'''
'''--- ISSUE_TEMPLATE.md ---
<!--
Thank you for reporting an issue.

This issue tracker is for bugs and issues found within the JavaScript implementation of IPFS.
If you require more general support please file an issue on our discuss forum. https://discuss.ipfs.io/

Please fill in as much of the template below as you're able.

Version: output of `jsipfs version --all` if using the CLI or `ipfs.version((err, version) => {})` if using the instance.
Platform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows). If using in a Browser, please share the browser version as well.
Subsystem: if known, please specify affected core module name (e.g Bitswap, libp2p, etc).

If possible, please provide code that demonstrates the problem, keeping it as
simple and free of external dependencies as you are able.
-->

- **Version**:
- **Platform**:
- **Subsystem**:

<!-- Bug, Feature, Question, Enhancement, Etc -->
#### Type:

<!-- 
One of following:
  Critical - System crash, application panic.
  High - The main functionality of the application does not work, API breakage, repo format breakage, etc.
  Medium - A non-essential functionality does not work, performance issues, etc.
  Low - An optional functionality does not work.
  Very Low - Translation or documentation mistake. Something that won't give anyone a bad day.
-->
#### Severity:

#### Description:

#### Steps to reproduce the error:

<!--
This is for you! Please read, and then delete this text before posting it.
The js-ipfs issues are only for bug reports and directly actionable features.

Read https://github.com/ipfs/community/blob/master/contributing.md#reporting-issues if your issue doesn't fit either of those categories.
-->

'''
'''--- README.md ---
<h1 align="center">
  <a href="https://ipfs.io">
    <img src="https://ipfs.io/ipfs/QmVk7srrwahXLNmcDYvyUEJptyoxpndnRa57YJ11L4jV26/ipfs.js.png" alt="IPFS in JavaScript logo" />
  </a>
</h1>

<h3 align="center">The JavaScript implementation of the IPFS protocol.</h3>

<p align="center">
  <a href="http://protocol.ai"><img src="https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat" /></a>
  <a href="http://ipfs.io/"><img src="https://img.shields.io/badge/project-IPFS-blue.svg?style=flat" /></a>
  <a href="http://webchat.freenode.net/?channels=%23ipfs"><img src="https://img.shields.io/badge/freenode-%23ipfs-blue.svg?style=flat" /></a>
  <a href="https://github.com/ipfs/team-mgmt/blob/master/MGMT_JS_CORE_DEV.md"><img src="https://img.shields.io/badge/team-mgmt-blue.svg?style=flat" /></a>
  <a href="https://github.com/ipfs/interface-ipfs-core"><img src="https://img.shields.io/badge/interface--ipfs--core-API%20Docs-blue.svg"></a>
</p>

<p align="center">
    <a href="https://ci.ipfs.team/job/ipfs/job/js-ipfs/job/master/"><img src="https://ci.ipfs.team/buildStatus/icon?job=ipfs/js-ipfs/master" /></a>
  <a href="https://codecov.io/gh/ipfs/js-ipfs"><img src="https://codecov.io/gh/ipfs/js-ipfs/branch/master/graph/badge.svg" /></a>
  <a href="https://david-dm.org/ipfs/js-ipfs"><img src="https://david-dm.org/ipfs/js-ipfs.svg?style=flat" /></a>
  <a href="https://github.com/feross/standard"><img src="https://img.shields.io/badge/code%20style-standard-brightgreen.svg?style=flat"></a>
  <a href=""><img src="https://img.shields.io/badge/npm-%3E%3D6.0.0-orange.svg?style=flat" /></a>
  <a href=""><img src="https://img.shields.io/badge/Node.js-%3E%3D10.0.0-orange.svg?style=flat" /></a>
  <br>
</p>

### Project status - `Alpha`

We've come a long way, but this project is still in Alpha, lots of development is happening, API might change, beware of the Dragons 🐉..

**Want to get started?** Check our [examples folder](/examples) to learn how to spawn an IPFS node in Node.js and in the Browser.

You can check the development status at the [Kanban Board](https://waffle.io/ipfs/js-ipfs).

[![Throughput Graph](https://graphs.waffle.io/ipfs/js-ipfs/throughput.svg)](https://waffle.io/ipfs/js-ipfs/metrics/throughput)

[**`Weekly Core Dev Calls`**](https://github.com/ipfs/pm/issues/650)

## Tech Lead

[David Dias](https://github.com/daviddias)

## Lead Maintainer

[Alan Shaw](https://github.com/alanshaw)

## Table of Contents

- [Install](#install)
  - [npm](#npm)
  - [Use in Node.js](#use-in-nodejs)
  - [Through command line tool](#through-command-line-tool)
  - [Use in the browser](#use-in-the-browser)
- [Usage](#usage)
  - [IPFS CLI](#ipfs-cli)
  - [IPFS Daemon](#ipfs-daemon)
  - [IPFS Module (use IPFS as a module in Node.js or in the Browser)](#ipfs-module)
  - [Tutorials and Examples](#tutorials-and-examples)
  - [API Docs](#api)
    - [Constructor](#ipfs-constructor)
    - [Events](#events)
    - [start](#nodestartcallback)
    - [stop](#nodestopcallback)
    - [Core API](#core-api)
      - [Files](#files)
      - [Graph](#graph)
      - [Name](#name)
      - [Crypto and Key Management](#crypto-and-key-management)
      - [Network](#network)
      - [Node Management](#node-management)
      - [Domain data types](#domain-data-types)
      - [Util](#util)
- [FAQ](#faq)
- [Running js-ipfs with Docker](#running-js-ipfs-with-docker)
- [Packages](#packages)
- [Development](#development)
  - [Clone and install dependencies](#clone-and-install-dependencies)
  - [Run Tests](#run-tests)
  - [Lint](#lint)
  - [Build a dist version](#build-a-dist-version)
- [Contribute](#contribute)
  - [Want to hack on IPFS?](#want-to-hack-on-ipfs)
- [License](#license)

## Install

### npm

This project is available through [npm](https://www.npmjs.com/). To install run

```bash
> npm install ipfs --save
```

We support both the Current and Active LTS versions of Node.js. Please see [nodejs.org](https://nodejs.org/) for what these currently are.

This project is tested on OSX & Linux, expected to work on Windows.

### Use in Node.js

To create an IPFS node programmatically:

```js
const IPFS = require('ipfs')
const node = new IPFS()

node.on('ready', () => {
  // Ready to use!
  // See https://github.com/ipfs/js-ipfs#core-api
})
```

### Through command line tool

In order to use js-ipfs as a CLI, you must install it with the `global` flag. Run the following (even if you have ipfs installed locally):

```bash
npm install ipfs --global
```

The CLI is available by using the command `jsipfs` in your terminal. This is aliased, instead of using `ipfs`, to make sure it does not conflict with the [Go implementation](https://github.com/ipfs/go-ipfs).

### Use in the browser

Learn how to bundle with browserify and webpack in the [`examples`](https://github.com/ipfs/js-ipfs/tree/master/examples) folder.

You can also load it using a `<script>` using the [unpkg](https://unpkg.com) CDN or the [jsDelivr](https://www.jsdelivr.com/package/npm/ipfs) CDN. Inserting one of the following lines will make a `Ipfs` object available in the global namespace.

```html
<!-- loading the minified version -->
<script src="https://unpkg.com/ipfs/dist/index.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/ipfs/dist/index.min.js"></script>

<!-- loading the human-readable (not minified) version -->
<script src="https://unpkg.com/ipfs/dist/index.js"></script>
<script src="https://cdn.jsdelivr.net/npm/ipfs/dist/index.js"></script>
```

Inserting one of the above lines will make an `Ipfs` object available in the global namespace:

```html
<script>
const node = new window.Ipfs()

node.on('ready', () => {
  // Ready to use!
  // See https://github.com/ipfs/js-ipfs#core-api
})
</script>
```

## Usage

### IPFS CLI

The `jsipfs` CLI, available when `js-ipfs` is installed globally, follows(should, it is a WIP) the same interface defined by `go-ipfs`, you can always use the `help` command for help menus.

```sh
# Install js-ipfs globally
> npm install ipfs --global
> jsipfs --help
Commands:
  bitswap               A set of commands to manipulate the bitswap agent.
  block                 Manipulate raw IPFS blocks.
  bootstrap             Show or edit the list of bootstrap peers.
  commands              List all available commands
  config <key> [value]  Get and set IPFS config values
  daemon                Start a long-running daemon process
# ...
```

`js-ipfs` uses some different default config values, so that they don't clash directly with a go-ipfs node running in the same machine. These are:

- default repo location: `~/.jsipfs` (can be changed with env variable `IPFS_PATH`)
- default swarm port: `4002`
- default API port: `5002`

### IPFS Daemon

The IPFS Daemon exposes the API defined [`http-api-spec`](https://github.com/ipfs/http-api-spec). You can use any of the IPFS HTTP-API client libraries with it, such as: [js-ipfs-http-client](https://github.com/ipfs/js-ipfs-http-client).

If you want a programmatic way to spawn a IPFS Daemon using JavaScript, check out [ipfsd-ctl module](https://github.com/ipfs/js-ipfsd-ctl)

### IPFS Module

Use the IPFS Module as a dependency of a project to __spawn in process instances of IPFS__. Create an instance by calling `new IPFS()` and waiting for its `ready` event:

```js
// Create the IPFS node instance
const node = new IPFS()

node.on('ready', () => {
  // Your node is now ready to use \o/

  // stopping a node
  node.stop(() => {
    // node is now 'offline'
  })
})
```

### [Tutorials and Examples](/examples)

You can find some examples and tutorials in the [examples](/examples) folder, these exist to help you get started using `js-ipfs`.

### API

#### IPFS Constructor

```js
const node = new IPFS([options])
```

Creates and returns an instance of an IPFS node. Use the `options` argument to specify advanced configuration. It is an object with any of these properties:

##### `options.repo`

| Type | Default |
|------|---------|
| string or [`ipfs.Repo`](https://github.com/ipfs/js-ipfs-repo) instance | `'~/.jsipfs'` in Node.js, `'ipfs'` in browsers |

The file path at which to store the IPFS node’s data. Alternatively, you can set up a customized storage system by providing an [`ipfs.Repo`](https://github.com/ipfs/js-ipfs-repo) instance.

Example:

```js
// Store data outside your user directory
const node = new IPFS({ repo: '/var/ipfs/data' })
```

##### `options.init`

| Type | Default |
|------|---------|
| boolean or object | `true` |

Initialize the repo when creating the IPFS node.

If you have already initialized a repo before creating your IPFS node (e.g. you are loading a repo that was saved to disk from a previous run of your program), you must make sure to set this to `false`. Note that *initializing* a repo is different from creating an instance of [`ipfs.Repo`](https://github.com/ipfs/js-ipfs-repo). The IPFS constructor sets many special properties when initializing a repo, so you should usually not try and call `repoInstance.init()` yourself.

Instead of a boolean, you may provide an object with custom initialization options. All properties are optional:

- `emptyRepo` (boolean) Whether to remove built-in assets, like the instructional tour and empty mutable file system, from the repo. (Default: `false`)
- `bits` (number) Number of bits to use in the generated key pair. (Default: `2048`)
- `privateKey` (string/PeerId) A pre-generated private key to use. Can be either a base64 string or a [PeerId](https://github.com/libp2p/js-peer-id) instance. **NOTE: This overrides `bits`.**
    ```js
    // Generating a Peer ID:
    const PeerId = require('peer-id')
    PeerId.create({ bits: 2048 }, (err, peerId) => {
      // Generates a new Peer ID, complete with public/private keypair
      // See https://github.com/libp2p/js-peer-id
    })
    ```
- `pass` (string) A passphrase to encrypt keys. You should generally use the [top-level `pass` option](#optionspass) instead of the `init.pass` option (this one will take its value from the top-level option if not set).

##### `options.start`

| Type | Default |
|------|---------|
| boolean | `true` |

 If `false`, do not automatically start the IPFS node. Instead, you’ll need to manually call [`node.start()`](#nodestartcallback) yourself.

##### `options.pass`

| Type | Default |
|------|---------|
| string | `null` |

A passphrase to encrypt/decrypt your keys.

##### `options.silent`

| Type | Default |
|------|---------|
| Boolean | `false` |

Prevents all logging output from the IPFS node.

##### `options.relay`

| Type | Default |
|------|---------|
| object | `{ enabled: false, hop: { enabled: false, active: false } }` |

Configure circuit relay (see the [circuit relay tutorial](https://github.com/ipfs/js-ipfs/tree/master/examples/circuit-relaying) to learn more).

- `enabled` (boolean): Enable circuit relay dialer and listener. (Default: `false`)
- `hop` (object)
    - `enabled` (boolean): Make this node a relay (other nodes can connect *through* it). (Default: `false`)
    - `active` (boolean): Make this an *active* relay node. Active relay nodes will attempt to dial a destination peer even if that peer is not yet connected to the relay. (Default: `false`)

##### `options.preload`

| Type | Default |
|------|---------|
| object | `{ enabled: true, addresses: [...] }` |

Configure remote preload nodes. The remote will preload content added on this node, and also attempt to preload objects requested by this node.

- `enabled` (boolean): Enable content preloading (Default: `true`)
- `addresses` (array): Multiaddr API addresses of nodes that should preload content. **NOTE:** nodes specified here should also be added to your node's bootstrap address list at [`config.Boostrap`](#optionsconfig).

##### `options.EXPERIMENTAL`

| Type | Default |
|------|---------|
| object | `{ pubsub: false, sharding: false, dht: false }` |

Enable and configure experimental features.

- `pubsub` (boolean): Enable libp2p pub-sub. (Default: `false`)
- `ipnsPubsub` (boolean): Enable pub-sub on IPNS. (Default: `false`)
- `sharding` (boolean): Enable directory sharding. Directories that have many child objects will be represented by multiple DAG nodes instead of just one. It can improve lookup performance when a directory has several thousand files or more. (Default: `false`)

##### `options.config`

| Type | Default |
|------|---------|
| object |  [`config-nodejs.js`](https://github.com/ipfs/js-ipfs/tree/master/src/core/runtime/config-nodejs.js) in Node.js, [`config-browser.js`](https://github.com/ipfs/js-ipfs/tree/master/src/core/runtime/config-browser.js) in browsers |

Modify the default IPFS node config. This object will be *merged* with the default config; it will not replace it.

##### `options.libp2p`

| Type | Default |
|------|---------|
| object | [`libp2p-nodejs.js`](https://github.com/ipfs/js-ipfs/blob/master/src/core/runtime/libp2p-nodejs.js) in Node.js, [`libp2p-browser.js`](https://github.com/ipfs/js-ipfs/blob/master/src/core/runtime/libp2p-browser.js) in browsers |
| function | [`libp2p bundle`](examples/custom-libp2p) |

The libp2p option allows you to build your libp2p node by configuration, or via a bundle function. If you are looking to just modify the below options, using the object format is the quickest way to get the default features of libp2p. If you need to create a more customized libp2p node, such as with custom transports or peer/content routers that need some of the ipfs data on startup, a custom bundle is a great way to achieve this.

You can see the bundle in action in the [custom libp2p example](examples/custom-libp2p).

- `modules` (object):
    - `transport` (Array<[libp2p.Transport](https://github.com/libp2p/interface-transport)>): An array of Libp2p transport classes/instances to use _instead_ of the defaults. See [libp2p/interface-transport](https://github.com/libp2p/interface-transport) for details.
    - `peerDiscovery` (Array<[libp2p.PeerDiscovery](https://github.com/libp2p/interface-peer-discovery)>): An array of Libp2p peer discovery classes/instances to use _instead_ of the defaults. See [libp2p/peer-discovery](https://github.com/libp2p/interface-peer-discovery) for details. If passing a class, configuration can be passed using the config section below under the key corresponding to you module's unique `tag` (a static property on the class)
- `config` (object):
    - `peerDiscovery` (object):
        - `[PeerDiscovery.tag]` (object): configuration for a peer discovery module
            - `enabled` (boolean): whether this module is enabled or disabled
            - `[custom config]` (any): other keys are specific to the module

##### `options.connectionManager`

| Type | Default |
|------|---------|
| object | [defaults](https://github.com/libp2p/js-libp2p-connection-manager#create-a-connectionmanager) |

Configure the libp2p connection manager.

#### Events

IPFS instances are Node.js [EventEmitters](https://nodejs.org/dist/latest-v8.x/docs/api/events.html#events_class_eventemitter). You can listen for events by calling `node.on('event', handler)`:

```js
const node = new IPFS({ repo: '/var/ipfs/data' })
node.on('error', errorObject => console.error(errorObject))
```

- `error` is always accompanied by an `Error` object with information about the error that occurred.

    ```js
    node.on('error', error => {
      console.error(error.message)
    })
    ```

- `init` is emitted after a new repo has been initialized. It will not be emitted if you set the `init: false` option on the constructor.

- `ready` is emitted when a node is ready to use. This is the final event you will receive when creating a node (after `init` and `start`).

    When creating a new IPFS node, you should almost always wait for the `ready` event before calling methods or interacting with the node.

- `start` is emitted when a node has started listening for connections. It will not be emitted if you set the `start: false` option on the constructor.

- `stop` is emitted when a node has closed all connections and released access to its repo. This is usually the result of calling [`node.stop()`](#nodestopcallback).

#### `node.start([callback])`

Start listening for connections with other IPFS nodes on the network. In most cases, you do not need to call this method — `new IPFS()` will automatically do it for you.

This method is asynchronous. There are several ways to be notified when the node has finished starting:

1. If you call `node.start()` with no arguments, it returns a promise.

    ```js
    const node = new IPFS({ start: false })

    node.on('ready', async () => {
      console.log('Node is ready to use!')

      try {
        await node.start()
        console.log('Node started!')
      } catch (error) {
        console.error('Node failed to start!', error)
      }
    })
    ```

2. If you pass a function as the final argument, it will be called when the node is started (Note: this method will **not** return a promise if you use a callback function).

    ```js
    const node = new IPFS({ start: false })

    node.on('ready', () => {
      console.log('Node is ready to use!')

      node.start(error => {
        if (error) {
          return console.error('Node failed to start!', error)
        }
        console.log('Node started!')
      })
    })
    ```

3. You can listen for the [`start` event](#events).

    ```js
    const node = new IPFS({ start: false })

    node.on('ready', () => {
      console.log('Node is ready to use!')
      node.start()
    })

    node.on('error', error => {
      console.error('Something went terribly wrong!', error)
    })

    node.on('start', () => console.log('Node started!'))
    ```

#### `node.stop([callback])`

Close and stop listening for connections with other IPFS nodes, then release access to the node’s repo.

This method is asynchronous. There are several ways to be notified when the node has completely stopped:

1. If you call `node.stop()` with no arguments, it returns a promise.

    ```js
    const node = new IPFS()

    node.on('ready', async () => {
      console.log('Node is ready to use!')

      try {
        await node.stop()
        console.log('Node stopped!')
      } catch (error) {
        console.error('Node failed to stop cleanly!', error)
      }
    })
    ```

2. If you pass a function as the final argument, it will be called when the node is stopped (Note: this method will **not** return a promise if you use a callback function).

    ```js
    const node = new IPFS()

    node.on('ready', () => {
      console.log('Node is ready to use!')

      node.stop(error => {
        if (error) {
          return console.error('Node failed to stop cleanly!', error)
        }
        console.log('Node stopped!')
      })
    })
    ```

3. You can listen for the [`stop` event](#events).

    ```js
    const node = new IPFS()

    node.on('ready', () => {
      console.log('Node is ready to use!')
      node.stop()
    })

    node.on('error', error => {
      console.error('Something went terribly wrong!', error)
    })

    node.on('stop', () => console.log('Node stopped!'))
    ```

#### Core API

[![](https://github.com/ipfs/interface-ipfs-core/raw/master/img/badge.png)](https://github.com/ipfs/interface-ipfs-core)

The IPFS core API provides all functionality that is not specific to setting up and starting or stopping a node. This API is available directly on an IPFS instance, on the command line (when using the CLI interface), and as an HTTP REST API. For a complete reference, see [![](https://img.shields.io/badge/interface--ipfs--core-API%20Docs-blue.svg)](https://github.com/ipfs/interface-ipfs-core).

The core API is grouped into several areas:

#### Files

- [Regular Files API](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md)
  - [`ipfs.add(data, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#add)
  - [`ipfs.addPullStream([options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addpullstream)
  - [`ipfs.addReadableStream([options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addreadablestream)
  - [`ipfs.addFromStream(stream, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addfromstream)
  - [`ipfs.addFromFs(path, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addfromfs)
  - [`ipfs.addFromUrl(url, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addfromurl)
  - [`ipfs.cat(ipfsPath, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#cat)
  - [`ipfs.catPullStream(ipfsPath, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#catpullstream)
  - [`ipfs.catReadableStream(ipfsPath, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#catreadablestream)
  - [`ipfs.get(ipfsPath, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#get)
  - [`ipfs.getPullStream(ipfsPath, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#getpullstream)
  - [`ipfs.getReadableStream(ipfsPath, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#getreadablestream)
  - [`ipfs.ls(ipfsPath, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#ls)
  - [`ipfs.lsPullStream(ipfsPath)`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#lspullstream)
  - [`ipfs.lsReadableStream(ipfsPath)`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#lsreadablestream)
- [MFS (mutable file system) specific](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#mutable-file-system)
  - [`ipfs.files.cp([from, to], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filescp)
  - [`ipfs.files.flush([path], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesflush)
  - [`ipfs.files.ls([path], [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesls)
  - [`ipfs.files.mkdir(path, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesmkdir)
  - [`ipfs.files.mv([from, to], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesmv)
  - [`ipfs.files.read(path, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesread)
  - [`ipfs.files.readPullStream(path, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesreadpullstream)
  - [`ipfs.files.readReadableStream(path, [options])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesreadreadablestream)
  - [`ipfs.files.rm(path, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesrm)
  - [`ipfs.files.stat(path, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#filesstat)
  - [`ipfs.files.write(path, content, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#fileswrite)

#### Graph

- [dag](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/DAG.md)
  - [`ipfs.dag.put(dagNode, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/DAG.md#dagput)
  - [`ipfs.dag.get(cid, [path], [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/DAG.md#dagget)
  - [`ipfs.dag.tree(cid, [path], [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/DAG.md#dagtree)

- [pin](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/PIN.md)
  - [`ipfs.pin.add(hash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/PIN.md#pinadd)
  - [`ipfs.pin.ls([hash], [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/PIN.md#pinls)
  - [`ipfs.pin.rm(hash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/PIN.md#pinrm)

- [object (legacy)](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md)
  - [`ipfs.object.new([template], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectnew)
  - [`ipfs.object.put(obj, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectput)
  - [`ipfs.object.get(multihash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectget)
  - [`ipfs.object.data(multihash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectdata)
  - [`ipfs.object.links(multihash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectlinks)
  - [`ipfs.object.stat(multihash, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectstat)
  - [`ipfs.object.patch.addLink(multihash, DAGLink, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectpatchaddlink)
  - [`ipfs.object.patch.rmLink(multihash, DAGLink, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectpatchrmlink)
  - [`ipfs.object.patch.appendData(multihash, data, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectpatchappenddata)
  - [`ipfs.object.patch.setData(multihash, data, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/OBJECT.md#objectpatchsetdata)

#### Block

- [block](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BLOCK.md)
  - [`ipfs.block.get(cid, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BLOCK.md#blockget)
  - [`ipfs.block.put(block, cid, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BLOCK.md#blockput)
  - [`ipfs.block.stat(cid, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BLOCK.md#blockstat)
- [bitswap](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BITSWAP.md)
  - [`ipfs.bitswap.wantlist([peerId], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/BITSWAP.md#bitswapwantlist)
  - [`ipfs.bitswap.stat([callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/BITSWAP.md#bitswapstat)

#### Name

- [name](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md)
  - [`ipfs.name.publish(value, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md#namepublish)
  - [`ipfs.name.pubsub.cancel(arg, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md#namepubsubcancel)
  - [`ipfs.name.pubsub.state([callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md#namepubsubstate)
  - [`ipfs.name.pubsub.subs([callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md#namepubsubsubs)
  - [`ipfs.name.resolve(value, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/NAME.md#nameresolve)

#### Crypto and Key Management

- [key](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/KEY.md)
  - [`ipfs.key.export(name, password, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keyexport)
  - [`ipfs.key.gen(name, options, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keygen)
  - [`ipfs.key.import(name, pem, password, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keyimport)
  - [`ipfs.key.list([callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keylist)
  - [`ipfs.key.rename(oldName, newName, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keyrename)
  - [`ipfs.key.rm(name, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/KEY.md#keyrm)

- crypto (not implemented yet)

#### Network

- [bootstrap](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/BOOTSTRAP.md)
  - [`ipfs.bootstrap.list([callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/BOOTSTRAP.md#bootstraplist)
  - [`ipfs.bootstrap.add(addr, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/BOOTSTRAP.md#bootstrapadd)
  - [`ipfs.bootstrap.rm(peer, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/BOOTSTRAP.md#bootstraprm)

- [dht](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/)
  - [`ipfs.dht.findPeer(peerId, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtfindpeer)
  - [`ipfs.dht.findProvs(multihash, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtfindprovs)
  - [`ipfs.dht.get(key, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtget)
  - [`ipfs.dht.provide(cid, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtprovide)
  - [`ipfs.dht.put(key, value, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtput)
  - [`ipfs.dht.query(peerId, [callback])`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/DHT.md#dhtquery)

- [pubsub](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md)
  - [`ipfs.pubsub.subscribe(topic, handler, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md#pubsubsubscribe)
  - [`ipfs.pubsub.unsubscribe(topic, handler, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md#pubsubunsubscribe)
  - [`ipfs.pubsub.publish(topic, data, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md#pubsubpublish)
  - [`ipfs.pubsub.ls(topic, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md#pubsubls)
  - [`ipfs.pubsub.peers(topic, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/PUBSUB.md#pubsubpeers)

- [libp2p](https://github.com/libp2p/interface-libp2p). Every IPFS instance also exposes the libp2p SPEC at `ipfs.libp2p`. The formal interface for this SPEC hasn't been defined but you can find documentation at its implementations:
  - [Node.js bundle](./src/core/runtime/libp2p-nodejs.js)
  - [Browser Bundle](./src/core/runtime/libp2p-browser.js)
  - [libp2p baseclass](https://github.com/libp2p/js-libp2p)

- [swarm](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/SWARM.md)
  - [`ipfs.swarm.addrs([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/SWARM.md#swarmaddrs)
  - [`ipfs.swarm.connect(addr, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/SWARM.md#swarmconnect)
  - [`ipfs.swarm.disconnect(addr, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/SWARM.md#swarmdisconnect)
  - [`ipfs.swarm.peers([options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/SWARM.md#swarmpeers)

#### Node Management

- [miscellaneous operations](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md)
  - [`ipfs.id([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#id)
  - [`ipfs.version([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#version)
  - [`ipfs.ping(peerId, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#ping)
  - [`ipfs.pingReadableStream(peerId, [options])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#pingreadablestream)
  - [`ipfs.pingPullStream(peerId, [options])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#pingpullstream)
  - `ipfs.init([options], [callback])`
  - `ipfs.start([callback])`
  - [`ipfs.stop([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#stop)
  - `ipfs.isOnline()`
  - [`ipfs.resolve(name, [options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/MISCELLANEOUS.md#resolve)

- [repo](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/REPO.md)
  - `ipfs.repo.init`
  - [`ipfs.repo.stat([options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/REPO.md#repostat)
  - [`ipfs.repo.version([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/REPO.md#repoversion)
  - `ipfs.repo.gc([options], [callback])` (not implemented yet)

- [stats](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md)
  - [`ipfs.stats.bitswap([callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md#statsbitswap)
  - [`ipfs.stats.bw([options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md#statsbw)
  - [`ipfs.stats.bwPullStream([options]) -> Pull Stream`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md#statsbwpullstream)
  - [`ipfs.stats.bwReadableStream([options]) -> Readable Stream`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md#statsbwreadablestream)
  - [`ipfs.stats.repo([options], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/STATS.md#statsrepo)

- [config](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/CONFIG.md)
  - [`ipfs.config.get([key], [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/CONFIG.md#configget)
  - [`ipfs.config.set(key, value, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/CONFIG.md#configset)
  - [`ipfs.config.replace(config, [callback])`](https://github.com/ipfs/interface-ipfs-core/tree/master/SPEC/CONFIG.md#configreplace)

#### Domain data types

A set of data types are exposed directly from the IPFS instance under `ipfs.types`. That way you're not required to import/require the following.

- [`ipfs.types.Buffer`](https://www.npmjs.com/package/buffer)
- [`ipfs.types.PeerId`](https://github.com/libp2p/js-peer-id)
- [`ipfs.types.PeerInfo`](https://github.com/libp2p/js-peer-info)
- [`ipfs.types.multiaddr`](https://github.com/multiformats/js-multiaddr)
- [`ipfs.types.multibase`](https://github.com/multiformats/js-multibase)
- [`ipfs.types.multihash`](https://github.com/multiformats/js-multihash)
- [`ipfs.types.CID`](https://github.com/ipld/js-cid)
- [`ipfs.types.dagPB`](https://github.com/ipld/js-ipld-dag-pb)
- [`ipfs.types.dagCBOR`](https://github.com/ipld/js-ipld-dag-cbor)

#### Util

A set of utils are exposed directly from the IPFS instance under `ipfs.util`. That way you're not required to import/require the following:

- [`ipfs.util.crypto`](https://github.com/libp2p/js-libp2p-crypto)
- [`ipfs.util.isIPFS`](https://github.com/ipfs-shipyard/is-ipfs)

## FAQ

#### How to enable WebRTC support for js-ipfs in the Browser

To add a WebRTC transport to your js-ipfs node, you must add a WebRTC multiaddr. To do that, simple override the config.Addresses.Swarm array which contains all the multiaddrs which the IPFS node will use. See below:

```JavaScript
const node = new IPFS({
  config: {
    Addresses: {
      Swarm: [
        '/dns4/wrtc-star.discovery.libp2p.io/tcp/443/wss/p2p-webrtc-star'
      ]
    }
  }
})

node.on('ready', () => {
  // your instance with WebRTC is ready
})
```

**Important:** This transport usage is kind of unstable and several users have experienced crashes. Track development of a solution at https://github.com/ipfs/js-ipfs/issues/1088.

#### Is there WebRTC support for js-ipfs with Node.js?

Yes, however, bear in mind that there isn't a 100% stable solution to use WebRTC in Node.js, use it at your own risk. The most tested options are:

- [wrtc](https://npmjs.org/wrtc) - Follow the install instructions.
- [electron-webrtc](https://npmjs.org/electron-webrtc)

To add WebRTC support in a IPFS node instance, do:

```JavaScript
const wrtc = require('wrtc') // or require('electron-webrtc')()
const WStar = require('libp2p-webrtc-star')
const wstar = new WStar({ wrtc })

const node = new IPFS({
  repo: 'your-repo-path',
  // start: false,
  config: {
    Addresses: {
      Swarm: [
        "/ip4/0.0.0.0/tcp/4002",
        "/ip4/127.0.0.1/tcp/4003/ws",
        "/dns4/wrtc-star.discovery.libp2p.io/tcp/443/wss/p2p-webrtc-star"
      ]
    }
  },
  libp2p: {
    modules: {
      transport: [wstar],
      peerDiscovery: [wstar.discovery]
    }
  }
})

node.on('ready', () => {
  // your instance with WebRTC is ready
})
```

To add WebRTC support to the IPFS daemon, you only need to install one of the WebRTC modules globally:

```bash
npm install wrtc --global
# or
npm install electron-webrtc --global
```

Then, update your IPFS Daemon config to include the multiaddr for this new transport on the `Addresses.Swarm` array. Add: `"/dns4/wrtc-star.discovery.libp2p.io/wss/p2p-webrtc-star"`

#### How can I configure an IPFS node to use a custom `signaling endpoint` for my WebRTC transport?

You'll need to execute a compatible `signaling server` ([libp2p-webrtc-star](https://github.com/libp2p/js-libp2p-webrtc-star) works) and include the correct configuration param for your IPFS node:

- provide the [`multiaddr`](https://github.com/multiformats/multiaddr) for the `signaling server`

```JavaScript
const node = new IPFS({
  repo: 'your-repo-path',
  config: {
    Addresses: {
      Swarm: [
        '/ip4/127.0.0.1/tcp/9090/ws/p2p-webrtc-star'
      ]
    }
  }
})
```

The code above assumes you are running a local `signaling server` on port `9090`. Provide the correct values accordingly.

#### Is there a more stable alternative to webrtc-star that offers a similar functionality?

Yes, websocket-star! A WebSockets based transport that uses a Relay to route the messages. To enable it, just do:

```JavaScript
const node = new IPFS({
  config: {
    Addresses: {
      Swarm: [
        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star'
      ]
    }
  }
})

node.on('ready', () => {
  // your instance with websocket-star is ready
})
```

#### I see some slowness when hopping between tabs Chrome with IPFS nodes, is there a reason why?

Yes, unfortunately, due to [Chrome aggressive resource throttling policy](https://github.com/ipfs/js-ipfs/issues/611), it cuts freezes the execution of any background tab, turning an IPFS node that was running on that webpage into a vegetable state.

A way to mitigate this in Chrome, is to run your IPFS node inside a Service Worker, so that the IPFS instance runs in a background process. You can learn how to install an IPFS node as a service worker in here the repo [ipfs-service-worker](https://github.com/ipfs/ipfs-service-worker)

#### Can I use IPFS in my Electron App?

Yes you can and in many ways. Read https://github.com/ipfs/notes/issues/256 for the multiple options.

If your [electron-rebuild step is failing](https://github.com/ipfs/js-ipfs/issues/843), all you need to do is:

```bash
# Electron's version.
export npm_config_target=2.0.0
# The architecture of Electron, can be ia32 or x64.
export npm_config_arch=x64
export npm_config_target_arch=x64
# Download headers for Electron.
export npm_config_disturl=https://atom.io/download/electron
# Tell node-pre-gyp that we are building for Electron.
export npm_config_runtime=electron
# Tell node-pre-gyp to build module from source code.
export npm_config_build_from_source=true
# Install all dependencies, and store cache to ~/.electron-gyp.
HOME=~/.electron-gyp npm install
```

If you find any other issue, please check the [`Electron Support` issue](https://github.com/ipfs/js-ipfs/issues/843).

#### Have more questions?

Ask for help in our forum at https://discuss.ipfs.io or in IRC (#ipfs on Freenode).

## Running js-ipfs with Docker

We have automatic Docker builds setup with Docker Hub: https://hub.docker.com/r/ipfs/js-ipfs/

All branches in the Github repository maps to a tag in Docker Hub, except `master` Git branch which is mapped to `latest` Docker tag.

You can run js-ipfs like this:

```
$ docker run -it -p 4002:4002 -p 4003:4003 -p 5002:5002 -p 9090:9090 ipfs/js-ipfs:latest

initializing ipfs node at /root/.jsipfs
generating 2048-bit RSA keypair...done
peer identity: Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS
to get started, enter:

         jsipfs files cat /ipfs/QmfGBRT6BbWJd7yUc2uYdaUZJBbnEFvTqehPFoSMQ6wgdr/readme

Initializing daemon...
Using wrtc for webrtc support
Swarm listening on /ip4/127.0.0.1/tcp/4003/ws/ipfs/Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS
Swarm listening on /ip4/172.17.0.2/tcp/4003/ws/ipfs/Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS
Swarm listening on /ip4/127.0.0.1/tcp/4002/ipfs/Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS
Swarm listening on /ip4/172.17.0.2/tcp/4002/ipfs/Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS
API is listening on: /ip4/0.0.0.0/tcp/5002
Gateway (readonly) is listening on: /ip4/0.0.0.0/tcp/9090
Daemon is ready

$ curl --silent localhost:5002/api/v0/id | jq .ID
"Qmbd5jx8YF1QLhvwfLbCTWXGyZLyEJHrPbtbpRESvYs4FS"
```

## Packages

Listing of the main packages used in the IPFS ecosystem. There are also three specifications worth linking here:

- [`interface-ipfs-core`](https://github.com/ipfs/interface-ipfs-core)
- [`http-api-spec`](https://github.com/ipfs/http-api-spec)
- [`cli spec`](https://github.com/ipfs/specs/tree/master/public-api/cli)

> This table is generated using the module `package-table` with `package-table --data=package-list.json`.

| Package | Version | Deps | CI | Coverage | Lead Maintainer |
| ---------|---------|---------|---------|---------|--------- |
| **Files** |
| [`ipfs-unixfs-engine`](//github.com/ipfs/js-ipfs-unixfs-engine) | [![npm](https://img.shields.io/npm/v/ipfs-unixfs-engine.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-unixfs-engine/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-unixfs-engine.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-unixfs-engine) | N/A | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-unixfs-engine/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-unixfs-engine) | [Alex Potsides](mailto:alex.potsides@protocol.ai) |
| **DAG** |
| [`ipld`](//github.com/ipld/js-ipld) | [![npm](https://img.shields.io/npm/v/ipld.svg?maxAge=86400&style=flat-square)](//github.com/ipld/js-ipld/releases) | [![Deps](https://david-dm.org/ipld/js-ipld.svg?style=flat-square)](https://david-dm.org/ipld/js-ipld) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipld/js-ipld/master)](https://ci.ipfs.team/job/ipld/job/js-ipld/job/master/) | [![codecov](https://codecov.io/gh/ipld/js-ipld/branch/master/graph/badge.svg)](https://codecov.io/gh/ipld/js-ipld) | [Volker Mische](mailto:volker.mische@gmail.com) |
| [`ipld-dag-pb`](//github.com/ipld/js-ipld-dag-pb) | [![npm](https://img.shields.io/npm/v/ipld-dag-pb.svg?maxAge=86400&style=flat-square)](//github.com/ipld/js-ipld-dag-pb/releases) | [![Deps](https://david-dm.org/ipld/js-ipld-dag-pb.svg?style=flat-square)](https://david-dm.org/ipld/js-ipld-dag-pb) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipld/js-ipld-dag-pb/master)](https://ci.ipfs.team/job/ipld/job/js-ipld-dag-pb/job/master/) | [![codecov](https://codecov.io/gh/ipld/js-ipld-dag-pb/branch/master/graph/badge.svg)](https://codecov.io/gh/ipld/js-ipld-dag-pb) | [Volker Mische](mailto:volker.mische@gmail.com) |
| [`ipld-dag-cbor`](//github.com/ipld/js-ipld-dag-cbor) | [![npm](https://img.shields.io/npm/v/ipld-dag-cbor.svg?maxAge=86400&style=flat-square)](//github.com/ipld/js-ipld-dag-cbor/releases) | [![Deps](https://david-dm.org/ipld/js-ipld-dag-cbor.svg?style=flat-square)](https://david-dm.org/ipld/js-ipld-dag-cbor) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipld/js-ipld-dag-cbor/master)](https://ci.ipfs.team/job/ipld/job/js-ipld-dag-cbor/job/master/) | [![codecov](https://codecov.io/gh/ipld/js-ipld-dag-cbor/branch/master/graph/badge.svg)](https://codecov.io/gh/ipld/js-ipld-dag-cbor) | [Volker Mische](mailto:volker.mische@gmail.com) |
| **Repo** |
| [`ipfs-repo`](//github.com/ipfs/js-ipfs-repo) | [![npm](https://img.shields.io/npm/v/ipfs-repo.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-repo/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-repo.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-repo) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipfs/js-ipfs-repo/master)](https://ci.ipfs.team/job/ipfs/job/js-ipfs-repo/job/master/) | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-repo/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-repo) | [Jacob Heun](mailto:jacobheun@gmail.com) |
| **Exchange** |
| [`ipfs-block-service`](//github.com/ipfs/js-ipfs-block-service) | [![npm](https://img.shields.io/npm/v/ipfs-block-service.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-block-service/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-block-service.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-block-service) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipfs/js-ipfs-block-service/master)](https://ci.ipfs.team/job/ipfs/job/js-ipfs-block-service/job/master/) | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-block-service/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-block-service) | N/A |
| [`ipfs-bitswap`](//github.com/ipfs/js-ipfs-bitswap) | [![npm](https://img.shields.io/npm/v/ipfs-bitswap.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-bitswap/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-bitswap.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-bitswap) | N/A | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-bitswap/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-bitswap) | [Volker Mische](mailto:volker.mische@gmail.com) |
| **libp2p** |
| [`libp2p`](//github.com/libp2p/js-libp2p) | [![npm](https://img.shields.io/npm/v/libp2p.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p) | [Jacob Heun](mailto:jacobheun@gmail.com) |
| [`libp2p-circuit`](//github.com/libp2p/js-libp2p-circuit) | [![npm](https://img.shields.io/npm/v/libp2p-circuit.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-circuit/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-circuit.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-circuit) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-circuit/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-circuit/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-circuit/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-circuit) | [Jacob Heun](mailto:jacobheun@gmail.com) |
| [`libp2p-floodsub`](//github.com/libp2p/js-libp2p-floodsub) | [![npm](https://img.shields.io/npm/v/libp2p-floodsub.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-floodsub/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-floodsub.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-floodsub) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-floodsub/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-floodsub) | N/A |
| [`libp2p-kad-dht`](//github.com/libp2p/js-libp2p-kad-dht) | [![npm](https://img.shields.io/npm/v/libp2p-kad-dht.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-kad-dht/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-kad-dht.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-kad-dht) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-kad-dht/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-kad-dht/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-kad-dht/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-kad-dht) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |
| [`libp2p-mdns`](//github.com/libp2p/js-libp2p-mdns) | [![npm](https://img.shields.io/npm/v/libp2p-mdns.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-mdns/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-mdns.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-mdns) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-mdns/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-mdns/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-mdns/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-mdns) | N/A |
| [`libp2p-mplex`](//github.com/libp2p/js-libp2p-mplex) | [![npm](https://img.shields.io/npm/v/libp2p-mplex.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-mplex/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-mplex.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-mplex) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-mplex/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-mplex) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |
| [`libp2p-railing`](//github.com/libp2p/js-libp2p-railing) | [![npm](https://img.shields.io/npm/v/libp2p-railing.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-railing/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-railing.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-railing) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-railing/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-railing) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |
| [`libp2p-secio`](//github.com/libp2p/js-libp2p-secio) | [![npm](https://img.shields.io/npm/v/libp2p-secio.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-secio/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-secio.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-secio) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-secio/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-secio) | N/A |
| [`libp2p-tcp`](//github.com/libp2p/js-libp2p-tcp) | [![npm](https://img.shields.io/npm/v/libp2p-tcp.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-tcp/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-tcp.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-tcp) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-tcp/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-tcp/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-tcp/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-tcp) | [Jacob Heun](mailto:jacobheun@gmail.com) |
| [`libp2p-webrtc-star`](//github.com/libp2p/js-libp2p-webrtc-star) | [![npm](https://img.shields.io/npm/v/libp2p-webrtc-star.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-webrtc-star/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-webrtc-star.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-webrtc-star) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-webrtc-star/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-webrtc-star/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-webrtc-star/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-webrtc-star) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |
| [`libp2p-websocket-star`](//github.com/libp2p/js-libp2p-websocket-star) | [![npm](https://img.shields.io/npm/v/libp2p-websocket-star.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-websocket-star/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-websocket-star.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-websocket-star) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-websocket-star/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-websocket-star) | [Jacob Heun](mailto:jacobheun@gmail.com) |
| [`libp2p-websockets`](//github.com/libp2p/js-libp2p-websockets) | [![npm](https://img.shields.io/npm/v/libp2p-websockets.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-websockets/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-websockets.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-websockets) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-websockets/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-websockets) | N/A |
| **Data Types** |
| [`ipfs-block`](//github.com/ipfs/js-ipfs-block) | [![npm](https://img.shields.io/npm/v/ipfs-block.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-block/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-block.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-block) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipfs/js-ipfs-block/master)](https://ci.ipfs.team/job/ipfs/job/js-ipfs-block/job/master/) | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-block/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-block) | N/A |
| [`ipfs-unixfs`](//github.com/ipfs/js-ipfs-unixfs) | [![npm](https://img.shields.io/npm/v/ipfs-unixfs.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-unixfs/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-unixfs.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-unixfs) | N/A | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-unixfs/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-unixfs) | [Alex Potsides](mailto:alex.potsides@protocol.ai) |
| [`peer-id`](//github.com/libp2p/js-peer-id) | [![npm](https://img.shields.io/npm/v/peer-id.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-peer-id/releases) | [![Deps](https://david-dm.org/libp2p/js-peer-id.svg?style=flat-square)](https://david-dm.org/libp2p/js-peer-id) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-peer-id/master)](https://ci.ipfs.team/job/libp2p/job/js-peer-id/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-peer-id/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-peer-id) | [Pedro Teixeira](mailto:i@pgte.me) |
| [`peer-info`](//github.com/libp2p/js-peer-info) | [![npm](https://img.shields.io/npm/v/peer-info.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-peer-info/releases) | [![Deps](https://david-dm.org/libp2p/js-peer-info.svg?style=flat-square)](https://david-dm.org/libp2p/js-peer-info) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-peer-info/master)](https://ci.ipfs.team/job/libp2p/job/js-peer-info/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-peer-info/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-peer-info) | N/A |
| [`multiaddr`](//github.com/multiformats/js-multiaddr) | [![npm](https://img.shields.io/npm/v/multiaddr.svg?maxAge=86400&style=flat-square)](//github.com/multiformats/js-multiaddr/releases) | [![Deps](https://david-dm.org/multiformats/js-multiaddr.svg?style=flat-square)](https://david-dm.org/multiformats/js-multiaddr) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=multiformats/js-multiaddr/master)](https://ci.ipfs.team/job/multiformats/job/js-multiaddr/job/master/) | [![codecov](https://codecov.io/gh/multiformats/js-multiaddr/branch/master/graph/badge.svg)](https://codecov.io/gh/multiformats/js-multiaddr) | N/A |
| [`multihashes`](//github.com/multiformats/js-multihash) | [![npm](https://img.shields.io/npm/v/multihashes.svg?maxAge=86400&style=flat-square)](//github.com/multiformats/js-multihash/releases) | [![Deps](https://david-dm.org/multiformats/js-multihash.svg?style=flat-square)](https://david-dm.org/multiformats/js-multihash) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=multiformats/js-multihash/master)](https://ci.ipfs.team/job/multiformats/job/js-multihash/job/master/) | [![codecov](https://codecov.io/gh/multiformats/js-multihash/branch/master/graph/badge.svg)](https://codecov.io/gh/multiformats/js-multihash) | [David Dias](mailto:daviddias@ipfs.io) |
| **Crypto** |
| [`libp2p-crypto`](//github.com/libp2p/js-libp2p-crypto) | [![npm](https://img.shields.io/npm/v/libp2p-crypto.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-crypto/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-crypto.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-crypto) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=libp2p/js-libp2p-crypto/master)](https://ci.ipfs.team/job/libp2p/job/js-libp2p-crypto/job/master/) | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-crypto/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-crypto) | [Friedel Ziegelmayer](mailto:dignifiedquire@gmail.com) |
| [`libp2p-keychain`](//github.com/libp2p/js-libp2p-keychain) | [![npm](https://img.shields.io/npm/v/libp2p-keychain.svg?maxAge=86400&style=flat-square)](//github.com/libp2p/js-libp2p-keychain/releases) | [![Deps](https://david-dm.org/libp2p/js-libp2p-keychain.svg?style=flat-square)](https://david-dm.org/libp2p/js-libp2p-keychain) | N/A | [![codecov](https://codecov.io/gh/libp2p/js-libp2p-keychain/branch/master/graph/badge.svg)](https://codecov.io/gh/libp2p/js-libp2p-keychain) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |
| **Generics/Utils** |
| [`ipfs-http-client`](//github.com/ipfs/js-ipfs-http-client) | [![npm](https://img.shields.io/npm/v/ipfs-http-client.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/js-ipfs-http-client/releases) | [![Deps](https://david-dm.org/ipfs/js-ipfs-http-client.svg?style=flat-square)](https://david-dm.org/ipfs/js-ipfs-http-client) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipfs/js-ipfs-http-client/master)](https://ci.ipfs.team/job/ipfs/job/js-ipfs-http-client/job/master/) | [![codecov](https://codecov.io/gh/ipfs/js-ipfs-http-client/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/js-ipfs-http-client) | [Alan Shaw](mailto:alan@tableflip.io) |
| [`ipfs-multipart`](//github.com/ipfs/ipfs-multipart) | [![npm](https://img.shields.io/npm/v/ipfs-multipart.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/ipfs-multipart/releases) | [![Deps](https://david-dm.org/ipfs/ipfs-multipart.svg?style=flat-square)](https://david-dm.org/ipfs/ipfs-multipart) | N/A | [![codecov](https://codecov.io/gh/ipfs/ipfs-multipart/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/ipfs-multipart) | N/A |
| [`is-ipfs`](//github.com/ipfs/is-ipfs) | [![npm](https://img.shields.io/npm/v/is-ipfs.svg?maxAge=86400&style=flat-square)](//github.com/ipfs/is-ipfs/releases) | [![Deps](https://david-dm.org/ipfs/is-ipfs.svg?style=flat-square)](https://david-dm.org/ipfs/is-ipfs) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=ipfs/is-ipfs/master)](https://ci.ipfs.team/job/ipfs/job/is-ipfs/job/master/) | [![codecov](https://codecov.io/gh/ipfs/is-ipfs/branch/master/graph/badge.svg)](https://codecov.io/gh/ipfs/is-ipfs) | [Marcin Rataj](mailto:lidel@lidel.org) |
| [`multihashing`](//github.com/multiformats/js-multihashing) | [![npm](https://img.shields.io/npm/v/multihashing.svg?maxAge=86400&style=flat-square)](//github.com/multiformats/js-multihashing/releases) | [![Deps](https://david-dm.org/multiformats/js-multihashing.svg?style=flat-square)](https://david-dm.org/multiformats/js-multihashing) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=multiformats/js-multihashing/master)](https://ci.ipfs.team/job/multiformats/job/js-multihashing/job/master/) | [![codecov](https://codecov.io/gh/multiformats/js-multihashing/branch/master/graph/badge.svg)](https://codecov.io/gh/multiformats/js-multihashing) | N/A |
| [`mafmt`](//github.com/multiformats/js-mafmt) | [![npm](https://img.shields.io/npm/v/mafmt.svg?maxAge=86400&style=flat-square)](//github.com/multiformats/js-mafmt/releases) | [![Deps](https://david-dm.org/multiformats/js-mafmt.svg?style=flat-square)](https://david-dm.org/multiformats/js-mafmt) | [![jenkins](https://ci.ipfs.team/buildStatus/icon?job=multiformats/js-mafmt/master)](https://ci.ipfs.team/job/multiformats/job/js-mafmt/job/master/) | [![codecov](https://codecov.io/gh/multiformats/js-mafmt/branch/master/graph/badge.svg)](https://codecov.io/gh/multiformats/js-mafmt) | [Vasco Santos](mailto:vasco.santos@moxy.studio) |

## Development

### Clone and install dependencies

```sh
> git clone https://github.com/ipfs/js-ipfs.git
> cd js-ipfs
> npm install
```

### Run tests

```sh
# run all the unit tests
> npm test

# run just IPFS tests in Node.js
> npm run test:node

# run just IPFS core tests
> npm run test:node:core

# run just IPFS HTTP-API tests
> npm run test:node:http

# run just IPFS CLI tests
> npm run test:node:cli

# run just IPFS core tests in the Browser (Chrome)
> npm run test:browser

# run some interface tests (block API) on Node.js
> npm run test:node:interface -- --grep '.block'
```

### Run interop tests

Run the interop tests with https://github.com/ipfs/interop

### Run benchmark tests

```sh
# run all the benchmark tests
> npm run benchmark

# run just IPFS benchmarks in Node.js
> npm run benchmark:node

# run just IPFS benchmarks in Node.js for an IPFS instance
> npm run benchmark:node:core

# run just IPFS benchmarks in Node.js for an IPFS daemon
> npm run benchmark:node:http

# run just IPFS benchmarks in the browser (Chrome)
> npm run benchmark:browser
```

### Lint

**Conforming to linting rules is a prerequisite to commit to js-ipfs.**

```sh
> npm run lint
```

### Build a dist version

```sh
> npm run build
```

### [Runtime Support](https://github.com/ipfs/js-ipfs/issues/536)

### Code Architecture and folder Structure

![](/img/overview.png)

##### Source code

```Bash
> tree src -L 2
src                 # Main source code folder
├── cli             # Implementation of the IPFS CLI
│   └── ...
├── http            # The HTTP-API implementation of IPFS as defined by http-api-spec
├── core            # IPFS implementation, the core (what gets loaded in browser)
│   ├── components  # Each of IPFS subcomponent
│   └── ...
└── ...
```

### Monitoring

The HTTP API exposed with js-ipfs can also be used for exposing metrics about
the running js-ipfs node and other Node.js metrics.

To enable it, you need to set the environment variable `IPFS_MONITORING` (any value)

Once the environment variable is set and the js-ipfs daemon is running, you can get
the metrics (in prometheus format) by making a GET request to the following endpoint:

```
http://localhost:5002/debug/metrics/prometheus
```

### IPFS Architecture

![](/img/architecture.png)

[Annotated version](https://user-images.githubusercontent.com/1211152/47606420-b6265780-da13-11e8-923b-b365a8534e0e.png)j

What does this image explain?

- IPFS uses `ipfs-repo` which picks `fs` or `indexeddb` as its storage drivers, depending if it is running in Node.js or in the Browser.
- The exchange protocol, `bitswap`, uses the Block Service which in turn uses the Repo, offering a get and put of blocks to the IPFS implementation.
- The DAG API (previously Object) comes from the IPLD Resolver, it can support several IPLD Formats (i.e: dag-pb, dag-cbor, etc).
- The Files API uses `ipfs-unixfs-engine` to import and export files to and from IPFS.
- libp2p, the network stack of IPFS, uses libp2p to dial and listen for connections, to use the DHT, for discovery mechanisms, and more.

## Contribute

IPFS implementation in JavaScript is a work in progress. As such, there's a few things you can do right now to help out:

- Go through the modules below and **check out existing issues**. This would be especially useful for modules in active development. Some knowledge of IPFS may be required, as well as the infrastructure behind it - for instance, you may need to read up on p2p and more complex operations like muxing to be able to help technically.
- **Perform code reviews**. More eyes will help (a) speed the project along, (b) ensure quality, and (c) reduce possible future bugs.
- Take a look at go-ipfs and some of the planning repositories or issues: for instance, the [libp2p spec](https://github.com/ipfs/specs/pull/19). Contributions here that would be most helpful are **top-level comments** about how it should look based on our understanding. Again, the more eyes the better.
- **Add tests**. There can never be enough tests.

### Want to hack on IPFS?

[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)

## License

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fipfs%2Fjs-ipfs.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fipfs%2Fjs-ipfs?ref=badge_large)

'''
'''--- RELEASE.md ---
# Release Template

> short tl;dr; of the release

# 🗺 What's left for release

# 🔦 Highlights

# 🏗 API Changes

# ✅ Release Checklist

- Robustness and quality
  - [ ] Ensure that all tests are passing, this includes:
    - [ ] unit
    - [ ] interop
    - [ ] sharness
  - [ ] Publish a release candidate to npm
      ```sh
      # Minor prerelease (e.g. 0.33.1 -> 0.34.0-rc.0)
      $ npx aegir release --type preminor --preid rc --dist-tag next

      # Increment prerelease (e.g. 0.34.0-rc.0 -> 0.34.0-rc.1)
      $ npx aegir release --type prerelease --preid rc --dist-tag next
      ```
  - [ ] Run tests of the following projects with the new release:
    - [ ] [ipfs-pubsub-room](https://github.com/ipfs-shipyard/ipfs-pubsub-room)
    - [ ] [peer-base](https://github.com/peer-base/peer-base)
    - [ ] [ipfs-log](https://github.com/orbitdb/ipfs-log)
    - [ ] [orbit-db](https://github.com/orbitdb/orbit-db)
    - [ ] [service-worker-gateway](https://github.com/ipfs-shipyard/service-worker-gateway)
  - [ ] Update js.ipfs.io examples and Service Worker Gateway to use latest js-ipfs
- Documentation
  - [ ] Ensure that README.md is up to date
  - [ ] Ensure that all the examples run
- Communication
  - [ ] Create the release issue
  - [ ] Take a snapshot between of everyone that has contributed to this release (including its subdeps in IPFS, libp2p, IPLD and multiformats) using [`name-your-contributors`](https://www.npmjs.com/package/name-your-contributors). Generate a nice markdown list with [this script](https://gist.github.com/alanshaw/5a2d9465c5a05b201d949551bdb1fcc3).
  - [ ] Announcements (both pre-release and post-release)
    - [ ] Twitter
    - [ ] IRC
    - [ ] Reddit
    - [ ] [discuss.ipfs.io](https://discuss.ipfs.io/c/announcements)
    - [ ] Announce it on the [IPFS Users mlist](https://groups.google.com/forum/#!forum/ipfs-users)
  - [ ] Blog post
  - [ ] Copy release notes to the [GitHub Release description](https://github.com/ipfs/js-ipfs/releases)

# ❤️ Huge thank you to everyone that made this release possible

In alphabetical order, here are all the humans that contributed to the release:

- ...

# 🙌🏽 Want to contribute?

Would you like to contribute to the IPFS project and don't know how? Well, there are a few places you can get started:

- Check the issues with the `help wanted` label at the Ready column in our waffle board - https://waffle.io/ipfs/js-ipfs?label=help%20wanted
- Join an IPFS All Hands, introduce yourself and let us know where you would like to contribute - https://github.com/ipfs/team-mgmt/#weekly-ipfs-all-hands
- Hack with IPFS and show us what you made! The All Hands call is also the perfect venue for demos, join in and show us what you built
- Join the discussion at http://discuss.ipfs.io/ and help users finding their answers.
- Join the [⚡️ⒿⓈ Core Dev Team Weekly Sync 🙌🏽](https://github.com/ipfs/team-mgmt/issues/650) and be part of the Sprint action!

# ⁉️ Do you have questions?

The best place to ask your questions about IPFS, how it works and what you can do with it is at [discuss.ipfs.io](http://discuss.ipfs.io). We are also available at the `#ipfs` channel on Freenode.

'''
'''--- examples/README.md ---
# `js-ipfs` Examples and Tutorials

In this folder, you can find a variety of examples to help you get started in using js-ipfs, in Node.js and in the Browser. Every example has a specific purpose and some of each incorporate a full tutorial that you can follow through, helping you expand your knowledge about IPFS and the Distributed Web in General.

Let us know if you find any issue or if you want to contribute and add a new tutorial, feel welcome to submit a PR, thank you!

## Tutorials

- [Tutorial: IPFS 101, spawn a node and add a file to IPFS](./ipfs-101)
- [Tutorial: Build a tiny browser app to exchange files between nodes](./exchange-files-in-browser)
- [Tutorial: Interact with IPFS directly from your Terminal](./ipfs-cli-fun)
- [Tutorial: Resolve through IPLD graphs with the dag API](./traverse-ipld-graphs)
- [Tutorial: Use IPFS to explore the Ethereum BlockChain](./explore-ethereum-blockchain)
- [Tutorial (Video): How to build an application with IPFS PubSub Room](https://www.youtube.com/watch?v=Nv_Teb--1zg)
- [Tutorial (Video): How to build an Collaborative Editing Application with IPFS using CRDT](https://www.youtube.com/watch?v=-kdx8rJd8rQ)
- [Tutorial - Understanding Circuit Relay](./circuit-relaying)

## Examples

- [js-ipfs in the browser with Browserify](./browser-browserify)
- [js-ipfs in the browser with Parcel.js](./browser-parceljs)
- [js-ipfs in the browser with WebPack](./browser-webpack)
- [js-ipfs in the browser with a `<script>` tag](./browser-script-tag)
- [js-ipfs in electron](./run-in-electron)
- [Using streams to add a directory of files to ipfs](./browser-add-readable-stream)
- [Customizing the ipfs repository](./custom-ipfs-repo)
- [Customizing your libp2p bundle](./custom-libp2p)
- [Streaming video from ipfs to the browser using `ReadableStream`s](./browser-readablestream)
- [The Mutable File System in the browser](./browser-mfs)

## Understanding the IPFS Stack

In this section, you will find explanations to different pieces of IPFS Architecture and how `js-ipfs` implements them.

![](../img/architecture.png)

[Annotated version](https://user-images.githubusercontent.com/1211152/47606420-b6265780-da13-11e8-923b-b365a8534e0e.png)

> These explanations are still a work in progress

- Storing and Retrieving blocks (soon™)
- IPLD (InterPlanetary Linked-Data) (soon™)
- IPFS Networking - Managing your swarm, libp2p and more (soon™)

'''
'''--- examples/browser-add-readable-stream/README.md ---
# Using duplex streams to add files to IPFS in the browser

If you have a number of files that you'd like to add to IPFS and end up with a hash representing the directory containing your files, you can invoke [`ipfs.add`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#add) with an array of objects.

But what if you don't know how many there will be in advance?  You can add multiple files to a directory in IPFS over time by using [`ipfs.addReadableStream`](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md#addreadablestream).

See `index.js` for a working example and open `index.html` in your browser to see it run.

'''
'''--- examples/browser-add-readable-stream/index.html ---
<html>
  <body>
    <pre id="output"></pre>
    <script src="https://unpkg.com/ipfs/dist/index.js"></script>
    <script src="index.js"></script>
  </body>
</html>

'''
'''--- examples/browser-add-readable-stream/index.js ---
'use strict'

/* global Ipfs */
/* eslint-env browser */

const repoPath = `ipfs-${Math.random()}`
const ipfs = new Ipfs({ repo: repoPath })

ipfs.on('ready', () => {
  const directory = 'directory'

  // Our list of files
  const files = createFiles(directory)

  streamFiles(directory, files, (err, directoryHash) => {
    if (err) {
      return log(`There was an error adding the files ${err}`)
    }

    ipfs.ls(directoryHash, (err, files) => {
      if (err) {
        return log(`There was an error listing the files ${err}`)
      }

      log(`
--

Directory contents:

${directory}/ ${directoryHash}`)

      files.forEach((file, index) => {
        log(` ${index < files.length - 1 ? '\u251C' : '\u2514'}\u2500 ${file.name} ${file.path} ${file.hash}`)
      })
    })
  })
})

const createFiles = (directory) => {
  return [{
    path: `${directory}/file1.txt`,

    // content could be a stream, a url etc
    content: ipfs.types.Buffer.from('one', 'utf8')
  }, {
    path: `${directory}/file2.txt`,
    content: ipfs.types.Buffer.from('two', 'utf8')
  }, {
    path: `${directory}/file3.txt`,
    content: ipfs.types.Buffer.from('three', 'utf8')
  }]
}

const streamFiles = (directory, files, cb) => {
  // Create a stream to write files to
  const stream = ipfs.addReadableStream()
  stream.on('data', function (data) {
    log(`Added ${data.path} hash: ${data.hash}`)

    // The last data event will contain the directory hash
    if (data.path === directory) {
      cb(null, data.hash)
    }
  })

  // Add the files one by one
  files.forEach(file => stream.write(file))

  // When we have no more files to add, close the stream
  stream.end()
}

const log = (line) => {
  document.getElementById('output').appendChild(document.createTextNode(`${line}\r\n`))
}

'''
'''--- examples/browser-browserify/README.md ---
# Bundle js-ipfs with Browserify!

> In this example, you will find a boilerplate you can use to guide yourself into bundling js-ipfs with browserify, so that you can use it in your own web app!

## Run this example

```bash
> npm install
> npm start
```

Now open your browser at `http://localhost:8888`

You should see the following:

![](https://ipfs.io/ipfs/QmNtpcWCEd6LjdPNfBFDaVZdD4jpgT8ZTAwoFJXKhYMJdo/1.png)
![](https://ipfs.io/ipfs/QmNtpcWCEd6LjdPNfBFDaVZdD4jpgT8ZTAwoFJXKhYMJdo/2.png)

'''
'''--- examples/browser-browserify/package.json ---
{
  "name": "bundle-browserify",
  "version": "1.0.0",
  "description": "Bundle js-ipfs with Browserify",
  "main": "index.js",
  "scripts": {
    "bundle": "browserify src/index.js > public/bundle.js",
    "serve": "http-server public -a 127.0.0.1 -p 8888",
    "start": "npm run bundle && npm run serve"
  },
  "keywords": [],
  "license": "MIT",
  "devDependencies": {
    "ipfs": "file:../../",
    "browserify": "^14.0.0",
    "concat-stream": "^1.6.0",
    "http-server": "~0.9.0"
  },
  "dependencies": {}
}

'''
'''--- examples/browser-browserify/public/index.html ---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8"/>
    <title>js-ipfs example</title>
    <script src="bundle.js"></script>
    <style>
      .content {
        border: 1px solid black;
        padding: 10px;
        margin: 5px 0;
      }
    </style>
  </head>
  <body>
    <h1>JS IPFS - Add data to IPFS from the browser</h1>
    <textarea id="source"></textarea>
    <button id="store">add to ipfs</button>
    <div>
      <div>found in ipfs:</div>
      <div class="content" id="hash">[ipfs hash]</div>
      <div class="content" id="content">[ipfs content]</div>
    </div>
  </body>
</html>

'''
'''--- examples/browser-browserify/src/index.js ---
'use strict'

const IPFS = require('ipfs')

const node = new IPFS({ repo: String(Math.random() + Date.now()) })

node.once('ready', () => console.log('IPFS node is ready'))

function store () {
  const toStore = document.getElementById('source').value

  node.add(Buffer.from(toStore), (err, res) => {
    if (err || !res) {
      return console.error('ipfs add error', err, res)
    }

    res.forEach((file) => {
      if (file && file.hash) {
        console.log('successfully stored', file.hash)
        display(file.hash)
      }
    })
  })
}

function display (hash) {
  // buffer: true results in the returned result being a buffer rather than a stream
  node.cat(hash, (err, data) => {
    if (err) { return console.error('ipfs cat error', err) }

    document.getElementById('hash').innerText = hash
    document.getElementById('content').innerText = data
  })
}

document.addEventListener('DOMContentLoaded', () => {
  document.getElementById('store').onclick = store
})

'''
'''--- examples/browser-create-react-app/.env ---
# required because react-scripts scans *up* the tree from this project and finds
# a conflicting version of eslint in the node_modules dir for js-ipfs.
SKIP_PREFLIGHT_CHECK=true

'''
'''--- examples/browser-create-react-app/README.md ---
## IPFS React app

A minimal demonstration of how to use js-ipfs in a `create-react-app` generated app.

It boots up a js-ipfs instance via a custom React hook in `./src/hooks/use-ipfs-factory.js`, which is called from `./src/App.js`, which is where the magic happens.

![Screen shot of the js ipfs node id info](./screenshot.png)

This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app). **v2.1.3**

## Available Scripts

In the project directory, you can run:

### `npm start`

Runs the app in the development mode.<br>
Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

The page will reload if you make edits.<br>
You will also see any lint errors in the console.

### `npm test`

Launches the test runner in the interactive watch mode.<br>
See the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.

### `npm run build`

Builds the app for production to the `build` folder.<br>
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.<br>
Your app is ready to be deployed!

See the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.

### `npm run eject`

**Note: this is a one-way operation. Once you `eject`, you can’t go back!**

If you aren’t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.

Instead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.

You don’t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.

## Learn More

You can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).

To learn React, check out the [React documentation](https://reactjs.org/).

### Code Splitting

This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting

### Analyzing the Bundle Size

This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size

### Making a Progressive Web App

This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app

### Advanced Configuration

This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration

### Deployment

This section has moved here: https://facebook.github.io/create-react-app/docs/deployment

### `npm run build` fails to minify

This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify

'''
'''--- examples/browser-create-react-app/package.json ---
{
  "name": "ipfs-react-demo",
  "version": "0.1.0",
  "private": true,
  "dependencies": {
    "dot-prop": "^4.2.0",
    "ipfs": "file:../../",
    "ipfs-css": "^0.12.0",
    "react": "^16.8.0",
    "react-dom": "^16.8.0",
    "react-scripts": "2.1.3",
    "tachyons": "^4.11.1"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": "react-app"
  },
  "browserslist": [
    ">0.2%",
    "not dead",
    "not ie <= 11",
    "not op_mini all"
  ]
}

'''
'''--- examples/browser-create-react-app/public/index.html ---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="shortcut icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="theme-color" content="#000000" />
    <!--
      manifest.json provides metadata used when your web app is added to the
      homescreen on Android. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>IPFS React App</title>
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"></div>
    <!--
      This HTML file is a template.
      If you open it directly in the browser, you will see an empty page.

      You can add webfonts, meta tags, or analytics to this file.
      The build step will place the bundled scripts into the <body> tag.

      To begin the development, run `npm start` or `yarn start`.
      To create a production bundle, use `npm run build` or `yarn build`.
    -->
  </body>
</html>

'''
'''--- examples/browser-create-react-app/public/manifest.json ---
{
  "short_name": "React App",
  "name": "Create React App Sample",
  "icons": [
    {
      "src": "favicon.ico",
      "sizes": "64x64 32x32 24x24 16x16",
      "type": "image/x-icon"
    }
  ],
  "start_url": ".",
  "display": "standalone",
  "theme_color": "#000000",
  "background_color": "#ffffff"
}

'''
'''--- examples/browser-create-react-app/src/App.js ---
import React from 'react'
import useIpfsFactory from './hooks/use-ipfs-factory.js'
import useIpfs from './hooks/use-ipfs.js'
import logo from './ipfs-logo.svg'

const App = () => {
  const { ipfs, ipfsInitError } = useIpfsFactory({commands: ['id']})
  const id = useIpfs(ipfs, 'id')
  return (
    <div className='sans-serif'>
      <header className="flex items-center pa3 bg-navy bb bw3 b--aqua">
        <a href="https://ipfs.io" title="home">
          <img alt="IPFS logo" src={logo} style={{ height: 50 }} className='v-top' />
        </a>
        <h1 className="flex-auto ma0 tr f3 fw2 montserrat aqua">IPFS React</h1>
      </header>
      <main>
        {ipfsInitError && (
          <div className='bg-yellow pa4 mw7 center mv4 white'>
            Error: {ipfsInitError.message || ipfsInitError}
          </div>
        )}
        {id && <IpfsId {...id} />}
      </main>
    </div>
  )
}

const Title = ({children}) => {
  return (
    <h2 className="f5 ma0 pb2 tracked aqua fw4 montserrat">{children}</h2>
  )
}

const IpfsId = (props) => {
  if  (!props) return null
  return (
    <section className='bg-snow mw7 center mt5'>
      <h1 className='f3 fw4 ma0 pv3 aqua montserrat tc'>Connected to IPFS</h1>
      <div className='pa4'>
        {['id', 'agentVersion'].map((key) => (
          <div className="mb4" key={key}>
            <Title>{key}</Title>
            <div className='bg-white pa2 br2 truncate monospace'>{props[key]}</div>
          </div>
        ))}
      </div>
    </section>
  )
}

export default App

'''
'''--- examples/browser-create-react-app/src/App.test.js ---
import React from 'react'
import ReactDOM from 'react-dom'
import App from './App'

it('renders without crashing', () => {
  const div = document.createElement('div')
  ReactDOM.render(<App />, div)
  ReactDOM.unmountComponentAtNode(div)
});

'''
'''--- examples/browser-create-react-app/src/hooks/use-ipfs-factory.js ---
import Ipfs from 'ipfs'
import { useEffect, useState } from 'react'

let ipfs = null

/*
 * A quick demo using React hooks to create an ipfs instance.
 *
 * Hooks are brand new at the time of writing, and this pattern
 * is intended to show it is possible. I don't know if it is wise.
 *
 * Next steps would be to store the ipfs instance on the context
 * so use-ipfs calls can grab it from there rather than expecting
 * it to be passed in.
 */
export default function useIpfsFactory ({commands}) {
  const [isIpfsReady, setIpfsReady] = useState(!!ipfs)
  const [ipfsInitError, setIpfsInitError] = useState(null)

  useEffect(() => {
    // The fn to useEffect should not return anything other than a cleanup fn,
    // So it cannot be marked async, which causes it to return a promise,
    // Hence we delegate to a async fn rather than making the param an async fn.
    startIpfs()
    return function cleanup () {
      if (ipfs && ipfs.stop) {
        console.log('Stopping IPFS')
        ipfs.stop()
        setIpfsReady(false)
      }
    }
  }, [])

  async function startIpfs () {
    if (ipfs) {
      console.log('IPFS already started')

    } else if (window.ipfs && window.ipfs.enable) {
      console.log('Found window.ipfs')
      ipfs = await window.ipfs.enable({commands})

    } else {
      try {
        console.time('IPFS Started')
        ipfs = await promiseMeJsIpfs(Ipfs, {})
        console.timeEnd('IPFS Started')
      } catch (error) {
        console.error('IPFS init error:', error)
        ipfs = null
        setIpfsInitError(error)
      }
    }

    setIpfsReady(!!ipfs)
  }

  return {ipfs, isIpfsReady, ipfsInitError}
}

function promiseMeJsIpfs (Ipfs, opts) {
  return new Promise((resolve, reject) => {
    const ipfs = new Ipfs(opts)
    ipfs.once('ready', () => resolve(ipfs))
    ipfs.once('error', err => reject(err))
  })
}

'''
'''--- examples/browser-create-react-app/src/hooks/use-ipfs.js ---
import { useState, useEffect } from 'react'
import dotProp from 'dot-prop'

/*
 * Pass the command you'd like to call on an ipfs instance.
 *
 * Uses setState to capture the response, so your component
 * will re-render when the result turns up.
 *
 */
export default function useIpfs (ipfs, cmd, opts) {
  const [res, setRes] = useState(null)
  useEffect(() => {
    callIpfs(ipfs, cmd, opts, setRes)
  }, [ipfs, cmd, opts])
  return res
}

async function callIpfs (ipfs, cmd, opts, setRes) {
  if (!ipfs) return null
  console.log(`Call ipfs.${cmd}`)
  const ipfsCmd = dotProp.get(ipfs, cmd)
  const res = await ipfsCmd(opts)
  console.log(`Result ipfs.${cmd}`, res)
  setRes(res)
}

'''
'''--- examples/browser-create-react-app/src/index.css ---
@import "../node_modules/tachyons";
@import "../node_modules/ipfs-css";

'''
'''--- examples/browser-create-react-app/src/index.js ---
import React from 'react'
import ReactDOM from 'react-dom'
import './index.css'
import App from './App'

ReactDOM.render(<App />, document.getElementById('root'))

'''
'''--- examples/browser-create-react-app/src/ipfs-logo.svg ---
<svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 553 235.3"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#469ea2}.cls-3{fill:#6acad1}.cls-4,.cls-5{fill:#083b54}.cls-4{fill-opacity:.15}.cls-5{fill-opacity:.05}</style></defs><title>IPFS logo (new)</title><path class="cls-1" d="M239 63h17.8v105H239V63zm35.6 0h36.3c7.9 0 14.5.9 19.6 2.6s9.2 4.1 12.1 7.1a24.45 24.45 0 0 1 6.2 10.2 40.75 40.75 0 0 1 1.8 12.1 45.69 45.69 0 0 1-1.8 12.9 26.58 26.58 0 0 1-6.2 10.8 30.59 30.59 0 0 1-12.1 7.3c-5.1 1.8-11.5 2.7-19.3 2.7h-19.1V168h-17.5V63zm36.2 51a38.37 38.37 0 0 0 11.1-1.3 16.3 16.3 0 0 0 6.8-3.7 13.34 13.34 0 0 0 3.5-5.8 29.75 29.75 0 0 0 1-7.6 25.68 25.68 0 0 0-1-7.7 12 12 0 0 0-3.6-5.5 17.15 17.15 0 0 0-6.9-3.4 41.58 41.58 0 0 0-10.9-1.2h-18.5V114h18.5zm119.9-51v15.3h-49.2V108h46.3v15.4h-46.3V168h-17.8V63h67zm26.2 72.9c.8 6.9 3.3 11.9 7.4 15s10.4 4.7 18.6 4.7a32.61 32.61 0 0 0 10.1-1.3 20.52 20.52 0 0 0 6.6-3.5 12 12 0 0 0 3.5-5.2 19.08 19.08 0 0 0 1-6.4 16.14 16.14 0 0 0-.7-4.9 12.87 12.87 0 0 0-2.6-4.5 16.59 16.59 0 0 0-5.1-3.6 35 35 0 0 0-8.2-2.4l-13.4-2.5a89.76 89.76 0 0 1-14.1-3.7 33.51 33.51 0 0 1-10.4-5.8 22.28 22.28 0 0 1-6.3-8.8 34.1 34.1 0 0 1-2.1-12.7 26 26 0 0 1 11.3-22.4 36.35 36.35 0 0 1 12.6-5.6 65.89 65.89 0 0 1 15.8-1.8c7.2 0 13.3.8 18.2 2.5a34.46 34.46 0 0 1 11.9 6.5 28.21 28.21 0 0 1 6.9 9.3 42.1 42.1 0 0 1 3.2 11l-16.8 2.6c-1.4-5.9-3.7-10.2-7.1-13.1s-8.7-4.3-16.1-4.3a43.9 43.9 0 0 0-10.5 1.1 19.47 19.47 0 0 0-6.8 3.1 11.63 11.63 0 0 0-3.7 4.6 14.08 14.08 0 0 0-1.1 5.4c0 4.6 1.2 8 3.7 10.3s6.9 4 13.2 5.3l14.5 2.8c11.1 2.1 19.2 5.6 24.4 10.5s7.8 12.1 7.8 21.4a31.37 31.37 0 0 1-2.4 12.3 25.27 25.27 0 0 1-7.4 9.8 36.58 36.58 0 0 1-12.4 6.6 56 56 0 0 1-17.3 2.4c-13.4 0-24-2.8-31.6-8.5s-11.9-14.4-12.6-26.2h18z"/><path class="cls-2" d="M30.3 164l84 48.5 84-48.5V67l-84-48.5-84 48.5v97z"/><path class="cls-3" d="M105.7 30.1l-61 35.2a18.19 18.19 0 0 1 0 3.3l60.9 35.2a14.55 14.55 0 0 1 17.3 0l60.9-35.2a18.19 18.19 0 0 1 0-3.3L123 30.1a14.55 14.55 0 0 1-17.3 0zm84 48.2l-61 35.6a14.73 14.73 0 0 1-8.6 15l.1 70a15.57 15.57 0 0 1 2.8 1.6l60.9-35.2a14.73 14.73 0 0 1 8.6-15V79.9a20 20 0 0 1-2.8-1.6zm-150.8.4a15.57 15.57 0 0 1-2.8 1.6v70.4a14.38 14.38 0 0 1 8.6 15l60.9 35.2a15.57 15.57 0 0 1 2.8-1.6v-70.4a14.38 14.38 0 0 1-8.6-15L38.9 78.7z"/><path class="cls-2" d="M114.3 29l75.1 43.4v86.7l-75.1 43.4-75.1-43.4V72.3L114.3 29m0-10.3l-84 48.5v97l84 48.5 84-48.5v-97l-84-48.5z"/><path class="cls-2" d="M114.9 132h-1.2A15.66 15.66 0 0 1 98 116.3v-1.2a15.66 15.66 0 0 1 15.7-15.7h1.2a15.66 15.66 0 0 1 15.7 15.7v1.2a15.66 15.66 0 0 1-15.7 15.7zm0 64.5h-1.2a15.65 15.65 0 0 0-13.7 8l14.3 8.2 14.3-8.2a15.65 15.65 0 0 0-13.7-8zm83.5-48.5h-.6a15.66 15.66 0 0 0-15.7 15.7v1.2a15.13 15.13 0 0 0 2 7.6l14.3-8.3V148zm-14.3-89a15.4 15.4 0 0 0-2 7.6v1.2a15.66 15.66 0 0 0 15.7 15.7h.6V67.2L184.1 59zm-69.8-40.3L100 26.9a15.73 15.73 0 0 0 13.7 8.1h1.2a15.65 15.65 0 0 0 13.7-8l-14.3-8.3zM44.6 58.9l-14.3 8.3v16.3h.6a15.66 15.66 0 0 0 15.7-15.7v-1.2a16.63 16.63 0 0 0-2-7.7zM30.9 148h-.6v16.2l14.3 8.3a15.4 15.4 0 0 0 2-7.6v-1.2A15.66 15.66 0 0 0 30.9 148z"/><path class="cls-4" d="M114.3 213.2v-97.1l-84-48.5v97.1z"/><path class="cls-5" d="M198.4 163.8v-97l-84 48.5v97.1z"/></svg>
'''
'''--- examples/browser-mfs/README.md ---
# Mutable File System examples

The MFS is a file system abstraction built on top of IPFS.  It supports all the operations you would expect such as creating directories, adding files to them, renaming, coping, deleting, etc.

## Running the demo

In this directory:

```
$ npm install
$ npm start
```

Then open [http://localhost:8888](http://localhost:8888) in your browser.

'''
'''--- examples/browser-mfs/filetree.js ---
'use strict'

const {
  log,
  createNode
} = require('./utils')

const FILE_TYPES = {
  FILE: 0,
  DIRECTORY: 1
}

let selected = {}

const getSelected = () => {
  return Object.values(selected)
}

const loadFiles = async (ipfs, path) => {
  const output = {}
  path = path.replace(/\/\/+/g, '/')

  const contents = await ipfs.files.ls(path, {
    long: true
  })
    .catch(error => log(error))

  for (let i = 0; i < contents.length; i++) {
    let entry = contents[i]
    output[entry.name] = entry

    if (entry.type === FILE_TYPES.DIRECTORY) {
      entry.contents = await loadFiles(ipfs, `${path}/${entry.name}`)
    }
  }

  return output
}

const listFiles = (parent, files, prefix) => {
  const fileNames = Object.keys(files)

  fileNames.forEach((name, index) => {
    const file = files[name]
    const lastFile = index === fileNames.length - 1
    const listIcon = lastFile ? '└── ' : '├── '
    const listing = `${prefix}${listIcon}${name}`

    if (file.type === FILE_TYPES.DIRECTORY) {
      parent.appendChild(createNode('pre', `${listing}/`))
      let descender = '|'
      let directoryPrefix = `${prefix}${descender}   `

      if (lastFile) {
        directoryPrefix = `${prefix}    `
      }

      listFiles(parent, file.contents, directoryPrefix)
    } else {
      parent.appendChild(createNode('pre', listing))
    }
  })
}

const updateTree = async (ipfs) => {
  const files = await loadFiles(ipfs, '/')
  const container = document.querySelector('#files')

  while (container.firstChild) {
    container.removeChild(container.firstChild)
  }

  container.appendChild(createNode('pre', '/'))

  listFiles(container, files, '')
}

module.exports = {
  getSelected,
  updateTree
}

'''
'''--- examples/browser-mfs/forms.js ---
'use strict'

const modalScreen = document.getElementById('modal-screen')

modalScreen.onclick = (event) => {
  if (event.target === modalScreen) {
    hideForms()
  }
}

const forms = {
  mkdir: document.getElementById('form-mkdir'),
  mv: document.getElementById('form-mv'),
  cp: document.getElementById('form-cp'),
  rm: document.getElementById('form-rm'),
  stat: document.getElementById('form-stat'),
  read: document.getElementById('form-read')
}

const getValue = (id) => {
  const element = document.getElementById(id)

  if (element.type === 'checkbox') {
    return Boolean(element.checked)
  }

  if (element.type === 'number') {
    const result = parseInt(element.value.trim())

    return isNaN(result) ? undefined : result
  }

  return element.value.trim()
}

const hideForms = () => {
  modalScreen.style.display = 'none'

  Object.values(forms)
    .forEach(form => {
      form.style.display = 'none'
    })
}

const showForm = (form) => {
  return (event) => {
    event.preventDefault()

    modalScreen.style.display = 'block'
    form.style.display = 'block'
  }
}

const mkdirForm = (onMkdir) => {
  const button = document.getElementById('button-mkdir')
  const submit = document.getElementById('button-form-mkdir-submit')

  button.onclick = showForm(forms.mkdir)
  submit.onclick = () => {
    hideForms()

    onMkdir(
      getValue('form-mkdir-path'),
      getValue('form-mkdir-parents'),
      getValue('form-mkdir-format'),
      getValue('form-mkdir-hashalg'),
      getValue('form-mkdir-flush')
    )
  }

  button.disabled = false
}

const mvForm = (onMv) => {
  const button = document.getElementById('button-mv')
  const submit = document.getElementById('button-form-mv-submit')

  button.onclick = showForm(forms.mv)
  submit.onclick = () => {
    hideForms()

    onMv(
      [getValue('form-mv-path')],
      getValue('form-mv-dest'),
      getValue('form-mv-parents'),
      getValue('form-mv-format'),
      getValue('form-mv-hashalg'),
      getValue('form-mv-flush')
    )
  }

  button.disabled = false
}

const cpForm = (onCp) => {
  const button = document.getElementById('button-cp')
  const submit = document.getElementById('button-form-cp-submit')

  button.onclick = showForm(forms.cp)
  submit.onclick = () => {
    hideForms()

    onCp(
      [getValue('form-cp-path')],
      getValue('form-cp-dest'),
      getValue('form-cp-parents'),
      getValue('form-cp-format'),
      getValue('form-cp-hashalg'),
      getValue('form-cp-flush')
    )
  }

  button.disabled = false
}

const rmForm = (onRm) => {
  const button = document.getElementById('button-rm')
  const submit = document.getElementById('button-form-rm-submit')

  button.onclick = showForm(forms.rm)
  submit.onclick = () => {
    hideForms()

    onRm(
      [getValue('form-rm-path')],
      getValue('form-rm-recursive')
    )
  }

  button.disabled = false
}

const statForm = (onStat) => {
  const button = document.getElementById('button-stat')
  const submit = document.getElementById('button-form-stat-submit')

  button.onclick = showForm(forms.stat)
  submit.onclick = () => {
    hideForms()

    onStat(
      getValue('form-stat-path'),
      getValue('form-stat-hash'),
      getValue('form-stat-size'),
      getValue('form-stat-withlocal')
    )
  }

  button.disabled = false
}

const readForm = (onRead) => {
  const button = document.getElementById('button-read')
  const submit = document.getElementById('button-form-read-submit')

  button.onclick = showForm(forms.read)
  submit.onclick = () => {
    hideForms()

    onRead(
      getValue('form-read-path'),
      getValue('form-read-offset'),
      getValue('form-read-length')
    )
  }

  button.disabled = false
}

module.exports = {
  mkdirForm,
  mvForm,
  rmForm,
  cpForm,
  statForm,
  readForm,
  hideForms
}

'''
'''--- examples/browser-mfs/index.html ---
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8"/>
    <title><%= htmlWebpackPlugin.options.title %></title>
    <style type="text/css">

body {
  margin: 0;
  padding: 0;
}

button {
  font-size: 1.5em;
  padding: 5px 10px;
}

#container {
  height: calc(100vh - 60px);
  padding: 20px;
  border: 10px transparent;
}

#container.drag-over {
  border: 10px dashed green;
}

#buttons {
  height: 50px;
}

#display {
  display: flex;
  height: calc(100vh - 90px);
}

#log {
  flex-grow: 2;
  padding: 10px;
  height: calc(100vh - 120px);
  overflow: auto;
}

#log p {
  font-family: "Lucida Console", Monaco, monospace;
  margin: 0;
  white-space: pre;
  line-height: 1.4;
}

#log p.error {
  color: red;
}

#log p.output {
  color: green;
}

#files {
  width: 50vw;
}

#files pre {
  margin: 0;
  line-height: 1.4;
}

#modal-screen {
  position: absolute;
  height: 100vh;
  width: 100vw;
  background-color: rgba(0, 0, 0, 0.4);
  top: 0;
  left: 0;
}

.modal {
  -webkit-box-shadow: 0px 0px 92px -3px rgba(0, 0, 0, 0.4);
  -moz-box-shadow: 0px 0px 92px -3px rgba(0, 0, 0, 0.4);
  box-shadow: 0px 0px 92px -3px rgba(0, 0, 0, 0.4);
  background-color: white;

  position: absolute;
  top: 50px;
  width: 500px;
  margin-left: 50%;
  left: -250px;
  padding: 20px;
  display: none;
}

.modal h2 {
  margin-top: 10px;
}

.modal input {
  font-size: 1.5em;
  padding: 5px 10px;
}

.modal label, .modal input, .modal checkbox, .modal button {
  display: block;
  margin: 10px 0;
}
    </style>
  </head>
  <body>
    <div id="container" ondrop="dropHandler(event)" ondragover="dragOverHandler(event)">
      <div id="buttons">
        <button id="button-cp" disabled>cp</button>
        <button id="button-mkdir" disabled>mkdir</button>
        <button id="button-mv" disabled>mv</button>
        <button id="button-read" disabled>read</button>
        <button id="button-rm" disabled>rm</button>
        <button id="button-stat" disabled>stat</button>
      </div>
      <div id="display">
        <div id="files"></div>
        <div id="log"></div>
      </div>
    </div>

    <div id="modal-screen"></div>

    <div id="form-mkdir" class="modal">
      <h2>mkdir</h2>

      <label for="form-mkdir-path">path:</label>
      <input type="text" id="form-mkdir-path" value="/" />

      <label for="form-mkdir-parents">format:</label>
      <input type="text" id="form-mkdir-format" value="dag-pb" />

      <label for="form-mkdir-parents">hashAlg:</label>
      <input type="text" id="form-mkdir-hashalg" value="sha2-256" />

      <label for="form-mkdir-parents">parents:</label>
      <input type="checkbox" id="form-mkdir-parents" checked />

      <label for="form-mkdir-parents">flush:</label>
      <input type="checkbox" id="form-mkdir-flush" checked />

      <button id="button-form-mkdir-submit">Go!</button>
    </div>

    <div id="form-cp" class="modal">
      <h2>cp</h2>

      <label for="form-cp-path">path:</label>
      <input type="text" id="form-cp-path" value="/" />

      <label for="form-cp-dest">destination:</label>
      <input type="text" id="form-cp-dest" value="/" />

      <label for="form-cp-parents">format:</label>
      <input type="text" id="form-cp-format" value="dag-pb" />

      <label for="form-cp-parents">hashAlg:</label>
      <input type="text" id="form-cp-hashalg" value="sha2-256" />

      <label for="form-cp-parents">parents:</label>
      <input type="checkbox" id="form-cp-parents" checked />

      <label for="form-cp-parents">flush:</label>
      <input type="checkbox" id="form-cp-flush" checked />

      <button id="button-form-cp-submit">Go!</button>
    </div>

    <div id="form-mv" class="modal">
      <h2>mv</h2>

      <label for="form-mv-path">path:</label>
      <input type="text" id="form-mv-path" value="/" />

      <label for="form-mv-dest">destination:</label>
      <input type="text" id="form-mv-dest" value="/" />

      <label for="form-mv-parents">format:</label>
      <input type="text" id="form-mv-format" value="dag-pb" />

      <label for="form-mv-parents">hashAlg:</label>
      <input type="text" id="form-mv-hashalg" value="sha2-256" />

      <label for="form-mv-parents">parents:</label>
      <input type="checkbox" id="form-mv-parents" checked />

      <label for="form-mv-parents">flush:</label>
      <input type="checkbox" id="form-mv-flush" checked />

      <button id="button-form-mv-submit">Go!</button>
    </div>

    <div id="form-rm" class="modal">
      <h2>rm</h2>

      <label for="form-rm-path">path:</label>
      <input type="text" id="form-rm-path" value="/" />

      <label for="form-mkdir-recursive">recursive:</label>
      <input type="checkbox" id="form-rm-recursive" checked />

      <button id="button-form-rm-submit">Go!</button>
    </div>

    <div id="form-stat" class="modal">
      <h2>stat</h2>

      <label for="form-stat-path">path:</label>
      <input type="text" id="form-stat-path" value="/" />

      <label for="form-stat-hash">hash:</label>
      <input type="checkbox" id="form-stat-hash" />

      <label for="form-stat-size">size:</label>
      <input type="checkbox" id="form-stat-size" />

      <label for="form-stat-withlocal">withLocal:</label>
      <input type="checkbox" id="form-stat-withlocal" checked />

      <button id="button-form-stat-submit">Go!</button>
    </div>

    <div id="form-read" class="modal">
      <h2>read</h2>

      <label for="form-read-path">path:</label>
      <input type="text" id="form-read-path" value="/" />

      <label for="form-read-offset">offset:</label>
      <input type="number" id="form-read-offset" value="" />

      <label for="form-read-length">length:</label>
      <input type="number" id="form-read-length" value="" />

      <button id="button-form-read-submit">Go!</button>
    </div>
  </body>
</html>

'''
'''--- examples/browser-mfs/index.js ---
'use strict'

/* eslint-env browser */

const IPFS = require('ipfs')
const ipfs = new IPFS({
  repo: `ipfs-${Math.random()}`
})
const {
  dragDrop,
  log,
  bufferToArrayBuffer
} = require('./utils')
const {
  updateTree
} = require('./filetree')
const {
  mvForm,
  mkdirForm,
  rmForm,
  cpForm,
  statForm,
  readForm,
  hideForms
} = require('./forms')
const mime = require('mime-sniffer')

hideForms()

log('IPFS: Initialising')

ipfs.on('ready', () => {
  // Allow adding files to IPFS via drag and drop
  dragDrop(async (files) => {
    /* eslint-disable-next-line no-alert */
    const destinationDirectory = prompt(`Dropped ${files.length} file${files.length > 1 ? 's' : ''}, please enter a directory to store them in`, '/')

    if (!destinationDirectory || !`${destinationDirectory}`.trim()) {
      return
    }

    await Promise.all(
      files.map(file => {
        const path = `${destinationDirectory}/${file.name}`.replace(/\/\/+/g, '/')
        log(`ipfs.files.write('${path}', <File>, { create: true, parents: true })`)
        return ipfs.files.write(path, file, {
          create: true,
          parents: true
        })
          .catch(error => log(error))
      })
    )

    updateTree(ipfs)
  })

  mkdirForm(async (path, parents, format, hashAlg, flush) => {
    log(`ipfs.files.mkdir('${path}', ${JSON.stringify({
      parents,
      format,
      hashAlg,
      flush
    }, null, 2)})`)

    await ipfs.files.mkdir(path, {
      parents,
      format,
      hashAlg,
      flush
    })
      .catch(error => log(error))

    updateTree(ipfs)
  })

  mvForm(async (paths, destination, parents, format, hashAlg, flush) => {
    log(`ipfs.files.mv(${paths.map(path => `'${path}'`).join(', ')}, ${JSON.stringify({
      parents,
      format,
      hashAlg,
      flush
    }, null, 2)})`)

    await ipfs.files.mv.apply(null, paths.concat(destination, {
      parents,
      format,
      hashAlg,
      flush
    }))
      .catch(error => log(error))

    updateTree(ipfs)
  })

  rmForm(async (paths, recursive) => {
    log(`ipfs.files.rm(${paths.map(path => `'${path}'`).join(', ')}, ${JSON.stringify({
      recursive
    }, null, 2)})`)

    await ipfs.files.rm.apply(null, paths.concat({
      recursive
    }))
      .catch(error => log(error))

    updateTree(ipfs)
  })

  cpForm(async (paths, destination, parents, format, hashAlg, flush) => {
    log(`ipfs.files.cp(${paths.map(path => `'${path}'`).join(', ')}, '${destination}', ${JSON.stringify({
      parents,
      format,
      hashAlg,
      flush
    }, null, 2)})`)

    await ipfs.files.cp.apply(null, paths.concat(destination, {
      parents,
      format,
      hashAlg,
      flush
    }))
      .catch(error => log(error))

    updateTree(ipfs)
  })

  statForm(async (path, hash, size, withLocal) => {
    log(`ipfs.files.stat('${path}', ${JSON.stringify({
      hash,
      size,
      withLocal
    }, null, 2)})`)

    await ipfs.files.stat(path, {
      hash,
      size,
      withLocal
    })
      .then((stats) => log(stats))
      .catch(error => log(error))
  })

  readForm(async (path, offset, length) => {
    log(`ipfs.files.read('${path}', ${JSON.stringify({
      offset,
      length
    }, null, 2)})`)

    await ipfs.files.read(path, {
      offset,
      length
    })
      .then((buffer) => {
        mime.lookup(buffer, (error, result) => {
          // will cause file to be downloaded if we don't know what it is
          let mimeType = 'application/octet-stream'

          if (!error) {
            mimeType = result.mime
          }

          const data = bufferToArrayBuffer(buffer)
          const file = new Blob([data], {
            type: mimeType
          })
          const fileURL = URL.createObjectURL(file)
          window.open(fileURL)
        })
      })
      .catch(error => log(error))
  })

  log('IPFS: Ready')
  log('IPFS: Drop some files into this window to get started')
  log('')

  updateTree(ipfs)
})

'''
'''--- examples/browser-mfs/package.json ---
{
  "name": "browser-mfs",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "build": "webpack",
    "start": "npm run build && http-server dist -a 127.0.0.1 -p 8888"
  },
  "author": "",
  "license": "ISC",
  "devDependencies": {
    "html-webpack-plugin": "^3.2.0",
    "http-server": "~0.11.1",
    "uglifyjs-webpack-plugin": "^1.2.0",
    "webpack": "^4.15.1",
    "webpack-cli": "^3.0.8"
  },
  "dependencies": {
    "ipfs": "../../",
    "mime-sniffer": "~0.0.3"
  }
}

'''
'''--- examples/browser-mfs/utils.js ---
'use strict'

const createNode = (type, content, attrbutes) => {
  attrbutes = attrbutes || {}

  const node = document.createElement(type)
  node.innerText = content

  Object.keys(attrbutes).forEach(attrbute => {
    if (attrbute === 'className') {
      node.className = attrbutes[attrbute]

      return
    }

    node.setAttribute(attrbute, attrbutes[attrbute])
  })

  return node
}

const log = (line) => {
  const output = document.querySelector('#log')
  let message
  let className = ''

  if (line instanceof Error) {
    className = 'error'
    message = `Error: ${line.message}`
  } else if (typeof line === 'string') {
    message = line
  } else {
    className = 'output'
    message = JSON.stringify(line, null, 2)
  }

  if (!message) {
    return
  }

  const node = createNode('p', message, {
    className
  })
  output.appendChild(node)
  output.scrollTop = output.offsetHeight

  return node
}

const dragDrop = (onFiles) => {
  const container = document.querySelector('#container')

  container.ondragover = (event) => {
    container.className = 'drag-over'
    event.preventDefault()
  }

  container.ondragleave = () => {
    container.className = ''
  }

  container.ondrop = (event) => {
    container.className = ''
    event.preventDefault()

    const files = Array.from(event.dataTransfer.items)
      .map(item => item.getAsFile())
      .filter(item => Boolean(item))

    if (files.length) {
      onFiles(files)
    }
  }
}

const bufferToArrayBuffer = (buffer) => {
  const ab = new ArrayBuffer(buffer.length)
  const view = new Uint8Array(ab)

  for (let i = 0; i < buffer.length; ++i) {
    view[i] = buffer[i]
  }

  return ab
}

module.exports = {
  log,
  dragDrop,
  createNode,
  bufferToArrayBuffer
}

'''
'''--- examples/browser-mfs/webpack.config.js ---
'use strict'

const path = require('path')
const UglifyJsPlugin = require('uglifyjs-webpack-plugin')
const HtmlWebpackPlugin = require('html-webpack-plugin')

module.exports = {
  mode: 'development',
  devtool: 'source-map',
  entry: [
    './index.js'
  ],
  plugins: [
    new UglifyJsPlugin({
      sourceMap: true,
      uglifyOptions: {
        mangle: false,
        compress: false
      }
    }),
    new HtmlWebpackPlugin({
      title: 'IPFS MFS example',
      template: 'index.html'
    })
  ],
  output: {
    path: path.join(__dirname, 'dist'),
    filename: 'bundle.js'
  },
  node: {
    fs: 'empty'
  }
}

'''
'''--- examples/browser-parceljs/README.md ---
# Bundle js-ipfs with [Parcel.js](https://parceljs.org/)

> In this example, you will find a boilerplate application that connects to
IPFS using JS-IPFS and is bundled with [Parcel.js](https://parceljs.org/), so
that you can follow it for creating Parcel.js bundled js-ipfs DApps.

## Before you start

1. Start your IPFS daemon of choice e.g. `ipfs daemon` (optional if you do not
want to serve the example over IPFS)
1. Open a new terminal
1. `cd` into this folder
1. Run `npm install`

## Running this example in development mode with auto-reloading

1. `npm start`
1. Open your browser at `http://localhost:1234`

You should see the following:

![](https://ipfs.io/ipfs/QmSiZ18GffagbbJ3z72kK7u3SP9MXqBB1vrU1KFYP3GMYs/1.png)

## Build and add to IPFS

1. Clear the contents of `dist` if this is not the first time you are building
e.g. `rm -r dist` on a unix system
1. `npm run build`
1. The production build of the site is now in the `dist` folder
1. Add the folder to ipfs using your IPFS client of choice e.g.
`ipfs add -r dist`

The last hash output is the hash of the directory.  This can be used to access
this example served over IPFS and will be accessible by a public gateway:

> https://ipfs.io/ipfs/<hash_of_directory>/

'''
'''--- examples/browser-parceljs/package.json ---
{
  "name": "browser-parceljs",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "browserslist": [
    "last 2 Chrome versions"
  ],
  "scripts": {
    "lint": "standard public/**/*.js",
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "parcel public/index.html",
    "build": "parcel build public/index.html --public-url ./"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "ipfs": "file:../../"
  },
  "devDependencies": {
    "@babel/cli": "^7.1.5",
    "@babel/core": "^7.1.6",
    "@babel/preset-env": "^7.1.6",
    "babel-plugin-syntax-async-functions": "^6.13.0",
    "babel-plugin-transform-regenerator": "^6.26.0",
    "babel-polyfill": "^6.26.0",
    "parcel-bundler": "^1.10.3",
    "standard": "^12.0.1"
  }
}

'''
'''--- examples/browser-parceljs/public/index.html ---
<!DOCTYPE html>

<html lang="en">

  <head>
    <meta charset="utf-8">
    <title>js-ipfs parcel.js browser example</title>
  </head>

  <body>
    <header>
      <h1 id="status">Connecting to IPFS...</h1>
    </header>

    <main>
      <pre id="output"></pre>
    </main>

    <script src="./index.js"></script>

  </body>

</html>

'''
'''--- examples/browser-parceljs/public/index.js ---
import 'babel-polyfill'
import IPFS from 'ipfs'

// IPFS node setup
const node = new IPFS({ repo: String(Math.random() + Date.now()) })

// UI elements
const status = document.getElementById('status')
const output = document.getElementById('output')

output.textContent = ''

function log (txt) {
  console.info(txt)
  output.textContent += `${txt.trim()}\n`
}

node.on('ready', async () => {
  status.innerText = 'Connected to IPFS :)'

  const version = await node.version()

  log(`The IPFS node version is ${version.version}`)

  const filesAdded = await node.add({
    path: 'hello-parcel.txt',
    content: Buffer.from('Hello from parcel.js bundled ipfs example')
  })

  log(`This page deployed ${filesAdded[0].path} to IPFS and its hash is ${filesAdded[0].hash}`)

  const fileBuffer = await node.cat(filesAdded[0].hash)

  log(`The contents of the file was: ${fileBuffer.toString()}`)
})

'''
'''--- examples/browser-readablestream/README.md ---
# Streaming video from IPFS using ReadableStreams

We can use the execllent [`videostream`](https://www.npmjs.com/package/videostream) to stream video from IPFS to the browser.  All we need to do is return a [`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream)-like object that contains the requested byte ranges.

Take a look at [`index.js`](./index.js) to see a working example.

## Running the demo

In this directory:

```
$ npm install
$ npm start
```

Then open [http://localhost:8888](http://localhost:8888) in your browser.

'''
'''--- examples/browser-readablestream/index.html ---
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8"/>
    <title><%= htmlWebpackPlugin.options.title %></title>
    <style type="text/css">

body {
  margin: 0;
  padding: 0;
}

#container {
  display: flex;
  height: 100vh;
}

pre {
  flex-grow: 2;
  padding: 10px;
  height: calc(100vh - 45px);
  overflow: auto;
}

#form-wrapper {
  padding: 20px;
}

form {
  padding-bottom: 10px;
  display: flex;
}

#hash {
  display: inline-block;
  margin: 0 10px 10px 0;
  font-size: 16px;
  flex-grow: 2;
  padding: 5px;
}

button {
  display: inline-block;
  font-size: 16px;
  height: 32px;
}

video {
  max-width: 50vw;
}

    </style>
  </head>
  <body>
    <div id="container" ondrop="dropHandler(event)" ondragover="dragOverHandler(event)">
      <div id="form-wrapper">
          <form>
            <input type="text" id="hash" placeholder="Hash" disabled />
            <button id="gobutton" disabled>Go!</button>
          </form>
          <video id="video" controls></video>
      </div>
      <pre id="output" style="display: inline-block"></pre>
    </div>
  </body>
</html>

'''
'''--- examples/browser-readablestream/index.js ---
'use strict'

/* eslint-env browser */

const Ipfs = require('../../')
const videoStream = require('videostream')
const ipfs = new Ipfs({ repo: 'ipfs-' + Math.random() })
const {
  dragDrop,
  statusMessages,
  createVideoElement,
  log
} = require('./utils')

log('IPFS: Initialising')

ipfs.on('ready', () => {
  // Set up event listeners on the <video> element from index.html
  const videoElement = createVideoElement()
  const hashInput = document.getElementById('hash')
  const goButton = document.getElementById('gobutton')
  let stream

  goButton.onclick = function (event) {
    event.preventDefault()

    log(`IPFS: Playing ${hashInput.value.trim()}`)

    // Set up the video stream an attach it to our <video> element
    videoStream({
      createReadStream: function createReadStream (opts) {
        const start = opts.start

        // The videostream library does not always pass an end byte but when
        // it does, it wants bytes between start & end inclusive.
        // catReadableStream returns the bytes exclusive so increment the end
        // byte if it's been requested
        const end = opts.end ? start + opts.end + 1 : undefined

        log(`Stream: Asked for data starting at byte ${start} and ending at byte ${end}`)

        // If we've streamed before, clean up the existing stream
        if (stream && stream.destroy) {
          stream.destroy()
        }

        // This stream will contain the requested bytes
        stream = ipfs.catReadableStream(hashInput.value.trim(), {
          offset: start,
          length: end && end - start
        })

        // Log error messages
        stream.on('error', (error) => log(error))

        if (start === 0) {
          // Show the user some messages while we wait for the data stream to start
          statusMessages(stream, log)
        }

        return stream
      }
    }, videoElement)
  }

  // Allow adding files to IPFS via drag and drop
  dragDrop(ipfs, log)

  log('IPFS: Ready')
  log('IPFS: Drop an .mp4 file into this window to add a file')
  log('IPFS: Then press the "Go!" button to start playing a video')

  hashInput.disabled = false
  goButton.disabled = false
})

'''
'''--- examples/browser-readablestream/package.json ---
{
  "name": "browser-videostream",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "build": "webpack",
    "start": "npm run build && http-server dist -a 127.0.0.1 -p 8888"
  },
  "author": "",
  "license": "ISC",
  "devDependencies": {
    "html-webpack-plugin": "^3.2.0",
    "http-server": "~0.11.1",
    "terser-webpack-plugin": "^1.2.1",
    "webpack": "^4.28.4"
  },
  "dependencies": {
    "videostream": "^2.4.2"
  }
}

'''
'''--- examples/browser-readablestream/utils.js ---
'use strict'

const log = (line) => {
  const output = document.getElementById('output')
  let message

  if (line.message) {
    message = `Error: ${line.message.toString()}`
  } else {
    message = line
  }

  if (message) {
    const node = document.createTextNode(`${message}\r\n`)
    output.appendChild(node)

    output.scrollTop = output.offsetHeight

    return node
  }
}

const dragDrop = (ipfs) => {
  const container = document.querySelector('#container')

  container.ondragover = (event) => {
    event.preventDefault()
  }

  container.ondrop = (event) => {
    event.preventDefault()

    Array.prototype.slice.call(event.dataTransfer.items)
      .filter(item => item.kind === 'file')
      .map(item => item.getAsFile())
      .forEach(file => {
        const progress = log(`IPFS: Adding ${file.name} 0%`)

        const reader = new window.FileReader()
        reader.onload = (event) => {
          ipfs.add({
            path: file.name,
            content: ipfs.types.Buffer.from(event.target.result)
          }, {
            progress: (addedBytes) => {
              progress.textContent = `IPFS: Adding ${file.name} ${parseInt((addedBytes / file.size) * 100)}%\r\n`
            }
          }, (error, added) => {
            if (error) {
              return log(error)
            }

            const hash = added[0].hash

            log(`IPFS: Added ${hash}`)

            document.querySelector('#hash').value = hash
          })
        }

        reader.readAsArrayBuffer(file)
      })

    if (event.dataTransfer.items && event.dataTransfer.items.clear) {
      event.dataTransfer.items.clear()
    }

    if (event.dataTransfer.clearData) {
      event.dataTransfer.clearData()
    }
  }
}

module.exports.statusMessages = (stream) => {
  let time = 0
  const timeouts = [
    'Stream: Still loading data from IPFS...',
    'Stream: This can take a while depending on content availability',
    'Stream: Hopefully not long now',
    'Stream: *Whistles absentmindedly*',
    'Stream: *Taps foot*',
    'Stream: *Looks at watch*',
    'Stream: *Stares at floor*',
    'Stream: *Checks phone*',
    'Stream: *Stares at ceiling*',
    'Stream: Got anything nice planned for the weekend?'
  ].map(message => {
    time += 5000

    return setTimeout(() => {
      log(message)
    }, time)
  })

  stream.once('data', () => {
    log('Stream: Started receiving data')
    timeouts.forEach(clearTimeout)
  })
  stream.once('error', () => {
    timeouts.forEach(clearTimeout)
  })
}

const createVideoElement = () => {
  const videoElement = document.getElementById('video')
  videoElement.addEventListener('loadedmetadata', () => {
    videoElement.play()
      .catch(log)
  })

  const events = [
    'playing',
    'waiting',
    'seeking',
    'seeked',
    'ended',
    'loadedmetadata',
    'loadeddata',
    'canplay',
    'canplaythrough',
    'durationchange',
    'play',
    'pause',
    'suspend',
    'emptied',
    'stalled',
    'error',
    'abort'
  ]
  events.forEach(event => {
    videoElement.addEventListener(event, () => {
      log(`Video: ${event}`)
    })
  })

  videoElement.addEventListener('error', () => {
    log(videoElement.error)
  })

  return videoElement
}

module.exports.log = log
module.exports.dragDrop = dragDrop
module.exports.createVideoElement = createVideoElement

'''
'''--- examples/browser-readablestream/webpack.config.js ---
'use strict'

const path = require('path')
const TerserPlugin = require('terser-webpack-plugin')
const HtmlWebpackPlugin = require('html-webpack-plugin')

module.exports = {
  devtool: 'source-map',
  entry: [
    './index.js'
  ],
  plugins: [
    new HtmlWebpackPlugin({
      title: 'IPFS Videostream example',
      template: 'index.html'
    })
  ],
  optimization: {
    minimizer: [
      new TerserPlugin({
        terserOptions: {
          parse: {
            // we want terser to parse ecma 8 code. However, we don't want it
            // to apply any minfication steps that turns valid ecma 5 code
            // into invalid ecma 5 code. This is why the 'compress' and 'output'
            // sections only apply transformations that are ecma 5 safe
            // https://github.com/facebook/create-react-app/pull/4234
            ecma: 8
          },
          compress: {
            ecma: 5,
            warnings: false
          },
          mangle: {
            safari10: true
          },
          output: {
            ecma: 5,
            comments: false
          }
        },
        // Use multi-process parallel running to improve the build speed
        // Default number of concurrent runs: os.cpus().length - 1
        parallel: true,
        // Enable file caching
        cache: true,
        sourceMap: true
      })
    ]
  },
  output: {
    path: path.join(__dirname, 'dist'),
    filename: 'bundle.js'
  }
}

'''
'''--- examples/browser-script-tag/README.md ---
# Use IPFS in the browser with `<script>` tags

You can use IPFS in your in-browser JavaScript code with just a `<script>` tag.

```
<script src="https://unpkg.com/ipfs/dist/index.min.js"></script>
```

This exposes a global `Ipfs`; you can get a node by making a `new Ipfs()`.

See `index.html` for a working example.

'''
'''--- examples/browser-script-tag/index.html ---
<!doctype html>
<html>
<head>
  <title>IPFS in the Browser</title>
  <script src="https://unpkg.com/ipfs/dist/index.min.js"></script>
  <script type="text/javascript">
    const node = new Ipfs({ repo: 'ipfs-' + Math.random() })

    node.once('ready', () => {
      console.log('Online status: ', node.isOnline() ? 'online' : 'offline')

      document.getElementById("status").innerHTML= 'Node status: ' + (node.isOnline() ? 'online' : 'offline')

      // You can write more code here to use it. Use methods like
      // node.add, node.get. See the API docs here:
      // https://github.com/ipfs/interface-ipfs-core
    })
  </script>
</head>
<body>
  <h1>IPFS in the Browser</h1>
  <p>This page creates an IPFS node in your browser and drops it into the global Javascript namespace as <b><em style="background-color:#d7d6d6">node</em></b>. Open the console to play around with it.</p>
  <p>Note that opening two tabs of this page in the same browser won't work well, because they will share node configuration. You'll end up trying to run two instances of the same node, with the same private key and identity, which is a Bad Idea.</p>
  <h1 id="status">Node status: offline</h1>

  <h2>Some suggestions</h2>

  <p>Try adding a new file:</p>

  <code style="display:block; white-space:pre-wrap; background-color:#d7d6d6">
    node.add(new node.types.Buffer('Hello world!'), (err, filesAdded) => {
      if (err) {
        return console.error('Error - ipfs add', err, res)
      }

      filesAdded.forEach((file) => console.log('successfully stored', file.hash))
    })
  </code>

  <p>You can cat that same file. If you used the exact same string as above ('Hello world!') you should have an hash like this: 'QmQzCQn4puG4qu8PVysxZmscmQ5vT1ZXpqo7f58Uh9QfyY'</p>

  <code style="display:block; white-space:pre-wrap; background-color:#d7d6d6">
    node.cat('QmQzCQn4puG4qu8PVysxZmscmQ5vT1ZXpqo7f58Uh9QfyY', function (err, data) {
      if (err) {
        return console.error('Error - ipfs files cat', err, res)
      }

      console.log(data.toString())
    })
  </code>
</body>
</html>

'''
'''--- examples/browser-video-streaming/README.md ---
# Streaming video in the browser with js-ipfs and hls.js

This example shows a method for video/audio streaming in the browser over IPFS.

## Why use HLS?

HLS (Apple's HTTP Live Streaming) is one of several protocols currently available for adaptive bitrate streaming.

One of the advantages of HLS over some other streaming technologies is that the content can be hosted on a plain old web server without any special server-side support. The way this works is that the original content (the stream or video/audio file) is split up into small MPEG2-TS segments before being uploaded to the server. The segments are then fetched by the HLS player on the fly (using regular HTTP GET requests) and get spliced together to a continuous stream.

In addition to the segments there are also so-called manifests (m3u8 files) which contain metadata about segments and their bitrates. A stream can contain segments of multiple bitrates and the HLS player will automatically switch to the optimal bitrate based on client performance.

The fact that HLS content is just "a bunch of files" makes it a good choice for IPFS (another protocol that works this way is MPEG-DASH, which could certainly be a good choice as well). Furthermore, the [hls.js](https://github.com/video-dev/hls.js) library enables straightforward integration with the HTML5 video element.

## hlsjs-ipfs-loader

The hls.js library ships with an HTTP based content loader only, but it's fortunately possible to configure custom content loaders as well, which is what makes IPFS streaming possible in this case. A loader implementation that fetches content using js-ipfs can be found [here](https://www.npmjs.com/package/hlsjs-ipfs-loader), and is easy to use on a regular HTML page:

```html
<script src="https://unpkg.com/ipfs/dist/index.js"></script>
<script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
<script src="https://unpkg.com/hlsjs-ipfs-loader@0.1.2/dist/index.js"></script>
```

## Generating HLS content

In order for any of the above to be useful, we also need to have a way to actually generate HLS manifests and MPEG2-TS segments from an arbitrary video/audio file. Luckily, most new builds of `ffmpeg` are compiled with this capability.

For example, say we have a directory containing a video file `BigBuckBunny_320x180.mp4`. We can then create a sub directory and generate the HLS data there, and finally add it to IPFS:

```bash
> mkdir hls-bunny
> cd hls-bunny
> ffmpeg -i ../BigBuckBunny_320x180.mp4 -profile:v baseline -level 3.0 -start_number 0 -hls_time 5 -hls_list_size 0 -f hls master.m3u8
> ipfs add -Qr .
```

The most important piece of information to note down is the name you choose for the HLS manifest (master.m3u8 in this example, but you're free to use any name), and the hash returned by `ipfs add`. Consult [streaming.js](streaming.js) for a full example of how these values are used.

## Putting it all together

*Note:* If you try to run the example straight from disk, some browsers (e.g Chrome) might, for security reasons, prevent some resources from loading correctly. To get around this, simply cd into the directory of this example and use http-server from npm:

```bash
> npm install -g http-server
> http-server
```

You should then be able to stream Big Buck Bunny by pointing your browser at http://localhost:8080.

In addition to video streaming, plain audio streaming works fine as well. Simply use the same ffmpeg + ipfs procedure as described above, but with your audio file as input. You may also want to change the video tag to `audio` (video tags will play plain audio as well, but the player looks a bit strange).

On a final note, without diving too deep into what the specific ffmpeg HLS options above mean, it's worth mentioning the `hls_time` option, which defines the length of each HLS chunk (in seconds) and is potentially interesting for performance tuning (see for example [this article](https://bitmovin.com/mpeg-dash-hls-segment-length/)).

'''
'''--- examples/browser-video-streaming/index.html ---
<html>
  <body>
    <video id="video" controls></video>
    <script src="https://unpkg.com/ipfs/dist/index.js"></script>
    <script src="https://unpkg.com/hlsjs-ipfs-loader@0.1.3/dist/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
    <script src="streaming.js"></script>
  </body>
</html>

'''
'''--- examples/browser-video-streaming/streaming.js ---
'use strict'

/* global Hls Ipfs HlsjsIpfsLoader */
/* eslint-env browser */

const testhash = 'QmdpAidwAsBGptFB3b6A9Pyi5coEbgjHrL3K2Qrsutmj9K'
const repoPath = 'ipfs-' + Math.random()
const node = new Ipfs({ repo: repoPath })

node.on('ready', () => {
  Hls.DefaultConfig.loader = HlsjsIpfsLoader
  Hls.DefaultConfig.debug = false
  if (Hls.isSupported()) {
    const video = document.getElementById('video')
    const hls = new Hls()
    hls.config.ipfs = node
    hls.config.ipfsHash = testhash
    hls.loadSource('master.m3u8')
    hls.attachMedia(video)
    hls.on(Hls.Events.MANIFEST_PARSED, () => video.play())
  }
})

'''
'''--- examples/browser-webpack/README.md ---
# Bundle js-ipfs with Webpack!

> In this example, you will find a boilerplate you can use to guide yourself into bundling js-ipfs with webpack, so that you can use it in your own web app!

## Run this example

Once the daemon is on, run the following commands within this folder:

```bash
> npm install
> npm start
```

Now open your browser at `http://localhost:3000`

You should see the following:

![](https://ipfs.io/ipfs/QmZndNLRct3co7h1yVB72S4qfwAwbq7DQghCpWpVQ45jSi/1.png)

'''
'''--- examples/browser-webpack/index.html ---
<html>
  <head>
    <title>Sample App</title>
  </head>
  <body>
    <div id='root'></div>
    <script src="/static/bundle.js"></script>
  </body>
</html>

'''
'''--- examples/browser-webpack/package.json ---
{
  "name": "bundle-webpack",
  "version": "1.0.0",
  "description": "Bundle js-ipfs with WebPack",
  "scripts": {
    "start": "node server.js"
  },
  "license": "MIT",
  "keywords": [],
  "devDependencies": {
    "@babel/core": "^7.2.2",
    "@babel/preset-env": "^7.2.3",
    "@babel/preset-react": "^7.0.0",
    "babel-loader": "^8.0.5",
    "react": "^16.7.0",
    "react-dom": "^16.7.0",
    "react-hot-loader": "^4.6.3",
    "webpack": "^4.28.4",
    "webpack-dev-server": "^3.1.14"
  },
  "dependencies": {
    "ipfs": "file:../../"
  },
  "browserslist": [
    ">1%",
    "not dead",
    "not ie <= 11",
    "not op_mini all"
  ]
}

'''
'''--- examples/browser-webpack/server.js ---
'use strict'

const webpack = require('webpack')
const WebpackDevServer = require('webpack-dev-server')
const config = require('./webpack.config')

const wds = new WebpackDevServer(webpack(config), {
  publicPath: config.output.publicPath,
  hot: true,
  historyApiFallback: true
})

wds.listen(3000, 'localhost', (err, result) => {
  if (err) {
    throw err
  }

  console.log('Listening at localhost:3000')
})

'''
'''--- examples/browser-webpack/src/components/app.js ---
'use strict'

const React = require('react')
const IPFS = require('ipfs')

const stringToUse = 'hello world from webpacked IPFS'

class App extends React.Component {
  constructor (props) {
    super(props)
    this.state = {
      id: null,
      version: null,
      protocol_version: null,
      added_file_hash: null,
      added_file_contents: null
    }
  }
  componentDidMount () {
    const self = this
    let node

    create()

    function create () {
      // Create the IPFS node instance

      node = new IPFS({ repo: String(Math.random() + Date.now()) })

      node.once('ready', () => {
        console.log('IPFS node is ready')
        ops()
      })
    }

    function ops () {
      node.id((err, res) => {
        if (err) {
          throw err
        }
        self.setState({
          id: res.id,
          version: res.agentVersion,
          protocol_version: res.protocolVersion
        })
      })

      node.add([Buffer.from(stringToUse)], (err, filesAdded) => {
        if (err) { throw err }

        const hash = filesAdded[0].hash
        self.setState({ added_file_hash: hash })

        node.cat(hash, (err, data) => {
          if (err) { throw err }
          self.setState({ added_file_contents: data.toString() })
        })
      })
    }
  }
  render () {
    return (
      <div style={{ textAlign: 'center' }}>
        <h1>Everything is working!</h1>
        <p>Your ID is <strong>{this.state.id}</strong></p>
        <p>Your IPFS version is <strong>{this.state.version}</strong></p>
        <p>Your IPFS protocol version is <strong>{this.state.protocol_version}</strong></p>
        <hr />
        <div>
          Added a file! <br />
          {this.state.added_file_hash}
        </div>
        <br />
        <br />
        <p>
          Contents of this file: <br />
          {this.state.added_file_contents}
        </p>
      </div>
    )
  }
}
module.exports = App

'''
'''--- examples/browser-webpack/src/components/index.js ---
'use strict'

const React = require('react')
const ReactDOM = require('react-dom')
const App = require('./app')

ReactDOM.render(<App />, document.getElementById('root'))

'''
'''--- examples/browser-webpack/webpack.config.js ---
'use strict'

var path = require('path')
var webpack = require('webpack')

module.exports = {
  devtool: 'eval',
  entry: [
    'webpack-dev-server/client?http://localhost:3000',
    'webpack/hot/only-dev-server',
    './src/components/index'
  ],
  output: {
    path: path.join(__dirname, 'dist'),
    filename: 'bundle.js',
    publicPath: '/static/'
  },
  plugins: [
    new webpack.HotModuleReplacementPlugin()
  ],
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: 'babel-loader',
          options: {
            presets: ['@babel/preset-env', '@babel/preset-react']
          }
        }
      }
    ]
  },
  node: {
    fs: 'empty',
    net: 'empty',
    tls: 'empty'
  }
}

'''
'''--- examples/circuit-relaying/README.md ---
# Tutorial - Understanding Circuit Relay

> Welcome! This tutorial will help you understand circuit relay, where it fits in the stack and how to use it.

### So what is a `circuit-relay` and what do we need it for?

In p2p networks there are many cases where two nodes can't talk to each other directly. That may happen because of network topology, i.e. NATs, or execution environments - for example browser nodes can't connect to each other directly because they lack any sort of socket functionality and relaying on specialized rendezvous nodes introduces an undesirable centralization point to the network. A `circuit-relay` is a way to solve this problem - it is a node that allows two other nodes that can't otherwise talk to each other, use a third node, a relay to do so.

#### How does circuit relay work?

>for a more in-depth explanation take a look at the [relay spec](https://github.com/libp2p/specs/blob/master/relay/README.md) and `js-libp2p-circuit` [README](https://github.com/libp2p/js-libp2p-circuit/blob/master/README.md)

Here is a simple diagram depicting how a typical circuit-relay connection might look:

```
+---------------------+         |          |         +---------------------+
|       Node A        |---------> FIREWALL <---------|        Node B       |
+----------^----------+         |          |         +----------^----------+
           |                                                    |           
           |               +---------------------+              |           
           +--------------->   Circuit Relay     <--------------+           
                           +---------------------+                          
```

`Node A` tries to connect to `Node B` but, UH-OH! There is a firewall in between that's preventing it from happening. If both `Node A` and `Node B` know about a relay, they can use it to establish the connection.

This is what it looks like, in simplified steps:

1. `Node A` tries to connect to `Node B` over one of its known addresses
2. Connection fails because of firewall/NAT/incompatible transports/etc...
3. Both `Node A` and `Node B` know of the same relay - `Relay`
4. `Node A` falls back to dialing over `Relay` to `Node B` using its `'/p2p-circuit'` address, which involves:
   1. `Node A` sends a `HOP` request to `Relay`
   2. `Relay` extracts the destination address, figures out that a circuit to `Node B` is being requested
   3. `Relay` sends a `STOP` request to `Node B`
   4. `Node B` responds with a `SUCCESS` message
   5. `Relay` proceed to create a circuit over the two nodes
5. `Node A` and `Node B` are now connected over `Relay`

That's it!

#### What's up with this `HOP` and `STOP`?

Circuit relay consists of two logical parts — dialer/listener and relay (`HOP`). The listener is also known as the `STOP` node. Each of these — dial, listen, and relay — happen on a different node. If we use the nodes from the above example, it looks something like this:

- The `dialer` knows how to dial a `relay` (`HOP`) - `Node A`
- The `relay` (`HOP`) knows how to contact a destination node (`STOP`) and create a circuit - `Relay` node
- The `listener` (`STOP`) knows how to process relay requests that come from the relay (`HOP`) node - `Node B`

_Fun fact - the `HOP` and `STOP` names are also used internally by circuit to identify the network message types._

#### A few caveats (and features)

There are a couple of caveats and features to be aware of:

- A `Relay` will only work if it already has a connection to the `STOP` node
- No `multihop` dialing is supported. It's a feature planed for upcoming releases (no date on this one)
  - `multihop` dialing is when several relays are used to establish the connection
- It is possible to use explicit relay addresses to connect to a node, or even to listen for connections on. See next section to learn how to do this.

#### A word on circuit relay addresses

A circuit relay address is a [multiaddress](https://multiformats.io/multiaddr/) that describes how to either connect to a peer over a relay (or relays), or allow a peer to announce it is reachable over a particular relay or any relay it is already connected to.

Circuit relay addresses are very flexible and can describe many different aspects of how to esablish the relayed connection. In its simplest form, it looks something like this:

- `/p2p-circuit/ipfs/QmPeer`

If we want to be specific as to which transport we want to use to establish the relay, we can encode that in the address as well:

- `/ip4/127.0.0.1/tcp/65000/ipfs/QmRelay/p2p-circuit/ipfs/QmPeer`

This tells us that we want to use `QmRelay` located at address 127.0.0.1 and port 65000.

- `/ip4/127.0.0.1/tcp/65000/ipfs/QmRelay/p2p-circuit/ip4/127.0.0.1/tcp/8080/ws/ipfs/QmPeer`

We can take it a step further and encode the same information for the destination peer. In this case, we have it located at 127.0.0.1 on port 8080 and using a Web sockets transport!

- `/ip4/127.0.0.1/tcp/65000/ipfs/QmRelay/p2p-circuit`

If a node is configured with this address, it will use the specified host (`/ip4/127.0.0.1/tcp/65000/ipfs/QmRelay`) as a relay and it will be reachable over this relay.
  - There could multiple addresses of this sort specified in the config, in which case the node will be reachable over all of them.
  - This is useful if, for example, the node is behind a firewall but wants to be reachable from the outside over a specific relay.

Other use-cases are also supported by this scheme, e.g. we can have multiple hops (circuit-relay nodes) encoded in the address, something planed for future releases.

## Step-by-step instructions

Here's what we are going to be doing, today:

1. Install and configure `go-ipfs` and `js-ipfs` nodes
2. Configure and run the js or go ipfs node
3. Configure and run the bundled example
4. Connect the two browser nodes to the circuit relay
5. Dial the two browser nodes using a `/p2p-circuit` address
6. Finally, send data from one browser using the bundled example!

> We should end up with something similar to the bellow screenshot after we've gone through all the steps:

![](./img/img7.png)

Let's go.

### 1. Set up

You'll need to have an implementation of IPFS running on your machine. Currently, this means either go-ipfs or js-ipfs.

Installing go-ipfs can be done by installing the binary [here](https://ipfs.io/ipns/dist.ipfs.io/#go-ipfs). Alternatively, you could follow the instructions in the README at [ipfs/go-ipfs](https://github.com/ipfs/go-ipfs).

Installing js-ipfs requires you to have node and [npm](https://www.npmjs.com). Then, you simply run:

```sh
> npm install --global ipfs
...
> jsipfs --help
Commands:
...
```

This will alias `jsipfs` on your machine; this is to avoid issues with `go-ipfs` being called `ipfs`.

At this point, you have either js-ipfs or go-ipfs running. Now, initialize it:

```sh
> ipfs init
# or
> jsipfs init
```

This will set up your IPFS repo in your home directory.

#### Configure and run the js or go ipfs node

You can use a `go-ipfs` or a `js-ipfs` node as a relay. We'll demonstrate how to set both up in this tutorial and we encourage you to try both out. That said, either js or go should do the trick!

##### Setting up a `go-ipfs` node

In order to enable the relay functionality in `go-ipfs` we need to edit it's configuration file, located under `~/.ipfs/config`:

```js
  "Swarm": {
    "AddrFilters": null,
    "ConnMgr": {
      "GracePeriod": "20s",
      "HighWater": 900,
      "LowWater": 600,
      "Type": "basic"
    },
    "DisableBandwidthMetrics": false,
    "DisableNatPortMap": false,
    "DisableRelay": false,
    "EnableRelayHop": true
  }
```

The two options we're looking for are `DisableRelay` and `EnableRelayHop`. We want the former (`DisableRelay`) set to `false` and the latter (`EnableRelayHop`) to `true`, just like in the example above. That should set our go node as a relay.

We also need to make sure our go node can be dialed from the browser. For that, we need to enable a transport that both the browser and the go node can communicate over. We will use the web sockets transport, although there are others that can be used, such as `webrtc-star` and `websocket-star`. To enable the transport and set the interface and port we need to edit the `~/.ipfs/config` one more time. Let's find the `Swarm` array and add our desired address there. I picked `/ip4/0.0.0.0/tcp/4004/ws` because it is a port I know is not being used by anything on my machine, but we can also use port `0` so that the OS chooses a random available port for us — either one should work.

```
  "Swarm": [
    "/ip4/0.0.0.0/tcp/4001",
    "/ip4/0.0.0.0/tcp/4004/ws",
    "/ip6/::/tcp/4001"
  ],
```

The config should look similar to the above snippet after we've edited it.

##### Setting up a `js-ipfs` node

We need to go through similar steps to enable circuit relay in `jsipfs`. However, the config options are slightly different — that should change once this feature is not marked as experimental, but for now we have to deal with two different sets of options.

Just as we did with `go-ipfs`, go ahead and edit `js-ipfs` config file located under `~/.jsipfs/config`. Let's add the following config:

```js
  "relay": {
    "enabled": true,
    "hop": {
      "enabled": true
    }
  }
```

Note that we don't have to do anything to enable the `websocket` transport as it is enabled by default in `jsipfs`.

##### Starting the relay node

We can start the relay nodes by either running `ipfs daemon` or `jsipfs daemon`:

**go ipfs**

```
$ ipfs daemon
Initializing daemon...
Swarm listening on /ip4/127.0.0.1/tcp/4001
Swarm listening on /ip4/192.168.1.132/tcp/4001
Swarm listening on /ip6/::1/tcp/4001
Swarm listening on /p2p-circuit/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF
Swarm announcing /ip4/127.0.0.1/tcp/4001
Swarm announcing /ip4/186.4.18.182/tcp/58986
Swarm announcing /ip4/192.168.1.132/tcp/4001
Swarm announcing /ip6/::1/tcp/4001
API server listening on /ip4/127.0.0.1/tcp/5001
Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080
Daemon is ready
```

In the case of go ipfs, the crucial `/ipfs/Qm...` part of the multiaddr might be missing. In that case, you can get it by running the `ipfs id` command.

```
$ ipfs id
{
        "ID": "QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF",
        "PublicKey": "CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC84qPFzqajCfnvaJunqt48S1LIBRthXV60q5QClL+dUfOOU/m7v1ZcpNhvFFUN6tVCDaoT5AxEv0czxZiVx/njl6FVIc6tE1J+HWpc8cbAXNY6QbbyzKl/rjp7V8/QClE0JqgjIk84wnWGTwFhOEt0hnpu2XFt9iHaenSfg3EAa8K9MlbxmbawuxNLJJf7VZXkJrUNl6WOglAVU8Sqc4QaahCLVK5Dzo98zDBq1KDBxMbUgH0LTqzr6i+saxkEHZmBKO+mMVT3LzOUx1DQR4pLAw1qgoJstsIZEaJ2XLh975IiI7OKqWYH7+3NyNK2sldJK/4Zko4rH3irmnkAxLcFAgMBAAE=",
        "Addresses": [
                "/ip4/127.0.0.1/tcp/4001/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF",
                "/ip4/192.168.1.132/tcp/4001/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF",
                "/ip6/::1/tcp/4001/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF",
                "/ip4/186.4.18.182/tcp/13285/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF",
                "/ip4/186.4.18.182/tcp/13285/ipfs/QmY73BLYav2gYc9PCEnjQqbfSGiqFv3aMsRXNyKFGtUoGF"
        ],
        "AgentVersion": "go-ipfs/0.4.14-dev/cb5bb7dd8",
        "ProtocolVersion": "ipfs/0.1.0"
}
```

We can then grab the resolved multiaddr from the `Addresses` array — `/ip4/127.0.0.1/tcp/4004/ws/ipfs/Qm...`. Let's note it down somewhere and move to the next step.

**js ipfs**

```
$ jsipfs daemon
Initializing daemon...
Swarm listening on /p2p-circuit/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
Swarm listening on /p2p-circuit/ip4/0.0.0.0/tcp/4002/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
Swarm listening on /p2p-circuit/ip4/127.0.0.1/tcp/4003/ws/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
Swarm listening on /ip4/127.0.0.1/tcp/4003/ws/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
Swarm listening on /ip4/127.0.0.1/tcp/4002/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
Swarm listening on /ip4/192.168.1.132/tcp/4002/ipfs/QmfQj8YwDdy1uP2DpZBa7k38rSGPvhHiC52cdAGWBqoVpq
API is listening on: /ip4/127.0.0.1/tcp/5002
Gateway (readonly) is listening on: /ip4/127.0.0.1/tcp/9090
Daemon is ready
```

Look out for an address similar to `/ip4/127.0.0.1/tcp/4003/ws/ipfs/Qm...`. Note it down somewhere, and let's move on to the next step.

### 2. Configure and run the bundled example

Now that we have ipfs installed and initialized, let's set up the included example. This is a standard npm package, so the usual `npm install` should get us going. Let's `cd` into the `examples/circuit-relaying` directory and run:

```
npm install
```

After it finishes, we should be able to run the project with `npm start` and get output similar to:

```
npm run start
Server running at http://localhost:1234
```

The bundled example is a simple chat app that uses another cool ipfs feature - [pubsub](https://github.com/libp2p/specs/tree/master/pubsub). Let's open up a browser and paste the above url into the address bar. We should see something similar to the following image:

![](./img/img1.png)

### 3. Connect the two browser nodes to the circuit relay

In order for our browser nodes to be able to messages each other, we need to get them connected. But to do that, we need to use a relay - browser nodes can't be connected directly because of lack of socket support.

Remember the caveat above `Currently a Relay will only work if it already has a connection to the STOP node`? This means that we need to connect our browser nodes to the relay node first.

Having both browsers running side by side (as shown in the first screenshot), enter the `/ip4/127.0.0.1/tcp/4003/ws/ipfs/...` address noted above into the `Connect to Peer` field and hit the `Connect` button:

![](./img/img3.png)

After connecting to the IPFS node, we should see the relay peer show up under the `Peers Connected` box.

![](./img/img4.png)

Let's repeat the same steps with the second tab. Now, both of our browser nodes should be connected to the relay and we can move on to the next step.

### 4. Dial the two browser nodes using a `/p2p-circuit` address

Now that our browsers are both connected to the relay peer, let's get them connected to each other. Head out to the `Addresses` box in one of the tabs, copy the `/p2p-circuit` address and then paste it into the `Connect to Peer` box in the other tab. Repeat these steps on the second tab.

![](./img/img5.png)

Let's hit the `Connect` button on each of the tabs and we should get the two browsers connected and join the chat room.

![](./img/img6.png)

### 5. Send data browser to browser.

Now that we have the two browsers connected, let's try the app out. Type a few words in one of the browser windows and you should see them appear in the other as well!

![](./img/img7.png)

Thats it!

### So what just happened?

Good question!

- We used [js-ipfs](htpps://github.com/ipfs/js-ipfs) running in the browser with circuit relay enabled:
  - _Notice the `relay.enabled` below_

you can find it in [src/app.js](src/app.js)
```js
const ipfs = new IPFS({
  repo: repo(),
  relay: {
    enabled: true,
    hop: {
      enabled: true
    }
  },
  config: {
    Bootstrap: []
  }
})
```

- We connected the browser nodes to an external node over its websocket transport using the `/ip4/127.0.0.1/tcp/4003/ws/ipfs/...` multiaddr. That external node happens to be a `HOP` node, meaning that it can relay connections for our browsers (and other nodes) allowing them to connect

- And finally we connected the two browser nodes using the `/p2p-circuit/ipfs/...` multiaddr. Take a look at the code below in [src/app.js](src/app.js#L102...L107) - lines 102-107

```js
ipfs.swarm.connect(peer, (err) => {
  if (err) {
    return console.error(err)
  }
  $pAddrs.innerHTML += `<li>${peer.trim()}</li>`
})
```

The above code snippet handles connecting to other nodes using `ipfs.swarm.connect`. Notice how there wasn't anything special we had to do to use the circuit once we had everything connected; all the magic is in the multiaddr! [Multiaddrs](https://multiformats.io/multiaddr/) are **AWESOME**!

I encourage the reader to take a look at the bundled app code to see how the browser nodes get setup, suffice to say nothing changes from the perspective of using an `IPFS` node in js code, apart from the new `EXPERIMENTAL` options.

Finally, a side note on [pubsub](https://github.com/libp2p/specs/blob/master/pubsub/README.md). We've used the amazing [ipfs-pubsub-room](https://github.com/ipfs-shipyard/ipfs-pubsub-room) module, to enable the chat functionality. Make sure to take a look at the demo [video](https://www.youtube.com/watch?v=Nv_Teb--1zg) that explains how pubsub works and how it can be used to build other applications!

Cheers!

'''
'''--- examples/circuit-relaying/index.html ---
<!DOCTYPE html>
<html>
<meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<title>IPFS simple messaging</title>
<meta name="description" content="Simple chat app on ipfs">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="./main.css">

<body>
  <header>
    <h1>IPFS Simple Messaging</h1>
  </header>
  <main>
    <div class="columns box">
      <div class="row">
        <div class="box">
          <label>Room (double click to change):</label>
          <span id="room"></span>
          <input type="text" id="room-id" style="display: none">
        </div>
        <div class="box msgs-box">
          <ul id="msgs"></ul>
        </div>
        <div>
          <label>message:</label>
          <input type="text" id="message"></input>
          <button id="send">Send</button>
        </div>
      </div>
      <div class="row">
        <div class="box peers-box">
          <label>Peers Joined Room:</label>
          <ul id="peers"></ul>
        </div>
        <div class="box peers-box">
          <label>Peers Connected:</label>
          <ul id="peers-addrs"></ul>
        </div>
        <div>
          <label>Connect to Peer:</label>
          <input type="text" id="peer"></input>
          <button id="connect">Connect</button>
        </div>
      </div>
      <div class="row">
        <div class="box row">
          <label>Peer id:</label>
          <ul id="peer-id"></ul>
        </div>
        <div class="box addrs-box">
          <label>Addresses:</label>
          <ul id="addrs"></ul>
        </div>
      </div>
    </div>
  </main>
  <script src="src/app.js"></script>
</body>

</html>
'''
'''--- examples/circuit-relaying/main.css ---
* {
  box-sizing: border-box;
}

body {
  height: 100%;
}

body {
  font-family: sans-serif;
  color: white;
  background: linear-gradient(to bottom, #041727 0%, #062b3f 100%);
  pointer-events: auto;
}

h1,
h2,
h3 {
  margin: 0;
}

h1 {
  font-size: 2em;
  font-weight: 300;
}

h2 {
  font-size: 1.25em;
  font-weight: 700;
}

h3 {
  font-size: 1.0em;
  font-weight: 700;
}

main,
header {
  filter: none;
}

.dragover-popup {
  position: fixed;
  top: 0.5em;
  left: 0.5em;
  width: calc(100% - 1em);
  height: calc(100% - 1em);
  background-color: rgba(0, 0, 0, 0.5);
  display: none;
  pointer-events: none;
}

.dragover-popup h1 {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%)
}

body.dragging main,
body.dragging header {
  filter: blur(5px);
}

body.dragging .dragover-popup {
  display: block;
}

header {
  text-align: center;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 3em 0;
}

ul {
  margin: 0;
  padding: 0;
  list-style: none;
}

ul li {
  margin: 1em 0;
  font-size: 1em;
  font-family: monospace;
  word-wrap: break-word;
}

button {
  background-color: rgba(0, 0, 0, 0.2);
  color: #6acad1;
  border: 2px solid #6acad1;
  font-size: 1em;
  padding: 0.625em 1.5em;
  border-radius: 0.125em;
  margin: .5em 0;
}

button.full {
  margin-right: 0;
  margin-left: 0;
  width: 100%;
}

button:hover {
  color: white;
  border: 2px solid white;
  cursor: pointer;
}

.address {
  font-family: monospace
}

.disabled *,
input:disabled,
button:disabled {
  opacity: 0.2;
}

input {
  width: 100%;
  border: 2px solid rgba(0, 0, 0, 0.2);
  color: black;
  padding: 0.7em;
  border-radius: 2px;
}

input:hover,
input:focus,
input:active {
  border-color: #6acad1;
}

input,
button {
  outline: none;
}

main {
  width: 90%;
  margin: 0 auto;
}

.buttons,
.columns {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  height: 100%;
}

.msgs-box {
  flex: 1 1 0px;
  overflow-y: scroll;
  min-height: 250px;
}

.peers-box {
  flex: 1 1 0px;
  overflow-y: scroll;
  min-height: 182px;
}

.addrs-box {
  flex: 1;
  overflow-y: scroll;
  max-height: 273px;
}

.row {
  display: flex; 
  flex-direction: column;
}

.buttons>button,
.columns>div {
  width: calc(33% - 0.5em);
}

.buttons>button {
  margin: 0 0 1em;
}

.box {
  background-color: rgba(255, 255, 255, 0.05);
  padding: 1em;
  margin-bottom: 1em;
}

.box>h2 {
  display: block;
  border-bottom: 2px solid rgba(255, 255, 255, 0.1);
  border-right: 0;
  border-left: 0;
  text-align: center;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
}

.errors {
  grid-area: errors;
  color: red;
  font-style: italic;
  font-size: 1.125em;
  display: block;
  margin: 0 0 1em;
}

.errors.hidden {
  display: none;
}

table {
  width: 100%;
  margin: 1em 0;
  word-break: break-all;
  border-collapse: collapse;
}

table thead {
  background-color: rgba(255, 255, 255, 0.1);
  font-weight: normal
}

table th,
table td {
  padding: 0.5em 0;
}

table td:last-child,
table th:last-child {
  width: 20%;
  text-align: center;
}

table td:first-child {
  width: 45%;
}

table td:nth-child(2) {
  width: 35%;
  font-family: monospace;
}

table tr:hover {
  background-color: rgba(0, 0, 0, 0.2)
}

table a {
  color: inherit;
}
'''
'''--- examples/circuit-relaying/package.json ---
{
  "name": "ipfs-quick-msg",
  "version": "0.0.1",
  "description": "IPFS quick msg",
  "main": "index.js",
  "scripts": {
    "clean": "rm -rf dist/*",
    "build": "parcel build index.html --public-url '.'",
    "start": "parcel index.html",
    "test": "echo \"Error: no test specified\" && exit 1",
    "deploy": "ipfs add -r --quieter dist",
    "lint": "aegir lint"
  },
  "author": "Dmitriy Ryajov <dryajov@gmail.com>",
  "license": "MIT",
  "dependencies": {
    "ipfs": "file:../../",
    "ipfs-pubsub-room": "^1.4.0"
  },
  "devDependencies": {
    "aegir": "^18.0.3",
    "ipfs-css": "~0.2.0",
    "parcel-bundler": "^1.6.2",
    "tachyons": "^4.9.1"
  },
  "browserslist": [
    ">1%",
    "not dead",
    "not ie <= 11",
    "not op_mini all"
  ]
}

'''
'''--- examples/circuit-relaying/src/app.js ---
'use strict'

const IPFS = require('ipfs')
const Helpers = require('./helpers')

const $peerId = document.querySelector('#peer-id')
const $message = document.querySelector('#message')
const $msgs = document.querySelector('#msgs')
const $send = document.querySelector('#send')
const $peer = document.querySelector('#peer')
const $connect = document.querySelector('#connect')
const $pAddrs = document.querySelector('#peers-addrs')
const $room = document.querySelector('#room')
const $roomId = document.querySelector('#room-id')

let roomName = `default`
const fragment = window.location.hash.substr(1)
if (fragment) {
  roomName = fragment
}

$pAddrs.value = ''
$room.innerText = roomName

const repo = () => {
  return 'ipfs/pubsub-demo/' + Math.random()
}

const ipfs = new IPFS({
  repo: repo(),
  relay: {
    enabled: true, // enable relay dialer/listener (STOP)
    hop: {
      enabled: true // make this node a relay (HOP)
    }
  },
  EXPERIMENTAL: {
    pubsub: true // enable pubsub
  },
  config: {
    Bootstrap: []
  }
})

const peersSet = new Set()
const helpers = Helpers(ipfs, peersSet)
const createRoom = helpers.createRoom
const sendMsg = helpers.sendMsg
const updatePeers = helpers.updatePeers
const updateAddrs = helpers.updateAddrs

ipfs.once('ready', () => ipfs.id((err, info) => {
  if (err) { throw err }
  console.log('IPFS node ready with id ' + info.id)

  let room = createRoom(roomName)

  $peerId.innerHTML = `<li>${info.id}</li>`
  updateAddrs(info.addresses)

  $send.addEventListener('click', () => {
    sendMsg(room)
  })

  $room.addEventListener('dblclick', () => {
    $room.setAttribute('style', 'display: none')
    $roomId.setAttribute('style', 'display: inline')
  })

  $roomId.addEventListener('keyup', (event) => {
    const kp = event.keyCode || event.which
    if (kp === 13 && $roomId.value.length > 0) {
      let name = $roomId.value
      $room.innerText = name

      $room.setAttribute('style', 'display: inline')
      $roomId.setAttribute('style', 'display: none')

      $roomId.value = ''
      $msgs.innerHTML = ''
      window.location.hash = name
      room = createRoom(name)
      peersSet.clear()
      updatePeers(peersSet)
    } else if (kp === 27) {
      $roomId.value = ''
      $room.setAttribute('style', 'display: inline')
      $roomId.setAttribute('style', 'display: none')
    }
  })

  $message.addEventListener('keyup', (event) => {
    const kp = event.keyCode || event.which
    if (kp === 13) {
      sendMsg(room)
    }
  })

  $connect.addEventListener('click', () => {
    const peer = $peer.value
    $peer.value = ''
    ipfs.swarm.connect(peer, (err) => {
      if (err) {
        return console.error(err)
      }
      $pAddrs.innerHTML += `<li>${peer.trim()}</li>`
    })
  })
}))

'''
'''--- examples/circuit-relaying/src/helpers.js ---
'use strict'

const Room = require('ipfs-pubsub-room')
const $message = document.querySelector('#message')
const $msgs = document.querySelector('#msgs')
const $addrs = document.querySelector('#addrs')
const $peers = document.querySelector('#peers')

const NAMESPACE = `ipfs-quick-msg`

const mkRoomName = (name) => {
  return `${NAMESPACE}-${name}`
}

module.exports = (ipfs, peersSet) => {
  const createRoom = (name) => {
    const room = Room(ipfs, mkRoomName(name))

    room.on('peer joined', (peer) => {
      console.log('peer ' + peer + ' joined')
      peersSet.add(peer)
      updatePeers()
    })

    room.on('peer left', (peer) => {
      console.log('peer ' + peer + ' left')
      peersSet.delete(peer)
      updatePeers()
    })

    // send and receive messages
    room.on('message', (message) => {
      console.log('got message from ' + message.from + ': ' + message.data.toString())
      const node = document.createElement(`li`)
      node.innerText = `${message.from.substr(-4)}: ${message.data.toString()}`
      $msgs.appendChild(node)
    })

    return room
  }

  const sendMsg = (room) => {
    const msg = $message.value
    if (msg.length > 0) {
      $message.value = ''
      room.broadcast(msg)
      $message.focus()
    }
  }

  const updatePeers = () => {
    const tags = Array.from(peersSet).map((p) => {
      return `<li>${p}</li>`
    })
    $peers.innerHTML = tags
  }

  const updateAddrs = (addrs) => {
    $addrs.innerHTML = `
        <div>
            <ul>
                ${addrs.map((addr) => `<li>${addr.toString()}</li>`)}
            <ul>
        </div>`
  }

  return {
    createRoom,
    sendMsg,
    updatePeers,
    updateAddrs
  }
}

'''
'''--- examples/custom-ipfs-repo/README.md ---
# Customizing the IPFS Repo

This example shows you how to customize your repository, including where your data is stored and how the repo locking is managed. Customizing your repo makes it easier to extend IPFS for your particular needs. You may want to customize your repo if:

* If you want to store data somewhere that’s not on your local disk, like S3, a Redis instance, a different machine on your local network, or in your own database system, like MongoDB or Postgres, you might use a custom datastore.
* If you have multiple browser windows or workers sharing the same IPFS storage, you might want to use a custom lock to coordinate between them. (Locking is currently only used to ensure a single IPFS instance can access a repo at a time. This check is done on `repo.open()`. A more complex lock, coupled with a custom datastore, could allow for safe writes to a single datastore from multiple IPFS nodes.)

You can find full details on customization in the [IPFS Repo Docs](https://github.com/ipfs/js-ipfs-repo#setup).

## Run this example

```
> npm install
> npm start
```

## Other Options

### Custom `storageBackends`
This example leverages [datastore-fs](https://github.com/ipfs/js-datastore-fs) to store all data in the IPFS Repo. You can customize each of the 4 `storageBackends` to meet the needs of your project. For an example on how to manage your entire IPFS REPO on S3, you can see the [datastore-s3 example](https://github.com/ipfs/js-datastore-s3/tree/master/examples/full-s3-repo).

### Custom Repo Lock
This example uses one of the locks that comes with IPFS Repo. If you would like to control how locking happens, such as with a centralized S3 IPFS Repo, you can pass in your own custom lock. See [custom-lock.js](./custom-lock.js) for an example of a custom lock that can be used for [datastore-s3](https://github.com/ipfs/js-datastore-s3). This is also being used in the [full S3 example](https://github.com/ipfs/js-datastore-s3/tree/master/examples/full-s3-repo).

```js
const S3Lock = require('./custom-lock')

const repo = new Repo('/tmp/.ipfs', {
  ...
  lock: new S3Lock(s3DatastoreInstance)
})
```
'''
'''--- examples/custom-ipfs-repo/custom-lock.js ---
'use strict'

const PATH = require('path')

/**
 * Uses an object in an S3 bucket as a lock to signal that an IPFS repo is in use.
 * When the object exists, the repo is in use. You would normally use this to make
 * sure multiple IPFS nodes don’t use the same S3 bucket as a datastore at the same time.
 */
class S3Lock {
  constructor (s3Datastore) {
    this.s3 = s3Datastore
  }

  /**
   * Returns the location of the lock file given the path it should be located at
   *
   * @private
   * @param {string} dir
   * @returns {string}
   */
  getLockfilePath (dir) {
    return PATH.join(dir, 'repo.lock')
  }

  /**
   * Creates the lock. This can be overriden to customize where the lock should be created
   *
   * @param {string} dir
   * @param {function(Error, LockCloser)} callback
   * @returns {void}
   */
  lock (dir, callback) {
    const lockPath = this.getLockfilePath(dir)

    this.locked(dir, (err, alreadyLocked) => {
      if (err || alreadyLocked) {
        return callback(new Error('The repo is already locked'))
      }

      // There's no lock yet, create one
      this.s3.put(lockPath, Buffer.from(''), (err, data) => {
        if (err) {
          return callback(err, null)
        }

        callback(null, this.getCloser(lockPath))
      })
    })
  }

  /**
   * Returns a LockCloser, which has a `close` method for removing the lock located at `lockPath`
   *
   * @param {string} lockPath
   * @returns {LockCloser}
   */
  getCloser (lockPath) {
    return {
      /**
       * Removes the lock. This can be overriden to customize how the lock is removed. This
       * is important for removing any created locks.
       *
       * @param {function(Error)} callback
       * @returns {void}
       */
      close: (callback) => {
        this.s3.delete(lockPath, (err) => {
          if (err && err.statusCode !== 404) {
            return callback(err)
          }

          callback(null)
        })
      }
    }
  }

  /**
   * Calls back on whether or not a lock exists. Override this method to customize how the check is made.
   *
   * @param {string} dir
   * @param {function(Error, boolean)} callback
   * @returns {void}
   */
  locked (dir, callback) {
    this.s3.get(this.getLockfilePath(dir), (err, data) => {
      if (err && err.message.match(/not found/)) {
        return callback(null, false)
      } else if (err) {
        return callback(err)
      }

      callback(null, true)
    })
  }
}

module.exports = S3Lock

'''
'''--- examples/custom-ipfs-repo/index.js ---
'use strict'

const IPFS = require('ipfs')
const Repo = require('ipfs-repo')
const fsLock = require('ipfs-repo/src/lock')

// Create our custom options
const customRepositoryOptions = {

  /**
   * IPFS nodes store different information in separate storageBackends, or datastores.
   * Each storage backend can use the same type of datastore or a different one — you
   * could store your keys in a levelDB database while everything else is in files,
   * for example. (See https://github.com/ipfs/interface-datastore for more about datastores.)
   */
  storageBackends: {
    root: require('datastore-fs'), // version and config data will be saved here
    blocks: require('datastore-fs'),
    keys: require('datastore-fs'),
    datastore: require('datastore-fs')
  },

  /**
   * Storage Backend Options will get passed into the instantiation of their counterpart
   * in `storageBackends`. If you create a custom datastore, this is where you can pass in
   * custom constructor arguments. You can see an S3 datastore example at:
   * https://github.com/ipfs/js-datastore-s3/tree/master/examples/full-s3-repo
   *
   * NOTE: The following options are being overriden for demonstration purposes only.
   * In most instances you can simply use the default options, by not passing in any
   * overrides, which is recommended if you have no need to override.
   */
  storageBackendOptions: {
    root: {
      extension: '.ipfsroot', // Defaults to ''. Used by datastore-fs; Appended to all files
      errorIfExists: false, // Used by datastore-fs; If the datastore exists, don't throw an error
      createIfMissing: true // Used by datastore-fs; If the datastore doesn't exist yet, create it
    },
    blocks: {
      sharding: false, // Used by IPFSRepo Blockstore to determine sharding; Ignored by datastore-fs
      extension: '.ipfsblock', // Defaults to '.data'.
      errorIfExists: false,
      createIfMissing: true
    },
    keys: {
      extension: '.ipfskey', // No extension by default
      errorIfExists: false,
      createIfMissing: true
    },
    datastore: {
      extension: '.ipfsds', // No extension by default
      errorIfExists: false,
      createIfMissing: true
    }
  },

  /**
   * A custom lock can be added here. Or the build in Repo `fs` or `memory` locks can be used.
   * See https://github.com/ipfs/js-ipfs-repo for more details on setting the lock.
   */
  lock: fsLock
}

// Initialize our IPFS node with the custom repo options
const node = new IPFS({
  repo: new Repo('/tmp/custom-repo/.ipfs', customRepositoryOptions)
})

// Test the new repo by adding and fetching some data
node.on('ready', () => {
  console.log('Ready')
  node.version()
    .then((version) => {
      console.log('Version:', version.version)
    })
    // Once we have the version, let's add a file to IPFS
    .then(() => {
      return node.add({
        path: 'test-data.txt',
        content: Buffer.from('We are using a customized repo!')
      })
    })
    // Log out the added files metadata and cat the file from IPFS
    .then((filesAdded) => {
      console.log('\nAdded file:', filesAdded[0].path, filesAdded[0].hash)
      return node.cat(filesAdded[0].hash)
    })
    // Print out the files contents to console
    .then((data) => {
      console.log('\nFetched file content:')
      process.stdout.write(data)
    })
    // Log out the error, if there is one
    .catch((err) => {
      console.log('File Processing Error:', err)
    })
    // After everything is done, shut the node down
    // We don't need to worry about catching errors here
    .then(() => {
      console.log('\n\nStopping the node')
      return node.stop()
    })
    // Let users know where they can inspect the repo
    .then(() => {
      console.log('Check "/tmp/custom-repo/.ipfs" to see what your customized repository looks like on disk.')
    })
})

'''
'''--- examples/custom-ipfs-repo/package.json ---
{
  "name": "custom-ipfs-repo",
  "version": "0.1.0",
  "description": "Customizing your ipfs repo",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node index.js"
  },
  "license": "MIT",
  "dependencies": {
    "datastore-fs": "~0.7.0",
    "ipfs": "file:../../",
    "ipfs-repo": "~0.26.1"
  }
}

'''
'''--- examples/custom-libp2p/README.md ---
# Customizing your libp2p bundle

This example shows you how to make full use of the ipfs configuration to create a libp2p bundle function. As IPFS applications become more complex, their needs for a custom libp2p bundle also grow. Instead of fighting with configuration options, you can use your own libp2p bundle function to get exactly what you need.

## Run this example

Running this example should result in metrics being logged out to the console every few seconds.

```
> npm install
> npm start
```

## Play with the configuration!

With the metrics for peers and bandwidth stats being logged out, try playing around with the nodes configuration to see what kind of metrics you can get. How many peers are you getting? What does your bandwidth look like?

This is also a good opportunity to explore the various stats that ipfs offers! Not seeing a statistic you think would be useful? We'd love to have you [contribute](https://github.com/ipfs/js-ipfs/blob/master/CONTRIBUTING.md)!

'''
'''--- examples/custom-libp2p/index.js ---
'use strict'

const Libp2p = require('libp2p')
const IPFS = require('ipfs')
const TCP = require('libp2p-tcp')
const MulticastDNS = require('libp2p-mdns')
const WebSocketStar = require('libp2p-websocket-star')
const Bootstrap = require('libp2p-bootstrap')
const SPDY = require('libp2p-spdy')
const KadDHT = require('libp2p-kad-dht')
const MPLEX = require('libp2p-mplex')
const SECIO = require('libp2p-secio')
const assert = require('assert')

/**
 * Options for the libp2p bundle
 * @typedef {Object} libp2pBundle~options
 * @property {PeerInfo} peerInfo - The PeerInfo of the IPFS node
 * @property {PeerBook} peerBook - The PeerBook of the IPFS node
 * @property {Object} config - The config of the IPFS node
 * @property {Object} options - The options given to the IPFS node
 */

/**
 * This is the bundle we will use to create our fully customized libp2p bundle.
 *
 * @param {libp2pBundle~options} opts The options to use when generating the libp2p node
 * @returns {Libp2p} Our new libp2p node
 */
const libp2pBundle = (opts) => {
  // Set convenience variables to clearly showcase some of the useful things that are available
  const peerInfo = opts.peerInfo
  const peerBook = opts.peerBook
  const bootstrapList = opts.config.Bootstrap

  // Create our WebSocketStar transport and give it our PeerId, straight from the ipfs node
  const wsstar = new WebSocketStar({
    id: peerInfo.id
  })

  // Build and return our libp2p node
  return new Libp2p({
    peerInfo,
    peerBook,
    // Lets limit the connection managers peers and have it check peer health less frequently
    connectionManager: {
      maxPeers: 25,
      pollInterval: 5000
    },
    modules: {
      transport: [
        TCP,
        wsstar
      ],
      streamMuxer: [
        MPLEX,
        SPDY
      ],
      connEncryption: [
        SECIO
      ],
      peerDiscovery: [
        MulticastDNS,
        Bootstrap,
        wsstar.discovery
      ],
      dht: KadDHT
    },
    config: {
      peerDiscovery: {
        mdns: {
          interval: 10000,
          enabled: true
        },
        bootstrap: {
          interval: 10000,
          enabled: true,
          list: bootstrapList
        }
      },
      // Turn on relay with hop active so we can connect to more peers
      relay: {
        enabled: true,
        hop: {
          enabled: true,
          active: true
        }
      },
      dht: {
        kBucketSize: 20
      },
      EXPERIMENTAL: {
        dht: true,
        pubsub: true
      }
    }
  })
}

// Now that we have our custom libp2p bundle, let's start up the ipfs node!
const node = new IPFS({
  libp2p: libp2pBundle
})

// Listen for the node to start, so we can log out some metrics
node.once('start', (err) => {
  assert.ifError(err, 'Should startup without issue')

  // Lets log out the number of peers we have every 2 seconds
  setInterval(() => {
    node.swarm.peers((err, peers) => {
      if (err) {
        console.log('An error occurred trying to check our peers:', err)
        process.exit(1)
      }
      console.log(`The node now has ${peers.length} peers.`)
    })
  }, 2000)

  // Log out the bandwidth stats every 4 seconds so we can see how our configuration is doing
  setInterval(() => {
    node.stats.bw((err, stats) => {
      if (err) {
        console.log('An error occurred trying to check our stats:', err)
      }
      console.log(`\nBandwidth Stats: ${JSON.stringify(stats, null, 2)}\n`)
    })
  }, 4000)
})

'''
'''--- examples/custom-libp2p/package.json ---
{
  "name": "custom-libp2p",
  "version": "0.1.0",
  "description": "Customizing your libp2p node",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node index.js"
  },
  "license": "MIT",
  "dependencies": {
    "ipfs": "file:../../",
    "libp2p": "~0.24.0",
    "libp2p-bootstrap": "~0.9.3",
    "libp2p-kad-dht": "~0.11.1",
    "libp2p-mdns": "~0.12.0",
    "libp2p-mplex": "~0.8.4",
    "libp2p-secio": "~0.10.1",
    "libp2p-spdy": "~0.13.0",
    "libp2p-tcp": "~0.13.0",
    "libp2p-websocket-star": "~0.9.0"
  }
}

'''
'''--- examples/exchange-files-in-browser/README.md ---
# Exchange files between the browser and other IPFS nodes

This tutorial will help you exchange files between browser nodes and go-ipfs or js-ipfs nodes!

**Note:** As `js-ipfs@0.33.x` currently doesn't support DHT peer discovery, the peer from which you are fetching data should be within the reach (local or in public IP) of the browser node.

That being said, we will explain how to circumvent these caveats and once they are fixed, we'll update the tutorial as well.

## Application diagram

The goal of this tutorial is to create a simple application with an IPFS node that dials to other instances using WebRTC, and at the same time dial and transfer files from a browser IPFS node using WebSockets as the transport.

```
┌──────────────┐                ┌──────────────┐
│   Browser    │ libp2p(WebRTC) │   Browser    │
│              │◀──────────────▶│              │
└──────────────┘                └──────────────┘
       ▲                                  ▲
       │WebSockets              WebSockets│
       │        ┌──────────────┐          │
       │        │   Desktop    │          │
       └───────▶│   Terminal   │◀─────────┘
                └──────────────┘
```

## Tutorial goal

The goal of this tutorial is for you to have something like this in the end:

![](img/goal.png)

## Step-by-step instructions

Here's what we are going to be doing:

1. Install a `go-ipfs` or `js-ipfs` node in your machine
2. Make your daemons listen on WebSockets
3. Start the app
4. Dial to a node using WebSockets (your desktop ones)
5. Transfer files between all of your nodes!

Just follow the instructions below and it will be up and running in no time!

### 1. Install `go-ipfs` or `js-ipfs`

If you already have `go-ipfs` or `js-ipfs` installed in your machine, you can skip this step. Otherwise, read on.

This tutorial works with either `go-ipfs` or `js-ipfs`, so you can install one of your choosing.

`go-ipfs` can be installed via its binary [here](https://ipfs.io/ipns/dist.ipfs.io/#go-ipfs). Alternatively, you can follow the install instructions in [ipfs/go-ipfs](https://github.com/ipfs/go-ipfs#install).

`js-ipfs` requires you to have [node and npm](https://www.npmjs.com/get-npm) installed. Then, you simply run:

```sh
> npm install --global ipfs
```

This will alias `jsipfs` on your machine; this is to avoid issues with `go-ipfs` being called `ipfs`.

At this point, you should have either `js-ipfs` or `go-ipfs` running. Now, initialize it:

```sh
> ipfs init
# or
> jsipfs init
```

This will set up an IPFS repo in your home directory.

### 2. Make your daemons listen on WebSockets

Now you need to edit your `config` file, the one you just set up with `{js}ipfs init`. It should be in either `~/.jsipfs/config` or `~/.ipfs/config`, depending on whether you're using JS or Go.

**Note:** `js-ipfs` sets up a websocket listener by default, so if you're using the JS implementation you can skip this and just start the daemon.

Since websockets support is currently not on by default, you'll need to add a WebSockets address manually. Look into your config file to find the `Addresses` section:

```json
"Addresses": {
  "Swarm": [
    "/ip4/0.0.0.0/tcp/4002"
  ],
  "API": "/ip4/127.0.0.1/tcp/5002",
  "Gateway": "/ip4/127.0.0.1/tcp/9090"
}
```

Add the `/ip4/127.0.0.1/tcp/9999/ws` entry to your `Swarm` array. Now it should look like this:

```json
"Addresses": {
  "Swarm": [
    "/ip4/0.0.0.0/tcp/4002",
    "/ip4/127.0.0.1/tcp/9999/ws"
  ],
  "API": "/ip4/127.0.0.1/tcp/5002",
  "Gateway": "/ip4/127.0.0.1/tcp/9090"
}
```

Save the file and it should be able to listen on Websockets. We're ready to start the daemon.

```sh
> ipfs daemon
# or
> jsipfs daemon
```

You should see the Websocket address in the output:

```sh
Initializing daemon...
Swarm listening on /ip4/127.0.0.1/tcp/4001
Swarm listening on /ip4/127.0.0.1/tcp/9999/ws
Swarm listening on /ip4/192.168.10.38/tcp/4001
Swarm listening on /ip4/192.168.10.38/tcp/9999/ws
API server listening on /ip4/127.0.0.1/tcp/5001
Gateway (readonly) server listening on /ip4/0.0.0.0/tcp/8080
Daemon is ready
```

Check the `/ws` in line 5, that means it is listening. Cool.

### 3. Start the app

Make sure you're in `js-ipfs/examples/exchange-files-in-browser`.

We'll need to install and bundle the dependencies to run the app. Let's do it:

```sh
> npm install
...
> npm run bundle
...
> npm start
```

You should see something like this if all went well:

```sh
Starting up http-server, serving public
Available on:
  http://127.0.0.1:12345
  http://192.168.2.92:12345
Hit CTRL-C to stop the server
```

Now go to http://127.0.0.1:12345 in a modern browser and you're on!

### 4. Dial to a node using WebSockets (your desktop ones)

Make sure you have a daemon running. If you don't, run:

```sh
> ipfs daemon
# or
> jsipfs daemon
```

Open another terminal window to find the websocket addresses that it is listening on:

```sh
> ipfs id
# or
> jsipfs id
```

It should look like this: `/ip4/127.0.0.1/tcp/9999/ws/ipfs/<your_peer_id>`.

Copy and paste the *multiaddr* to connect to that peer:

![](img/connect-1.png)

Check that you got connected:

![](img/connect-2.png)

### 5. Transfer files between all of your nodes!

Now you can add files through the CLI with:

```sh
> ipfs add <file>
# or
> jsipfs add <file>
```

Copy and paste the *multihash* and fetch the file in the browser!

![](img/fetch.png)

You can also open two browser tabs, drag and drop files in one of them, and fetch them in the other!

But the coolest thing about this tutorial is `pubsub`! You can open two tabs that will share files through workspaces named after the url. Try opening two tabs with the following url:

```
http://127.0.0.1:12345/#file-exchange
# You can substitute `file-exchange` with anything you like, just make sure the two tabs are in the same workspace.
```

Now every file that you upload in one tab will appear in the other! You can even open a new tab in that workspace and it will sync the files that were added before!

![](img/pubsub.png)

'''
'''--- examples/exchange-files-in-browser/img/diagram.txt ---
┌──────────────┐                   ┌──────────────┐
│   Browser    │                   │   Browser    │
│              │      WebRTC       │              │
│              │◀─────────────────▶│              │
│              │                   │              │
└──────────────┘                   └──────────────┘
        ▲                                  ▲
        │                                  │
        │                                  │
        │                                  │
        │WebSockets              WebSockets│
        │                                  │
        │                                  │
        │        ┌──────────────┐          │
        │        │   Desktop    │          │
        │        │              │          │
        └───────▶│              │◀─────────┘
                 │              │
                 └──────────────┘
'''
'''--- examples/exchange-files-in-browser/package.json ---
{
  "name": "exchange-files-browser",
  "version": "0.0.0",
  "scripts": {
    "bundle": "browserify public/app.js > public/bundle.js",
    "start": "http-server -c-1 -p 12345 public",
    "dev": "npm run bundle && npm run start"
  },
  "license": "MIT",
  "devDependencies": {
    "browserify": "^16.2.0",
    "http-server": "^0.11.1"
  },
  "dependencies": {
    "ipfs": "file:../../",
    "stream-buffers": "^3.0.1"
  }
}

'''
'''--- examples/exchange-files-in-browser/public/app.css ---

/* ===========================================================================
   Layout
   =========================================================================== */

* {
  box-sizing: border-box;
}

body {
  min-height: 100vh;
  font-family: sans-serif;
  color: #0B3A53;
  background: #141E30; /* Fallback for old browsers */
  background: -webkit-linear-gradient(to top, #243B55, #141E30); /* Chrome 10-25, Safari 5.1-6 */
  background: linear-gradient(to top, #243B55, #141E30); /* W3C, IE 10+/ Edge, Firefox 16+, Chrome 26+, Opera 12+, Safari 7+ */
  pointer-events: auto;
  padding: 0;
  margin: 0;
}

h1, h2, h3 {
  margin: 0;
}

h1 {
  font-size: 2em;
  font-weight: 300;
}

h2 {
  font-size: 1.25em;
  font-weight: 700;
}

h3 {
  font-size: 1.0em;
  font-weight: 700;
}

header {
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 2em 0;
}

main {
    width: 90%;
    margin: 0 auto;
}

.columns {
  display: flex;
  justify-content: space-between;
}

/* ===========================================================================
   Buttons & Inputs
   =========================================================================== */

button {
  padding: 0.625em 1.5em;
  border: 2px solid #69C4CD;
  border-radius: 2px;
  background-color: #69C4CD;
  color: #FFF;
  font-size: 0.9em;
  cursor: pointer;
  outline: none;
}

button:hover {
  opacity: 0.9;
}

input {
  width: 100%;
  margin-right: 3px;
  padding: 0.7em;
  border: 2px solid rgba(0, 0, 0, 0.2);
  border-radius: 2px;
  color: #000;
  outline: none;
}

input:hover,
input:focus,
input:active {
  border-color: #69C4CD;
}

.input-button {
  display: flex;
}

.disabled *,
input:disabled,
button:disabled {
  opacity: 0.2;
}

/* ===========================================================================
   Tables
   =========================================================================== */

table {
  width: 100%;
  margin: 1em 0;
  padding: 1em;
  border-spacing: 0;
  background-color: #FFF;
  word-break: break-all;
}

table th,
table td {
  padding: 1em;
  font-size: 0.8em;
  text-align: left;
  font-weight: normal;
}

table th {
  padding-top: 0;
  font-size: 0.7em;
  text-transform: uppercase;
  opacity: 0.5;
}

table tbody tr:nth-child(odd) {
  background-color: #F7F8FA;
}

table tbody tr:hover {
  background-color: rgb(100, 196, 205);
  background-color: rgba(100, 196, 205, 0.2);
}

.table-action {
  opacity: 0.5;
}

.table-action:hover {
  opacity: 1;
}

/* ===========================================================================
   Box
   =========================================================================== */

.box {
  display: flex;
  flex-direction: column;
  margin-bottom: 1em;
  padding: 1em;
  border-radius: 2px;
  background-color: #F7F8FA;
}

.box > h2 {
  display: block;
  border-bottom: 1px solid #B7BBC8;
  text-align: center;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
}

/* Node
   =========================================================================== */

.box.node > div {
  display: flex;
  margin-bottom: 1em;
}

.box.node > div:last-child {
  margin-bottom: 0;
}

.box.node > div > h3 {
  flex: 0 0 15%;
}

.box.node > div pre,
.box.node > div > ul {
  flex: 0 0 85%;
  margin: 0;
}

.box.node ul {
  margin: 0;
  padding: 0;
  list-style: none;
}

.node-addresses li {
  margin-bottom: 0.5em;
  font-size: 0.7em;
  word-wrap: break-word;
}

#logs {
  margin: 0;
  color: #EA5037;
}

#logs.success {
    color: #0CB892;
}

/* Peers
   =========================================================================== */

#peers {
  flex: 0 0 calc(35% - 1em);
}

/* Files
   =========================================================================== */

#files {
  flex: 0 0 65%;
  min-height: 500px;
}

#file-status {
  font-style: italic;
  color: #6ACAD1;
  font-size: 0.8em;
  margin: 1em 0;
}

#files table th:nth-child(1),
#files table td:nth-child(1) {
  width: 35%;
}

#files table th:nth-child(2),
#files table td:nth-child(2) {
  width: 50%;
}

#files table th:nth-child(3),
#files table td:nth-child(3) {
  width: 15%;
}

#files .empty-row td {
  text-align: center;
  opacity: 0.5;
}

#drag-container {
  height: 10em;
  margin-top: 1em;
  display: flex;
  justify-content: center;
  align-items: center;
  border: 1px dashed;
  border-radius: 2px;
  opacity: 0.7;
}

#drag-container.dragging {
  background-color: #E7E8EE;
  opacity: 1;

}

#drag-container p {
  margin-left: 1em;
}

#progress-container {
  margin-top: 1em;
  border-radius: 0.5em;
  background-color: #0B3A53;
  overflow-x: hidden;
}

#progress-bar {
  height: 1em;
  border-radius: 0.5em;
  background-color: #6ACAD1;
  transform: translateX(-100%);
}

/* ===========================================================================
   Responsiveness
   =========================================================================== */

@media (max-width: 768px) {
  .columns {
    flex-direction: column-reverse;
  }
}

'''
'''--- examples/exchange-files-in-browser/public/app.js ---
/* global location */
'use strict'

const IPFS = require('ipfs')

// Node
const $nodeId = document.querySelector('.node-id')
const $nodeAddresses = document.querySelector('.node-addresses')
const $logs = document.querySelector('#logs')
// Peers
const $peers = document.querySelector('#peers')
const $peersList = $peers.querySelector('tbody')
const $multiaddrInput = document.querySelector('#multiaddr-input')
const $connectButton = document.querySelector('#peer-btn')
// Files
const $multihashInput = document.querySelector('#multihash-input')
const $fetchButton = document.querySelector('#fetch-btn')
const $dragContainer = document.querySelector('#drag-container')
const $progressBar = document.querySelector('#progress-bar')
const $fileHistory = document.querySelector('#file-history tbody')
const $emptyRow = document.querySelector('.empty-row')
// Misc
const $allDisabledButtons = document.querySelectorAll('button:disabled')
const $allDisabledInputs = document.querySelectorAll('input:disabled')
const $allDisabledElements = document.querySelectorAll('.disabled')

const FILES = []
const workspace = location.hash

let fileSize = 0

let node
let info
let Buffer

/* ===========================================================================
   Start the IPFS node
   =========================================================================== */

function start () {
  if (!node) {
    const options = {
      EXPERIMENTAL: {
        pubsub: true
      },
      repo: 'ipfs-' + Math.random(),
      config: {
        Addresses: {
          Swarm: ['/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star']
        }
      }
    }

    node = new IPFS(options)

    Buffer = node.types.Buffer

    node.once('start', () => {
      node.id()
        .then((id) => {
          info = id
          updateView('ready', node)
          onSuccess('Node is ready.')
          setInterval(refreshPeerList, 1000)
          setInterval(sendFileList, 10000)
        })
        .catch((error) => onError(error))

      subscribeToWorkpsace()
    })
  }
}

/* ===========================================================================
   Pubsub
   =========================================================================== */

const messageHandler = (message) => {
  const myNode = info.id
  const hash = message.data.toString()
  const messageSender = message.from

  // append new files when someone uploads them
  if (myNode !== messageSender && !isFileInList(hash)) {
    $multihashInput.value = hash
    getFile()
  }
}

const subscribeToWorkpsace = () => {
  node.pubsub.subscribe(workspace, messageHandler)
    .catch(() => onError('An error occurred when subscribing to the workspace.'))
}

const publishHash = (hash) => {
  const data = Buffer.from(hash)

  node.pubsub.publish(workspace, data)
    .catch(() => onError('An error occurred when publishing the message.'))
}

/* ===========================================================================
   Files handling
   =========================================================================== */

const isFileInList = (hash) => FILES.indexOf(hash) !== -1

const sendFileList = () => FILES.forEach((hash) => publishHash(hash))

const updateProgress = (bytesLoaded) => {
  let percent = 100 - ((bytesLoaded / fileSize) * 100)

  $progressBar.style.transform = `translateX(${-percent}%)`
}

const resetProgress = () => {
  $progressBar.style.transform = 'translateX(-100%)'
}

function appendFile (name, hash, size, data) {
  const file = new window.Blob([data], { type: 'application/octet-binary' })
  const url = window.URL.createObjectURL(file)
  const row = document.createElement('tr')

  const nameCell = document.createElement('td')
  nameCell.innerHTML = name

  const hashCell = document.createElement('td')
  hashCell.innerHTML = hash

  const sizeCell = document.createElement('td')
  sizeCell.innerText = size

  const downloadCell = document.createElement('td')
  const link = document.createElement('a')
  link.setAttribute('href', url)
  link.setAttribute('download', name)
  link.innerHTML = '<img width=20 class="table-action" src="assets/download.svg" alt="Download" />'
  downloadCell.appendChild(link)

  row.appendChild(nameCell)
  row.appendChild(hashCell)
  row.appendChild(sizeCell)
  row.appendChild(downloadCell)

  $fileHistory.insertBefore(row, $fileHistory.firstChild)

  publishHash(hash)
}

function getFile () {
  const hash = $multihashInput.value

  $multihashInput.value = ''

  if (!hash) {
    return onError('No multihash was inserted.')
  } else if (isFileInList(hash)) {
    return onSuccess('The file is already in the current workspace.')
  }

  FILES.push(hash)

  node.get(hash)
    .then((files) => {
      files.forEach((file) => {
        if (file.content) {
          appendFile(file.name, hash, file.size, file.content)
          onSuccess(`The ${file.name} file was added.`)
          $emptyRow.style.display = 'none'
        }
      })
    })
    .catch(() => onError('An error occurred when fetching the files.'))
}

/* Drag & Drop
   =========================================================================== */

const onDragEnter = () => $dragContainer.classList.add('dragging')

const onDragLeave = () => $dragContainer.classList.remove('dragging')

function onDrop (event) {
  onDragLeave()
  event.preventDefault()

  const dt = event.dataTransfer
  const filesDropped = dt.files

  function readFileContents (file) {
    return new Promise((resolve) => {
      const reader = new window.FileReader()
      reader.onload = (event) => resolve(event.target.result)
      reader.readAsArrayBuffer(file)
    })
  }

  const files = []
  for (let i = 0; i < filesDropped.length; i++) {
    files.push(filesDropped[i])
  }

  files.forEach((file) => {
    readFileContents(file)
      .then((buffer) => {
        fileSize = file.size

        node.add({
          path: file.name,
          content: Buffer.from(buffer)
        }, { wrap: true, progress: updateProgress }, (err, filesAdded) => {
          if (err) {
            return onError(err)
          }

          // As we are wrapping the content we use that hash to keep
          // the original file name when adding it to the table
          $multihashInput.value = filesAdded[1].hash

          resetProgress()
          getFile()
        })
      })
      .catch(onError)
  })
}

/* ===========================================================================
   Peers handling
   =========================================================================== */

function connectToPeer (event) {
  const multiaddr = $multiaddrInput.value

  if (!multiaddr) {
    return onError('No multiaddr was inserted.')
  }

  node.swarm.connect(multiaddr)
    .then(() => {
      onSuccess(`Successfully connected to peer.`)
      $multiaddrInput.value = ''
    })
    .catch(() => onError('An error occurred when connecting to the peer.'))
}

function refreshPeerList () {
  node.swarm.peers()
    .then((peers) => {
      const peersAsHtml = peers.reverse()
        .map((peer) => {
          if (peer.addr) {
            const addr = peer.addr.toString()
            if (addr.indexOf('ipfs') >= 0) {
              return addr
            } else {
              return addr + peer.peer.id.toB58String()
            }
          }
        })
        .map((addr) => {
          return `<tr><td>${addr}</td></tr>`
        }).join('')

      $peersList.innerHTML = peersAsHtml
    })
    .catch((error) => onError(error))
}

/* ===========================================================================
   Error handling
   =========================================================================== */

function onSuccess (msg) {
  $logs.classList.add('success')
  $logs.innerHTML = msg
}

function onError (err) {
  let msg = 'An error occured, check the dev console'

  if (err.stack !== undefined) {
    msg = err.stack
  } else if (typeof err === 'string') {
    msg = err
  }

  $logs.classList.remove('success')
  $logs.innerHTML = msg
}

window.onerror = onError

/* ===========================================================================
   App states
   =========================================================================== */

const states = {
  ready: () => {
    const addressesHtml = info.addresses.map((address) => {
      return `<li><pre>${address}</pre></li>`
    }).join('')
    $nodeId.innerText = info.id
    $nodeAddresses.innerHTML = addressesHtml
    $allDisabledButtons.forEach(b => { b.disabled = false })
    $allDisabledInputs.forEach(b => { b.disabled = false })
    $allDisabledElements.forEach(el => { el.classList.remove('disabled') })
  }
}

function updateView (state, ipfs) {
  if (states[state] !== undefined) {
    states[state]()
  } else {
    throw new Error('Could not find state "' + state + '"')
  }
}

/* ===========================================================================
   Boot the app
   =========================================================================== */

const startApplication = () => {
  // Setup event listeners
  $dragContainer.addEventListener('dragenter', onDragEnter)
  $dragContainer.addEventListener('dragover', onDragEnter)
  $dragContainer.addEventListener('drop', onDrop)
  $dragContainer.addEventListener('dragleave', onDragLeave)
  $fetchButton.addEventListener('click', getFile)
  $connectButton.addEventListener('click', connectToPeer)

  start()
}

startApplication()

'''
'''--- examples/exchange-files-in-browser/public/assets/download.svg ---
<?xml version="1.0" encoding="iso-8859-1"?>
<!-- Generator: Adobe Illustrator 19.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 490.4 490.4" style="enable-background:new 0 0 490.4 490.4;" xml:space="preserve">
<g>
	<g>
		<path d="M490.4,245.2C490.4,110,380.4,0,245.2,0S0,110,0,245.2s110,245.2,245.2,245.2S490.4,380.4,490.4,245.2z M24.5,245.2
			c0-121.7,99-220.7,220.7-220.7s220.7,99,220.7,220.7s-99,220.7-220.7,220.7S24.5,366.9,24.5,245.2z" fill="#0B3A53" />
		<path d="M253.9,360.4l68.9-68.9c4.8-4.8,4.8-12.5,0-17.3s-12.5-4.8-17.3,0l-48,48V138.7c0-6.8-5.5-12.3-12.3-12.3
			s-12.3,5.5-12.3,12.3v183.4l-48-48c-4.8-4.8-12.5-4.8-17.3,0s-4.8,12.5,0,17.3l68.9,68.9c2.4,2.4,5.5,3.6,8.7,3.6
			S251.5,362.8,253.9,360.4z" fill="#0B3A53"/>
	</g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
</svg>

'''
'''--- examples/exchange-files-in-browser/public/assets/ipfs-logo.svg ---
<svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 553 235.3"><defs><style>.cls-1{fill:#fff;}.cls-2{fill:#469ea2;}.cls-3{fill:#6acad1;}.cls-4,.cls-5{fill:#083b54;}.cls-4{fill-opacity:0.15;}.cls-5{fill-opacity:0.05;}</style></defs><title>IPFS logo (new)</title><path class="cls-1" d="M239,63h17.8V168H239V63Z"/><path class="cls-1" d="M274.6,63h36.3c7.9,0,14.5.9,19.6,2.6s9.2,4.1,12.1,7.1a24.45,24.45,0,0,1,6.2,10.2A40.75,40.75,0,0,1,350.6,95a45.69,45.69,0,0,1-1.8,12.9,26.58,26.58,0,0,1-6.2,10.8,30.59,30.59,0,0,1-12.1,7.3c-5.1,1.8-11.5,2.7-19.3,2.7H292.1V168H274.6V63Zm36.2,51a38.37,38.37,0,0,0,11.1-1.3,16.3,16.3,0,0,0,6.8-3.7,13.34,13.34,0,0,0,3.5-5.8,29.75,29.75,0,0,0,1-7.6,25.68,25.68,0,0,0-1-7.7,12,12,0,0,0-3.6-5.5,17.15,17.15,0,0,0-6.9-3.4,41.58,41.58,0,0,0-10.9-1.2H292.3V114h18.5Z"/><path class="cls-1" d="M430.7,63V78.3H381.5V108h46.3v15.4H381.5V168H363.7V63h67Z"/><path class="cls-1" d="M456.9,135.9c0.8,6.9,3.3,11.9,7.4,15s10.4,4.7,18.6,4.7a32.61,32.61,0,0,0,10.1-1.3,20.52,20.52,0,0,0,6.6-3.5,12,12,0,0,0,3.5-5.2,19.08,19.08,0,0,0,1-6.4,16.14,16.14,0,0,0-.7-4.9,12.87,12.87,0,0,0-2.6-4.5,16.59,16.59,0,0,0-5.1-3.6,35,35,0,0,0-8.2-2.4l-13.4-2.5a89.76,89.76,0,0,1-14.1-3.7,33.51,33.51,0,0,1-10.4-5.8,22.28,22.28,0,0,1-6.3-8.8,34.1,34.1,0,0,1-2.1-12.7,26,26,0,0,1,11.3-22.4,36.35,36.35,0,0,1,12.6-5.6,65.89,65.89,0,0,1,15.8-1.8c7.2,0,13.3.8,18.2,2.5A34.46,34.46,0,0,1,511,69.5a28.21,28.21,0,0,1,6.9,9.3,42.1,42.1,0,0,1,3.2,11l-16.8,2.6c-1.4-5.9-3.7-10.2-7.1-13.1S488.5,75,481.1,75a43.9,43.9,0,0,0-10.5,1.1,19.47,19.47,0,0,0-6.8,3.1,11.63,11.63,0,0,0-3.7,4.6,14.08,14.08,0,0,0-1.1,5.4c0,4.6,1.2,8,3.7,10.3s6.9,4,13.2,5.3l14.5,2.8c11.1,2.1,19.2,5.6,24.4,10.5s7.8,12.1,7.8,21.4a31.37,31.37,0,0,1-2.4,12.3,25.27,25.27,0,0,1-7.4,9.8,36.58,36.58,0,0,1-12.4,6.6,56,56,0,0,1-17.3,2.4c-13.4,0-24-2.8-31.6-8.5s-11.9-14.4-12.6-26.2h18Z"/><path class="cls-2" d="M30.3,164l84,48.5,84-48.5V67l-84-48.5L30.3,67v97Z"/><path class="cls-3" d="M105.7,30.1l-61,35.2a18.19,18.19,0,0,1,0,3.3l60.9,35.2a14.55,14.55,0,0,1,17.3,0l60.9-35.2a18.19,18.19,0,0,1,0-3.3L123,30.1a14.55,14.55,0,0,1-17.3,0h0Zm84,48.2-61,35.6a14.73,14.73,0,0,1-8.6,15l0.1,70a15.57,15.57,0,0,1,2.8,1.6l60.9-35.2a14.73,14.73,0,0,1,8.6-15V79.9a20,20,0,0,1-2.8-1.6h0Zm-150.8.4a15.57,15.57,0,0,1-2.8,1.6v70.4a14.38,14.38,0,0,1,8.6,15l60.9,35.2a15.57,15.57,0,0,1,2.8-1.6V128.9a14.38,14.38,0,0,1-8.6-15L38.9,78.7h0Z"/><path class="cls-2" d="M114.3,29l75.1,43.4v86.7l-75.1,43.4L39.2,159.1V72.3L114.3,29m0-10.3-84,48.5v97l84,48.5,84-48.5v-97l-84-48.5h0Z"/><path class="cls-2" d="M114.9,132h-1.2A15.66,15.66,0,0,1,98,116.3v-1.2a15.66,15.66,0,0,1,15.7-15.7h1.2a15.66,15.66,0,0,1,15.7,15.7v1.2A15.66,15.66,0,0,1,114.9,132Z"/><path class="cls-2" d="M114.9,196.5h-1.2a15.65,15.65,0,0,0-13.7,8l14.3,8.2,14.3-8.2a15.65,15.65,0,0,0-13.7-8h0Z"/><path class="cls-2" d="M198.4,148h-0.6a15.66,15.66,0,0,0-15.7,15.7v1.2a15.13,15.13,0,0,0,2,7.6l14.3-8.3V148h0Z"/><path class="cls-2" d="M184.1,59a15.4,15.4,0,0,0-2,7.6v1.2a15.66,15.66,0,0,0,15.7,15.7h0.6V67.2L184.1,59h0Z"/><path class="cls-2" d="M114.3,18.7L100,26.9A15.73,15.73,0,0,0,113.7,35h1.2a15.65,15.65,0,0,0,13.7-8l-14.3-8.3h0Z"/><path class="cls-2" d="M44.6,58.9L30.3,67.2V83.5h0.6A15.66,15.66,0,0,0,46.6,67.8V66.6a16.63,16.63,0,0,0-2-7.7h0Z"/><path class="cls-2" d="M30.9,148H30.3v16.2l14.3,8.3a15.4,15.4,0,0,0,2-7.6v-1.2A15.66,15.66,0,0,0,30.9,148h0Z"/><path class="cls-4" d="M114.3,213.2V116.1l-84-48.5v97.1Z"/><path class="cls-5" d="M198.4,163.8v-97l-84,48.5v97.1Z"/></svg>
'''
'''--- examples/exchange-files-in-browser/public/assets/upload.svg ---
<?xml version="1.0" encoding="iso-8859-1"?>
<!-- Generator: Adobe Illustrator 19.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="Capa_1" x="0px" y="0px" viewBox="0 0 294.156 294.156" style="enable-background:new 0 0 294.156 294.156;" xml:space="preserve" width="512px" height="512px">
<g>
	<path d="M227.002,108.256c-2.755-41.751-37.6-74.878-80.036-74.878c-42.447,0-77.298,33.141-80.038,74.907   C28.978,113.059,0,145.39,0,184.184c0,42.234,34.36,76.595,76.595,76.595h116.483c3.313,0,6-2.687,6-6s-2.687-6-6-6H76.595   C40.977,248.778,12,219.801,12,184.184c0-34.275,26.833-62.568,61.087-64.411c3.184-0.171,5.678-2.803,5.678-5.991   c0-0.119-0.003-0.236-0.01-0.355c0.09-37.536,30.654-68.049,68.211-68.049c37.563,0,68.132,30.518,68.211,68.063   c-0.005,0.116-0.009,0.238-0.009,0.329c0,3.196,2.505,5.831,5.696,5.992c34.37,1.741,61.292,30.038,61.292,64.421   c0,19.526-8.698,37.801-23.864,50.138c-2.571,2.091-2.959,5.87-0.868,8.44c2.091,2.571,5.87,2.959,8.44,0.868   c17.98-14.626,28.292-36.293,28.292-59.447C294.156,145.269,265.08,112.926,227.002,108.256z" fill="#0B3A53"/>
	<path d="M140.966,141.078v76.511c0,3.313,2.687,6,6,6s6-2.687,6-6v-76.511c0-3.313-2.687-6-6-6S140.966,137.765,140.966,141.078z" fill="#0B3A53"/>
	<path d="M181.283,152.204c1.536,0,3.071-0.586,4.243-1.757c2.343-2.343,2.343-6.142,0-8.485l-34.317-34.317   c-2.343-2.343-6.143-2.343-8.485,0l-34.317,34.317c-2.343,2.343-2.343,6.142,0,8.485c2.343,2.343,6.143,2.343,8.485,0   l30.074-30.074l30.074,30.074C178.212,151.618,179.748,152.204,181.283,152.204z" fill="#0B3A53"/>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
</svg>

'''
'''--- examples/exchange-files-in-browser/public/index.html ---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="app.css">
    <title>IPFS - Exchange Files</title>
  </head>

  <body ondragover="event.preventDefault()">
    <header>
      <img width=200 src="assets/ipfs-logo.svg" alt="IPFS" />
    </header>

    <main>
      <div class="box node">
        <h2>Node</h2>

        <div>
          <h3>ID</h3>
          <pre class="node-id"></pre>
        </div>

        <div>
          <h3>Addresses</h3>
          <ul class="node-addresses"></ul>
        </div>

        <div>
          <h3>Logs</h3>
          <div>
            <pre id="logs" class="success">Initializing node...</pre>
          </div>
        </div>
      </div>

      <div class="columns">
        <div id="peers" class="box disabled">
          <h2>Peers</h2>

          <div class="input-button">
            <input id="multiaddr-input" type="text" placeholder="Multiaddr" disabled />
            <button id="peer-btn" disabled>Connect</button>
          </div>

          <table>
            <thead>
              <tr>
                <th>Connected Peers</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>

        <div id="files" class="box disabled" ondragover="event.preventDefault()">
          <h2>Files</h2>

          <div class="input-button">
            <input id="multihash-input" type="text" placeholder="Multihash" disabled />
            <button id="fetch-btn" type="button" disabled>Fetch</button>
          </div>

          <div id="drag-container">
            <img width=100 src="assets/upload.svg" alt="Upload" />
            <p><b>Drag &amp; drop</b> a file to upload it.</p>
          </div>

          <div id="progress-container">
            <div id="progress-bar"></div>
          </div>

          <table id="file-history">
            <thead>
              <tr>
                <th>Name</th>
                <th>CID</th>
                <th>Size</th>
              </tr>
            </thead>
            <tbody>
              <tr class="empty-row">
                <td colspan="4">There are no files in this workspace.</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </main>

    <!-- The app bundled with IPFS -->
    <script src="bundle.js"></script>
  </body>
</html>

'''
'''--- examples/explore-ethereum-blockchain/README.md ---
# Use IPFS to explore the Ethereum Blockchain

> This is a pre-example to a full Ethereum to IPFS bridge. It shows how to resolve Ethereum hashes through the IPFS DAG get API.

## Set up

Make sure to have the latest js-ipfs installed by doing

```sh
> npm install ipfs -g
```

If this is the first time you use js-ipfs, make sure to init your repo with

```sh
> jsipfs init
```

## Load ethereum chain data into ipfs

We've some ethereum blocks available at [eth-stuffs](./eth-stuffs) folder, you can add them to ipfs by running:

```sh
> ./load-eth-stuffs.sh
z43AaGEvwdfzjrCZ3Sq7DKxdDHrwoaPQDtqF4jfdkNEVTiqGVFW
z43AaGEywSDX5PUJcrn5GfZmb6FjisJyR7uahhWPk456f7k7LDA
z43AaGF42R2DXsU65bNnHRCypLPr9sg6D7CUws5raiqATVaB1jj
z45oqTS2AQ9SgyVa31LRGZgfibtdoPvP2miMNaXbDLLgD9MdAAr
z45oqTS8wZaNGU2eepKHRbXvmV93cKQbiL241RB3bRtMYZP8hNm
z45oqTS8wZaNGU2eepKHRbXvmV93cKQbiL241RB3bRtMYZP8hNm
z45oqTS4E1GeJujnKVJG3xSVnS64A8mMCWhKSkCWACNCeD95mtQ
z45oqTS4MnurEeEaanvFieeJDNHH3jGNk9NJEiyrwXwYQSWfxUB
z45oqTRwExySeMeivsU1Y9UdzWDp2mx71TtQhmTGzRaXCcsNujj
z45oqTRzb9a5xyvx5RbfSXH1K5jibyZ4AxnXyYReuLw7KU5veYw
```

## Explore these blocks using the DAG API

NOTE: Currently your js-ipfs daemon must NOT be running for the following examples to work.

Some examples

```sh
> jsipfs dag get z43AaGEvwdfzjrCZ3Sq7DKxdDHrwoaPQDtqF4jfdkNEVTiqGVFW/
> jsipfs dag get z43AaGEvwdfzjrCZ3Sq7DKxdDHrwoaPQDtqF4jfdkNEVTiqGVFW/parentHash
...
```

'''
'''--- examples/explore-ethereum-blockchain/load-eth-stuffs.sh ---
# Blocks
jsipfs block put --format=eth-block --mhtype=keccak-256 eth-stuffs/block_302515
jsipfs block put --format=eth-block --mhtype=keccak-256 eth-stuffs/block_302516
jsipfs block put --format=eth-block --mhtype=keccak-256 eth-stuffs/block_302517

# State Trie
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_000017_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_00001_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_00001_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_000_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_00_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_0_302516
jsipfs block put --format=eth-state-trie --mhtype=keccak-256 eth-stuffs/state_r_302516

'''
'''--- examples/ipfs-101/1.js ---
'use strict'

const IPFS = require('ipfs')

const node = new IPFS()

node.on('ready', async () => {
  const version = await node.version()

  console.log('Version:', version.version)

  const filesAdded = await node.add({
    path: 'hello.txt',
    content: Buffer.from('Hello World 101')
  })

  console.log('Added file:', filesAdded[0].path, filesAdded[0].hash)

  const fileBuffer = await node.cat(filesAdded[0].hash)

  console.log('Added file contents:', fileBuffer.toString())
})

'''
'''--- examples/ipfs-101/README.md ---
# IPFS 101, spawn a node and add a file to the IPFS network

In this tutorial, we go through spawning an IPFS node, adding a file and cat'ing the file multihash locally and through the gateway.

You can find a complete version of this tutorial in [1.js](./1.js). For this tutorial, you need to install `ipfs` using `npm install ipfs`.

Creating an IPFS instance can be done in one line, after requiring the module, you simply have to:

```js
const IPFS = require('ipfs')

const node = new IPFS()
```

We can listen for the `ready` event to learn when the node is ready to be used. Within the ready event, we'll use `async`/`await` to help us manage the async flow.

As a test, we are going to check the version of the node.

```js
const IPFS = require('ipfs')

const node = new IPFS()

node.on('ready', async () => {
  const version = await node.version()

  console.log('Version:', version.version)
})
```

(If you prefer not to use `async`/`await`, you can instead use `.then()` as you would with any promise,
or pass an [error-first callback](https://nodejs.org/api/errors.html#errors_error_first_callbacks), e.g. `node.version((err, version) => { ... })`)

Running the code above gets you:

```bash
> node 1.js
Version: 0.31.2
```

Now let's make it more interesting and add a file to IPFS using `node.add`. A file consists of a path and content.

You can learn about the IPFS File API at [interface-ipfs-core](https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/FILES.md).

```js
node.on('ready', async () => {
  const version = await node.version()

  console.log('Version:', version.version)

  const filesAdded = await node.add({
    path: 'hello.txt',
    content: Buffer.from('Hello World 101')
  })

  console.log('Added file:', filesAdded[0].path, filesAdded[0].hash)
})
```

You can now go to an IPFS Gateway and load the printed hash from a gateway. Go ahead and try it!

```bash
> node 1.js
Version: 0.31.2

Added file: hello.txt QmXgZAUWd8yo4tvjBETqzUy3wLx5YRzuDwUQnBwRGrAmAo
# Copy that hash and load it on the gateway, here is a prefiled url:
# https://ipfs.io/ipfs/QmXgZAUWd8yo4tvjBETqzUy3wLx5YRzuDwUQnBwRGrAmAo
```

The last step of this tutorial is retrieving the file back using the `cat` 😺 call.

```js
node.on('ready', async () => {
  const version = await node.version()

  console.log('Version:', version.version)

  const filesAdded = await node.add({
    path: 'hello.txt',
    content: Buffer.from('Hello World 101')
  })

  console.log('Added file:', filesAdded[0].path, filesAdded[0].hash)

  const fileBuffer = await node.cat(filesAdded[0].hash)

  console.log('Added file contents:', fileBuffer.toString())
})
```

That's it! You just added and retrieved a file from the Distributed Web!

'''
'''--- examples/ipfs-101/hello.txt ---
Hello, how are you today? Welcome to the Distributed Web!

'''
'''--- examples/ipfs-101/package.json ---
{
  "name": "ipfs-101",
  "version": "0.0.0",
  "description": "this package.json needs to exist because of new npm config https://github.com/ipfs/js-ipfs/issues/977#issuecomment-326741092",
  "main": "1.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "David Dias <daviddias@ipfs.io>",
  "license": "MIT",
  "dependencies": {
    "ipfs": "file:../../"
  }
}

'''
'''--- examples/run-in-electron/README.md ---
# js-ipfs in Electron

> This example is heavily inspired by [electron-quick-start](https://github.com/electron/electron-quick-start).

To try it by yourself, do:

```
> npm install
> ./node_modules/.bin/electron-rebuild
# or 
> ./build.sh
#
# You can also try to use `npm start` to see where electron errors
```

'''
'''--- examples/run-in-electron/build.sh ---
# Electron's version.
export npm_config_target=2.0.0
# The architecture of Electron, can be ia32 or x64.
export npm_config_arch=x64
export npm_config_target_arch=x64
# Download headers for Electron.
export npm_config_disturl=https://atom.io/download/electron
# Tell node-pre-gyp that we are building for Electron.
export npm_config_runtime=electron
# Tell node-pre-gyp to build module from source code.
export npm_config_build_from_source=true
# Install all dependencies, and store cache to ~/.electron-gyp.
HOME=~/.electron-gyp npm install

'''
'''--- examples/run-in-electron/index.html ---
<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>IPFS</title>
  </head>
  <body>
    <h1>IPFS in electron!</h1>
    <h2>now check your console</h2>
    <script>require('./renderer.js')</script>
  </body>
</html>

'''
'''--- examples/run-in-electron/main.js ---
'use strict'

const electron = require('electron')
const app = electron.app
const BrowserWindow = electron.BrowserWindow

const IPFS = require('ipfs')
const path = require('path')
const url = require('url')

let mainWindow

function createWindow () {
  mainWindow = new BrowserWindow({ width: 800, height: 600 })

  // and load the index.html of the app.
  mainWindow.loadURL(url.format({
    pathname: path.join(__dirname, 'index.html'),
    protocol: 'file:',
    slashes: true
  }))

  // Open the DevTools.
  mainWindow.webContents.openDevTools()

  // Emitted when the window is closed.
  mainWindow.on('closed', () => {
    mainWindow = null
  })
}

app.on('ready', () => {
  createWindow()

  // Spawn your IPFS node \o/
  const node = new IPFS()

  node.on('ready', () => {
    node.id((err, id) => {
      if (err) {
        return console.log(err)
      }
      console.log(id)
    })
  })
})

// Quit when all windows are closed.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') { app.quit() }
})

app.on('activate', () => {
  if (mainWindow === null) { createWindow() }
})

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and require them here.

'''
'''--- examples/run-in-electron/package.json ---
{
  "name": "js-ipfs-in-electron",
  "version": "0.0.0",
  "description": "A minimal Electron application with js-ipfs",
  "main": "main.js",
  "scripts": {
    "start": "electron .",
    "postinstall": "electron-rebuild"
  },
  "keywords": [
    "Electron",
    "IPFS",
    "Example"
  ],
  "author": "David Dias <daviddias@ipfs.io>",
  "license": "MIT",
  "devDependencies": {
    "electron": "^2.0.0",
    "electron-rebuild": "^1.7.2",
    "ipfs": "ipfs/js-ipfs"
  }
}

'''
'''--- examples/run-in-electron/renderer.js ---

'''
'''--- examples/traverse-ipld-graphs/README.md ---
Resolve through IPLD graphs with the dag API
============================================

IPLD stands for [`InterPlanetary Linked-Data`](https://ipld.io/), it is the data model of the content-addressable web. It gives IPFS the ability to resolve through any kind of content-addressed graph, as long as the [adapter for the format is available](https://github.com/ipld/interface-ipld-format#modules-that-implement-the-interface).

This tutorial goes through several operations over IPLD graphs using the [DAG API](https://github.com/ipfs/interface-ipfs-core/tree/master/API/dag).

## [create nodes to build a graph](./put.js)

## [retrieve a node from a graph](./get.js)

## [resolve a path in a graph](./get-path.js)

## [resolve through graphs of different kind](./get-path-accross-formats.js)

## [explore a graph with the .tree](./tree.js)

## [traverse through a slice of the ethereum blockchain](./eth.js)

## [traverse through a git repo](./git.js)
The example objects contained in "git-objects" have already been decompressed with zlib.  An example of how to do this:

    $ cat .git/objects/7d/df25817f57c2090a9568cdb17106a76dad7d04 | zlib-flate -uncompress > 7ddf25817f57c2090a9568cdb17106a76dad7d04 

## Video of the demos

Find a video with a walkthrough of this examples on Youtube:

[![](https://ipfs.io/ipfs/QmYkeiPtVTR8TdgBNa4u46RvjfnbUFUxSDdb8BqDpqDEer)](https://youtu.be/drULwJ_ZDRQ?t=1m29s)

'''
'''--- examples/traverse-ipld-graphs/create-node.js ---
'use strict'

const IPFS = require('../../src/core')
// In your project, replace by the following line and install IPFS as a dep
// const IPFS = require('ipfs')

function createNode (options, callback) {
  if (typeof options === 'function') {
    callback = options
    options = {}
  }

  options.path = options.path || '/tmp/ipfs' + Math.random()

  const node = new IPFS({
    repo: options.path
  })

  node.on('start', () => callback(null, node))
}

module.exports = createNode

'''
'''--- examples/traverse-ipld-graphs/eth.js ---
'use strict'

const createNode = require('./create-node.js')
const asyncEach = require('async/each')
const path = require('path')
const multihashing = require('multihashing-async')
const Block = require('ipfs-block')
const CID = require('cids')
const fs = require('fs')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  const ethBlocks = [
    path.join(__dirname, '/eth-blocks/block_302516'),
    path.join(__dirname, '/eth-blocks/block_302517')
  ]

  asyncEach(ethBlocks, (ethBlockPath, cb) => {
    const data = fs.readFileSync(ethBlockPath)

    multihashing(data, 'keccak-256', (err, multihash) => {
      if (err) {
        cb(err)
      }
      const cid = new CID(1, 'eth-block', multihash)
      // console.log(cid.toBaseEncodedString())

      ipfs.block.put(new Block(data, cid), cb)
    })
  }, (err) => {
    if (err) {
      throw err
    }

    const block302516 = 'z43AaGEywSDX5PUJcrn5GfZmb6FjisJyR7uahhWPk456f7k7LDA'
    const block302517 = 'z43AaGF42R2DXsU65bNnHRCypLPr9sg6D7CUws5raiqATVaB1jj'

    function errOrLog (err, result) {
      if (err) {
        throw err
      }
      console.log(result.value.toString('hex'))
    }

    ipfs.dag.get(block302516 + '/number', errOrLog)
    ipfs.dag.get(block302517 + '/parent/number', errOrLog)
  })
})

'''
'''--- examples/traverse-ipld-graphs/get-path-accross-formats.js ---
'use strict'

const createNode = require('./create-node.js')
const series = require('async/series')
const dagPB = require('ipld-dag-pb')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  let cidPBNode
  let cidCBORNode

  series([
    (cb) => {
      const someData = Buffer.from('capoeira')

      dagPB.DAGNode.create(someData, (err, node) => {
        if (err) {
          cb(err)
        }

        ipfs.dag.put(node, { format: 'dag-pb', hashAlg: 'sha2-256' }, (err, cid) => {
          if (err) {
            cb(err)
          }
          cidPBNode = cid
          cb()
        })
      })
    },
    (cb) => {
      const myData = {
        name: 'David',
        likes: ['js-ipfs', 'icecream', 'steak'],
        hobbies: [cidPBNode]
      }

      ipfs.dag.put(myData, { format: 'dag-cbor', hashAlg: 'sha3-512' }, (err, cid) => {
        if (err) {
          throw err
        }

        cidCBORNode = cid
        cb()
      })
    },
    (cb) => {
      ipfs.dag.get(cidCBORNode, 'hobbies/0/Data', (err, result) => {
        if (err) {
          throw err
        }

        console.log(result.value.toString())
      })
    }
  ])
})

'''
'''--- examples/traverse-ipld-graphs/get-path.js ---
'use strict'

const createNode = require('./create-node.js')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  const myData = {
    name: 'David',
    likes: ['js-ipfs', 'icecream', 'steak']
  }

  ipfs.dag.put(myData, { format: 'dag-cbor', hashAlg: 'sha2-256' }, (err, cid) => {
    if (err) {
      throw err
    }

    ipfs.dag.get(cid, 'name', (err, result) => {
      if (err) {
        throw err
      }

      console.log(result.value, result.remainderPath)
    })

    ipfs.dag.get(cid, 'likes', (err, result) => {
      if (err) {
        throw err
      }

      console.log(result.value)
    })

    const cidStr = cid.toBaseEncodedString()

    ipfs.dag.get(cidStr + '/likes/0', (err, result) => {
      if (err) {
        throw err
      }

      console.log(result.value)
    })
  })
})

'''
'''--- examples/traverse-ipld-graphs/get.js ---
'use strict'

const createNode = require('./create-node.js')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  const myData = {
    name: 'David',
    likes: ['js-ipfs', 'icecream', 'steak']
  }

  ipfs.dag.put(myData, { format: 'dag-cbor', hashAlg: 'sha2-256' }, (err, cid) => {
    if (err) {
      throw err
    }

    ipfs.dag.get(cid, (err, result) => {
      if (err) {
        throw err
      }

      console.log(JSON.stringify(result.value))
    })
  })
})

'''
'''--- examples/traverse-ipld-graphs/git.js ---
'use strict'

const createNode = require('./create-node.js')
const asyncEach = require('async/each')
const path = require('path')
const multihashing = require('multihashing-async')
const Block = require('ipfs-block')
const CID = require('cids')
const fs = require('fs')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  const gitObjects = [
    path.join(__dirname, '/git-objects/0f328c91df28c5c01b9e9f9f7e663191fa156593'),
    path.join(__dirname, '/git-objects/177bf18bc707d82b21cdefd0b43b38fc8c5c13fe'),
    path.join(__dirname, '/git-objects/23cc25f631cb076d5de5036c87678ea713cbaa6a'),
    path.join(__dirname, '/git-objects/4e425dba7745a781f0712c9a01455899e8c0c249'),
    path.join(__dirname, '/git-objects/6850c7be7136e6be00976ddbae80671b945c3e9d'),
    path.join(__dirname, '/git-objects/a5095353cd62a178663dd26efc2d61f4f61bccbe'),
    path.join(__dirname, '/git-objects/dc9bd15e8b81b6565d3736f9c308bd1bba60f33a'),
    path.join(__dirname, '/git-objects/e68e6f6e31857877a79fd6b3956898436bb5a76f'),
    path.join(__dirname, '/git-objects/ee62b3d206cb23f939208898f32d8708c0e3fa3c'),
    path.join(__dirname, '/git-objects/ee71cef5001b84b0314438f76cf0acd338a2fd21')
  ]

  asyncEach(gitObjects, (gitObjectsPath, cb) => {
    const data = fs.readFileSync(gitObjectsPath)

    multihashing(data, 'sha1', (err, multihash) => {
      if (err) {
        return cb(err)
      }
      const cid = new CID(1, 'git-raw', multihash)
      console.log(cid.toBaseEncodedString())

      ipfs.block.put(new Block(data, cid), cb)
    })
  }, (err) => {
    if (err) {
      throw err
    }

    const v1tag = 'z8mWaGfwSWLMPJ6Q2JdsAjGiXTf61Nbue'

    function errOrLog (comment) {
      return (err, result) => {
        if (err) {
          throw err
        }

        if (Buffer.isBuffer(result.value)) { // Blobs (files) are returned as buffer instance
          result.value = result.value.toString()
        }

        console.log('-'.repeat(80))
        console.log(comment)
        console.log(result.value)
      }
    }

    ipfs.dag.get(v1tag + '/', errOrLog('Tag object:'))
    ipfs.dag.get(v1tag + '/object/message', errOrLog('Tagged commit message:'))
    ipfs.dag.get(v1tag + '/object/parents/0/message', errOrLog('Parent of tagged commit:'))

    ipfs.dag.get(v1tag + '/object/tree/src/hash/hello/hash', errOrLog('/src/hello file:'))
    ipfs.dag.get(v1tag + '/object/parents/0/tree/src/hash/hello/hash', errOrLog('previous version of /src/hello file:'))
  })
})

'''
'''--- examples/traverse-ipld-graphs/put.js ---
'use strict'

const createNode = require('./create-node.js')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  const myData = {
    name: 'David',
    likes: ['js-ipfs', 'icecream', 'steak']
  }

  ipfs.dag.put(myData, { format: 'dag-cbor', hashAlg: 'sha2-256' }, (err, cid) => {
    if (err) {
      throw err
    }
    console.log(cid.toBaseEncodedString())
    // should print:
    //   zdpuAzZSktMhXjJu5zneSFrg9ue5rLXKAMC9KLigqhQ7Q7vRm
  })
})

'''
'''--- examples/traverse-ipld-graphs/tree.js ---
'use strict'

const createNode = require('./create-node.js')
const series = require('async/series')
const dagPB = require('ipld-dag-pb')

createNode((err, ipfs) => {
  if (err) {
    throw err
  }

  console.log('\nStart of the example:')

  let cidPBNode
  let cidCBORNode

  series([
    (cb) => {
      const someData = Buffer.from('capoeira')

      dagPB.DAGNode.create(someData, (err, node) => {
        if (err) {
          cb(err)
        }

        ipfs.dag.put(node, { format: 'dag-pb', hashAlg: 'sha2-256' }, (err, cid) => {
          if (err) {
            cb(err)
          }
          cidPBNode = cid
          cb()
        })
      })
    },
    (cb) => {
      const myData = {
        name: 'David',
        likes: ['js-ipfs', 'icecream', 'steak'],
        hobbies: [{ '/': cidPBNode.toBaseEncodedString() }]
      }

      ipfs.dag.put(myData, { format: 'dag-cbor', hashAlg: 'sha3-512' }, (err, cid) => {
        if (err) {
          throw err
        }

        cidCBORNode = cid
        cb()
      })
    },
    (cb) => {
      ipfs.dag.tree(cidCBORNode, { recursive: true }, (err, paths) => {
        if (err) {
          throw err
        }

        console.log(paths)
      })
    }
  ])
})

'''
'''--- img/architecture.txt ---
 ┌─────────────────────────────────────────────────────────────────────────────┐
 │                            The IPFS Architecture                            │
 └─────────────────────────────────────────────────────────────────────────────┘
               ┏━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━
                  ======================= IPFS Daemon =======================  ┃
               ┃                                                               ┃
               ┃┌────┐ ┏ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━
                │    │     ++++++++++++++++++ IPFS Core ++++++++++++++++++    ┃
                │    │ ┃ ┌──────────────────────────────────────────────────┐
                │HTTP│ ┌─│                  API (Core API)                  │ ┃┃
               ┃│Gate│ │ ├──────┬──────┬──────┬──────┬──────┬───────┬───────┤  ┃
               ┃│way │◀┤ │ Repo │Block │ DAG  │ Pin  │Files │       │Network│ ┃
                │    │ │ └──────┴──────┴──────┴──────┴──────┘       └───────┘
                │    │ │     │      │      │      │      │              │     ┃
                │    │ │     │      │ ┌────┘      │ ┌────┘         ┌────┘      ┃
               ┃└────┘ │  ┌──┘      │ │    ┌──────┘ │              ▼          ┃┃
               ┃       │  │┌────────┘ │    ▼        ▼   ┌────────────────────┐
                ┌────┐ │  ││          │┌───────┐┌──────┐│ libp2p             │┃
                │    │ │  ││          ││Pinning││Unixfs││ (Network, PubSub,  │
                │    │ │  ││          ││Service││Engine││ Swarm, Crypto)     │┃┃
               ┃│    │ │  ││          │└───────┘└──────┘│┌──────────────────┐│ ┃
               ┃│HTTP│ │  ││          │    │        │   ││Connection Manager││┃
                │RPC │ │  ││          ├────┴────────┘   │└──────────────────┘│
┌───┐┌────────┐ │API │◀┘  ││          │                 │┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ │┃
│CLI││ipfs-api│ │    │ ┃  ││          │                 │  Peer Reputation  ││ ┃
└───┘└────────┘┃│    │    ││          │                 │└ ─ ─ ─ ─ ─ ─ ─ ─ ─ │┃┃
               ┃│    │ ┃  ││       ┌──┘                 └────────────────────┘
                │    │    ││       │                   ┌ ─ ─ ─ ─ ┐┌ ─ ─ ─ ─ ─ ┃
                └────┘ ┃  ││       │                    Providers      GC    │
                          ││       ▼                   │ Service ││           ┃┃
               ┃       ┃  ││┌─────────────┐             ─ ─ ─ ─ ─  ─ ─ ─ ─ ─ ┘ ┃
               ┃          │││Graph Service│─────┬───────────┬───────────┐     ┃
                       ┃  ││└─────────────┘     ▼           ▼           ▼
                          ││       │      ┌ ─ ─ ─ ─ ─ ┌ ─ ─ ─ ─ ─ ┌ ─ ─ ─ ─ ─ ┃
                       ┃  │└───────┤       GraphSync │ GraphSyncB│ GraphSyncC│ ┃
               ┃          │        ▼      └ ─ ─ ─ ─ ─ └ ─ ─ ─ ─ ─ └ ─ ─ ─ ─ ─ ┃┃
               ┃       ┃  │ ┌─────────────┐
                          │ │Block Service│─────┬───────────┬───────────┐     ┃
                       ┃  │ └─────────────┘     ▼           ▼           ▼
                          │        │      ┌──────────┐┌ ─ ─ ─ ─ ─ ┌ ─ ─ ─ ─ ─ ┃┃
               ┃       ┃  └─────┬──┴──────│ Bitswap  │  BitswapB │  BitswapB │ ┃
               ┃                ▼         └──────────┘└ ─ ─ ─ ─ ─ └ ─ ─ ─ ─ ─ ┃
                       ┃   ┌─────────┐
                           │  Repo   │                                        ┃
                       ┃   └─────────┘                                         ┃
               ┃                │                                             ┃┃
               ┃       ┃      ┌─┴──────┬──────────┬───────┐
                              ▼        ▼          ▼       ▼                   ┃
                       ┃   ┌────┐┌──────────┐┌────────┐┌────┐
                           │ fs ││indexedDB ││LevelDB ││ S3 │                 ┃┃
               ┃       ┃   └────┘└──────────┘└────────┘└────┘                  ┃
               ┃                                                              ┃
                       ┗ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━ ━
                 ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━   ━━

   ┌───────────────────────────────────────────────────────────────────────────┐
   │ Legend                                                                    │
   │ ┌ ─ ─ ┐                                                                   │
   │         Planned, not yet implemented                                      │
   │ └ ─ ─ ┘                                                                   │
   │ ┌─────┐                                                                   │
   │ │     │ Exist and shipped with IPFS                                       │
   │ └─────┘                                                                   │
   └───────────────────────────────────────────────────────────────────────────┘
'''
'''--- img/core.txt ---
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│                                  IPFS Core                                  │
│                                                                             │
├ ─ ─ ─ ─┌ ─ ─ ─ ─┌ ─ ─ ─ ─┌ ─ ─ ─ ─┌ ─ ─ ─ ─                        ┌ ─ ─ ─ ─│
│  Repo  │ Block  │Bitswap │  DAG   │ Files  │                         Swarm  │
│        │        │        │        │                                │        │
└────────┴───┬────┴────────┴────────┴────────┴────────────────────────────────┘
     │       │         │       │      │                                  │
     │       │         │       │      ▼                                  │
     │       │         │       │ ┌──────────────────┐                    ▼
     │       │         │       │ │ipfs-unixfs-engine│   ┌─────────────────────┐
     │       │         │       │ └──────┬───────────┤   │                     │
     │       │         │       │      │ │ipfs-unixfs│   │       libp2p        │
     │       │         │       │      │ └───────────┘   │                     │
     │       │         │       ▼      ▼                 └─────────────────────┘
     │       │         │     ┌─────────────┬────────┐
     │       │         │     │ipfs-resolver│dag-pb  │
     │       │         │     └─────────────┼────────┤
     │       ▼         │            │      │dag-cbor│
     │   ┌─────────────┴─────┐      │      ├────────┤
     │   │ipfs-blocks-service│◀─────┘      │ethereum│
     │   └─────────────┬─────┘             ├────────┤
     │       │    │    │                   │...     │
     │       │    │    │                   └────────┘
     │       │    │    │
     │       │    ▼    ▼
     │       │  ┌────────────┐
     ├───────┴──│ipfs-bitswap│
     │          └────────────┘
     ▼
┌─────────┬─────────┐
│         │   fs    │
│ipfs-repo├─────────┤
│         │IndexedDB│
└─────────┴─────────┘
'''
'''--- img/overview.txt ---

                     offline mode - uses IPFS core directly
                  ┌────────────────────────────────────────────┐
                  │                                            │
                  │                                            │
                  │ online mode - uses IPFS through http-api   │
 ┌────────────┐   │                          ┌─────────────┐   │    ┌─────────┐
 │            │   │ ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─    │             │   │    │         │
 │    CLI     │───┴──  ipfs-http-client  ├──▶│  HTTP-API   │───┴───▶│IPFS Core│
 │            │     └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─    │             │        │         │
 └────────────┘                              └─────────────┘        └─────────┘
        △                                           △                    △
        ├───────────────────────────────────────────┴────────────────────┘
        │
 ┌────────────┐
 │   Tests    │
 └────────────┘                                                                

'''
'''--- init-and-daemon.sh ---
#! /usr/bin/env bash

set -e

if [ -n "$IPFS_PATH" ]; then
  echo "Using $IPFS_PATH as IPFS repository"
else
  echo "You need to set IPFS_PATH environment variable to use this script"
  exit 1
fi

# Initialize the repo but ignore if error if it already exists
# This can be the case when we restart a container without stopping/removing it
node src/cli/bin.js init || true

if [ -n "$IPFS_API_HOST" ]; then
  sed -i.bak "s/127.0.0.1/$IPFS_API_HOST/g" $IPFS_PATH/config
fi

node src/cli/bin.js daemon

'''
'''--- package-list.json ---
{
  "columns": [
    "Package",
    "Version",
    "Deps",
    "CI",
    "Coverage",
    "Lead Maintainer"
  ],
  "rows": [
    "Files",
    ["ipfs/js-ipfs-unixfs-engine", "ipfs-unixfs-engine"],

    "DAG",
    ["ipld/js-ipld", "ipld"],
    ["ipld/js-ipld-dag-pb", "ipld-dag-pb"],
    ["ipld/js-ipld-dag-cbor", "ipld-dag-cbor"],

    "Repo",
    ["ipfs/js-ipfs-repo", "ipfs-repo"],

    "Exchange",
    ["ipfs/js-ipfs-block-service", "ipfs-block-service"],
    ["ipfs/js-ipfs-bitswap", "ipfs-bitswap"],

    "libp2p",
    ["libp2p/js-libp2p", "libp2p"],
    ["libp2p/js-libp2p-circuit", "libp2p-circuit"],
    ["libp2p/js-libp2p-floodsub", "libp2p-floodsub"],
    ["libp2p/js-libp2p-kad-dht", "libp2p-kad-dht"],
    ["libp2p/js-libp2p-mdns", "libp2p-mdns"],
    ["libp2p/js-libp2p-mplex", "libp2p-mplex"],
    ["libp2p/js-libp2p-railing", "libp2p-railing"],
    ["libp2p/js-libp2p-secio", "libp2p-secio"],
    ["libp2p/js-libp2p-tcp", "libp2p-tcp"],
    ["libp2p/js-libp2p-webrtc-star", "libp2p-webrtc-star"],
    ["libp2p/js-libp2p-websocket-star", "libp2p-websocket-star"],
    ["libp2p/js-libp2p-websockets", "libp2p-websockets"],

    "Data Types",
    ["ipfs/js-ipfs-block", "ipfs-block"],
    ["ipfs/js-ipfs-unixfs", "ipfs-unixfs"],
    ["libp2p/js-peer-id", "peer-id"],
    ["libp2p/js-peer-info", "peer-info"],
    ["multiformats/js-multiaddr", "multiaddr"],
    ["multiformats/js-multihash", "multihashes"],

    "Crypto",
    ["libp2p/js-libp2p-crypto", "libp2p-crypto"],
    ["libp2p/js-libp2p-keychain", "libp2p-keychain"],

    "Generics/Utils",
    ["ipfs/js-ipfs-http-client", "ipfs-http-client"],
    ["ipfs/ipfs-multipart", "ipfs-multipart"],
    ["ipfs/is-ipfs", "is-ipfs"],
    ["multiformats/js-multihashing", "multihashing"],
    ["multiformats/js-mafmt", "mafmt"]
  ]
}

'''
'''--- package.json ---
{
  "name": "ipfs",
  "version": "0.34.4",
  "description": "JavaScript implementation of the IPFS specification",
  "leadMaintainer": "Alan Shaw <alan@tableflip.io>",
  "bin": {
    "jsipfs": "src/cli/bin.js"
  },
  "main": "src/core/index.js",
  "browser": {
    "./src/core/components/init-assets.js": false,
    "./src/core/runtime/add-from-fs-nodejs.js": "./src/core/runtime/add-from-fs-browser.js",
    "./src/core/runtime/config-nodejs.js": "./src/core/runtime/config-browser.js",
    "./src/core/runtime/dns-nodejs.js": "./src/core/runtime/dns-browser.js",
    "./src/core/runtime/fetch-nodejs.js": "./src/core/runtime/fetch-browser.js",
    "./src/core/runtime/libp2p-nodejs.js": "./src/core/runtime/libp2p-browser.js",
    "./src/core/runtime/preload-nodejs.js": "./src/core/runtime/preload-browser.js",
    "./src/core/runtime/repo-nodejs.js": "./src/core/runtime/repo-browser.js",
    "./test/utils/create-repo-nodejs.js": "./test/utils/create-repo-browser.js",
    "stream": "readable-stream",
    "joi": "joi-browser"
  },
  "engines": {
    "node": ">=10.0.0",
    "npm": ">=6.0.0"
  },
  "scripts": {
    "lint": "aegir lint",
    "build": "aegir build",
    "test": "aegir test -t node -t browser -t webworker --no-cors --timeout=10000",
    "test:node": "aegir test -t node --timeout=10000",
    "test:browser": "aegir test -t browser --no-cors --timeout=10000",
    "test:webworker": "aegir test -t webworker --no-cors --timeout=10000",
    "test:node:core": "aegir test -t node -f test/core/**/*.js --timeout=10000",
    "test:node:http": "aegir test -t node -f test/http-api/index.js --timeout=10000",
    "test:node:gateway": "aegir test -t node -f test/gateway/index.js --timeout=10000",
    "test:node:cli": "aegir test -t node -f test/cli/index.js --timeout=10000",
    "test:node:interface": "aegir test -t node -f test/core/interface.spec.js --timeout=10000",
    "test:bootstrapers": "IPFS_TEST=bootstrapers aegir test -t browser -f test/bootstrapers.js --timeout=10000",
    "benchmark": "echo \"Error: no benchmarks yet\" && exit 1",
    "benchmark:node": "echo \"Error: no benchmarks yet\" && exit 1",
    "benchmark:node:core": "echo \"Error: no benchmarks yet\" && exit 1",
    "benchmark:node:http": "echo \"Error: no benchmarks yet\" && exit 1",
    "benchmark:browser": "echo \"Error: no benchmarks yet\" && exit 1",
    "release": "aegir release -t node -t browser",
    "release-minor": "aegir release --type minor -t node -t browser",
    "release-major": "aegir release --type major -t node -t browser",
    "coverage": "aegir coverage",
    "coverage-publish": "aegir-coverage publish",
    "dep-check": "npx dependency-check package.json './test/**/*.js' './src/**/*.js'"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/ipfs/js-ipfs.git"
  },
  "keywords": [
    "IPFS"
  ],
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/ipfs/js-ipfs/issues"
  },
  "homepage": "https://github.com/ipfs/js-ipfs#readme",
  "devDependencies": {
    "aegir": "^18.0.3",
    "chai": "^4.2.0",
    "delay": "^4.1.0",
    "detect-node": "^2.0.4",
    "dir-compare": "^1.4.0",
    "dirty-chai": "^2.0.1",
    "execa": "^1.0.0",
    "form-data": "^2.3.3",
    "hat": "0.0.3",
    "interface-ipfs-core": "~0.96.0",
    "ipfsd-ctl": "~0.41.0",
    "libp2p-websocket-star": "~0.10.2",
    "ncp": "^2.0.0",
    "qs": "^6.5.2",
    "rimraf": "^2.6.2",
    "sinon": "^7.1.1",
    "stream-to-promise": "^2.2.0"
  },
  "dependencies": {
    "@nodeutils/defaults-deep": "^1.1.0",
    "async": "^2.6.1",
    "bignumber.js": "^8.0.2",
    "binary-querystring": "~0.1.2",
    "bl": "^2.1.2",
    "boom": "^7.2.0",
    "bs58": "^4.0.1",
    "byteman": "^1.3.5",
    "cid-tool": "~0.2.0",
    "cids": "~0.5.5",
    "class-is": "^1.1.0",
    "datastore-core": "~0.6.0",
    "datastore-pubsub": "~0.1.1",
    "debug": "^4.1.0",
    "err-code": "^1.1.2",
    "file-type": "^10.2.0",
    "fnv1a": "^1.0.1",
    "fsm-event": "^2.1.0",
    "get-folder-size": "^2.0.0",
    "glob": "^7.1.3",
    "hapi": "^18.0.0",
    "hapi-pino": "^5.2.0",
    "hoek": "^6.1.2",
    "human-to-milliseconds": "^1.0.0",
    "interface-datastore": "~0.6.0",
    "ipfs-bitswap": "~0.22.0",
    "ipfs-block": "~0.8.0",
    "ipfs-block-service": "~0.15.1",
    "ipfs-http-client": "^29.0.0",
    "ipfs-http-response": "~0.2.1",
    "ipfs-mfs": "~0.9.1",
    "ipfs-multipart": "~0.1.0",
    "ipfs-repo": "~0.26.1",
    "ipfs-unixfs": "~0.1.16",
    "ipfs-unixfs-engine": "~0.35.3",
    "ipld": "~0.21.1",
    "ipld-bitcoin": "~0.1.8",
    "ipld-dag-pb": "~0.15.0",
    "ipld-ethereum": "^2.0.1",
    "ipld-git": "~0.2.2",
    "ipld-zcash": "~0.1.6",
    "ipns": "~0.5.0",
    "is-ipfs": "~0.4.8",
    "is-pull-stream": "~0.0.0",
    "is-stream": "^1.1.0",
    "joi": "^14.3.0",
    "joi-browser": "^13.4.0",
    "joi-multiaddr": "^4.0.0",
    "libp2p": "~0.25.0-rc.0",
    "libp2p-bootstrap": "~0.9.3",
    "libp2p-crypto": "~0.16.0",
    "libp2p-kad-dht": "~0.14.4",
    "libp2p-keychain": "~0.3.3",
    "libp2p-mdns": "~0.12.0",
    "libp2p-mplex": "~0.8.4",
    "libp2p-record": "~0.6.1",
    "libp2p-secio": "~0.11.0",
    "libp2p-tcp": "~0.13.0",
    "libp2p-webrtc-star": "~0.15.5",
    "libp2p-websocket-star-multi": "~0.4.0",
    "libp2p-websockets": "~0.12.2",
    "lodash": "^4.17.11",
    "mafmt": "^6.0.2",
    "mime-types": "^2.1.21",
    "mkdirp": "~0.5.1",
    "multiaddr": "^6.0.0",
    "multiaddr-to-uri": "^4.0.0",
    "multibase": "~0.6.0",
    "multihashes": "~0.4.14",
    "multihashing-async": "~0.5.1",
    "node-fetch": "^2.3.0",
    "once": "^1.4.0",
    "peer-book": "~0.9.0",
    "peer-id": "~0.12.0",
    "peer-info": "~0.15.0",
    "progress": "^2.0.1",
    "promisify-es6": "^1.0.3",
    "protons": "^1.0.1",
    "pull-abortable": "^4.1.1",
    "pull-cat": "^1.1.11",
    "pull-defer": "~0.2.3",
    "pull-file": "^1.1.0",
    "pull-ndjson": "~0.1.1",
    "pull-pushable": "^2.2.0",
    "pull-sort": "^1.0.1",
    "pull-stream": "^3.6.9",
    "pull-stream-to-stream": "^1.3.4",
    "pump": "^3.0.0",
    "readable-stream": "^3.1.1",
    "receptacle": "^1.3.2",
    "stream-to-pull-stream": "^1.7.2",
    "tar-stream": "^2.0.0",
    "temp": "~0.9.0",
    "update-notifier": "^2.5.0",
    "varint": "^5.0.0",
    "yargs": "^12.0.5",
    "yargs-promise": "^1.1.0"
  },
  "optionalDependencies": {
    "prom-client": "^11.1.3",
    "prometheus-gc-stats": "~0.6.0"
  },
  "contributors": [
    "0xflotus <0xflotus@gmail.com>",
    "A_A <21040751+Otto-AA@users.noreply.github.com>",
    "Alan Shaw <alan.shaw@protocol.ai>",
    "Alan Shaw <alan@tableflip.io>",
    "Alex North <alex@alexnorth.me>",
    "Alex Potsides <alex@achingbrain.net>",
    "Andrew de Andrade <andrew@deandrade.com.br>",
    "André Cruz <andremiguelcruz@msn.com>",
    "Arkadiy Kukarkin <parkan@users.noreply.github.com>",
    "Arpit Agarwal <93arpit@gmail.com>",
    "Arpit Agarwal <atvanguard@users.noreply.github.com>",
    "Bernard Mordan <bernard@tableflip.io>",
    "Brian Vander Schaaf <bvs330@gmail.com>",
    "Bruno Zell <bruno.zzell@gmail.com>",
    "CHEVALAY JOSSELIN <josselin54.chevalay@gmail.com>",
    "Caio Gondim <me@caiogondim.com>",
    "Chance Hudson <jchancehud@gmail.com>",
    "Christian Couder <chriscool@tuxfamily.org>",
    "Dafeng <dfguo.joe@gmail.com>",
    "Dan Ordille <dordille@gmail.com>",
    "Daniel J. O'Quinn <danieljoquinn@gmail.com>",
    "Daniela Borges Matos de Carvalho <alunassertiva@gmail.com>",
    "David Dias <daviddias.p@gmail.com>",
    "David Gilbertson <gilbertson.david@gmail.com>",
    "David da Silva <dasilvacontin@gmail.com>",
    "Diogo Silva <fsdiogo@gmail.com>",
    "Dmitriy Ryajov <dryajov@gmail.com>",
    "Dzmitry Das <dbachko@gmail.com>",
    "Enrico Marino <enrico.marino@email.com>",
    "Faheel Ahmad <faheel@live.in>",
    "Felix Yan <felixonmars@archlinux.org>",
    "Francisco Baio Dias <xicombd@gmail.com>",
    "Francisco Baio Dias <francisco@typeform.com>",
    "Friedel Ziegelmayer <dignifiedquire@gmail.com>",
    "Gar <gar+gh@danger.computer>",
    "Georgios Rassias <georassias@gmail.com>",
    "Gorka Ludlow <gorka@aquigorka.com>",
    "Greenkeeper <support@greenkeeper.io>",
    "Haad <haadcode@users.noreply.github.com>",
    "Haoliang Yu <haoliangyu@users.noreply.github.com>",
    "Harsh Vakharia <harshjv@users.noreply.github.com>",
    "Henrique Dias <hacdias@gmail.com>",
    "Henry Rodrick <moshisushi@gmail.com>",
    "Heo Sangmin <heo@mapiacompany.com>",
    "Hugo Dias <mail@hugodias.me>",
    "Hugo Dias <hugomrdias@gmail.com>",
    "Jacob Heun <jacobheun@gmail.com>",
    "Jacob Heun <jake@andyet.net>",
    "Jade Meskill <jade.meskill@gmail.com>",
    "Johannes Wikner <johannes.wikner@gmail.com>",
    "Jon Schlinkert <dev@sellside.com>",
    "Jonathan <jkrone@vt.edu>",
    "João Antunes <j.goncalo.antunes@gmail.com>",
    "João Santos <joaosantos15@users.noreply.github.com>",
    "Kevin Wang <kevin@fossa.io>",
    "Lars Gierth <larsg@systemli.org>",
    "Lukas Drgon <lukas.drgon@gmail.com>",
    "Maciej Krüger <mkg20001@gmail.com>",
    "Marcin Rataj <lidel@lidel.org>",
    "Marius Darila <marius.darila@gmail.com>",
    "Mat Kelly <machawk1@gmail.com>",
    "Michelle Lee <michelle@protocol.ai>",
    "Mikeal Rogers <mikeal.rogers@gmail.com>",
    "Mithgol <getgit@mithgol.ru>",
    "Molly <momack2@users.noreply.github.com>",
    "My9Bot <34904312+My9Bot@users.noreply.github.com>",
    "Nuno Nogueira <nunofmn@gmail.com>",
    "Oli Evans <oli@tableflip.io>",
    "Oskar Nyberg <oskar@oskarnyberg.com>",
    "Pascal Precht <pascal.precht@googlemail.com>",
    "Pau Ramon Revilla <masylum@gmail.com>",
    "Paulo Rodrigues <me@paulogr.com>",
    "Pedro Teixeira <i@pgte.me>",
    "Portia Burton <plburton@gmail.com>",
    "Raoul Millais <raoul@raoulmillais.com>",
    "RasmusErik Voel Jensen <github@solsort.com>",
    "Richard Littauer <richard.littauer@gmail.com>",
    "Richard Schneider <makaretu@gmail.com>",
    "Rob Brackett <rob@robbrackett.com>",
    "Rod Keys <rod@zokos.com>",
    "Sangwon Hong <qpakzk@gmail.com>",
    "Sid Harder <sideharder@gmail.com>",
    "SidHarder <softwarenavigator@gmail.com>",
    "Stephen Whitmore <stephen.whitmore@gmail.com>",
    "Stephen Whitmore <noffle@users.noreply.github.com>",
    "Terence Pae <terencepae@gmail.com>",
    "Uroš Jurglič <jurglic@gmail.com>",
    "Vasco Santos <vasco.santos@ua.pt>",
    "Vasco Santos <vasco.santos@moxy.studio>",
    "Volker Mische <volker.mische@gmail.com>",
    "Xiao Liang <yxliang01@users.noreply.github.com>",
    "Yahya <ya7yaz@gmail.com>",
    "Yole <yole@ultiledger.io>",
    "bitspill <bitspill+github@bitspill.net>",
    "datafatmunger <jbg@peerparty.org>",
    "haad <haad@headbanggames.com>",
    "jbenet <juan@benet.ai>",
    "jonahweissman <19804455+jonahweissman@users.noreply.github.com>",
    "kevingzhang <kevin.zhang.canada@gmail.com>",
    "kumavis <kumavis@users.noreply.github.com>",
    "nginnever <ginneversource@gmail.com>",
    "npmcdn-to-unpkg-bot <npmcdn-to-unpkg-bot@users.noreply.github.com>",
    "robbsolter <35879806+robbsolter@users.noreply.github.com>",
    "seungwon-kang <ksw3894@gmail.com>",
    "tcme <hi@this-connect.me>",
    "victorbjelkholm <victorbjelkholm@gmail.com>",
    "Łukasz Magiera <magik6k@users.noreply.github.com>",
    "Максим Ильин <negamaxi@gmail.com>"
  ]
}

'''
'''--- src/cli/bin.js ---
#! /usr/bin/env node

'use strict'

const YargsPromise = require('yargs-promise')
const yargs = require('yargs/yargs')
const updateNotifier = require('update-notifier')
const utils = require('./utils')
const print = utils.print
const mfs = require('ipfs-mfs/cli')
const debug = require('debug')('ipfs:cli')
const pkg = require('../../package.json')

async function main (args) {
  const oneWeek = 1000 * 60 * 60 * 24 * 7
  updateNotifier({ pkg, updateCheckInterval: oneWeek }).notify()

  const cli = yargs(args)
    .option('silent', {
      desc: 'Write no output',
      type: 'boolean',
      default: false,
      coerce: silent => {
        if (silent) utils.disablePrinting()
        return silent
      }
    })
    .option('pass', {
      desc: 'Pass phrase for the keys',
      type: 'string',
      default: ''
    })
    .epilog(utils.ipfsPathHelp)
    .demandCommand(1)
    .fail((msg, err, yargs) => {
      if (err) {
        throw err // preserve stack
      }

      if (args.length > 0) {
        print(msg)
      }

      yargs.showHelp()
    })

  // Function to get hold of a singleton ipfs instance
  const getIpfs = utils.singleton(cb => utils.getIPFS(yargs(args).argv, cb))

  // add MFS (Files API) commands
  mfs(cli)

  cli
    .commandDir('commands')
    .help()
    .strict()
    .completion()

  let exitCode = 0

  try {
    const { data } = await new YargsPromise(cli, { getIpfs }).parse(args)
    if (data) print(data)
  } catch (err) {
    debug(err)

    // the argument can have a different shape depending on where the error came from
    if (err.message || (err.error && err.error.message)) {
      print(err.message || err.error.message)
    } else {
      print('Unknown error, please re-run the command with DEBUG=ipfs:cli to see debug output')
    }

    exitCode = 1
  } finally {
    // If an IPFS instance was used in the handler then clean it up here
    if (getIpfs.instance) {
      try {
        const cleanup = getIpfs.rest[0]
        await cleanup()
      } catch (err) {
        debug(err)
        exitCode = 1
      }
    }
  }

  if (exitCode) {
    process.exit(exitCode)
  }
}

main(process.argv.slice(2))

'''
'''--- src/cli/commands/add.js ---
'use strict'

const sortBy = require('lodash/sortBy')
const pull = require('pull-stream')
const promisify = require('promisify-es6')
const getFolderSize = promisify(require('get-folder-size'))
const byteman = require('byteman')
const mh = require('multihashes')
const multibase = require('multibase')
const toPull = require('stream-to-pull-stream')
const { print, isDaemonOn, createProgressBar } = require('../utils')
const { cidToString } = require('../../utils/cid')
const globSource = require('../../utils/files/glob-source')

async function getTotalBytes (paths, cb) {
  const sizes = await Promise.all(paths.map(p => getFolderSize(p)))
  return sizes.reduce((total, size) => total + size, 0)
}

function addPipeline (source, addStream, options) {
  return new Promise((resolve, reject) => {
    pull(
      source,
      addStream,
      pull.collect((err, added) => {
        if (err) {
          // Tweak the error message and add more relevant infor for the CLI
          if (err.code === 'ERR_DIR_NON_RECURSIVE') {
            err.message = `'${err.path}' is a directory, use the '-r' flag to specify directories`
          }
          return reject(err)
        }

        if (options.silent) return resolve()

        if (options.quieter) {
          print(added.pop().hash)
          return resolve()
        }

        sortBy(added, 'path')
          .reverse()
          .map((file) => {
            const log = options.quiet ? [] : ['added']
            log.push(cidToString(file.hash, { base: options.cidBase }))
            if (!options.quiet && file.path.length > 0) log.push(file.path)
            return log.join(' ')
          })
          .forEach((msg) => print(msg))

        resolve()
      })
    )
  })
}

module.exports = {
  command: 'add [file...]',

  describe: 'Add a file to IPFS using the UnixFS data format',

  builder: {
    progress: {
      alias: 'p',
      type: 'boolean',
      default: true,
      describe: 'Stream progress data'
    },
    recursive: {
      alias: 'r',
      type: 'boolean',
      default: false
    },
    trickle: {
      alias: 't',
      type: 'boolean',
      default: false,
      describe: 'Use the trickle DAG builder'
    },
    'wrap-with-directory': {
      alias: 'w',
      type: 'boolean',
      default: false
    },
    'only-hash': {
      alias: 'n',
      type: 'boolean',
      default: false,
      describe: 'Only chunk and hash, do not write'
    },
    chunker: {
      default: 'size-262144',
      describe: 'Chunking algorithm to use, formatted like [size-{size}, rabin, rabin-{avg}, rabin-{min}-{avg}-{max}]'
    },
    'enable-sharding-experiment': {
      type: 'boolean',
      default: false
    },
    'shard-split-threshold': {
      type: 'integer',
      default: 1000
    },
    'raw-leaves': {
      type: 'boolean',
      describe: 'Use raw blocks for leaf nodes. (experimental)'
    },
    'cid-version': {
      type: 'integer',
      describe: 'CID version. Defaults to 0 unless an option that depends on CIDv1 is passed. (experimental)',
      default: 0
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    },
    hash: {
      type: 'string',
      choices: Object.keys(mh.names),
      describe: 'Hash function to use. Will set CID version to 1 if used. (experimental)'
    },
    quiet: {
      alias: 'q',
      type: 'boolean',
      default: false,
      describe: 'Write minimal output'
    },
    quieter: {
      alias: 'Q',
      type: 'boolean',
      default: false,
      describe: 'Write only final hash'
    },
    silent: {
      type: 'boolean',
      default: false,
      describe: 'Write no output'
    },
    pin: {
      type: 'boolean',
      default: true,
      describe: 'Pin this object when adding'
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const options = {
        strategy: argv.trickle ? 'trickle' : 'balanced',
        shardSplitThreshold: argv.enableShardingExperiment
          ? argv.shardSplitThreshold
          : Infinity,
        cidVersion: argv.cidVersion,
        rawLeaves: argv.rawLeaves,
        onlyHash: argv.onlyHash,
        hashAlg: argv.hash,
        wrapWithDirectory: argv.wrapWithDirectory,
        pin: argv.pin,
        chunker: argv.chunker
      }

      if (options.enableShardingExperiment && isDaemonOn()) {
        throw new Error('Error: Enabling the sharding experiment should be done on the daemon')
      }

      const source = argv.file
        ? globSource(...argv.file, { recursive: argv.recursive })
        : toPull.source(process.stdin) // Pipe directly to ipfs.add

      const adder = ipfs.addPullStream(options)

      // No progress or piping directly to ipfs.add: no need to getTotalBytes
      if (!argv.progress || !argv.file) {
        return addPipeline(source, adder, argv)
      }

      const totalBytes = await getTotalBytes(argv.file)
      const bar = createProgressBar(totalBytes)

      options.progress = byteLength => {
        bar.update(byteLength / totalBytes, { progress: byteman(byteLength, 2, 'MB') })
      }

      return addPipeline(source, adder, argv)
    })())
  }
}

'''
'''--- src/cli/commands/bitswap.js ---
'use strict'

module.exports = {
  command: 'bitswap <command>',

  description: 'Interact with the bitswap agent.',

  builder (yargs) {
    return yargs.commandDir('bitswap')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/bitswap/stat.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'stat',

  describe: 'Show some diagnostic information on the bitswap agent.',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const stats = await ipfs.bitswap.stat()
      stats.wantlist = stats.wantlist.map(k => cidToString(k['/'], { base: cidBase, upgrade: false }))
      stats.peers = stats.peers || []

      print(`bitswap status
  blocks received: ${stats.blocksReceived}
  dup blocks received: ${stats.dupBlksReceived}
  dup data received: ${stats.dupDataReceived}B
  wantlist [${stats.wantlist.length} keys]
    ${stats.wantlist.join('\n    ')}
  partners [${stats.peers.length}]
    ${stats.peers.join('\n    ')}`)
    })())
  }
}

'''
'''--- src/cli/commands/bitswap/unwant.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'unwant <key>',

  describe: 'Removes a given block from your wantlist.',

  builder: {
    key: {
      alias: 'k',
      describe: 'Key to remove from your wantlist',
      type: 'string'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },
  handler ({ getIpfs, key, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      await ipfs.bitswap.unwant(key)
      print(`Key ${cidToString(key, { base: cidBase, upgrade: false })} removed from wantlist`)
    })())
  }
}

'''
'''--- src/cli/commands/bitswap/wantlist.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'wantlist [peer]',

  describe: 'Print out all blocks currently on the bitswap wantlist for the local peer.',

  builder: {
    peer: {
      alias: 'p',
      describe: 'Specify which peer to show wantlist for.',
      type: 'string'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, peer, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const list = await ipfs.bitswap.wantlist(peer)
      list.Keys.forEach(k => print(cidToString(k['/'], { base: cidBase, upgrade: false })))
    })())
  }
}

'''
'''--- src/cli/commands/block.js ---
'use strict'

module.exports = {
  command: 'block <command>',

  description: 'Manipulate raw IPFS blocks.',

  builder (yargs) {
    return yargs
      .commandDir('block')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/block/get.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'get <key>',

  describe: 'Get a raw IPFS block',

  builder: {},

  handler ({ getIpfs, key, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const block = await ipfs.block.get(key)
      if (block) {
        print(block.data, false)
      } else {
        print('Block was unwanted before it could be remotely retrieved')
      }
    })())
  }
}

'''
'''--- src/cli/commands/block/put.js ---
'use strict'

const bl = require('bl')
const fs = require('fs')
const multibase = require('multibase')
const promisify = require('promisify-es6')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'put [block]',

  describe: 'Stores input as an IPFS block',

  builder: {
    format: {
      alias: 'f',
      describe: 'cid format for blocks to be created with.',
      default: 'dag-pb'
    },
    mhtype: {
      describe: 'multihash hash function',
      default: 'sha2-256'
    },
    mhlen: {
      describe: 'multihash hash length',
      default: undefined
    },
    version: {
      describe: 'cid version',
      type: 'number'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      let data

      if (argv.block) {
        data = await promisify(fs.readFile)(argv.block)
      } else {
        data = await new Promise((resolve, reject) => {
          process.stdin.pipe(bl((err, input) => {
            if (err) return reject(err)
            resolve(input)
          }))
        })
      }

      const ipfs = await argv.getIpfs()
      const { cid } = await ipfs.block.put(data, argv)
      print(cidToString(cid, { base: argv.cidBase }))
    })())
  }
}

'''
'''--- src/cli/commands/block/rm.js ---
'use strict'

const { print, isDaemonOn } = require('../../utils')

module.exports = {
  command: 'rm <key>',

  describe: 'Remove a raw IPFS block',

  builder: {},

  handler ({ getIpfs, key, resolve }) {
    resolve((async () => {
      if (isDaemonOn()) {
        // TODO implement this once `js-ipfs-http-client` supports it
        throw new Error('rm block with daemon running is not yet implemented')
      }

      const ipfs = await getIpfs()
      await ipfs.block.rm(key)
      print('removed ' + key)
    })())
  }
}

'''
'''--- src/cli/commands/block/stat.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'stat <key>',

  describe: 'Print information of a raw IPFS block',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, key, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const stats = await ipfs.block.stat(key)
      print('Key: ' + cidToString(stats.key, { base: cidBase }))
      print('Size: ' + stats.size)
    })())
  }
}

'''
'''--- src/cli/commands/bootstrap.js ---
'use strict'

module.exports = {
  command: 'bootstrap <command>',

  description: 'Show or edit the list of bootstrap peers.',

  builder (yargs) {
    return yargs
      .commandDir('bootstrap')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/bootstrap/add.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'add [<peer>]',

  describe: 'Add peers to the bootstrap list',

  builder: {
    default: {
      describe: 'Add default bootstrap nodes.',
      type: 'boolean',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const list = await ipfs.bootstrap.add(argv.peer, { default: argv.default })
      list.Peers.forEach((peer) => print(peer))
    })())
  }
}

'''
'''--- src/cli/commands/bootstrap/list.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'list',

  describe: 'Show peers in the bootstrap list',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const list = await ipfs.bootstrap.list()
      list.Peers.forEach((node) => print(node))
    })())
  }
}

'''
'''--- src/cli/commands/bootstrap/rm.js ---
'use strict'

const debug = require('debug')
const log = debug('cli:bootstrap')
log.error = debug('cli:bootstrap:error')
const print = require('../../utils').print

module.exports = {
  command: 'rm [<peer>]',

  describe: 'Removes peers from the bootstrap list',

  builder: {
    all: {
      type: 'boolean',
      describe: 'Remove all bootstrap peers.',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const list = await ipfs.bootstrap.rm(argv.peer, { all: argv.all })
      list.Peers.forEach((peer) => print(peer))
    })())
  }
}

'''
'''--- src/cli/commands/cat.js ---
'use strict'

module.exports = {
  command: 'cat <ipfsPath>',

  describe: 'Fetch and cat an IPFS path referencing a file',

  builder: {
    offset: {
      alias: 'o',
      type: 'integer',
      describe: 'Byte offset to begin reading from'
    },
    length: {
      alias: ['n', 'count'],
      type: 'integer',
      describe: 'Maximum number of bytes to read'
    }
  },

  handler ({ getIpfs, ipfsPath, offset, length, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()

      return new Promise((resolve, reject) => {
        const stream = ipfs.catReadableStream(ipfsPath, { offset, length })

        stream.on('error', reject)
        stream.on('end', resolve)

        stream.pipe(process.stdout)
      })
    })())
  }
}

'''
'''--- src/cli/commands/cid.js ---
'use strict'

const path = require('path')

const cidCommandsPath = path.join(
  path.dirname(require.resolve('cid-tool')), 'cli', 'commands'
)

module.exports = {
  command: 'cid <command>',

  description: 'Convert, format and discover properties of CIDs.',

  builder (yargs) {
    return yargs
      .commandDir(cidCommandsPath)
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/commands.js ---
'use strict'
const print = require('../utils').print
const path = require('path')
const glob = require('glob').sync

module.exports = {
  command: 'commands',

  describe: 'List all available commands',

  handler () {
    const basePath = path.resolve(__dirname, '..')

    // modeled after https://github.com/vdemedes/ronin/blob/master/lib/program.js#L78
    const files = glob(path.join(basePath, 'commands', '**', '*.js'))
    const cmds = files.map((p) => {
      return p.replace(/\//g, path.sep)
        .replace(/^./, ($1) => $1.toUpperCase())
        .replace(path.join(basePath, 'commands'), '')
        .replace(path.sep, '')
        .split(path.sep)
        .join(' ')
        .replace('.js', '')
    }).sort().map((cmd) => `ipfs ${cmd}`)

    print(['ipfs'].concat(cmds).join('\n'))
  }
}

'''
'''--- src/cli/commands/config.js ---
'use strict'
const print = require('../utils').print

module.exports = {
  command: 'config <key> [value]',

  description: 'Get and set IPFS config values',

  builder (yargs) {
    return yargs
      .commandDir('config')
      .options({
        bool: {
          type: 'boolean',
          default: false,
          global: false
        },
        json: {
          type: 'boolean',
          default: false,
          global: false
        }
      })
  },

  handler (argv) {
    argv.resolve((async () => {
      if (argv._handled) {
        return
      }
      argv._handled = true

      const { bool, json, key, getIpfs } = argv
      const ipfs = await getIpfs()
      let value = argv.value

      if (!value) {
        // Get the value of a given key
        value = await ipfs.config.get(key)

        if (typeof value === 'object') {
          print(JSON.stringify(value, null, 2))
        } else {
          print(value)
        }
      } else {
        // Set the new value of a given key

        if (bool) {
          value = (value === 'true')
        } else if (json) {
          try {
            value = JSON.parse(value)
          } catch (err) {
            throw new Error('invalid JSON provided')
          }
        }

        await ipfs.config.set(key, value)
      }
    })())
  }
}

'''
'''--- src/cli/commands/config/edit.js ---
'use strict'

const spawn = require('child_process').spawn
const fs = require('fs')
const temp = require('temp')
const promisify = require('promisify-es6')
const utils = require('../../utils')

module.exports = {
  command: 'edit',

  describe: 'Opens the config file for editing in $EDITOR',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (argv._handled) return
      argv._handled = true

      const editor = process.env.EDITOR

      if (!editor) {
        throw new Error('ENV variable $EDITOR not set')
      }

      const ipfs = await argv.getIpfs()

      async function getConfig () {
        try {
          await ipfs.config.get()
        } catch (err) {
          throw new Error('failed to get the config')
        }
      }

      async function saveTempConfig (config) {
        const path = temp.path({ prefix: 'ipfs-config' })

        try {
          await promisify(fs.writeFile)(JSON.stringify(config, null, 2))
        } catch (err) {
          throw new Error('failed to write the config to a temporary file')
        }

        return path
      }

      function openEditor (path) {
        return new Promise((resolve, reject) => {
          const child = spawn(editor, [path], { stdio: 'inherit' })

          child.on('exit', (err, code) => {
            if (err) return reject(new Error('error on the editor'))
            resolve(path)
          })
        })
      }

      async function readTempConfig (path) {
        let data

        try {
          data = await promisify(fs.readFile)(path, 'utf8')
        } catch (err) {
          throw new Error('failed to get the updated config')
        }

        try {
          return JSON.parse(data)
        } catch (err) {
          throw new Error(`failed to parse the updated config "${err.message}"`)
        }
      }

      async function saveConfig (config) {
        config = utils.isDaemonOn()
          ? Buffer.from(JSON.stringify(config)) : config

        try {
          await ipfs.config.replace(config)
        } catch (err) {
          throw new Error('failed to save the config')
        }
      }

      const config = await getConfig()
      const tmpPath = saveTempConfig(config)
      await openEditor(tmpPath)
      const updatedConfig = await readTempConfig(tmpPath)
      await saveConfig(updatedConfig)
    })())
  }
}

'''
'''--- src/cli/commands/config/replace.js ---
'use strict'

const path = require('path')
const fs = require('fs')
const utils = require('../../utils')

module.exports = {
  command: 'replace <file>',

  describe: 'Replaces the config with <file>',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (argv._handled) return
      argv._handled = true

      const filePath = path.resolve(process.cwd(), argv.file)

      const config = utils.isDaemonOn()
        ? filePath : JSON.parse(fs.readFileSync(filePath, 'utf8'))

      const ipfs = await argv.getIpfs()
      return ipfs.config.replace(config)
    })())
  }
}

'''
'''--- src/cli/commands/config/show.js ---
'use strict'

const debug = require('debug')
const log = debug('cli:config')
log.error = debug('cli:config:error')
const print = require('../../utils').print

module.exports = {
  command: 'show',

  describe: 'Outputs the content of the config file',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (argv._handled) return
      argv._handled = true

      const ipfs = await argv.getIpfs()
      const config = await ipfs.config.get()
      print(JSON.stringify(config, null, 4))
    })())
  }
}

'''
'''--- src/cli/commands/daemon.js ---
'use strict'

const { getRepoPath, print, ipfsPathHelp } = require('../utils')

module.exports = {
  command: 'daemon',

  describe: 'Start a long-running daemon process',

  builder (yargs) {
    return yargs
      .epilog(ipfsPathHelp)
      .option('enable-sharding-experiment', {
        type: 'boolean',
        default: false
      })
      .option('enable-pubsub-experiment', {
        type: 'boolean',
        default: false
      })
      .option('offline', {
        desc: 'Run offline. Do not connect to the rest of the network but provide local API.',
        default: false
      })
      .option('enable-namesys-pubsub', {
        type: 'boolean',
        default: false
      })
  },

  handler (argv) {
    argv.resolve((async () => {
      print('Initializing IPFS daemon...')

      const repoPath = getRepoPath()

      // Required inline to reduce startup time
      const HttpApi = require('../../http')
      const api = new HttpApi({
        silent: argv.silent,
        repo: process.env.IPFS_PATH,
        offline: argv.offline,
        pass: argv.pass,
        EXPERIMENTAL: {
          pubsub: argv.enablePubsubExperiment,
          ipnsPubsub: argv.enableNamesysPubsub,
          dht: argv.enableDhtExperiment,
          sharding: argv.enableShardingExperiment
        }
      })

      try {
        await api.start()
      } catch (err) {
        if (err.code === 'ENOENT' && err.message.match(/uninitialized/i)) {
          print('Error: no initialized ipfs repo found in ' + repoPath)
          print('please run: jsipfs init')
          process.exit(1)
        }
        throw err
      }

      print('Daemon is ready')

      const cleanup = async () => {
        print(`Received interrupt signal, shutting down...`)
        await api.stop()
        process.exit(0)
      }

      // listen for graceful termination
      process.on('SIGTERM', cleanup)
      process.on('SIGINT', cleanup)
      process.on('SIGHUP', cleanup)
    })())
  }
}

'''
'''--- src/cli/commands/dag.js ---
'use strict'

module.exports = {
  command: 'dag <command>',

  description: 'Interact with ipld dag objects.',

  builder (yargs) {
    return yargs
      .commandDir('dag')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/dag/get.js ---
'use strict'

const CID = require('cids')
const print = require('../../utils').print

module.exports = {
  command: 'get <cid path>',

  describe: 'Get a dag node or value from ipfs.',

  builder: {
    'local-resolve': {
      type: 'boolean',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const refParts = argv.cidpath.split('/')
      const cidString = refParts[0]
      const path = refParts.slice(1).join('/')
      const cid = new CID(cidString)

      const options = {
        localResolve: argv.localResolve
      }

      const ipfs = await argv.getIpfs()
      let result

      try {
        result = await ipfs.dag.get(cid, path, options)
      } catch (err) {
        return print(`dag get failed: ${err.message}`)
      }

      if (options.localResolve) {
        print('resolving path within the node only')
        print(`remainder path: ${result.remainderPath || 'n/a'}\n`)
      }

      const node = result.value

      // TODO we need to find* a way to pretty print objects
      // * reads as 'agree in'
      if (node._json) {
        delete node._json.multihash
        node._json.data = '0x' + node._json.data.toString('hex')
        print(JSON.stringify(node._json))
        return
      }

      if (Buffer.isBuffer(node)) {
        print('0x' + node.toString('hex'))
        return
      }

      if (node.raw) {
        print(node.raw)
      } else {
        print(node)
      }
    })())
  }
}

'''
'''--- src/cli/commands/dht.js ---
'use strict'

module.exports = {
  command: 'dht <command>',

  description: 'Issue commands directly through the DHT.',

  builder (yargs) {
    return yargs.commandDir('dht')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/dht/find-peer.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'findpeer <peerID>',

  describe: 'Find the multiaddresses associated with a Peer ID.',

  builder: {},

  handler ({ getIpfs, peerID, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const peers = await ipfs.dht.findPeer(peerID)
      const addresses = peers.multiaddrs.toArray().map((ma) => ma.toString())

      addresses.forEach((addr) => {
        print(addr)
      })
    })())
  }
}

'''
'''--- src/cli/commands/dht/find-providers.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'findprovs <key>',

  describe: 'Find peers that can provide a specific value, given a key.',

  builder: {
    'num-providers': {
      alias: 'n',
      describe: 'The number of providers to find. Default: 20.',
      default: 20
    }
  },

  handler (argv) {
    const { getIpfs, key, resolve } = argv
    const opts = {
      maxNumProviders: argv['num-providers']
    }

    resolve((async () => {
      const ipfs = await getIpfs()
      const provs = await ipfs.dht.findProvs(key, opts)

      provs.forEach((element) => {
        print(element.id.toB58String())
      })
    })())
  }
}

'''
'''--- src/cli/commands/dht/get.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'get <key>',

  describe: 'Given a key, query the routing system for its best value.',

  builder: {},

  handler ({ getIpfs, key, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const value = await ipfs.dht.get(key)

      print(value)
    })())
  }
}

'''
'''--- src/cli/commands/dht/provide.js ---
'use strict'

module.exports = {
  command: 'provide <key>',

  describe: 'Announce to the network that you are providing given values.',

  builder: {
    recursive: {
      alias: 'r',
      recursive: 'Recursively provide entire graph.',
      default: false
    }
  },

  handler ({ getIpfs, key, recursive, resolve }) {
    const opts = {
      recursive
    }

    resolve((async () => {
      const ipfs = await getIpfs()
      await ipfs.dht.provide(key, opts)
    })())
  }
}

'''
'''--- src/cli/commands/dht/put.js ---
'use strict'

module.exports = {
  command: 'put <key> <value>',

  describe: 'Write a key/value pair to the routing system.',

  builder: {},

  handler ({ getIpfs, key, value, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      await ipfs.dht.put(key, value)
    })())
  }
}

'''
'''--- src/cli/commands/dht/query.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'query <peerID>',

  describe: 'Find the closest Peer IDs to a given Peer ID by querying the DHT.',

  builder: {},

  handler ({ getIpfs, peerID, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const result = await ipfs.dht.query(peerID)

      result.forEach((peerID) => {
        print(peerID.id.toB58String())
      })
    })())
  }
}

'''
'''--- src/cli/commands/dns.js ---
'use strict'
const print = require('../utils').print

module.exports = {
  command: 'dns <domain>',

  describe: 'Resolve DNS links',

  builder: {
    format: {
      type: 'string'
    }
  },

  handler ({ getIpfs, domain, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const path = await ipfs.dns(domain)
      print(path)
    })())
  }
}

'''
'''--- src/cli/commands/file.js ---
'use strict'

module.exports = {
  command: 'file <command>',

  description: 'Interact with IPFS objects representing Unix filesystems.',

  builder (yargs) {
    return yargs
      .commandDir('file')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/file/ls.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'ls <key>',

  describe: 'List directory contents for Unix filesystem objects.',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const path = argv.key
      // `ipfs file ls` is deprecated. See https://ipfs.io/docs/commands/#ipfs-file-ls
      print(`This functionality is deprecated, and will be removed in future versions. If possible, please use 'ipfs ls' instead.`)

      const ipfs = await argv.getIpfs()
      let links = await ipfs.ls(path)

      // Single file? Then print its hash
      if (links.length === 0) {
        links = [{ hash: path }]
      }

      links.forEach((file) => print(file.hash))
    })())
  }
}

'''
'''--- src/cli/commands/get.js ---
'use strict'

var fs = require('fs')
const path = require('path')
const mkdirp = require('mkdirp')
const pull = require('pull-stream')
const toPull = require('stream-to-pull-stream')
const print = require('../utils').print

function checkArgs (hash, outPath) {
  // format the output directory
  if (!outPath.endsWith(path.sep)) {
    outPath += path.sep
  }

  return outPath
}

function ensureDirFor (dir, file, callback) {
  const lastSlash = file.path.lastIndexOf('/')
  const filePath = file.path.substring(0, lastSlash + 1)
  const dirPath = path.join(dir, filePath)
  mkdirp(dirPath, callback)
}

function fileHandler (dir) {
  return function onFile (file, callback) {
    ensureDirFor(dir, file, (err) => {
      if (err) {
        callback(err)
      } else {
        const fullFilePath = path.join(dir, file.path)

        if (file.content) {
          file.content
            .pipe(fs.createWriteStream(fullFilePath))
            .once('error', callback)
            .once('finish', callback)
        } else {
          // this is a dir
          mkdirp(fullFilePath, callback)
        }
      }
    })
  }
}

module.exports = {
  command: 'get <ipfsPath>',

  describe: 'Fetch a file or directory with files references from an IPFS Path',

  builder: {
    output: {
      alias: 'o',
      type: 'string',
      default: process.cwd()
    }
  },

  handler ({ getIpfs, ipfsPath, output, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()

      return new Promise((resolve, reject) => {
        const dir = checkArgs(ipfsPath, output)
        const stream = ipfs.getReadableStream(ipfsPath)

        print(`Saving file(s) ${ipfsPath}`)
        pull(
          toPull.source(stream),
          pull.asyncMap(fileHandler(dir)),
          pull.onEnd((err) => {
            if (err) return reject(err)
            resolve()
          })
        )
      })
    })())
  }
}

'''
'''--- src/cli/commands/id.js ---
'use strict'
const print = require('../utils').print

module.exports = {
  command: 'id',

  describe: 'Shows IPFS Node ID info',

  builder: {
    format: {
      alias: 'f',
      type: 'string'
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const id = await ipfs.id()
      print(JSON.stringify(id, '', 2))
    })())
  }
}

'''
'''--- src/cli/commands/init.js ---
'use strict'

const utils = require('../utils')
const print = utils.print

module.exports = {
  command: 'init [config] [options]',
  describe: 'Initialize a local IPFS node',
  builder (yargs) {
    return yargs
      .epilog(utils.ipfsPathHelp)
      .positional('config', {
        describe: 'Node config, this should JSON and will be merged with the default config. Check https://github.com/ipfs/js-ipfs#optionsconfig',
        type: 'string'
      })
      .option('bits', {
        type: 'number',
        alias: 'b',
        default: '2048',
        describe: 'Number of bits to use in the generated RSA private key (defaults to 2048)'
      })
      .option('emptyRepo', {
        alias: 'e',
        type: 'boolean',
        describe: "Don't add and pin help files to the local storage"
      })
      .option('privateKey', {
        alias: 'k',
        type: 'string',
        describe: 'Pre-generated private key to use for the repo'
      })
  },

  handler (argv) {
    argv.resolve((async () => {
      const path = utils.getRepoPath()

      print(`initializing ipfs node at ${path}`)

      // Required inline to reduce startup time
      const IPFS = require('../../core')
      const Repo = require('ipfs-repo')

      const node = new IPFS({
        repo: new Repo(path),
        init: false,
        start: false,
        config: argv.config || {}
      })

      try {
        await node.init({
          bits: argv.bits,
          privateKey: argv.privateKey,
          emptyRepo: argv.emptyRepo,
          pass: argv.pass,
          log: print
        })
      } catch (err) {
        if (err.code === 'EACCES') {
          err.message = `EACCES: permission denied, stat $IPFS_PATH/version`
        }
        throw err
      }
    })())
  }
}

'''
'''--- src/cli/commands/key.js ---
'use strict'

module.exports = {
  command: 'key',

  description: 'Manage your keys',

  builder (yargs) {
    return yargs
      .commandDir('key')
  },

  handler (argv) {}
}

'''
'''--- src/cli/commands/key/export.js ---
'use strict'

const fs = require('fs')

module.exports = {
  command: 'export <name>',

  describe: 'Export the key as a password protected PKCS #8 PEM file',

  builder: {
    passout: {
      alias: 'p',
      describe: 'Password for the PEM',
      type: 'string',
      demandOption: true
    },
    output: {
      alias: 'o',
      describe: 'Output file',
      type: 'string',
      default: 'stdout'
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const pem = await ipfs.key.export(argv.name, argv.passout)
      if (argv.output === 'stdout') {
        process.stdout.write(pem)
      } else {
        fs.writeFileSync(argv.output, pem)
      }
    })())
  }
}

'''
'''--- src/cli/commands/key/gen.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'gen <name>',

  describe: 'Create a new key',

  builder: {
    type: {
      alias: 't',
      describe: 'type of the key to create [rsa, ed25519].',
      default: 'rsa'
    },
    size: {
      alias: 's',
      describe: 'size of the key to generate.',
      default: 2048,
      type: 'number'
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const opts = {
        type: argv.type,
        size: argv.size
      }
      const ipfs = await argv.getIpfs()
      const key = await ipfs.key.gen(argv.name, opts)
      print(`generated ${key.id} ${key.name}`)
    })())
  }
}

'''
'''--- src/cli/commands/key/import.js ---
'use strict'

const fs = require('fs')
const print = require('../../utils').print

module.exports = {
  command: 'import <name>',

  describe: 'Import the key from a PKCS #8 PEM file',

  builder: {
    passin: {
      alias: 'p',
      describe: 'Password for the PEM',
      type: 'string'
    },
    input: {
      alias: 'i',
      describe: 'Input PEM file',
      type: 'string',
      demandOption: true,
      coerce: ('input', input => fs.readFileSync(input, 'utf8'))
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const key = await ipfs.key.import(argv.name, argv.input, argv.passin)
      print(`imported ${key.id} ${key.name}`)
    })())
  }
}

'''
'''--- src/cli/commands/key/list.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'list',

  describe: 'List all local keys',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const keys = await ipfs.key.list()
      keys.forEach((ki) => print(`${ki.id} ${ki.name}`))
    })())
  }
}

'''
'''--- src/cli/commands/key/rename.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'rename <name> <newName>',

  describe: 'Rename a key',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const res = await ipfs.key.rename(argv.name, argv.newName)
      print(`renamed to ${res.id} ${res.now}`)
    })())
  }
}

'''
'''--- src/cli/commands/key/rm.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'rm <name>',

  describe: 'Remove a key',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const key = await ipfs.key.rm(argv.name)
      print(`${key.id} ${key.name}`)
    })())
  }
}

'''
'''--- src/cli/commands/ls.js ---
'use strict'

const multibase = require('multibase')
const { print, rightpad } = require('../utils')
const { cidToString } = require('../../utils/cid')

module.exports = {
  command: 'ls <key>',

  describe: 'List files for the given directory',

  builder: {
    v: {
      alias: 'headers',
      desc: 'Print table headers (Hash, Size, Name).',
      type: 'boolean',
      default: false
    },
    r: {
      alias: 'recursive',
      desc: 'List subdirectories recursively',
      type: 'boolean',
      default: false
    },
    'resolve-type': {
      desc: 'Resolve linked objects to find out their types. (not implemented yet)',
      type: 'boolean',
      default: false // should be true when implemented
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, key, recursive, headers, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      let links = await ipfs.ls(key, { recursive })

      links = links.map(file => Object.assign(file, { hash: cidToString(file.hash, { base: cidBase }) }))

      if (headers) {
        links = [{ hash: 'Hash', size: 'Size', name: 'Name' }].concat(links)
      }

      const multihashWidth = Math.max.apply(null, links.map((file) => file.hash.length))
      const sizeWidth = Math.max.apply(null, links.map((file) => String(file.size).length))

      let pathParts = key.split('/')

      if (key.startsWith('/ipfs/')) {
        pathParts = pathParts.slice(2)
      }

      links.forEach(link => {
        const fileName = link.type === 'dir' ? `${link.name || ''}/` : link.name
        const padding = link.depth - pathParts.length
        print(
          rightpad(link.hash, multihashWidth + 1) +
          rightpad(link.size || '', sizeWidth + 1) +
          '  '.repeat(padding) + fileName
        )
      })
    })())
  }
}

'''
'''--- src/cli/commands/name.js ---
'use strict'

/*
IPNS is a PKI namespace, where names are the hashes of public keys, and
the private key enables publishing new (signed) values. In both publish
and resolve, the default name used is the node's own PeerID,
which is the hash of its public key.
*/
module.exports = {
  command: 'name <command>',

  description: 'Publish and resolve IPNS names.',

  builder (yargs) {
    return yargs.commandDir('name')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/name/publish.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'publish <ipfsPath>',

  describe: 'Publish IPNS names.',

  builder: {
    resolve: {
      alias: 'r',
      describe: 'Resolve given path before publishing. Default: true.',
      default: true
    },
    lifetime: {
      alias: 't',
      describe: 'Time duration that the record will be valid for. Default: 24h.',
      default: '24h'
    },
    key: {
      alias: 'k',
      describe: 'Name of the key to be used or a valid PeerID, as listed by "ipfs key list -l". Default: self.',
      default: 'self'
    },
    ttl: {
      describe: 'Time duration this record should be cached for (caution: experimental).',
      default: ''
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      // yargs-promise adds resolve/reject properties to argv
      // resolve should use the alias as resolve will always be overwritten to a function
      let resolve = true

      if (argv.r === false || argv.r === 'false') {
        resolve = false
      }

      const opts = {
        resolve,
        lifetime: argv.lifetime,
        key: argv.key,
        ttl: argv.ttl
      }

      const ipfs = await argv.getIpfs()
      const result = await ipfs.name.publish(argv.ipfsPath, opts)
      print(`Published to ${result.name}: ${result.value}`)
    })())
  }
}

'''
'''--- src/cli/commands/name/pubsub.js ---
'use strict'

/*
Manage and inspect the state of the IPNS pubsub resolver.
Note: this command is experimental and subject to change as the system is refined.
*/
module.exports = {
  command: 'pubsub',

  description: 'IPNS pubsub management.',

  builder (yargs) {
    return yargs.commandDir('pubsub')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/name/pubsub/cancel.js ---
'use strict'

const print = require('../../../utils').print

module.exports = {
  command: 'cancel <name>',

  describe: 'Cancel a name subscription.',

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const result = await ipfs.name.pubsub.cancel(argv.name)
      print(result.canceled ? 'canceled' : 'no subscription')
    })())
  }
}

'''
'''--- src/cli/commands/name/pubsub/state.js ---
'use strict'

const print = require('../../../utils').print

module.exports = {
  command: 'state',

  describe: 'Query the state of IPNS pubsub.',

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const result = await ipfs.name.pubsub.state()
      print(result.enabled ? 'enabled' : 'disabled')
    })())
  }
}

'''
'''--- src/cli/commands/name/pubsub/subs.js ---
'use strict'

const print = require('../../../utils').print

module.exports = {
  command: 'subs',

  describe: 'Show current name subscriptions.',

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const result = await ipfs.name.pubsub.subs()
      result.forEach(s => print(s))
    })())
  }
}

'''
'''--- src/cli/commands/name/resolve.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'resolve [<name>]',

  describe: 'Resolve IPNS names.',

  builder: {
    nocache: {
      alias: 'n',
      describe: 'Do not use cached entries. Default: false.',
      default: false
    },
    recursive: {
      alias: 'r',
      recursive: 'Resolve until the result is not an IPNS name. Default: false.',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const opts = {
        nocache: argv.nocache,
        recursive: argv.recursive
      }

      const ipfs = await argv.getIpfs()
      const result = await ipfs.name.resolve(argv.name, opts)

      if (result && result.path) {
        print(result.path)
      } else {
        print(result)
      }
    })())
  }
}

'''
'''--- src/cli/commands/object.js ---
'use strict'

module.exports = {
  command: 'object <command>',

  description: 'Interact with ipfs objects.',

  builder (yargs) {
    return yargs
      .commandDir('object')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/object/data.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'data <key>',

  describe: 'Outputs the raw bytes in an IPFS object',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const data = await ipfs.object.data(argv.key, { enc: 'base58' })
      print(data, false)
    })())
  }
}

'''
'''--- src/cli/commands/object/get.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'get <key>',

  describe: 'Get and serialize the DAG node named by <key>',

  builder: {
    'data-encoding': {
      type: 'string',
      default: 'base64'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, key, dataEncoding, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const node = await ipfs.object.get(key, { enc: 'base58' })
      let data = node.data

      if (Buffer.isBuffer(data)) {
        data = node.data.toString(dataEncoding || undefined)
      }

      const answer = {
        Data: data,
        Hash: cidToString(key, { base: cidBase, upgrade: false }),
        Size: node.size,
        Links: node.links.map((l) => {
          return {
            Name: l.name,
            Size: l.size,
            Hash: cidToString(l.cid, { base: cidBase, upgrade: false })
          }
        })
      }

      print(JSON.stringify(answer))
    })())
  }
}

'''
'''--- src/cli/commands/object/links.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'links <key>',

  describe: 'Outputs the links pointed to by the specified object',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, key, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const links = await ipfs.object.links(key, { enc: 'base58' })

      links.forEach((link) => {
        const cidStr = cidToString(link.cid, { base: cidBase, upgrade: false })
        print(`${cidStr} ${link.size} ${link.name}`)
      })
    })())
  }
}

'''
'''--- src/cli/commands/object/new.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'new [<template>]',

  describe: 'Create new ipfs objects',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, template, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const cid = await ipfs.object.new(template)
      print(cidToString(cid, { base: cidBase, upgrade: false }))
    })())
  }
}

'''
'''--- src/cli/commands/object/patch.js ---
'use strict'

module.exports = {
  command: 'patch',

  description: 'Create a new merkledag object based on an existing one.',

  builder (yargs) {
    return yargs
      .commandDir('patch')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/object/patch/add-link.js ---
'use strict'

const dagPB = require('ipld-dag-pb')
const DAGLink = dagPB.DAGLink
const multibase = require('multibase')
const promisify = require('promisify-es6')
const { print } = require('../../../utils')
const { cidToString } = require('../../../../utils/cid')

module.exports = {
  command: 'add-link <root> <name> <ref>',

  describe: 'Add a link to a given object',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, root, name, ref, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const nodeA = await ipfs.object.get(ref, { enc: 'base58' })
      const result = await promisify(dagPB.util.cid)(nodeA)
      const link = new DAGLink(name, nodeA.size, result)
      const cid = await ipfs.object.patch.addLink(root, link, { enc: 'base58' })
      print(cidToString(cid, { base: cidBase, upgrade: false }))
    })())
  }
}

'''
'''--- src/cli/commands/object/patch/append-data.js ---
'use strict'

const bl = require('bl')
const fs = require('fs')
const multibase = require('multibase')
const { print } = require('../../../utils')
const { cidToString } = require('../../../../utils/cid')

module.exports = {
  command: 'append-data <root> [data]',

  describe: 'Append data to the data segment of a dag node',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      let data

      if (argv.data) {
        data = fs.readFileSync(argv.data)
      } else {
        data = await new Promise((resolve, reject) => {
          process.stdin.pipe(bl((err, input) => {
            if (err) return reject(err)
            resolve(input)
          }))
        })
      }

      const ipfs = await argv.getIpfs()
      const cid = await ipfs.object.patch.appendData(argv.root, data, {
        enc: 'base58'
      })

      print(cidToString(cid, { base: argv.cidBase, upgrade: false }))
    })())
  }
}

'''
'''--- src/cli/commands/object/patch/rm-link.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../../utils')
const { cidToString } = require('../../../../utils/cid')

module.exports = {
  command: 'rm-link <root> <link>',

  describe: 'Remove a link from an object',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, root, link, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const cid = await ipfs.object.patch.rmLink(root, { name: link }, {
        enc: 'base58'
      })

      print(cidToString(cid, { base: cidBase, upgrade: false }))
    })())
  }
}

'''
'''--- src/cli/commands/object/patch/set-data.js ---
'use strict'

const fs = require('fs')
const bl = require('bl')
const multibase = require('multibase')
const { print } = require('../../../utils')
const { cidToString } = require('../../../../utils/cid')

module.exports = {
  command: 'set-data <root> [data]',

  describe: 'Set data field of an ipfs object',

  builder: {
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      let data

      if (argv.data) {
        data = fs.readFileSync(argv.data)
      } else {
        data = await new Promise((resolve, reject) => {
          process.stdin.pipe(bl((err, input) => {
            if (err) return reject(err)
            resolve(input)
          }))
        })
      }

      const ipfs = await argv.getIpfs()
      const cid = await ipfs.object.patch.setData(argv.root, data, {
        enc: 'base58'
      })

      print(cidToString(cid, { base: argv.cidBase, upgrade: false }))
    })())
  }
}

'''
'''--- src/cli/commands/object/put.js ---
'use strict'

const bl = require('bl')
const fs = require('fs')
const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'put [data]',

  describe: 'Stores input as a DAG object, outputs its key',

  builder: {
    'input-enc': {
      type: 'string',
      default: 'json'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in. Note: specifying a CID base for v0 CIDs will have no effect.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      let data

      if (argv.data) {
        data = fs.readFileSync(argv.data)
      } else {
        data = await new Promise((resolve, reject) => {
          process.stdin.pipe(bl((err, input) => {
            if (err) return reject(err)
            resolve(input)
          }))
        })
      }

      const ipfs = await argv.getIpfs()
      const cid = await ipfs.object.put(data, { enc: argv.inputEnc })
      print(`added ${cidToString(cid, { base: argv.cidBase, upgrade: false })}`)
    })())
  }
}

'''
'''--- src/cli/commands/object/stat.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'stat <key>',

  describe: 'Get stats for the DAG node named by <key>',

  builder: {},

  handler ({ getIpfs, key, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const stats = await ipfs.object.stat(key, { enc: 'base58' })
      delete stats.Hash // only for js-ipfs-http-client output
      Object.keys(stats).forEach((key) => print(`${key}: ${stats[key]}`))
    })())
  }
}

'''
'''--- src/cli/commands/pin.js ---
'use strict'

module.exports = {
  command: 'pin',

  description: 'Pin and unpin objects to local storage.',

  builder (yargs) {
    return yargs
      .commandDir('pin')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/pin/add.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'add <ipfsPath...>',

  describe: 'Pins object to local storage.',

  builder: {
    recursive: {
      type: 'boolean',
      alias: 'r',
      default: true,
      describe: 'Recursively pin the object linked to by the specified object(s).'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, ipfsPath, recursive, cidBase, resolve }) {
    resolve((async () => {
      const type = recursive ? 'recursive' : 'direct'
      const ipfs = await getIpfs()
      const results = await ipfs.pin.add(ipfsPath, { recursive })
      results.forEach((res) => {
        print(`pinned ${cidToString(res.hash, { base: cidBase })} ${type}ly`)
      })
    })())
  }
}

'''
'''--- src/cli/commands/pin/ls.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  // bracket syntax with '...' tells yargs to optionally accept a list
  command: 'ls [ipfsPath...]',

  describe: 'List objects pinned to local storage.',

  builder: {
    type: {
      type: 'string',
      alias: 't',
      default: 'all',
      choices: ['direct', 'indirect', 'recursive', 'all'],
      describe: 'The type of pinned keys to list.'
    },
    quiet: {
      type: 'boolean',
      alias: 'q',
      default: false,
      describe: 'Write just hashes of objects.'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler: ({ getIpfs, ipfsPath, type, quiet, cidBase, resolve }) => {
    resolve((async () => {
      const paths = ipfsPath
      const ipfs = await getIpfs()
      const results = await ipfs.pin.ls(paths, { type })
      results.forEach((res) => {
        let line = cidToString(res.hash, { base: cidBase })
        if (!quiet) {
          line += ` ${res.type}`
        }
        print(line)
      })
    })())
  }
}

'''
'''--- src/cli/commands/pin/rm.js ---
'use strict'

const multibase = require('multibase')
const { print } = require('../../utils')
const { cidToString } = require('../../../utils/cid')

module.exports = {
  command: 'rm <ipfsPath...>',

  describe: 'Removes the pinned object from local storage.',

  builder: {
    recursive: {
      type: 'boolean',
      alias: 'r',
      default: true,
      describe: 'Recursively unpin the objects linked to by the specified object(s).'
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler: ({ getIpfs, ipfsPath, recursive, cidBase, resolve }) => {
    resolve((async () => {
      const ipfs = await getIpfs()
      const results = await ipfs.pin.rm(ipfsPath, { recursive })
      results.forEach((res) => {
        print(`unpinned ${cidToString(res.hash, { base: cidBase })}`)
      })
    })())
  }
}

'''
'''--- src/cli/commands/ping.js ---
'use strict'

const pull = require('pull-stream')
const print = require('../utils').print

module.exports = {
  command: 'ping <peerId>',

  description: 'Measure the latency of a connection',

  builder: {
    count: {
      alias: 'n',
      type: 'integer',
      default: 10
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()

      return new Promise((resolve, reject) => {
        const peerId = argv.peerId
        const count = argv.count || 10
        pull(
          ipfs.pingPullStream(peerId, { count }),
          pull.drain(({ success, time, text }) => {
            // Check if it's a pong
            if (success && !text) {
              print(`Pong received: time=${time} ms`)
            // Status response
            } else {
              print(text)
            }
          }, err => {
            if (err) return reject(err)
            resolve()
          })
        )
      })
    })())
  }
}

'''
'''--- src/cli/commands/pubsub.js ---
'use strict'

module.exports = {
  command: 'pubsub <command>',

  description: 'pubsub commands',

  builder (yargs) {
    return yargs
      .commandDir('pubsub')
  },

  handler (argv) {}
}

'''
'''--- src/cli/commands/pubsub/ls.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'ls',

  describe: 'Get your list of subscriptions',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const subscriptions = await ipfs.pubsub.ls()
      subscriptions.forEach(sub => print(sub))
    })())
  }
}

'''
'''--- src/cli/commands/pubsub/peers.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'peers <topic>',

  describe: 'Get all peers subscribed to a topic',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const peers = await ipfs.pubsub.peers(argv.topic)
      peers.forEach(peer => print(peer))
    })())
  }
}

'''
'''--- src/cli/commands/pubsub/pub.js ---
'use strict'

module.exports = {
  command: 'pub <topic> <data>',

  describe: 'Publish data to a topic',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const data = Buffer.from(String(argv.data))
      const ipfs = await argv.getIpfs()
      await ipfs.pubsub.publish(argv.topic, data)
    })())
  }
}

'''
'''--- src/cli/commands/pubsub/sub.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'sub <topic>',

  describe: 'Subscribe to a topic',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const handler = msg => print(msg.data.toString())
      const ipfs = await argv.getIpfs()
      await ipfs.pubsub.subscribe(argv.topic, handler)
    })())
  }
}

'''
'''--- src/cli/commands/repo.js ---
'use strict'

module.exports = {
  command: 'repo <command>',

  description: 'Manipulate the IPFS repo.',

  builder (yargs) {
    return yargs
      .commandDir('repo')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/repo/gc.js ---
'use strict'

module.exports = {
  command: 'gc',

  describe: 'Perform a garbage collection sweep on the repo.',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      await ipfs.repo.gc()
    })())
  }
}

'''
'''--- src/cli/commands/repo/init.js ---
'use strict'

module.exports = {
  command: 'init',

  describe: '',

  builder: {},

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/repo/stat.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'stat',

  describe: 'Get stats for the currently used repo',

  builder: {
    human: {
      type: 'boolean',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const stats = await ipfs.repo.stat({ human: argv.human })
      print(`repo status
  number of objects: ${stats.numObjects}
  repo size: ${stats.repoSize}
  repo path: ${stats.repoPath}
  version: ${stats.version}
  maximum storage: ${stats.storageMax}`)
    })())
  }
}

'''
'''--- src/cli/commands/repo/version.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'version',

  describe: 'Shows IPFS repo version information',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const version = await ipfs.repo.version()
      print(version)
    })())
  }
}

'''
'''--- src/cli/commands/resolve.js ---
'use strict'

const multibase = require('multibase')
const print = require('../utils').print

module.exports = {
  command: 'resolve <name>',

  description: 'Resolve the value of names to IPFS',

  builder: {
    recursive: {
      alias: 'r',
      type: 'boolean',
      default: false
    },
    'cid-base': {
      describe: 'Number base to display CIDs in.',
      type: 'string',
      choices: multibase.names
    }
  },

  handler ({ getIpfs, name, recursive, cidBase, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()
      const res = await ipfs.resolve(name, { recursive, cidBase })
      print(res)
    })())
  }
}

'''
'''--- src/cli/commands/shutdown.js ---
'use strict'

module.exports = {
  command: 'shutdown',

  describe: 'Shut down the ipfs daemon',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      return ipfs.shutdown()
    })())
  }
}

'''
'''--- src/cli/commands/stats.js ---
'use strict'

module.exports = {
  command: 'stats <command>',

  description: 'Query IPFS statistics.',

  builder (yargs) {
    return yargs.commandDir('stats')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/stats/bitswap.js ---
'use strict'

// This is an alias for `bitswap stat`.
const bitswapStats = require('../bitswap/stat.js')
// The command needs to be renamed, else it would be `stats stat` instead of
// `stats bitswap`
bitswapStats.command = 'bitswap'
module.exports = bitswapStats

'''
'''--- src/cli/commands/stats/bw.js ---
'use strict'

const pull = require('pull-stream')
const print = require('../../utils').print

module.exports = {
  command: 'bw',

  describe: 'Get bandwidth information.',

  builder: {
    peer: {
      type: 'string',
      default: ''
    },
    proto: {
      type: 'string',
      default: ''
    },
    poll: {
      type: 'boolean',
      default: false
    },
    interval: {
      type: 'string',
      default: '1s'
    }
  },

  handler ({ getIpfs, peer, proto, poll, interval, resolve }) {
    resolve((async () => {
      const ipfs = await getIpfs()

      return new Promise((resolve, reject) => {
        const stream = ipfs.stats.bwPullStream({ peer, proto, poll, interval })

        const onChunk = chunk => {
          print(`bandwidth status
  total in: ${chunk.totalIn}B
  total out: ${chunk.totalOut}B
  rate in: ${chunk.rateIn}B/s
  rate out: ${chunk.rateOut}B/s`)
        }

        const onEnd = err => {
          if (err) return reject(err)
          resolve()
        }

        pull(stream, pull.drain(onChunk, onEnd))
      })
    })())
  }
}

'''
'''--- src/cli/commands/stats/repo.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'repo',

  describe: 'Get stats for the currently used repo',

  builder: {
    human: {
      type: 'boolean',
      default: false
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const stats = await ipfs.stats.repo({ human: argv.human })
      print(`repo status
  number of objects: ${stats.numObjects}
  repo size: ${stats.repoSize}
  repo path: ${stats.repoPath}
  version: ${stats.version}
  maximum storage: ${stats.storageMax}`)
    })())
  }
}

'''
'''--- src/cli/commands/swarm.js ---
'use strict'

module.exports = {
  command: 'swarm <command>',

  description: 'Swarm inspection tool.',

  builder (yargs) {
    return yargs
      .commandDir('swarm')
  },

  handler (argv) {
  }
}

'''
'''--- src/cli/commands/swarm/addrs.js ---
'use strict'

const print = require('../../utils').print

module.exports = {
  command: 'addrs',

  describe: '',

  builder (yargs) {
    return yargs
      .commandDir('addrs')
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const res = await ipfs.swarm.addrs()
      res.forEach((peer) => {
        const count = peer.multiaddrs.size
        print(`${peer.id.toB58String()} (${count})`)

        peer.multiaddrs.forEach((addr) => {
          const res = addr.decapsulate('ipfs').toString()
          print(`\t${res}`)
        })
      })
    })())
  }
}

'''
'''--- src/cli/commands/swarm/addrs/local.js ---
'use strict'

const utils = require('../../../utils')
const debug = require('debug')
const log = debug('cli:object')
log.error = debug('cli:object:error')
const print = require('../../../utils').print

module.exports = {
  command: 'local',

  describe: 'List local addresses',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (!utils.isDaemonOn()) {
        throw new Error('This command must be run in online mode. Try running \'ipfs daemon\' first.')
      }
      const ipfs = await argv.getIpfs()
      const res = await ipfs.swarm.localAddrs()
      res.forEach(addr => print(addr.toString()))
    })())
  }
}

'''
'''--- src/cli/commands/swarm/connect.js ---
'use strict'

const utils = require('../../utils')
const print = utils.print

module.exports = {
  command: 'connect <address>',

  describe: 'Open connection to a given address',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (!utils.isDaemonOn()) {
        throw new Error('This command must be run in online mode. Try running \'ipfs daemon\' first.')
      }
      const ipfs = await argv.getIpfs()
      const res = await ipfs.swarm.connect(argv.address)
      print(res.Strings[0])
    })())
  }
}

'''
'''--- src/cli/commands/swarm/disconnect.js ---
'use strict'

const utils = require('../../utils')
const print = require('../../utils').print

module.exports = {
  command: 'disconnect <address>',

  describe: 'Close connection to a given address',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (!utils.isDaemonOn()) {
        throw new Error('This command must be run in online mode. Try running \'ipfs daemon\' first.')
      }
      const ipfs = await argv.getIpfs()
      const res = await ipfs.swarm.disconnect(argv.address)
      print(res.Strings[0])
    })())
  }
}

'''
'''--- src/cli/commands/swarm/peers.js ---
'use strict'

const mafmt = require('mafmt')
const multiaddr = require('multiaddr')
const utils = require('../../utils')
const print = require('../../utils').print

module.exports = {
  command: 'peers',

  describe: 'List peers with open connections',

  builder: {},

  handler (argv) {
    argv.resolve((async () => {
      if (!utils.isDaemonOn()) {
        throw new Error('This command must be run in online mode. Try running \'ipfs daemon\' first.')
      }

      const ipfs = await argv.getIpfs()
      const result = await ipfs.swarm.peers()

      result.forEach((item) => {
        let ma = multiaddr(item.addr.toString())
        if (!mafmt.IPFS.matches(ma)) {
          ma = ma.encapsulate('/ipfs/' + item.peer.toB58String())
        }
        const addr = ma.toString()
        print(addr)
      })
    })())
  }
}

'''
'''--- src/cli/commands/version.js ---
'use strict'

const os = require('os')
const print = require('../utils').print

module.exports = {
  command: 'version',

  describe: 'Shows IPFS version information',

  builder: {
    number: {
      alias: 'n',
      type: 'boolean',
      default: false,
      describe: 'Print only the version number'
    },
    commit: {
      type: 'boolean',
      default: false,
      describe: `Include the version's commit hash`
    },
    repo: {
      type: 'boolean',
      default: false,
      describe: `Print only the repo's version number`
    },
    all: {
      type: 'boolean',
      default: false,
      describe: 'Print everything we have'
    }
  },

  handler (argv) {
    argv.resolve((async () => {
      const ipfs = await argv.getIpfs()
      const data = await ipfs.version()

      const withCommit = argv.all || argv.commit
      const parsedVersion = `${data.version}${withCommit ? `-${data.commit}` : ''}`

      if (argv.repo) {
        // go-ipfs prints only the number, even without the --number flag.
        print(data.repo)
      } else if (argv.number) {
        print(parsedVersion)
      } else if (argv.all) {
        print(`js-ipfs version: ${parsedVersion}`)
        print(`Repo version: ${data.repo}`)
        print(`System version: ${os.arch()}/${os.platform()}`)
        print(`Node.js version: ${process.version}`)
      } else {
        print(`js-ipfs version: ${parsedVersion}`)
      }
    })())
  }
}

'''
'''--- src/cli/utils.js ---
'use strict'

const fs = require('fs')
const os = require('os')
const multiaddr = require('multiaddr')
const path = require('path')
const debug = require('debug')
const log = debug('cli')
log.error = debug('cli:error')
const Progress = require('progress')
const byteman = require('byteman')
const promisify = require('promisify-es6')

exports = module.exports

exports.isDaemonOn = isDaemonOn
function isDaemonOn () {
  try {
    fs.readFileSync(path.join(exports.getRepoPath(), 'api'))
    log('daemon is on')
    return true
  } catch (err) {
    log('daemon is off')
    return false
  }
}

exports.getAPICtl = getAPICtl
function getAPICtl (apiAddr) {
  if (!apiAddr && !isDaemonOn()) {
    throw new Error('daemon is not on')
  }
  if (!apiAddr) {
    const apiPath = path.join(exports.getRepoPath(), 'api')
    apiAddr = multiaddr(fs.readFileSync(apiPath).toString()).toString()
  }
  // Required inline to reduce startup time
  const APIctl = require('ipfs-http-client')
  return APIctl(apiAddr)
}

exports.getIPFS = (argv, callback) => {
  if (argv.api || isDaemonOn()) {
    return callback(null, getAPICtl(argv.api), promisify((cb) => cb()))
  }

  // Required inline to reduce startup time
  const IPFS = require('../core')
  const node = new IPFS({
    silent: argv.silent,
    repo: exports.getRepoPath(),
    init: false,
    start: false,
    pass: argv.pass,
    EXPERIMENTAL: {
      pubsub: true
    }
  })

  const cleanup = promisify((cb) => {
    if (node && node._repo && !node._repo.closed) {
      node._repo.close((err) => cb(err))
    } else {
      cb()
    }
  })

  node.on('error', (err) => {
    throw err
  })

  node.once('ready', () => {
    callback(null, node, cleanup)
  })
}

exports.getRepoPath = () => {
  return process.env.IPFS_PATH || os.homedir() + '/.jsipfs'
}

let visible = true
exports.disablePrinting = () => { visible = false }

exports.print = (msg, newline) => {
  if (newline === undefined) {
    newline = true
  }

  if (visible) {
    if (msg === undefined) {
      msg = ''
    }
    msg = newline ? msg + '\n' : msg
    process.stdout.write(msg)
  }
}

exports.createProgressBar = (totalBytes) => {
  const total = byteman(totalBytes, 2, 'MB')
  const barFormat = `:progress / ${total} [:bar] :percent :etas`

  // 16 MB / 34 MB [===========             ] 48% 5.8s //
  return new Progress(barFormat, {
    incomplete: ' ',
    clear: true,
    stream: process.stdout,
    total: totalBytes
  })
}

exports.rightpad = (val, n) => {
  let result = String(val)
  for (let i = result.length; i < n; ++i) {
    result += ' '
  }
  return result
}

exports.ipfsPathHelp = 'ipfs uses a repository in the local file system. By default, the repo is ' +
  'located at ~/.jsipfs. To change the repo location, set the $IPFS_PATH environment variable:\n\n' +
  'export IPFS_PATH=/path/to/ipfsrepo\n'

exports.singleton = create => {
  const requests = []
  const getter = promisify(cb => {
    if (getter.instance) return cb(null, getter.instance, ...getter.rest)
    requests.push(cb)
    if (requests.length > 1) return
    create((err, instance, ...rest) => {
      getter.instance = instance
      getter.rest = rest
      while (requests.length) requests.pop()(err, instance, ...rest)
    })
  })
  return getter
}

'''
'''--- src/core/boot.js ---
'use strict'

const waterfall = require('async/waterfall')
const RepoErrors = require('ipfs-repo').errors

// Boot an IPFS node depending on the options set
module.exports = (self) => {
  self.log('booting')
  const options = self._options
  const doInit = options.init
  const doStart = options.start

  // Do the actual boot sequence
  waterfall([
    // Checks if a repo exists, and if so opens it
    // Will return callback with a bool indicating the existence
    // of the repo
    (cb) => {
      // nothing to do
      if (!self._repo.closed) {
        return cb(null, true)
      }

      self._repo.open((err, res) => {
        if (isRepoUninitializedError(err)) return cb(null, false)
        if (err) return cb(err)
        cb(null, true)
      })
    },
    (repoOpened, cb) => {
      // Init with existing initialized, opened, repo
      if (repoOpened) {
        return self.init({ repo: self._repo }, (err) => {
          if (err) return cb(Object.assign(err, { emitted: true }))
          cb()
        })
      }

      if (doInit) {
        const initOptions = Object.assign(
          { bits: 2048, pass: self._options.pass },
          typeof options.init === 'object' ? options.init : {}
        )
        return self.init(initOptions, (err) => {
          if (err) return cb(Object.assign(err, { emitted: true }))
          cb()
        })
      }

      cb()
    },
    (cb) => {
      // No problem, we don't have to start the node
      if (!doStart) {
        return cb()
      }

      self.start((err) => {
        if (err) return cb(Object.assign(err, { emitted: true }))
        cb()
      })
    }
  ], (err) => {
    if (err) {
      if (!err.emitted) {
        self.emit('error', err)
      }
      return
    }
    self.log('booted')
    self.emit('ready')
  })
}

function isRepoUninitializedError (err) {
  if (!err) {
    return false
  }

  // If the error is that no repo exists,
  // which happens when the version file is not found
  // we just want to signal that no repo exist, not
  // fail the whole process.

  // Use standardized errors as much as possible
  if (err.code === RepoErrors.ERR_REPO_NOT_INITIALIZED) {
    return true
  }

  // TODO: As error codes continue to be standardized, this logic can be phase out;
  // it is here to maintain compatibility
  if (err.message.match(/not found/) || // indexeddb
    err.message.match(/ENOENT/) || // fs
    err.message.match(/No value/) // memory
  ) {
    return true
  }

  return false
}

'''
'''--- src/core/components/bitswap.js ---
'use strict'

const OFFLINE_ERROR = require('../utils').OFFLINE_ERROR
const promisify = require('promisify-es6')
const setImmediate = require('async/setImmediate')
const Big = require('bignumber.js')
const CID = require('cids')
const PeerId = require('peer-id')
const errCode = require('err-code')

function formatWantlist (list, cidBase) {
  return Array.from(list).map((e) => ({ '/': e[1].cid.toBaseEncodedString() }))
}

module.exports = function bitswap (self) {
  return {
    wantlist: promisify((peerId, callback) => {
      if (typeof peerId === 'function') {
        callback = peerId
        peerId = null
      }

      if (!self.isOnline()) {
        return setImmediate(() => callback(new Error(OFFLINE_ERROR)))
      }

      let list
      if (peerId) {
        try {
          peerId = PeerId.createFromB58String(peerId)
        } catch (e) {
          peerId = null
        }
        if (!peerId) {
          return setImmediate(() => callback(new Error('Invalid peerId')))
        }
        list = self._bitswap.wantlistForPeer(peerId)
      } else {
        list = self._bitswap.getWantlist()
      }

      setImmediate(() => callback(null, { Keys: formatWantlist(list) }))
    }),

    stat: promisify((callback) => {
      if (!self.isOnline()) {
        return setImmediate(() => callback(new Error(OFFLINE_ERROR)))
      }

      const snapshot = self._bitswap.stat().snapshot

      setImmediate(() => {
        callback(null, {
          provideBufLen: parseInt(snapshot.providesBufferLength.toString()),
          blocksReceived: new Big(snapshot.blocksReceived),
          wantlist: formatWantlist(self._bitswap.getWantlist()),
          peers: self._bitswap.peers().map((id) => id.toB58String()),
          dupBlksReceived: new Big(snapshot.dupBlksReceived),
          dupDataReceived: new Big(snapshot.dupDataReceived),
          dataReceived: new Big(snapshot.dataReceived),
          blocksSent: new Big(snapshot.blocksSent),
          dataSent: new Big(snapshot.dataSent)
        })
      })
    }),

    unwant: promisify((keys, callback) => {
      if (!self.isOnline()) {
        return setImmediate(() => callback(new Error(OFFLINE_ERROR)))
      }

      if (!Array.isArray(keys)) {
        keys = [keys]
      }

      try {
        keys = keys.map((key) => {
          if (CID.isCID(key)) {
            return key
          }
          return new CID(key)
        })
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }

      setImmediate(() => callback(null, self._bitswap.unwant(keys)))
    })
  }
}

'''
'''--- src/core/components/block.js ---
'use strict'

const Block = require('ipfs-block')
const multihashing = require('multihashing-async')
const CID = require('cids')
const waterfall = require('async/waterfall')
const setImmediate = require('async/setImmediate')
const promisify = require('promisify-es6')
const errCode = require('err-code')

module.exports = function block (self) {
  return {
    get: promisify((cid, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      try {
        cid = cleanCid(cid)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }

      if (options.preload !== false) {
        self._preload(cid)
      }

      self._blockService.get(cid, callback)
    }),
    put: promisify((block, options, callback) => {
      callback = callback || function noop () {}

      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      if (Array.isArray(block)) {
        return callback(new Error('Array is not supported'))
      }

      waterfall([
        (cb) => {
          if (Block.isBlock(block)) {
            return cb(null, block)
          }

          if (options.cid && CID.isCID(options.cid)) {
            return cb(null, new Block(block, options.cid))
          }

          const mhtype = options.mhtype || 'sha2-256'
          const format = options.format || 'dag-pb'
          let cidVersion
          // const mhlen = options.mhlen || 0

          if (options.version == null) {
            // Pick appropriate CID version
            cidVersion = mhtype === 'sha2-256' && format === 'dag-pb' ? 0 : 1
          } else {
            cidVersion = options.version
          }

          multihashing(block, mhtype, (err, multihash) => {
            if (err) {
              return cb(err)
            }

            let cid
            try {
              cid = new CID(cidVersion, format, multihash)
            } catch (err) {
              return cb(err)
            }

            cb(null, new Block(block, cid))
          })
        },
        (block, cb) => self._blockService.put(block, (err) => {
          if (err) {
            return cb(err)
          }

          if (options.preload !== false) {
            self._preload(block.cid)
          }

          cb(null, block)
        })
      ], callback)
    }),
    rm: promisify((cid, callback) => {
      try {
        cid = cleanCid(cid)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }
      self._blockService.delete(cid, callback)
    }),
    stat: promisify((cid, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      try {
        cid = cleanCid(cid)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }

      if (options.preload !== false) {
        self._preload(cid)
      }

      self._blockService.get(cid, (err, block) => {
        if (err) {
          return callback(err)
        }
        callback(null, {
          key: cid.toString(),
          size: block.data.length
        })
      })
    })
  }
}

function cleanCid (cid) {
  if (CID.isCID(cid)) {
    return cid
  }

  // CID constructor knows how to do the cleaning :)
  return new CID(cid)
}

'''
'''--- src/core/components/bootstrap.js ---
'use strict'

const defaultConfig = require('../runtime/config-nodejs.js')
const isMultiaddr = require('mafmt').IPFS.matches
const promisify = require('promisify-es6')

function isValidMultiaddr (ma) {
  try {
    return isMultiaddr(ma)
  } catch (err) {
    return false
  }
}

function invalidMultiaddrError (ma) {
  return new Error(`${ma} is not a valid Multiaddr`)
}

module.exports = function bootstrap (self) {
  return {
    list: promisify((callback) => {
      self._repo.config.get((err, config) => {
        if (err) {
          return callback(err)
        }
        callback(null, { Peers: config.Bootstrap })
      })
    }),
    add: promisify((multiaddr, args, callback) => {
      if (typeof args === 'function') {
        callback = args
        args = { default: false }
      }

      if (multiaddr && !isValidMultiaddr(multiaddr)) {
        return setImmediate(() => callback(invalidMultiaddrError(multiaddr)))
      }

      self._repo.config.get((err, config) => {
        if (err) {
          return callback(err)
        }
        if (args.default) {
          config.Bootstrap = defaultConfig().Bootstrap
        } else if (multiaddr && config.Bootstrap.indexOf(multiaddr) === -1) {
          config.Bootstrap.push(multiaddr)
        }
        self._repo.config.set(config, (err) => {
          if (err) {
            return callback(err)
          }

          callback(null, {
            Peers: args.default ? defaultConfig().Bootstrap : [multiaddr]
          })
        })
      })
    }),
    rm: promisify((multiaddr, args, callback) => {
      if (typeof args === 'function') {
        callback = args
        args = { all: false }
      }
      if (multiaddr && !isValidMultiaddr(multiaddr)) {
        return setImmediate(() => callback(invalidMultiaddrError(multiaddr)))
      }

      self._repo.config.get((err, config) => {
        if (err) {
          return callback(err)
        }
        if (args.all) {
          config.Bootstrap = []
        } else {
          config.Bootstrap = config.Bootstrap.filter((mh) => mh !== multiaddr)
        }

        self._repo.config.set(config, (err) => {
          if (err) {
            return callback(err)
          }

          const res = []
          if (!args.all && multiaddr) {
            res.push(multiaddr)
          }

          callback(null, { Peers: res })
        })
      })
    })
  }
}

'''
'''--- src/core/components/config.js ---
'use strict'

const promisify = require('promisify-es6')

module.exports = function config (self) {
  return {
    get: promisify((key, callback) => {
      if (typeof key === 'function') {
        callback = key
        key = undefined
      }

      return self._repo.config.get(key, callback)
    }),
    set: promisify((key, value, callback) => {
      self._repo.config.set(key, value, callback)
    }),
    replace: promisify((config, callback) => {
      self._repo.config.set(config, callback)
    })
  }
}

'''
'''--- src/core/components/dag.js ---
'use strict'

const promisify = require('promisify-es6')
const CID = require('cids')
const pull = require('pull-stream')
const mapAsync = require('async/map')
const setImmediate = require('async/setImmediate')
const flattenDeep = require('lodash/flattenDeep')
const errCode = require('err-code')

module.exports = function dag (self) {
  return {
    put: promisify((dagNode, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      if (options.cid && (options.format || options.hashAlg)) {
        return callback(new Error('Can\'t put dag node. Please provide either `cid` OR `format` and `hashAlg` options.'))
      } else if (((options.format && !options.hashAlg) || (!options.format && options.hashAlg))) {
        return callback(new Error('Can\'t put dag node. Please provide `format` AND `hashAlg` options.'))
      }

      const optionDefaults = {
        format: 'dag-cbor',
        hashAlg: 'sha2-256'
      }

      options = options.cid ? options : Object.assign({}, optionDefaults, options)

      self._ipld.put(dagNode, options, (err, cid) => {
        if (err) return callback(err)

        if (options.preload !== false) {
          self._preload(cid)
        }

        callback(null, cid)
      })
    }),

    get: promisify((cid, path, options, callback) => {
      if (typeof path === 'function') {
        callback = path
        path = undefined
      }

      if (typeof options === 'function') {
        callback = options

        // Allow options in path position
        if (typeof path !== 'string') {
          options = path
          path = null
        } else {
          options = {}
        }
      }

      options = options || {}

      if (typeof cid === 'string') {
        const split = cid.split('/')

        try {
          cid = new CID(split[0])
        } catch (err) {
          return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
        }

        split.shift()

        if (split.length > 0) {
          path = split.join('/')
        } else {
          path = '/'
        }
      } else if (Buffer.isBuffer(cid)) {
        try {
          cid = new CID(cid)
        } catch (err) {
          return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
        }
      }

      if (options.preload !== false) {
        self._preload(cid)
      }

      self._ipld.get(cid, path, options, callback)
    }),

    tree: promisify((cid, path, options, callback) => {
      if (typeof path === 'object') {
        callback = options
        options = path
        path = undefined
      }

      if (typeof path === 'function') {
        callback = path
        path = undefined
      }

      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      if (typeof cid === 'string') {
        const split = cid.split('/')

        try {
          cid = new CID(split[0])
        } catch (err) {
          return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
        }

        split.shift()

        if (split.length > 0) {
          path = split.join('/')
        } else {
          path = undefined
        }
      }

      if (options.preload !== false) {
        self._preload(cid)
      }

      pull(
        self._ipld.treeStream(cid, path, options),
        pull.collect(callback)
      )
    }),

    // TODO - use IPLD selectors once they are implemented
    _getRecursive: promisify((multihash, options, callback) => {
      // gets flat array of all DAGNodes in tree given by multihash

      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      let cid

      try {
        cid = new CID(multihash)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }

      self.dag.get(cid, '', options, (err, res) => {
        if (err) { return callback(err) }

        mapAsync(res.value.links, (link, cb) => {
          self.dag._getRecursive(link.cid, options, cb)
        }, (err, nodes) => {
          // console.log('nodes:', nodes)
          if (err) return callback(err)
          callback(null, flattenDeep([res.value, nodes]))
        })
      })
    })
  }
}

'''
'''--- src/core/components/dht.js ---
'use strict'

const promisify = require('promisify-es6')
const every = require('async/every')
const PeerId = require('peer-id')
const PeerInfo = require('peer-info')
const CID = require('cids')
const each = require('async/each')
const nextTick = require('async/nextTick')

const errcode = require('err-code')

const debug = require('debug')
const log = debug('jsipfs:dht')
log.error = debug('jsipfs:dht:error')

module.exports = (self) => {
  return {
    /**
     * Given a key, query the DHT for its best value.
     *
     * @param {Buffer} key
     * @param {Object} options - get options
     * @param {number} options.timeout - optional timeout
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    get: promisify((key, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      if (!Buffer.isBuffer(key)) {
        try {
          key = (new CID(key)).buffer
        } catch (err) {
          log.error(err)

          return nextTick(() => callback(errcode(err, 'ERR_INVALID_CID')))
        }
      }

      self.libp2p.dht.get(key, options, callback)
    }),

    /**
     * Write a key/value pair to the DHT.
     *
     * Given a key of the form /foo/bar and a value of any
     * form, this will write that value to the DHT with
     * that key.
     *
     * @param {Buffer} key
     * @param {Buffer} value
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    put: promisify((key, value, callback) => {
      if (!Buffer.isBuffer(key)) {
        try {
          key = (new CID(key)).buffer
        } catch (err) {
          log.error(err)

          return nextTick(() => callback(errcode(err, 'ERR_INVALID_CID')))
        }
      }

      self.libp2p.dht.put(key, value, callback)
    }),

    /**
     * Find peers in the DHT that can provide a specific value, given a key.
     *
     * @param {CID} key - They key to find providers for.
     * @param {Object} options - findProviders options
     * @param {number} options.timeout - how long the query should maximally run, in milliseconds (default: 60000)
     * @param {number} options.maxNumProviders - maximum number of providers to find
     * @param {function(Error, Array<PeerInfo>)} [callback]
     * @returns {Promise<PeerInfo>|void}
     */
    findProvs: promisify((key, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      if (typeof key === 'string') {
        try {
          key = new CID(key)
        } catch (err) {
          log.error(err)

          return nextTick(() => callback(errcode(err, 'ERR_INVALID_CID')))
        }
      }

      self.libp2p.contentRouting.findProviders(key, options, callback)
    }),

    /**
     * Query the DHT for all multiaddresses associated with a `PeerId`.
     *
     * @param {PeerId} peer - The id of the peer to search for.
     * @param {function(Error, PeerInfo)} [callback]
     * @returns {Promise<PeerInfo>|void}
     */
    findPeer: promisify((peer, callback) => {
      if (typeof peer === 'string') {
        peer = PeerId.createFromB58String(peer)
      }

      self.libp2p.peerRouting.findPeer(peer, callback)
    }),

    /**
     * Announce to the network that we are providing given values.
     *
     * @param {CID|Array<CID>} keys - The keys that should be announced.
     * @param {Object} options - provide options
     * @param {bool} [options.recursive=false] - Provide not only the given object but also all objects linked from it.
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    provide: promisify((keys, options, callback) => {
      if (!Array.isArray(keys)) {
        keys = [keys]
      }
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      // ensure blocks are actually local
      every(keys, (key, cb) => {
        self._repo.blocks.has(key, cb)
      }, (err, has) => {
        if (err) {
          return callback(err)
        }

        if (!has) {
          const errMsg = 'block(s) not found locally, cannot provide'

          log.error(errMsg)
          return callback(errcode(errMsg, 'ERR_BLOCK_NOT_FOUND'))
        }

        if (options.recursive) {
          // TODO: Implement recursive providing
          return callback(errcode('not implemented yet', 'ERR_NOT_IMPLEMENTED_YET'))
        } else {
          each(keys, (cid, cb) => {
            self.libp2p.contentRouting.provide(cid, cb)
          }, callback)
        }
      })
    }),

    /**
     * Find the closest peers to a given `PeerId`, by querying the DHT.
     *
     * @param {PeerId} peer - The `PeerId` to run the query agains.
     * @param {function(Error, Array<PeerInfo>)} [callback]
     * @returns {Promise<Array<PeerInfo>>|void}
     */
    query: promisify((peerId, callback) => {
      if (typeof peerId === 'string') {
        try {
          peerId = PeerId.createFromB58String(peerId)
        } catch (err) {
          log.error(err)
          return callback(err)
        }
      }

      // TODO expose this method in peerRouting
      self.libp2p._dht.getClosestPeers(peerId.toBytes(), (err, peerIds) => {
        if (err) {
          log.error(err)
          return callback(err)
        }

        callback(null, peerIds.map((id) => new PeerInfo(id)))
      })
    })
  }
}

'''
'''--- src/core/components/dns.js ---
'use strict'

// dns-nodejs gets replaced by dns-browser when webpacked/browserified
const dns = require('../runtime/dns-nodejs')
const promisify = require('promisify-es6')

module.exports = () => {
  return promisify((domain, opts, callback) => {
    if (typeof domain !== 'string') {
      return callback(new Error('Invalid arguments, domain must be a string'))
    }

    if (typeof opts === 'function') {
      callback = opts
      opts = {}
    }

    opts = opts || {}

    dns(domain, opts, callback)
  })
}

'''
'''--- src/core/components/files-mfs.js ---
'use strict'

const mfs = require('ipfs-mfs/core')

module.exports = self => mfs({
  ipld: self._ipld,
  repo: self._repo,
  repoOwner: self._options.repoOwner
})

'''
'''--- src/core/components/files-regular/add-from-fs.js ---
'use strict'

module.exports = (self) => require('../../runtime/add-from-fs-nodejs')(self)

'''
'''--- src/core/components/files-regular/add-from-stream.js ---
'use strict'

module.exports = self => require('./add')(self)

'''
'''--- src/core/components/files-regular/add-from-url.js ---
'use strict'

const { URL } = require('url')
const fetch = require('../../runtime/fetch-nodejs')

module.exports = (self) => {
  return async (url, options, callback) => {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    let files

    try {
      const parsedUrl = new URL(url)
      const res = await fetch(url)

      if (!res.ok) {
        throw new Error('unexpected status code: ' + res.status)
      }

      // TODO: use res.body when supported
      const content = Buffer.from(await res.arrayBuffer())
      const path = decodeURIComponent(parsedUrl.pathname.split('/').pop())

      files = await self.add({ content, path }, options)
    } catch (err) {
      if (callback) {
        return callback(err)
      }
      throw err
    }

    if (callback) {
      callback(null, files)
    }

    return files
  }
}

'''
'''--- src/core/components/files-regular/add-pull-stream.js ---
'use strict'

const { importer } = require('ipfs-unixfs-engine')
const pull = require('pull-stream')
const toPull = require('stream-to-pull-stream')
const waterfall = require('async/waterfall')
const isStream = require('is-stream')
const isSource = require('is-pull-stream').isSource
const CID = require('cids')
const { parseChunkerString } = require('./utils')

const WRAPPER = 'wrapper/'

function noop () {}

function prepareFile (file, self, opts, callback) {
  opts = opts || {}

  let cid = new CID(file.multihash)

  if (opts.cidVersion === 1) {
    cid = cid.toV1()
  }

  waterfall([
    (cb) => opts.onlyHash
      ? cb(null, file)
      : self.object.get(file.multihash, Object.assign({}, opts, { preload: false }), cb),
    (node, cb) => {
      const b58Hash = cid.toBaseEncodedString()

      let size = node.size

      if (Buffer.isBuffer(node)) {
        size = node.length
      }

      cb(null, {
        path: opts.wrapWithDirectory
          ? file.path.substring(WRAPPER.length)
          : (file.path || b58Hash),
        hash: b58Hash,
        size
      })
    }
  ], callback)
}

function normalizeContent (content, opts) {
  if (!Array.isArray(content)) {
    content = [content]
  }

  return content.map((data) => {
    // Buffer input
    if (Buffer.isBuffer(data)) {
      data = { path: '', content: pull.values([data]) }
    }

    // Readable stream input
    if (isStream.readable(data)) {
      data = { path: '', content: toPull.source(data) }
    }

    if (isSource(data)) {
      data = { path: '', content: data }
    }

    if (data && data.content && typeof data.content !== 'function') {
      if (Buffer.isBuffer(data.content)) {
        data.content = pull.values([data.content])
      }

      if (isStream.readable(data.content)) {
        data.content = toPull.source(data.content)
      }
    }

    if (opts.wrapWithDirectory && !data.path) {
      throw new Error('Must provide a path when wrapping with a directory')
    }

    if (opts.wrapWithDirectory) {
      data.path = WRAPPER + data.path
    }

    return data
  })
}

function preloadFile (file, self, opts) {
  const isRootFile = opts.wrapWithDirectory
    ? file.path === ''
    : !file.path.includes('/')

  const shouldPreload = isRootFile && !opts.onlyHash && opts.preload !== false

  if (shouldPreload) {
    self._preload(file.hash)
  }

  return file
}

function pinFile (file, self, opts, cb) {
  // Pin a file if it is the root dir of a recursive add or the single file
  // of a direct add.
  const pin = 'pin' in opts ? opts.pin : true
  const isRootDir = !file.path.includes('/')
  const shouldPin = pin && isRootDir && !opts.onlyHash && !opts.hashAlg
  if (shouldPin) {
    return self.pin.add(file.hash, { preload: false }, err => cb(err, file))
  } else {
    cb(null, file)
  }
}

module.exports = function (self) {
  // Internal add func that gets used by all add funcs
  return function addPullStream (options) {
    options = options || {}

    let chunkerOptions
    try {
      chunkerOptions = parseChunkerString(options.chunker)
    } catch (err) {
      return pull.map(() => { throw err })
    }
    const opts = Object.assign({}, {
      shardSplitThreshold: self._options.EXPERIMENTAL.sharding
        ? 1000
        : Infinity
    }, options, chunkerOptions)

    // CID v0 is for multihashes encoded with sha2-256
    if (opts.hashAlg && opts.cidVersion !== 1) {
      opts.cidVersion = 1
    }

    let total = 0

    const prog = opts.progress || noop
    const progress = (bytes) => {
      total += bytes
      prog(total)
    }

    opts.progress = progress
    return pull(
      pull.map(content => normalizeContent(content, opts)),
      pull.flatten(),
      importer(self._ipld, opts),
      pull.asyncMap((file, cb) => prepareFile(file, self, opts, cb)),
      pull.map(file => preloadFile(file, self, opts)),
      pull.asyncMap((file, cb) => pinFile(file, self, opts, cb))
    )
  }
}

'''
'''--- src/core/components/files-regular/add-readable-stream.js ---
'use strict'

const pull = require('pull-stream')
const pushable = require('pull-pushable')
const Duplex = require('readable-stream').Duplex

class AddHelper extends Duplex {
  constructor (pullStream, push, options) {
    super(Object.assign({ objectMode: true }, options))
    this._pullStream = pullStream
    this._pushable = push
    this._waitingPullFlush = []
  }

  _read () {
    this._pullStream(null, (end, data) => {
      while (this._waitingPullFlush.length) {
        const cb = this._waitingPullFlush.shift()
        cb()
      }
      if (end) {
        if (end instanceof Error) {
          this.emit('error', end)
        }
      } else {
        this.push(data)
      }
    })
  }

  _write (chunk, encoding, callback) {
    this._waitingPullFlush.push(callback)
    this._pushable.push(chunk)
  }
}

module.exports = function (self) {
  return (options) => {
    options = options || {}

    const p = pushable()
    const s = pull(
      p,
      self.addPullStream(options)
    )

    const retStream = new AddHelper(s, p)

    retStream.once('finish', () => p.end())

    return retStream
  }
}

'''
'''--- src/core/components/files-regular/add.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream')
const sort = require('pull-sort')
const isStream = require('is-stream')
const isSource = require('is-pull-stream').isSource
const isString = require('lodash/isString')

module.exports = function (self) {
  const add = promisify((data, options, callback) => {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    options = options || {}

    // Buffer, pull stream or Node.js stream
    const isBufferOrStream = obj => Buffer.isBuffer(obj) || isStream.readable(obj) || isSource(obj)
    // An object like { content?, path? }, where content isBufferOrStream and path isString
    const isContentObject = obj => {
      if (typeof obj !== 'object') return false
      // path is optional if content is present
      if (obj.content) return isBufferOrStream(obj.content)
      // path must be a non-empty string if no content
      return Boolean(obj.path) && isString(obj.path)
    }
    // An input atom: a buffer, stream or content object
    const isInput = obj => isBufferOrStream(obj) || isContentObject(obj)
    // All is ok if data isInput or data is an array of isInput
    const ok = isInput(data) || (Array.isArray(data) && data.every(isInput))

    if (!ok) {
      return callback(new Error('invalid input: expected buffer, readable stream, pull stream, object or array of objects'))
    }

    pull(
      pull.values([data]),
      self.addPullStream(options),
      sort((a, b) => {
        if (a.path < b.path) return 1
        if (a.path > b.path) return -1
        return 0
      }),
      pull.collect(callback)
    )
  })

  return function () {
    const args = Array.from(arguments)

    // If we .add(<pull stream>), then promisify thinks the pull stream
    // is a callback! Add an empty options object in this case so that a
    // promise is returned.
    if (args.length === 1 && isSource(args[0])) {
      args.push({})
    }

    return add.apply(null, args)
  }
}

'''
'''--- src/core/components/files-regular/cat-pull-stream.js ---
'use strict'

const { exporter } = require('ipfs-unixfs-engine')
const pull = require('pull-stream')
const deferred = require('pull-defer')
const { normalizePath } = require('./utils')

module.exports = function (self) {
  return function catPullStream (ipfsPath, options) {
    if (typeof ipfsPath === 'function') {
      throw new Error('You must supply an ipfsPath')
    }

    options = options || {}

    ipfsPath = normalizePath(ipfsPath)
    const pathComponents = ipfsPath.split('/')
    const restPath = normalizePath(pathComponents.slice(1).join('/'))
    const filterFile = (file) => (restPath && file.path === restPath) || (file.path === ipfsPath)

    if (options.preload !== false) {
      self._preload(pathComponents[0])
    }

    const d = deferred.source()

    pull(
      exporter(ipfsPath, self._ipld, options),
      pull.filter(filterFile),
      pull.take(1),
      pull.collect((err, files) => {
        if (err) {
          return d.abort(err)
        }

        if (!files.length) {
          return d.abort(new Error('No such file'))
        }

        const file = files[0]

        if (!file.content && file.type === 'dir') {
          return d.abort(new Error('this dag node is a directory'))
        }

        if (!file.content) {
          return d.abort(new Error('this dag node has no content'))
        }

        d.resolve(file.content)
      })
    )

    return d
  }
}

'''
'''--- src/core/components/files-regular/cat-readable-stream.js ---
'use strict'

const toStream = require('pull-stream-to-stream')

module.exports = function (self) {
  return (ipfsPath, options) => toStream.source(self.catPullStream(ipfsPath, options))
}

'''
'''--- src/core/components/files-regular/cat.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream')

module.exports = function (self) {
  return promisify((ipfsPath, options, callback) => {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    pull(
      self.catPullStream(ipfsPath, options),
      pull.collect((err, buffers) => {
        if (err) { return callback(err) }
        callback(null, Buffer.concat(buffers))
      })
    )
  })
}

'''
'''--- src/core/components/files-regular/get-pull-stream.js ---
'use strict'

const { exporter } = require('ipfs-unixfs-engine')
const pull = require('pull-stream')
const errCode = require('err-code')
const { normalizePath } = require('./utils')

module.exports = function (self) {
  return (ipfsPath, options) => {
    options = options || {}

    if (options.preload !== false) {
      let pathComponents

      try {
        pathComponents = normalizePath(ipfsPath).split('/')
      } catch (err) {
        return pull.error(errCode(err, 'ERR_INVALID_PATH'))
      }

      self._preload(pathComponents[0])
    }

    return exporter(ipfsPath, self._ipld, options)
  }
}

'''
'''--- src/core/components/files-regular/get-readable-stream.js ---
'use strict'

const pull = require('pull-stream')
const toStream = require('pull-stream-to-stream')

module.exports = function (self) {
  return (ipfsPath, options) => {
    options = options || {}

    return toStream.source(
      pull(
        self.getPullStream(ipfsPath, options),
        pull.map((file) => {
          if (file.content) {
            file.content = toStream.source(file.content)
            file.content.pause()
          }

          return file
        })
      )
    )
  }
}

'''
'''--- src/core/components/files-regular/get.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream')

module.exports = function (self) {
  return promisify((ipfsPath, options, callback) => {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    options = options || {}

    pull(
      self.getPullStream(ipfsPath, options),
      pull.asyncMap((file, cb) => {
        if (file.content) {
          pull(
            file.content,
            pull.collect((err, buffers) => {
              if (err) { return cb(err) }
              file.content = Buffer.concat(buffers)
              cb(null, file)
            })
          )
        } else {
          cb(null, file)
        }
      }),
      pull.collect(callback)
    )
  })
}

'''
'''--- src/core/components/files-regular/index.js ---
'use strict'

module.exports = self => ({
  add: require('./add')(self),
  addFromFs: require('./add-from-fs')(self),
  addFromStream: require('./add-from-stream')(self),
  addFromURL: require('./add-from-url')(self),
  addPullStream: require('./add-pull-stream')(self),
  addReadableStream: require('./add-readable-stream')(self),
  cat: require('./cat')(self),
  catPullStream: require('./cat-pull-stream')(self),
  catReadableStream: require('./cat-readable-stream')(self),
  get: require('./get')(self),
  getPullStream: require('./get-pull-stream')(self),
  getReadableStream: require('./get-readable-stream')(self),
  ls: require('./ls')(self),
  lsPullStream: require('./ls-pull-stream')(self),
  lsReadableStream: require('./ls-readable-stream')(self)
})

'''
'''--- src/core/components/files-regular/ls-pull-stream.js ---
'use strict'

const { exporter } = require('ipfs-unixfs-engine')
const pull = require('pull-stream')
const CID = require('cids')
const { normalizePath } = require('./utils')

module.exports = function (self) {
  return function (ipfsPath, options) {
    options = options || {}

    const path = normalizePath(ipfsPath)
    const recursive = options.recursive
    const pathComponents = path.split('/')
    const pathDepth = pathComponents.length
    const maxDepth = recursive ? global.Infinity : pathDepth
    options.maxDepth = options.maxDepth || maxDepth

    if (options.preload !== false) {
      self._preload(pathComponents[0])
    }

    return pull(
      exporter(ipfsPath, self._ipld, options),
      pull.filter(node =>
        recursive ? node.depth >= pathDepth : node.depth === pathDepth
      ),
      pull.map(node => {
        node.hash = new CID(node.hash).toBaseEncodedString()
        delete node.content
        return node
      })
    )
  }
}

'''
'''--- src/core/components/files-regular/ls-readable-stream.js ---
'use strict'

const toStream = require('pull-stream-to-stream')

module.exports = function (self) {
  return (ipfsPath, options) => {
    return toStream.source(self.lsPullStream(ipfsPath, options))
  }
}

'''
'''--- src/core/components/files-regular/ls.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream')

module.exports = function (self) {
  return promisify((ipfsPath, options, callback) => {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    options = options || {}

    pull(
      self.lsPullStream(ipfsPath, options),
      pull.collect((err, values) => {
        if (err) {
          return callback(err)
        }
        callback(null, values)
      })
    )
  })
}

'''
'''--- src/core/components/files-regular/utils.js ---
'use strict'

const CID = require('cids')

exports.normalizePath = (path) => {
  if (Buffer.isBuffer(path)) {
    return new CID(path).toString()
  }
  if (CID.isCID(path)) {
    return path.toString()
  }
  if (path.indexOf('/ipfs/') === 0) {
    path = path.substring('/ipfs/'.length)
  }
  if (path.charAt(path.length - 1) === '/') {
    path = path.substring(0, path.length - 1)
  }
  return path
}

/**
 * Parses chunker string into options used by DAGBuilder in ipfs-unixfs-engine
 *
 *
 * @param  {String}   chunker Chunker algorithm supported formats:
 *                    "size-{size}"
 *                    "rabin"
 *                    "rabin-{avg}"
 *                    "rabin-{min}-{avg}-{max}"
 *
 * @return {Object}   Chunker options for DAGBuilder
 */
exports.parseChunkerString = (chunker) => {
  if (!chunker) {
    return {
      chunker: 'fixed'
    }
  } else if (chunker.startsWith('size-')) {
    const sizeStr = chunker.split('-')[1]
    const size = parseInt(sizeStr)
    if (isNaN(size)) {
      throw new Error('Chunker parameter size must be an integer')
    }
    return {
      chunker: 'fixed',
      chunkerOptions: {
        maxChunkSize: size
      }
    }
  } else if (chunker.startsWith('rabin')) {
    return {
      chunker: 'rabin',
      chunkerOptions: parseRabinString(chunker)
    }
  } else {
    throw new Error(`Unrecognized chunker option: ${chunker}`)
  }
}

/**
 * Parses rabin chunker string
 *
 * @param  {String}   chunker Chunker algorithm supported formats:
 *                            "rabin"
 *                            "rabin-{avg}"
 *                            "rabin-{min}-{avg}-{max}"
 *
 * @return {Object}   rabin chunker options
 */
function parseRabinString (chunker) {
  const options = {}
  const parts = chunker.split('-')
  switch (parts.length) {
    case 1:
      options.avgChunkSize = 262144
      break
    case 2:
      options.avgChunkSize = parseChunkSize(parts[1], 'avg')
      break
    case 4:
      options.minChunkSize = parseChunkSize(parts[1], 'min')
      options.avgChunkSize = parseChunkSize(parts[2], 'avg')
      options.maxChunkSize = parseChunkSize(parts[3], 'max')
      break
    default:
      throw new Error('Incorrect chunker format (expected "rabin" "rabin-[avg]" or "rabin-[min]-[avg]-[max]"')
  }

  return options
}

function parseChunkSize (str, name) {
  let size = parseInt(str)
  if (isNaN(size)) {
    throw new Error(`Chunker parameter ${name} must be an integer`)
  }

  return size
}

'''
'''--- src/core/components/id.js ---
'use strict'

const promisify = require('promisify-es6')
const setImmediate = require('async/setImmediate')
const pkgversion = require('../../../package.json').version

module.exports = function id (self) {
  return promisify((opts, callback) => {
    if (typeof opts === 'function') {
      callback = opts
      opts = {}
    }

    setImmediate(() => callback(null, {
      id: self._peerInfo.id.toB58String(),
      publicKey: self._peerInfo.id.pubKey.bytes.toString('base64'),
      addresses: self._peerInfo.multiaddrs
        .toArray()
        .map((ma) => ma.toString())
        .filter((ma) => ma.indexOf('ipfs') >= 0)
        .sort(),
      agentVersion: `js-ipfs/${pkgversion}`,
      protocolVersion: '9000'
    }))
  })
}

'''
'''--- src/core/components/index.js ---
'use strict'

exports.preStart = require('./pre-start')
exports.start = require('./start')
exports.stop = require('./stop')
exports.isOnline = require('./is-online')
exports.version = require('./version')
exports.id = require('./id')
exports.repo = require('./repo')
exports.init = require('./init')
exports.bootstrap = require('./bootstrap')
exports.config = require('./config')
exports.block = require('./block')
exports.object = require('./object')
exports.dag = require('./dag')
exports.libp2p = require('./libp2p')
exports.swarm = require('./swarm')
exports.ping = require('./ping')
exports.pingPullStream = require('./ping-pull-stream')
exports.pingReadableStream = require('./ping-readable-stream')
exports.pin = require('./pin')
exports.filesRegular = require('./files-regular')
exports.filesMFS = require('./files-mfs')
exports.bitswap = require('./bitswap')
exports.pubsub = require('./pubsub')
exports.dht = require('./dht')
exports.dns = require('./dns')
exports.key = require('./key')
exports.stats = require('./stats')
exports.resolve = require('./resolve')
exports.name = require('./name')

'''
'''--- src/core/components/init-assets.js ---
'use strict'

const path = require('path')
const glob = require('glob')
const pull = require('pull-stream')
const file = require('pull-file')
const CID = require('cids')

// Add the default assets to the repo.
module.exports = function addDefaultAssets (self, log, callback) {
  const initDocsPath = path.join(__dirname, '../../init-files/init-docs')
  const index = initDocsPath.lastIndexOf(path.sep)

  pull(
    pull.values([initDocsPath]),
    pull.asyncMap((val, cb) =>
      glob(path.join(val, '/**/*'), { nodir: true }, cb)
    ),
    pull.flatten(),
    pull.map(element => {
      const addPath = element.substring(index + 1)
      return { path: addPath, content: file(element) }
    }),
    self.addPullStream(),
    pull.through(file => {
      if (file.path === 'init-docs') {
        const cid = new CID(file.hash)
        log('to get started, enter:\n')
        log(`\tjsipfs cat /ipfs/${cid.toBaseEncodedString()}/readme\n`)
      }
    }),
    pull.collect((err) => {
      if (err) {
        return callback(err)
      }

      callback(null, true)
    })
  )
}

'''
'''--- src/core/components/init.js ---
'use strict'

const peerId = require('peer-id')
const waterfall = require('async/waterfall')
const parallel = require('async/parallel')
const promisify = require('promisify-es6')
const defaultsDeep = require('@nodeutils/defaults-deep')
const defaultConfig = require('../runtime/config-nodejs.js')
const Keychain = require('libp2p-keychain')
const {
  DAGNode
} = require('ipld-dag-pb')
const UnixFs = require('ipfs-unixfs')

const IPNS = require('../ipns')
const OfflineDatastore = require('../ipns/routing/offline-datastore')

const addDefaultAssets = require('./init-assets')

module.exports = function init (self) {
  return promisify((opts, callback) => {
    if (typeof opts === 'function') {
      callback = opts
      opts = {}
    }

    const done = (err, res) => {
      if (err) {
        self.emit('error', err)
        return callback(err)
      }

      self.preStart((err) => {
        if (err) {
          self.emit('error', err)
          return callback(err)
        }

        self.state.initialized()
        self.emit('init')
        callback(null, res)
      })
    }

    if (self.state.state() !== 'uninitialized') {
      return done(new Error('Not able to init from state: ' + self.state.state()))
    }

    self.state.init()
    self.log('init')

    // An initialized, open repo was passed, use this one!
    if (opts.repo) {
      self._repo = opts.repo
      return done(null, true)
    }

    opts.emptyRepo = opts.emptyRepo || false
    opts.bits = Number(opts.bits) || 2048
    opts.log = opts.log || function () {}

    const config = defaultsDeep(self._options.config, defaultConfig())
    let privateKey

    waterfall([
      // Verify repo does not yet exist.
      (cb) => self._repo.exists(cb),
      (exists, cb) => {
        self.log('repo exists?', exists)
        if (exists === true) {
          return cb(new Error('repo already exists'))
        }

        if (opts.privateKey) {
          self.log('using user-supplied private-key')
          if (typeof opts.privateKey === 'object') {
            cb(null, opts.privateKey)
          } else {
            peerId.createFromPrivKey(Buffer.from(opts.privateKey, 'base64'), cb)
          }
        } else {
          // Generate peer identity keypair + transform to desired format + add to config.
          opts.log(`generating ${opts.bits}-bit RSA keypair...`, false)
          self.log('generating peer id: %s bits', opts.bits)
          peerId.create({ bits: opts.bits }, cb)
        }
      },
      (peerId, cb) => {
        self.log('identity generated')
        config.Identity = {
          PeerID: peerId.toB58String(),
          PrivKey: peerId.privKey.bytes.toString('base64')
        }
        privateKey = peerId.privKey
        if (opts.pass) {
          config.Keychain = Keychain.generateOptions()
        }
        opts.log('done')
        opts.log('peer identity: ' + config.Identity.PeerID)

        self._repo.init(config, cb)
      },
      (_, cb) => self._repo.open(cb),
      (cb) => {
        self.log('repo opened')
        if (opts.pass) {
          self.log('creating keychain')
          const keychainOptions = Object.assign({ passPhrase: opts.pass }, config.Keychain)
          self._keychain = new Keychain(self._repo.keys, keychainOptions)
          self._keychain.importPeer('self', { privKey: privateKey }, cb)
        } else {
          cb(null, true)
        }
      },
      // Setup the offline routing for IPNS.
      // This is primarily used for offline ipns modifications, such as the initializeKeyspace feature.
      (_, cb) => {
        const offlineDatastore = new OfflineDatastore(self._repo)

        self._ipns = new IPNS(offlineDatastore, self._repo.datastore, self._peerInfo, self._keychain, self._options)
        cb(null, true)
      },
      // add empty unixfs dir object (go-ipfs assumes this exists)
      (_, cb) => {
        if (opts.emptyRepo) {
          return cb(null, true)
        }

        const tasks = [
          (cb) => {
            waterfall([
              (cb) => DAGNode.create(new UnixFs('directory').marshal(), cb),
              (node, cb) => self.dag.put(node, {
                version: 0,
                format: 'dag-pb',
                hashAlg: 'sha2-256'
              }, cb),
              (cid, cb) => self._ipns.initializeKeyspace(privateKey, cid.toBaseEncodedString(), cb)
            ], cb)
          }
        ]

        if (typeof addDefaultAssets === 'function') {
          // addDefaultAssets is undefined on browsers.
          // See package.json browser config
          tasks.push((cb) => addDefaultAssets(self, opts.log, cb))
        }

        self.log('adding assets')
        parallel(tasks, (err) => {
          if (err) {
            cb(err)
          } else {
            cb(null, true)
          }
        })
      }
    ], done)
  })
}

'''
'''--- src/core/components/is-online.js ---
'use strict'

module.exports = function isOnline (self) {
  return () => {
    return Boolean(self._bitswap && self.libp2p && self.libp2p.isStarted())
  }
}

'''
'''--- src/core/components/key.js ---
'use strict'

// See https://github.com/ipfs/specs/tree/master/keystore

const promisify = require('promisify-es6')

module.exports = function key (self) {
  return {
    gen: promisify((name, opts, callback) => {
      opts = opts || {}
      self._keychain.createKey(name, opts.type, opts.size, callback)
    }),

    info: promisify((name, callback) => {
      self._keychain.findKeyByName(name, callback)
    }),

    list: promisify((callback) => {
      self._keychain.listKeys(callback)
    }),

    rm: promisify((name, callback) => {
      self._keychain.removeKey(name, callback)
    }),

    rename: promisify((oldName, newName, callback) => {
      self._keychain.renameKey(oldName, newName, (err, key) => {
        if (err) return callback(err)
        const result = {
          was: oldName,
          now: key.name,
          id: key.id,
          overwrite: false
        }
        callback(null, result)
      })
    }),

    import: promisify((name, pem, password, callback) => {
      self._keychain.importKey(name, pem, password, callback)
    }),

    export: promisify((name, password, callback) => {
      self._keychain.exportKey(name, password, callback)
    })
  }
}

'''
'''--- src/core/components/libp2p.js ---
'use strict'

const get = require('lodash/get')
const defaultsDeep = require('@nodeutils/defaults-deep')
const ipnsUtils = require('../ipns/routing/utils')

module.exports = function libp2p (self, config) {
  const options = self._options || {}
  config = config || {}

  // Always create libp2p via a bundle function
  const createBundle = typeof options.libp2p === 'function'
    ? options.libp2p
    : defaultBundle

  const { datastore } = self._repo
  const peerInfo = self._peerInfo
  const peerBook = self._peerInfoBook
  const libp2p = createBundle({ options, config, datastore, peerInfo, peerBook })
  let discoveredPeers = []

  const putAndDial = peerInfo => {
    peerBook.put(peerInfo)
    libp2p.dial(peerInfo, () => {})
  }

  libp2p.on('start', () => {
    peerInfo.multiaddrs.forEach((ma) => {
      self._print('Swarm listening on', ma.toString())
    })
    discoveredPeers.forEach(putAndDial)
    discoveredPeers = []
  })

  libp2p.on('peer:discovery', (peerInfo) => {
    if (self.isOnline()) {
      putAndDial(peerInfo)
    } else {
      discoveredPeers.push(peerInfo)
    }
  })

  libp2p.on('peer:connect', peerInfo => peerBook.put(peerInfo))

  return libp2p
}

function defaultBundle ({ datastore, peerInfo, peerBook, options, config }) {
  const libp2pDefaults = {
    datastore,
    peerInfo,
    peerBook,
    config: {
      peerDiscovery: {
        mdns: {
          enabled: get(options, 'config.Discovery.MDNS.Enabled',
            get(config, 'Discovery.MDNS.Enabled', true))
        },
        webRTCStar: {
          enabled: get(options, 'config.Discovery.webRTCStar.Enabled',
            get(config, 'Discovery.webRTCStar.Enabled', true))
        },
        bootstrap: {
          list: get(options, 'config.Bootstrap',
            get(config, 'Bootstrap', []))
        }
      },
      relay: {
        enabled: get(options, 'relay.enabled',
          get(config, 'relay.enabled', false)),
        hop: {
          enabled: get(options, 'relay.hop.enabled',
            get(config, 'relay.hop.enabled', false)),
          active: get(options, 'relay.hop.active',
            get(config, 'relay.hop.active', false))
        }
      },
      dht: {
        kBucketSize: get(options, 'dht.kBucketSize', 20),
        enabled: get(options, 'dht.enabled', true) && !(get(options, 'offline', false)),
        randomWalk: {
          enabled: get(options, 'dht.randomWalk.enabled', true)
        },
        validators: {
          ipns: ipnsUtils.validator
        },
        selectors: {
          ipns: ipnsUtils.selector
        }
      },
      EXPERIMENTAL: {
        pubsub: get(options, 'EXPERIMENTAL.pubsub', false)
      }
    },
    connectionManager: get(options, 'connectionManager',
      get(config, 'connectionManager', {}))
  }

  const libp2pOptions = defaultsDeep(get(options, 'libp2p', {}), libp2pDefaults)

  // Required inline to reduce startup time
  // Note: libp2p-nodejs gets replaced by libp2p-browser when webpacked/browserified
  const Node = require('../runtime/libp2p-nodejs')
  return new Node(libp2pOptions)
}

'''
'''--- src/core/components/name-pubsub.js ---
'use strict'

const debug = require('debug')
const errcode = require('err-code')
const promisify = require('promisify-es6')

const IpnsPubsubDatastore = require('../ipns/routing/pubsub-datastore')

const log = debug('jsipfs:name-pubsub')
log.error = debug('jsipfs:name-pubsub:error')

// Is pubsub enabled
const isNamePubsubEnabled = (node) => {
  try {
    return Boolean(getPubsubRouting(node))
  } catch (err) {
    return false
  }
}

// Get pubsub from IPNS routing
const getPubsubRouting = (node) => {
  if (!node._ipns || !node._options.EXPERIMENTAL.ipnsPubsub) {
    const errMsg = 'IPNS pubsub subsystem is not enabled'

    throw errcode(errMsg, 'ERR_IPNS_PUBSUB_NOT_ENABLED')
  }

  // Only one store and it is pubsub
  if (IpnsPubsubDatastore.isIpnsPubsubDatastore(node._ipns.routing)) {
    return node._ipns.routing
  }

  // Find in tiered
  const pubsub = (node._ipns.routing.stores || []).find(s => IpnsPubsubDatastore.isIpnsPubsubDatastore(s))

  if (!pubsub) {
    const errMsg = 'IPNS pubsub datastore not found'

    throw errcode(errMsg, 'ERR_PUBSUB_DATASTORE_NOT_FOUND')
  }

  return pubsub
}

module.exports = function namePubsub (self) {
  return {
    /**
     * Query the state of IPNS pubsub.
     *
     * @returns {Promise|void}
     */
    state: promisify((callback) => {
      callback(null, {
        enabled: isNamePubsubEnabled(self)
      })
    }),
    /**
     * Cancel a name subscription.
     *
     * @param {String} name subscription name.
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    cancel: promisify((name, callback) => {
      let pubsub
      try {
        pubsub = getPubsubRouting(self)
      } catch (err) {
        return callback(err)
      }

      pubsub.cancel(name, callback)
    }),
    /**
     * Show current name subscriptions.
     *
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    subs: promisify((callback) => {
      let pubsub
      try {
        pubsub = getPubsubRouting(self)
      } catch (err) {
        return callback(err)
      }

      pubsub.getSubscriptions(callback)
    })
  }
}

'''
'''--- src/core/components/name.js ---
'use strict'

const debug = require('debug')
const promisify = require('promisify-es6')
const waterfall = require('async/waterfall')
const parallel = require('async/parallel')
const human = require('human-to-milliseconds')
const crypto = require('libp2p-crypto')
const errcode = require('err-code')

const log = debug('jsipfs:name')
log.error = debug('jsipfs:name:error')

const namePubsub = require('./name-pubsub')
const utils = require('../utils')
const path = require('../ipns/path')

const keyLookup = (ipfsNode, kname, callback) => {
  if (kname === 'self') {
    return callback(null, ipfsNode._peerInfo.id.privKey)
  }

  const pass = ipfsNode._options.pass

  waterfall([
    (cb) => ipfsNode._keychain.exportKey(kname, pass, cb),
    (pem, cb) => crypto.keys.import(pem, pass, cb)
  ], (err, privateKey) => {
    if (err) {
      log.error(err)
      return callback(errcode(err, 'ERR_CANNOT_GET_KEY'))
    }

    return callback(null, privateKey)
  })
}

module.exports = function name (self) {
  return {
    /**
     * IPNS is a PKI namespace, where names are the hashes of public keys, and
     * the private key enables publishing new (signed) values. In both publish
     * and resolve, the default name used is the node's own PeerID,
     * which is the hash of its public key.
     *
     * @param {String} value ipfs path of the object to be published.
     * @param {Object} options ipfs publish options.
     * @param {boolean} options.resolve resolve given path before publishing.
     * @param {String} options.lifetime time duration that the record will be valid for.
    This accepts durations such as "300s", "1.5h" or "2h45m". Valid time units are
    "ns", "ms", "s", "m", "h". Default is 24h.
     * @param {String} options.ttl time duration this record should be cached for (NOT IMPLEMENTED YET).
     * This accepts durations such as "300s", "1.5h" or "2h45m". Valid time units are
     "ns", "ms", "s", "m", "h" (caution: experimental).
     * @param {String} options.key name of the key to be used or a valid PeerID, as listed by 'ipfs key list -l'.
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    publish: promisify((value, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}
      const resolve = !(options.resolve === false)
      const lifetime = options.lifetime || '24h'
      const key = options.key || 'self'

      if (!self.isOnline()) {
        const errMsg = utils.OFFLINE_ERROR

        log.error(errMsg)
        return callback(errcode(errMsg, 'OFFLINE_ERROR'))
      }

      // TODO: params related logic should be in the core implementation

      // Normalize path value
      try {
        value = utils.normalizePath(value)
      } catch (err) {
        log.error(err)
        return callback(err)
      }

      parallel([
        (cb) => human(lifetime, cb),
        // (cb) => ttl ? human(ttl, cb) : cb(),
        (cb) => keyLookup(self, key, cb),
        // verify if the path exists, if not, an error will stop the execution
        (cb) => resolve.toString() === 'true' ? path.resolvePath(self, value, cb) : cb()
      ], (err, results) => {
        if (err) {
          log.error(err)
          return callback(err)
        }

        // Calculate lifetime with nanoseconds precision
        const pubLifetime = results[0].toFixed(6)
        const privateKey = results[1]

        // TODO IMPROVEMENT - Handle ttl for cache
        // const ttl = results[1]
        // const privateKey = results[2]

        // Start publishing process
        self._ipns.publish(privateKey, value, pubLifetime, callback)
      })
    }),

    /**
     * Given a key, query the DHT for its best value.
     *
     * @param {String} name ipns name to resolve. Defaults to your node's peerID.
     * @param {Object} options ipfs resolve options.
     * @param {boolean} options.nocache do not use cached entries.
     * @param {boolean} options.recursive resolve until the result is not an IPNS name.
     * @param {function(Error)} [callback]
     * @returns {Promise|void}
     */
    resolve: promisify((name, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}
      const nocache = options.nocache && options.nocache.toString() === 'true'
      const recursive = options.recursive && options.recursive.toString() === 'true'

      const offline = self._options.offline

      if (!self.isOnline() && !offline) {
        const errMsg = utils.OFFLINE_ERROR

        log.error(errMsg)
        return callback(errcode(errMsg, 'OFFLINE_ERROR'))
      }

      // TODO: params related logic should be in the core implementation

      if (offline && nocache) {
        const error = 'cannot specify both offline and nocache'

        log.error(error)
        return callback(errcode(new Error(error), 'ERR_NOCACHE_AND_OFFLINE'))
      }

      // Set node id as name for being resolved, if it is not received
      if (!name) {
        name = self._peerInfo.id.toB58String()
      }

      if (!name.startsWith('/ipns/')) {
        name = `/ipns/${name}`
      }

      const resolveOptions = {
        nocache,
        recursive
      }

      self._ipns.resolve(name, resolveOptions, callback)
    }),
    pubsub: namePubsub(self)
  }
}

'''
'''--- src/core/components/no-keychain.js ---
'use strict'

function fail () {
  throw new Error('Key management requires \'--pass ...\' option')
}

class NoKeychain {
  static get options () { fail() }
  static generateOptions () { fail() }

  createKey () { fail() }
  listKeys () { fail() }
  findKeyById () { fail() }
  findKeyByName () { fail() }
  renameKey () { fail() }
  removeKey () { fail() }
  exportKey () { fail() }
  importKey () { fail() }
  importPeer () { fail() }

  get cms () { fail() }
}

module.exports = NoKeychain

'''
'''--- src/core/components/object.js ---
'use strict'

const waterfall = require('async/waterfall')
const parallel = require('async/parallel')
const setImmediate = require('async/setImmediate')
const promisify = require('promisify-es6')
const dagPB = require('ipld-dag-pb')
const DAGNode = dagPB.DAGNode
const DAGLink = dagPB.DAGLink
const CID = require('cids')
const mh = require('multihashes')
const Unixfs = require('ipfs-unixfs')
const errCode = require('err-code')

function normalizeMultihash (multihash, enc) {
  if (typeof multihash === 'string') {
    if (enc === 'base58' || !enc) {
      return multihash
    }

    return Buffer.from(multihash, enc)
  } else if (Buffer.isBuffer(multihash)) {
    return multihash
  } else if (CID.isCID(multihash)) {
    return multihash.buffer
  } else {
    throw new Error('unsupported multihash')
  }
}

function parseBuffer (buf, encoding, callback) {
  switch (encoding) {
    case 'json':
      return parseJSONBuffer(buf, callback)
    case 'protobuf':
      return parseProtoBuffer(buf, callback)
    default:
      callback(new Error(`unkown encoding: ${encoding}`))
  }
}

function parseJSONBuffer (buf, callback) {
  let data
  let links

  try {
    const parsed = JSON.parse(buf.toString())

    links = (parsed.Links || []).map((link) => {
      return new DAGLink(
        link.Name || link.name,
        link.Size || link.size,
        mh.fromB58String(link.Hash || link.hash || link.multihash)
      )
    })
    data = Buffer.from(parsed.Data)
  } catch (err) {
    return callback(new Error('failed to parse JSON: ' + err))
  }

  DAGNode.create(data, links, callback)
}

function parseProtoBuffer (buf, callback) {
  dagPB.util.deserialize(buf, callback)
}

module.exports = function object (self) {
  function editAndSave (edit) {
    return (multihash, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      waterfall([
        (cb) => {
          self.object.get(multihash, options, cb)
        },
        (node, cb) => {
          // edit applies the edit func passed to
          // editAndSave
          edit(node, (err, node) => {
            if (err) {
              return cb(err)
            }

            self._ipld.put(node, {
              version: 0,
              hashAlg: 'sha2-256',
              format: 'dag-pb'
            }, (err, cid) => {
              if (err) return cb(err)

              if (options.preload !== false) {
                self._preload(cid)
              }

              cb(null, cid)
            })
          })
        }
      ], callback)
    }
  }

  return {
    new: promisify((template, options, callback) => {
      if (typeof template === 'function') {
        callback = template
        template = undefined
        options = {}
      }

      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      let data

      if (template) {
        if (template !== 'unixfs-dir') {
          return setImmediate(() => callback(new Error('unknown template')))
        }
        data = (new Unixfs('directory')).marshal()
      } else {
        data = Buffer.alloc(0)
      }

      DAGNode.create(data, (err, node) => {
        if (err) {
          return callback(err)
        }

        self._ipld.put(node, {
          version: 0,
          hashAlg: 'sha2-256',
          format: 'dag-pb'
        }, (err, cid) => {
          if (err) {
            return callback(err)
          }

          if (options.preload !== false) {
            self._preload(cid)
          }

          callback(null, cid)
        })
      })
    }),
    put: promisify((obj, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      const encoding = options.enc
      let node

      if (Buffer.isBuffer(obj)) {
        if (encoding) {
          parseBuffer(obj, encoding, (err, _node) => {
            if (err) {
              return callback(err)
            }
            node = _node
            next()
          })
        } else {
          DAGNode.create(obj, (err, _node) => {
            if (err) {
              return callback(err)
            }
            node = _node
            next()
          })
        }
      } else if (DAGNode.isDAGNode(obj)) {
        // already a dag node
        node = obj
        next()
      } else if (typeof obj === 'object') {
        DAGNode.create(obj.Data, obj.Links, (err, _node) => {
          if (err) {
            return callback(err)
          }
          node = _node
          next()
        })
      } else {
        return callback(new Error('obj not recognized'))
      }

      function next () {
        self._ipld.put(node, {
          version: 0,
          hashAlg: 'sha2-256',
          format: 'dag-pb'
        }, (err, cid) => {
          if (err) {
            return callback(err)
          }

          if (options.preload !== false) {
            self._preload(cid)
          }

          callback(null, cid)
        })
      }
    }),

    get: promisify((multihash, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      let mh, cid

      try {
        mh = normalizeMultihash(multihash, options.enc)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_MULTIHASH')))
      }

      try {
        cid = new CID(mh)
      } catch (err) {
        return setImmediate(() => callback(errCode(err, 'ERR_INVALID_CID')))
      }

      if (options.cidVersion === 1) {
        cid = cid.toV1()
      }

      if (options.preload !== false) {
        self._preload(cid)
      }

      self._ipld.get(cid, (err, result) => {
        if (err) {
          return callback(err)
        }

        callback(null, result.value)
      })
    }),

    data: promisify((multihash, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      self.object.get(multihash, options, (err, node) => {
        if (err) {
          return callback(err)
        }

        callback(null, node.data)
      })
    }),

    links: promisify((multihash, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      self.object.get(multihash, options, (err, node) => {
        if (err) {
          return callback(err)
        }

        callback(null, node.links)
      })
    }),

    stat: promisify((multihash, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      waterfall([
        (cb) => self.object.get(multihash, options, cb),
        (node, cb) => {
          parallel({
            serialized: (next) => dagPB.util.serialize(node, next),
            cid: (next) => dagPB.util.cid(node, next),
            node: (next) => next(null, node)
          }, cb)
        }
      ], (err, result) => {
        if (err) {
          return callback(err)
        }

        const blockSize = result.serialized.length
        const linkLength = result.node.links.reduce((a, l) => a + l.size, 0)

        callback(null, {
          Hash: result.cid.toBaseEncodedString(),
          NumLinks: result.node.links.length,
          BlockSize: blockSize,
          LinksSize: blockSize - result.node.data.length,
          DataSize: result.node.data.length,
          CumulativeSize: blockSize + linkLength
        })
      })
    }),

    patch: promisify({
      addLink (multihash, link, options, callback) {
        editAndSave((node, cb) => {
          DAGNode.addLink(node, link, cb)
        })(multihash, options, callback)
      },

      rmLink (multihash, linkRef, options, callback) {
        editAndSave((node, cb) => {
          if (DAGLink.isDAGLink(linkRef)) {
            linkRef = linkRef._name
          } else if (linkRef && linkRef.name) {
            linkRef = linkRef.name
          }
          DAGNode.rmLink(node, linkRef, cb)
        })(multihash, options, callback)
      },

      appendData (multihash, data, options, callback) {
        editAndSave((node, cb) => {
          const newData = Buffer.concat([node.data, data])
          DAGNode.create(newData, node.links, cb)
        })(multihash, options, callback)
      },

      setData (multihash, data, options, callback) {
        editAndSave((node, cb) => {
          DAGNode.create(data, node.links, cb)
        })(multihash, options, callback)
      }
    })
  }
}

'''
'''--- src/core/components/pin-set.js ---
'use strict'

const multihashes = require('multihashes')
const CID = require('cids')
const protobuf = require('protons')
const fnv1a = require('fnv1a')
const varint = require('varint')
const { DAGNode, DAGLink } = require('ipld-dag-pb')
const someSeries = require('async/someSeries')
const eachOfSeries = require('async/eachOfSeries')

const pbSchema = require('./pin.proto')

const emptyKeyHash = 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'
const emptyKey = multihashes.fromB58String(emptyKeyHash)
const defaultFanout = 256
const maxItems = 8192
const pb = protobuf(pbSchema)

function toB58String (hash) {
  return new CID(hash).toBaseEncodedString()
}

function readHeader (rootNode) {
  // rootNode.data should be a buffer of the format:
  // < varint(headerLength) | header | itemData... >
  const rootData = rootNode.data
  const hdrLength = varint.decode(rootData)
  const vBytes = varint.decode.bytes
  if (vBytes <= 0) {
    throw new Error('Invalid Set header length')
  }
  if (vBytes + hdrLength > rootData.length) {
    throw new Error('Impossibly large set header length')
  }
  const hdrSlice = rootData.slice(vBytes, hdrLength + vBytes)
  const header = pb.Set.decode(hdrSlice)
  if (header.version !== 1) {
    throw new Error(`Unsupported Set version: ${header.version}`)
  }
  if (header.fanout > rootNode.links.length) {
    throw new Error('Impossibly large fanout')
  }
  return {
    header: header,
    data: rootData.slice(hdrLength + vBytes)
  }
}

function hash (seed, key) {
  const buf = Buffer.alloc(4)
  buf.writeUInt32LE(seed, 0)
  const data = Buffer.concat([
    buf, Buffer.from(toB58String(key))
  ])
  return fnv1a(data.toString('binary'))
}

exports = module.exports = function (dag) {
  const pinSet = {
    // should this be part of `object` API?
    hasDescendant: (root, childhash, callback) => {
      const seen = {}

      if (CID.isCID(childhash) || Buffer.isBuffer(childhash)) {
        childhash = toB58String(childhash)
      }

      return searchChildren(root, callback)

      function searchChildren (root, cb) {
        someSeries(root.links, ({ cid }, done) => {
          const bs58Link = toB58String(cid)

          if (bs58Link === childhash) {
            return done(null, true)
          }

          if (bs58Link in seen) {
            return done(null, false)
          }

          seen[bs58Link] = true

          dag.get(cid, '', { preload: false }, (err, res) => {
            if (err) {
              return done(err)
            }

            searchChildren(res.value, done)
          })
        }, cb)
      }
    },

    storeSet: (keys, callback) => {
      const pins = keys.map(key => {
        if (typeof key === 'string' || Buffer.isBuffer(key)) {
          key = new CID(key)
        }

        return {
          key: key,
          data: null
        }
      })

      pinSet.storeItems(pins, (err, rootNode) => {
        if (err) { return callback(err) }

        dag.put(rootNode, {
          version: 0,
          format: 'dag-pb',
          hashAlg: 'sha2-256',
          preload: false
        }, (err, cid) => {
          if (err) { return callback(err, cid) }
          callback(null, { node: rootNode, cid })
        })
      })
    },

    storeItems: (items, callback) => {
      return storePins(items, 0, callback)

      function storePins (pins, depth, storePinsCb) {
        const pbHeader = pb.Set.encode({
          version: 1,
          fanout: defaultFanout,
          seed: depth
        })
        const headerBuf = Buffer.concat([
          Buffer.from(varint.encode(pbHeader.length)), pbHeader
        ])
        const fanoutLinks = []
        for (let i = 0; i < defaultFanout; i++) {
          fanoutLinks.push(new DAGLink('', 1, emptyKey))
        }

        if (pins.length <= maxItems) {
          const nodes = pins
            .map(item => {
              return ({
                link: new DAGLink('', 1, item.key),
                data: item.data || Buffer.alloc(0)
              })
            })
            // sorting makes any ordering of `pins` produce the same DAGNode
            .sort((a, b) => Buffer.compare(a.link.cid.buffer, b.link.cid.buffer))

          const rootLinks = fanoutLinks.concat(nodes.map(item => item.link))
          const rootData = Buffer.concat(
            [headerBuf].concat(nodes.map(item => item.data))
          )

          DAGNode.create(rootData, rootLinks, (err, rootNode) => {
            if (err) { return storePinsCb(err) }
            return storePinsCb(null, rootNode)
          })
        } else {
          // If the array of pins is > maxItems, we:
          //  - distribute the pins among `defaultFanout` bins
          //    - create a DAGNode for each bin
          //      - add each pin as a DAGLink to that bin
          //  - create a root DAGNode
          //    - add each bin as a DAGLink
          //  - send that root DAGNode via callback
          // (using go-ipfs' "wasteful but simple" approach for consistency)
          // https://github.com/ipfs/go-ipfs/blob/master/pin/set.go#L57

          const bins = pins.reduce((bins, pin) => {
            const n = hash(depth, pin.key) % defaultFanout
            bins[n] = n in bins ? bins[n].concat([pin]) : [pin]
            return bins
          }, {})

          eachOfSeries(bins, (bin, idx, eachCb) => {
            storePins(
              bin,
              depth + 1,
              (err, child) => storeChild(err, child, idx, eachCb)
            )
          }, err => {
            if (err) { return storePinsCb(err) }
            DAGNode.create(headerBuf, fanoutLinks, (err, rootNode) => {
              if (err) { return storePinsCb(err) }
              return storePinsCb(null, rootNode)
            })
          })
        }

        function storeChild (err, child, binIdx, cb) {
          if (err) { return cb(err) }

          const opts = {
            version: 0,
            hashAlg: 'sha2-256',
            format: 'dag-pb',
            preload: false
          }

          dag.put(child, opts, (err, cid) => {
            if (err) { return cb(err) }
            fanoutLinks[binIdx] = new DAGLink('', child.size, cid)
            cb(null)
          })
        }
      }
    },

    loadSet: (rootNode, name, callback) => {
      const link = rootNode.links.find(l => l.name === name)
      if (!link) {
        return callback(new Error('No link found with name ' + name))
      }

      dag.get(link.cid, '', { preload: false }, (err, res) => {
        if (err) { return callback(err) }
        const keys = []
        const step = link => keys.push(link.cid.buffer)
        pinSet.walkItems(res.value, step, err => {
          if (err) { return callback(err) }
          return callback(null, keys)
        })
      })
    },

    walkItems: (node, step, callback) => {
      let pbh
      try {
        pbh = readHeader(node)
      } catch (err) {
        return callback(err)
      }

      eachOfSeries(node.links, (link, idx, eachCb) => {
        if (idx < pbh.header.fanout) {
          // the first pbh.header.fanout links are fanout bins
          // if a fanout bin is not 'empty', dig into and walk its DAGLinks
          const linkHash = link.cid.buffer

          if (!emptyKey.equals(linkHash)) {
            // walk the links of this fanout bin
            return dag.get(linkHash, '', { preload: false }, (err, res) => {
              if (err) { return eachCb(err) }
              pinSet.walkItems(res.value, step, eachCb)
            })
          }
        } else {
          // otherwise, the link is a pin
          step(link, idx, pbh.data)
        }

        eachCb(null)
      }, callback)
    }
  }
  return pinSet
}

'''
'''--- src/core/components/pin.js ---
/* eslint max-nested-callbacks: ["error", 8] */
'use strict'

const promisify = require('promisify-es6')
const { DAGNode, DAGLink, util } = require('ipld-dag-pb')
const CID = require('cids')
const map = require('async/map')
const mapSeries = require('async/mapSeries')
const series = require('async/series')
const parallel = require('async/parallel')
const eachLimit = require('async/eachLimit')
const waterfall = require('async/waterfall')
const detectLimit = require('async/detectLimit')
const setImmediate = require('async/setImmediate')
const { Key } = require('interface-datastore')
const errCode = require('err-code')
const multibase = require('multibase')

const createPinSet = require('./pin-set')
const { resolvePath } = require('../utils')

// arbitrary limit to the number of concurrent dag operations
const concurrencyLimit = 300
const pinDataStoreKey = new Key('/local/pins')

function toB58String (hash) {
  return new CID(hash).toBaseEncodedString()
}

function invalidPinTypeErr (type) {
  const errMsg = `Invalid type '${type}', must be one of {direct, indirect, recursive, all}`
  return errCode(new Error(errMsg), 'ERR_INVALID_PIN_TYPE')
}

module.exports = (self) => {
  const repo = self._repo
  const dag = self.dag
  const pinset = createPinSet(dag)
  const types = {
    direct: 'direct',
    recursive: 'recursive',
    indirect: 'indirect',
    all: 'all'
  }

  let directPins = new Set()
  let recursivePins = new Set()

  const directKeys = () =>
    Array.from(directPins).map(key => new CID(key).buffer)
  const recursiveKeys = () =>
    Array.from(recursivePins).map(key => new CID(key).buffer)

  function getIndirectKeys (callback) {
    const indirectKeys = new Set()
    eachLimit(recursiveKeys(), concurrencyLimit, (multihash, cb) => {
      dag._getRecursive(multihash, (err, nodes) => {
        if (err) {
          return cb(err)
        }

        map(nodes, (node, cb) => util.cid(node, cb), (err, cids) => {
          if (err) {
            return cb(err)
          }

          cids
            .map(cids => cids.toBaseEncodedString())
            // recursive pins pre-empt indirect pins
            .filter(key => !recursivePins.has(key))
            .forEach(key => indirectKeys.add(key))

          cb()
        })
      })
    }, (err) => {
      if (err) { return callback(err) }
      callback(null, Array.from(indirectKeys))
    })
  }

  // Encode and write pin key sets to the datastore:
  // a DAGLink for each of the recursive and direct pinsets
  // a DAGNode holding those as DAGLinks, a kind of root pin
  function flushPins (callback) {
    let dLink, rLink, root
    series([
      // create a DAGLink to the node with direct pins
      cb => waterfall([
        cb => pinset.storeSet(directKeys(), cb),
        ({ node, cid }, cb) => DAGLink.create(types.direct, node.size, cid, cb),
        (link, cb) => { dLink = link; cb(null) }
      ], cb),

      // create a DAGLink to the node with recursive pins
      cb => waterfall([
        cb => pinset.storeSet(recursiveKeys(), cb),
        ({ node, cid }, cb) => DAGLink.create(types.recursive, node.size, cid, cb),
        (link, cb) => { rLink = link; cb(null) }
      ], cb),

      // the pin-set nodes link to a special 'empty' node, so make sure it exists
      cb => DAGNode.create(Buffer.alloc(0), (err, empty) => {
        if (err) { return cb(err) }
        dag.put(empty, {
          version: 0,
          hashAlg: 'sha2-256',
          format: 'dag-pb',
          preload: false
        }, cb)
      }),

      // create a root node with DAGLinks to the direct and recursive DAGs
      cb => DAGNode.create(Buffer.alloc(0), [dLink, rLink], (err, node) => {
        if (err) { return cb(err) }
        root = node
        dag.put(root, {
          version: 0,
          hashAlg: 'sha2-256',
          format: 'dag-pb',
          preload: false
        }, (err, cid) => {
          if (!err) {
            root.multihash = cid.buffer
          }
          cb(err)
        })
      }),

      // hack for CLI tests
      cb => repo.closed ? repo.open(cb) : cb(null, null),

      // save root to datastore under a consistent key
      cb => repo.datastore.put(pinDataStoreKey, root.multihash, cb)
    ], (err, res) => {
      if (err) { return callback(err) }
      self.log(`Flushed pins with root: ${root}`)
      return callback(null, root)
    })
  }

  const pin = {
    add: promisify((paths, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      options = options || {}

      const recursive = options.recursive == null ? true : options.recursive

      resolvePath(self.object, paths, (err, mhs) => {
        if (err) { return callback(err) }

        // verify that each hash can be pinned
        map(mhs, (multihash, cb) => {
          const key = toB58String(multihash)
          if (recursive) {
            if (recursivePins.has(key)) {
              // it's already pinned recursively
              return cb(null, key)
            }

            // entire graph of nested links should be pinned,
            // so make sure we have all the objects
            dag._getRecursive(key, { preload: options.preload }, (err) => {
              if (err) { return cb(err) }
              // found all objects, we can add the pin
              return cb(null, key)
            })
          } else {
            if (recursivePins.has(key)) {
              // recursive supersedes direct, can't have both
              return cb(new Error(`${key} already pinned recursively`))
            }
            if (directPins.has(key)) {
              // already directly pinned
              return cb(null, key)
            }

            // make sure we have the object
            dag.get(new CID(multihash), { preload: options.preload }, (err) => {
              if (err) { return cb(err) }
              // found the object, we can add the pin
              return cb(null, key)
            })
          }
        }, (err, results) => {
          if (err) { return callback(err) }

          // update the pin sets in memory
          const pinset = recursive ? recursivePins : directPins
          results.forEach(key => pinset.add(key))

          // persist updated pin sets to datastore
          flushPins((err, root) => {
            if (err) { return callback(err) }
            callback(null, results.map(hash => ({ hash })))
          })
        })
      })
    }),

    rm: promisify((paths, options, callback) => {
      if (typeof options === 'function') {
        callback = options
      }

      options = options || {}

      const recursive = options.recursive == null ? true : options.recursive

      if (options.cidBase && !multibase.names.includes(options.cidBase)) {
        return setImmediate(() => {
          callback(errCode(new Error('invalid multibase'), 'ERR_INVALID_MULTIBASE'))
        })
      }

      resolvePath(self.object, paths, (err, mhs) => {
        if (err) { return callback(err) }

        // verify that each hash can be unpinned
        map(mhs, (multihash, cb) => {
          pin._isPinnedWithType(multihash, types.all, (err, res) => {
            if (err) { return cb(err) }
            const { pinned, reason } = res
            const key = toB58String(multihash)
            if (!pinned) {
              return cb(new Error(`${key} is not pinned`))
            }

            switch (reason) {
              case (types.recursive):
                if (recursive) {
                  return cb(null, key)
                } else {
                  return cb(new Error(`${key} is pinned recursively`))
                }
              case (types.direct):
                return cb(null, key)
              default:
                return cb(new Error(
                  `${key} is pinned indirectly under ${reason}`
                ))
            }
          })
        }, (err, results) => {
          if (err) { return callback(err) }

          // update the pin sets in memory
          results.forEach(key => {
            if (recursive && recursivePins.has(key)) {
              recursivePins.delete(key)
            } else {
              directPins.delete(key)
            }
          })

          // persist updated pin sets to datastore
          flushPins((err, root) => {
            if (err) { return callback(err) }
            self.log(`Removed pins: ${results}`)
            callback(null, results.map(hash => ({ hash })))
          })
        })
      })
    }),

    ls: promisify((paths, options, callback) => {
      let type = types.all
      if (typeof paths === 'function') {
        callback = paths
        options = {}
        paths = null
      }
      if (typeof options === 'function') {
        callback = options
      }
      if (paths && paths.type) {
        options = paths
        paths = null
      }

      options = options || {}

      if (options.type) {
        if (typeof options.type !== 'string') {
          return setImmediate(() => callback(invalidPinTypeErr(options.type)))
        }
        type = options.type.toLowerCase()
      }
      if (!Object.keys(types).includes(type)) {
        return setImmediate(() => callback(invalidPinTypeErr(type)))
      }

      if (paths) {
        // check the pinned state of specific hashes
        waterfall([
          (cb) => resolvePath(self.object, paths, cb),
          (hashes, cb) => mapSeries(hashes, (hash, done) => pin._isPinnedWithType(hash, types.all, done), cb),
          (results, cb) => {
            results = results
              .filter(result => result.pinned)
              .map(({ key, reason }) => {
                switch (reason) {
                  case types.direct:
                  case types.recursive:
                    return {
                      hash: key,
                      type: reason
                    }
                  default:
                    return {
                      hash: key,
                      type: `${types.indirect} through ${reason}`
                    }
                }
              })

            if (!results.length) {
              return cb(new Error(`Path is not pinned`))
            }

            cb(null, results)
          }
        ], callback)
      } else {
        // show all pinned items of type
        let pins = []
        if (type === types.direct || type === types.all) {
          pins = pins.concat(
            Array.from(directPins).map(hash => ({
              type: types.direct,
              hash
            }))
          )
        }
        if (type === types.recursive || type === types.all) {
          pins = pins.concat(
            Array.from(recursivePins).map(hash => ({
              type: types.recursive,
              hash
            }))
          )
        }
        if (type === types.indirect || type === types.all) {
          getIndirectKeys((err, indirects) => {
            if (err) { return callback(err) }
            pins = pins
              // if something is pinned both directly and indirectly,
              // report the indirect entry
              .filter(({ hash }) =>
                !indirects.includes(hash) ||
                (indirects.includes(hash) && !directPins.has(hash))
              )
              .concat(indirects.map(hash => ({
                type: types.indirect,
                hash
              })))
            return callback(null, pins)
          })
        } else {
          callback(null, pins)
        }
      }
    }),

    _isPinnedWithType: promisify((multihash, type, callback) => {
      const key = toB58String(multihash)
      const { recursive, direct, all } = types

      // recursive
      if ((type === recursive || type === all) && recursivePins.has(key)) {
        return callback(null, {
          key,
          pinned: true,
          reason: recursive
        })
      }

      if (type === recursive) {
        return callback(null, {
          key,
          pinned: false
        })
      }

      // direct
      if ((type === direct || type === all) && directPins.has(key)) {
        return callback(null, {
          key,
          pinned: true,
          reason: direct
        })
      }

      if (type === direct) {
        return callback(null, {
          key,
          pinned: false
        })
      }

      // indirect (default)
      // check each recursive key to see if multihash is under it
      // arbitrary limit, enables handling 1000s of pins.
      detectLimit(recursiveKeys().map(key => new CID(key)), concurrencyLimit, (cid, cb) => {
        waterfall([
          (done) => dag.get(cid, '', { preload: false }, done),
          (result, done) => done(null, result.value),
          (node, done) => pinset.hasDescendant(node, key, done)
        ], cb)
      }, (err, cid) => callback(err, {
        key,
        pinned: Boolean(cid),
        reason: cid
      }))
    }),

    _load: promisify(callback => {
      waterfall([
        // hack for CLI tests
        (cb) => repo.closed ? repo.datastore.open(cb) : cb(null, null),
        (_, cb) => repo.datastore.has(pinDataStoreKey, cb),
        (has, cb) => has ? cb() : cb(new Error('No pins to load')),
        (cb) => repo.datastore.get(pinDataStoreKey, cb),
        (mh, cb) => {
          dag.get(new CID(mh), '', { preload: false }, cb)
        }
      ], (err, pinRoot) => {
        if (err) {
          if (err.message === 'No pins to load') {
            self.log('No pins to load')
            return callback()
          } else {
            return callback(err)
          }
        }

        parallel([
          cb => pinset.loadSet(pinRoot.value, types.recursive, cb),
          cb => pinset.loadSet(pinRoot.value, types.direct, cb)
        ], (err, keys) => {
          if (err) { return callback(err) }
          const [ rKeys, dKeys ] = keys

          directPins = new Set(dKeys.map(toB58String))
          recursivePins = new Set(rKeys.map(toB58String))

          self.log('Loaded pins from the datastore')
          return callback(null)
        })
      })
    })
  }

  return pin
}

'''
'''--- src/core/components/pin.proto.js ---
'use strict'

/**
 * Protobuf interface
 * from go-ipfs/pin/internal/pb/header.proto
 */
module.exports = `
  syntax = "proto2";

  package ipfs.pin;

  option go_package = "pb";

  message Set {
    optional uint32 version = 1;
    optional uint32 fanout = 2;
    optional fixed32 seed = 3;
  }
`

'''
'''--- src/core/components/ping-pull-stream.js ---
'use strict'

const debug = require('debug')
const OFFLINE_ERROR = require('../utils').OFFLINE_ERROR
const PeerId = require('peer-id')
const pull = require('pull-stream')
const Pushable = require('pull-pushable')

const log = debug('jsipfs:pingPullStream')
log.error = debug('jsipfs:pingPullStream:error')

module.exports = function pingPullStream (self) {
  return (peerId, opts) => {
    if (!self.isOnline()) {
      return pull.error(new Error(OFFLINE_ERROR))
    }

    opts = Object.assign({ count: 10 }, opts)

    const source = Pushable()

    getPeer(self.libp2p, source, peerId, (err, peer) => {
      if (err) {
        log.error(err)
        source.end(err)
        return
      }

      runPing(self.libp2p, source, opts.count, peer, (err) => {
        if (err) {
          log.error(err)
          source.push(getPacket({ success: false, text: err.toString() }))
          source.end()
        }
      })
    })

    return source
  }
}

function getPacket (msg) {
  // Default msg
  const basePacket = { success: true, time: 0, text: '' }
  return Object.assign(basePacket, msg)
}

function getPeer (libp2pNode, statusStream, peerIdStr, cb) {
  let peerId

  try {
    peerId = PeerId.createFromB58String(peerIdStr)
  } catch (err) {
    return cb(err)
  }

  let peerInfo

  try {
    peerInfo = libp2pNode.peerBook.get(peerId)
  } catch (err) {
    log('Peer not found in peer book, trying peer routing')

    // Share lookup status just as in the go implemmentation
    statusStream.push(getPacket({ text: `Looking up peer ${peerIdStr}` }))
    return libp2pNode.peerRouting.findPeer(peerId, cb)
  }

  cb(null, peerInfo)
}

function runPing (libp2pNode, statusStream, count, peer, cb) {
  libp2pNode.ping(peer, (err, p) => {
    if (err) { return cb(err) }

    let packetCount = 0
    let totalTime = 0
    statusStream.push(getPacket({ text: `PING ${peer.id.toB58String()}` }))

    p.on('ping', (time) => {
      statusStream.push(getPacket({ time }))
      totalTime += time
      packetCount++
      if (packetCount >= count) {
        const average = totalTime / count
        p.stop()
        statusStream.push(getPacket({ text: `Average latency: ${average}ms` }))
        statusStream.end()
      }
    })

    p.on('error', (err) => {
      log.error(err)
      p.stop()
      cb(err)
    })

    p.start()
  })
}

'''
'''--- src/core/components/ping-readable-stream.js ---
'use strict'

const toStream = require('pull-stream-to-stream')

module.exports = function pingReadableStream (self) {
  return (peerId, opts) => toStream.source(self.pingPullStream(peerId, opts))
}

'''
'''--- src/core/components/ping.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream/pull')

module.exports = function ping (self) {
  return promisify((peerId, opts, callback) => {
    if (typeof opts === 'function') {
      callback = opts
      opts = {}
    }

    pull(
      self.pingPullStream(peerId, opts),
      pull.collect(callback)
    )
  })
}

'''
'''--- src/core/components/pre-start.js ---
'use strict'

const peerId = require('peer-id')
const PeerInfo = require('peer-info')
const multiaddr = require('multiaddr')
const waterfall = require('async/waterfall')
const Keychain = require('libp2p-keychain')
const defaultsDeep = require('@nodeutils/defaults-deep')
const NoKeychain = require('./no-keychain')
/*
 * Load stuff from Repo into memory
 */
module.exports = function preStart (self) {
  return (callback) => {
    self.log('pre-start')

    const pass = self._options.pass
    waterfall([
      (cb) => self._repo.config.get(cb),
      (config, cb) => {
        if (!self._options.config) {
          return cb(null, config)
        }

        config = defaultsDeep(self._options.config, config)

        self.config.replace(config, (err) => {
          if (err) {
            return cb(err)
          }

          cb(null, config)
        })
      },
      (config, cb) => {
        // Create keychain configuration, if needed.
        if (config.Keychain) {
          return cb(null, config)
        }
        config.Keychain = Keychain.generateOptions()
        self.config.set('Keychain', config.Keychain, (err) => {
          self.log('using default keychain options')
          cb(err, config)
        })
      },
      (config, cb) => {
        // Construct the keychain
        if (self._keychain) {
          // most likely an init or upgrade has happened
        } else if (pass) {
          const keychainOptions = Object.assign({ passPhrase: pass }, config.Keychain)
          self._keychain = new Keychain(self._repo.keys, keychainOptions)
          self.log('keychain constructed')
        } else {
          self._keychain = new NoKeychain()
          self.log('no keychain, use --pass')
        }
        cb(null, config)
      },
      (config, cb) => {
        const privKey = config.Identity.PrivKey

        peerId.createFromPrivKey(privKey, (err, id) => {
          cb(err, config, id)
        })
      },
      (config, id, cb) => {
        // Import the private key as 'self', if needed.
        if (!pass) {
          return cb(null, config, id)
        }
        self._keychain.findKeyByName('self', (err) => {
          if (err) {
            self.log('Creating "self" key')
            return self._keychain.importPeer('self', id, (err) => cb(err, config, id))
          }
          cb(null, config, id)
        })
      },
      (config, id, cb) => {
        self.log('peer created')
        self._peerInfo = new PeerInfo(id)

        if (config.Addresses && config.Addresses.Swarm) {
          config.Addresses.Swarm.forEach((addr) => {
            let ma = multiaddr(addr)

            if (ma.getPeerId()) {
              ma = ma.encapsulate('/ipfs/' + self._peerInfo.id.toB58String())
            }

            self._peerInfo.multiaddrs.add(ma)
          })
        }

        cb()
      },
      (cb) => self.pin._load(cb)
    ], callback)
  }
}

'''
'''--- src/core/components/pubsub.js ---
'use strict'

const promisify = require('promisify-es6')
const setImmediate = require('async/setImmediate')
const errCode = require('err-code')

const errPubsubDisabled = () => {
  return errCode(new Error('pubsub experiment is not enabled'), 'ERR_PUBSUB_DISABLED')
}

module.exports = function pubsub (self) {
  return {
    subscribe: (topic, handler, options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      if (!self._options.EXPERIMENTAL.pubsub) {
        return callback
          ? setImmediate(() => callback(errPubsubDisabled()))
          : Promise.reject(errPubsubDisabled())
      }

      if (!callback) {
        return new Promise((resolve, reject) => {
          self.libp2p.pubsub.subscribe(topic, options, handler, (err) => {
            if (err) {
              return reject(err)
            }
            resolve()
          })
        })
      }

      self.libp2p.pubsub.subscribe(topic, options, handler, callback)
    },

    unsubscribe: (topic, handler, callback) => {
      if (!self._options.EXPERIMENTAL.pubsub) {
        return callback
          ? setImmediate(() => callback(errPubsubDisabled()))
          : Promise.reject(errPubsubDisabled())
      }

      self.libp2p.pubsub.unsubscribe(topic, handler)

      if (!callback) {
        return Promise.resolve()
      }

      setImmediate(() => callback())
    },

    publish: promisify((topic, data, callback) => {
      if (!self._options.EXPERIMENTAL.pubsub) {
        return setImmediate(() => callback(errPubsubDisabled()))
      }
      self.libp2p.pubsub.publish(topic, data, callback)
    }),

    ls: promisify((callback) => {
      if (!self._options.EXPERIMENTAL.pubsub) {
        return setImmediate(() => callback(errPubsubDisabled()))
      }
      self.libp2p.pubsub.ls(callback)
    }),

    peers: promisify((topic, callback) => {
      if (!self._options.EXPERIMENTAL.pubsub) {
        return setImmediate(() => callback(errPubsubDisabled()))
      }
      self.libp2p.pubsub.peers(topic, callback)
    }),

    setMaxListeners (n) {
      if (!self._options.EXPERIMENTAL.pubsub) {
        throw errPubsubDisabled()
      }
      self.libp2p.pubsub.setMaxListeners(n)
    }
  }
}

'''
'''--- src/core/components/repo.js ---
'use strict'

const promisify = require('promisify-es6')
const repoVersion = require('ipfs-repo').repoVersion

module.exports = function repo (self) {
  return {
    init: (bits, empty, callback) => {
      // 1. check if repo already exists
    },

    /**
     * If the repo has been initialized, report the current version.
     * Otherwise report the version that would be initialized.
     *
     * @param {function(Error, Number)} [callback]
     * @returns {undefined}
     */
    version: promisify((callback) => {
      self._repo._isInitialized(err => {
        if (err) {
          // TODO: (dryajov) This is really hacky, there must be a better way
          const match = [
            /Key not found in database \[\/version\]/,
            /ENOENT/,
            /repo is not initialized yet/
          ].some((m) => {
            return m.test(err.message)
          })
          if (match) {
            // this repo has not been initialized
            return callback(null, repoVersion)
          }
          return callback(err)
        }

        self._repo.version.get(callback)
      })
    }),

    gc: promisify((options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      callback(new Error('Not implemented'))
    }),

    stat: promisify((options, callback) => {
      if (typeof options === 'function') {
        callback = options
        options = {}
      }

      self._repo.stat(options, (err, stats) => {
        if (err) return callback(err)

        callback(null, {
          numObjects: stats.numObjects,
          repoSize: stats.repoSize,
          repoPath: stats.repoPath,
          version: stats.version.toString(),
          storageMax: stats.storageMax
        })
      })
    }),

    path: () => self._repo.path
  }
}

'''
'''--- src/core/components/resolve.js ---
'use strict'

const promisify = require('promisify-es6')
const isIpfs = require('is-ipfs')
const setImmediate = require('async/setImmediate')
const doUntil = require('async/doUntil')
const CID = require('cids')
const { cidToString } = require('../../utils/cid')

module.exports = (self) => {
  return promisify((name, opts, cb) => {
    if (typeof opts === 'function') {
      cb = opts
      opts = {}
    }

    opts = opts || {}

    if (!isIpfs.path(name)) {
      return setImmediate(() => cb(new Error('invalid argument')))
    }

    // TODO remove this and update subsequent code when IPNS is implemented
    if (!isIpfs.ipfsPath(name)) {
      return setImmediate(() => cb(new Error('resolve non-IPFS names is not implemented')))
    }

    const split = name.split('/') // ['', 'ipfs', 'hash', ...path]
    const cid = new CID(split[2])

    if (split.length === 3) {
      return setImmediate(() => cb(null, `/ipfs/${cidToString(cid, { base: opts.cidBase })}`))
    }

    const path = split.slice(3).join('/')

    resolve(cid, path, (err, cid) => {
      if (err) return cb(err)
      if (!cid) return cb(new Error('found non-link at given path'))
      cb(null, `/ipfs/${cidToString(cid, { base: opts.cidBase })}`)
    })
  })

  // Resolve the given CID + path to a CID.
  function resolve (cid, path, callback) {
    let value

    doUntil(
      (cb) => {
        self.block.get(cid, (err, block) => {
          if (err) return cb(err)

          const r = self._ipld.resolvers[cid.codec]

          if (!r) {
            return cb(new Error(`No resolver found for codec "${cid.codec}"`))
          }

          r.resolver.resolve(block.data, path, (err, result) => {
            if (err) return cb(err)
            value = result.value
            path = result.remainderPath
            cb()
          })
        })
      },
      () => {
        const endReached = !path || path === '/'

        if (endReached) {
          return true
        }

        if (value) {
          cid = new CID(value['/'])
        }

        return false
      },
      (err) => {
        if (err) return callback(err)
        if (value && value['/']) return callback(null, new CID(value['/']))
        callback()
      }
    )
  }
}

'''
'''--- src/core/components/start.js ---
'use strict'

const series = require('async/series')
const Bitswap = require('ipfs-bitswap')
const get = require('lodash/get')
const setImmediate = require('async/setImmediate')
const promisify = require('promisify-es6')
const { TieredDatastore } = require('datastore-core')

const IPNS = require('../ipns')
const PubsubDatastore = require('../ipns/routing/pubsub-datastore')
const OfflineDatastore = require('../ipns/routing/offline-datastore')
const createLibp2pBundle = require('./libp2p')

module.exports = (self) => {
  return promisify((callback) => {
    const done = (err) => {
      if (err) {
        setImmediate(() => self.emit('error', err))
        return callback(err)
      }

      self.state.started()
      setImmediate(() => self.emit('start'))
      callback()
    }

    if (self.state.state() !== 'stopped') {
      return done(new Error(`Not able to start from state: ${self.state.state()}`))
    }

    self.log('starting')
    self.state.start()

    series([
      (cb) => {
        // The repo may be closed if previously stopped
        self._repo.closed
          ? self._repo.open(cb)
          : cb()
      },
      (cb) => {
        self._repo.config.get((err, config) => {
          if (err) return cb(err)

          const libp2p = createLibp2pBundle(self, config)

          libp2p.start(err => {
            if (err) return cb(err)
            self.libp2p = libp2p
            cb()
          })
        })
      },
      (cb) => {
        // Setup online routing for IPNS with a tiered routing composed by a DHT and a Pubsub router (if properly enabled)
        const ipnsStores = []

        // Add IPNS pubsub if enabled
        let pubsubDs
        if (get(self._options, 'EXPERIMENTAL.ipnsPubsub', false)) {
          const pubsub = self.libp2p.pubsub
          const localDatastore = self._repo.datastore
          const peerId = self._peerInfo.id

          pubsubDs = new PubsubDatastore(pubsub, localDatastore, peerId)
          ipnsStores.push(pubsubDs)
        }

        // DHT should be added as routing if we are not running with local flag
        if (!self._options.offline) {
          ipnsStores.push(self.libp2p.dht)
        } else {
          const offlineDatastore = new OfflineDatastore(self._repo)
          ipnsStores.push(offlineDatastore)
        }

        // Create ipns routing with a set of datastores
        const routing = new TieredDatastore(ipnsStores)
        self._ipns = new IPNS(routing, self._repo.datastore, self._peerInfo, self._keychain, self._options)

        self._bitswap = new Bitswap(
          self.libp2p,
          self._repo.blocks,
          { statsEnabled: true }
        )

        self._bitswap.start()
        self._blockService.setExchange(self._bitswap)

        self._preload.start()
        self._ipns.republisher.start()
        self._mfsPreload.start(cb)
      }
    ], done)
  })
}

'''
'''--- src/core/components/stats.js ---
'use strict'

const promisify = require('promisify-es6')
const Big = require('bignumber.js')
const Pushable = require('pull-pushable')
const human = require('human-to-milliseconds')
const toStream = require('pull-stream-to-stream')
const errCode = require('err-code')

function bandwidthStats (self, opts) {
  return new Promise((resolve, reject) => {
    let stats

    if (opts.peer) {
      stats = self.libp2p.stats.forPeer(opts.peer)
    } else if (opts.proto) {
      stats = self.libp2p.stats.forProtocol(opts.proto)
    } else {
      stats = self.libp2p.stats.global
    }

    if (!stats) {
      resolve({
        totalIn: new Big(0),
        totalOut: new Big(0),
        rateIn: new Big(0),
        rateOut: new Big(0)
      })
      return
    }

    resolve({
      totalIn: stats.snapshot.dataReceived,
      totalOut: stats.snapshot.dataSent,
      rateIn: new Big(stats.movingAverages.dataReceived['60000'].movingAverage() / 60),
      rateOut: new Big(stats.movingAverages.dataSent['60000'].movingAverage() / 60)
    })
  })
}

module.exports = function stats (self) {
  const _bwPullStream = (opts) => {
    opts = opts || {}
    let interval = null
    let stream = Pushable(true, () => {
      if (interval) {
        clearInterval(interval)
      }
    })

    if (opts.poll) {
      human(opts.interval || '1s', (err, value) => {
        if (err) {
          return stream.end(errCode(err, 'ERR_INVALID_POLL_INTERVAL'))
        }

        interval = setInterval(() => {
          bandwidthStats(self, opts)
            .then((stats) => stream.push(stats))
            .catch((err) => stream.end(err))
        }, value)
      })
    } else {
      bandwidthStats(self, opts)
        .then((stats) => {
          stream.push(stats)
          stream.end()
        })
        .catch((err) => stream.end(err))
    }

    return stream.source
  }

  return {
    bitswap: require('./bitswap')(self).stat,
    repo: require('./repo')(self).stat,
    bw: promisify((opts, callback) => {
      if (typeof opts === 'function') {
        callback = opts
        opts = {}
      }

      opts = opts || {}

      bandwidthStats(self, opts)
        .then((stats) => callback(null, stats))
        .catch((err) => callback(err))
    }),
    bwReadableStream: (opts) => toStream.source(_bwPullStream(opts)),
    bwPullStream: _bwPullStream
  }
}

'''
'''--- src/core/components/stop.js ---
'use strict'

const series = require('async/series')
const promisify = require('promisify-es6')

module.exports = (self) => {
  return promisify((callback) => {
    callback = callback || function noop () {}

    self.log('stop')

    if (self.state.state() === 'stopped') {
      return callback(new Error('Already stopped'))
    }

    if (self.state.state() !== 'running') {
      return callback(new Error('Not able to stop from state: ' + self.state.state()))
    }

    const done = (err) => {
      if (err) {
        self.emit('error', err)
        return callback(err)
      }
      self.state.stopped()
      self.emit('stop')
      callback()
    }

    self.state.stop()
    self._blockService.unsetExchange()
    self._bitswap.stop()
    self._preload.stop()

    series([
      (cb) => self._ipns.republisher.stop(cb),
      (cb) => self._mfsPreload.stop(cb),
      (cb) => {
        const libp2p = self.libp2p
        self.libp2p = null
        libp2p.stop(cb)
      },
      (cb) => self._repo.close(cb)
    ], done)
  })
}

'''
'''--- src/core/components/swarm.js ---
'use strict'

const promisify = require('promisify-es6')
const values = require('lodash/values')

const OFFLINE_ERROR = require('../utils').OFFLINE_ERROR

module.exports = function swarm (self) {
  return {
    peers: promisify((opts, callback) => {
      if (typeof opts === 'function') {
        callback = opts
        opts = {}
      }

      opts = opts || {}

      if (!self.isOnline()) {
        return callback(new Error(OFFLINE_ERROR))
      }

      const verbose = opts.v || opts.verbose
      // TODO: return latency and streams when verbose is set
      // we currently don't have this information

      const peers = []

      values(self._peerInfoBook.getAll()).forEach((peer) => {
        const connectedAddr = peer.isConnected()

        if (!connectedAddr) { return }

        const tupple = {
          addr: connectedAddr,
          peer: peer.id
        }
        if (verbose) {
          tupple.latency = 'unknown'
        }

        peers.push(tupple)
      })

      callback(null, peers)
    }),

    // all the addrs we know
    addrs: promisify((callback) => {
      if (!self.isOnline()) {
        return callback(new Error(OFFLINE_ERROR))
      }

      const peers = values(self._peerInfoBook.getAll())

      callback(null, peers)
    }),

    localAddrs: promisify((callback) => {
      if (!self.isOnline()) {
        return callback(new Error(OFFLINE_ERROR))
      }

      callback(null, self.libp2p.peerInfo.multiaddrs.toArray())
    }),

    connect: promisify((maddr, callback) => {
      if (!self.isOnline()) {
        return callback(new Error(OFFLINE_ERROR))
      }

      self.libp2p.dial(maddr, callback)
    }),

    disconnect: promisify((maddr, callback) => {
      if (!self.isOnline()) {
        return callback(new Error(OFFLINE_ERROR))
      }

      self.libp2p.hangUp(maddr, callback)
    }),

    filters: promisify((callback) => callback(new Error('Not implemented')))
  }
}

'''
'''--- src/core/components/version.js ---
'use strict'

const pkg = require('../../../package.json')
const promisify = require('promisify-es6')

// TODO add the commit hash of the current ipfs version to the response.
module.exports = function version (self) {
  return promisify((opts, callback) => {
    if (typeof opts === 'function') {
      callback = opts
      opts = {}
    }

    self.repo.version((err, repoVersion) => {
      if (err) {
        return callback(err)
      }

      callback(null, {
        version: pkg.version,
        repo: repoVersion,
        commit: ''
      })
    })
  })
}

'''
'''--- src/core/config.js ---
'use strict'

const Joi = require('joi').extend(require('joi-multiaddr'))

const schema = Joi.object().keys({
  repo: Joi.alternatives().try(
    Joi.object(), // TODO: schema for IPFS repo
    Joi.string()
  ).allow(null),
  repoOwner: Joi.boolean().default(true),
  preload: Joi.object().keys({
    enabled: Joi.boolean().default(true),
    addresses: Joi.array().items(Joi.multiaddr().options({ convert: false })),
    interval: Joi.number().integer().default(30 * 1000)
  }).allow(null),
  init: Joi.alternatives().try(
    Joi.boolean(),
    Joi.object().keys({ bits: Joi.number().integer() })
  ).allow(null),
  start: Joi.boolean(),
  offline: Joi.boolean(),
  pass: Joi.string().allow(''),
  relay: Joi.object().keys({
    enabled: Joi.boolean(),
    hop: Joi.object().keys({
      enabled: Joi.boolean(),
      active: Joi.boolean()
    }).allow(null)
  }).allow(null),
  EXPERIMENTAL: Joi.object().keys({
    pubsub: Joi.boolean(),
    ipnsPubsub: Joi.boolean(),
    sharding: Joi.boolean(),
    dht: Joi.boolean()
  }).allow(null),
  connectionManager: Joi.object().allow(null),
  config: Joi.object().keys({
    Addresses: Joi.object().keys({
      Swarm: Joi.array().items(Joi.multiaddr().options({ convert: false })),
      API: Joi.multiaddr().options({ convert: false }),
      Gateway: Joi.multiaddr().options({ convert: false })
    }).allow(null),
    Discovery: Joi.object().keys({
      MDNS: Joi.object().keys({
        Enabled: Joi.boolean(),
        Interval: Joi.number().integer()
      }).allow(null),
      webRTCStar: Joi.object().keys({
        Enabled: Joi.boolean()
      }).allow(null)
    }).allow(null),
    Bootstrap: Joi.array().items(Joi.multiaddr().IPFS().options({ convert: false }))
  }).allow(null),
  libp2p: Joi.alternatives().try(
    Joi.func(),
    Joi.object().keys({
      modules: Joi.object().allow(null) // TODO: schemas for libp2p modules?
    })
  ).allow(null)
}).options({ allowUnknown: true })

module.exports.validate = (config) => Joi.attempt(config, schema)

'''
'''--- src/core/index.js ---
'use strict'

const BlockService = require('ipfs-block-service')
const Ipld = require('ipld')
const PeerId = require('peer-id')
const PeerInfo = require('peer-info')
const crypto = require('libp2p-crypto')
const isIPFS = require('is-ipfs')
const multiaddr = require('multiaddr')
const multihash = require('multihashes')
const PeerBook = require('peer-book')
const multibase = require('multibase')
const CID = require('cids')
const debug = require('debug')
const defaultsDeep = require('@nodeutils/defaults-deep')
const EventEmitter = require('events')

const config = require('./config')
const boot = require('./boot')
const components = require('./components')

// replaced by repo-browser when running in the browser
const defaultRepo = require('./runtime/repo-nodejs')
const preload = require('./preload')
const mfsPreload = require('./mfs-preload')

// All known (non-default) IPLD formats
const IpldFormats = {
  get 'bitcoin-block' () {
    return require('ipld-bitcoin')
  },
  get 'eth-account-snapshot' () {
    return require('ipld-ethereum').ethAccountSnapshot
  },
  get 'eth-block' () {
    return require('ipld-ethereum').ethBlock
  },
  get 'eth-block-list' () {
    return require('ipld-ethereum').ethBlockList
  },
  get 'eth-state-trie' () {
    return require('ipld-ethereum').ethStateTrie
  },
  get 'eth-storage-trie' () {
    return require('ipld-ethereum').ethStorageTrie
  },
  get 'eth-tx' () {
    return require('ipld-ethereum').ethTx
  },
  get 'eth-tx-trie' () {
    return require('ipld-ethereum').ethTxTrie
  },
  get 'git-raw' () {
    return require('ipld-git')
  },
  get 'zcash-block' () {
    return require('ipld-zcash')
  }
}

class IPFS extends EventEmitter {
  constructor (options) {
    super()

    const defaults = {
      init: true,
      start: true,
      EXPERIMENTAL: {},
      preload: {
        enabled: true,
        addresses: [
          '/dnsaddr/node0.preload.ipfs.io/https',
          '/dnsaddr/node1.preload.ipfs.io/https'
        ]
      }
    }

    options = config.validate(options || {})

    this._options = defaultsDeep(options, defaults)

    if (options.init === false) {
      this._options.init = false
    }

    if (!(options.start === false)) {
      this._options.start = true
    }

    if (typeof options.repo === 'string' ||
        options.repo === undefined) {
      this._repo = defaultRepo(options.repo)
    } else {
      this._repo = options.repo
    }

    // IPFS utils
    this.log = debug('jsipfs')
    this.log.err = debug('jsipfs:err')

    // IPFS types
    this.types = {
      Buffer: Buffer,
      PeerId: PeerId,
      PeerInfo: PeerInfo,
      multiaddr: multiaddr,
      multibase: multibase,
      multihash: multihash,
      CID: CID
    }

    // IPFS Core Internals
    // this._repo - assigned above
    this._peerInfoBook = new PeerBook()
    this._peerInfo = undefined
    this._bitswap = undefined
    this._blockService = new BlockService(this._repo)
    this._ipld = new Ipld({
      blockService: this._blockService,
      loadFormat: (codec, callback) => {
        this.log('Loading IPLD format', codec)
        if (IpldFormats[codec]) return callback(null, IpldFormats[codec])
        callback(new Error(`Missing IPLD format "${codec}"`))
      }
    })
    this._preload = preload(this)
    this._mfsPreload = mfsPreload(this)
    this._ipns = undefined
    // eslint-disable-next-line no-console
    this._print = this._options.silent ? this.log : console.log

    // IPFS Core exposed components
    //   - for booting up a node
    this.init = components.init(this)
    this.preStart = components.preStart(this)
    this.start = components.start(this)
    this.stop = components.stop(this)
    this.shutdown = this.stop
    this.isOnline = components.isOnline(this)
    //   - interface-ipfs-core defined API
    Object.assign(this, components.filesRegular(this))
    this.version = components.version(this)
    this.id = components.id(this)
    this.repo = components.repo(this)
    this.bootstrap = components.bootstrap(this)
    this.config = components.config(this)
    this.block = components.block(this)
    this.object = components.object(this)
    this.dag = components.dag(this)
    this.files = components.filesMFS(this)
    this.libp2p = null // assigned on start
    this.swarm = components.swarm(this)
    this.name = components.name(this)
    this.bitswap = components.bitswap(this)
    this.pin = components.pin(this)
    this.ping = components.ping(this)
    this.pingPullStream = components.pingPullStream(this)
    this.pingReadableStream = components.pingReadableStream(this)
    this.pubsub = components.pubsub(this)
    this.dht = components.dht(this)
    this.dns = components.dns(this)
    this.key = components.key(this)
    this.stats = components.stats(this)
    this.resolve = components.resolve(this)

    if (this._options.EXPERIMENTAL.pubsub) {
      this.log('EXPERIMENTAL pubsub is enabled')
    }
    if (this._options.EXPERIMENTAL.ipnsPubsub) {
      if (!this._options.EXPERIMENTAL.pubsub) {
        this.log('EXPERIMENTAL pubsub is enabled to use IPNS pubsub')
        this._options.EXPERIMENTAL.pubsub = true
      }

      this.log('EXPERIMENTAL IPNS pubsub is enabled')
    }
    if (this._options.EXPERIMENTAL.sharding) {
      this.log('EXPERIMENTAL sharding is enabled')
    }

    this.state = require('./state')(this)

    // ipfs.util
    this.util = {
      crypto,
      isIPFS
    }

    boot(this)
  }
}

exports = module.exports = IPFS

exports.createNode = (options) => {
  return new IPFS(options)
}

'''
'''--- src/core/ipns/index.js ---
'use strict'

const { createFromPrivKey } = require('peer-id')
const series = require('async/series')
const Receptacle = require('receptacle')

const errcode = require('err-code')
const debug = require('debug')
const log = debug('jsipfs:ipns')
log.error = debug('jsipfs:ipns:error')

const IpnsPublisher = require('./publisher')
const IpnsRepublisher = require('./republisher')
const IpnsResolver = require('./resolver')
const path = require('./path')

const defaultRecordTtl = 60 * 1000

class IPNS {
  constructor (routing, datastore, peerInfo, keychain, options) {
    this.publisher = new IpnsPublisher(routing, datastore)
    this.republisher = new IpnsRepublisher(this.publisher, datastore, peerInfo, keychain, options)
    this.resolver = new IpnsResolver(routing)
    this.cache = new Receptacle({ max: 1000 }) // Create an LRU cache with max 1000 items
    this.routing = routing
  }

  // Publish
  publish (privKey, value, lifetime, callback) {
    series([
      (cb) => createFromPrivKey(privKey.bytes, cb),
      (cb) => this.publisher.publishWithEOL(privKey, value, lifetime, cb)
    ], (err, results) => {
      if (err) {
        log.error(err)
        return callback(err)
      }

      log(`IPNS value ${value} was published correctly`)

      // Add to cache
      const id = results[0].toB58String()
      const ttEol = parseFloat(lifetime)
      const ttl = (ttEol < defaultRecordTtl) ? ttEol : defaultRecordTtl

      this.cache.set(id, value, { ttl: ttl })

      log(`IPNS value ${value} was cached correctly`)

      callback(null, {
        name: id,
        value: value
      })
    })
  }

  // Resolve
  resolve (name, options, callback) {
    if (typeof name !== 'string') {
      const errMsg = `name received is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_NAME'))
    }

    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    options = options || {}

    // If recursive, we should not try to get the cached value
    if (!options.nocache && !options.recursive) {
      // Try to get the record from cache
      const id = name.split('/')[2]
      const result = this.cache.get(id)

      if (result) {
        return callback(null, {
          path: result
        })
      }
    }

    this.resolver.resolve(name, options, (err, result) => {
      if (err) {
        log.error(err)
        return callback(err)
      }

      log(`IPNS record from ${name} was resolved correctly`)

      callback(null, {
        path: result
      })
    })
  }

  // Initialize keyspace
  // sets the ipns record for the given key to point to an empty directory
  initializeKeyspace (privKey, value, callback) {
    this.publisher.publish(privKey, value, callback)
  }
}

exports = module.exports = IPNS
exports.path = path

'''
'''--- src/core/ipns/path.js ---
'use strict'

const isIPFS = require('is-ipfs')

const debug = require('debug')
const log = debug('jsipfs:ipns:path')
log.error = debug('jsipfs:ipns:path:error')

// resolves the given path by parsing out protocol-specific entries
// (e.g. /ipns/<node-key>) and then going through the /ipfs/ entries and returning the final node
const resolvePath = (ipfsNode, name, callback) => {
  // ipns path
  if (isIPFS.ipnsPath(name)) {
    log(`resolve ipns path ${name}`)

    return ipfsNode._ipns.resolve(name, callback)
  }

  // ipfs path
  ipfsNode.dag.get(name.substring('/ipfs/'.length), (err, value) => {
    if (err) {
      return callback(err)
    }

    return callback(null, value)
  })
}

module.exports = {
  resolvePath
}

'''
'''--- src/core/ipns/publisher.js ---
'use strict'

const PeerId = require('peer-id')
const { Key } = require('interface-datastore')
const series = require('async/series')
const errcode = require('err-code')

const debug = require('debug')
const log = debug('jsipfs:ipns:publisher')
log.error = debug('jsipfs:ipns:publisher:error')

const ipns = require('ipns')

const defaultRecordTtl = 60 * 60 * 1000

// IpnsPublisher is capable of publishing and resolving names to the IPFS routing system.
class IpnsPublisher {
  constructor (routing, datastore) {
    this._routing = routing
    this._datastore = datastore
  }

  // publish record with a eol
  publishWithEOL (privKey, value, lifetime, callback) {
    if (!privKey || !privKey.bytes) {
      const errMsg = `one or more of the provided parameters are not defined`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_UNDEFINED_PARAMETER'))
    }

    PeerId.createFromPrivKey(privKey.bytes, (err, peerId) => {
      if (err) {
        return callback(err)
      }

      this._updateOrCreateRecord(privKey, value, lifetime, peerId, (err, record) => {
        if (err) {
          return callback(err)
        }

        this._putRecordToRouting(record, peerId, callback)
      })
    })
  }

  // Accepts a keypair, as well as a value (ipfsPath), and publishes it out to the routing system
  publish (privKey, value, callback) {
    this.publishWithEOL(privKey, value, defaultRecordTtl, callback)
  }

  _putRecordToRouting (record, peerId, callback) {
    if (!(PeerId.isPeerId(peerId))) {
      const errMsg = `peerId received is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_PEER_ID'))
    }
    const publicKey = peerId._pubKey

    ipns.embedPublicKey(publicKey, record, (err, embedPublicKeyRecord) => {
      if (err) {
        return callback(err)
      }

      let keys
      try {
        keys = ipns.getIdKeys(peerId.toBytes())
      } catch (err) {
        log.error(err)
        return callback(err)
      }

      series([
        (cb) => this._publishEntry(keys.routingKey, embedPublicKeyRecord || record, peerId, cb),
        // Publish the public key to support old go-ipfs nodes that are looking for it in the routing
        // We will be able to deprecate this part in the future, since the public keys will be only
        // in IPNS record and the peerId.
        (cb) => this._publishPublicKey(keys.routingPubKey, publicKey, peerId, cb)
      ], (err) => {
        if (err) {
          log.error(err)
          return callback(err)
        }

        callback(null, embedPublicKeyRecord || record)
      })
    })
  }

  _publishEntry (key, entry, peerId, callback) {
    if (!(Key.isKey(key))) {
      const errMsg = `datastore key does not have a valid format`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_DATASTORE_KEY'))
    }

    let entryData
    try {
      // Marshal record
      entryData = ipns.marshal(entry)
    } catch (err) {
      log.error(err)
      return callback(err)
    }

    // Add record to routing (buffer key)
    this._routing.put(key.toBuffer(), entryData, (err, res) => {
      if (err) {
        const errMsg = `ipns record for ${key.toString()} could not be stored in the routing`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_PUTTING_TO_ROUTING'))
      }

      log(`ipns record for ${key.toString()} was stored in the routing`)
      callback(null, res)
    })
  }

  _publishPublicKey (key, publicKey, peerId, callback) {
    if ((!Key.isKey(key))) {
      const errMsg = `datastore key does not have a valid format`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_DATASTORE_KEY'))
    }

    if (!publicKey || !publicKey.bytes) {
      const errMsg = `one or more of the provided parameters are not defined`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_UNDEFINED_PARAMETER'))
    }

    // Add public key to routing (buffer key)
    this._routing.put(key.toBuffer(), publicKey.bytes, (err, res) => {
      if (err) {
        const errMsg = `public key for ${key.toString()} could not be stored in the routing`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_PUTTING_TO_ROUTING'))
      }

      log(`public key for ${key.toString()} was stored in the routing`)
      callback(null, res)
    })
  }

  // Returns the record this node has published corresponding to the given peer ID.
  // If `checkRouting` is true and we have no existing record, this method will check the routing system for any existing records.
  _getPublished (peerId, options, callback) {
    if (!(PeerId.isPeerId(peerId))) {
      const errMsg = `peerId received is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_PEER_ID'))
    }

    options = options || {}
    const checkRouting = options.checkRouting !== false

    this._datastore.get(ipns.getLocalKey(peerId.id), (err, dsVal) => {
      if (err) {
        if (err.code !== 'ERR_NOT_FOUND') {
          const errMsg = `unexpected error getting the ipns record ${peerId.id} from datastore`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_UNEXPECTED_DATASTORE_RESPONSE'))
        }

        if (!checkRouting) {
          return callback((errcode(err)))
        }

        // Try to get from routing
        let keys
        try {
          keys = ipns.getIdKeys(peerId.toBytes())
        } catch (err) {
          log.error(err)
          return callback(err)
        }

        this._routing.get(keys.routingKey.toBuffer(), (err, res) => {
          if (err) {
            return callback(err)
          }

          // unmarshal data
          this._unmarshalData(res, callback)
        })
      } else {
        // unmarshal data
        this._unmarshalData(dsVal, callback)
      }
    })
  }

  _unmarshalData (data, callback) {
    let result
    try {
      result = ipns.unmarshal(data)
    } catch (err) {
      log.error(err)
      return callback(errcode(err, 'ERR_INVALID_RECORD_DATA'))
    }

    callback(null, result)
  }

  _updateOrCreateRecord (privKey, value, validity, peerId, callback) {
    if (!(PeerId.isPeerId(peerId))) {
      const errMsg = `peerId received is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_PEER_ID'))
    }

    const getPublishedOptions = {
      checkRouting: true
    }

    this._getPublished(peerId, getPublishedOptions, (err, record) => {
      if (err) {
        if (err.code !== 'ERR_NOT_FOUND') {
          const errMsg = `unexpected error when determining the last published IPNS record for ${peerId.id}`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_DETERMINING_PUBLISHED_RECORD'))
        }
      }

      // Determinate the record sequence number
      let seqNumber = 0
      if (record && record.sequence !== undefined) {
        seqNumber = record.value.toString() !== value ? record.sequence + 1 : record.sequence
      }

      // Create record
      ipns.create(privKey, value, seqNumber, validity, (err, entryData) => {
        if (err) {
          const errMsg = `ipns record for ${value} could not be created`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_CREATING_IPNS_RECORD'))
        }

        // TODO IMPROVEMENT - set ttl (still experimental feature for go)

        // Marshal record
        const data = ipns.marshal(entryData)

        // Store the new record
        this._datastore.put(ipns.getLocalKey(peerId.id), data, (err, res) => {
          if (err) {
            const errMsg = `ipns record for ${value} could not be stored in the datastore`

            log.error(errMsg)
            return callback(errcode(new Error(errMsg), 'ERR_STORING_IN_DATASTORE'))
          }

          log(`ipns record for ${value} was stored in the datastore`)
          callback(null, entryData)
        })
      })
    })
  }
}

exports = module.exports = IpnsPublisher

'''
'''--- src/core/ipns/republisher.js ---
'use strict'

const ipns = require('ipns')
const crypto = require('libp2p-crypto')
const PeerId = require('peer-id')
const errcode = require('err-code')

const debug = require('debug')
const each = require('async/each')
const waterfall = require('async/waterfall')
const log = debug('jsipfs:ipns:republisher')
log.error = debug('jsipfs:ipns:republisher:error')

const minute = 60 * 1000
const hour = 60 * minute

const defaultBroadcastInterval = 4 * hour
const defaultRecordLifetime = 24 * hour

class IpnsRepublisher {
  constructor (publisher, datastore, peerInfo, keychain, options) {
    this._publisher = publisher
    this._datastore = datastore
    this._peerInfo = peerInfo
    this._keychain = keychain
    this._options = options
    this._republishHandle = null
  }

  start () {
    if (this._republishHandle) {
      const errMsg = 'already running'

      log.error(errMsg)
      throw errcode(new Error(errMsg), 'ERR_REPUBLISH_ALREADY_RUNNING')
    }

    // TODO: this handler should be isolated in another module
    const republishHandle = {
      _onCancel: null,
      _timeoutId: null,
      runPeriodically: (fn, period) => {
        republishHandle._timeoutId = setTimeout(() => {
          republishHandle._timeoutId = null

          fn((nextPeriod) => {
            // Was republish cancelled while fn was being called?
            if (republishHandle._onCancel) {
              return republishHandle._onCancel()
            }
            // Schedule next
            republishHandle.runPeriodically(fn, nextPeriod || period)
          })
        }, period)
      },
      cancel: (cb) => {
        // Not currently running a republish, can callback immediately
        if (republishHandle._timeoutId) {
          clearTimeout(republishHandle._timeoutId)
          return cb()
        }
        // Wait for republish to finish then call callback
        republishHandle._onCancel = cb
      }
    }

    const { privKey } = this._peerInfo.id
    const { pass } = this._options

    republishHandle.runPeriodically((done) => {
      this._republishEntries(privKey, pass, () => done(defaultBroadcastInterval))
    }, minute)

    this._republishHandle = republishHandle
  }

  stop (callback) {
    const republishHandle = this._republishHandle

    if (!republishHandle) {
      const errMsg = 'not running'

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_REPUBLISH_NOT_RUNNING'))
    }

    this._republishHandle = null
    republishHandle.cancel(callback)
  }

  _republishEntries (privateKey, pass, callback) {
    // TODO: Should use list of published entries.
    // We can't currently *do* that because go uses this method for now.
    this._republishEntry(privateKey, (err) => {
      if (err) {
        const errMsg = 'cannot republish entry for the node\'s private key'

        log.error(errMsg)
        return
      }

      // keychain needs pass to get the cryptographic keys
      if (pass) {
        this._keychain.listKeys((err, list) => {
          if (err) {
            log.error(err)
            return
          }

          each(list, (key, cb) => {
            waterfall([
              (cb) => this._keychain.exportKey(key.name, pass, cb),
              (pem, cb) => crypto.keys.import(pem, pass, cb)
            ], (err, privKey) => {
              if (err) {
                log.error(err)
                return
              }

              this._republishEntry(privKey, cb)
            })
          }, (err) => {
            if (err) {
              log.error(err)
            }
            callback(null)
          })
        })
      } else {
        callback(null)
      }
    })
  }

  _republishEntry (privateKey, callback) {
    if (!privateKey || !privateKey.bytes) {
      const errMsg = `one or more of the provided parameters are not defined`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_UNDEFINED_PARAMETER'))
    }

    waterfall([
      (cb) => PeerId.createFromPrivKey(privateKey.bytes, cb),
      (peerId, cb) => this._getPreviousValue(peerId, cb)
    ], (err, value) => {
      if (err) {
        return callback(err.code === 'ERR_NO_ENTRY_FOUND' ? null : err)
      }

      this._publisher.publishWithEOL(privateKey, value, defaultRecordLifetime, callback)
    })
  }

  _getPreviousValue (peerId, callback) {
    if (!(PeerId.isPeerId(peerId))) {
      const errMsg = `peerId received is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_PEER_ID'))
    }

    this._datastore.get(ipns.getLocalKey(peerId.id), (err, dsVal) => {
      // error handling
      // no need to republish
      if (err && err.notFound) {
        const errMsg = `no previous entry for record with id: ${peerId.id}`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_NO_ENTRY_FOUND'))
      } else if (err) {
        return callback(err)
      }

      if (!Buffer.isBuffer(dsVal)) {
        const errMsg = `found ipns record that we couldn't process`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_INVALID_IPNS_RECORD'))
      }

      // unmarshal data
      let record
      try {
        record = ipns.unmarshal(dsVal)
      } catch (err) {
        const errMsg = `found ipns record that we couldn't convert to a value`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_INVALID_IPNS_RECORD'))
      }

      callback(null, record.value)
    })
  }
}

exports = module.exports = IpnsRepublisher

'''
'''--- src/core/ipns/resolver.js ---
'use strict'

const ipns = require('ipns')
const crypto = require('libp2p-crypto')
const PeerId = require('peer-id')
const errcode = require('err-code')

const debug = require('debug')
const log = debug('jsipfs:ipns:resolver')
log.error = debug('jsipfs:ipns:resolver:error')

const defaultMaximumRecursiveDepth = 32

class IpnsResolver {
  constructor (routing) {
    this._routing = routing
  }

  resolve (name, options, callback) {
    if (typeof options === 'function') {
      callback = options
      options = {}
    }

    if (typeof name !== 'string') {
      const errMsg = `one or more of the provided parameters are not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_PARAMETER'))
    }

    options = options || {}
    const recursive = options.recursive && options.recursive.toString() === 'true'

    const nameSegments = name.split('/')

    if (nameSegments.length !== 3 || nameSegments[0] !== '') {
      const errMsg = `invalid name syntax for ${name}`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_NAME_SYNTAX'))
    }

    const key = nameSegments[2]

    // Define a maximum depth if recursive option enabled
    let depth

    if (recursive) {
      depth = defaultMaximumRecursiveDepth
    }

    this.resolver(key, depth, (err, res) => {
      if (err) {
        return callback(err)
      }

      log(`${name} was locally resolved correctly`)
      callback(null, res)
    })
  }

  // Recursive resolver according to the specified depth
  resolver (name, depth, callback) {
    // Exceeded recursive maximum depth
    if (depth === 0) {
      const errMsg = `could not resolve name (recursion limit of ${defaultMaximumRecursiveDepth} exceeded)`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_RESOLVE_RECURSION_LIMIT'))
    }

    this._resolveName(name, (err, res) => {
      if (err) {
        return callback(err)
      }

      const nameSegments = res.split('/')

      // If obtained a ipfs cid or recursive option is disabled
      if (nameSegments[1] === 'ipfs' || !depth) {
        return callback(null, res)
      }

      // continue recursively until depth equals 0
      this.resolver(nameSegments[2], depth - 1, callback)
    })
  }

  // resolve ipns entries from the provided routing
  _resolveName (name, callback) {
    let peerId

    try {
      peerId = PeerId.createFromB58String(name)
    } catch (err) {
      return callback(err)
    }

    const { routingKey, routingPubKey } = ipns.getIdKeys(peerId.toBytes())

    this._routing.get(routingKey.toBuffer(), (err, record) => {
      if (err) {
        if (err.code !== 'ERR_NOT_FOUND') {
          const errMsg = `unexpected error getting the ipns record ${peerId.id}`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_UNEXPECTED_ERROR_GETTING_RECORD'))
        }
        const errMsg = `record requested was not found for ${name} (${routingKey}) in the network`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_NO_RECORD_FOUND'))
      }

      // IPNS entry
      let ipnsEntry
      try {
        ipnsEntry = ipns.unmarshal(record)
      } catch (err) {
        const errMsg = `found ipns record that we couldn't convert to a value`

        log.error(errMsg)
        return callback(errcode(new Error(errMsg), 'ERR_INVALID_RECORD_RECEIVED'))
      }

      // if the record has a public key validate it
      if (ipnsEntry.pubKey) {
        return this._validateRecord(peerId, ipnsEntry, callback)
      }

      // Otherwise, try to get the public key from routing
      this._routing.get(routingKey.toBuffer(), (err, pubKey) => {
        if (err) {
          if (err.code !== 'ERR_NOT_FOUND') {
            const errMsg = `unexpected error getting the public key for the ipns record ${peerId.id}`

            log.error(errMsg)
            return callback(errcode(new Error(errMsg), 'ERR_UNEXPECTED_ERROR_GETTING_PUB_KEY'))
          }
          const errMsg = `public key requested was not found for ${name} (${routingPubKey}) in the network`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_NO_RECORD_FOUND'))
        }

        try {
          // Insert it into the peer id, in order to be validated by IPNS validator
          peerId.pubKey = crypto.keys.unmarshalPublicKey(pubKey)
        } catch (err) {
          const errMsg = `found public key record that we couldn't convert to a value`

          log.error(errMsg)
          return callback(errcode(new Error(errMsg), 'ERR_INVALID_PUB_KEY_RECEIVED'))
        }

        this._validateRecord(peerId, ipnsEntry, callback)
      })
    })
  }

  // validate a resolved record
  _validateRecord (peerId, ipnsEntry, callback) {
    ipns.extractPublicKey(peerId, ipnsEntry, (err, pubKey) => {
      if (err) {
        return callback(err)
      }

      // IPNS entry validation
      ipns.validate(pubKey, ipnsEntry, (err) => {
        if (err) {
          return callback(err)
        }

        callback(null, ipnsEntry.value.toString())
      })
    })
  }
}

exports = module.exports = IpnsResolver

'''
'''--- src/core/ipns/routing/offline-datastore.js ---
'use strict'

const { Key } = require('interface-datastore')
const { Record } = require('libp2p-record')
const { encodeBase32 } = require('./utils')

const errcode = require('err-code')
const debug = require('debug')
const log = debug('jsipfs:ipns:offline-datastore')
log.error = debug('jsipfs:ipns:offline-datastore:error')

// Offline datastore aims to mimic the same encoding as routing when storing records
// to the local datastore
class OfflineDatastore {
  constructor (repo) {
    this._repo = repo
  }

  /**
   * Put a value to the local datastore indexed by the received key properly encoded.
   * @param {Buffer} key identifier of the value.
   * @param {Buffer} value value to be stored.
   * @param {function(Error)} callback
   * @returns {void}
   */
  put (key, value, callback) {
    if (!Buffer.isBuffer(key)) {
      const errMsg = `Offline datastore key must be a buffer`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_KEY'))
    }

    if (!Buffer.isBuffer(value)) {
      const errMsg = `Offline datastore value must be a buffer`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_VALUE'))
    }

    let routingKey

    try {
      routingKey = this._routingKey(key)
    } catch (err) {
      const errMsg = `Not possible to generate the routing key`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_GENERATING_ROUTING_KEY'))
    }

    // Marshal to libp2p record as the DHT does
    const record = new Record(key, value)

    this._repo.datastore.put(routingKey, record.serialize(), callback)
  }

  /**
   * Get a value from the local datastore indexed by the received key properly encoded.
   * @param {Buffer} key identifier of the value to be obtained.
   * @param {function(Error, Buffer)} callback
   * @returns {void}
   */
  get (key, callback) {
    if (!Buffer.isBuffer(key)) {
      const errMsg = `Offline datastore key must be a buffer`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_KEY'))
    }

    let routingKey

    try {
      routingKey = this._routingKey(key)
    } catch (err) {
      const errMsg = `Not possible to generate the routing key`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_GENERATING_ROUTING_KEY'))
    }

    this._repo.datastore.get(routingKey, (err, res) => {
      if (err) {
        return callback(err)
      }

      // Unmarshal libp2p record as the DHT does
      let record
      try {
        record = Record.deserialize(res)
      } catch (err) {
        log.error(err)
        return callback(err)
      }

      callback(null, record.value)
    })
  }

  // encode key properly - base32(/ipns/{cid})
  _routingKey (key) {
    return new Key('/' + encodeBase32(key), false)
  }
}

exports = module.exports = OfflineDatastore

'''
'''--- src/core/ipns/routing/pubsub-datastore.js ---
'use strict'

const ipns = require('ipns')
const { fromB58String, toB58String } = require('multihashes')
const PubsubDatastore = require('datastore-pubsub')

const withIs = require('class-is')

const errcode = require('err-code')
const debug = require('debug')
const log = debug('jsipfs:ipns:pubsub')
log.error = debug('jsipfs:ipns:pubsub:error')

// Pubsub datastore aims to manage the pubsub subscriptions for IPNS
class IpnsPubsubDatastore {
  constructor (pubsub, localDatastore, peerId) {
    this._pubsub = pubsub
    this._subscriptions = {}

    // Bind _handleSubscriptionKey function, which is called by PubsubDatastore.
    this._handleSubscriptionKey = this._handleSubscriptionKey.bind(this)
    this._pubsubDs = new PubsubDatastore(pubsub, localDatastore, peerId, ipns.validator, this._handleSubscriptionKey)
  }

  /**
   * Put a value to the pubsub datastore indexed by the received key properly encoded.
   * @param {Buffer} key identifier of the value.
   * @param {Buffer} value value to be stored.
   * @param {function(Error)} callback
   * @returns {void}
   */
  put (key, value, callback) {
    this._pubsubDs.put(key, value, callback)
  }

  /**
   * Get a value from the pubsub datastore indexed by the received key properly encoded.
   * Moreover, the identifier topic is subscribed and the pubsub datastore records will be
   * updated once new publishes occur.
   * @param {Buffer} key identifier of the value to be obtained.
   * @param {function(Error, Buffer)} callback
   * @returns {void}
   */
  get (key, callback) {
    this._pubsubDs.get(key, (err, res) => {
      // Add topic subscribed
      const ns = key.slice(0, ipns.namespaceLength)

      if (ns.toString() === ipns.namespace) {
        const stringifiedTopic = key.toString()
        const id = toB58String(key.slice(ipns.namespaceLength))

        this._subscriptions[stringifiedTopic] = id

        log(`subscribed pubsub ${stringifiedTopic}: ${id}`)
      }

      // If no data was obtained, after storing the subscription, return the error.
      if (err) {
        return callback(err)
      }

      callback(null, res)
    })
  }

  // Modify subscription key to have a proper encoding
  _handleSubscriptionKey (key, callback) {
    const subscriber = this._subscriptions[key]

    if (!subscriber) {
      const errMsg = `key ${key} does not correspond to a subscription`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_KEY'))
    }

    let keys
    try {
      keys = ipns.getIdKeys(fromB58String(subscriber))
    } catch (err) {
      log.error(err)
      return callback(err)
    }

    callback(null, keys.routingKey.toBuffer())
  }

  /**
   * Get pubsub subscriptions related to ipns.
   * @param {function(Error, Object)} callback
   * @returns {void}
   */
  getSubscriptions (callback) {
    const subscriptions = Object.values(this._subscriptions).filter(Boolean)

    return callback(null, subscriptions.map((sub) => `${ipns.namespace}${sub}`))
  }

  /**
   * Cancel pubsub subscriptions related to ipns.
   * @param {String} name ipns path to cancel the pubsub subscription.
   * @param {function(Error, Object)} callback
   * @returns {void}
   */
  cancel (name, callback) {
    if (typeof name !== 'string') {
      const errMsg = `received subscription name is not valid`

      log.error(errMsg)
      return callback(errcode(new Error(errMsg), 'ERR_INVALID_SUBSCRIPTION_NAME'))
    }

    // Trim /ipns/ prefix from the name
    if (name.startsWith(ipns.namespace)) {
      name = name.substring(ipns.namespaceLength)
    }

    const stringifiedTopic = Object.keys(this._subscriptions).find((key) => this._subscriptions[key] === name)

    // Not found topic
    if (!stringifiedTopic) {
      return callback(null, {
        canceled: false
      })
    }

    // Unsubscribe topic
    try {
      const bufTopic = Buffer.from(stringifiedTopic)

      this._pubsubDs.unsubscribe(bufTopic)
    } catch (err) {
      return callback(err)
    }

    this._subscriptions[stringifiedTopic] = undefined
    log(`unsubscribed pubsub ${stringifiedTopic}: ${name}`)

    callback(null, {
      canceled: true
    })
  }
}

exports = module.exports = withIs(IpnsPubsubDatastore, { className: 'IpnsPubsubDatastore', symbolName: '@js-ipfs/ipns/IpnsPubsubDatastore' })

'''
'''--- src/core/ipns/routing/utils.js ---
'use strict'

const multibase = require('multibase')
const ipns = require('ipns')

module.exports = {
  encodeBase32: (buf) => {
    const m = multibase.encode('base32', buf).slice(1) // slice off multibase codec

    return m.toString().toUpperCase() // should be uppercase for interop with go
  },
  validator: {
    func: (key, record, cb) => ipns.validator.validate(record, key, cb)
  },
  selector: (k, records) => ipns.validator.select(records[0], records[1])
}

'''
'''--- src/core/mfs-preload.js ---
'use strict'

const debug = require('debug')

const log = debug('jsipfs:mfs-preload')
log.error = debug('jsipfs:mfs-preload:error')

module.exports = (self) => {
  const options = self._options.preload || {}
  options.interval = options.interval || 30 * 1000

  if (!options.enabled) {
    log('MFS preload disabled')
    return {
      start: (cb) => setImmediate(cb),
      stop: (cb) => setImmediate(cb)
    }
  }

  let rootCid
  let timeoutId

  const preloadMfs = () => {
    self.files.stat('/', (err, stats) => {
      if (err) {
        timeoutId = setTimeout(preloadMfs, options.interval)
        return log.error('failed to stat MFS root for preload', err)
      }

      if (rootCid !== stats.hash) {
        log(`preloading updated MFS root ${rootCid} -> ${stats.hash}`)

        return self._preload(stats.hash, (err) => {
          timeoutId = setTimeout(preloadMfs, options.interval)
          if (err) return log.error(`failed to preload MFS root ${stats.hash}`, err)
          rootCid = stats.hash
        })
      }

      timeoutId = setTimeout(preloadMfs, options.interval)
    })
  }

  return {
    start (cb) {
      self.files.stat('/', (err, stats) => {
        if (err) return cb(err)
        rootCid = stats.hash
        log(`monitoring MFS root ${rootCid}`)
        timeoutId = setTimeout(preloadMfs, options.interval)
        cb()
      })
    },
    stop (cb) {
      clearTimeout(timeoutId)
      cb()
    }
  }
}

'''
'''--- src/core/preload.js ---
'use strict'

const setImmediate = require('async/setImmediate')
const retry = require('async/retry')
const toUri = require('multiaddr-to-uri')
const debug = require('debug')
const CID = require('cids')
const preload = require('./runtime/preload-nodejs')

const log = debug('jsipfs:preload')
log.error = debug('jsipfs:preload:error')

const noop = (err) => { if (err) log.error(err) }

module.exports = self => {
  const options = self._options.preload || {}
  options.enabled = Boolean(options.enabled)
  options.addresses = options.addresses || []

  if (!options.enabled || !options.addresses.length) {
    const api = (_, callback) => {
      if (callback) {
        setImmediate(() => callback())
      }
    }
    api.start = () => {}
    api.stop = () => {}
    return api
  }

  let stopped = true
  let requests = []
  const apiUris = options.addresses.map(apiAddrToUri)

  const api = (cid, callback) => {
    callback = callback || noop

    if (typeof cid !== 'string') {
      try {
        cid = new CID(cid).toBaseEncodedString()
      } catch (err) {
        return setImmediate(() => callback(err))
      }
    }

    const fallbackApiUris = Array.from(apiUris)
    let request
    const now = Date.now()

    retry({ times: fallbackApiUris.length }, (cb) => {
      if (stopped) return cb(new Error(`preload aborted for ${cid}`))

      // Remove failed request from a previous attempt
      requests = requests.filter(r => r !== request)

      const apiUri = fallbackApiUris.shift()

      request = preload(`${apiUri}/api/v0/refs?r=true&arg=${cid}`, cb)
      requests = requests.concat(request)
    }, (err) => {
      requests = requests.filter(r => r !== request)

      if (err) {
        return callback(err)
      }

      log(`preloaded ${cid} in ${Date.now() - now}ms`)
      callback()
    })
  }

  api.start = () => {
    stopped = false
  }

  api.stop = () => {
    stopped = true
    log(`canceling ${requests.length} pending preload request(s)`)
    requests.forEach(r => r.cancel())
    requests = []
  }

  return api
}

function apiAddrToUri (addr) {
  if (!(addr.endsWith('http') || addr.endsWith('https'))) {
    addr = addr + '/http'
  }
  return toUri(addr)
}

'''
'''--- src/core/runtime/add-from-fs-browser.js ---
'use strict'

const promisify = require('promisify-es6')

module.exports = self => {
  return promisify((...args) => {
    const callback = args.pop()
    callback(new Error('not available in the browser'))
  })
}

'''
'''--- src/core/runtime/add-from-fs-nodejs.js ---
'use strict'

const promisify = require('promisify-es6')
const pull = require('pull-stream')
const globSource = require('../../utils/files/glob-source')

module.exports = self => {
  return promisify((...args) => {
    const callback = args.pop()
    const options = typeof args[args.length - 1] === 'string' ? {} : args.pop()
    const paths = args

    pull(
      globSource(...paths, options),
      self.addPullStream(options),
      pull.collect(callback)
    )
  })
}

'''
'''--- src/core/runtime/config-browser.js ---
'use strict'

module.exports = () => ({
  Addresses: {
    Swarm: [
    ],
    API: '',
    Gateway: ''
  },
  Discovery: {
    MDNS: {
      Enabled: false,
      Interval: 10
    },
    webRTCStar: {
      Enabled: true
    }
  },
  Bootstrap: [
    '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/dns4/sfo-3.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/dns4/sgp-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6'
  ]
})

'''
'''--- src/core/runtime/config-nodejs.js ---
'use strict'

module.exports = () => ({
  Addresses: {
    Swarm: [
      '/ip4/0.0.0.0/tcp/4002',
      '/ip4/127.0.0.1/tcp/4003/ws'
    ],
    API: '/ip4/127.0.0.1/tcp/5002',
    Gateway: '/ip4/127.0.0.1/tcp/9090'
  },
  Discovery: {
    MDNS: {
      Enabled: true,
      Interval: 10
    },
    webRTCStar: {
      Enabled: true
    }
  },
  Bootstrap: [
    '/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
    '/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6'
  ]
})

'''
'''--- src/core/runtime/dns-browser.js ---
/* global self */
'use strict'

module.exports = (domain, opts, callback) => {
  if (typeof opts === 'function') {
    callback = opts
    opts = {}
  }

  opts = opts || {}

  domain = encodeURIComponent(domain)
  let url = `https://ipfs.io/api/v0/dns?arg=${domain}`

  Object.keys(opts).forEach(prop => {
    url += `&${encodeURIComponent(prop)}=${encodeURIComponent(opts[prop])}`
  })

  self.fetch(url, { mode: 'cors' })
    .then((response) => {
      return response.json()
    })
    .then((response) => {
      if (response.Path) {
        return callback(null, response.Path)
      } else {
        return callback(new Error(response.Message))
      }
    })
    .catch((error) => {
      callback(error)
    })
}

'''
'''--- src/core/runtime/dns-nodejs.js ---
'use strict'

const dns = require('dns')
const _ = require('lodash')
const errcode = require('err-code')

module.exports = (domain, opts, callback) => {
  resolveDnslink(domain)
    .catch(err => {
      // If the code is not ENOTFOUND or ERR_DNSLINK_NOT_FOUND then throw the error
      if (err.code !== 'ENOTFOUND' && err.code !== 'ERR_DNSLINK_NOT_FOUND') throw err

      if (domain.startsWith('_dnslink.')) {
        // The supplied domain contains a _dnslink component
        // Check the non-_dnslink domain
        const rootDomain = domain.replace('_dnslink.', '')
        return resolveDnslink(rootDomain)
      }
      // Check the _dnslink subdomain
      const _dnslinkDomain = `_dnslink.${domain}`
      // If this throws then we propagate the error
      return resolveDnslink(_dnslinkDomain)
    })
    .then(dnslinkRecord => {
      callback(null, dnslinkRecord.replace('dnslink=', ''))
    })
    .catch(callback)
}

function resolveDnslink (domain) {
  const DNSLINK_REGEX = /^dnslink=.+$/
  return new Promise((resolve, reject) => {
    dns.resolveTxt(domain, (err, records) => {
      if (err) return reject(err)
      resolve(records)
    })
  })
    .then(records => {
      return _.chain(records).flatten().filter(record => {
        return DNSLINK_REGEX.test(record)
      }).value()
    })
    .then(dnslinkRecords => {
      // we now have dns text entries as an array of strings
      // only records passing the DNSLINK_REGEX text are included
      if (dnslinkRecords.length === 0) {
        throw errcode(`No dnslink records found for domain: ${domain}`, 'ERR_DNSLINK_NOT_FOUND')
      }
      return dnslinkRecords[0]
    })
}

'''
'''--- src/core/runtime/fetch-browser.js ---
/* eslint-env browser */
'use strict'
module.exports = fetch

'''
'''--- src/core/runtime/fetch-nodejs.js ---
'use strict'
module.exports = require('node-fetch')

'''
'''--- src/core/runtime/libp2p-browser.js ---
'use strict'

const WS = require('libp2p-websockets')
const WebRTCStar = require('libp2p-webrtc-star')
const WebSocketStarMulti = require('libp2p-websocket-star-multi')
const Multiplex = require('libp2p-mplex')
const SECIO = require('libp2p-secio')
const Bootstrap = require('libp2p-bootstrap')
const KadDHT = require('libp2p-kad-dht')
const libp2p = require('libp2p')
const defaultsDeep = require('@nodeutils/defaults-deep')
const multiaddr = require('multiaddr')

class Node extends libp2p {
  constructor (_options) {
    const wrtcstar = new WebRTCStar({ id: _options.peerInfo.id })

    // this can be replaced once optional listening is supported with the below code. ref: https://github.com/libp2p/interface-transport/issues/41
    // const wsstar = new WebSocketStar({ id: _options.peerInfo.id })
    const wsstarServers = _options.peerInfo.multiaddrs.toArray().map(String).filter(addr => addr.includes('p2p-websocket-star'))
    _options.peerInfo.multiaddrs.replace(wsstarServers.map(multiaddr), '/p2p-websocket-star') // the ws-star-multi module will replace this with the chosen ws-star servers
    const wsstar = new WebSocketStarMulti({ servers: wsstarServers, id: _options.peerInfo.id, ignore_no_online: !wsstarServers.length || _options.wsStarIgnoreErrors })

    const defaults = {
      modules: {
        transport: [
          WS,
          wrtcstar,
          wsstar
        ],
        streamMuxer: [
          Multiplex
        ],
        connEncryption: [
          SECIO
        ],
        peerDiscovery: [
          wrtcstar.discovery,
          wsstar.discovery,
          Bootstrap
        ],
        dht: KadDHT
      },
      config: {
        peerDiscovery: {
          bootstrap: {
            enabled: true
          },
          webRTCStar: {
            enabled: true
          },
          websocketStar: {
            enabled: true
          }
        },
        dht: {
          enabled: false
        },
        EXPERIMENTAL: {
          pubsub: false
        }
      }
    }

    super(defaultsDeep(_options, defaults))
  }
}

module.exports = Node

'''
'''--- src/core/runtime/libp2p-nodejs.js ---
'use strict'

const TCP = require('libp2p-tcp')
const MulticastDNS = require('libp2p-mdns')
const WS = require('libp2p-websockets')
const WebSocketStarMulti = require('libp2p-websocket-star-multi')
const Bootstrap = require('libp2p-bootstrap')
const KadDHT = require('libp2p-kad-dht')
const Multiplex = require('libp2p-mplex')
const SECIO = require('libp2p-secio')
const libp2p = require('libp2p')
const defaultsDeep = require('@nodeutils/defaults-deep')
const multiaddr = require('multiaddr')

class Node extends libp2p {
  constructor (_options) {
    // this can be replaced once optional listening is supported with the below code. ref: https://github.com/libp2p/interface-transport/issues/41
    // const wsstar = new WebSocketStar({ id: _options.peerInfo.id })
    const wsstarServers = _options.peerInfo.multiaddrs.toArray().map(String).filter(addr => addr.includes('p2p-websocket-star'))
    _options.peerInfo.multiaddrs.replace(wsstarServers.map(multiaddr), '/p2p-websocket-star') // the ws-star-multi module will replace this with the chosen ws-star servers
    const wsstar = new WebSocketStarMulti({ servers: wsstarServers, id: _options.peerInfo.id, ignore_no_online: !wsstarServers.length || _options.wsStarIgnoreErrors })

    const defaults = {
      modules: {
        transport: [
          TCP,
          WS,
          wsstar
        ],
        streamMuxer: [
          Multiplex
        ],
        connEncryption: [
          SECIO
        ],
        peerDiscovery: [
          MulticastDNS,
          Bootstrap,
          wsstar.discovery
        ],
        dht: KadDHT
      },
      config: {
        peerDiscovery: {
          mdns: {
            enabled: true
          },
          bootstrap: {
            enabled: true
          },
          websocketStar: {
            enabled: true
          }
        },
        dht: {
          kBucketSize: 20,
          enabled: true,
          randomWalk: {
            enabled: true
          }
        },
        EXPERIMENTAL: {
          pubsub: false
        }
      }
    }

    super(defaultsDeep(_options, defaults))
  }
}

module.exports = Node

'''
'''--- src/core/runtime/preload-browser.js ---
/* eslint-env browser */
'use strict'

const debug = require('debug')

const log = debug('jsipfs:preload')
log.error = debug('jsipfs:preload:error')

module.exports = function preload (url, callback) {
  log(url)

  const controller = new AbortController()
  const signal = controller.signal

  fetch(url, { signal })
    .then(res => {
      if (!res.ok) {
        log.error('failed to preload', url, res.status, res.statusText)
        throw new Error(`failed to preload ${url}`)
      }
      return res.text()
    })
    .then(() => callback())
    .catch(callback)

  return {
    cancel: () => controller.abort()
  }
}

'''
'''--- src/core/runtime/preload-nodejs.js ---
'use strict'

const http = require('http')
const https = require('https')
const { URL } = require('url')
const debug = require('debug')
const setImmediate = require('async/setImmediate')

const log = debug('jsipfs:preload')
log.error = debug('jsipfs:preload:error')

module.exports = function preload (url, callback) {
  log(url)

  try {
    url = new URL(url)
  } catch (err) {
    return setImmediate(() => callback(err))
  }

  const transport = url.protocol === 'https:' ? https : http

  const req = transport.get({
    hostname: url.hostname,
    port: url.port,
    path: url.pathname + url.search
  }, (res) => {
    if (res.statusCode < 200 || res.statusCode >= 300) {
      res.resume()
      log.error('failed to preload', url.href, res.statusCode, res.statusMessage)
      return callback(new Error(`failed to preload ${url}`))
    }

    res.on('data', chunk => log(`data ${chunk}`))

    res.on('abort', () => {
      callback(new Error('request aborted'))
    })

    res.on('error', err => {
      log.error('response error preloading', url.href, err)
      callback(err)
    })

    res.on('end', () => {
      // If aborted, callback is called in the abort handler
      if (!res.aborted) callback()
    })
  })

  req.on('error', err => {
    log.error('request error preloading', url.href, err)
    callback(err)
  })

  return {
    cancel: () => {
      // No need to call callback here
      // before repsonse - called in req error handler
      // after response - called in res abort hander
      req.abort()
    }
  }
}

'''
'''--- src/core/runtime/repo-browser.js ---
'use strict'

const IPFSRepo = require('ipfs-repo')

module.exports = (dir) => {
  const repoPath = dir || 'ipfs'
  return new IPFSRepo(repoPath)
}

'''
'''--- src/core/runtime/repo-nodejs.js ---
'use strict'

const os = require('os')
const IPFSRepo = require('ipfs-repo')
const path = require('path')

module.exports = (dir) => {
  const repoPath = dir || path.join(os.homedir(), '.jsipfs')

  return new IPFSRepo(repoPath)
}

'''
'''--- src/core/state.js ---
'use strict'

const debug = require('debug')
const log = debug('jsipfs:state')
log.error = debug('jsipfs:state:error')

const fsm = require('fsm-event')

module.exports = (self) => {
  const s = fsm('uninitialized', {
    uninitialized: {
      init: 'initializing',
      initialized: 'stopped'
    },
    initializing: {
      initialized: 'stopped'
    },
    stopped: {
      start: 'starting'
    },
    starting: {
      started: 'running'
    },
    running: {
      stop: 'stopping'
    },
    stopping: {
      stopped: 'stopped'
    }
  })

  // log events
  s.on('error', (err) => log.error(err))
  s.on('done', () => log('-> ' + s._state))

  // -- Actions

  s.init = () => {
    s('init')
  }

  s.initialized = () => {
    s('initialized')
  }

  s.stop = () => {
    s('stop')
  }

  s.stopped = () => {
    s('stopped')
  }

  s.start = () => {
    s('start')
  }

  s.started = () => {
    s('started')
  }

  s.state = () => s._state

  return s
}

'''
'''--- src/core/utils.js ---
'use strict'

const promisify = require('promisify-es6')
const map = require('async/map')
const isIpfs = require('is-ipfs')
const CID = require('cids')

const ERR_BAD_PATH = 'ERR_BAD_PATH'
exports.OFFLINE_ERROR = 'This command must be run in online mode. Try running \'ipfs daemon\' first.'

/**
 * Break an ipfs-path down into it's hash and an array of links.
 *
 * examples:
 *  b58Hash -> { hash: 'b58Hash', links: [] }
 *  b58Hash/mercury/venus -> { hash: 'b58Hash', links: ['mercury', 'venus']}
 *  /ipfs/b58Hash/links/by/name -> { hash: 'b58Hash', links: ['links', 'by', 'name'] }
 *
 * @param  {String} ipfsPath An ipfs-path
 * @return {Object}            { hash: base58 string, links: [string], ?err: Error }
 * @throws on an invalid @param ipfsPath
 */
function parseIpfsPath (ipfsPath) {
  const invalidPathErr = new Error('invalid ipfs ref path')
  ipfsPath = ipfsPath.replace(/^\/ipfs\//, '')
  const matched = ipfsPath.match(/([^/]+(?:\/[^/]+)*)\/?$/)
  if (!matched) {
    throw invalidPathErr
  }

  const [hash, ...links] = matched[1].split('/')

  // check that a CID can be constructed with the hash
  if (isIpfs.cid(hash)) {
    return { hash, links }
  } else {
    throw invalidPathErr
  }
}

/**
 * Returns a well-formed ipfs Path.
 * The returned path will always be prefixed with /ipfs/ or /ipns/.
 * If the received string is not a valid ipfs path, an error will be returned
 * examples:
 *  b58Hash -> { hash: 'b58Hash', links: [] }
 *  b58Hash/mercury/venus -> { hash: 'b58Hash', links: ['mercury', 'venus']}
 *  /ipfs/b58Hash/links/by/name -> { hash: 'b58Hash', links: ['links', 'by', 'name'] }
 *
 * @param  {String} pathStr An ipfs-path, or ipns-path or a cid
 * @return {String} ipfs-path or ipns-path
 * @throws on an invalid @param ipfsPath
 */
const normalizePath = (pathStr) => {
  if (isIpfs.cid(pathStr)) {
    return `/ipfs/${pathStr}`
  } else if (isIpfs.path(pathStr)) {
    return pathStr
  } else {
    throw Object.assign(new Error(`invalid ${pathStr} path`), { code: ERR_BAD_PATH })
  }
}

/**
 * Resolve various styles of an ipfs-path to the hash of the target node.
 * Follows links in the path.
 *
 * Accepts formats:
 *  - <base58 string>
 *  - <base58 string>/link/to/venus
 *  - /ipfs/<base58 string>/link/to/pluto
 *  - multihash Buffer
 *  - Arrays of the above
 *
 * @param  {IPFS}               objectAPI The IPFS object api
 * @param  {Described above}    ipfsPaths A single or collection of ipfs-paths
 * @param  {Function<err, res>} callback res is Array<Buffer(hash)>
 *                              if no callback is passed, returns a Promise
 * @return {Promise|void}
 */
const resolvePath = promisify(function (objectAPI, ipfsPaths, callback) {
  if (!Array.isArray(ipfsPaths)) {
    ipfsPaths = [ipfsPaths]
  }

  map(ipfsPaths, (path, cb) => {
    if (typeof path !== 'string') {
      let cid

      try {
        cid = new CID(path)
      } catch (err) {
        return cb(err)
      }

      return cb(null, cid.buffer)
    }

    let parsedPath
    try {
      parsedPath = exports.parseIpfsPath(path)
    } catch (err) {
      return cb(err)
    }

    const rootHash = new CID(parsedPath.hash)
    const rootLinks = parsedPath.links

    if (!rootLinks.length) {
      return cb(null, rootHash.buffer)
    }

    objectAPI.get(rootHash, follow.bind(null, rootHash, rootLinks))

    // recursively follow named links to the target node
    function follow (cid, links, err, obj) {
      if (err) {
        return cb(err)
      }

      if (!links.length) {
        // done tracing, obj is the target node
        return cb(null, cid.buffer)
      }

      const linkName = links[0]
      const nextObj = obj.links.find(link => link.name === linkName)
      if (!nextObj) {
        return cb(new Error(
          `no link named "${linkName}" under ${cid.toBaseEncodedString()}`
        ))
      }

      objectAPI.get(nextObj.cid, follow.bind(null, nextObj.cid, links.slice(1)))
    }
  }, callback)
})

exports.normalizePath = normalizePath
exports.parseIpfsPath = parseIpfsPath
exports.resolvePath = resolvePath

'''
'''--- src/http/api/resources/bitswap.js ---
'use strict'

const Joi = require('joi')
const multibase = require('multibase')
const { cidToString } = require('../../../utils/cid')
const { parseKey } = require('./block')

exports.wantlist = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  async handler (request, h) {
    const { ipfs } = request.server.app
    const peerId = request.query.peer
    const cidBase = request.query['cid-base']

    const list = await ipfs.bitswap.wantlist(peerId)

    return h.response({
      Keys: list.Keys.map(k => ({
        '/': cidToString(k['/'], { base: cidBase, upgrade: false })
      }))
    })
  }
}

exports.stat = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  async handler (request, h) {
    const { ipfs } = request.server.app
    const cidBase = request.query['cid-base']

    const stats = await ipfs.bitswap.stat()

    stats.wantlist = stats.wantlist.map(k => ({
      '/': cidToString(k['/'], { base: cidBase, upgrade: false })
    }))

    return h.response({
      ProvideBufLen: stats.provideBufLen,
      BlocksReceived: stats.blocksReceived,
      Wantlist: stats.wantlist,
      Peers: stats.peers,
      DupBlksReceived: stats.dupBlksReceived,
      DupDataReceived: stats.dupDataReceived,
      DataReceived: stats.dataReceived,
      BlocksSent: stats.blocksSent,
      DataSent: stats.dataSent
    })
  }
}

exports.unwant = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that assigns a `key` to request.pre.args
  parseArgs: parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const key = request.pre.args.key
    const { ipfs } = request.server.app
    await ipfs.bitswap.unwant(key)
    return h.response({ key: cidToString(key, { base: request.query['cid-base'], upgrade: false }) })
  }
}

'''
'''--- src/http/api/resources/block.js ---
'use strict'

const CID = require('cids')
const multipart = require('ipfs-multipart')
const Joi = require('joi')
const multibase = require('multibase')
const Boom = require('boom')
const { cidToString } = require('../../../utils/cid')
const debug = require('debug')
const log = debug('jsipfs:http-api:block')
log.error = debug('jsipfs:http-api:block:error')

// common pre request handler that parses the args and returns `key` which is assigned to `request.pre.args`
exports.parseKey = (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest("Argument 'key' is required")
  }

  try {
    return { key: new CID(request.query.arg) }
  } catch (err) {
    log.error(err)
    throw Boom.badRequest('Not a valid hash')
  }
}

exports.get = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const key = request.pre.args.key

    let block
    try {
      block = await request.server.app.ipfs.block.get(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get block' })
    }

    if (!block) {
      throw Boom.notFound('Block was unwanted before it could be remotely retrieved')
    }

    return h.response(block.data).header('X-Stream-Output', '1')
  }
}

exports.put = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // pre request handler that parses the args and returns `data` which is assigned to `request.pre.args`
  parseArgs: (request, h) => {
    if (!request.payload) {
      throw Boom.badRequest("File argument 'data' is required")
    }

    return new Promise((resolve, reject) => {
      const parser = multipart.reqParser(request.payload)
      let file

      parser.on('file', (fileName, fileStream) => {
        file = Buffer.alloc(0)

        fileStream.on('data', (data) => {
          file = Buffer.concat([file, data])
        })
      })

      parser.on('end', () => {
        if (!file) {
          return reject(Boom.badRequest("File argument 'data' is required"))
        }

        resolve({ data: file })
      })
    })
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { data } = request.pre.args
    const { ipfs } = request.server.app

    let block
    try {
      block = await ipfs.block.put(data, {
        mhtype: request.query.mhtype,
        format: request.query.format,
        version: request.query.version && parseInt(request.query.version)
      })
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to put block' })
    }

    return h.response({
      Key: cidToString(block.cid, { base: request.query['cid-base'] }),
      Size: block.data.length
    })
  }
}

exports.rm = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { key } = request.pre.args

    try {
      await request.server.app.ipfs.block.rm(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to delete block' })
    }

    return h.response()
  }
}

exports.stat = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { key } = request.pre.args

    let stats
    try {
      stats = await request.server.app.ipfs.block.stat(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get block stats' })
    }

    return h.response({
      Key: cidToString(stats.key, { base: request.query['cid-base'] }),
      Size: stats.size
    })
  }
}

'''
'''--- src/http/api/resources/bootstrap.js ---
'use strict'

const multiaddr = require('multiaddr')
const Boom = require('boom')

exports.list = async (request, h) => {
  const { ipfs } = request.server.app
  const list = await ipfs.bootstrap.list()
  return h.response(list)
}

exports.add = {
  parseArgs (request, h) {
    const q = request.query
    const def = q.default === 'true'

    if (q.arg != null) {
      try {
        return {
          addr: multiaddr(q.arg),
          default: def
        }
      } catch (err) {
        throw Boom.badRequest('Not a valid multiaddr')
      }
    }

    console.log('parseArgs', { default: def })

    return { default: def }
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { addr, default: def } = request.pre.args
    const list = await ipfs.bootstrap.add(addr && addr.toString(), { default: def })
    return h.response(list)
  }
}

exports.addDefault = async (request, h) => {
  const { ipfs } = request.server.app
  const list = await ipfs.bootstrap.add(null, { default: true })
  return h.response(list)
}

exports.rm = {
  parseArgs (request, h) {
    const q = request.query
    const all = q.all === 'true'

    if (q.arg != null) {
      try {
        return {
          addr: multiaddr(q.arg),
          all: all
        }
      } catch (err) {
        throw Boom.badRequest('Not a valid multiaddr')
      }
    }

    return { all }
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { addr, all } = request.pre.args
    const list = await ipfs.bootstrap.rm(addr && addr.toString(), { all })
    return h.response(list)
  }
}

exports.rmAll = async (request, h) => {
  const { ipfs } = request.server.app
  const list = await ipfs.bootstrap.rm(null, { all: true })
  return h.response(list)
}

'''
'''--- src/http/api/resources/config.js ---
'use strict'

const debug = require('debug')
const get = require('lodash/get')
const set = require('lodash/set')
const log = debug('jsipfs:http-api:config')
log.error = debug('jsipfs:http-api:config:error')
const multipart = require('ipfs-multipart')
const Boom = require('boom')

exports.getOrSet = {
  // pre request handler that parses the args and returns `key` & `value` which are assigned to `request.pre.args`
  parseArgs (request, h) {
    const parseValue = (args) => {
      if (request.query.bool !== undefined) {
        args.value = args.value === 'true'
      } else if (request.query.json !== undefined) {
        try {
          args.value = JSON.parse(args.value)
        } catch (err) {
          log.error(err)
          throw Boom.badRequest('failed to unmarshal json. ' + err)
        }
      }

      return args
    }

    if (request.query.arg instanceof Array) {
      return parseValue({
        key: request.query.arg[0],
        value: request.query.arg[1]
      })
    }

    if (request.params.key) {
      return parseValue({
        key: request.params.key,
        value: request.query.arg
      })
    }

    if (!request.query.arg) {
      throw Boom.badRequest("Argument 'key' is required")
    }

    return { key: request.query.arg }
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args
    let { value } = request.pre.args

    // check that value exists - typeof null === 'object'
    if (value && (typeof value === 'object' &&
        value.type === 'Buffer')) {
      throw Boom.badRequest('Invalid value type')
    }

    let originalConfig
    try {
      originalConfig = await ipfs.config.get()
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get config value' })
    }

    if (value === undefined) {
      // Get the value of a given key
      value = get(originalConfig, key)
      if (value === undefined) {
        throw Boom.notFound('Failed to get config value: key has no attributes')
      }
    } else {
      // Set the new value of a given key
      const updatedConfig = set(originalConfig, key, value)
      try {
        await ipfs.config.replace(updatedConfig)
      } catch (err) {
        throw Boom.boomify(err, { message: 'Failed to get config value' })
      }
    }

    return h.response({
      Key: key,
      Value: value
    })
  }
}

exports.get = async (request, h) => {
  const { ipfs } = request.server.app

  let config
  try {
    config = await ipfs.config.get()
  } catch (err) {
    throw Boom.boomify(err, { message: 'Failed to get config value' })
  }

  return h.response({
    Value: config
  })
}

exports.show = async (request, h) => {
  const { ipfs } = request.server.app

  let config
  try {
    config = await ipfs.config.get()
  } catch (err) {
    throw Boom.boomify(err, { message: 'Failed to get config value' })
  }

  return h.response(config)
}

exports.replace = {
  // pre request handler that parses the args and returns `config` which is assigned to `request.pre.args`
  async parseArgs (request, h) {
    if (!request.payload) {
      throw Boom.badRequest("Argument 'file' is required")
    }

    const fileStream = await new Promise((resolve, reject) => {
      multipart.reqParser(request.payload)
        .on('file', (fileName, fileStream) => resolve(fileStream))
        .on('end', () => reject(Boom.badRequest("Argument 'file' is required")))
    })

    const file = await new Promise((resolve, reject) => {
      fileStream
        .on('data', data => resolve(data))
        .on('end', () => reject(Boom.badRequest("Argument 'file' is required")))
    })

    try {
      return { config: JSON.parse(file.toString()) }
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to decode file as config' })
    }
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { config } = request.pre.args

    try {
      await ipfs.config.replace(config)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to save config' })
    }

    return h.response()
  }
}

'''
'''--- src/http/api/resources/dht.js ---
'use strict'

const Joi = require('joi')
const Boom = require('boom')

const CID = require('cids')

const debug = require('debug')
const log = debug('jsipfs:http-api:dht')
log.error = debug('jsipfs:http-api:dht:error')

exports = module.exports

exports.findPeer = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required()
    }).unknown()
  },
  async handler (request, h) {
    const ipfs = request.server.app.ipfs
    const { arg } = request.query
    let res

    try {
      res = await ipfs.dht.findPeer(arg)
    } catch (err) {
      if (err.code === 'ERR_LOOKUP_FAILED') {
        throw Boom.notFound(err.toString())
      } else {
        throw Boom.boomify(err, { message: err.toString() })
      }
    }

    return h.response({
      Responses: [{
        ID: res.id.toB58String(),
        Addrs: res.multiaddrs.toArray().map((a) => a.toString())
      }],
      Type: 2
    })
  }
}

exports.findProvs = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required(),
      'num-providers': Joi.number().integer().default(20),
      timeout: Joi.number()
    }).unknown()
  },
  async handler (request, h) {
    const ipfs = request.server.app.ipfs
    const { arg } = request.query

    request.query.maxNumProviders = request.query['num-providers']

    const res = await ipfs.dht.findProvs(arg, request.query)

    return h.response({
      Responses: res.map((peerInfo) => ({
        ID: peerInfo.id.toB58String(),
        Addrs: peerInfo.multiaddrs.toArray().map((a) => a.toString())
      })),
      Type: 4
    })
  }
}

exports.get = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required(),
      timeout: Joi.number()
    }).unknown()
  },
  async handler (request, h) {
    const ipfs = request.server.app.ipfs
    const { arg } = request.query

    const res = await ipfs.dht.get(Buffer.from(arg))

    return h.response({
      Extra: res.toString(),
      Type: 5
    })
  }
}

exports.provide = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required()
    }).unknown()
  },
  async handler (request, h) {
    const ipfs = request.server.app.ipfs
    const { arg } = request.query
    let cid

    try {
      cid = new CID(arg)
    } catch (err) {
      log.error(err)
      throw Boom.boomify(err, { message: err.toString() })
    }

    await ipfs.dht.provide(cid)

    return h.response()
  }
}

exports.put = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.array().items(Joi.string()).length(2).required()
    }).unknown()
  },
  parseArgs: (request, h) => {
    return {
      key: request.query.arg[0],
      value: request.query.arg[1]
    }
  },
  async handler (request, h) {
    const key = request.pre.args.key
    const value = request.pre.args.value
    const ipfs = request.server.app.ipfs

    await ipfs.dht.put(Buffer.from(key), Buffer.from(value))

    return h.response()
  }
}

exports.query = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required()
    }).unknown()
  },
  async handler (request, h) {
    const ipfs = request.server.app.ipfs
    const { arg } = request.query

    const res = await ipfs.dht.query(arg)
    const response = res.map((peerInfo) => ({
      ID: peerInfo.id.toB58String()
    }))

    return h.response(response)
  }
}

'''
'''--- src/http/api/resources/dns.js ---
'use strict'

const Boom = require('boom')

module.exports = async (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest("Argument 'domain' is required")
  }

  const path = await request.server.app.ipfs.dns(request.query.arg)
  return h.response({
    Path: path
  })
}

'''
'''--- src/http/api/resources/file.js ---
'use strict'

const isIpfs = require('is-ipfs')
const unixfsEngine = require('ipfs-unixfs-engine')
const exporter = unixfsEngine.exporter
const pull = require('pull-stream')
const toB58String = require('multihashes').toB58String
const Boom = require('boom')

const fileTypeMap = {
  file: 'File',
  dir: 'Directory'
}

function toFileObject (file) {
  const fo = {
    Hash: toB58String(file.hash),
    Size: file.size,
    Type: fileTypeMap[file.type] || file.type
  }
  if (fo.Hash !== file.name) {
    fo.Name = file.name
  }
  return fo
}

// common pre request handler that parses the args and returns `key` which is assigned to `request.pre.args`
exports.parseKey = (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest("Argument 'key' is required")
  }

  let key = request.query.arg
  if (key.indexOf('/ipfs/') === 0) {
    key = key.substring(6)
  }

  let hash = key
  const slashIndex = hash.indexOf('/')
  if (slashIndex > 0) {
    hash = hash.substring(0, slashIndex)
  }

  if (!isIpfs.ipfsPath(request.query.arg) && !isIpfs.cid(request.query.arg)) {
    throw Boom.badRequest('invalid ipfs ref path')
  }

  const subpaths = key.split('/')
  subpaths.shift()
  return {
    path: request.query.arg,
    subpaths: subpaths,
    key: key,
    hash: hash
  }
}

exports.ls = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { path, subpaths } = request.pre.args.path
    const rootDepth = subpaths.length

    const files = await new Promise((resolve, reject) => {
      pull(
        exporter(path, ipfs._ipld, { maxDepth: rootDepth + 1 }),
        pull.collect((err, files) => {
          if (err) return reject(err)
          resolve(files)
        })
      )
    })

    const res = {
      Arguments: {},
      Objects: {}
    }
    const links = []
    files.forEach((file) => {
      if (file.depth === rootDepth) {
        const id = toB58String(file.hash)
        res.Arguments[path] = id
        res.Objects[id] = toFileObject(file)
        res.Objects[id].Links = file.type === 'file' ? null : links
      } else {
        links.push(toFileObject(file))
      }
    })

    return h.response(res)
  }
}

'''
'''--- src/http/api/resources/files-regular.js ---
'use strict'

const multipart = require('ipfs-multipart')
const debug = require('debug')
const tar = require('tar-stream')
const log = debug('jsipfs:http-api:files')
log.error = debug('jsipfs:http-api:files:error')
const pull = require('pull-stream')
const toPull = require('stream-to-pull-stream')
const pushable = require('pull-pushable')
const toStream = require('pull-stream-to-stream')
const abortable = require('pull-abortable')
const Joi = require('joi')
const Boom = require('boom')
const ndjson = require('pull-ndjson')
const { PassThrough } = require('readable-stream')
const multibase = require('multibase')
const isIpfs = require('is-ipfs')
const promisify = require('promisify-es6')
const { cidToString } = require('../../../utils/cid')

function numberFromQuery (query, key) {
  if (query && query[key] !== undefined) {
    const value = parseInt(query[key], 10)

    if (isNaN(value)) {
      return undefined
    }

    return value
  }
}

// common pre request handler that parses the args and returns `key` which is assigned to `request.pre.args`
exports.parseKey = (request, h) => {
  const { arg } = request.query

  if (!arg) {
    throw Boom.badRequest("Argument 'key' is required")
  }

  if (!isIpfs.ipfsPath(arg) && !isIpfs.cid(arg) && !isIpfs.ipfsPath('/ipfs/' + arg)) {
    throw Boom.badRequest('invalid ipfs ref path')
  }

  return {
    key: arg,
    options: {
      offset: numberFromQuery(request.query, 'offset'),
      length: numberFromQuery(request.query, 'length')
    }
  }
}

exports.cat = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key, options } = request.pre.args

    const stream = await new Promise((resolve, reject) => {
      let pusher
      let started = false

      pull(
        ipfs.catPullStream(key, options),
        pull.drain(
          chunk => {
            if (!started) {
              started = true
              pusher = pushable()
              resolve(toStream.source(pusher).pipe(new PassThrough()))
            }
            pusher.push(chunk)
          },
          err => {
            if (err) {
              log.error(err)

              // We already started flowing, abort the stream
              if (started) {
                return pusher.end(err)
              }

              err.message = err.message === 'No such file'
                ? err.message
                : 'Failed to cat file: ' + err

              return reject(err)
            }

            pusher.end()
          }
        )
      )
    })

    return h.response(stream).header('X-Stream-Output', '1')
  }
}

exports.get = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args
    const pack = tar.pack()

    let filesArray
    try {
      filesArray = await ipfs.get(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get key' })
    }

    pack.entry = promisify(pack.entry.bind(pack))

    Promise
      .all(filesArray.map(file => {
        const header = { name: file.path }

        if (file.content) {
          header.size = file.size
          return pack.entry(header, file.content)
        } else {
          header.type = 'directory'
          return pack.entry(header)
        }
      }))
      .then(() => pack.finalize())
      .catch(err => {
        log.error(err)
        pack.emit('error', err)
        pack.destroy()
      })

    // reply must be called right away so that tar-stream offloads its content
    // otherwise it will block in large files
    return h.response(pack).header('X-Stream-Output', '1')
  }
}

exports.add = {
  validate: {
    query: Joi.object()
      .keys({
        'cid-version': Joi.number().integer().min(0).max(1).default(0),
        'cid-base': Joi.string().valid(multibase.names),
        'raw-leaves': Joi.boolean(),
        'only-hash': Joi.boolean(),
        pin: Joi.boolean().default(true),
        'wrap-with-directory': Joi.boolean(),
        chunker: Joi.string()
      })
      // TODO: Necessary until validate "recursive", "stream-channels" etc.
      .options({ allowUnknown: true })
  },

  async handler (request, h) {
    if (!request.payload) {
      throw Boom.badRequest('Array, Buffer, or String is required.')
    }

    const { ipfs } = request.server.app

    const fileAdder = await new Promise((resolve, reject) => {
      // TODO: make pull-multipart
      const parser = multipart.reqParser(request.payload)
      let filesParsed = false
      const adder = pushable()

      parser.on('file', (fileName, fileStream) => {
        if (!filesParsed) {
          resolve(adder)
          filesParsed = true
        }

        adder.push({
          path: decodeURIComponent(fileName),
          content: toPull(fileStream)
        })
      })

      parser.on('directory', (dirName) => {
        adder.push({
          path: decodeURIComponent(dirName),
          content: ''
        })
      })

      parser.on('end', () => {
        if (!filesParsed) {
          reject(new Error("File argument 'data' is required."))
        }
        adder.end()
      })
    })

    const replyStream = pushable()
    const progressHandler = bytes => replyStream.push({ Bytes: bytes })

    const options = {
      cidVersion: request.query['cid-version'],
      rawLeaves: request.query['raw-leaves'],
      progress: request.query.progress ? progressHandler : null,
      onlyHash: request.query['only-hash'],
      hashAlg: request.query.hash,
      wrapWithDirectory: request.query['wrap-with-directory'],
      pin: request.query.pin,
      chunker: request.query.chunker
    }

    const aborter = abortable()
    const stream = toStream.source(pull(
      replyStream,
      aborter,
      ndjson.serialize()
    ))

    // const stream = toStream.source(replyStream.source)
    // hapi is not very clever and throws if no
    // - _read method
    // - _readableState object
    // are there :(
    if (!stream._read) {
      stream._read = () => {}
      stream._readableState = {}
      stream.unpipe = () => {}
    }

    let filesAdded = false

    pull(
      fileAdder,
      ipfs.addPullStream(options),
      pull.map(file => ({
        Name: file.path, // addPullStream already turned this into a hash if it wanted to
        Hash: cidToString(file.hash, { base: request.query['cid-base'] }),
        Size: file.size
      })),
      pull.drain(
        file => {
          replyStream.push(file)
          filesAdded = true
        },
        err => {
          if (err || !filesAdded) {
            request.raw.res.addTrailers({
              'X-Stream-Error': JSON.stringify({
                Message: err ? err.message : 'Failed to add files.',
                Code: 0
              })
            })
            return aborter.abort()
          }

          replyStream.end()
        }
      )
    )

    return h.response(stream)
      .header('x-chunked-output', '1')
      .header('content-type', 'application/json')
      .header('Trailer', 'X-Stream-Error')
  }
}

exports.ls = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args
    const recursive = request.query && request.query.recursive === 'true'
    const cidBase = request.query['cid-base']

    let files
    try {
      files = await ipfs.ls(key, { recursive })
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to list dir' })
    }

    return h.response({
      Objects: [{
        Hash: key,
        Links: files.map((file) => ({
          Name: file.name,
          Hash: cidToString(file.hash, { base: cidBase }),
          Size: file.size,
          Type: toTypeCode(file.type),
          Depth: file.depth
        }))
      }]
    })
  }
}

function toTypeCode (type) {
  switch (type) {
    case 'dir':
      return 1
    case 'file':
      return 2
    default:
      return 0
  }
}

'''
'''--- src/http/api/resources/id.js ---
'use strict'

exports.get = async (request, h) => {
  const id = await request.server.app.ipfs.id()
  return h.response({
    ID: id.id,
    PublicKey: id.publicKey,
    Addresses: id.addresses,
    AgentVersion: id.agentVersion,
    ProtocolVersion: id.protocolVersion
  })
}

'''
'''--- src/http/api/resources/index.js ---
'use strict'

exports.version = require('./version')
exports.shutdown = require('./shutdown')
exports.id = require('./id')
exports.ping = require('./ping')
exports.bootstrap = require('./bootstrap')
exports.repo = require('./repo')
exports.object = require('./object')
exports.pin = require('./pin')
exports.config = require('./config')
exports.block = require('./block')
exports.swarm = require('./swarm')
exports.bitswap = require('./bitswap')
exports.file = require('./file')
exports.filesRegular = require('./files-regular')
exports.pubsub = require('./pubsub')
exports.dns = require('./dns')
exports.key = require('./key')
exports.stats = require('./stats')
exports.resolve = require('./resolve')
exports.name = require('./name')
exports.dht = require('./dht')

'''
'''--- src/http/api/resources/key.js ---
'use strict'

function toKeyInfo (key) {
  return {
    Name: key.name,
    Id: key.id
  }
}

exports.list = async (request, h) => {
  const { ipfs } = request.server.app
  const keys = await ipfs.key.list()
  return h.response({ Keys: keys.map(toKeyInfo) })
}

exports.rm = async (request, h) => {
  const { ipfs } = request.server.app
  const name = request.query.arg
  const key = await ipfs.key.rm(name)
  return h.response({ Keys: [ toKeyInfo(key) ] })
}

exports.rename = async (request, h) => {
  const { ipfs } = request.server.app
  const [ oldName, newName ] = request.query.arg
  const key = await ipfs.key.rename(oldName, newName)
  return h.response({
    Was: key.was,
    Now: key.name,
    Id: key.id,
    Overwrite: key.overwrite
  })
}

exports.gen = async (request, h) => {
  const { ipfs } = request.server.app
  const { arg, type, size } = request.query
  const key = await ipfs.key.gen(arg, { type, size: parseInt(size) })
  return h.response(toKeyInfo(key))
}

exports.export = async (request, h) => {
  const { ipfs } = request.server.app
  const { arg: name, password } = request.query
  const pem = await ipfs.key.export(name, password)
  return h.response(pem).type('application/x-pem-file')
}

exports.import = async (request, h) => {
  const { ipfs } = request.server.app
  const { arg: name, pem, password } = request.query
  const key = await ipfs.key.import(name, pem, password)
  return h.response(toKeyInfo(key))
}

'''
'''--- src/http/api/resources/name.js ---
'use strict'

const Joi = require('joi')

exports.resolve = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string(),
      nocache: Joi.boolean().default(false),
      recursive: Joi.boolean().default(false)
    }).unknown()
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { arg } = request.query

    const res = await ipfs.name.resolve(arg, request.query)

    return h.response({
      Path: res.path
    })
  }
}

exports.publish = {
  validate: {
    query: Joi.object().keys({
      arg: Joi.string().required(),
      resolve: Joi.boolean().default(true),
      lifetime: Joi.string().default('24h'),
      key: Joi.string().default('self')
    }).unknown()
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { arg } = request.query

    const res = await ipfs.name.publish(arg, request.query)

    return h.response({
      Name: res.name,
      Value: res.value
    })
  }
}

exports.pubsub = {
  state: {
    async handler (request, h) {
      const { ipfs } = request.server.app

      const res = await ipfs.name.pubsub.state()

      return h.response({
        Enabled: res.enabled
      })
    }
  },
  subs: {
    async handler (request, h) {
      const { ipfs } = request.server.app

      const res = await ipfs.name.pubsub.subs()

      return h.response({
        Strings: res
      })
    }
  },
  cancel: {
    validate: {
      query: Joi.object().keys({
        arg: Joi.string().required()
      }).unknown()
    },
    async handler (request, h) {
      const { ipfs } = request.server.app
      const { arg } = request.query

      const res = await ipfs.name.pubsub.cancel(arg)

      return h.response({
        Canceled: res.canceled
      })
    }
  }
}

'''
'''--- src/http/api/resources/object.js ---
'use strict'

const promisify = require('promisify-es6')
const CID = require('cids')
const multipart = require('ipfs-multipart')
const dagPB = require('ipld-dag-pb')
const { DAGNode, DAGLink } = dagPB
const calculateCid = promisify(dagPB.util.cid)
const deserialize = promisify(dagPB.util.deserialize)
const createDagNode = promisify(DAGNode.create)
const Joi = require('joi')
const multibase = require('multibase')
const Boom = require('boom')
const { cidToString } = require('../../../utils/cid')
const debug = require('debug')
const log = debug('jsipfs:http-api:object')
log.error = debug('jsipfs:http-api:object:error')

// common pre request handler that parses the args and returns `key` which is assigned to `request.pre.args`
exports.parseKey = (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest("Argument 'key' is required")
  }

  try {
    return { key: new CID(request.query.arg) }
  } catch (err) {
    log.error(err)
    throw Boom.badRequest('invalid ipfs ref path')
  }
}

exports.new = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  async handler (request, h) {
    const { ipfs } = request.server.app
    const template = request.query.arg

    let cid, node
    try {
      cid = await ipfs.object.new(template)
      node = await ipfs.object.get(cid)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to create object' })
    }

    const nodeJSON = node.toJSON()

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

exports.get = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { key } = request.pre.args
    const enc = request.query.enc || 'base58'
    const { ipfs } = request.server.app

    let node, cid
    try {
      node = await ipfs.object.get(key, { enc: enc })
      cid = await calculateCid(node)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get object' })
    }

    const nodeJSON = node.toJSON()

    if (Buffer.isBuffer(node.data)) {
      nodeJSON.data = node.data.toString(request.query['data-encoding'] || undefined)
    }

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

exports.put = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // pre request handler that parses the args and returns `node`
  // which is assigned to `request.pre.args`
  async parseArgs (request, h) {
    if (!request.payload) {
      throw Boom.badRequest("File argument 'data' is required")
    }

    const enc = request.query.inputenc

    const fileStream = await new Promise((resolve, reject) => {
      multipart.reqParser(request.payload)
        .on('file', (name, stream) => resolve(stream))
        .on('end', () => reject(Boom.badRequest("File argument 'data' is required")))
    })

    const data = await new Promise((resolve, reject) => {
      fileStream
        .on('data', data => resolve(data))
        .on('end', () => reject(Boom.badRequest("File argument 'data' is required")))
    })

    if (enc === 'protobuf') {
      try {
        return { node: await deserialize(data) }
      } catch (err) {
        throw Boom.badRequest('Failed to deserialize: ' + err)
      }
    }

    let nodeJson
    try {
      nodeJson = JSON.parse(data.toString())
    } catch (err) {
      throw Boom.badRequest('Failed to parse the JSON: ' + err)
    }

    try {
      return { node: await createDagNode(nodeJson.Data, nodeJson.Links) }
    } catch (err) {
      throw Boom.badRequest('Failed to create DAG node: ' + err)
    }
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { node } = request.pre.args

    let cid
    try {
      cid = await ipfs.object.put(node)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to put node' })
    }

    const nodeJSON = node.toJSON()

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

exports.stat = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args

    let stats
    try {
      stats = await ipfs.object.stat(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to stat object' })
    }

    stats.Hash = cidToString(stats.Hash, { base: request.query['cid-base'], upgrade: false })

    return h.response(stats)
  }
}

exports.data = {
  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args

    let data
    try {
      data = await ipfs.object.data(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get object data' })
    }

    return h.response(data)
  }
}

exports.links = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKey method that returns a `key`
  parseArgs: exports.parseKey,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key } = request.pre.args

    let node
    try {
      node = await ipfs.object.get(key)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to get object links' })
    }

    const nodeJSON = node.toJSON()

    return h.response({
      Hash: cidToString(key, { base: request.query['cid-base'], upgrade: false }),
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    })
  }
}

// common pre request handler that parses the args and returns `data` & `key` which are assigned to `request.pre.args`
exports.parseKeyAndData = async (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest("Argument 'root' is required")
  }

  if (!request.payload) {
    throw Boom.badRequest("File argument 'data' is required")
  }

  // TODO: support ipfs paths: https://github.com/ipfs/http-api-spec/pull/68/files#diff-2625016b50d68d922257f74801cac29cR3880
  let cid
  try {
    cid = new CID(request.query.arg)
  } catch (err) {
    throw Boom.badRequest('invalid ipfs ref path')
  }

  const fileStream = await new Promise((resolve, reject) => {
    multipart.reqParser(request.payload)
      .on('file', (fileName, fileStream) => resolve(fileStream))
      .on('end', () => reject(Boom.badRequest("File argument 'data' is required")))
  })

  const fileData = await new Promise((resolve, reject) => {
    fileStream
      .on('data', data => resolve(data))
      .on('end', () => reject(Boom.badRequest("File argument 'data' is required")))
  })

  return { data: fileData, key: cid }
}

exports.patchAppendData = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKeyAndData method that returns a `data` & `key`
  parseArgs: exports.parseKeyAndData,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key, data } = request.pre.args

    let cid, node
    try {
      cid = await ipfs.object.patch.appendData(key, data)
      node = await ipfs.object.get(cid)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to append data to object' })
    }

    const nodeJSON = node.toJSON()

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

exports.patchSetData = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // uses common parseKeyAndData method that returns a `data` & `key`
  parseArgs: exports.parseKeyAndData,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { key, data } = request.pre.args

    let cid, node
    try {
      cid = await ipfs.object.patch.setData(key, data)
      node = await ipfs.object.get(cid)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to set data on object' })
    }

    const nodeJSON = node.toJSON()

    return h.response({
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    })
  }
}

exports.patchAddLink = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // pre request handler that parses the args and returns `root`, `name` & `ref` which is assigned to `request.pre.args`
  parseArgs: (request, reply) => {
    if (!(request.query.arg instanceof Array) ||
        request.query.arg.length !== 3) {
      throw Boom.badRequest("Arguments 'root', 'name' & 'ref' are required")
    }

    if (!request.query.arg[0]) {
      throw Boom.badRequest('cannot create link with no root')
    }

    if (!request.query.arg[1]) {
      throw Boom.badRequest('cannot create link with no name!')
    }

    if (!request.query.arg[2]) {
      throw Boom.badRequest('cannot create link with no ref')
    }

    try {
      return {
        root: new CID(request.query.arg[0]),
        name: request.query.arg[1],
        ref: new CID(request.query.arg[2])
      }
    } catch (err) {
      log.error(err)
      throw Boom.badRequest('invalid ipfs ref path')
    }
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { root, name, ref } = request.pre.args

    let node, cid
    try {
      node = await ipfs.object.get(ref)
      cid = await ipfs.object.patch.addLink(root, new DAGLink(name, node.size, ref))
      node = await ipfs.object.get(cid)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to add link to object' })
    }

    const nodeJSON = node.toJSON()

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

exports.patchRmLink = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  // pre request handler that parses the args and returns `root` & `link` which is assigned to `request.pre.args`
  parseArgs (request, h) {
    if (!(request.query.arg instanceof Array) ||
        request.query.arg.length !== 2) {
      throw Boom.badRequest("Arguments 'root' & 'link' are required")
    }

    if (!request.query.arg[1]) {
      throw Boom.badRequest('cannot remove link with no name!')
    }

    try {
      return {
        root: new CID(request.query.arg[0]),
        link: request.query.arg[1]
      }
    } catch (err) {
      log.error(err)
      throw Boom.badRequest('invalid ipfs ref path')
    }
  },

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { ipfs } = request.server.app
    const { root, link } = request.pre.args

    let cid, node
    try {
      cid = await ipfs.object.patch.rmLink(root, { name: link })
      node = await ipfs.object.get(cid)
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to remove link from object' })
    }

    const nodeJSON = node.toJSON()

    const answer = {
      Data: nodeJSON.data,
      Hash: cidToString(cid, { base: request.query['cid-base'], upgrade: false }),
      Size: nodeJSON.size,
      Links: nodeJSON.links.map((l) => {
        return {
          Name: l.name,
          Size: l.size,
          Hash: cidToString(l.cid, { base: request.query['cid-base'], upgrade: false })
        }
      })
    }

    return h.response(answer)
  }
}

'''
'''--- src/http/api/resources/pin.js ---
'use strict'

const mapValues = require('lodash/mapValues')
const keyBy = require('lodash/keyBy')
const multibase = require('multibase')
const Joi = require('joi')
const Boom = require('boom')
const isIpfs = require('is-ipfs')
const { cidToString } = require('../../../utils/cid')

function parseArgs (request, h) {
  let { arg } = request.query

  if (!arg) {
    throw Boom.badRequest("Argument 'arg' is required")
  }

  arg = Array.isArray(arg) ? arg : [arg]

  arg.forEach(path => {
    if (!isIpfs.ipfsPath(path) && !isIpfs.cid(path)) {
      throw Boom.badRequest('invalid ipfs ref path')
    }
  })

  const recursive = request.query.recursive !== 'false'
  return { path: arg, recursive }
}

exports.ls = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  parseArgs (request, h) {
    let { arg } = request.query

    if (arg) {
      arg = Array.isArray(arg) ? arg : [arg]

      arg.forEach(path => {
        if (!isIpfs.ipfsPath(path) && !isIpfs.cid(path)) {
          throw Boom.badRequest('invalid ipfs ref path')
        }
      })
    }

    const type = request.query.type || 'all'
    return { path: request.query.arg, type }
  },

  async handler (request, h) {
    const { ipfs } = request.server.app
    const { path, type } = request.pre.args

    let result
    try {
      result = await ipfs.pin.ls(path, { type })
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to list pins' })
    }

    return h.response({
      Keys: mapValues(
        keyBy(result, obj => cidToString(obj.hash, { base: request.query['cid-base'] })),
        obj => ({ Type: obj.type })
      )
    })
  }
}

exports.add = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  parseArgs,

  async handler (request, h) {
    const { ipfs } = request.server.app
    const { path, recursive } = request.pre.args

    let result
    try {
      result = await ipfs.pin.add(path, { recursive })
    } catch (err) {
      if (err.message.includes('already pinned recursively')) {
        throw Boom.boomify(err, { statusCode: 400 })
      }
      throw Boom.boomify(err, { message: 'Failed to add pin' })
    }

    return h.response({
      Pins: result.map(obj => cidToString(obj.hash, { base: request.query['cid-base'] }))
    })
  }
}

exports.rm = {
  validate: {
    query: Joi.object().keys({
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },

  parseArgs,

  async handler (request, h) {
    const { ipfs } = request.server.app
    const { path, recursive } = request.pre.args

    let result
    try {
      result = await ipfs.pin.rm(path, { recursive })
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to remove pin' })
    }

    return h.response({
      Pins: result.map(obj => cidToString(obj.hash, { base: request.query['cid-base'] }))
    })
  }
}

'''
'''--- src/http/api/resources/ping.js ---
'use strict'

const Joi = require('joi')
const pull = require('pull-stream')
const ndjson = require('pull-ndjson')
const { PassThrough } = require('readable-stream')

module.exports = {
  validate: {
    query: Joi.object().keys({
      n: Joi.alternatives()
        .when('count', {
          is: Joi.any().exist(),
          then: Joi.any().forbidden(),
          otherwise: Joi.number().integer().greater(0)
        }),
      count: Joi.number().integer().greater(0),
      arg: Joi.string().required()
    }).unknown()
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const peerId = request.query.arg

    // Default count to 10
    const count = request.query.n || request.query.count || 10

    const responseStream = await new Promise((resolve, reject) => {
      const stream = new PassThrough()

      pull(
        ipfs.pingPullStream(peerId, { count }),
        pull.map((chunk) => ({
          Success: chunk.success,
          Time: chunk.time,
          Text: chunk.text
        })),
        ndjson.serialize(),
        pull.drain(chunk => {
          stream.write(chunk)
        }, err => {
          if (err) return reject(err)
          resolve(stream)
          stream.end()
        })
      )
    })

    return h.response(responseStream)
      .type('application/json')
      .header('X-Chunked-Output', '1')
  }
}

'''
'''--- src/http/api/resources/pubsub.js ---
'use strict'

const PassThrough = require('stream').PassThrough
const bs58 = require('bs58')
const binaryQueryString = require('binary-querystring')
const Boom = require('boom')

exports.subscribe = {
  async handler (request, h) {
    const query = request.query
    const discover = query.discover === 'true'
    const topic = query.arg

    if (!topic) {
      throw Boom.badRequest('Missing topic')
    }

    const { ipfs } = request.server.app

    const res = new PassThrough({ highWaterMark: 1 })

    const handler = (msg) => {
      res.write(JSON.stringify({
        from: bs58.decode(msg.from).toString('base64'),
        data: msg.data.toString('base64'),
        seqno: msg.seqno.toString('base64'),
        topicIDs: msg.topicIDs
      }) + '\n', 'utf8')
    }

    // js-ipfs-http-client needs a reply, and go-ipfs does the same thing
    res.write('{}\n')

    const unsubscribe = () => {
      ipfs.pubsub.unsubscribe(topic, handler, () => res.end())
    }

    request.events.once('disconnect', unsubscribe)
    request.events.once('finish', unsubscribe)

    await ipfs.pubsub.subscribe(topic, handler, { discover: discover })

    return h.response(res)
      .header('X-Chunked-Output', '1')
      .header('content-encoding', 'identity') // stop gzip from buffering, see https://github.com/hapijs/hapi/issues/2975
      .header('content-type', 'application/json')
  }
}

exports.publish = {
  async handler (request, h) {
    const { arg } = request.query
    const topic = arg[0]

    const rawArgs = binaryQueryString(request.url.search)
    const buf = rawArgs.arg && rawArgs.arg[1]

    const { ipfs } = request.server.app

    if (!topic) {
      throw Boom.badRequest('Missing topic')
    }

    if (!buf || buf.length === 0) {
      throw Boom.badRequest('Missing buf')
    }

    try {
      await ipfs.pubsub.publish(topic, buf)
    } catch (err) {
      throw Boom.boomify(err, { message: `Failed to publish to topic ${topic}` })
    }

    return h.response()
  }
}

exports.ls = {
  async handler (request, h) {
    const { ipfs } = request.server.app

    let subscriptions
    try {
      subscriptions = await ipfs.pubsub.ls()
    } catch (err) {
      throw Boom.boomify(err, { message: 'Failed to list subscriptions' })
    }

    return h.response({ Strings: subscriptions })
  }
}

exports.peers = {
  async handler (request, h) {
    const topic = request.query.arg
    const { ipfs } = request.server.app

    let peers
    try {
      peers = await ipfs.pubsub.peers(topic)
    } catch (err) {
      const message = topic
        ? `Failed to find peers subscribed to ${topic}: ${err}`
        : `Failed to find peers: ${err}`

      throw Boom.boomify(err, { message })
    }

    return h.response({ Strings: peers })
  }
}

'''
'''--- src/http/api/resources/repo.js ---
'use strict'

exports.gc = async (request, h) => {
  const { ipfs } = request.server.app
  await ipfs.repo.gc()
  return h.response()
}

exports.version = async (request, h) => {
  const { ipfs } = request.server.app
  const version = await ipfs.repo.version()
  return h.response({
    Version: version
  })
}

exports.stat = async (request, h) => {
  const { ipfs } = request.server.app
  const human = request.query.human === 'true'
  const stat = await ipfs.repo.stat({ human })

  return h.response({
    NumObjects: stat.numObjects,
    RepoSize: stat.repoSize,
    RepoPath: stat.repoPath,
    Version: stat.version,
    StorageMax: stat.storageMax
  })
}

'''
'''--- src/http/api/resources/resolve.js ---
'use strict'

const Joi = require('joi')
const debug = require('debug')
const multibase = require('multibase')

const log = debug('jsipfs:http-api:resolve')
log.error = debug('jsipfs:http-api:resolve:error')

module.exports = {
  validate: {
    query: Joi.object().keys({
      r: Joi.alternatives()
        .when('recursive', {
          is: Joi.any().exist(),
          then: Joi.any().forbidden(),
          otherwise: Joi.boolean()
        }),
      recursive: Joi.boolean(),
      arg: Joi.string().required(),
      'cid-base': Joi.string().valid(multibase.names)
    }).unknown()
  },
  async handler (request, h) {
    const { ipfs } = request.server.app
    const name = request.query.arg
    const recursive = request.query.r || request.query.recursive || false
    const cidBase = request.query['cid-base']

    log(name, { recursive, cidBase })
    const res = await ipfs.resolve(name, { recursive, cidBase })

    return h.response({ Path: res })
  }
}

'''
'''--- src/http/api/resources/shutdown.js ---
'use strict'

/*
 * Stop the daemon.
 *
 * Returns an empty response to the caller then
 * on the next 'tick' emits SIGTERM.
 */
module.exports = (request, h) => {
  setImmediate(() => process.emit('SIGTERM'))
  return h.response()
}

'''
'''--- src/http/api/resources/stats.js ---
'use strict'

const { Transform } = require('readable-stream')

const transformBandwidth = (stat) => {
  return {
    TotalIn: stat.totalIn,
    TotalOut: stat.totalOut,
    RateIn: stat.rateIn,
    RateOut: stat.rateOut
  }
}

exports.bitswap = require('./bitswap').stat

exports.repo = require('./repo').stat

exports.bw = async (request, h) => {
  const { ipfs } = request.server.app
  const options = {
    peer: request.query.peer,
    proto: request.query.proto,
    poll: request.query.poll === 'true',
    interval: request.query.interval || '1s'
  }

  const res = ipfs.stats.bwReadableStream(options)
  const output = new Transform({
    writableObjectMode: true,
    transform (chunk, encoding, cb) {
      this.push(JSON.stringify(transformBandwidth(chunk)) + '\n')
      cb()
    }
  })

  request.events.on('disconnect', () => {
    res.destroy()
  })

  res.pipe(output)

  return h.response(output)
    .header('content-type', 'application/json')
    .header('x-chunked-output', '1')
}

'''
'''--- src/http/api/resources/swarm.js ---
'use strict'

const multiaddr = require('multiaddr')
const Boom = require('boom')

// common pre request handler that parses the args and returns `addr` which is assigned to `request.pre.args`
exports.parseAddrs = (request, h) => {
  if (!request.query.arg) {
    throw Boom.badRequest('Argument `addr` is required')
  }

  try {
    multiaddr(request.query.arg)
  } catch (err) {
    throw Boom.boomify(err, { statusCode: 400 })
  }

  return {
    addr: request.query.arg
  }
}

exports.peers = {
  async handler (request, h) {
    const rawVerbose = request.query.v || request.query.verbose
    const verbose = rawVerbose === 'true'
    const { ipfs } = request.server.app

    const peers = await ipfs.swarm.peers({ verbose })

    return h.response({
      Peers: peers.map((p) => {
        const res = {
          Peer: p.peer.toB58String(),
          Addr: p.addr.toString()
        }

        if (verbose) {
          res.Latency = p.latency
        }

        return res
      })
    })
  }
}

exports.addrs = {
  async handler (request, h) {
    const { ipfs } = request.server.app
    const peers = await ipfs.swarm.addrs()

    const addrs = {}
    peers.forEach((peer) => {
      addrs[peer.id.toB58String()] = peer.multiaddrs.toArray()
        .map((addr) => addr.toString())
    })

    return h.response({
      Addrs: addrs
    })
  }
}

exports.localAddrs = {
  async handler (request, h) {
    const { ipfs } = request.server.app
    const addrs = await ipfs.swarm.localAddrs()

    return h.response({
      Strings: addrs.map((addr) => addr.toString())
    })
  }
}

exports.connect = {
  // uses common parseAddr method that returns a `addr`
  parseArgs: exports.parseAddrs,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { addr } = request.pre.args
    const { ipfs } = request.server.app

    await ipfs.swarm.connect(addr)

    return h.response({
      Strings: [`connect ${addr} success`]
    })
  }
}

exports.disconnect = {
  // uses common parseAddr method that returns a `addr`
  parseArgs: exports.parseAddrs,

  // main route handler which is called after the above `parseArgs`, but only if the args were valid
  async handler (request, h) {
    const { addr } = request.pre.args
    const { ipfs } = request.server.app

    await ipfs.swarm.disconnect(addr)

    return h.response({
      Strings: [`disconnect ${addr} success`]
    })
  }
}

'''
'''--- src/http/api/resources/version.js ---
'use strict'

module.exports = async (request, h) => {
  const { ipfs } = request.server.app
  const version = await ipfs.version()

  return h.response({
    Version: version.version,
    Commit: version.commit,
    Repo: version.repo
  })
}

'''
'''--- src/http/api/routes/bitswap.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/bitswap/wantlist',
    options: {
      validate: resources.bitswap.wantlist.validate
    },
    handler: resources.bitswap.wantlist.handler
  },
  {
    method: '*',
    path: '/api/v0/bitswap/stat',
    options: {
      validate: resources.bitswap.stat.validate
    },
    handler: resources.bitswap.stat.handler
  },
  {
    method: '*',
    path: '/api/v0/bitswap/unwant',
    options: {
      pre: [
        { method: resources.bitswap.unwant.parseArgs, assign: 'args' }
      ],
      validate: resources.bitswap.unwant.validate
    },
    handler: resources.bitswap.unwant.handler
  }
]

'''
'''--- src/http/api/routes/block.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/block/get',
    options: {
      pre: [
        { method: resources.block.get.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.block.get.handler
  },
  {
    method: '*',
    path: '/api/v0/block/put',
    options: {
      payload: {
        parse: false,
        output: 'stream'
      },
      pre: [
        { method: resources.block.put.parseArgs, assign: 'args' }
      ],
      validate: resources.block.put.validate
    },
    handler: resources.block.put.handler
  },
  {
    method: '*',
    path: '/api/v0/block/rm',
    config: {
      pre: [
        { method: resources.block.rm.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.block.rm.handler
  },
  {
    method: '*',
    path: '/api/v0/block/stat',
    config: {
      pre: [
        { method: resources.block.stat.parseArgs, assign: 'args' }
      ],
      validate: resources.block.stat.validate
    },
    handler: resources.block.stat.handler
  }
]

'''
'''--- src/http/api/routes/bootstrap.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/bootstrap',
    handler: resources.bootstrap.list
  },
  {
    method: '*',
    path: '/api/v0/bootstrap/add',
    options: {
      pre: [
        { method: resources.bootstrap.add.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.bootstrap.add.handler
  },
  {
    method: '*',
    path: '/api/v0/bootstrap/add/default',
    handler: resources.bootstrap.addDefault
  },
  {
    method: '*',
    path: '/api/v0/bootstrap/list',
    handler: resources.bootstrap.list
  },
  {
    method: '*',
    path: '/api/v0/bootstrap/rm',
    options: {
      pre: [
        { method: resources.bootstrap.rm.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.bootstrap.rm.handler
  },
  {
    method: '*',
    path: '/api/v0/bootstrap/rm/all',
    handler: resources.bootstrap.rmAll
  }
]

'''
'''--- src/http/api/routes/config.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/config/{key?}',
    options: {
      pre: [
        { method: resources.config.getOrSet.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.config.getOrSet.handler
  },
  {
    method: '*',
    path: '/api/v0/config/show',
    handler: resources.config.show
  },
  {
    method: '*',
    path: '/api/v0/config/replace',
    options: {
      payload: {
        parse: false,
        output: 'stream'
      },
      pre: [
        { method: resources.config.replace.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.config.replace.handler
  }
]

'''
'''--- src/http/api/routes/debug.js ---
'use strict'

const client = require('prom-client')
const Boom = require('boom')

// Clear the register to make sure we're not registering multiple ones
client.register.clear()
const gauge = new client.Gauge({ name: 'number_of_peers', help: 'the_number_of_currently_connected_peers' })

// Endpoint for handling debug metrics
module.exports = {
  method: 'GET',
  path: '/debug/metrics/prometheus',
  async handler (request, h) {
    if (!process.env.IPFS_MONITORING) {
      throw Boom.notImplemented('Monitoring is disabled. Enable it by setting environment variable IPFS_MONITORING')
    }

    const { ipfs } = request.server.app
    const peers = await ipfs.swarm.peers()

    gauge.set(peers.length)

    return h.response(client.register.metrics())
      .type(client.register.contentType)
  }
}

'''
'''--- src/http/api/routes/dht.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/dht/findpeer',
    options: {
      validate: resources.dht.findPeer.validate
    },
    handler: resources.dht.findPeer.handler
  },
  {
    method: '*',
    path: '/api/v0/dht/findprovs',
    options: {
      validate: resources.dht.findProvs.validate
    },
    handler: resources.dht.findProvs.handler
  },
  {
    method: '*',
    path: '/api/v0/dht/get',
    options: {
      validate: resources.dht.get.validate
    },
    handler: resources.dht.get.handler
  },
  {
    method: '*',
    path: '/api/v0/dht/provide',
    options: {
      validate: resources.dht.provide.validate
    },
    handler: resources.dht.provide.handler
  },
  {
    method: '*',
    path: '/api/v0/dht/put',
    options: {
      pre: [
        { method: resources.dht.put.parseArgs, assign: 'args' }
      ],
      validate: resources.dht.put.validate
    },
    handler: resources.dht.put.handler
  },
  {
    method: '*',
    path: '/api/v0/dht/query',
    options: {
      validate: resources.dht.query.validate
    },
    handler: resources.dht.query.handler
  }
]

'''
'''--- src/http/api/routes/dns.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/dns',
  handler: resources.dns
}

'''
'''--- src/http/api/routes/file.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  // TODO fix method
  method: '*',
  path: '/api/v0/file/ls',
  config: {
    pre: [
      { method: resources.file.ls.parseArgs, assign: 'args' }
    ]
  },
  handler: resources.file.ls.handler
}

'''
'''--- src/http/api/routes/files-regular.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    // TODO fix method
    method: '*',
    path: '/api/v0/cat',
    options: {
      pre: [
        { method: resources.filesRegular.cat.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.filesRegular.cat.handler
  },
  {
    // TODO fix method
    method: '*',
    path: '/api/v0/get',
    options: {
      pre: [
        { method: resources.filesRegular.get.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.filesRegular.get.handler
  },
  {
    // TODO fix method
    method: '*',
    path: '/api/v0/add',
    options: {
      payload: {
        parse: false,
        output: 'stream',
        maxBytes: Number.MAX_SAFE_INTEGER
      },
      validate: resources.filesRegular.add.validate
    },
    handler: resources.filesRegular.add.handler
  },
  {
    // TODO fix method
    method: '*',
    path: '/api/v0/ls',
    options: {
      pre: [
        { method: resources.filesRegular.ls.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.filesRegular.ls.handler
  }
]

'''
'''--- src/http/api/routes/id.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/id',
  handler: resources.id.get
}

'''
'''--- src/http/api/routes/index.js ---
'use strict'

module.exports = [
  require('./version'),
  require('./shutdown'),
  require('./id'),
  ...require('./bootstrap'),
  ...require('./block'),
  ...require('./object'),
  ...require('./pin'),
  ...require('./repo'),
  ...require('./config'),
  require('./ping'),
  ...require('./swarm'),
  ...require('./bitswap'),
  require('./file'),
  ...require('./files-regular'),
  ...require('ipfs-mfs/http'),
  ...require('./pubsub'),
  require('./debug'),
  ...require('./webui'),
  require('./dns'),
  ...require('./key'),
  ...require('./stats'),
  require('./resolve'),
  ...require('./name'),
  ...require('./dht')
]

'''
'''--- src/http/api/routes/key.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/key/list',
    handler: resources.key.list
  },
  {
    method: '*',
    path: '/api/v0/key/gen',
    handler: resources.key.gen
  },
  {
    method: '*',
    path: '/api/v0/key/rm',
    handler: resources.key.rm
  },
  {
    method: '*',
    path: '/api/v0/key/rename',
    handler: resources.key.rename
  },
  {
    method: '*',
    path: '/api/v0/key/export',
    handler: resources.key.export
  },
  {
    method: '*',
    path: '/api/v0/key/import',
    handler: resources.key.import
  }
]

'''
'''--- src/http/api/routes/name.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/name/resolve',
    options: {
      validate: resources.name.resolve.validate
    },
    handler: resources.name.resolve.handler
  },
  {
    method: '*',
    path: '/api/v0/name/publish',
    options: {
      validate: resources.name.publish.validate
    },
    handler: resources.name.publish.handler
  },
  {
    method: '*',
    path: '/api/v0/name/pubsub/state',
    handler: resources.name.pubsub.state.handler
  },
  {
    method: '*',
    path: '/api/v0/name/pubsub/subs',
    handler: resources.name.pubsub.subs.handler
  },
  {
    method: '*',
    path: '/api/v0/name/pubsub/cancel',
    options: {
      validate: resources.name.pubsub.cancel.validate
    },
    handler: resources.name.pubsub.cancel.handler
  }
]

'''
'''--- src/http/api/routes/object.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/object/new',
    options: {
      validate: resources.object.new.validate
    },
    handler: resources.object.new.handler
  },
  {
    method: '*',
    path: '/api/v0/object/get',
    options: {
      pre: [
        { method: resources.object.get.parseArgs, assign: 'args' }
      ],
      validate: resources.object.get.validate
    },
    handler: resources.object.get.handler
  },
  {
    method: '*',
    path: '/api/v0/object/put',
    options: {
      payload: {
        parse: false,
        output: 'stream'
      },
      pre: [
        { method: resources.object.put.parseArgs, assign: 'args' }
      ],
      validate: resources.object.put.validate
    },
    handler: resources.object.put.handler
  },
  {
    method: '*',
    path: '/api/v0/object/stat',
    options: {
      pre: [
        { method: resources.object.stat.parseArgs, assign: 'args' }
      ],
      validate: resources.object.stat.validate
    },
    handler: resources.object.stat.handler
  },
  {
    method: '*',
    path: '/api/v0/object/data',
    options: {
      pre: [
        { method: resources.object.data.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.object.data.handler
  },
  {
    method: '*',
    path: '/api/v0/object/links',
    options: {
      pre: [
        { method: resources.object.links.parseArgs, assign: 'args' }
      ],
      validate: resources.object.links.validate
    },
    handler: resources.object.links.handler
  },
  {
    method: '*',
    path: '/api/v0/object/patch/append-data',
    options: {
      payload: {
        parse: false,
        output: 'stream'
      },
      pre: [
        { method: resources.object.patchAppendData.parseArgs, assign: 'args' }
      ],
      validate: resources.object.patchAppendData.validate
    },
    handler: resources.object.patchAppendData.handler
  },
  {
    method: '*',
    path: '/api/v0/object/patch/set-data',
    options: {
      payload: {
        parse: false,
        output: 'stream'
      },
      pre: [
        { method: resources.object.patchSetData.parseArgs, assign: 'args' }
      ],
      validate: resources.object.patchSetData.validate
    },
    handler: resources.object.patchSetData.handler
  },
  {
    method: '*',
    path: '/api/v0/object/patch/add-link',
    options: {
      pre: [
        { method: resources.object.patchAddLink.parseArgs, assign: 'args' }
      ],
      validate: resources.object.patchAddLink.validate
    },
    handler: resources.object.patchAddLink.handler
  },
  {
    method: '*',
    path: '/api/v0/object/patch/rm-link',
    options: {
      pre: [
        { method: resources.object.patchRmLink.parseArgs, assign: 'args' }
      ],
      validate: resources.object.patchRmLink.validate
    },
    handler: resources.object.patchRmLink.handler
  }
]

'''
'''--- src/http/api/routes/pin.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/pin/add',
    options: {
      pre: [
        { method: resources.pin.add.parseArgs, assign: 'args' }
      ],
      validate: resources.pin.add.validate
    },
    handler: resources.pin.add.handler
  },
  {
    method: '*',
    path: '/api/v0/pin/rm',
    options: {
      pre: [
        { method: resources.pin.rm.parseArgs, assign: 'args' }
      ],
      validate: resources.pin.rm.validate
    },
    handler: resources.pin.rm.handler
  },
  {
    method: '*',
    path: '/api/v0/pin/ls',
    config: {
      pre: [
        { method: resources.pin.ls.parseArgs, assign: 'args' }
      ],
      validate: resources.pin.ls.validate
    },
    handler: resources.pin.ls.handler
  }
]

'''
'''--- src/http/api/routes/ping.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/ping',
  config: {
    handler: resources.ping.handler,
    validate: resources.ping.validate
  }
}

'''
'''--- src/http/api/routes/pubsub.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/pubsub/sub',
    handler: resources.pubsub.subscribe.handler
  },
  {
    method: '*',
    path: '/api/v0/pubsub/pub',
    handler: resources.pubsub.publish.handler
  },
  {
    method: '*',
    path: '/api/v0/pubsub/ls',
    handler: resources.pubsub.ls.handler
  },
  {
    method: '*',
    path: '/api/v0/pubsub/peers',
    handler: resources.pubsub.peers.handler
  }
]

'''
'''--- src/http/api/routes/repo.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/repo/version',
    handler: resources.repo.version
  },
  {
    method: '*',
    path: '/api/v0/repo/stat',
    handler: resources.repo.stat
  }
  // TODO: implement the missing spec https://github.com/ipfs/interface-ipfs-core/blob/master/SPEC/REPO.md
]

'''
'''--- src/http/api/routes/resolve.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/resolve',
  options: {
    validate: resources.resolve.validate
  },
  handler: resources.resolve.handler
}

'''
'''--- src/http/api/routes/shutdown.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/shutdown',
  handler: resources.shutdown
}

'''
'''--- src/http/api/routes/stats.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/stats/bitswap',
    options: {
      validate: resources.stats.bitswap.validate
    },
    handler: resources.stats.bitswap.handler
  },
  {
    method: '*',
    path: '/api/v0/stats/repo',
    handler: resources.stats.repo
  },
  {
    method: '*',
    path: '/api/v0/stats/bw',
    handler: resources.stats.bw
  }
]

'''
'''--- src/http/api/routes/swarm.js ---
'use strict'

const resources = require('../resources')

module.exports = [
  {
    method: '*',
    path: '/api/v0/swarm/peers',
    handler: resources.swarm.peers.handler
  },
  {
    method: '*',
    path: '/api/v0/swarm/addrs',
    handler: resources.swarm.addrs.handler
  },
  {
    method: '*',
    path: '/api/v0/swarm/addrs/local',
    handler: resources.swarm.localAddrs.handler
  },
  {
    method: '*',
    path: '/api/v0/swarm/connect',
    options: {
      pre: [
        { method: resources.swarm.connect.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.swarm.connect.handler
  },
  {
    method: '*',
    path: '/api/v0/swarm/disconnect',
    options: {
      pre: [
        { method: resources.swarm.disconnect.parseArgs, assign: 'args' }
      ]
    },
    handler: resources.swarm.disconnect.handler
  }
  // TODO
  // {
  //  method: '*',
  //  path: '/api/v0/swarm/filters',
  //  handler: resources.swarm.disconnect
  // }
]

'''
'''--- src/http/api/routes/version.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/api/v0/version',
  handler: resources.version
}

'''
'''--- src/http/api/routes/webui.js ---
'use strict'

const resources = require('../../gateway/resources')

module.exports = [
  {
    method: '*',
    path: '/ipfs/{cid*}',
    options: {
      pre: [
        { method: resources.gateway.checkCID, assign: 'args' }
      ]
    },
    handler: resources.gateway.handler
  },
  {
    method: '*',
    path: '/webui',
    handler (request, h) {
      return h.redirect('/ipfs/QmXc9raDM1M5G5fpBnVyQ71vR4gbnskwnB9iMEzBuLgvoZ')
    }
  }
]

'''
'''--- src/http/error-handler.js ---
'use strict'

module.exports = server => {
  server.ext('onPreResponse', (request, h) => {
    const res = request.response

    if (!res.isBoom) {
      return h.continue
    }

    const message = res.message || res.output.payload.message
    const { statusCode } = res.output.payload
    let code

    if (res.data && res.data.code != null) {
      code = res.data.code
    } else {
      // Map status code to error code as defined by go-ipfs
      // https://github.com/ipfs/go-ipfs-cmdkit/blob/0262a120012063c359727423ec703b9649eec447/error.go#L12-L20
      if (statusCode >= 400 && statusCode < 500) {
        code = statusCode === 404 ? 3 : 1
      } else {
        code = 0
      }
    }

    if (process.env.DEBUG || statusCode >= 500) {
      const { req } = request.raw
      const debug = {
        method: req.method,
        url: request.url.path,
        headers: req.headers,
        info: request.info,
        payload: request.payload,
        response: res.output.payload
      }

      server.logger().error(debug)
      server.logger().error(res)
    }

    return h.response({
      Message: message,
      Code: code,
      Type: 'error'
    }).code(statusCode)
  })
}

'''
'''--- src/http/gateway/resources/gateway.js ---
'use strict'

const debug = require('debug')
const log = debug('jsipfs:http-gateway')
log.error = debug('jsipfs:http-gateway:error')
const pull = require('pull-stream')
const pushable = require('pull-pushable')
const toStream = require('pull-stream-to-stream')
const fileType = require('file-type')
const mime = require('mime-types')
const { PassThrough } = require('readable-stream')
const Boom = require('boom')

const { resolver } = require('ipfs-http-response')
const PathUtils = require('../utils/path')
const { cidToString } = require('../../../utils/cid')

function detectContentType (ref, chunk) {
  let fileSignature

  // try to guess the filetype based on the first bytes
  // note that `file-type` doesn't support svgs, therefore we assume it's a svg if ref looks like it
  if (!ref.endsWith('.svg')) {
    fileSignature = fileType(chunk)
  }

  // if we were unable to, fallback to the `ref` which might contain the extension
  const mimeType = mime.lookup(fileSignature ? fileSignature.ext : ref)

  return mime.contentType(mimeType)
}

module.exports = {
  checkCID (request, h) {
    if (!request.params.cid) {
      throw Boom.badRequest('Path Resolve error: path must contain at least one component')
    }

    return { ref: `/ipfs/${request.params.cid}` }
  },

  async handler (request, h) {
    const { ref } = request.pre.args
    const { ipfs } = request.server.app

    let data
    try {
      data = await resolver.cid(ipfs, ref)
    } catch (err) {
      const errorToString = err.toString()
      log.error('err: ', errorToString, ' fileName: ', err.fileName)

      // switch case with true feels so wrong.
      switch (true) {
        case (errorToString === 'Error: This dag node is a directory'):
          data = await resolver.directory(ipfs, ref, err.cid)

          if (typeof data === 'string') {
            // no index file found
            if (!ref.endsWith('/')) {
              // for a directory, if URL doesn't end with a /
              // append / and redirect permanent to that URL
              return h.redirect(`${ref}/`).permanent(true)
            }
            // send directory listing
            return h.response(data)
          }

          // found index file
          // redirect to URL/<found-index-file>
          return h.redirect(PathUtils.joinURLParts(ref, data[0].name))
        case (errorToString.startsWith('Error: no link named')):
          throw Boom.boomify(err, { statusCode: 404 })
        case (errorToString.startsWith('Error: multihash length inconsistent')):
        case (errorToString.startsWith('Error: Non-base58 character')):
          throw Boom.boomify(err, { statusCode: 400 })
        default:
          log.error(err)
          throw err
      }
    }

    if (ref.endsWith('/')) {
      // remove trailing slash for files
      return h.redirect(PathUtils.removeTrailingSlash(ref)).permanent(true)
    }

    return new Promise((resolve, reject) => {
      let pusher
      let started = false

      pull(
        ipfs.catPullStream(data.cid),
        pull.drain(
          chunk => {
            if (!started) {
              started = true
              pusher = pushable()
              const res = h.response(toStream.source(pusher).pipe(new PassThrough()))

              // Etag maps directly to an identifier for a specific version of a resource
              res.header('Etag', `"${data.cid}"`)

              // Set headers specific to the immutable namespace
              if (ref.startsWith('/ipfs/')) {
                res.header('Cache-Control', 'public, max-age=29030400, immutable')
              }

              const contentType = detectContentType(ref, chunk)

              log('ref ', ref)
              log('mime-type ', contentType)

              if (contentType) {
                log('writing content-type header')
                res.header('Content-Type', contentType)
              }

              resolve(res)
            }
            pusher.push(chunk)
          },
          err => {
            if (err) {
              log.error(err)

              // We already started flowing, abort the stream
              if (started) {
                return pusher.end(err)
              }

              return reject(err)
            }

            pusher.end()
          }
        )
      )
    })
  },

  afterHandler (request, h) {
    const { response } = request
    if (response.statusCode === 200) {
      const { ref } = request.pre.args
      response.header('X-Ipfs-Path', ref)
      if (ref.startsWith('/ipfs/')) {
        const rootCid = ref.split('/')[2]
        const ipfsOrigin = cidToString(rootCid, { base: 'base32' })
        response.header('Suborigin', 'ipfs000' + ipfsOrigin)
      }
      // TODO: we don't have case-insensitive solution for /ipns/ yet (https://github.com/ipfs/go-ipfs/issues/5287)
    }
    return h.continue
  }

}

'''
'''--- src/http/gateway/resources/index.js ---
'use strict'

module.exports = {
  gateway: require('./gateway')
}

'''
'''--- src/http/gateway/routes/gateway.js ---
'use strict'

const resources = require('../resources')

module.exports = {
  method: '*',
  path: '/ipfs/{cid*}',
  options: {
    handler: resources.gateway.handler,
    pre: [
      { method: resources.gateway.checkCID, assign: 'args' }
    ],
    ext: {
      onPostHandler: { method: resources.gateway.afterHandler }
    }
  }
}

'''
'''--- src/http/gateway/routes/index.js ---
'use strict'

module.exports = [require('./gateway')]

'''
'''--- src/http/gateway/utils/path.js ---
'use strict'

function splitPath (path) {
  if (path[path.length - 1] === '/') {
    path = path.substring(0, path.length - 1)
  }

  return path.substring(6).split('/')
}

function removeLeadingSlash (url) {
  if (url[0] === '/') {
    url = url.substring(1)
  }

  return url
}

function removeTrailingSlash (url) {
  if (url.endsWith('/')) {
    url = url.substring(0, url.length - 1)
  }

  return url
}

function removeSlashFromBothEnds (url) {
  url = removeLeadingSlash(url)
  url = removeTrailingSlash(url)

  return url
}

function joinURLParts (...urls) {
  urls = urls.filter((url) => url.length > 0)
  urls = [ '' ].concat(urls.map((url) => removeSlashFromBothEnds(url)))

  return urls.join('/')
}

module.exports = {
  splitPath: splitPath,
  removeTrailingSlash: removeTrailingSlash,
  joinURLParts: joinURLParts
}

'''
'''--- src/http/index.js ---
'use strict'

const Hapi = require('hapi')
const Pino = require('hapi-pino')
const debug = require('debug')
const multiaddr = require('multiaddr')
const promisify = require('promisify-es6')

const IPFS = require('../core')
const WStar = require('libp2p-webrtc-star')
const TCP = require('libp2p-tcp')
const MulticastDNS = require('libp2p-mdns')
const WS = require('libp2p-websockets')
const Bootstrap = require('libp2p-bootstrap')
const errorHandler = require('./error-handler')

function uriToMultiaddr (uri) {
  const ipPort = uri.split('/')[2].split(':')
  return `/ip4/${ipPort[0]}/tcp/${ipPort[1]}`
}

class HttpApi {
  constructor (options) {
    this._options = options || {}
    this._log = debug('jsipfs:http-api')
    this._log.error = debug('jsipfs:http-api:error')

    if (process.env.IPFS_MONITORING) {
      // Setup debug metrics collection
      const prometheusClient = require('prom-client')
      const prometheusGcStats = require('prometheus-gc-stats')
      const collectDefaultMetrics = prometheusClient.collectDefaultMetrics
      collectDefaultMetrics({ timeout: 5000 })
      prometheusGcStats(prometheusClient.register)()
    }
  }

  async start () {
    this._log('starting')

    const libp2p = { modules: {} }

    // Attempt to use any of the WebRTC versions available globally
    let electronWebRTC
    let wrtc
    try {
      electronWebRTC = require('electron-webrtc')()
    } catch (err) {
      this._log('failed to load optional electron-webrtc dependency')
    }
    try {
      wrtc = require('wrtc')
    } catch (err) {
      this._log('failed to load optional webrtc dependency')
    }

    if (wrtc || electronWebRTC) {
      const using = wrtc ? 'wrtc' : 'electron-webrtc'
      this._log(`Using ${using} for webrtc support`)
      const wstar = new WStar({ wrtc: (wrtc || electronWebRTC) })
      libp2p.modules.transport = [TCP, WS, wstar]
      libp2p.modules.peerDiscovery = [MulticastDNS, Bootstrap, wstar.discovery]
    }

    // start the daemon
    const ipfsOpts = Object.assign({ init: false }, this._options, { start: true, libp2p })
    const ipfs = new IPFS(ipfsOpts)

    await new Promise((resolve, reject) => {
      ipfs.once('error', err => {
        this._log('error starting core', err)
        err.code = 'ENOENT'
        reject(err)
      })
      ipfs.once('start', resolve)
    })

    this._ipfs = ipfs

    const config = await ipfs.config.get()

    const apiAddr = config.Addresses.API.split('/')
    const apiServer = await this._createApiServer(apiAddr[2], apiAddr[4], ipfs)
    await apiServer.start()
    apiServer.info.ma = uriToMultiaddr(apiServer.info.uri)
    this._apiServer = apiServer

    // for the CLI to know the where abouts of the API
    await promisify(ipfs._repo.apiAddr.set)(apiServer.info.ma)

    const gatewayAddr = config.Addresses.Gateway.split('/')
    const gatewayServer = await this._createGatewayServer(gatewayAddr[2], gatewayAddr[4], ipfs)
    await gatewayServer.start()
    gatewayServer.info.ma = uriToMultiaddr(gatewayServer.info.uri)
    this._gatewayServer = gatewayServer

    ipfs._print('API listening on %s', apiServer.info.ma)
    ipfs._print('Gateway (read only) listening on %s', gatewayServer.info.ma)
    ipfs._print('Web UI available at %s', apiServer.info.uri + '/webui')
    this._log('started')
    return this
  }

  async _createApiServer (host, port, ipfs) {
    const server = Hapi.server({
      host,
      port,
      // CORS is enabled by default
      // TODO: shouldn't, fix this
      routes: {
        cors: true
      }
    })
    server.app.ipfs = ipfs

    await server.register({
      plugin: Pino,
      options: {
        prettyPrint: process.env.NODE_ENV !== 'production',
        logEvents: ['onPostStart', 'onPostStop', 'response', 'request-error'],
        level: process.env.DEBUG ? 'debug' : 'error'
      }
    })

    const setHeader = (key, value) => {
      server.ext('onPreResponse', (request, h) => {
        const { response } = request
        if (response.isBoom) {
          response.output.headers[key] = value
        } else {
          response.header(key, value)
        }
        return h.continue
      })
    }

    // Set default headers
    setHeader('Access-Control-Allow-Headers',
      'X-Stream-Output, X-Chunked-Output, X-Content-Length')
    setHeader('Access-Control-Expose-Headers',
      'X-Stream-Output, X-Chunked-Output, X-Content-Length')

    server.route(require('./api/routes'))

    errorHandler(server)

    return server
  }

  async _createGatewayServer (host, port, ipfs) {
    const server = Hapi.server({ host, port })
    server.app.ipfs = ipfs

    await server.register({
      plugin: Pino,
      options: {
        prettyPrint: Boolean(process.env.DEBUG),
        logEvents: ['onPostStart', 'onPostStop', 'response', 'request-error'],
        level: process.env.DEBUG ? 'debug' : 'error'
      }
    })

    server.route(require('./gateway/routes'))

    return server
  }

  get apiAddr () {
    if (!this._apiServer) throw new Error('API address unavailable - server is not started')
    return multiaddr('/ip4/127.0.0.1/tcp/' + this._apiServer.info.port)
  }

  async stop () {
    this._log('stopping')
    await Promise.all([
      this._apiServer && this._apiServer.stop(),
      this._gatewayServer && this._gatewayServer.stop(),
      this._ipfs && this._ipfs.stop()
    ])
    this._log('stopped')
    return this
  }
}

module.exports = HttpApi

'''
'''--- src/index.js ---
'use strict'

const IPFS = require('./core')

exports = module.exports = IPFS

'''
'''--- src/utils/cid.js ---
'use strict'

const CID = require('cids')

/**
* Stringify a CID encoded in the requested base, upgrading to v1 if necessary.
*
* Setting upgrade to false will disable automatic CID upgrading from v0 to v1
* which is necessary if the multibase is something other than base58btc. Note
* that it will also not apply the encoding (since v0 CIDs can only be encoded
* as base58btc).
*
* @param {CID|Buffer|String} cid The CID to encode
* @param {Object} [options] Optional options
* @param {String} [options.base] Name of multibase codec to encode the CID with
* @param {Boolean} [options.upgrade] Automatically upgrade v0 CIDs to v1 when
* necessary. Default: true.
* @returns {String}
*/
exports.cidToString = (cid, options) => {
  options = options || {}
  options.base = options.base || null
  options.upgrade = options.upgrade !== false

  if (!CID.isCID(cid)) {
    cid = new CID(cid)
  }

  if (cid.version === 0 && options.base && options.base !== 'base58btc') {
    if (!options.upgrade) return cid.toString()
    cid = cid.toV1()
  }

  return cid.toBaseEncodedString(options.base)
}

'''
'''--- src/utils/files/glob-source.js ---
'use strict'

const fs = require('fs')
const Path = require('path')
const pull = require('pull-stream')
const glob = require('glob')
const cat = require('pull-cat')
const defer = require('pull-defer')
const pushable = require('pull-pushable')
const map = require('async/map')
const errCode = require('err-code')

/**
* Create a pull stream source that can be piped to ipfs.addPullStream for the
* provided file paths.
*
* @param {String} ...paths File system path(s) to glob from
* @param {Object} [options] Optional options
* @param {Boolean} [options.recursive] Recursively glob all paths in directories
* @param {Boolean} [options.hidden] Include .dot files in matched paths
* @param {Array<String>} [options.ignore] Glob paths to ignore
* @param {Boolean} [options.followSymlinks] follow symlinks
* @returns {Function} pull stream source
*/
module.exports = (...args) => {
  const options = typeof args[args.length - 1] === 'string' ? {} : args.pop()
  const paths = args
  const deferred = defer.source()

  const globSourceOptions = {
    recursive: options.recursive,
    glob: {
      dot: Boolean(options.hidden),
      ignore: Array.isArray(options.ignore) ? options.ignore : [],
      follow: options.followSymlinks != null ? options.followSymlinks : true
    }
  }

  // Check the input paths comply with options.recursive and convert to glob sources
  map(paths, pathAndType, (err, results) => {
    if (err) return deferred.abort(err)

    try {
      const sources = results.map(res => toGlobSource(res, globSourceOptions))
      deferred.resolve(cat(sources))
    } catch (err) {
      deferred.abort(err)
    }
  })

  return pull(
    deferred,
    pull.map(({ path, contentPath }) => ({
      path,
      content: fs.createReadStream(contentPath)
    }))
  )
}

function toGlobSource ({ path, type }, options) {
  options = options || {}

  const baseName = Path.basename(path)

  if (type === 'file') {
    return pull.values([{ path: baseName, contentPath: path }])
  }

  if (type === 'dir' && !options.recursive) {
    throw errCode(
      new Error(`'${path}' is a directory and recursive option not set`),
      'ERR_DIR_NON_RECURSIVE',
      { path }
    )
  }

  const globOptions = Object.assign({}, options.glob, {
    cwd: path,
    nodir: true,
    realpath: false,
    absolute: false
  })

  // TODO: want to use pull-glob but it doesn't have the features...
  const pusher = pushable()

  glob('**/*', globOptions)
    .on('match', m => pusher.push(m))
    .on('end', () => pusher.end())
    .on('abort', () => pusher.end())
    .on('error', err => pusher.end(err))

  return pull(
    pusher,
    pull.map(p => ({
      path: `${baseName}/${toPosix(p)}`,
      contentPath: Path.join(path, p)
    }))
  )
}

function pathAndType (path, cb) {
  fs.stat(path, (err, stat) => {
    if (err) return cb(err)
    cb(null, { path, type: stat.isDirectory() ? 'dir' : 'file' })
  })
}

const toPosix = path => path.replace(/\\/g, '/')

'''
'''--- test/bootstrapers.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const IPFS = require('..')
const IPFSFactory = require('ipfsd-ctl')
const bootstrapList = require('../src/core/runtime/config-browser.js')().Bootstrap
const waitFor = require('./utils/wait-for')

/*
 * These tests were graciously made for lgierth, so that he can test the
 * WebSockets Bootstrappers easily <3
 */
describe('Check that a js-ipfs node can indeed contact the bootstrappers', () => {
  let ipfsd

  before(function (done) {
    this.timeout(30 * 1000)

    const factory = IPFSFactory.create({ type: 'proc', exec: IPFS })

    factory.spawn({
      config: {
        Addresses: {
          Swarm: []
        }
      }
    }, (err, node) => {
      expect(err).to.not.exist()
      ipfsd = node
      done()
    })
  })

  after(done => ipfsd.stop(done))

  it('a node connects to bootstrappers', function (done) {
    this.timeout(2 * 60 * 1000)

    const test = (cb) => {
      ipfsd.api.swarm.peers((err, peers) => {
        if (err) return cb(err)

        const peerList = peers.map((peer) => peer.addr.toString())

        if (peerList.length !== bootstrapList.length) {
          return cb(null, false)
        }

        cb(null, bootstrapList.every(addr => peerList.includes(addr)))
      })
    }

    waitFor(test, { name: 'connect to all bootstrap nodes', timeout: 60 * 1000 }, done)
  })
})

'''
'''--- test/cli/bitswap.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOn = require('../utils/on-and-off').on
const PeerId = require('peer-id')
const CID = require('cids')
const waitFor = require('../utils/wait-for')

describe('bitswap', () => runOn((thing) => {
  let ipfs
  let peerId
  const key0 = 'QmUBdnXXPyoDFXj3Hj39dNJ5VkN3QFRskXxcGaYFBB8CNR'
  const key1 = 'zb2rhafnd6kEUujnoMkozHnWXY7XpWttyVDWKXfChqA42VTDU'

  before(() => {
    ipfs = thing.ipfs
  })

  before(() => {
    ipfs('block get ' + key0).catch(() => {})
    ipfs('block get ' + key1).catch(() => {})
  })

  before(function (done) {
    this.timeout(60 * 1000)

    PeerId.create({ bits: 512 }, (err, peer) => {
      expect(err).to.not.exist()
      peerId = peer.toB58String()
      done()
    })
  })

  before(function (done) {
    this.timeout(2 * 60 * 1000)

    const test = (cb) => {
      ipfs('bitswap wantlist')
        .then(out => cb(null, out.includes(key0) && out.includes(key1)))
        .catch(cb)
    }

    waitFor(test, {
      name: `${key0} and ${key1} to be wanted`,
      timeout: 60 * 1000
    }, done)
  })

  it('wantlist', function () {
    this.timeout(20 * 1000)
    return ipfs('bitswap wantlist').then((out) => {
      expect(out).to.include(key0)
      expect(out).to.include(key1)
    })
  })

  it('should get wantlist with CIDs encoded in specified base', function () {
    this.timeout(20 * 1000)
    return ipfs('bitswap wantlist --cid-base=base64').then((out) => {
      expect(out).to.include(new CID(key1).toBaseEncodedString('base64') + '\n')
    })
  })

  it('wantlist peerid', function () {
    this.timeout(20 * 1000)
    return ipfs('bitswap wantlist ' + peerId).then((out) => {
      expect(out).to.eql('')
    })
  })

  it('stat', function () {
    this.timeout(20 * 1000)

    return ipfs('bitswap stat').then((out) => {
      expect(out).to.include([
        'bitswap status',
        '  blocks received: 0',
        '  dup blocks received: 0',
        '  dup data received: 0B',
        // We sometimes pick up partners while the tests run and the order of
        // wanted keys is not defined so our assertion ends here.
        '  wantlist [2 keys]'
      ].join('\n'))

      expect(out).to.include(key0)
      expect(out).to.include(key1)
    })
  })

  it('should get stats with wantlist CIDs encoded in specified base', function () {
    this.timeout(20 * 1000)
    return ipfs('bitswap stat --cid-base=base64').then((out) => {
      expect(out).to.include(new CID(key1).toBaseEncodedString('base64'))
    })
  })

  it('unwant', function () {
    return ipfs('bitswap unwant ' + key0).then((out) => {
      expect(out).to.eql(`Key ${key0} removed from wantlist\n`)
    })
  })
}))

'''
'''--- test/cli/block.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('block', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('put', function () {
    this.timeout(40 * 1000)
    return ipfs('block put test/fixtures/test-data/hello').then((out) => {
      expect(out).to.eql('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp\n')
    })
  })

  it('put with flags, format and mhtype', function () {
    this.timeout(40 * 1000)

    return ipfs('block put --format eth-block --mhtype keccak-256 test/fixtures/test-data/eth-block')
      .then((out) =>
        expect(out).to.eql('z43AaGF23fmvRnDP56Ub9WcJCfzSfqtmzNCCvmz5eudT8dtdCDS\n'))
  })

  it('should put and print CID encoded in specified base', function () {
    this.timeout(40 * 1000)

    return ipfs('block put test/fixtures/test-data/hello --cid-base=base64').then((out) => {
      expect(out).to.eql('mAXASIKlIkE8vD0ebj4GXaUswGEsNLtHBzSoewPuF0pmhkqRH\n')
    })
  })

  it('get', function () {
    this.timeout(40 * 1000)

    return ipfs('block get QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp')
      .then((out) => expect(out).to.eql('hello world\n'))
  })

  it('get block from file without a final newline', function () {
    this.timeout(40 * 1000)

    return ipfs('block put test/fixtures/test-data/no-newline').then((out) => {
      expect(out).to.eql('QmTwbQs4sGcCiPxV97SpbHS7QgmVg9SiKxcG1AcF1Ly2SL\n')
      return ipfs('block get QmTwbQs4sGcCiPxV97SpbHS7QgmVg9SiKxcG1AcF1Ly2SL')
    })
      .then((out) => expect(out).to.eql('there is no newline at end of this file'))
  })

  it('stat', function () {
    this.timeout(40 * 1000)

    return ipfs('block stat QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp')
      .then((out) => {
        expect(out).to.eql([
          'Key: QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp',
          'Size: 12'
        ].join('\n') + '\n')
      })
  })

  it('should stat and print CID encoded in specified base', function () {
    this.timeout(80 * 1000)

    return ipfs('block put test/fixtures/test-data/hello')
      .then((out) => {
        expect(out).to.eql('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp\n')
        return ipfs('block stat QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp --cid-base=base64')
      })
      .then((out) => {
        expect(out).to.eql([
          'Key: mAXASIKlIkE8vD0ebj4GXaUswGEsNLtHBzSoewPuF0pmhkqRH',
          'Size: 12'
        ].join('\n') + '\n')
      })
  })

  it.skip('rm', function () {
    this.timeout(40 * 1000)

    return ipfs('block rm QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp')
      .then((out) => {
        expect(out).to.eql(
          'removed QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp\n'
        )
      })
  })
}))

'''
'''--- test/cli/bootstrap.js ---
/* eslint max-nested-callbacks: ['error', 8] */
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('bootstrap', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  const defaultList = [
    '/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
    '/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6'
  ]

  const updatedList = [
    '/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
    '/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',
    '/ip4/111.111.111.111/tcp/1001/ipfs/QmcyFFKfLDGJKwufn2GeitxvhricsBQyNKTkrD14psikoD'
  ]

  it('add default', function () {
    this.timeout(40 * 1000)

    return ipfs('bootstrap add --default').then((out) => {
      expect(out).to.equal(defaultList.join('\n') + '\n')
    })
  })

  it('list the bootstrap nodes', function () {
    this.timeout(40 * 1000)

    return ipfs('bootstrap list').then((out) => {
      expect(out).to.equal(defaultList.join('\n') + '\n')
    })
  })

  it('add another bootstrap node', function () {
    this.timeout(40 * 1000)

    return ipfs('bootstrap add /ip4/111.111.111.111/tcp/1001/ipfs/QmcyFFKfLDGJKwufn2GeitxvhricsBQyNKTkrD14psikoD').then((out) => {
      expect(out).to.equal('/ip4/111.111.111.111/tcp/1001/ipfs/QmcyFFKfLDGJKwufn2GeitxvhricsBQyNKTkrD14psikoD\n')
      return ipfs('bootstrap list')
    }).then((out) => expect(out).to.equal(updatedList.join('\n') + '\n'))
  })

  it('rm a bootstrap node', function () {
    this.timeout(40 * 1000)

    return ipfs('bootstrap rm /ip4/111.111.111.111/tcp/1001/ipfs/QmcyFFKfLDGJKwufn2GeitxvhricsBQyNKTkrD14psikoD').then((out) => {
      expect(out).to.equal('/ip4/111.111.111.111/tcp/1001/ipfs/QmcyFFKfLDGJKwufn2GeitxvhricsBQyNKTkrD14psikoD\n')
      return ipfs('bootstrap list')
    }).then((out) => {
      expect(out).to.equal(defaultList.join('\n') + '\n')
    })
  })

  it('rm all bootstrap nodes', function () {
    this.timeout(40 * 1000)

    return ipfs('bootstrap rm --all').then((out) => {
      expect(out).to.equal('')
      return ipfs('bootstrap list')
    }).then((out) => {
      expect(out).to.equal('')
    })
  })
}))

'''
'''--- test/cli/commands.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

const commandCount = 93
describe('commands', () => runOnAndOff((thing) => {
  let ipfs

  before(function () {
    this.timeout(30 * 1000)
    ipfs = thing.ipfs
  })

  it('list the commands', () => {
    return ipfs('commands').then((out) => {
      expect(out.split('\n')).to.have.length(commandCount + 1)
    })
  })
}))

'''
'''--- test/cli/config.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const fs = require('fs')
const path = require('path')
const runOnAndOff = require('../utils/on-and-off')

describe('config', () => runOnAndOff((thing) => {
  let ipfs
  let configPath
  let originalConfigPath
  let updatedConfig
  let restoreConfig

  before(() => {
    ipfs = thing.ipfs
    configPath = path.join(ipfs.repoPath, 'config')
    originalConfigPath = path.join(__dirname, '../fixtures/go-ipfs-repo/config')
    updatedConfig = () => JSON.parse(fs.readFileSync(configPath, 'utf8'))
    restoreConfig = () => fs.writeFileSync(configPath, fs.readFileSync(originalConfigPath, 'utf8'), 'utf8')
  })

  describe('get/set', function () {
    this.timeout(40 * 1000)

    it('set a config key with a string value', () => {
      return ipfs('config foo bar').then((out) => {
        expect(updatedConfig().foo).to.equal('bar')
      })
    })

    it('set a config key with true', () => {
      return ipfs('config foo true --bool').then((out) => {
        expect(updatedConfig().foo).to.equal(true)
      })
    })

    it('set a config key with false', () => {
      return ipfs('config foo false --bool').then((out) => {
        expect(updatedConfig().foo).to.equal(false)
      })
    })

    it('set a config key with null', () => {
      return ipfs('config foo null --json').then((out) => {
        expect(updatedConfig().foo).to.equal(null)
      })
    })

    it('set a config key with json', () => {
      return ipfs('config foo {"bar":0} --json').then((out) => {
        expect(updatedConfig().foo).to.deep.equal({ bar: 0 })
      })
    })

    it('set a config key with invalid json', () => {
      return ipfs.fail('config foo {"bar:0} --json')
    })

    it('get a config key value', () => {
      return ipfs('config Identity.PeerID').then((out) => {
        expect(out).to.exist()
      })
    })

    it('call config with no arguments', () => {
      return ipfs('config')
        .then(out => expect(out).to.include('bin.js config <key> [value]'))
    })
  })

  describe('show', function () {
    this.timeout(40 * 1000)

    it('returns the full config', () => {
      return ipfs('config show').then((out) => {
        expect(JSON.parse(out)).to.be.eql(updatedConfig())
      })
    })
  })

  describe.skip('replace', () => {
    it('replace config with file', () => {
      const filePath = 'test/fixtures/test-data/otherconfig'
      const expectedConfig = JSON.parse(fs.readFileSync(filePath, 'utf8'))

      return ipfs(`config replace ${filePath}`).then((out) => {
        expect(updatedConfig()).to.be.eql(expectedConfig)
      })
    })

    after(() => {
      restoreConfig()
    })
  })
}))

'''
'''--- test/cli/daemon.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const clean = require('../utils/clean')
const ipfsCmd = require('../utils/ipfs-exec')
const isWindows = require('../utils/platforms').isWindows
const os = require('os')
const path = require('path')
const hat = require('hat')
const fs = require('fs')

const skipOnWindows = isWindows() ? it.skip : it

const checkLock = (repo, cb) => {
  // skip on windows
  // https://github.com/ipfs/js-ipfsd-ctl/pull/155#issuecomment-326983530
  if (!isWindows) {
    if (fs.existsSync(path.join(repo, 'repo.lock'))) {
      cb(new Error('repo.lock not removed'))
    }
    if (fs.existsSync(path.join(repo, 'api'))) {
      cb(new Error('api file not removed'))
    }
  }
  cb()
}

function testSignal (ipfs, sig) {
  return ipfs('init').then(() => {
    return ipfs('config', 'Addresses', JSON.stringify({
      API: '/ip4/127.0.0.1/tcp/0',
      Gateway: '/ip4/127.0.0.1/tcp/0'
    }), '--json')
  }).then(() => {
    const proc = ipfs('daemon')
    return new Promise((resolve, reject) => {
      proc.stdout.on('data', (data) => {
        if (data.toString().includes(`Daemon is ready`)) {
          if (proc.kill(sig)) {
            resolve()
          } else {
            reject(new Error(`Unable to ${sig} process`))
          }
        }
      })
      proc.stderr.on('data', (data) => {
        if (data.toString().length > 0) {
          reject(new Error(data))
        }
      })
    })
  })
}

describe('daemon', () => {
  let repoPath
  let ipfs

  beforeEach(() => {
    repoPath = path.join(os.tmpdir(), 'ipfs-test-not-found-' + hat())
    ipfs = ipfsCmd(repoPath)
  })

  afterEach(() => clean(repoPath))

  skipOnWindows('do not crash if Addresses.Swarm is empty', function (done) {
    this.timeout(100 * 1000)
    // These tests are flaky, but retrying 3 times seems to make it work 99% of the time
    this.retries(3)

    ipfs('init').then(() => {
      return ipfs('config', 'Addresses', JSON.stringify({
        Swarm: [],
        API: '/ip4/127.0.0.1/tcp/0',
        Gateway: '/ip4/127.0.0.1/tcp/0'
      }), '--json')
    }).then(() => {
      const res = ipfs('daemon')
      const timeout = setTimeout(() => {
        done(new Error('Daemon did not get ready in time'))
      }, 1000 * 120)
      res.stdout.on('data', (data) => {
        const line = data.toString()
        if (line.includes('Daemon is ready')) {
          clearTimeout(timeout)
          res.kill()
          done()
        }
      })
    }).catch(err => done(err))
  })

  skipOnWindows('should handle SIGINT gracefully', function (done) {
    this.timeout(100 * 1000)

    testSignal(ipfs, 'SIGINT').then(() => {
      checkLock(repoPath, done)
    }).catch(done)
  })

  skipOnWindows('should handle SIGTERM gracefully', function (done) {
    this.timeout(100 * 1000)

    testSignal(ipfs, 'SIGTERM').then(() => {
      checkLock(repoPath, done)
    }).catch(done)
  })

  skipOnWindows('should handle SIGHUP gracefully', function (done) {
    this.timeout(100 * 1000)

    testSignal(ipfs, 'SIGHUP').then(() => {
      checkLock(repoPath, done)
    }).catch(done)
  })

  it('gives error if user hasn\'t run init before', function (done) {
    this.timeout(100 * 1000)

    const expectedError = 'no initialized ipfs repo found in ' + repoPath

    ipfs('daemon').catch((err) => {
      expect(err.stdout).to.have.string(expectedError)
      done()
    })
  })

  it('should be silent', function (done) {
    this.timeout(10 * 1000)
    const res = ipfs('daemon --silent')
    res.catch(function () {}) // Handles the unhandled promise rejection
    let output = ''
    const onData = (d) => { output += d }
    res.stdout.on('data', onData)
    res.stderr.on('data', onData)
    setTimeout(function () {
      res.kill()
      expect(output).to.be.empty()
      done()
    }, 5 * 1000)
  })

  it('should present ipfs path help when option help is received', function (done) {
    this.timeout(100 * 1000)

    ipfs('daemon --help').then((res) => {
      expect(res).to.have.string('export IPFS_PATH=/path/to/ipfsrepo')
      done()
    })
  })
})

'''
'''--- test/cli/dag.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('dag', () => runOnAndOff.off((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('get', function () {
    this.timeout(20 * 1000)

    // put test eth-block
    return ipfs('block put --format eth-block --mhtype keccak-256 test/fixtures/test-data/eth-block').then((out) => {
      expect(out).to.eql('z43AaGF23fmvRnDP56Ub9WcJCfzSfqtmzNCCvmz5eudT8dtdCDS\n')
      // lookup path on eth-block
      return ipfs('dag get z43AaGF23fmvRnDP56Ub9WcJCfzSfqtmzNCCvmz5eudT8dtdCDS/parentHash')
    }).then((out) => {
      let expectHash = Buffer.from('c8c0a17305adea9bbb4b98a52d44f0c1478f5c48fc4b64739ee805242501b256', 'hex')
      expect(out).to.be.eql('0x' + expectHash.toString('hex') + '\n')
    })
  })
}))

'''
'''--- test/cli/dht.js ---
/* eslint-env mocha */

'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const series = require('async/series')
const parallel = require('async/parallel')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'js' })

const ipfsExec = require('../utils/ipfs-exec')

const daemonOpts = {
  exec: `./src/cli/bin.js`,
  config: {
    Bootstrap: [],
    Discovery: {
      MDNS: {
        Enabled: false
      },
      webRTCStar: {
        Enabled: false
      }
    }
  },
  initOptions: { bits: 512 }
}

describe('dht', () => {
  let nodes = []
  let ipfsA
  let ipfsB
  let idA
  let idB
  let multiaddrB

  // spawn daemons
  before(function (done) {
    this.timeout(80 * 1000)
    series([
      (cb) => df.spawn(daemonOpts, (err, _ipfsd) => {
        expect(err).to.not.exist()

        ipfsA = ipfsExec(_ipfsd.repoPath)
        nodes.push(_ipfsd)
        cb()
      }),
      (cb) => df.spawn(daemonOpts, (err, _ipfsd) => {
        expect(err).to.not.exist()

        ipfsB = ipfsExec(_ipfsd.repoPath)
        nodes.push(_ipfsd)
        cb()
      })
    ], done)
  })

  // get ids
  before(function (done) {
    this.timeout(80 * 1000)
    parallel([
      (cb) => nodes[0].api.id((err, res) => {
        expect(err).to.not.exist()

        idA = res.id
        cb()
      }),
      (cb) => nodes[1].api.id((err, res) => {
        expect(err).to.not.exist()

        multiaddrB = res.addresses[0]
        idB = res.id
        cb()
      })
    ], done)
  })

  // connect daemons
  before(function (done) {
    this.timeout(80 * 1000)

    nodes[0].api.swarm.connect(multiaddrB, done)
  })

  after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

  it('should be able to put a value to the dht and get it afterwards', function () {
    this.timeout(60 * 1000)

    const key = 'testkey'
    const value = 'testvalue'

    return ipfsA(`dht put ${key} ${value}`)
      .then((res) => {
        expect(res).to.exist()

        return ipfsB(`dht get ${key}`)
      })
      .then((res) => {
        expect(res).to.exist()
        expect(res).to.have.string(value)
      })
  })

  it('should be able to provide data and to be present in the findproviders', function () {
    this.timeout(60 * 1000)
    let cidAdded

    return ipfsA('add src/init-files/init-docs/readme')
      .then((res) => {
        expect(res).to.exist()
        cidAdded = res.split(' ')[1]

        return ipfsA(`dht provide ${cidAdded}`)
      })
      .then((res) => {
        expect(res).to.exist()

        return ipfsB(`dht findprovs ${cidAdded}`)
      })
      .then((res) => {
        expect(res).to.exist()
        expect(res).to.have.string(idA)
      })
  })

  it('findpeer', function () {
    this.timeout(60 * 1000)

    return ipfsA(`dht findpeer ${idB}`)
      .then((res) => {
        expect(res).to.exist()
        expect(res).to.have.string(multiaddrB)
      })
  })

  it('query', function () {
    this.timeout(60 * 1000)

    return ipfsA(`dht query ${idB}`)
      .then((res) => {
        expect(res).to.exist()
        expect(res).to.have.string(idB)
      })
  })
})

'''
'''--- test/cli/dns.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('dns', () => runOnAndOff((thing) => {
  let ipfs

  before(function () {
    this.timeout(60 * 1000)
    ipfs = thing.ipfs
  })

  it('resolve ipfs.io dns', function () {
    this.timeout(60 * 1000)

    return ipfs('dns ipfs.io').then((res) => {
      expect(res.substr(0, 6)).to.eql('/ipns/')
    })
  })

  it('resolve _dnslink.ipfs.io dns', function () {
    this.timeout(60 * 1000)

    return ipfs('dns _dnslink.ipfs.io').then((res) => {
      expect(res.substr(0, 6)).to.eql('/ipns/')
    })
  })
}))

'''
'''--- test/cli/file.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')
const file = 'QmR56UJmAaZLXLdTT1ALrE9vVqV8soUEekm9BMd4FnuYqV'
const dir = 'Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z'

describe('file ls', () => runOnAndOff((thing) => {
  let ipfs

  before(function () {
    this.timeout(50 * 1000)
    ipfs = thing.ipfs
    return ipfs('add -r test/fixtures/test-data/recursive-get-dir')
  })

  it('prints a filename', () => {
    return ipfs(`file ls ${file}`)
      .then((out) => expect(out).to.eql(
        `This functionality is deprecated, and will be removed in future versions. If possible, please use 'ipfs ls' instead.\n` +
        `${file}\n`
      ))
  })

  it('prints the filenames in a directory', () => {
    return ipfs(`file ls ${dir}`)
      .then((out) => expect(out).to.eql(
        `This functionality is deprecated, and will be removed in future versions. If possible, please use 'ipfs ls' instead.\n` +
        'QmamKEPmEH9RUsqRQsfNf5evZQDQPYL9KXg1ADeT7mkHkT\n' +
        'QmPkWYfSLCEBLZu7BZt4kigGDMe3cpogMbeVf97gN2xJDN\n' +
        'QmUqyZtPmsRy1U5Mo8kz2BAMmk1hfJ7yW1KAFTMB2odsFv\n' +
        'QmUhUuiTKkkK8J6JZ9zmj8iNHPuNfGYcszgRumzhHBxEEU\n' +
        'QmR56UJmAaZLXLdTT1ALrE9vVqV8soUEekm9BMd4FnuYqV\n'
      ))
  })
}))

'''
'''--- test/cli/files.js ---
/* eslint-env mocha */
'use strict'

const fs = require('fs')
const os = require('os')
const expect = require('chai').expect
const path = require('path')
const hat = require('hat')
const compareDir = require('dir-compare').compareSync
const rimraf = require('rimraf').sync
const CID = require('cids')
const mh = require('multihashes')
const runOnAndOff = require('../utils/on-and-off')
const clean = require('../utils/clean')

// TODO: Test against all algorithms Object.keys(mh.names)
// This subset is known to work with both go-ipfs and js-ipfs as of 2017-09-05
const HASH_ALGS = [
  'sha1',
  'sha2-256',
  'sha2-512',
  'keccak-224',
  'keccak-256',
  'keccak-384',
  'keccak-512'
]

describe('files', () => runOnAndOff((thing) => {
  let ipfs
  const readme = fs.readFileSync(path.join(process.cwd(), '/src/init-files/init-docs/readme'))
    .toString('utf-8')

  const recursiveGetDirResults = [
    'added QmR56UJmAaZLXLdTT1ALrE9vVqV8soUEekm9BMd4FnuYqV recursive-get-dir/version',
    'added QmYE7xo6NxbHEVEHej1yzxijYaNY51BaeKxjXxn6Ssa6Bs recursive-get-dir/init-docs/tour/0.0-intro',
    'added QmciSU8hfpAXKjvK5YLUSwApomGSWN5gFbP4EpDAEzu2Te recursive-get-dir/init-docs/tour',
    'added QmTumTjvcYCAvRRwQ8sDRxh8ezmrcr88YFU7iYNroGGTBZ recursive-get-dir/init-docs/security-notes',
    'added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB recursive-get-dir/init-docs/readme',
    'added QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha recursive-get-dir/init-docs/quick-start',
    'added QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7 recursive-get-dir/init-docs/help',
    'added QmQN88TEidd3RY2u3dpib49fERTDfKtDpvxnvczATNsfKT recursive-get-dir/init-docs/docs/index',
    'added QmegvLXxpVKiZ4b57Xs1syfBVRd8CbucVHAp7KpLQdGieC recursive-get-dir/init-docs/docs',
    'added QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y recursive-get-dir/init-docs/contact',
    'added QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V recursive-get-dir/init-docs/about',
    'added QmUhUuiTKkkK8J6JZ9zmj8iNHPuNfGYcszgRumzhHBxEEU recursive-get-dir/init-docs',
    'added QmeiTxVN4xAjxUzHzBqCpK3GaT3GeiLQeJRpYDXDfLeEmR recursive-get-dir/datastore/MANIFEST-000014',
    'added QmQpc75sJGUv59dAwHF7vazBGV9o6C7z587Dp9nv7HYAps recursive-get-dir/datastore/LOG.old',
    'added QmbFNLNr9at9eK5LrNyUdyE5cdLb5yaT9DkjXw7BK68kcM recursive-get-dir/datastore/LOG',
    'added QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH recursive-get-dir/datastore/LOCK',
    'added QmVJi93Yj5RW3NuqqxonGz3jAXUYHrdQvWrURxg1TiLEuX recursive-get-dir/datastore/CURRENT',
    'added QmcJ6TXPMPm6puSC9vpxuG57PyfGpr8bvTgkKU9SHHU5Uo recursive-get-dir/datastore/000010.ldb',
    'added QmPFVLPmp9zv5Z5KUqLhe2EivAGccQW2r7M7jhVJGLZoZU recursive-get-dir/datastore/000005.ldb',
    'added QmfExFwdFKspsY2q5WnhQjd1QDKnjpTQ4UkiHqqQxV7h67 recursive-get-dir/datastore/000002.ldb',
    'added QmUqyZtPmsRy1U5Mo8kz2BAMmk1hfJ7yW1KAFTMB2odsFv recursive-get-dir/datastore',
    'added QmPkWYfSLCEBLZu7BZt4kigGDMe3cpogMbeVf97gN2xJDN recursive-get-dir/config',
    'added QmbJgQa4XNBFvGQcLbWBNtvWZetbCUKiyAQNfePoTzwf9L recursive-get-dir/blocks/CIQPD/CIQPDQJBGYDZNMOAGGYNRNMP2VDKWBWGAEDDEJDACM3SGG3VIANDDXI.data',
    'added QmSCUPYy4CfFt9nA61J9v2DMfJygQAJjaUcRmygDbVME2D recursive-get-dir/blocks/CIQPD',
    'added QmTU72W5EAnNUAtnVW1qoFzdDD8FyiBjpF5MUzjBAFnHS6 recursive-get-dir/blocks/CIQOY/CIQOYW2THIZBRGI7IN33ROGCKOFZLXJJ2MPKYZBTV4H3N7GYHXMAO6A.data',
    'added QmQ1mNtPTJ6JG3TNNq73m2orvsfKCKrqMKoXyXwRKWM1ma recursive-get-dir/blocks/CIQOY',
    'added QmaTXag3TaaG6hFUXGxybEuMUk7UHSutZobZgDtjr6aXjf recursive-get-dir/blocks/CIQON/CIQONICFQZH7QVU6IPSIM3AK7AD554D3BWZPAGEAQYQOWMFZQDUUAEI.data',
    'added QmNi9kKnfKJGuofhBRKMdKj5R6BQAYHWRtu3vXJHRy69TE recursive-get-dir/blocks/CIQON',
    'added QmTH5Jc2uhu5LqGEFAgrn2HwoDHLpvQd9b6fyoUGi6aeQu recursive-get-dir/blocks/CIQOM/CIQOMBKARLB7PAITVSNH7VEGIQJRPL6J7FT2XYVKAXT4MQPXXPUYUNY.data',
    'added Qmec4atiyfysPR8HU5gPfjKY1NpQDY2kmSeeadx8wLEBqY recursive-get-dir/blocks/CIQOM',
    'added QmeBypQ2yE4t4Loybhby15DjkeLDXJKCcgMfxTXeFnHa8F recursive-get-dir/blocks/CIQOL/CIQOLBQZSZAODJGGH6RYYVBUXHTS3SM5EORZDU63LYPEFUAFE4SBM4I.data',
    'added Qmd6s8LXAEjW7y9QbGSzeuewrRBYjJHmcazG3Hk7cJ74da recursive-get-dir/blocks/CIQOL',
    'added QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH recursive-get-dir/blocks/CIQOH/CIQOHMGEIKMPYHAUTL57JSEZN64SIJ5OIHSGJG4TJSSJLGI3PBJLQVI.data',
    'added QmTnaav9VTSVyLu8PvRzh4gJ8heF9rpdWzeDb7rMx5DkxV recursive-get-dir/blocks/CIQOH',
    'added Qmc1nasezDdPyZiXB5VB6Aygzswcr6QkauzzXMeUGouHTN recursive-get-dir/blocks/CIQMB/CIQMB7DLJFKD267QJ2B5FJNHZPTSVA7IB6OHXSQ2XSVEEKMKK6RT75I.data',
    'added QmeqJBkwmzsVR79HBKLW7AYhfAMxMaJs5dGHSgey5ezy7N recursive-get-dir/blocks/CIQMB',
    'added QmaSjzSSRanYzRGPXQY6m5SWfSkkfcnzNkurJEQc4chPJx recursive-get-dir/blocks/CIQLB/CIQLBS5HG4PRCRQ7O4EBXFD5QN6MTI5YBYMCVQJDXPKCOVR6RMLHZFQ.data',
    'added QmQ8ag7ysVyCMzJGFjxrUStwWtniQ69c7G9aezbmsKeNYD recursive-get-dir/blocks/CIQLB/CIQLBK52T5EHVHZY5URTG5JS3JCUJDQM2DRB5RVF33DCUUOFJNGVDUI.data',
    'added Qmbqod68qdYiEs7kkTGu7G59adekUbAFAAg7WEyM6iPP5z recursive-get-dir/blocks/CIQLB',
    'added Qmd4FKC6GcKnhJHnEJJwqg9A1eDd7JXKkG5v3iv9XSHtwq recursive-get-dir/blocks/CIQKK/CIQKKLBWAIBQZOIS5X7E32LQAL6236OUKZTMHPQSFIXPWXNZHQOV7JQ.data',
    'added QmUBsjP45UUHzKymAUqwEFJsuCvfC1AcaLvBgMsoGMipoG recursive-get-dir/blocks/CIQKK',
    'added QmWR1EuH5cui4EW5W16ADxzmYEFPjHDs1LcPe3uQL3CmiS recursive-get-dir/blocks/CIQJG/CIQJGO2B2N75IUEM372FSMG76VV256I4PXBULZZ5ASNLK4FL4EG7XOI.data',
    'added QmWrs7zVFkbpsTEbEpe3MyAB8ssUNp8jamE7i4PZ736zWy recursive-get-dir/blocks/CIQJG',
    'added QmWNXfkCTxSAuFBdNQ8gGmyxnZ28XrzRbjjmvCViLoNU5W recursive-get-dir/blocks/CIQJF/CIQJFGRQHQ45VCQLM7AJNF2GF5UHUAGGHC6LLAH6VYDEKLQMD4QLILY.data',
    'added QmWjsRHRK7ENAhMvgwfkze9bkySxjAsNMGXrMGMsFcrDWU recursive-get-dir/blocks/CIQJF',
    'added QmTt3mbtfVGEfqqjec9WZcWaC4SkesErDPAhhr8NRfsWFp recursive-get-dir/blocks/CIQJB/CIQJBQD2O6K4CGJVCCTJNUP57QHR4SKHZ74OIITBBGLOMCO3ZOLWLGA.data',
    'added QmQebEvyaFbez884asHoTrNsbck1JdMLcM8EhUFYCraGHZ recursive-get-dir/blocks/CIQJB',
    'added Qmb7AKKnZwLLFtseMZiHkq4fKNhP5rSggcvN2oGXUBZv8B recursive-get-dir/blocks/CIQJ2/CIQJ23BL4UHXA2KTI6NLTXZM4PW4VEFWQBJ4ACZQAS37BLGL4HUO5XY.data',
    'added QmT1zKYzUpt2kF8AEV2igH9hXwzGu4q8pc4uJ9BLWqjMhT recursive-get-dir/blocks/CIQJ2',
    'added QmazVLpyExfPkwASngrz3MDZD1pdaBUxj7VqAkjAFAWaa9 recursive-get-dir/blocks/CIQIX/CIQIXBZMUTXFC5QIGMLJNXLLHZOPGSL2PBC65D4UIVWM6TI5F5TAFNI.data',
    'added QmNM7hxdJfaApCJe1ubCrhAQSA6AWQXUvKZrHcf5RxsNvn recursive-get-dir/blocks/CIQIX',
    'added QmRfQcw4qrW91Vqj3evXiH11MuvRVJb7S7vKSgau7aBzRa recursive-get-dir/blocks/CIQHP/CIQHPUVCWD6JA6AFUVD6VA64TGWP67KYA3AIMBUMVWGZ5AQN2L2HSWQ.data',
    'added QmRsyLntZoGPWURqtemAmgRdtmuCjbbdZ5xzkCAEUhh4iU recursive-get-dir/blocks/CIQHP',
    'added QmU7mw6KaaAJA6tHi9FdiHu2HtA6rjb6e1aYuWscwTJ9yV recursive-get-dir/blocks/CIQHB/CIQHBGZNZRPWVEFNMTLP4OS5EAVHFMCX2HD7FZUC2B3WUU3D4LGKS5A.data',
    'added Qma1ytRhbzt3tGcJopMvd7g3ZE38mRKTTuJuRaHmguq8mN recursive-get-dir/blocks/CIQHB',
    'added QmVLdEzvgvM5k7NUWWSgURAZuJmiQBnbuZga3EpRip8xTu recursive-get-dir/blocks/CIQHA/CIQHAKDLTL5GMIFGN5YVY4BA22FPHUIODJEXS4LCTQDWA275XAJDAPI.data',
    'added QmddXWuKjfCbF6HXR9jStKDoLEAZ7xc8SZgDanQLMiGjpn recursive-get-dir/blocks/CIQHA',
    'added QmZe7irS2FotZtsUx9wpy5QPKJF6YEaAEZLHLUwQy6XgY8 recursive-get-dir/blocks/CIQH7/CIQH7OEYWXL34RWYL7VXLWEU4FWPVGT24VJT7DUZPTNLF25N25IGGQA.data',
    'added Qmb5NqTFar7MnxyRwwQtfb81nyS6g5NRG1bdo6AefmvhXU recursive-get-dir/blocks/CIQH7',
    'added QmWGima5TqLfUTzUsCF6h3oXGvwu3QQ1zjZYLDMaGeFRbB recursive-get-dir/blocks/CIQGP/CIQGPALRQ24P6NS4OWHTQ7R247ZI7KJWP3QWPQYS43LFULQC5ANLQFI.data',
    'added QmZMHzPS1qema8HvLk4jRuSLrUjRHZ8Siu6Wc4njAmx8MG recursive-get-dir/blocks/CIQGP',
    'added QmabxyrxY1uUzHcd7mTBCfibFwemGC89vuJFUw4UkebmSn recursive-get-dir/blocks/CIQGF/CIQGFTQ7FSI2COUXWWLOQ45VUM2GUZCGAXLWCTOKKPGTUWPXHBNIVOY.data',
    'added QmYLZ3uqYLkViS7Bh3vxcT5yrPscyWMV11iqFVJnqA7JVT recursive-get-dir/blocks/CIQGF',
    'added QmSMYdQtDTqykd7oLKZq3vJtS7KoWZwjL7GA9zj6UsCngE recursive-get-dir/blocks/CIQFT/CIQFTFEEHEDF6KLBT32BFAGLXEZL4UWFNWM4LFTLMXQBCERZ6CMLX3Y.data',
    'added QmWjMLA3ppmngQaHs8YEQ3Bru4tKoDeJh2cKv7U7dtLUuf recursive-get-dir/blocks/CIQFT',
    'added QmVdfEEiQmem5GanTjja7HKHNFpfa2LB8196fD9m9b656Q recursive-get-dir/blocks/CIQFF/CIQFFRR4O52TS2Z7QLDDTF32OIR4FWLKT5YLL7MLDVIT7DC3NHOK5VA.data',
    'added QmUcLzGWDuBPA6iVF65n676KiCbQNXV4owecfSR4QFVy3U recursive-get-dir/blocks/CIQFF',
    'added QmNtkNt8oZASY7AYVpswA3RQ43hASjP1NGj8GB1L6vgHUx recursive-get-dir/blocks/CIQFE/CIQFEAGMNNXXTYKYQSANT6IBNTFN7WR5RPD5F6GN6MBKUUO25DNOTWQ.data',
    'added QmXrrAYhbThjuHRPA23HujCLFbTrnwd3jmvNbZBAnKEddk recursive-get-dir/blocks/CIQFE',
    'added QmcozcFvmaTqVPaFXgZUHPsroSG8YP6tHEYyFaFhnonwSG recursive-get-dir/blocks/CIQEU/CIQEUWUVLBXVFYSYCHHSCRTXCYHGIOBXKWUMKFR3UPAFHQ5WK5362FQ.data',
    'added QmVU52FEpQQF3ViFGUKLhLeJaRKpCZfqN4AWLuzAXyrzyU recursive-get-dir/blocks/CIQEU',
    'added QmPiJAUg2J3dWWnQvtKXbkr8g1qCxX4RCPkU3wFmxd6x8H recursive-get-dir/blocks/CIQER/CIQERMRAAFXUAUOX3V2DCW7R77FRIVHQ3V5OIPPS3XQBX34KRPNOIRQ.data',
    'added QmboWqKvhjxdBw1AfxQ56sqhqrrtG7ibaGhHb19TPnjr69 recursive-get-dir/blocks/CIQER',
    'added QmPbgB6GzeUEnvXqQgYLTJnrdcm95kGRWH36euTr2eAB2w recursive-get-dir/blocks/CIQEN/CIQENVCICS44LLYUDQ5KVN6ALXC6QRHK2X4R6EUFRMBB5OSFO2FUYDQ.data',
    'added QmZCxJdNTR1MHRNGGWgZRZdW66FTpyTLdT8odbUz1CP7J9 recursive-get-dir/blocks/CIQEN',
    'added QmQCYnQWAHqSy1ts7VmHbp18BFEmbVvfX7FASVQF21uo5g recursive-get-dir/blocks/CIQDV/CIQDVKITASFS55MC2TXCX5XMZLMGTYVODWPEDIW7JYEG7YXBIA7IUWY.data',
    'added QmQaTiy1CufRfP3zTCW8fAtNWjvdeWuMkvTi4q6dykNDif recursive-get-dir/blocks/CIQDV',
    'added QmSynZ3cTjBzpMTSPCP5Q6RJSa9WEAA8p178cZRLnKdahz recursive-get-dir/blocks/CIQDM/CIQDMKFEUGKSLXMEXO774EZOYCYNHPRVFD53ZSAU7237F67XDSQGCYQ.data',
    'added QmNS3zMGDTPRTuR8nbPz4ddQpGN4gtuVyZ5G3mn3ajg4Rb recursive-get-dir/blocks/CIQDM',
    'added QmTpxXKswGwhTYLn1qL4EG9aLGFXS2LSnreceV2FJeArVh recursive-get-dir/blocks/CIQDD/CIQDDZ5EDQK5AP7LRTLZHQZUR2R3GECRFV3WPKNL7PL2SKFIL2LXC4Y.data',
    'added Qmbm7ToWsTta4Y1RipmRudCenKF7qAHRVTCtTPuoVqfY8H recursive-get-dir/blocks/CIQDD/CIQDDVW2EZIJF4NQH7WJNESD7XHQSXA5EGJVNTPVHD7444C2KLKXHDI.data',
    'added QmSCq2peGvGDXZKuX565UczxRpgzsiPPF3PgcJq9zDbByL recursive-get-dir/blocks/CIQDD',
    'added QmdgaiKe1HFfhrZvLwTFCrXmgTojhSWuBvyFXUVc8KzJVc recursive-get-dir/blocks/CIQBE/CIQBED3K6YA5I3QQWLJOCHWXDRK5EXZQILBCKAPEDUJENZ5B5HJ5R3A.data',
    'added QmYwUkwNwJN2cevwXKL48DRpbbjbdLWyyLANG3BKTtsTZ8 recursive-get-dir/blocks/CIQBE',
    'added QmamKEPmEH9RUsqRQsfNf5evZQDQPYL9KXg1ADeT7mkHkT recursive-get-dir/blocks',
    'added Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z recursive-get-dir'
  ]

  before(() => {
    ipfs = thing.ipfs
  })

  it('add with progress', function () {
    this.timeout(30 * 1000)

    return ipfs('add -p src/init-files/init-docs/readme')
      .then((out) => {
        expect(out)
          .to.eql('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
      })
  })

  it('add', function () {
    this.timeout(30 * 1000)

    return ipfs('add src/init-files/init-docs/readme')
      .then((out) => {
        expect(out)
          .to.eql('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
      })
  })

  it('add multiple', function () {
    this.timeout(30 * 1000)

    return ipfs('add', 'src/init-files/init-docs/readme', 'test/fixtures/odd-name-[v0]/odd name [v1]/hello', '--wrap-with-directory')
      .then((out) => {
        expect(out)
          .to.include('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
        expect(out)
          .to.include('added QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o hello\n')
      })
  })

  it('add alias', function () {
    this.timeout(30 * 1000)

    return ipfs('add src/init-files/init-docs/readme')
      .then((out) => {
        expect(out)
          .to.eql('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
      })
  })

  it('add recursively test', function () {
    this.timeout(60 * 1000)

    return ipfs('add -r test/fixtures/test-data/recursive-get-dir')
      .then((out) => {
        expect(out).to.eql(recursiveGetDirResults.join('\n') + '\n')
      })
  })

  it('add directory with trailing slash test', function () {
    this.timeout(30 * 1000)

    return ipfs('add -r test/fixtures/test-data/recursive-get-dir/')
      .then((out) => {
        expect(out).to.eql(recursiveGetDirResults.join('\n') + '\n')
      })
  })

  it('add directory with odd name', function () {
    this.timeout(30 * 1000)
    const expected = [
      'added QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o odd-name-[v0]/odd name [v1]/hello',
      'added QmYRMUVULBfj7WrdPESnwnyZmtayN6Sdrwh1nKcQ9QgQeZ odd-name-[v0]/odd name [v1]',
      'added QmXJGoo27bg7ExNAtr9vRcivxDwcfHtkxatGno9HrUdR16 odd-name-[v0]'
    ]

    return ipfs('add -r test/fixtures/odd-name-[v0]')
      .then((out) => {
        expect(out).to.eql(expected.join('\n') + '\n')
      })
  })

  it('add and wrap with a directory', function () {
    this.timeout(30 * 1000)

    return ipfs('add -w src/init-files/init-docs/readme').then((out) => {
      expect(out).to.be.eql([
        'added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme',
        'added QmapdaVPjHXdcswef82FnGQUauMNpk9xYFkLDZKgAxhMwq'
      ].join('\n') + '\n')
    })
  })

  it('add with cid-version=0', function () {
    this.timeout(30 * 1000)

    return ipfs('add src/init-files/init-docs/readme --cid-version=0').then((out) => {
      expect(out)
        .to.eql('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
    })
  })

  it('add with cid-version=1 < default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs('add test/fixtures/less-than-default-max-chunk-size --cid-version=1')
      .then((out) => {
        expect(out)
          .to.eql('added zb2rhh5LdXumxQfNZCqV8pmcC56LX71ERgf2qCNQsmZnwYYx9 less-than-default-max-chunk-size\n')
      })
  })

  it('add with cid-version=1 > default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs('add test/fixtures/greater-than-default-max-chunk-size --cid-version=1')
      .then((out) => {
        expect(out)
          .to.eql('added zdj7WbyyZoWVifUHUe58SNS184PpN8qAuCP6HpAY91iA8CveT greater-than-default-max-chunk-size\n')
      })
  })

  it('add with cid-version=1 and raw-leaves=false < default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs(`add test/fixtures/less-than-default-max-chunk-size --cid-version=1 --raw-leaves=false`)
      .then((out) => {
        expect(out)
          .to.eql('added zdj7WWPWpmpFkrWJBhUEZ4QkGumsFsEdkaaEGs7U4dzJraogp less-than-default-max-chunk-size\n')
      })
  })

  it('add with cid-version=1 and raw-leaves=false > default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs(`add test/fixtures/greater-than-default-max-chunk-size --cid-version=1 --raw-leaves=false`)
      .then((out) => {
        expect(out)
          .to.eql('added zdj7WmYojH6vMkDQFNDNwUy2ZawrggqAhS6jjRJwb1C4KXZni greater-than-default-max-chunk-size\n')
      })
  })

  it('add with cid-version=1 and raw-leaves=true < default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs('add test/fixtures/less-than-default-max-chunk-size --cid-version=1 --raw-leaves=true')
      .then((out) => {
        expect(out)
          .to.eql('added zb2rhh5LdXumxQfNZCqV8pmcC56LX71ERgf2qCNQsmZnwYYx9 less-than-default-max-chunk-size\n')
      })
  })

  it('add with cid-version=1 and raw-leaves=true > default max chunk size', function () {
    this.timeout(30 * 1000)

    return ipfs('add test/fixtures/greater-than-default-max-chunk-size --cid-version=1 --raw-leaves=true')
      .then((out) => {
        expect(out)
          .to.eql('added zdj7WbyyZoWVifUHUe58SNS184PpN8qAuCP6HpAY91iA8CveT greater-than-default-max-chunk-size\n')
      })
  })

  it('add from pipe', () => {
    const proc = ipfs('add')
    proc.stdin.write(Buffer.from('hello\n'))
    proc.stdin.end()
    return proc
      .then(out => {
        expect(out)
          .to.eql('added QmZULkCELmmk5XNfCgTnCyFgAVxBRBXyDHGGMVoLFLiXEN QmZULkCELmmk5XNfCgTnCyFgAVxBRBXyDHGGMVoLFLiXEN\n')
      })
  })

  it('add --quiet', function () {
    this.timeout(30 * 1000)

    return ipfs('add -q src/init-files/init-docs/readme')
      .then((out) => {
        expect(out)
          .to.eql('QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB\n')
      })
  })

  it('add --quieter', function () {
    this.timeout(30 * 1000)

    return ipfs('add -Q -w test/fixtures/test-data/hello')
      .then((out) => {
        expect(out)
          .to.eql('QmYRMUVULBfj7WrdPESnwnyZmtayN6Sdrwh1nKcQ9QgQeZ\n')
      })
  })

  it('add --silent', function () {
    this.timeout(30 * 1000)

    return ipfs('add --silent src/init-files/init-docs/readme')
      .then((out) => {
        expect(out)
          .to.eql('')
      })
  })

  it('add --only-hash outputs correct hash', function () {
    return ipfs('add --only-hash src/init-files/init-docs/readme')
      .then(out =>
        expect(out)
          .to.eql('added QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB readme\n')
      )
  })

  it('add --only-hash does not add a file to the datastore', function () {
    this.timeout(30 * 1000)
    this.slow(10 * 1000)
    const content = String(Math.random())
    const filepath = path.join(os.tmpdir(), `${content}.txt`)
    fs.writeFileSync(filepath, content)

    return ipfs(`add --only-hash ${filepath}`)
      .then(out => {
        const hash = out.split(' ')[1]

        // 'jsipfs object get <hash>' should timeout with the daemon on
        // and should fail fast with the daemon off
        return Promise.race([
          ipfs.fail(`object get ${hash}`),
          new Promise((resolve, reject) => setTimeout(resolve, 4000))
        ])
          .then(() => clean(filepath))
      })
  })

  it('add pins by default', function () {
    this.timeout(10 * 1000)
    const filePath = path.join(os.tmpdir(), hat())
    const content = String(Math.random())
    fs.writeFileSync(filePath, content)

    return ipfs(`add -Q ${filePath}`)
      .then(out => {
        const hash = out.trim()
        return ipfs(`pin ls ${hash}`)
          .then(ls => expect(ls).to.include(hash))
      })
      .then(() => clean(filePath))
  })

  it('add does not pin with --pin=false', function () {
    this.timeout(20 * 1000)
    const filePath = path.join(os.tmpdir(), hat())
    const content = String(Math.random())
    fs.writeFileSync(filePath, content)

    return ipfs(`add -Q --pin=false ${filePath}`)
      .then(out => ipfs.fail(`pin ls ${out.trim()}`))
      .then(() => clean(filePath))
  })

  HASH_ALGS.forEach((name) => {
    it(`add with hash=${name} and raw-leaves=false`, function () {
      this.timeout(30 * 1000)

      return ipfs(`add src/init-files/init-docs/readme --hash=${name} --raw-leaves=false`)
        .then((out) => {
          const hash = out.split(' ')[1]
          const cid = new CID(hash)
          expect(mh.decode(cid.multihash).name).to.equal(name)
        })
    })
  })

  it('should add and print CID encoded in specified base', function () {
    this.timeout(30 * 1000)

    return ipfs('add test/fixtures/test-data/hello --cid-base=base64')
      .then((out) => {
        expect(out).to.eql('added mAXASIEbUSBS5xa8UHDqqt8BdxehE6tX5HxKFiwIeukV2i0wO hello\n')
      })
  })

  it('cat', function () {
    this.timeout(30 * 1000)

    return ipfs('cat QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')
      .then((out) => {
        expect(out).to.eql(readme)
      })
  })

  it('cat alias', function () {
    this.timeout(20 * 1000)

    return ipfs('cat QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')
      .then((out) => {
        expect(out).to.eql(readme)
      })
  })

  it('cat part of a file using `count`', function () {
    this.timeout(30 * 1000)

    return ipfs('cat QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB --offset 21 --count 5')
      .then((out) => {
        expect(out).to.eql(readme.substring(21, 26))
      })
  })

  it('cat part of a file using `length`', function () {
    this.timeout(30 * 1000)

    return ipfs('cat QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB --offset 21 --length 5')
      .then((out) => {
        expect(out).to.eql(readme.substring(21, 26))
      })
  })

  it('cat non-existent file', () => {
    return ipfs('cat QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB/dummy')
      .then(() => expect.fail(0, 1, 'Should have thrown an error'))
      .catch((err) => {
        expect(err).to.exist()
      })
  })

  it('get', function () {
    this.timeout(20 * 1000)

    return ipfs('get QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')
      .then((out) => {
        expect(out)
          .to.eql('Saving file(s) QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB\n')

        const file = path.join(process.cwd(), 'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')

        expect(fs.readFileSync(file).toString()).to.eql(readme)

        rimraf(file)
      })
  })

  it('get alias', function () {
    this.timeout(20 * 1000)

    return ipfs('get QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')
      .then((out) => {
        expect(out)
          .to.eql('Saving file(s) QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB\n')

        const file = path.join(process.cwd(), 'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB')

        expect(fs.readFileSync(file).toString()).to.eql(readme)

        rimraf(file)
      })
  })

  it('get recursively', function () {
    this.timeout(20 * 1000)

    const outDir = path.join(process.cwd(), 'Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z')
    rimraf(outDir)

    return ipfs('get Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z')
      .then((out) => {
        expect(out).to.eql(
          'Saving file(s) Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z\n'
        )

        const outDir = path.join(process.cwd(), 'Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z')
        const expectedDir = path.join(process.cwd(), 'test', 'fixtures', 'test-data', 'recursive-get-dir')

        const compareResult = compareDir(outDir, expectedDir, {
          compareContent: true,
          compareSize: true
        })

        expect(compareResult.differences).to.equal(0)
        rimraf(outDir)
      })
  })
}))

'''
'''--- test/cli/general.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('general cli options', () => runOnAndOff.off((thing) => {
  it('should handle --silent flag', () => {
    return thing.ipfs('help --silent').then((out) => {
      expect(out).to.be.empty()
    })
  })

  it('should handle unknown arguments correctly', () => {
    return thing.ipfs('random --again').then((out) => {
      expect(out).to.include('Unknown arguments: again, random')
      expect(out).to.include('random')
      expect(out).to.include('again')
    })
  })
}))

'''
'''--- test/cli/id.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('id', () => runOnAndOff((thing) => {
  let ipfs

  before(function () {
    this.timeout(60 * 1000)
    ipfs = thing.ipfs
  })

  it('get the id', function () {
    this.timeout(60 * 1000)

    return ipfs('id').then((res) => {
      const id = JSON.parse(res)
      expect(id).to.have.property('id')
      expect(id).to.have.property('publicKey')
      expect(id).to.have.property('addresses')
    })
  })
}))

'''
'''--- test/cli/index.js ---
/* eslint-env mocha */
'use strict'

const fs = require('fs')

describe('cli', () => {
  fs.readdirSync(__dirname)
    .filter((file) => file !== 'index.js')
    .forEach((file) => require('./' + file))
})

'''
'''--- test/cli/init.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const path = require('path')
const fs = require('fs')
const clean = require('../utils/clean')
const hat = require('hat')
const ipfsExec = require('../utils/ipfs-exec')
const os = require('os')

describe('init', function () {
  this.timeout(40 * 1000)

  let repoPath
  let ipfs

  const readme = fs.readFileSync(path.join(process.cwd(), '/src/init-files/init-docs/readme'))
    .toString('utf-8')

  const repoExistsSync = (p) => fs.existsSync(path.join(repoPath, p))

  const repoDirSync = (p) => {
    return fs.readdirSync(path.join(repoPath, p)).filter((f) => {
      return !f.startsWith('.')
    })
  }
  beforeEach(() => {
    repoPath = os.tmpdir() + '/ipfs-' + hat()
    ipfs = ipfsExec(repoPath)
  })

  afterEach(() => clean(repoPath))

  it('basic', function () {
    this.timeout(40 * 1000)

    return ipfs('init').then((out) => {
      expect(repoDirSync('blocks')).to.have.length.above(2)
      expect(repoExistsSync('config')).to.equal(true)
      expect(repoExistsSync('version')).to.equal(true)

      // Test that the following was written when init-ing the repo
      // jsipfs cat /ipfs/QmfGBRT6BbWJd7yUc2uYdaUZJBbnEFvTqehPFoSMQ6wgdr/readme
      let command = out.substring(out.indexOf('cat'), out.length - 2 /* omit the newline char */)
      return ipfs(command)
    }).then((out) => expect(out).to.equal(readme))
  })

  it('bits', function () {
    this.timeout(40 * 1000)

    return ipfs('init --bits 1024').then(() => {
      expect(repoDirSync('blocks')).to.have.length.above(2)
      expect(repoExistsSync('config')).to.equal(true)
      expect(repoExistsSync('version')).to.equal(true)
    })
  })

  it('empty', function () {
    this.timeout(40 * 1000)

    return ipfs('init --bits 1024 --empty-repo true').then(() => {
      expect(repoDirSync('blocks')).to.have.length(2)
      expect(repoExistsSync('config')).to.equal(true)
      expect(repoExistsSync('version')).to.equal(true)
    })
  })

  it('should present ipfs path help when option help is received', function (done) {
    this.timeout(100 * 1000)

    ipfs('init --help').then((res) => {
      expect(res).to.have.string('export IPFS_PATH=/path/to/ipfsrepo')
      done()
    })
  })
})

'''
'''--- test/cli/key.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')
const hat = require('hat')

describe('key', () => runOnAndOff.off((thing) => {
  const name = 'test-key-' + hat()
  const newName = 'test-key-' + hat()
  const pass = '--pass ' + hat()
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('gen', function () {
    this.timeout(40 * 1000)

    return ipfs(`${pass} key gen ${name} --type rsa --size 2048`)
      .then((out) => {
        expect(out).to.include(name)
      })
  })

  it('list', function () {
    this.timeout(20 * 1000)

    return ipfs(`${pass} key list`)
      .then((out) => {
        expect(out).to.include(name)
      })
  })

  it('rename', function () {
    this.timeout(20 * 1000)

    return ipfs(`${pass} key rename ${name} ${newName}`)
      .then((out) => {
        expect(out).to.include(newName)
      })
  })

  it('rm', function () {
    this.timeout(20 * 1000)

    return ipfs(`${pass} key rm ${newName}`)
      .then((out) => {
        expect(out).to.include(newName)
      })
  })
}))

'''
'''--- test/cli/ls.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')

describe('ls', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
    return ipfs('add -r test/fixtures/test-data/recursive-get-dir')
  })

  it('prints added files', function () {
    this.timeout(20 * 1000)
    return ipfs('ls Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z')
      .then((out) => {
        expect(out).to.eql(
          'QmamKEPmEH9RUsqRQsfNf5evZQDQPYL9KXg1ADeT7mkHkT 123530 blocks/\n' +
          'QmPkWYfSLCEBLZu7BZt4kigGDMe3cpogMbeVf97gN2xJDN 3939   config\n' +
          'QmUqyZtPmsRy1U5Mo8kz2BAMmk1hfJ7yW1KAFTMB2odsFv 5503   datastore/\n' +
          'QmUhUuiTKkkK8J6JZ9zmj8iNHPuNfGYcszgRumzhHBxEEU 7397   init-docs/\n' +
          'QmR56UJmAaZLXLdTT1ALrE9vVqV8soUEekm9BMd4FnuYqV 10     version\n'
        )
      })
  })

  it('prints nothing for non-existant hashes', function () {
    // If the daemon is off, ls should fail
    // If the daemon is on, ls should search until it hits a timeout
    return Promise.race([
      ipfs.fail('ls QmYmW4HiZhotsoSqnv2o1oSssvkRM8b9RweBoH7ao5nki2'),
      new Promise((resolve, reject) => setTimeout(resolve, 4000))
    ])
      .catch(() => expect.fail(0, 1, 'Should have thrown or timedout'))
  })

  it('adds a header, -v', function () {
    this.timeout(20 * 1000)
    return ipfs('ls /ipfs/Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z -v')
      .then((out) => {
        expect(out).to.eql(
          'Hash                                           Size   Name\n' +
          'QmamKEPmEH9RUsqRQsfNf5evZQDQPYL9KXg1ADeT7mkHkT 123530 blocks/\n' +
          'QmPkWYfSLCEBLZu7BZt4kigGDMe3cpogMbeVf97gN2xJDN 3939   config\n' +
          'QmUqyZtPmsRy1U5Mo8kz2BAMmk1hfJ7yW1KAFTMB2odsFv 5503   datastore/\n' +
          'QmUhUuiTKkkK8J6JZ9zmj8iNHPuNfGYcszgRumzhHBxEEU 7397   init-docs/\n' +
          'QmR56UJmAaZLXLdTT1ALrE9vVqV8soUEekm9BMd4FnuYqV 10     version\n'
        )
      })
  })

  it('follows a path, <hash>/<subdir>', function () {
    this.timeout(20 * 1000)

    return ipfs('ls /ipfs/Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z/init-docs')
      .then((out) => {
        expect(out).to.eql(
          'QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V 1688 about\n' +
          'QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y 200  contact\n' +
          'QmegvLXxpVKiZ4b57Xs1syfBVRd8CbucVHAp7KpLQdGieC 65   docs/\n' +
          'QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7 322  help\n' +
          'QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha 1728 quick-start\n' +
          'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB 1102 readme\n' +
          'QmTumTjvcYCAvRRwQ8sDRxh8ezmrcr88YFU7iYNroGGTBZ 1027 security-notes\n' +
          'QmciSU8hfpAXKjvK5YLUSwApomGSWN5gFbP4EpDAEzu2Te 863  tour/\n'
        )
      })
  })

  it('recursively follows folders, -r', function () {
    this.slow(2000)
    this.timeout(20 * 1000)

    return ipfs('ls -r /ipfs/Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z/init-docs')
      .then(out => {
        expect(out).to.eql(
          'QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V 1688 about\n' +
          'QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y 200  contact\n' +
          'QmegvLXxpVKiZ4b57Xs1syfBVRd8CbucVHAp7KpLQdGieC 65   docs/\n' +
          'QmQN88TEidd3RY2u3dpib49fERTDfKtDpvxnvczATNsfKT 14     index\n' +
          'QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7 322  help\n' +
          'QmdncfsVm2h5Kqq9hPmU7oAVX2zTSVP3L869tgTbPYnsha 1728 quick-start\n' +
          'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB 1102 readme\n' +
          'QmTumTjvcYCAvRRwQ8sDRxh8ezmrcr88YFU7iYNroGGTBZ 1027 security-notes\n' +
          'QmciSU8hfpAXKjvK5YLUSwApomGSWN5gFbP4EpDAEzu2Te 863  tour/\n' +
          'QmYE7xo6NxbHEVEHej1yzxijYaNY51BaeKxjXxn6Ssa6Bs 807    0.0-intro\n'
        )
      })
  })

  it('should ls and print CIDs encoded in specified base', function () {
    this.timeout(20 * 1000)

    return ipfs('ls Qmaj2NmcyAXT8dFmZRRytE12wpcaHADzbChKToMEjBsj5Z --cid-base=base64')
      .then((out) => {
        expect(out).to.eql(
          'mAXASILidvV1YroHLqBvmuXko1Ly1UVenZV1K+MvhsjXhdvZQ 123530 blocks/\n' +
          'mAXASIBT4ZYkQw0IApLoNHBxSjpezyayKZHJyxmFKpt0I3sK5 3939   config\n' +
          'mAXASIGCpScP8zpa0CqUgyVCR/Cm0Co8pnULGe3seXSsOnJsJ 5503   datastore/\n' +
          'mAXASIF58POI3+TbHb69iXpD3dRqfXusEj1mHMwPCFenM6HWZ 7397   init-docs/\n' +
          'mAXASICiW5ai+KiU60glImEMMkiHaNSOAivpXspriIhJO8iHI 10     version\n'
        )
      })
  })
}))

'''
'''--- test/cli/name-pubsub.js ---
/* eslint max-nested-callbacks: ["error", 7] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const parallel = require('async/parallel')
const series = require('async/series')
const ipfsExec = require('../utils/ipfs-exec')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'js' })

const checkAll = (bits) => string => bits.every(bit => string.includes(bit))
const emptyDirCid = 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn'

const spawnDaemon = (callback) => {
  df.spawn({
    exec: `./src/cli/bin.js`,
    args: ['--enable-namesys-pubsub'],
    initOptions: { bits: 512 },
    config: {
      Bootstrap: [],
      Discovery: {
        MDNS: {
          Enabled: false
        },
        webRTCStar: {
          Enabled: false
        }
      }
    }
  }, callback)
}

describe('name-pubsub', () => {
  describe('enabled', () => {
    let ipfsA
    let ipfsB
    let nodeAId
    let nodeBId
    let bMultiaddr
    let nodes = []

    // Spawn daemons
    before(function (done) {
      // CI takes longer to instantiate the daemon, so we need to increase the
      // timeout for the before step
      this.timeout(80 * 1000)

      series([
        (cb) => {
          spawnDaemon((err, node) => {
            expect(err).to.not.exist()
            ipfsA = ipfsExec(node.repoPath)
            nodes.push(node)
            cb()
          })
        },
        (cb) => {
          spawnDaemon((err, node) => {
            expect(err).to.not.exist()
            ipfsB = ipfsExec(node.repoPath)
            nodes.push(node)
            cb()
          })
        }
      ], done)
    })

    // Get node ids
    before(function (done) {
      parallel([
        (cb) => {
          ipfsA('id').then((res) => {
            nodeAId = JSON.parse(res)
            cb()
          })
        },
        (cb) => {
          ipfsB('id').then((res) => {
            const id = JSON.parse(res)

            nodeBId = id
            bMultiaddr = id.addresses[0]
            cb()
          })
        }
      ], done)
    })

    // Connect
    before(function () {
      return ipfsA('swarm', 'connect', bMultiaddr)
        .then((out) => {
          expect(out).to.eql(`connect ${bMultiaddr} success\n`)
        })
    })

    after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

    describe('pubsub commands', () => {
      it('should get enabled state of pubsub', function () {
        return ipfsA('name pubsub state')
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.have.string('enabled') // enabled
          })
      })

      it('should subscribe on name resolve', function () {
        this.timeout(80 * 1000)

        return ipfsB(`name resolve ${nodeAId.id}`)
          .catch((err) => {
            expect(err).to.exist() // Not available (subscribed)

            return ipfsB('pubsub ls')
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.have.string('/record/') // have a record ipns subscribtion

            return ipfsB('name pubsub subs')
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.have.string(`/ipns/${nodeAId.id}`) // have subscription
          })
      })

      it('should be able to cancel subscriptions', function () {
        this.timeout(80 * 1000)

        return ipfsA(`name pubsub cancel /ipns/${nodeBId.id}`)
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.have.string('no subscription') // tried to cancel a not yet subscribed id

            return ipfsA(`name resolve ${nodeBId.id}`)
          })
          .catch((err) => {
            expect(err).to.exist() // Not available (subscribed now)

            return ipfsA(`name pubsub cancel /ipns/${nodeBId.id}`)
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.have.string('canceled') // canceled now

            return ipfsA('pubsub ls')
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.not.have.string('/ipns/') // ipns subscribtion not available

            return ipfsA('name pubsub subs')
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.not.have.string(`/ipns/${nodeBId.id}`) // ipns subscribtion not available
          })
      })
    })

    describe('pubsub records', () => {
      let cidAdded

      before(function (done) {
        this.timeout(50 * 1000)
        ipfsA('add src/init-files/init-docs/readme')
          .then((out) => {
            cidAdded = out.split(' ')[1]
            done()
          })
      })

      it('should publish the received record to the subscriber', function () {
        this.timeout(80 * 1000)

        return ipfsB(`name resolve ${nodeBId.id}`)
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.satisfy(checkAll([emptyDirCid])) // Empty dir received (subscribed)

            return ipfsA(`name resolve ${nodeBId.id}`)
          })
          .catch((err) => {
            expect(err).to.exist() // Not available (subscribed now)

            return ipfsB(`name publish ${cidAdded}`)
          })
          .then((res) => {
            // published to IpfsB and published through pubsub to ipfsa
            expect(res).to.exist()
            expect(res).to.satisfy(checkAll([cidAdded, nodeBId.id]))

            return ipfsB(`name resolve ${nodeBId.id}`)
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.satisfy(checkAll([cidAdded]))

            return ipfsA(`name resolve ${nodeBId.id}`)
          })
          .then((res) => {
            expect(res).to.exist()
            expect(res).to.satisfy(checkAll([cidAdded])) // value propagated to node B
          })
      })
    })
  })

  describe('disabled', () => {
    let ipfsA
    let nodes = []

    // Spawn daemons
    before(function (done) {
      // CI takes longer to instantiate the daemon, so we need to increase the
      // timeout for the before step
      this.timeout(80 * 1000)

      df.spawn({
        exec: `./src/cli/bin.js`,
        config: {},
        initOptions: { bits: 512 }
      }, (err, node) => {
        expect(err).to.not.exist()
        ipfsA = ipfsExec(node.repoPath)
        nodes.push(node)
        done()
      })
    })

    after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

    it('should get disabled state of pubsub', function () {
      return ipfsA('name pubsub state')
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.have.string('disabled')
        })
    })

    it('should get error getting the available subscriptions', function () {
      return ipfsA('name pubsub subs')
        .catch((err) => {
          expect(err).to.exist() // error as it is disabled
          expect(err.toString()).to.have.string('IPNS pubsub subsystem is not enabled')
        })
    })

    it('should get error canceling a subscription', function () {
      return ipfsA('name pubsub cancel /ipns/QmSWxaPcGgf4TDnFEBDWz2JnbHywF14phmY9hNcAeBEK5v')
        .catch((err) => {
          expect(err).to.exist() // error as it is disabled
          expect(err.toString()).to.have.string('IPNS pubsub subsystem is not enabled')
        })
    })
  })
})

'''
'''--- test/cli/name.js ---
/* eslint max-nested-callbacks: ["error", 6] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const hat = require('hat')
const ipfsExec = require('../utils/ipfs-exec')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'js' })

const checkAll = (bits) => string => bits.every(bit => string.includes(bit))

describe('name', () => {
  describe('working locally', () => {
    const passPhrase = hat()
    const pass = '--pass ' + passPhrase
    const name = 'test-key-' + hat()

    let ipfs
    let ipfsd

    let cidAdded
    let nodeId
    let keyId

    before(function (done) {
      this.timeout(80 * 1000)

      df.spawn({
        exec: `./src/cli/bin.js`,
        config: {
          Bootstrap: []
        },
        args: ['--pass', passPhrase, '--offline'],
        initOptions: { bits: 512 }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()

        ipfsd = _ipfsd
        ipfs = ipfsExec(_ipfsd.repoPath)

        ipfs(`${pass} key gen ${name} --type rsa --size 2048`)
          .then((out) => {
            expect(out).to.include(name)
            keyId = out.split(' ')[1]

            return ipfs('id')
          })
          .then((res) => {
            const id = JSON.parse(res)
            expect(id).to.have.property('id')
            nodeId = id.id

            return ipfs('add src/init-files/init-docs/readme')
          })
          .then((out) => {
            cidAdded = out.split(' ')[1]
            done()
          })
      })
    })

    after(function (done) {
      if (ipfsd) {
        ipfsd.stop(() => done())
      } else {
        done()
      }
    })

    it('should publish correctly when the file was already added', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded}`).then((res) => {
        expect(res).to.exist()
        expect(res).to.satisfy(checkAll([cidAdded, nodeId]))
      })
    })

    it('should publish and resolve an entry with the default options', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded}`)
        .then((res) => {
          expect(res).to.exist()

          return ipfs('name resolve')
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded]))
        })
    })

    it('should publish correctly when the file was not added but resolve is disabled', function () {
      this.timeout(70 * 1000)

      const notAddedCid = 'QmPFVLPmp9zv5Z5KUqLhe2EivAGccQW2r7M7jhVJGLZoZU'

      return ipfs(`name publish ${notAddedCid} --resolve false`).then((res) => {
        expect(res).to.exist()
        expect(res).to.satisfy(checkAll([notAddedCid, nodeId]))
      })
    })

    it('should not get the entry correctly if its validity time expired', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded} --lifetime 10ns`)
        .then((res) => {
          expect(res).to.exist()

          setTimeout(function () {
            return ipfs('name resolve')
              .then((res) => {
                expect(res).to.not.exist()
              })
              .catch((err) => {
                expect(err).to.exist()
              })
          }, 1)
        })
    })

    it('should publish correctly when a new key is used', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded} --key ${name}`).then((res) => {
        expect(res).to.exist()
        expect(res).to.satisfy(checkAll([cidAdded, keyId]))
      })
    })

    it('should return the immediate pointing record, unless using the recursive parameter', function () {
      this.timeout(90 * 1000)

      return ipfs(`name publish ${cidAdded}`)
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded, nodeId]))

          return ipfs(`name publish /ipns/${nodeId} --key ${name}`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([nodeId, keyId]))

          return ipfs(`name resolve ${keyId}`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([nodeId]))
        })
    })

    it('should go recursively until finding an ipfs hash', function () {
      this.timeout(90 * 1000)

      return ipfs(`name publish ${cidAdded}`)
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded, nodeId]))

          return ipfs(`name publish /ipns/${nodeId} --key ${name}`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([nodeId, keyId]))

          return ipfs(`name resolve ${keyId} --recursive`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded]))
        })
    })
  })

  describe('using dht', () => {
    const passPhrase = hat()
    const pass = '--pass ' + passPhrase
    const name = 'test-key-' + hat()

    let ipfs
    let ipfsd

    let cidAdded
    let nodeId
    let keyId

    before(function (done) {
      this.timeout(80 * 1000)

      df.spawn({
        exec: `./src/cli/bin.js`,
        config: {
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            },
            webRTCStar: {
              Enabled: false
            }
          }
        },
        args: ['--pass', passPhrase],
        initOptions: { bits: 512 }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()

        ipfsd = _ipfsd
        ipfs = ipfsExec(_ipfsd.repoPath)

        ipfs(`${pass} key gen ${name} --type rsa --size 2048`)
          .then((out) => {
            expect(out).to.include(name)
            keyId = out.split(' ')[1]

            return ipfs('id')
          })
          .then((res) => {
            const id = JSON.parse(res)
            expect(id).to.have.property('id')
            nodeId = id.id

            return ipfs('add src/init-files/init-docs/readme')
          })
          .then((out) => {
            cidAdded = out.split(' ')[1]
            done()
          })
      })
    })

    after(function (done) {
      if (ipfsd) {
        ipfsd.stop(() => done())
      } else {
        done()
      }
    })

    it('should publish and resolve an entry with the default options', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded}`)
        .then((res) => {
          expect(res).to.exist()

          return ipfs('name resolve')
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded]))
        })
    })

    it('should not get the entry correctly if its validity time expired', function () {
      this.timeout(70 * 1000)

      return ipfs(`name publish ${cidAdded} --lifetime 10ns`)
        .then((res) => {
          expect(res).to.exist()

          setTimeout(function () {
            return ipfs('name resolve')
              .then((res) => {
                expect(res).to.not.exist()
              })
              .catch((err) => {
                expect(err).to.exist()
              })
          }, 1)
        })
    })

    it('should return the immediate pointing record, unless using the recursive parameter', function () {
      this.timeout(90 * 1000)

      return ipfs(`name publish ${cidAdded}`)
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([cidAdded, nodeId]))

          return ipfs(`name publish /ipns/${nodeId} --key ${name}`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([nodeId, keyId]))

          return ipfs(`name resolve ${keyId}`)
        })
        .then((res) => {
          expect(res).to.exist()
          expect(res).to.satisfy(checkAll([nodeId]))
        })
    })
  })
})

'''
'''--- test/cli/object.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const runOnAndOff = require('../utils/on-and-off')
const UnixFs = require('ipfs-unixfs')
const path = require('path')
const fs = require('fs')
const crypto = require('crypto')
const os = require('os')
const multibase = require('multibase')

describe('object', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('new', () => {
    return ipfs('object new').then((out) => {
      expect(out).to.eql(
        'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n\n'
      )
    })
  })

  it('new unixfs-dir', () => {
    return ipfs('object new unixfs-dir').then((out) => {
      expect(out).to.eql(
        'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn\n'
      )
    })
  })

  // TODO: unskip after switch to v1 CIDs by default
  it.skip('should new and print CID encoded in specified base', () => {
    return ipfs('object new --cid-base=base64').then((out) => {
      expect(out).to.eql(
        'mAXASIOOwxEKY/BwUmvv0yJlvuSQnrkHkZJuTTKSVmRt4UrhV\n'
      )
    })
  })

  it('get', () => {
    return ipfs('object get QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n').then((out) => {
      const result = JSON.parse(out)
      expect(result.Links).to.eql([])
      expect(result.Data).to.eql('')
    })
  })

  it('get with data', function () {
    this.timeout(15 * 1000)

    return ipfs('object new')
      .then((out) => out.trim())
      .then((hash) => ipfs(`object patch set-data ${hash} test/fixtures/test-data/hello`))
      .then((out) => out.trim())
      .then((hash) => ipfs(`object get ${hash}`))
      .then((out) => {
        const result = JSON.parse(out)
        expect(result.Data).to.eql('aGVsbG8gd29ybGQK')
      })
  })

  it('get while overriding data-encoding', function () {
    this.timeout(15 * 1000)

    return ipfs('object new')
      .then((out) => out.trim())
      .then((hash) => ipfs(`object patch set-data ${hash} test/fixtures/test-data/hello`))
      .then((out) => out.trim())
      .then((hash) => ipfs(`object get --data-encoding=utf8 ${hash}`))
      .then((out) => {
        const result = JSON.parse(out)
        expect(result.Data).to.eql('hello world\n')
      })
  })

  it('should get and print CIDs encoded in specified base', () => {
    return ipfs('add test/fixtures/planets -r --cid-version=1')
      .then(out => {
        const lines = out.trim().split('\n')
        return lines[lines.length - 1].split(' ')[1]
      })
      .then(cid => ipfs(`object get ${cid} --cid-base=base64`))
      .then(out => {
        const result = JSON.parse(out)
        expect(multibase.isEncoded(result.Hash)).to.deep.equal('base64')
        result.Links.forEach(l => {
          expect(multibase.isEncoded(l.Hash)).to.deep.equal('base64')
        })
      })
  })

  it('put', () => {
    return ipfs('object put test/fixtures/test-data/node.json').then((out) => {
      expect(out).to.eql(
        'added QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm\n'
      )
    })
  })

  // TODO: unskip after switch to v1 CIDs by default
  it.skip('should put and print CID encoded in specified base', () => {
    return ipfs('object put test/fixtures/test-data/node.json --cid-base=base64')
      .then((out) => {
        expect(out).to.eql(
          'added mAXASIKbM02Neyt6L1RRLYVEOuNlqDOzTvBboo3cI/u6f/+Vk\n'
        )
      })
  })

  it('stat', function () {
    this.timeout(40 * 1000)

    return ipfs('object stat QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm').then((out) => {
      expect(out).to.eql([
        'NumLinks: 1',
        'BlockSize: 60',
        'LinksSize: 53',
        'DataSize: 7',
        'CumulativeSize: 68'
      ].join('\n') + '\n')
    })
  })

  it('data', () => {
    return ipfs('object data QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm').then((out) => {
      expect(out).to.eql('another')
    })
  })

  it('unaltered data', function () {
    this.timeout(10 * 1000)

    // has to be big enough to span several DAGNodes
    const data = crypto.randomBytes(1024 * 300)
    const file = path.join(os.tmpdir(), `file-${Math.random()}.txt`)

    fs.writeFileSync(file, data)

    return ipfs(`add ${file}`)
      .then((out) => {
        return ipfs.raw(`object data ${out.split(' ')[1]}`)
      })
      .then((out) => {
        const meta = UnixFs.unmarshal(out)

        expect(meta.type).to.equal('file')
        expect(meta.fileSize()).to.equal(data.length)
      })
  })

  it('links', () => {
    return ipfs('object links QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm').then((out) => {
      expect(out).to.eql(
        'QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V 8 some link\n'
      )
    })
  })

  it('should get links and print CIDs encoded in specified base', () => {
    return ipfs('add test/fixtures/planets -r --cid-version=1')
      .then(out => {
        const lines = out.trim().split('\n')
        return lines[lines.length - 1].split(' ')[1]
      })
      .then(cid => ipfs(`object links ${cid} --cid-base=base64`))
      .then(out => {
        out.trim().split('\n').forEach(line => {
          const cid = line.split(' ')[0]
          expect(multibase.isEncoded(cid)).to.deep.equal('base64')
        })
      })
  })

  describe('patch', function () {
    this.timeout(40 * 1000)

    it('append-data', () => {
      return ipfs('object patch append-data QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n test/fixtures/test-data/badconfig').then((out) => {
        expect(out).to.eql(
          'QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6\n'
        )
      })
    })

    // TODO: unskip after switch to v1 CIDs by default
    it.skip('should append-data and print CID encoded in specified base', () => {
      return ipfs('object patch append-data QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n test/fixtures/test-data/badconfig --cid-base=base64').then((out) => {
        expect(out).to.eql(
          'mAXASIP+BZ7jGtaTyLGOs0xYcQvH7K9kVKEbyzXAkwLoZwrRj\n'
        )
      })
    })

    it('set-data', () => {
      return ipfs('object patch set-data QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6 test/fixtures/test-data/badconfig').then((out) => {
        expect(out).to.eql(
          'QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6\n'
        )
      })
    })

    // TODO: unskip after switch to v1 CIDs by default
    it.skip('should set-data and print CID encoded in specified base', () => {
      return ipfs('object patch set-data QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6 test/fixtures/test-data/badconfig --cid-base=base64').then((out) => {
        expect(out).to.eql(
          'mAXASIP+BZ7jGtaTyLGOs0xYcQvH7K9kVKEbyzXAkwLoZwrRj\n'
        )
      })
    })

    it('add-link', () => {
      return ipfs('object patch add-link QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n foo QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn').then((out) => {
        expect(out).to.eql(
          'QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK\n'
        )
      })
    })

    // TODO: unskip after switch to v1 CIDs by default
    it.skip('should add-link and print CID encoded in specified base', () => {
      return ipfs('object patch add-link QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n foo QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --cid-base=base64').then((out) => {
        expect(out).to.eql(
          'mAXASIOEVPbXq2xYoEsRZhaPB61btcy1x359osjv4a2L/lgPs\n'
        )
      })
    })

    it('rm-link', () => {
      return ipfs('object patch rm-link QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK foo').then((out) => {
        expect(out).to.eql(
          'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n\n'
        )
      })
    })

    // TODO: unskip after switch to v1 CIDs by default
    it.skip('should rm-link and print CID encoded in specified base', () => {
      return ipfs('object patch rm-link QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK foo --cid-base=base64').then((out) => {
        expect(out).to.eql(
          'mAXASIOOwxEKY/BwUmvv0yJlvuSQnrkHkZJuTTKSVmRt4UrhV\n'
        )
      })
    })
  })
}))

'''
'''--- test/cli/pin.js ---
/* eslint-env mocha */
/* eslint max-nested-callbacks: ["error", 8] */
'use strict'

const expect = require('chai').expect
const CID = require('cids')
const runOnAndOff = require('../utils/on-and-off')

// fixture structure:
//  planets/
//   solar-system.md
//   mercury/
//    wiki.md
const fixturePath = 'test/fixtures/planets'
const pins = {
  root: 'QmTAMavb995EHErSrKo7mB8dYkpaSJxu6ys1a6XJyB2sys',
  solarWiki: 'QmTMbkDfvHwq3Aup6Nxqn3KKw9YnoKzcZvuArAfQ9GF3QG',
  mercuryDir: 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q',
  mercuryWiki: 'QmVgSHAdMxFAuMP2JiMAYkB8pCWP1tcB9djqvq8GKAFiHi'
}

describe('pin', () => runOnAndOff(thing => {
  let ipfs

  before(function () {
    this.timeout(15 * 1000)
    ipfs = thing.ipfs
    return ipfs(`add -r ${fixturePath}`)
  })

  describe('rm', function () {
    it('recursively (default)', () => {
      return ipfs(`pin rm ${pins.root}`)
        .then(out => expect(out).to.equal(`unpinned ${pins.root}\n`))
    })

    it('should rm and print CIDs encoded in specified base', function () {
      this.timeout(30 * 1000)

      return ipfs(`add -r ${fixturePath}`)
        .then(() => ipfs(`pin rm ${pins.root} --cid-base=base64`))
        .then(out => {
          const b64CidStr = new CID(pins.root).toV1().toBaseEncodedString('base64')
          expect(out).to.eql(`unpinned ${b64CidStr}\n`)
        })
    })
  })

  describe('add', function () {
    it('recursively (default)', () => {
      return ipfs(`pin add ${pins.root}`)
        .then(out =>
          expect(out).to.eql(`pinned ${pins.root} recursively\n`)
        )
    })

    it('direct', () => {
      return ipfs(`pin add ${pins.solarWiki} --recursive false`)
        .then(out =>
          expect(out).to.eql(`pinned ${pins.solarWiki} directly\n`)
        )
    })

    it('should add and print CIDs encoded in specified base', () => {
      return ipfs(`pin add ${pins.root} --cid-base=base64`)
        .then(out => {
          const b64CidStr = new CID(pins.root).toV1().toBaseEncodedString('base64')
          expect(out).to.eql(`pinned ${b64CidStr} recursively\n`)
        })
    })
  })

  describe('ls', function () {
    it('lists all pins when no hash is passed', function () {
      return ipfs('pin ls -q').then(out => {
        const results = out.split('\n')
        expect(results).to.include.members(Object.values(pins))
      })
    })

    it('handles multiple hashes', function () {
      return ipfs(`pin ls ${pins.root} ${pins.solarWiki}`)
        .then(out => {
          expect(out).to.eql(
            `${pins.root} recursive\n${pins.solarWiki} direct\n`
          )
        })
    })

    it('can print quietly', function () {
      return ipfs('pin ls -q').then(out => {
        const firstLineParts = out.split(/\s/)[0].split(' ')
        expect(firstLineParts).to.have.length(1)
      })
    })

    it('should ls and print CIDs encoded in specified base', () => {
      return ipfs(`pin ls ${pins.root} --cid-base=base64`)
        .then(out => {
          const b64CidStr = new CID(pins.root).toV1().toBaseEncodedString('base64')
          expect(out).to.eql(`${b64CidStr} recursive\n`)
        })
    })
  })
}))

'''
'''--- test/cli/ping.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const series = require('async/series')
const DaemonFactory = require('ipfsd-ctl')
const ipfsExec = require('../utils/ipfs-exec')

const df = DaemonFactory.create({ type: 'js' })
const expect = chai.expect
chai.use(dirtyChai)

const config = {
  Bootstrap: [],
  Discovery: {
    MDNS: {
      Enabled:
        false
    }
  }
}

describe('ping', function () {
  this.timeout(60 * 1000)
  let ipfsdA
  let ipfsdB
  let bMultiaddr
  let ipfsdBId
  let cli

  before((done) => {
    this.timeout(60 * 1000)
    series([
      (cb) => {
        df.spawn({
          exec: `./src/cli/bin.js`,
          config,
          initOptions: { bits: 512 }
        }, (err, _ipfsd) => {
          expect(err).to.not.exist()
          ipfsdB = _ipfsd
          cb()
        })
      },
      (cb) => {
        ipfsdB.api.id((err, peerInfo) => {
          expect(err).to.not.exist()
          ipfsdBId = peerInfo.id
          bMultiaddr = peerInfo.addresses[0]
          cb()
        })
      }
    ], done)
  })

  before(function (done) {
    this.timeout(60 * 1000)

    df.spawn({
      exec: './src/cli/bin.js',
      config,
      initoptions: { bits: 512 }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsdA = _ipfsd
      // Without DHT we need to have an already established connection
      ipfsdA.api.swarm.connect(bMultiaddr, done)
    })
  })

  before((done) => {
    this.timeout(60 * 1000)
    cli = ipfsExec(ipfsdA.repoPath)
    done()
  })

  after((done) => {
    if (!ipfsdA) return done()
    ipfsdA.stop(done)
  })

  after((done) => {
    if (!ipfsdB) return done()
    ipfsdB.stop(done)
  })

  it('ping host', (done) => {
    this.timeout(60 * 1000)
    const ping = cli(`ping ${ipfsdBId}`)
    const result = []
    ping.stdout.on('data', (output) => {
      const packets = output.toString().split('\n').slice(0, -1)
      result.push(...packets)
    })

    ping.stdout.on('end', () => {
      expect(result).to.have.lengthOf(12)
      expect(result[0]).to.equal(`PING ${ipfsdBId}`)
      for (let i = 1; i < 11; i++) {
        expect(result[i]).to.match(/^Pong received: time=\d+ ms$/)
      }
      expect(result[11]).to.match(/^Average latency: \d+(.\d+)?ms$/)
      done()
    })

    ping.catch((err) => {
      expect(err).to.not.exist()
    })
  })

  it('ping host with --n option', (done) => {
    this.timeout(60 * 1000)
    const ping = cli(`ping --n 1 ${ipfsdBId}`)
    const result = []
    ping.stdout.on('data', (output) => {
      const packets = output.toString().split('\n').slice(0, -1)
      result.push(...packets)
    })

    ping.stdout.on('end', () => {
      expect(result).to.have.lengthOf(3)
      expect(result[0]).to.equal(`PING ${ipfsdBId}`)
      expect(result[1]).to.match(/^Pong received: time=\d+ ms$/)
      expect(result[2]).to.match(/^Average latency: \d+(.\d+)?ms$/)
      done()
    })

    ping.catch((err) => {
      expect(err).to.not.exist()
    })
  })

  it('ping host with --count option', (done) => {
    this.timeout(60 * 1000)
    const ping = cli(`ping --count 1 ${ipfsdBId}`)
    const result = []
    ping.stdout.on('data', (output) => {
      const packets = output.toString().split('\n').slice(0, -1)
      result.push(...packets)
    })

    ping.stdout.on('end', () => {
      expect(result).to.have.lengthOf(3)
      expect(result[0]).to.equal(`PING ${ipfsdBId}`)
      expect(result[1]).to.match(/^Pong received: time=\d+ ms$/)
      expect(result[2]).to.match(/^Average latency: \d+(.\d+)?ms$/)
      done()
    })

    ping.catch((err) => {
      expect(err).to.not.exist()
    })
  })
})

'''
'''--- test/cli/progress-bar.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const createProgressBar = require('../../src/cli/utils').createProgressBar

describe('progress bar', () => {
  it('created with the correct properties', () => {
    const total = 1000

    const bar = createProgressBar(total)
    expect(bar.total).to.eql(total)
    expect(typeof bar.tick).to.eql('function')
  })
})

'''
'''--- test/cli/pubsub.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const delay = require('delay')
const series = require('async/series')
const ipfsExec = require('../utils/ipfs-exec')
const IPFS = require('../../src')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'js' })

const config = {
  Bootstrap: [],
  Discovery: {
    MDNS: {
      Enabled:
        false
    }
  }
}

describe('pubsub', function () {
  this.timeout(80 * 1000)

  let node
  let ipfsdA
  let ipfsdB
  let cli
  let httpApi

  const topicA = 'nonscentsA'
  const topicB = 'nonscentsB'
  const topicC = 'nonscentsC'

  before(function (done) {
    this.timeout(60 * 1000)

    DaemonFactory
      .create({ type: 'proc' })
      .spawn({
        exec: IPFS,
        initOptions: { bits: 512 },
        config,
        args: ['--enable-pubsub-experiment']
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsdA = _ipfsd
        node = _ipfsd.api
        done()
      })
  })

  after((done) => ipfsdB.stop(done))

  before((done) => {
    df.spawn({
      initOptions: { bits: 512 },
      args: ['--enable-pubsub-experiment'],
      exec: `./src/cli/bin.js`,
      config
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      httpApi = _ipfsd.api
      ipfsdB = _ipfsd
      httpApi.repoPath = ipfsdB.repoPath
      done()
    })
  })

  after((done) => ipfsdA.stop(done))
  after((done) => ipfsdB.stop(done))

  before((done) => {
    cli = ipfsExec(httpApi.repoPath)
    done()
  })

  it('subscribe and publish', () => {
    const sub = cli(`pubsub sub ${topicA}`)

    sub.stdout.on('data', (c) => {
      expect(c.toString().trim()).to.be.eql('world')
      sub.kill()
    })

    return Promise.all([
      sub.catch(ignoreKill),
      delay(1000)
        .then(() => cli(`pubsub pub ${topicA} world`))
        .then((out) => {
          expect(out).to.be.eql('')
        })
    ])
  })

  it('ls', function () {
    this.timeout(80 * 1000)
    let sub

    return new Promise((resolve, reject) => {
      sub = cli(`pubsub sub ${topicB}`)
      sub.stdout.once('data', d => resolve(d.toString().trim()))
      delay(200).then(() => cli(`pubsub pub ${topicB} world`))
    })
      .then(data => expect(data).to.be.eql('world'))
      .then(() => cli('pubsub ls'))
      .then(out => {
        expect(out.trim()).to.be.eql(topicB)
        sub.kill()
        return sub.catch(ignoreKill)
      })
  })

  it('peers', (done) => {
    let sub
    let instancePeerId
    let peerAddress
    const handler = (msg) => {
      expect(msg.data.toString()).to.be.eql('world')
      cli(`pubsub peers ${topicC}`)
        .then((out) => {
          expect(out.trim()).to.be.eql(instancePeerId)
          sub.kill()
          node.pubsub.unsubscribe(topicC, handler)
          done()
        })
    }

    series([
      (cb) => httpApi.id((err, peerInfo) => {
        expect(err).to.not.exist()
        peerAddress = peerInfo.addresses[0]
        expect(peerAddress).to.exist()
        cb()
      }),
      (cb) => node.id((err, peerInfo) => {
        expect(err).to.not.exist()
        instancePeerId = peerInfo.id.toString()
        cb()
      }),
      (cb) => node.swarm.connect(peerAddress, cb),
      (cb) => node.pubsub.subscribe(topicC, handler, cb)
    ],
    (err) => {
      expect(err).to.not.exist()
      sub = cli(`pubsub sub ${topicC}`)

      return Promise.all([
        sub.catch(ignoreKill),
        delay(1000)
          .then(() => cli(`pubsub pub ${topicC} world`))
      ])
    })
  })
})

function ignoreKill (err) {
  if (!err.killed) {
    throw err
  }
}

'''
'''--- test/cli/repo.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const repoVersion = require('ipfs-repo').repoVersion

const runOnAndOff = require('../utils/on-and-off')

describe('repo', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('get the repo version', () => {
    return ipfs('repo version').then((out) => {
      expect(out).to.eql(`${repoVersion}\n`)
    })
  })
}))

'''
'''--- test/cli/resolve.js ---
/* eslint-env mocha */
'use strict'

const path = require('path')
const expect = require('chai').expect
const isIpfs = require('is-ipfs')
const CID = require('cids')

const runOnAndOff = require('../utils/on-and-off')

describe('resolve', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('should resolve an IPFS hash', () => {
    const filePath = path.join(process.cwd(), '/src/init-files/init-docs/readme')
    let hash

    return ipfs(`add ${filePath}`)
      .then((out) => {
        hash = out.split(' ')[1]
        expect(isIpfs.cid(hash)).to.be.true()
        return ipfs(`resolve /ipfs/${hash}`)
      })
      .then((out) => {
        expect(out).to.contain(`/ipfs/${hash}`)
      })
  })

  it('should resolve an IPFS hash and print CID encoded in specified base', function () {
    this.timeout(10 * 1000)

    const filePath = path.join(process.cwd(), '/src/init-files/init-docs/readme')
    let b58Hash
    let b64Hash

    return ipfs(`add ${filePath}`)
      .then((out) => {
        b58Hash = out.split(' ')[1]
        expect(isIpfs.cid(b58Hash)).to.be.true()
        b64Hash = new CID(b58Hash).toV1().toBaseEncodedString('base64')
        return ipfs(`resolve /ipfs/${b58Hash} --cid-base=base64`)
      })
      .then((out) => {
        expect(out).to.contain(`/ipfs/${b64Hash}`)
      })
  })

  it('should resolve an IPFS path link', function () {
    this.timeout(10 * 1000)

    const filePath = path.join(process.cwd(), '/src/init-files/init-docs/readme')
    let fileHash, rootHash

    return ipfs(`add ${filePath} --wrap-with-directory`)
      .then((out) => {
        const lines = out.split('\n')

        fileHash = lines[0].split(' ')[1]
        rootHash = lines[1].split(' ')[1]

        expect(isIpfs.cid(fileHash)).to.be.true()
        expect(isIpfs.cid(rootHash)).to.be.true()

        return ipfs(`resolve /ipfs/${rootHash}/readme`)
      })
      .then((out) => {
        expect(out).to.contain(`/ipfs/${fileHash}`)
      })
  })
}))

'''
'''--- test/cli/swarm.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const series = require('async/series')
const ipfsExec = require('../utils/ipfs-exec')

const parallel = require('async/parallel')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'js' })

const config = {
  Bootstrap: [],
  Discovery: {
    MDNS: {
      Enabled:
        false
    }
  }
}

describe('swarm', () => {
  let bMultiaddr
  let ipfsA

  let nodes = []
  before(function (done) {
    // CI takes longer to instantiate the daemon, so we need to increase the
    // timeout for the before step
    this.timeout(80 * 1000)

    series([
      (cb) => {
        df.spawn({
          exec: `./src/cli/bin.js`,
          config,
          initOptions: { bits: 512 }
        }, (err, node) => {
          expect(err).to.not.exist()
          ipfsA = ipfsExec(node.repoPath)
          nodes.push(node)
          cb()
        })
      },
      (cb) => {
        df.spawn({
          exec: `./src/cli/bin.js`,
          config,
          initOptions: { bits: 512 }
        }, (err, node) => {
          expect(err).to.not.exist()
          node.api.id((err, id) => {
            expect(err).to.not.exist()
            bMultiaddr = id.addresses[0]
            nodes.push(node)
            cb()
          })
        })
      }
    ], done)
  })

  after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

  describe('daemon on (through http-api)', function () {
    this.timeout(60 * 1000)

    it('connect', () => {
      return ipfsA('swarm', 'connect', bMultiaddr).then((out) => {
        expect(out).to.eql(`connect ${bMultiaddr} success\n`)
      })
    })

    it('peers', () => {
      return ipfsA('swarm peers').then((out) => {
        expect(out).to.eql(bMultiaddr + '\n')
      })
    })

    it('addrs', () => {
      return ipfsA('swarm addrs').then((out) => {
        expect(out).to.have.length.above(1)
      })
    })

    it('addrs local', () => {
      return ipfsA('swarm addrs local').then((out) => {
        expect(out).to.have.length.above(1)
      })
    })

    it('disconnect', () => {
      return ipfsA('swarm', 'disconnect', bMultiaddr).then((out) => {
        expect(out).to.eql(
          `disconnect ${bMultiaddr} success\n`
        )
      })
    })

    it('`peers` should not throw after `disconnect`', () => {
      return ipfsA('swarm peers').then((out) => {
        expect(out).to.be.empty()
      })
    })
  })
})

'''
'''--- test/cli/version.js ---
/* eslint max-nested-callbacks: ["error", 5] */
/* eslint-env mocha */
'use strict'

const os = require('os')
const expect = require('chai').expect
const repoVersion = require('ipfs-repo').repoVersion
const pkgversion = require('../../package.json').version
const runOnAndOff = require('../utils/on-and-off')

describe('version', () => runOnAndOff((thing) => {
  let ipfs

  before(() => {
    ipfs = thing.ipfs
  })

  it('get the version', () =>
    ipfs('version').then(out =>
      expect(out).to.eql(
        `js-ipfs version: ${pkgversion}\n`
      )
    )
  )

  it('handles --number', () =>
    ipfs('version --number').then(out =>
      expect(out).to.eql(`${pkgversion}\n`)
    )
  )

  it('handles --commit', () =>
    ipfs('version --commit').then(out =>
      expect(out).to.eql(`js-ipfs version: ${pkgversion}-\n`)
    )
  )

  describe('handles --all', function () {
    it('prints js-ipfs version', () =>
      ipfs('version --all').then(out => {
        expect(out).to.include(`js-ipfs version: ${pkgversion}`)
      })
    )

    it('prints repo version', () =>
      ipfs('version --all').then(out => {
        expect(out).to.include(`Repo version: ${repoVersion}`)
      })
    )

    it('prints arch/platform', () =>
      ipfs('version --all').then(out => {
        expect(out).to.include(`System version: ${os.arch()}/${os.platform()}`)
      })
    )

    it('prints Node.js version', () =>
      ipfs('version --all').then(out => {
        expect(out).to.include(`Node.js version: ${process.version}`)
      })
    )
  })

  it('handles --repo', () =>
    ipfs('version --repo').then(out =>
      expect(out).to.eql(`${repoVersion}\n`)
    )
  )
}))

'''
'''--- test/core/bitswap.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const _ = require('lodash')
const series = require('async/series')
const waterfall = require('async/waterfall')
const parallel = require('async/parallel')
const Block = require('ipfs-block')
const multiaddr = require('multiaddr')
const isNode = require('detect-node')
const multihashing = require('multihashing-async')
const CID = require('cids')

const IPFSFactory = require('ipfsd-ctl')

const IPFS = require('../../src/core')

function makeBlock (callback) {
  const d = Buffer.from(`IPFS is awesome ${Math.random()}`)

  multihashing(d, 'sha2-256', (err, multihash) => {
    if (err) {
      return callback(err)
    }
    callback(null, new Block(d, new CID(multihash)))
  })
}

function wire (targetNode, dialerNode, callback) {
  targetNode.id((err, identity) => {
    expect(err).to.not.exist()
    const addr = identity.addresses
      .map((addr) => multiaddr(addr.toString().split('ipfs')[0]))
      .filter((addr) => _.includes(addr.protoNames(), 'ws'))[0]

    if (!addr) {
      // Note: the browser doesn't have a websockets listening addr
      return callback()
    }

    const targetAddr = addr
      .encapsulate(multiaddr(`/ipfs/${identity.id}`)).toString()
      .replace('0.0.0.0', '127.0.0.1')

    dialerNode.swarm.connect(targetAddr, callback)
  })
}

function connectNodes (remoteNode, inProcNode, callback) {
  series([
    (cb) => wire(remoteNode, inProcNode, cb),
    // need timeout so we wait for identify to happen.
    // This call is just to ensure identify happened
    (cb) => setTimeout(() => wire(inProcNode, remoteNode, cb), 500)
  ], callback)
}

let nodes = []

function addNode (fDaemon, inProcNode, callback) {
  fDaemon.spawn({
    exec: './src/cli/bin.js',
    initOptions: { bits: 512 },
    config: {
      Addresses: {
        Swarm: [`/ip4/127.0.0.1/tcp/0/ws`]
      },
      Discovery: {
        MDNS: {
          Enabled: false
        }
      },
      Bootstrap: []
    }
  }, (err, ipfsd) => {
    expect(err).to.not.exist()
    nodes.push(ipfsd)
    connectNodes(ipfsd.api, inProcNode, (err) => callback(err, ipfsd.api))
  })
}

describe('bitswap', function () {
  this.timeout(80 * 1000)

  let inProcNode // Node spawned inside this process
  let fDaemon
  let fInProc

  before(function () {
    fDaemon = IPFSFactory.create({ type: 'js' })
    fInProc = IPFSFactory.create({ type: 'proc' })
  })

  beforeEach(function (done) {
    this.timeout(60 * 1000)

    let config = {
      Addresses: {
        Swarm: []
      },
      Discovery: {
        MDNS: {
          Enabled: false
        }
      },
      Bootstrap: []
    }

    if (isNode) {
      config = Object.assign({}, config, {
        config: {
          Addresses: {
            Swarm: ['/ip4/127.0.0.1/tcp/0']
          }
        }
      })
    }

    fInProc.spawn({
      exec: IPFS,
      config: config,
      initOptions: { bits: 512 }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      nodes.push(_ipfsd)
      inProcNode = _ipfsd.api
      done()
    })
  })

  afterEach(function (done) {
    this.timeout(80 * 1000)
    const tasks = nodes.map((node) => (cb) => node.stop(cb))
    parallel(tasks, (err) => {
      expect(err).to.not.exist()
      nodes = []
      done()
    })
  })

  describe('transfer a block between', () => {
    it('2 peers', function (done) {
      this.timeout(80 * 1000)

      let remoteNode
      let block
      waterfall([
        (cb) => parallel([
          (cb) => makeBlock(cb),
          (cb) => addNode(fDaemon, inProcNode, cb)
        ], cb),
        (res, cb) => {
          block = res[0]
          remoteNode = res[1]
          cb()
        },
        (cb) => remoteNode.block.put(block, cb),
        (key, cb) => inProcNode.block.get(block.cid, cb),
        (b, cb) => {
          expect(b.data).to.eql(block.data)
          cb()
        }
      ], done)
    })

    it('3 peers', function (done) {
      this.timeout(80 * 1000)

      let blocks
      const remoteNodes = []

      series([
        (cb) => parallel(_.range(6).map((i) => makeBlock), (err, _blocks) => {
          expect(err).to.not.exist()
          blocks = _blocks
          cb()
        }),
        (cb) => addNode(fDaemon, inProcNode, (err, _ipfs) => {
          remoteNodes.push(_ipfs)
          cb(err)
        }),
        (cb) => addNode(fDaemon, inProcNode, (err, _ipfs) => {
          remoteNodes.push(_ipfs)
          cb(err)
        }),
        (cb) => connectNodes(remoteNodes[0], remoteNodes[1], cb),
        (cb) => remoteNodes[0].block.put(blocks[0], cb),
        (cb) => remoteNodes[0].block.put(blocks[1], cb),
        (cb) => remoteNodes[1].block.put(blocks[2], cb),
        (cb) => remoteNodes[1].block.put(blocks[3], cb),
        (cb) => inProcNode.block.put(blocks[4], cb),
        (cb) => inProcNode.block.put(blocks[5], cb),
        // 3. Fetch blocks on all nodes
        (cb) => parallel(_.range(6).map((i) => (cbI) => {
          const check = (n, cid, callback) => {
            n.block.get(cid, (err, b) => {
              expect(err).to.not.exist()
              expect(b).to.eql(blocks[i])
              callback()
            })
          }

          series([
            (cbJ) => check(remoteNodes[0], blocks[i].cid, cbJ),
            (cbJ) => check(remoteNodes[1], blocks[i].cid, cbJ),
            (cbJ) => check(inProcNode, blocks[i].cid, cbJ)
          ], cbI)
        }), cb)
      ], done)
    })
  })

  describe('transfer a file between', function () {
    this.timeout(160 * 1000)

    it('2 peers', (done) => {
      // TODO make this test more interesting (10Mb file)
      // TODO remove randomness from the test
      const file = Buffer.from(`I love IPFS <3 ${Math.random()}`)

      waterfall([
        // 0. Start node
        (cb) => addNode(fDaemon, inProcNode, cb),
        // 1. Add file to tmp instance
        (remote, cb) => {
          remote.add([{ path: 'awesome.txt', content: file }], cb)
        },
        // 2. Request file from local instance
        (filesAdded, cb) => inProcNode.cat(filesAdded[0].hash, cb)
      ], (err, data) => {
        expect(err).to.not.exist()
        expect(data).to.eql(file)
        done()
      })
    })
  })

  describe('unwant', () => {
    it('should callback with error for invalid CID input', (done) => {
      inProcNode.bitswap.unwant('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })
})

'''
'''--- test/core/block.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const hat = require('hat')

const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('block', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('get', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.block.get('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })

  describe('put', () => {
    it('should not error when passed null options', (done) => {
      ipfs.block.put(Buffer.from(hat()), null, (err) => {
        expect(err).to.not.exist()
        done()
      })
    })
  })

  describe('rm', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.block.rm('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })

  describe('stat', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.block.stat('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })

    it('should not error when passed null options', (done) => {
      ipfs.block.put(Buffer.from(hat()), (err, block) => {
        expect(err).to.not.exist()

        ipfs.block.stat(block.cid, null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })
})

'''
'''--- test/core/bootstrap.spec.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const isNode = require('detect-node')
const IPFS = require('../../src')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'proc' })

describe('bootstrap', () => {
  if (!isNode) {
    return
  }

  let node
  let ipfsd

  before(function (done) {
    this.timeout(40 * 1000)
    df.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: {
        Addresses: {
          Swarm: ['/ip4/127.0.0.1/tcp/0']
        }
      }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      node = _ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  const defaultList = [
    '/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
    '/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6'
  ]

  const updatedList = [
    '/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
    '/ip4/104.236.179.241/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip4/162.243.248.213/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip4/128.199.219.111/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip4/104.236.76.40/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip4/178.62.158.247/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip4/178.62.61.185/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/ip6/2604:a880:1:20::1f9:9001/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z',
    '/ip6/2604:a880:1:20::203:d001/tcp/4001/ipfs/QmSoLPppuBtQSGwKDZT2M73ULpjvfd3aZ6ha4oFGL1KrGM',
    '/ip6/2604:a880:0:1010::23:d001/tcp/4001/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',
    '/ip6/2400:6180:0:d0::151:6001/tcp/4001/ipfs/QmSoLSafTMBsPKadTEgaXctDQVcqN88CNLHXMkTNwMKPnu',
    '/ip6/2604:a880:800:10::4a:5001/tcp/4001/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',
    '/ip6/2a03:b0c0:0:1010::23:1001/tcp/4001/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',
    '/ip6/2a03:b0c0:1:d0::e7:1/tcp/4001/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',
    '/ip6/2604:a880:1:20::1d9:6001/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx',
    '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',
    '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',
    '/ip4/111.111.111.111/tcp/1001/ipfs/QmXFX2P5ammdmXQgfqGkfswtEVFsZUJ5KeHRXQYCTdiTAb'
  ]

  it('get bootstrap list', (done) => {
    node.bootstrap.list((err, list) => {
      expect(err).to.not.exist()
      expect(list.Peers).to.deep.equal(defaultList)
      done()
    })
  })

  it('add a peer to the bootstrap list', (done) => {
    node.bootstrap.add('/ip4/111.111.111.111/tcp/1001/ipfs/QmXFX2P5ammdmXQgfqGkfswtEVFsZUJ5KeHRXQYCTdiTAb', (err, res) => {
      expect(err).to.not.exist()
      expect(res).to.be.eql({ Peers: ['/ip4/111.111.111.111/tcp/1001/ipfs/QmXFX2P5ammdmXQgfqGkfswtEVFsZUJ5KeHRXQYCTdiTAb'] })
      node.bootstrap.list((err, list) => {
        expect(err).to.not.exist()
        expect(list.Peers).to.deep.equal(updatedList)
        done()
      })
    })
  })

  it('remove a peer from the bootstrap list', (done) => {
    node.bootstrap.rm('/ip4/111.111.111.111/tcp/1001/ipfs/QmXFX2P5ammdmXQgfqGkfswtEVFsZUJ5KeHRXQYCTdiTAb', (err, res) => {
      expect(err).to.not.exist()
      expect(res).to.be.eql({ Peers: ['/ip4/111.111.111.111/tcp/1001/ipfs/QmXFX2P5ammdmXQgfqGkfswtEVFsZUJ5KeHRXQYCTdiTAb'] })
      node.bootstrap.list((err, list) => {
        expect(err).to.not.exist()
        expect(list.Peers).to.deep.equal(defaultList)
        done()
      })
    })
  })

  it('fails if passing in a invalid multiaddr', (done) => {
    node.bootstrap.add('/funky/invalid/multiaddr', (err, res) => {
      expect(err).to.match(/not a valid Multiaddr/)
      expect(err).to.match(/funky/)
      expect(res).to.not.exist()
      done()
    })
  })
})

'''
'''--- test/core/circuit-relay.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const parallel = require('async/parallel')
const series = require('async/series')
const waterfall = require('async/waterfall')
const multiaddr = require('multiaddr')
const crypto = require('crypto')
const IPFS = require('../../src')

const DaemonFactory = require('ipfsd-ctl')
const procDf = DaemonFactory.create({ type: 'proc', exec: IPFS })

const baseConf = {
  Bootstrap: [],
  Addresses: {
    API: '/ip4/0.0.0.0/tcp/0',
    Gateway: '/ip4/0.0.0.0/tcp/0'
  },
  Discovery: {
    MDNS: {
      Enabled:
        false
    }
  }
}

function setupInProcNode (addrs, hop, callback) {
  if (typeof hop === 'function') {
    callback = hop
    hop = false
  }

  procDf.spawn({
    libp2p: {
      config: {
        relay: {
          enabled: true,
          hop: {
            enabled: hop
          }
        }
      }
    },
    config: Object.assign({}, baseConf, {
      Addresses: {
        Swarm: addrs
      }
    })
  }, (err, ipfsd) => {
    expect(err).to.not.exist()
    ipfsd.api.id((err, id) => {
      callback(err, { ipfsd, addrs: id.addresses })
    })
  })
}

const wsAddr = (addrs) => addrs.map((a) => a.toString()).find((a) => a.includes('/ws'))
const tcpAddr = (addrs) => addrs.map((a) => a.toString()).find((a) => !a.includes('/ws'))

describe('circuit relay', () => {
  describe(`A <-> R <-> B`, function () {
    this.timeout(80 * 1000)

    let nodeA
    let nodeAAddr
    let nodeB
    let nodeBAddr
    let nodeBCircuitAddr

    let relayNode

    let nodes
    before('create and connect', function (done) {
      parallel([
        (cb) => setupInProcNode([
          '/ip4/0.0.0.0/tcp/0',
          '/ip4/0.0.0.0/tcp/0/ws'
        ], true, cb),
        (cb) => setupInProcNode(['/ip4/0.0.0.0/tcp/0'], cb),
        (cb) => setupInProcNode(['/ip4/0.0.0.0/tcp/0/ws'], cb)
      ], function (err, res) {
        expect(err).to.not.exist()
        nodes = res.map((node) => node.ipfsd)

        relayNode = res[0].ipfsd

        nodeAAddr = tcpAddr(res[1].addrs)
        nodeA = res[1].ipfsd.api

        nodeBAddr = wsAddr(res[2].addrs)

        nodeB = res[2].ipfsd.api
        nodeBCircuitAddr = `/p2p-circuit/ipfs/${multiaddr(nodeBAddr).getPeerId()}`

        // ensure we have an address string
        expect(nodeAAddr).to.be.a('string')
        expect(nodeBAddr).to.be.a('string')
        expect(nodeBCircuitAddr).to.be.a('string')

        series([
          (cb) => relayNode.api.swarm.connect(nodeAAddr, cb),
          (cb) => relayNode.api.swarm.connect(nodeBAddr, cb),
          (cb) => setTimeout(cb, 1000),
          (cb) => nodeA.swarm.connect(nodeBCircuitAddr, cb)
        ], done)
      })
    })

    after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

    it('should transfer', function (done) {
      const data = crypto.randomBytes(128)
      waterfall([
        (cb) => nodeA.add(data, cb),
        (res, cb) => nodeB.cat(res[0].hash, cb),
        (buffer, cb) => {
          expect(buffer).to.deep.equal(data)
          cb()
        }
      ], done)
    })
  })
})

'''
'''--- test/core/config.spec.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const config = require('../../src/core/config')

describe('config', () => {
  it('should allow empty config', () => {
    const cfg = {}
    expect(() => config.validate(cfg)).to.not.throw()
  })

  it('should allow undefined config', () => {
    const cfg = undefined
    expect(() => config.validate(cfg)).to.not.throw()
  })

  it('should allow unknown key at root', () => {
    const cfg = { [`${Date.now()}`]: 'test' }
    expect(() => config.validate(cfg)).to.not.throw()
  })

  it('should validate valid repo', () => {
    const cfgs = [
      { repo: { unknown: 'value' } },
      { repo: '/path/to-repo' },
      { repo: null },
      { repo: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid repo', () => {
    const cfgs = [
      { repo: 138 }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid init', () => {
    const cfgs = [
      { init: { bits: 138 } },
      { init: { bits: 138, unknown: 'value' } },
      { init: true },
      { init: false },
      { init: null },
      { init: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid init', () => {
    const cfgs = [
      { init: 138 },
      { init: { bits: 'not an int' } }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid start', () => {
    const cfgs = [
      { start: true },
      { start: false },
      { start: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid start', () => {
    const cfgs = [
      { start: 138 },
      { start: 'make it so number 1' },
      { start: null }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid pass', () => {
    const cfgs = [
      { pass: 'correctbatteryhorsestaple' },
      { pass: '' },
      { pass: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid pass', () => {
    const cfgs = [
      { pass: 138 },
      { pass: null }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid relay', () => {
    const cfgs = [
      { relay: { enabled: true, hop: { enabled: true } } },
      { relay: { enabled: false, hop: { enabled: false } } },
      { relay: { enabled: false, hop: null } },
      { relay: { enabled: false } },
      { relay: null },
      { relay: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid relay', () => {
    const cfgs = [
      { relay: 138 },
      { relay: { enabled: 138 } },
      { relay: { enabled: true, hop: 138 } },
      { relay: { enabled: true, hop: { enabled: 138 } } }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid EXPERIMENTAL', () => {
    const cfgs = [
      { EXPERIMENTAL: { pubsub: true, dht: true, sharding: true } },
      { EXPERIMENTAL: { pubsub: false, dht: false, sharding: false } },
      { EXPERIMENTAL: { unknown: 'value' } },
      { EXPERIMENTAL: null },
      { EXPERIMENTAL: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid EXPERIMENTAL', () => {
    const cfgs = [
      { EXPERIMENTAL: { pubsub: 138 } },
      { EXPERIMENTAL: { dht: 138 } },
      { EXPERIMENTAL: { sharding: 138 } }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid config', () => {
    const cfgs = [
      { config: { Addresses: { Swarm: ['/ip4/0.0.0.0/tcp/4002'] } } },
      { config: { Addresses: { Swarm: [] } } },
      { config: { Addresses: { Swarm: undefined } } },

      { config: { Addresses: { API: '/ip4/127.0.0.1/tcp/5002' } } },
      { config: { Addresses: { API: undefined } } },

      { config: { Addresses: { Gateway: '/ip4/127.0.0.1/tcp/9090' } } },
      { config: { Addresses: { Gateway: undefined } } },

      { config: { Addresses: { unknown: 'value' } } },
      { config: { Addresses: null } },
      { config: { Addresses: undefined } },

      { config: { Discovery: { MDNS: { Enabled: true } } } },
      { config: { Discovery: { MDNS: { Enabled: false } } } },
      { config: { Discovery: { MDNS: { Interval: 138 } } } },
      { config: { Discovery: { MDNS: { unknown: 'value' } } } },
      { config: { Discovery: { MDNS: null } } },
      { config: { Discovery: { MDNS: undefined } } },

      { config: { Discovery: { webRTCStar: { Enabled: true } } } },
      { config: { Discovery: { webRTCStar: { Enabled: false } } } },
      { config: { Discovery: { webRTCStar: { unknown: 'value' } } } },
      { config: { Discovery: { webRTCStar: null } } },
      { config: { Discovery: { webRTCStar: undefined } } },

      { config: { Discovery: { unknown: 'value' } } },
      { config: { Discovery: null } },
      { config: { Discovery: undefined } },

      { config: { Bootstrap: ['/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z'] } },
      { config: { Bootstrap: [] } },

      { config: { unknown: 'value' } },
      { config: null },
      { config: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid config', () => {
    const cfgs = [
      { config: { Addresses: { Swarm: 138 } } },
      { config: { Addresses: { Swarm: null } } },

      { config: { Addresses: { API: 138 } } },
      { config: { Addresses: { API: null } } },

      { config: { Addresses: { Gateway: 138 } } },
      { config: { Addresses: { Gateway: null } } },

      { config: { Discovery: { MDNS: { Enabled: 138 } } } },
      { config: { Discovery: { MDNS: { Interval: true } } } },

      { config: { Discovery: { webRTCStar: { Enabled: 138 } } } },

      { config: { Bootstrap: ['/ip4/0.0.0.0/tcp/4002'] } },
      { config: { Bootstrap: 138 } },

      { config: 138 }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })

  it('should validate valid libp2p', () => {
    const cfgs = [
      { libp2p: { modules: {} } },
      { libp2p: { modules: { unknown: 'value' } } },
      { libp2p: { modules: null } },
      { libp2p: { modules: undefined } },
      { libp2p: { unknown: 'value' } },
      { libp2p: () => {} },
      { libp2p: null },
      { libp2p: undefined }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.not.throw())
  })

  it('should validate invalid libp2p', () => {
    const cfgs = [
      { libp2p: { modules: 138 } },
      { libp2p: 138 }
    ]

    cfgs.forEach(cfg => expect(() => config.validate(cfg)).to.throw())
  })
})

'''
'''--- test/core/create-node.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const series = require('async/series')
const sinon = require('sinon')
const waterfall = require('async/waterfall')
const parallel = require('async/parallel')
const os = require('os')
const path = require('path')
const hat = require('hat')

const isNode = require('detect-node')
const IPFS = require('../../src/core')

// This gets replaced by `create-repo-browser.js` in the browser
const createTempRepo = require('../utils/create-repo-nodejs.js')

describe('create node', function () {
  let tempRepo

  beforeEach(() => {
    tempRepo = createTempRepo()
  })

  afterEach((done) => tempRepo.teardown(done))

  it('custom repoPath', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: path.join(os.tmpdir(), 'ipfs-repo-' + hat()),
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    node.once('start', (err) => {
      expect(err).to.not.exist()

      node.config.get((err, config) => {
        expect(err).to.not.exist()

        expect(config.Identity).to.exist()
        node.once('stop', done)
        node.stop()
      })
    })
  })

  it('custom repo', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    node.once('start', (err) => {
      expect(err).to.not.exist()
      node.config.get((err, config) => {
        expect(err).to.not.exist()

        expect(config.Identity).to.exist()
        node.once('stop', done)
        node.stop()
      })
    })
  })

  it('IPFS.createNode', function (done) {
    this.timeout(80 * 1000)

    const node = IPFS.createNode({
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    node.once('start', (err) => {
      expect(err).to.not.exist()
      node.config.get((err, config) => {
        expect(err).to.not.exist()

        expect(config.Identity).to.exist()
        // note: key length doesn't map to buffer length
        expect(config.Identity.PrivKey.length).is.below(2048)

        node.once('stop', done)
        node.stop()
      })
    })
  })

  it('init: { bits: 1024 }', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      init: {
        bits: 512
      },
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    node.once('start', (err) => {
      expect(err).to.not.exist()
      node.config.get((err, config) => {
        expect(err).to.not.exist()
        expect(config.Identity).to.exist()
        expect(config.Identity.PrivKey.length).is.below(1024)
        node.once('stop', done)
        node.stop()
      })
    })
  })

  it('should be silent', function (done) {
    this.timeout(30 * 1000)

    sinon.spy(console, 'log')

    const ipfs = new IPFS({
      silent: true,
      repo: tempRepo
    })

    ipfs.on('ready', () => {
      expect(console.log.called).to.be.false()
      console.log.restore()
      ipfs.stop(done)
    })
  })

  it('init: false errors (start default: true) and errors only once', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      init: false,
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    const shouldHappenOnce = () => {
      let timeoutId = null

      return (err) => {
        expect(err).to.exist()

        // Bad news, this handler has been executed before
        if (timeoutId) {
          clearTimeout(timeoutId)
          return done(new Error('error handler called multiple times'))
        }

        timeoutId = setTimeout(done, 100)
      }
    }

    node.on('error', shouldHappenOnce())
  })

  it('init: false, start: false', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      init: false,
      start: false,
      config: {
        Addresses: {
          Swarm: []
        }
      }
    })

    let happened = false

    function shouldNotHappen () {
      happened = true
    }

    node.once('error', shouldNotHappen)
    node.once('start', shouldNotHappen)
    node.once('stop', shouldNotHappen)

    setTimeout(() => {
      expect(happened).to.equal(false)
      done()
    }, 250)
  })

  it('init: true, start: false', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      init: true,
      start: false,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      }
    })

    node.once('error', done)
    node.once('stop', done)
    node.once('start', () => node.stop())

    node.once('ready', () => node.start())
  })

  it('init: true, start: false, use callback', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      init: true,
      start: false,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      }
    })

    node.once('error', done)
    node.once('ready', () => node.start(() => node.stop(done)))
  })

  it('overload config', function (done) {
    this.timeout(80 * 1000)

    if (!isNode) { return done() }

    const node = new IPFS({
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: ['/ip4/127.0.0.1/tcp/9977']
        },
        Bootstrap: []
      }
    })

    node.once('start', (err) => {
      expect(err).to.not.exist()
      node.config.get((err, config) => {
        expect(err).to.not.exist()

        expect(config.Addresses.Swarm).to.eql(['/ip4/127.0.0.1/tcp/9977'])
        expect(config.Bootstrap).to.eql([])

        node.stop(done)
      })
    })
  })

  it('start and stop, start and stop', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      }
    })

    series([
      (cb) => node.once('start', cb),
      (cb) => node.stop(cb),
      (cb) => node.start(cb),
      (cb) => node.stop(cb)
    ], done)
  })

  it('stop as promised', function (done) {
    this.timeout(80 * 1000)

    const node = new IPFS({
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      }
    })

    node.once('ready', () => {
      node.stop()
        .then(done)
        .catch(done)
    })
  })

  it('can start node twice without crash', function (done) {
    this.timeout(80 * 1000)

    const options = {
      repo: tempRepo,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      }
    }

    let node = new IPFS(options)

    series([
      (cb) => node.once('start', cb),
      (cb) => node.stop(cb),
      (cb) => {
        node = new IPFS(options)
        node.once('error', cb)
        node.once('start', cb)
      },
      (cb) => node.stop(cb)
    ], done)
  })

  it('does not share identity with a simultaneously created node', function (done) {
    this.timeout(2 * 60 * 1000)

    let _nodeNumber = 0
    function createNode (repo) {
      _nodeNumber++
      return new IPFS({
        repo,
        init: { emptyRepo: true },
        config: {
          Addresses: {
            API: `/ip4/127.0.0.1/tcp/${5010 + _nodeNumber}`,
            Gateway: `/ip4/127.0.0.1/tcp/${9090 + _nodeNumber}`,
            Swarm: [
              `/ip4/0.0.0.0/tcp/${4010 + _nodeNumber * 2}`
            ]
          },
          Bootstrap: []
        }
      })
    }

    let repoA
    let repoB
    let nodeA
    let nodeB

    waterfall([
      (cb) => {
        repoA = createTempRepo()
        repoB = createTempRepo()
        nodeA = createNode(repoA)
        nodeB = createNode(repoB)
        cb()
      },
      (cb) => parallel([
        (cb) => nodeA.once('start', cb),
        (cb) => nodeB.once('start', cb)
      ], cb),
      (_, cb) => parallel([
        (cb) => nodeA.id(cb),
        (cb) => nodeB.id(cb)
      ], cb),
      ([idA, idB], cb) => {
        expect(idA.id).to.not.equal(idB.id)
        cb()
      }
    ], (error) => {
      parallel([
        (cb) => nodeA.stop(cb),
        (cb) => nodeB.stop(cb)
      ], (stopError) => {
        parallel([
          (cb) => repoA.teardown(cb),
          (cb) => repoB.teardown(cb)
        ], (teardownError) => {
          done(error || stopError || teardownError)
        })
      })
    })
  })
})

'''
'''--- test/core/dag.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('dag', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('get', () => {
    it('should callback with error for invalid string CID input', (done) => {
      ipfs.dag.get('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })

    it('should callback with error for invalid buffer CID input', (done) => {
      ipfs.dag.get(Buffer.from('INVALID CID'), (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })

  describe('tree', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.dag.tree('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })
})

'''
'''--- test/core/dht.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('dht', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(30 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: {
        Bootstrap: []
      }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('findprovs', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.dht.findProvs('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })
  })
})

'''
'''--- test/core/files-regular-utils.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const utils = require('../../src/core/components/files-regular/utils')

describe('files-regular/utils', () => {
  describe('parseChunkerString', () => {
    it('handles an empty string', () => {
      const options = utils.parseChunkerString('')
      expect(options).to.have.property('chunker').to.equal('fixed')
    })

    it('handles a null chunker string', () => {
      const options = utils.parseChunkerString(null)
      expect(options).to.have.property('chunker').to.equal('fixed')
    })

    it('parses a fixed size string', () => {
      const options = utils.parseChunkerString('size-512')
      expect(options).to.have.property('chunker').to.equal('fixed')
      expect(options)
        .to.have.property('chunkerOptions')
        .to.have.property('maxChunkSize')
        .to.equal(512)
    })

    it('parses a rabin string without size', () => {
      const options = utils.parseChunkerString('rabin')
      expect(options).to.have.property('chunker').to.equal('rabin')
      expect(options)
        .to.have.property('chunkerOptions')
        .to.have.property('avgChunkSize')
    })

    it('parses a rabin string with only avg size', () => {
      const options = utils.parseChunkerString('rabin-512')
      expect(options).to.have.property('chunker').to.equal('rabin')
      expect(options)
        .to.have.property('chunkerOptions')
        .to.have.property('avgChunkSize')
        .to.equal(512)
    })

    it('parses a rabin string with min, avg, and max', () => {
      const options = utils.parseChunkerString('rabin-42-92-184')
      expect(options).to.have.property('chunker').to.equal('rabin')
      expect(options).to.have.property('chunkerOptions')
      expect(options.chunkerOptions).to.have.property('minChunkSize').to.equal(42)
      expect(options.chunkerOptions).to.have.property('avgChunkSize').to.equal(92)
      expect(options.chunkerOptions).to.have.property('maxChunkSize').to.equal(184)
    })

    it('throws an error for unsupported chunker type', () => {
      const fn = () => utils.parseChunkerString('fake-512')
      expect(fn).to.throw(Error)
    })

    it('throws an error for incorrect format string', () => {
      const fn = () => utils.parseChunkerString('fixed-abc')
      expect(fn).to.throw(Error)
    })

    it('throws an error for incorrect rabin format string', () => {
      let fn = () => utils.parseChunkerString('rabin-1-2-3-4')
      expect(fn).to.throw(Error)
    })

    it('throws an error for non integer rabin parameters', () => {
      const fn = () => utils.parseChunkerString('rabin-abc')
      expect(fn).to.throw(Error)
    })
  })
})

'''
'''--- test/core/files-sharding.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const pull = require('pull-stream')

const IPFS = require('../../src/core')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'proc' })

describe('files directory (sharding tests)', () => {
  function createTestFiles () {
    const files = []

    for (let i = 0; i < 1005; i++) {
      files.push({
        path: 'test-folder/' + i,
        content: Buffer.from('some content ' + i)
      })
    }

    return files
  }

  describe('without sharding', () => {
    let ipfs
    let ipfsd

    before(function (done) {
      this.timeout(40 * 1000)

      df.spawn({
        exec: IPFS,
        initOptions: { bits: 512 },
        config: {
          Addresses: {
            Swarm: []
          },
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            }
          }
        }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsd = _ipfsd
        ipfs = _ipfsd.api
        done()
      })
    })

    after(function (done) {
      this.timeout(40 * 1000)
      ipfsd.stop(done)
    })

    it('should be able to add dir without sharding', function (done) {
      this.timeout(70 * 1000)

      pull(
        pull.values(createTestFiles()),
        ipfs.addPullStream(),
        pull.collect((err, results) => {
          expect(err).to.not.exist()
          const last = results[results.length - 1]
          expect(last.path).to.eql('test-folder')
          expect(last.hash).to.eql('QmWWM8ZV6GPhqJ46WtKcUaBPNHN5yQaFsKDSQ1RE73w94Q')
          done()
        })
      )
    })
  })

  describe('with sharding', () => {
    let ipfs
    let ipfsd

    before(function (done) {
      this.timeout(40 * 1000)

      df.spawn({
        exec: IPFS,
        initOptions: { bits: 512 },
        args: ['--enable-sharding-experiment'],
        config: {
          Addresses: {
            Swarm: []
          },
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            }
          }
        }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsd = _ipfsd
        ipfs = _ipfsd.api
        done()
      })
    })

    after(function (done) {
      this.timeout(40 * 1000)
      ipfsd.stop(done)
    })

    it('should be able to add dir with sharding', function (done) {
      this.timeout(80 * 1000)

      pull(
        pull.values(createTestFiles()),
        ipfs.addPullStream(),
        pull.collect((err, results) => {
          expect(err).to.not.exist()
          const last = results[results.length - 1]
          expect(last.path).to.eql('test-folder')
          expect(last.hash).to.eql('Qmb3JNLq2KcvDTSGT23qNQkMrr4Y4fYMktHh6DtC7YatLa')
          done()
        })
      )
    })
  })
})

'''
'''--- test/core/files.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const hat = require('hat')
const pull = require('pull-stream')
const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('files', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('get', () => {
    it('should callback with error for invalid IPFS path input', (done) => {
      const invalidPath = null
      ipfs.get(invalidPath, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_PATH')
        done()
      })
    })
  })

  describe('getReadableStream', () => {
    it('should return erroring stream for invalid IPFS path input', (done) => {
      const invalidPath = null
      const stream = ipfs.getReadableStream(invalidPath)

      stream.on('error', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_PATH')
        done()
      })
    })
  })

  describe('getPullStream', () => {
    it('should return erroring stream for invalid IPFS path input', (done) => {
      const invalidPath = null
      pull(
        ipfs.getPullStream(invalidPath),
        pull.collect((err) => {
          expect(err).to.exist()
          expect(err.code).to.equal('ERR_INVALID_PATH')
          done()
        })
      )
    })
  })

  describe('add', () => {
    it('should not error when passed null options', (done) => {
      ipfs.add(Buffer.from(hat()), null, (err) => {
        expect(err).to.not.exist()
        done()
      })
    })

    it('should add a file with a v1 CID', (done) => {
      ipfs.add(Buffer.from([0, 1, 2]), {
        cidVersion: 1
      }, (err, files) => {
        expect(err).to.not.exist()
        expect(files.length).to.equal(1)
        expect(files[0].hash).to.equal('zb2rhiNedvrkpYhcrgtpmhKk5UPzcgizgSXaQLYXNY745BmYP')
        expect(files[0].size).to.equal(3)
        done()
      })
    })

    it('should add a file with a v1 CID and not raw leaves', (done) => {
      ipfs.add(Buffer.from([0, 1, 2]), {
        cidVersion: 1,
        rawLeaves: false
      }, (err, files) => {
        expect(err).to.not.exist()
        expect(files.length).to.equal(1)
        expect(files[0].hash).to.equal('zdj7WcDSFNSsZkdkbpSDGeLsBtHbYKyvPQsaw6PpeeYdGqoAx')
        expect(files[0].size).to.equal(11)
        done()
      })
    })
  })
})

'''
'''--- test/core/init.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const isNode = require('detect-node')
const hat = require('hat')
const crypto = require('libp2p-crypto')
const isIPFS = require('is-ipfs')
const IPFS = require('../../src/core')

const privateKey = 'CAASqAkwggSkAgEAAoIBAQChVmiObYo6pkKrMSd3OzW1cTL+RDmX1rkETYGKWV9TPXMNgElFTYoYHqT9QZomj5RI8iUmHccjzqr4J0mV+E0NpvHHOLlmDZ82lAw2Zx7saUkeQWvC0S9Z0o3aTx2sSubZV53rSomkZgQH4fYTs4RERejV4ltzLFdzQQBwWrBvlagpPHUCxKDUCnE5oIzdbD26ltWViPBWr7TfotzC8Lyi/tceqCpHMUJGMbsVgypnlgpey07MBvs71dVh5LcRen/ztsQO6Yju4D3QgWoyD0SIUdJFvBzEwL9bSiA3QjUc/fkGd7EcdN5bebYOqAi4ZIiAMLp3i4+B8Tzq/acull43AgMBAAECggEBAIDgZE75o4SsEO9tKWht7L5OeXxxBUyMImkUfJkGQUZd/MzZIC5y/Q+9UvBW+gs5gCsw+onTGaM50Iq/32Ej4nE4XURVxIuH8BmJ86N1hlc010qK2cjajqeCsPulXT+m6XbOLYCpnv+q2idt0cL1EH/1FEPeOEztK8ION4qIdw36SoykfTx/RqtkKHtS01AwN82EOPbWk7huyQT5R5MsCZmRJXBFkpNtiL+8619BH2aVlghHO4NouF9wQjdz/ysVuyYg+3rX2cpGjuHDTZ6hVQiJD1lF6D+dua7UPyHYAG2iRQiKZmCjitt9ywzPxiRaYF/aZ02FEMWckZulR09axskCgYEAzjl6ER8WwxYHn4tHse+CrIIF2z5cscdrh7KSwd3Rse9hIIBDJ/0KkvoYd1IcWrS8ywLrRfSLIjEU9u7IN1m+IRVWJ61fXNqOHm9clAu6qNhCN6W2+JfxDkUygTwmsq0v3huO+qkiMQz+a4nAXJe8Utd36ywgPhVGxFa/7x1v1N0CgYEAyEdiYRFf1aQZcO7+B2FH+tkGJsB30VIBhcpG9EukuQUUulLHhScc/KRj+EFAACLdkTqlVI0xVYIWaaCXwoQCWKixjZ5mYPC+bBLgn4IoDS6XTdHtR7Vn3UUvGTKsM0/z4e8/0eSzGNCHoYez9IoBlPNic0sQuST4jzgS2RYnFCMCgYASWSzSLyjwTJp7CIJlg4Dl5l+tBRxsOOkJVssV8q2AnmLO6HqRKUNylkvs+eJJ88DEc0sJm1txvFo4KkCoJBT1jpduyk8szMlOTew3w99kvHEP0G+6KJKrCV8X/okW5q/WnC8ZgEjpglV0rfnugxWfbUpfIzrvKydzuqAzHzRfBQKBgQDANtKSeoxRjEbmfljLWHAure8bbgkQmfXgI7xpZdfXwqqcECpw/pLxXgycDHOSLeQcJ/7Y4RGCEXHVOk2sX+mokW6mjmmPjD4VlyCBtfcef6KzC1EBS3c9g9KqCln+fTOBmY7UsPu6SxiAzK7HeVP/Un8gS+Dm8DalrZlZQ8uJpQKBgF6mL/Xo/XUOiz2jAD18l8Y6s49bA9H2CoLpBGTV1LfY5yTFxRy4R3qnX/IzsKy567sbtkEFKJxplc/RzCQfrgbdj7k26SbKtHR3yERaFGRYq8UeAHeYC1/N19LF5BMQL4y5R4PJ1SFPeJCL/wXiMqs1maTqvKqtc4bbegNdwlxn'

// This gets replaced by `create-repo-browser.js` in the browser
const createTempRepo = require('../utils/create-repo-nodejs.js')

describe('init', () => {
  if (!isNode) { return }

  let ipfs
  let repo

  beforeEach(() => {
    repo = createTempRepo()

    ipfs = new IPFS({
      repo: repo,
      init: false,
      start: false
    })
  })

  afterEach((done) => repo.teardown(done))

  it('basic', (done) => {
    ipfs.init({ bits: 512, pass: hat() }, (err) => {
      expect(err).to.not.exist()

      repo.exists((err, res) => {
        expect(err).to.not.exist()
        expect(res).to.equal(true)

        repo.config.get((err, config) => {
          expect(err).to.not.exist()
          expect(config.Identity).to.exist()
          expect(config.Keychain).to.exist()
          done()
        })
      })
    })
  })

  it('set # of bits in key', function (done) {
    this.timeout(40 * 1000)

    ipfs.init({ bits: 1024, pass: hat() }, (err) => {
      expect(err).to.not.exist()

      repo.config.get((err, config) => {
        expect(err).to.not.exist()
        expect(config.Identity.PrivKey.length).is.above(256)
        done()
      })
    })
  })

  it('pregenerated key is being used', (done) => {
    ipfs.init({ privateKey }, (err) => {
      expect(err).to.not.exist()

      repo.config.get((err, config) => {
        expect(err).to.not.exist()
        expect(config.Identity.PeerID).is.equal('QmRsooYQasV5f5r834NSpdUtmejdQcpxXkK6qsozZWEihC')
        done()
      })
    })
  })

  it('init docs are written', (done) => {
    ipfs.init({ bits: 512, pass: hat() }, (err) => {
      expect(err).to.not.exist()
      const multihash = 'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB'

      ipfs.object.get(multihash, { enc: 'base58' }, (err, node) => {
        expect(err).to.not.exist()
        expect(node.links).to.exist()
        done()
      })
    })
  })

  it('empty repo', (done) => {
    ipfs.init({ bits: 512, emptyRepo: true }, (err) => {
      expect(err).to.not.exist()

      // Should not have default assets
      const multihash = Buffer.from('12205e7c3ce237f936c76faf625e90f7751a9f5eeb048f59873303c215e9cce87599', 'hex')

      ipfs.object.get(multihash, {}, (err, node) => {
        expect(err).to.exist()
        done()
      })
    })
  })

  it('util', () => {
    expect(ipfs.util).to.be.deep.equal({
      crypto: crypto,
      isIPFS: isIPFS
    })
  })
})

'''
'''--- test/core/interface.spec.js ---
/* eslint-env mocha, browser */
'use strict'

const tests = require('interface-ipfs-core')
const CommonFactory = require('../utils/interface-common-factory')
const isNode = require('detect-node')
const dnsFetchStub = require('../utils/dns-fetch-stub')

describe('interface-ipfs-core tests', function () {
  this.timeout(20 * 1000)

  // ipfs.dns in the browser calls out to https://ipfs.io/api/v0/dns.
  // The following code stubs self.fetch to return a static CID for calls
  // to https://ipfs.io/api/v0/dns?arg=ipfs.io.
  if (!isNode) {
    const fetch = self.fetch

    before(() => {
      self.fetch = dnsFetchStub(fetch)
    })

    after(() => {
      self.fetch = fetch
    })
  }

  const defaultCommonFactory = CommonFactory.create()

  tests.bitswap(defaultCommonFactory, { skip: !isNode })

  tests.block(defaultCommonFactory)

  tests.bootstrap(defaultCommonFactory)

  tests.config(defaultCommonFactory)

  tests.dag(defaultCommonFactory)

  tests.dht(CommonFactory.create({
    spawnOptions: {
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      },
      initOptions: { bits: 512 }
    }
  }), {
    skip: isNode ? [
      // dht.get
      {
        name: 'should get a value after it was put on another node',
        reason: 'Needs https://github.com/ipfs/interface-ipfs-core/pull/383'
      }
    ] : true
  })

  tests.filesRegular(defaultCommonFactory, {
    skip: isNode ? null : [{
      name: 'addFromStream',
      reason: 'Not designed to run in the browser'
    }, {
      name: 'addFromFs',
      reason: 'Not designed to run in the browser'
    }, {
      name: 'addFromURL',
      reason: 'Not designed to run in the browser'
    }]
  })

  // TODO needs MFS module to be updated
  // tests.filesMFS(defaultCommonFactory)

  tests.key(CommonFactory.create({
    spawnOptions: {
      args: ['--pass ipfs-is-awesome-software'],
      initOptions: { bits: 512 }
    }
  }))

  tests.miscellaneous(CommonFactory.create({
    // No need to stop, because the test suite does a 'stop' test.
    createTeardown: () => cb => cb()
  }), {
    skip: [
      {
        name: 'should resolve an IPNS DNS link',
        reason: 'TODO IPNS not implemented yet'
      },
      {
        name: 'should resolve IPNS link recursively',
        reason: 'TODO IPNS not implemented yet'
      }
    ]
  })

  tests.name(CommonFactory.create({
    spawnOptions: {
      args: ['--pass ipfs-is-awesome-software', '--offline'],
      initOptions: { bits: 512 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }
  }))

  tests.namePubsub(CommonFactory.create({
    spawnOptions: {
      args: ['--enable-namesys-pubsub'],
      initOptions: { bits: 1024 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }
  }))

  tests.object(defaultCommonFactory)

  tests.pin(defaultCommonFactory)

  tests.ping(defaultCommonFactory, {
    skip: isNode ? null : {
      reason: 'FIXME: ping implementation requires DHT'
    }
  })

  tests.pubsub(CommonFactory.create({
    spawnOptions: {
      args: ['--enable-pubsub-experiment'],
      initOptions: { bits: 512 }
    }
  }), {
    skip: isNode ? null : {
      reason: 'FIXME: disabled because no swarm addresses'
    }
  })

  tests.repo(defaultCommonFactory, {
    skip: [
      // repo.gc
      {
        name: 'gc',
        reason: 'TODO: repo.gc is not implemented in js-ipfs yet!'
      }
    ]
  })

  tests.stats(defaultCommonFactory)

  tests.swarm(CommonFactory.create({
    createSetup ({ ipfsFactory, nodes }) {
      return callback => {
        callback(null, {
          spawnNode (repoPath, config, cb) {
            if (typeof repoPath === 'function') {
              cb = repoPath
              repoPath = undefined
            }

            if (typeof config === 'function') {
              cb = config
              config = null
            }

            const spawnOptions = { repoPath, config, initOptions: { bits: 512 } }

            ipfsFactory.spawn(spawnOptions, (err, _ipfsd) => {
              if (err) {
                return cb(err)
              }

              nodes.push(_ipfsd)
              cb(null, _ipfsd.api)
            })
          }
        })
      }
    }
  }), { skip: !isNode })

  tests.types(defaultCommonFactory)

  tests.util(defaultCommonFactory, { skip: { reason: 'FIXME: currently failing' } })
})

'''
'''--- test/core/kad-dht.node.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const parallel = require('async/parallel')

const IPFSFactory = require('ipfsd-ctl')
const f = IPFSFactory.create({ type: 'js' })

const config = {
  Bootstrap: [],
  Discovery: {
    MDNS: {
      Enabled: false
    },
    webRTCStar: {
      Enabled: false
    }
  }
}

function createNode (callback) {
  f.spawn({
    exec: './src/cli/bin.js',
    config,
    initOptions: { bits: 512 }
  }, callback)
}

describe('kad-dht is routing content and peers correctly', () => {
  let nodeA
  let nodeB
  let nodeC
  let addrB
  let addrC

  let nodes
  before(function (done) {
    this.timeout(30 * 1000)

    parallel([
      (cb) => createNode(cb),
      (cb) => createNode(cb),
      (cb) => createNode(cb)
    ], (err, _nodes) => {
      expect(err).to.not.exist()
      nodes = _nodes
      nodeA = _nodes[0].api
      nodeB = _nodes[1].api
      nodeC = _nodes[2].api
      parallel([
        (cb) => nodeA.id(cb),
        (cb) => nodeB.id(cb),
        (cb) => nodeC.id(cb)
      ], (err, ids) => {
        expect(err).to.not.exist()
        addrB = ids[1].addresses[0]
        addrC = ids[2].addresses[0]
        parallel([
          (cb) => nodeA.swarm.connect(addrB, cb),
          (cb) => nodeB.swarm.connect(addrC, cb)
        ], done)
      })
    })
  })

  after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

  it('add a file in B, fetch in A', function (done) {
    this.timeout(30 * 1000)
    const file = {
      path: 'testfile1.txt',
      content: Buffer.from('hello kad 1')
    }

    nodeB.add(file, (err, filesAdded) => {
      expect(err).to.not.exist()

      nodeA.cat(filesAdded[0].hash, (err, data) => {
        expect(err).to.not.exist()
        expect(data).to.eql(file.content)
        done()
      })
    })
  })

  it('add a file in C, fetch through B in A', function (done) {
    this.timeout(30 * 1000)
    const file = {
      path: 'testfile2.txt',
      content: Buffer.from('hello kad 2')
    }

    nodeC.add(file, (err, filesAdded) => {
      expect(err).to.not.exist()

      nodeA.cat(filesAdded[0].hash, (err, data) => {
        expect(err).to.not.exist()
        expect(data).to.eql(file.content)
        done()
      })
    })
  })
})

'''
'''--- test/core/key-exchange.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const hat = require('hat')
const IPFS = require('../../src/core')

// This gets replaced by `create-repo-browser.js` in the browser
const createTempRepo = require('../utils/create-repo-nodejs.js')

describe('key exchange', () => {
  let ipfs
  let repo
  let selfPem
  let passwordPem = hat()

  before(function (done) {
    this.timeout(20 * 1000)
    repo = createTempRepo()
    ipfs = new IPFS({
      repo: repo,
      pass: hat()
    })
    ipfs.on('ready', () => done())
  })

  after((done) => ipfs.stop(done))

  after((done) => repo.teardown(done))

  it('exports', (done) => {
    ipfs.key.export('self', passwordPem, (err, pem) => {
      expect(err).to.not.exist()
      expect(pem).to.exist()
      selfPem = pem
      done()
    })
  })

  it('imports', function (done) {
    this.timeout(20 * 1000)

    ipfs.key.import('clone', selfPem, passwordPem, (err, key) => {
      expect(err).to.not.exist()
      expect(key).to.exist()
      expect(key).to.have.property('name', 'clone')
      expect(key).to.have.property('id')
      done()
    })
  })
})

'''
'''--- test/core/libp2p.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const MemoryStore = require('interface-datastore').MemoryDatastore
const PeerInfo = require('peer-info')
const PeerBook = require('peer-book')
const WebSocketStar = require('libp2p-websocket-star')
const Multiplex = require('libp2p-mplex')
const SECIO = require('libp2p-secio')
const KadDHT = require('libp2p-kad-dht')
const Libp2p = require('libp2p')

const libp2pComponent = require('../../src/core/components/libp2p')

describe('libp2p customization', function () {
  // Provide some extra time for ci since we're starting libp2p nodes in each test
  this.timeout(25 * 1000)

  let datastore
  let peerInfo
  let peerBook
  let testConfig
  let _libp2p

  before(function (done) {
    this.timeout(25 * 1000)

    testConfig = {
      Addresses: {
        Swarm: ['/ip4/0.0.0.0/tcp/4002'],
        API: '/ip4/127.0.0.1/tcp/5002',
        Gateway: '/ip4/127.0.0.1/tcp/9090'
      },
      Discovery: {
        MDNS: {
          Enabled: false
        },
        webRTCStar: {
          Enabled: false
        }
      },
      EXPERIMENTAL: {
        pubsub: false
      }
    }
    datastore = new MemoryStore()
    peerBook = new PeerBook()
    PeerInfo.create((err, pi) => {
      peerInfo = pi
      done(err)
    })
  })

  afterEach((done) => {
    if (!_libp2p) return done()

    _libp2p.stop(() => {
      _libp2p = null
      done()
    })
  })

  describe('bundle', () => {
    it('should allow for using a libp2p bundle', (done) => {
      const ipfs = {
        _repo: {
          datastore
        },
        _peerInfo: peerInfo,
        _peerBook: peerBook,
        _print: console.log,
        _options: {
          libp2p: (opts) => {
            const wsstar = new WebSocketStar({ id: opts.peerInfo.id })

            return new Libp2p({
              peerInfo: opts.peerInfo,
              peerBook: opts.peerBook,
              modules: {
                transport: [
                  wsstar
                ],
                streamMuxer: [
                  Multiplex
                ],
                connEncryption: [
                  SECIO
                ],
                peerDiscovery: [
                  wsstar.discovery
                ],
                dht: KadDHT
              }
            })
          }
        }
      }

      _libp2p = libp2pComponent(ipfs, testConfig)

      _libp2p.start((err) => {
        expect(err).to.not.exist()
        expect(_libp2p._config).to.not.have.property('peerDiscovery')
        expect(_libp2p._transport).to.have.length(1)
        done()
      })
    })
  })

  describe('options', () => {
    it('should use options by default', (done) => {
      const ipfs = {
        _repo: {
          datastore
        },
        _peerInfo: peerInfo,
        _peerBook: peerBook,
        _print: console.log
      }

      _libp2p = libp2pComponent(ipfs, testConfig)

      _libp2p.start((err) => {
        expect(err).to.not.exist()
        expect(_libp2p._config).to.deep.include({
          peerDiscovery: {
            bootstrap: {
              enabled: true,
              list: []
            },
            mdns: {
              enabled: false
            },
            webRTCStar: {
              enabled: false
            },
            websocketStar: {
              enabled: true
            }
          },
          EXPERIMENTAL: {
            pubsub: false
          }
        })
        expect(_libp2p._transport).to.have.length(3)
        done()
      })
    })

    it('should allow for overriding via options', (done) => {
      const wsstar = new WebSocketStar({ id: peerInfo.id })

      const ipfs = {
        _repo: {
          datastore
        },
        _peerInfo: peerInfo,
        _peerBook: peerBook,
        _print: console.log,
        _options: {
          config: {
            Discovery: {
              MDNS: {
                Enabled: true
              }
            }
          },
          EXPERIMENTAL: {
            pubsub: true
          },
          libp2p: {
            modules: {
              transport: [
                wsstar
              ],
              peerDiscovery: [
                wsstar.discovery
              ]
            }
          }
        }
      }

      _libp2p = libp2pComponent(ipfs, testConfig)

      _libp2p.start((err) => {
        expect(err).to.not.exist()
        expect(_libp2p._config).to.deep.include({
          peerDiscovery: {
            bootstrap: {
              enabled: true,
              list: []
            },
            mdns: {
              enabled: true
            },
            webRTCStar: {
              enabled: false
            },
            websocketStar: {
              enabled: true
            }
          },
          EXPERIMENTAL: {
            pubsub: true
          }
        })
        expect(_libp2p._transport).to.have.length(1)
        done()
      })
    })
  })
})

'''
'''--- test/core/mfs-preload.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const waitFor = require('../utils/wait-for')
const mfsPreload = require('../../src/core/mfs-preload')

const createMockFilesStat = (cids = []) => {
  let n = 0
  return (path, cb) => cb(null, { hash: cids[n++] || 'QmHash' })
}

const createMockPreload = () => {
  const preload = (cid, cb) => {
    preload.cids.push(cid)
    cb()
  }
  preload.cids = []
  return preload
}

describe('MFS preload', () => {
  // CIDs returned from our mock files.stat function
  const statCids = ['QmInitial', 'QmSame', 'QmSame', 'QmUpdated']
  let mockPreload
  let mockFilesStat
  let mockIpfs

  beforeEach(() => {
    mockPreload = createMockPreload()
    mockFilesStat = createMockFilesStat(statCids)
    mockIpfs = {
      files: {
        stat: mockFilesStat
      },
      _preload: mockPreload,
      _options: {
        preload: {
          interval: 10
        }
      }
    }
  })

  it('should preload MFS root periodically', function (done) {
    this.timeout(80 * 1000)

    mockIpfs._options.preload.enabled = true

    // The CIDs we expect to have been preloaded
    const expectedPreloadCids = ['QmSame', 'QmUpdated']
    const preloader = mfsPreload(mockIpfs)

    preloader.start((err) => {
      expect(err).to.not.exist()

      const test = (cb) => {
        // Slice off any extra CIDs it processed
        const cids = mockPreload.cids.slice(0, expectedPreloadCids.length)
        if (cids.length !== expectedPreloadCids.length) return cb(null, false)
        cb(null, cids.every((cid, i) => cid === expectedPreloadCids[i]))
      }

      waitFor(test, { name: 'CIDs to be preloaded' }, (err) => {
        expect(err).to.not.exist()
        preloader.stop(done)
      })
    })
  })

  it('should disable preloading MFS', function (done) {
    mockIpfs._options.preload.enabled = false

    const preloader = mfsPreload(mockIpfs)

    preloader.start((err) => {
      expect(err).to.not.exist()

      setTimeout(() => {
        expect(mockPreload.cids).to.be.empty()

        done()
      }, 500)
    })
  })
})

'''
'''--- test/core/name-pubsub.js ---
/* eslint max-nested-callbacks: ["error", 6] */
/* eslint-env mocha */
'use strict'

const hat = require('hat')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const parallel = require('async/parallel')

const isNode = require('detect-node')
const IPFS = require('../../src')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'proc' })

const ipfsRef = '/ipfs/QmPFVLPmp9zv5Z5KUqLhe2EivAGccQW2r7M7jhVJGLZoZU'

describe('name-pubsub', function () {
  if (!isNode) {
    return
  }

  let nodes
  let nodeA
  let nodeB
  let idA

  const createNode = (callback) => {
    df.spawn({
      exec: IPFS,
      args: [`--pass ${hat()}`, '--enable-namesys-pubsub'],
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }, callback)
  }

  before(function (done) {
    this.timeout(40 * 1000)

    parallel([
      (cb) => createNode(cb),
      (cb) => createNode(cb)
    ], (err, _nodes) => {
      expect(err).to.not.exist()

      nodes = _nodes
      nodeA = _nodes[0].api
      nodeB = _nodes[1].api

      parallel([
        (cb) => nodeA.id(cb),
        (cb) => nodeB.id(cb)
      ], (err, ids) => {
        expect(err).to.not.exist()

        idA = ids[0]
        nodeA.swarm.connect(ids[1].addresses[0], done)
      })
    })
  })

  after((done) => parallel(nodes.map((node) => (cb) => node.stop(cb)), done))

  it('should publish and then resolve correctly', function (done) {
    this.timeout(80 * 1000)

    nodeB.name.resolve(idA.id, (err) => {
      expect(err).to.exist()

      nodeA.name.publish(ipfsRef, { resolve: false }, (err, res) => {
        expect(err).to.not.exist()
        expect(res).to.exist()

        nodeB.name.resolve(idA.id, (err, res) => {
          expect(err).to.not.exist()
          expect(res).to.exist()
          expect(res.path).to.equal(ipfsRef)
          done()
        })
      })
    })
  })
})

'''
'''--- test/core/name.js ---
/* eslint max-nested-callbacks: ["error", 7] */
/* eslint-env mocha */
'use strict'

const hat = require('hat')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const sinon = require('sinon')

const fs = require('fs')
const parallel = require('async/parallel')
const series = require('async/series')

const isNode = require('detect-node')
const IPFS = require('../../src')
const ipnsPath = require('../../src/core/ipns/path')
const { Key } = require('interface-datastore')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ type: 'proc' })

const ipfsRef = '/ipfs/QmPFVLPmp9zv5Z5KUqLhe2EivAGccQW2r7M7jhVJGLZoZU'

const publishAndResolve = (publisher, resolver, ipfsRef, publishOpts, nodeId, resolveOpts, callback) => {
  series([
    (cb) => publisher.name.publish(ipfsRef, publishOpts, cb),
    (cb) => resolver.name.resolve(nodeId, resolveOpts, cb)
  ], (err, res) => {
    expect(err).to.not.exist()
    expect(res[0]).to.exist()
    expect(res[1]).to.exist()
    expect(res[1].path).to.equal(ipfsRef)
    callback()
  })
}

describe('name', function () {
  if (!isNode) {
    return
  }

  describe('working locally', function () {
    let node
    let nodeId
    let ipfsd

    before(function (done) {
      this.timeout(50 * 1000)
      df.spawn({
        exec: IPFS,
        args: [`--pass ${hat()}`, '--offline'],
        config: { Bootstrap: [] }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsd = _ipfsd
        node = _ipfsd.api

        node.id().then((res) => {
          expect(res.id).to.exist()

          nodeId = res.id
          done()
        })
      })
    })

    after((done) => ipfsd.stop(done))

    it('should publish and then resolve correctly with the default options', function (done) {
      this.timeout(50 * 1000)

      publishAndResolve(node, node, ipfsRef, { resolve: false }, nodeId, {}, done)
    })

    it('should publish correctly with the lifetime option and resolve', function (done) {
      this.timeout(50 * 1000)

      const publishOpts = {
        resolve: false,
        lifetime: '2h'
      }

      publishAndResolve(node, node, ipfsRef, publishOpts, nodeId, {}, done)
    })

    it('should not get the entry correctly if its validity time expired', function (done) {
      this.timeout(50 * 1000)

      node.name.publish(ipfsRef, { resolve: false, lifetime: '1ms' }, (err, res) => {
        expect(err).to.not.exist()
        expect(res).to.exist()

        setTimeout(function () {
          node.name.resolve(nodeId, (err) => {
            expect(err).to.exist()
            done()
          })
        }, 2)
      })
    })

    it('should recursively resolve to an IPFS hash', function (done) {
      this.timeout(90 * 1000)
      const keyName = hat()

      node.key.gen(keyName, { type: 'rsa', size: 2048 }, function (err, key) {
        expect(err).to.not.exist()
        series([
          (cb) => node.name.publish(ipfsRef, { resolve: false }, cb),
          (cb) => node.name.publish(`/ipns/${nodeId}`, { resolve: false, key: keyName }, cb),
          (cb) => node.name.resolve(key.id, { recursive: true }, cb)
        ], (err, res) => {
          expect(err).to.not.exist()
          expect(res[2]).to.exist()
          expect(res[2].path).to.equal(ipfsRef)
          done()
        })
      })
    })

    it('should not recursively resolve to an IPFS hash if the option recursive is not provided', function (done) {
      this.timeout(90 * 1000)
      const keyName = hat()

      node.key.gen(keyName, { type: 'rsa', size: 2048 }, function (err, key) {
        expect(err).to.not.exist()
        series([
          (cb) => node.name.publish(ipfsRef, { resolve: false }, cb),
          (cb) => node.name.publish(`/ipns/${nodeId}`, { resolve: false, key: keyName }, cb),
          (cb) => node.name.resolve(key.id, cb)
        ], (err, res) => {
          expect(err).to.not.exist()
          expect(res[2]).to.exist()
          expect(res[2].path).to.equal(`/ipns/${nodeId}`)
          done()
        })
      })
    })
  })

  describe('republisher', function () {
    if (!isNode) {
      return
    }

    let node
    let ipfsd

    before(function (done) {
      this.timeout(40 * 1000)
      df.spawn({
        exec: IPFS,
        args: [`--pass ${hat()}`, '--offline'],
        config: { Bootstrap: [] }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsd = _ipfsd
        node = _ipfsd.api

        done()
      })
    })

    afterEach(() => {
      sinon.restore()
    })

    after((done) => ipfsd.stop(done))

    it('should republish entries after 60 seconds', function (done) {
      this.timeout(120 * 1000)
      sinon.spy(node._ipns.republisher, '_republishEntries')

      setTimeout(function () {
        expect(node._ipns.republisher._republishEntries.calledOnce).to.equal(true)
        done()
      }, 60 * 1000)
    })

    it('should error if run republish again', function (done) {
      this.timeout(120 * 1000)
      sinon.spy(node._ipns.republisher, '_republishEntries')

      try {
        node._ipns.republisher.start()
      } catch (err) {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_REPUBLISH_ALREADY_RUNNING') // already runs when starting
        done()
      }
    })
  })

  describe('work with dht', () => {
    let nodes
    let nodeA
    let nodeB
    let nodeC
    let idA

    const createNode = (callback) => {
      df.spawn({
        exec: IPFS,
        args: [`--pass ${hat()}`],
        config: {
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            },
            webRTCStar: {
              Enabled: false
            }
          }
        }
      }, callback)
    }

    before(function (done) {
      this.timeout(70 * 1000)

      parallel([
        (cb) => createNode(cb),
        (cb) => createNode(cb),
        (cb) => createNode(cb)
      ], (err, _nodes) => {
        expect(err).to.not.exist()

        nodes = _nodes
        nodeA = _nodes[0].api
        nodeB = _nodes[1].api
        nodeC = _nodes[2].api

        parallel([
          (cb) => nodeA.id(cb),
          (cb) => nodeB.id(cb)
        ], (err, ids) => {
          expect(err).to.not.exist()

          idA = ids[0]
          parallel([
            (cb) => nodeC.swarm.connect(ids[0].addresses[0], cb), // C => A
            (cb) => nodeC.swarm.connect(ids[1].addresses[0], cb), // C => B
            (cb) => nodeA.swarm.connect(ids[1].addresses[0], cb) // A => B
          ], done)
        })
      })
    })

    after(function (done) {
      this.timeout(80 * 1000)

      parallel(nodes.map((node) => (cb) => node.stop(cb)), done)
    })

    it('should publish and then resolve correctly with the default options', function (done) {
      this.timeout(380 * 1000)
      publishAndResolve(nodeA, nodeB, ipfsRef, { resolve: false }, idA.id, {}, done)
    })

    it('should recursively resolve to an IPFS hash', function (done) {
      this.timeout(360 * 1000)
      const keyName = hat()

      nodeA.key.gen(keyName, { type: 'rsa', size: 2048 }, function (err, key) {
        expect(err).to.not.exist()
        series([
          (cb) => nodeA.name.publish(ipfsRef, { resolve: false }, cb),
          (cb) => nodeA.name.publish(`/ipns/${idA.id}`, { resolve: false, key: keyName }, cb),
          (cb) => nodeB.name.resolve(key.id, { recursive: true }, cb)
        ], (err, res) => {
          expect(err).to.not.exist()
          expect(res[2]).to.exist()
          expect(res[2].path).to.equal(ipfsRef)
          done()
        })
      })
    })
  })

  describe('errors', function () {
    if (!isNode) {
      return
    }

    let node
    let nodeId
    let ipfsd

    before(function (done) {
      this.timeout(40 * 1000)
      df.spawn({
        exec: IPFS,
        args: [`--pass ${hat()}`],
        config: {
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            },
            webRTCStar: {
              Enabled: false
            }
          }
        }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        ipfsd = _ipfsd
        node = _ipfsd.api

        node.id().then((res) => {
          expect(res.id).to.exist()

          nodeId = res.id
          done()
        })
      })
    })

    after((done) => ipfsd.stop(done))

    it('should error to publish if does not receive private key', function (done) {
      node._ipns.publisher.publish(null, ipfsRef, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_UNDEFINED_PARAMETER')
        done()
      })
    })

    it('should error to publish if an invalid private key is received', function (done) {
      node._ipns.publisher.publish({ bytes: 'not that valid' }, ipfsRef, (err) => {
        expect(err).to.exist()
        done()
      })
    })

    it('should error to publish if _updateOrCreateRecord fails', function (done) {
      const stub = sinon.stub(node._ipns.publisher, '_updateOrCreateRecord').callsArgWith(4, 'error')

      node.name.publish(ipfsRef, { resolve: false }, (err) => {
        expect(err).to.exist()

        stub.restore()
        done()
      })
    })

    it('should error to publish if _putRecordToRouting receives an invalid peer id', function (done) {
      node._ipns.publisher._putRecordToRouting(undefined, undefined, (err) => {
        expect(err).to.exist()
        done()
      })
    })

    it('should error to publish if receives an invalid datastore key', function (done) {
      const stub = sinon.stub(Key, 'isKey').returns(false)

      node.name.publish(ipfsRef, { resolve: false }, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_DATASTORE_KEY')

        stub.restore()
        done()
      })
    })

    it('should error to publish if we receive a unexpected error getting from datastore', function (done) {
      const stub = sinon.stub(node._ipns.publisher._datastore, 'get').callsArgWith(1, 'error-unexpected')

      node.name.publish(ipfsRef, { resolve: false }, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_DETERMINING_PUBLISHED_RECORD')

        stub.restore()
        done()
      })
    })

    it('should error to publish if we receive a unexpected error putting to datastore', function (done) {
      const stub = sinon.stub(node._ipns.publisher._datastore, 'put').callsArgWith(2, 'error-unexpected')

      node.name.publish(ipfsRef, { resolve: false }, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_STORING_IN_DATASTORE')

        stub.restore()
        done()
      })
    })

    it('should error to resolve if the received name is not a string', function (done) {
      node._ipns.resolver.resolve(false, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_PARAMETER')
        done()
      })
    })

    it('should error to resolve if receives an invalid ipns path', function (done) {
      node._ipns.resolver.resolve('ipns/<cid>', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_NAME_SYNTAX')
        done()
      })
    })

    it('should publish and then fail to resolve if receive error getting from datastore', function (done) {
      const stub = sinon.stub(node._ipns.resolver._routing, 'get').callsArgWith(1, 'error-unexpected')

      node.name.publish(ipfsRef, { resolve: false }, (err, res) => {
        expect(err).to.not.exist()
        expect(res).to.exist()

        node.name.resolve(nodeId, { nocache: true }, (err) => {
          expect(err).to.exist()
          expect(err.code).to.equal('ERR_UNEXPECTED_ERROR_GETTING_RECORD')
          stub.restore()
          done()
        })
      })
    })

    it('should publish and then fail to resolve if does not find the record', function (done) {
      const stub = sinon.stub(node._ipns.resolver._routing, 'get').callsArgWith(1, { code: 'ERR_NOT_FOUND' })

      node.name.publish(ipfsRef, { resolve: false }, (err, res) => {
        expect(err).to.not.exist()
        expect(res).to.exist()

        node.name.resolve(nodeId, { nocache: true }, (err) => {
          expect(err).to.exist()
          expect(err.code).to.equal('ERR_NO_RECORD_FOUND')
          stub.restore()
          done()
        })
      })
    })

    it('should publish and then fail to resolve if does not receive a buffer', function (done) {
      const stub = sinon.stub(node._ipns.resolver._routing, 'get').callsArgWith(1, undefined, 'data')

      node.name.publish(ipfsRef, { resolve: false }, (err, res) => {
        expect(err).to.not.exist()
        expect(res).to.exist()

        node.name.resolve(nodeId, { nocache: true }, (err) => {
          expect(err).to.exist()
          expect(err.code).to.equal('ERR_INVALID_RECORD_RECEIVED')
          stub.restore()
          done()
        })
      })
    })
  })

  describe('ipns.path', function () {
    const path = 'test/fixtures/planets/solar-system.md'
    const fixture = {
      path,
      content: fs.readFileSync(path)
    }

    let node
    let ipfsd
    let nodeId

    if (!isNode) {
      return
    }

    before(function (done) {
      this.timeout(40 * 1000)
      df.spawn({
        exec: IPFS,
        args: [`--pass ${hat()}`, '--offline'],
        config: {
          Bootstrap: [],
          Discovery: {
            MDNS: {
              Enabled: false
            },
            webRTCStar: {
              Enabled: false
            }
          }
        }
      }, (err, _ipfsd) => {
        expect(err).to.not.exist()
        node = _ipfsd.api
        ipfsd = _ipfsd

        node.id().then((res) => {
          expect(res.id).to.exist()

          nodeId = res.id
          done()
        })
      })
    })

    after((done) => ipfsd.stop(done))

    it('should resolve an ipfs path correctly', function (done) {
      node.add(fixture, (err, res) => {
        expect(err).to.not.exist()

        node.name.publish(`/ipfs/${res[0].hash}`, (err) => {
          expect(err).to.not.exist()

          ipnsPath.resolvePath(node, `/ipfs/${res[0].hash}`, (err, value) => {
            expect(err).to.not.exist()
            expect(value).to.exist()
            done()
          })
        })
      })
    })

    it('should resolve an ipns path correctly', function (done) {
      node.add(fixture, (err, res) => {
        expect(err).to.not.exist()
        node.name.publish(`/ipfs/${res[0].hash}`, (err) => {
          expect(err).to.not.exist()
          ipnsPath.resolvePath(node, `/ipns/${nodeId}`, (err, value) => {
            expect(err).to.not.exist()
            expect(value).to.exist()
            done()
          })
        })
      })
    })
  })
})

'''
'''--- test/core/node.js ---
'use strict'

require('./circuit-relay')
require('./files-regular-utils')
require('./name')
require('./key-exchange')
require('./pin')
require('./pin-set')
// require('./key-exchange')
require('./utils')

'''
'''--- test/core/object.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const hat = require('hat')
const IPFSFactory = require('ipfsd-ctl')
const auto = require('async/auto')
const waterfall = require('async/waterfall')
const IPFS = require('../../src/core')

describe('object', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(50 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('get', () => {
    it('should callback with error for invalid CID input', (done) => {
      ipfs.object.get('INVALID CID', (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_CID')
        done()
      })
    })

    it('should not error when passed null options', (done) => {
      ipfs.object.put(Buffer.from(hat()), (err, cid) => {
        expect(err).to.not.exist()

        ipfs.object.get(cid, null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })

  describe('put', () => {
    it('should not error when passed null options', (done) => {
      ipfs.object.put(Buffer.from(hat()), null, (err) => {
        expect(err).to.not.exist()
        done()
      })
    })
  })

  describe('patch.addLink', () => {
    it('should not error when passed null options', (done) => {
      auto({
        a: (cb) => {
          waterfall([
            (done) => ipfs.object.put(Buffer.from(hat()), done),
            (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
          ], cb)
        },
        b: (cb) => {
          waterfall([
            (done) => ipfs.object.put(Buffer.from(hat()), done),
            (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
          ], cb)
        }
      }, (err, results) => {
        expect(err).to.not.exist()

        const link = {
          name: 'link-name',
          cid: results.b.cid,
          size: results.b.node.size
        }

        ipfs.object.patch.addLink(results.a.cid, link, null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })

  describe('patch.rmLink', () => {
    it('should not error when passed null options', (done) => {
      auto({
        nodeA: (cb) => {
          waterfall([
            (done) => ipfs.object.put(Buffer.from(hat()), done),
            (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
          ], cb)
        },
        nodeB: (cb) => {
          waterfall([
            (done) => ipfs.object.put(Buffer.from(hat()), done),
            (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
          ], cb)
        },
        nodeAWithLink: ['nodeA', 'nodeB', (res, cb) => {
          waterfall([
            (done) => ipfs.object.patch.addLink(res.nodeA.cid, {
              name: res.nodeB.node.name,
              multihash: res.nodeB.cid,
              size: res.nodeB.node.size
            }, done),
            (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
          ], cb)
        }]
      }, (err, res) => {
        expect(err).to.not.exist()

        const link = res.nodeAWithLink.node.links[0]
        ipfs.object.patch.rmLink(res.nodeAWithLink.cid, link, null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })

  describe('patch.appendData', () => {
    it('should not error when passed null options', (done) => {
      ipfs.object.put(Buffer.from(hat()), null, (err, cid) => {
        expect(err).to.not.exist()

        ipfs.object.patch.appendData(cid, Buffer.from(hat()), null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })

  describe('patch.setData', () => {
    it('should not error when passed null options', (done) => {
      ipfs.object.put(Buffer.from(hat()), null, (err, cid) => {
        expect(err).to.not.exist()

        ipfs.object.patch.setData(cid, Buffer.from(hat()), null, (err) => {
          expect(err).to.not.exist()
          done()
        })
      })
    })
  })
})

'''
'''--- test/core/pin-set.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const parallelLimit = require('async/parallelLimit')
const series = require('async/series')
const {
  util: {
    cid
  },
  DAGNode
} = require('ipld-dag-pb')
const CID = require('cids')

const IPFS = require('../../src/core')
const createPinSet = require('../../src/core/components/pin-set')
const createTempRepo = require('../utils/create-repo-nodejs')

const defaultFanout = 256
const maxItems = 8192

/**
 * Creates @param num DAGNodes, limited to 500 at a time to save memory
 * @param  {[type]}   num      the number of nodes to create
 * @param  {Function} callback node-style callback, result is an Array of all
 *                              created nodes
 * @return {void}
 */
function createNodes (num, callback) {
  const items = []
  for (let i = 0; i < num; i++) {
    items.push(cb =>
      createNode(String(i), (err, res) => cb(err, res.cid.toBaseEncodedString()))
    )
  }

  parallelLimit(items, 500, callback)
}

function createNode (data, links = [], callback) {
  if (typeof links === 'function') {
    callback = links
    links = []
  }

  DAGNode.create(data, links, (err, node) => {
    if (err) {
      return callback(err)
    }

    cid(node, (err, result) => {
      callback(err, {
        node,
        cid: result
      })
    })
  })
}

describe('pinSet', function () {
  let ipfs
  let pinSet
  let repo

  before(function (done) {
    this.timeout(80 * 1000)
    repo = createTempRepo()
    ipfs = new IPFS({
      repo,
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          }
        }
      }
    })
    ipfs.on('ready', () => {
      pinSet = createPinSet(ipfs.dag)
      done()
    })
  })

  after(function (done) {
    this.timeout(80 * 1000)
    ipfs.stop(done)
  })

  after((done) => repo.teardown(done))

  describe('storeItems', function () {
    it('generates a root node with links and hash', function (done) {
      const expectedRootHash = 'QmcLiSTjcjoVC2iuGbk6A2PVcWV3WvjZT4jxfNis1vjyrR'

      createNode('data', (err, result) => {
        expect(err).to.not.exist()
        const nodeHash = result.cid.toBaseEncodedString()
        pinSet.storeSet([nodeHash], (err, rootNode) => {
          expect(err).to.not.exist()
          expect(rootNode.cid.toBaseEncodedString()).to.eql(expectedRootHash)
          expect(rootNode.node.links).to.have.length(defaultFanout + 1)

          const lastLink = rootNode.node.links[rootNode.node.links.length - 1]
          const mhash = lastLink.cid.toBaseEncodedString()
          expect(mhash).to.eql(nodeHash)
          done()
        })
      })
    })
  })

  describe('handles large sets', function () {
    it('handles storing items > maxItems', function (done) {
      this.timeout(90 * 1000)
      const expectedHash = 'QmbvhSy83QWfgLXDpYjDmLWBFfGc8utoqjcXHyj3gYuasT'
      const count = maxItems + 1
      createNodes(count, (err, cids) => {
        expect(err).to.not.exist()
        pinSet.storeSet(cids, (err, result) => {
          expect(err).to.not.exist()

          expect(result.node.size).to.eql(3184696)
          expect(result.node.links).to.have.length(defaultFanout)
          expect(result.cid.toBaseEncodedString()).to.eql(expectedHash)

          pinSet.loadSet(result.node, '', (err, loaded) => {
            expect(err).to.not.exist()
            expect(loaded).to.have.length(30)
            const hashes = loaded.map(l => new CID(l).toBaseEncodedString())

            // just check the first node, assume all are children if successful
            pinSet.hasDescendant(result.node, hashes[0], (err, has) => {
              expect(err).to.not.exist()
              expect(has).to.eql(true)
              done()
            })
          })
        })
      })
    })

    // This test is largely taken from go-ipfs/pin/set_test.go
    // It fails after reaching maximum call stack depth but I don't believe it's
    // infinite. We need to reference go's pinSet impl to make sure
    // our sharding behaves correctly, or perhaps this test is misguided
    it.skip('stress test: stores items > (maxItems * defaultFanout) + 1', function (done) {
      this.timeout(180 * 1000)

      // this value triggers the creation of a recursive shard.
      // If the recursive sharding is done improperly, this will result in
      // an infinite recursion and crash (OOM)
      const limit = (defaultFanout * maxItems) + 1

      createNodes(limit, (err, nodes) => {
        expect(err).to.not.exist()
        series([
          cb => pinSet.storeSet(nodes.slice(0, -1), (err, res) => {
            expect(err).to.not.exist()
            cb(null, res)
          }),
          cb => pinSet.storeSet(nodes, (err, res) => {
            expect(err).to.not.exist()
            cb(null, res)
          })
        ], (err, rootNodes) => {
          expect(err).to.not.exist()
          expect(rootNodes[1].length - rootNodes[2].length).to.eql(2)
          done()
        })
      })
    })
  })

  describe('walkItems', function () {
    it(`fails if node doesn't have a pin-set protobuf header`, function (done) {
      createNode('datum', (err, node) => {
        expect(err).to.not.exist()

        pinSet.walkItems(node, () => {}, (err, res) => {
          expect(err).to.exist()
          expect(res).to.not.exist()
          done()
        })
      })
    })

    it('visits all non-fanout links of a root node', function (done) {
      const seen = []
      const walker = (link, idx, data) => seen.push({ link, idx, data })

      createNodes(defaultFanout, (err, nodes) => {
        expect(err).to.not.exist()

        pinSet.storeSet(nodes, (err, result) => {
          expect(err).to.not.exist()

          pinSet.walkItems(result.node, walker, err => {
            expect(err).to.not.exist()
            expect(seen).to.have.length(defaultFanout)
            expect(seen[0].idx).to.eql(defaultFanout)
            seen.forEach(item => {
              expect(item.data).to.eql(Buffer.alloc(0))
              expect(item.link).to.exist()
            })
            done()
          })
        })
      })
    })
  })
})

'''
'''--- test/core/pin.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const fs = require('fs')

const IPFS = require('../../src/core')
const createTempRepo = require('../utils/create-repo-nodejs')
const expectTimeout = require('../utils/expect-timeout')

// fixture structure:
//  planets/
//   solar-system.md
//   mercury/
//    wiki.md
const pins = {
  root: 'QmTAMavb995EHErSrKo7mB8dYkpaSJxu6ys1a6XJyB2sys',
  solarWiki: 'QmTMbkDfvHwq3Aup6Nxqn3KKw9YnoKzcZvuArAfQ9GF3QG',
  mercuryDir: 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q',
  mercuryWiki: 'QmVgSHAdMxFAuMP2JiMAYkB8pCWP1tcB9djqvq8GKAFiHi'
}
const pinTypes = {
  direct: 'direct',
  recursive: 'recursive',
  indirect: 'indirect',
  all: 'all'
}

describe('pin', function () {
  const fixtures = [
    'test/fixtures/planets/mercury/wiki.md',
    'test/fixtures/planets/solar-system.md'
  ].map(path => ({
    path,
    content: fs.readFileSync(path)
  }))

  let ipfs
  let pin
  let repo

  function expectPinned (hash, type, pinned = true) {
    if (typeof type === 'boolean') {
      pinned = type
      type = undefined
    }

    return pin._isPinnedWithType(hash, type || pinTypes.all)
      .then(result => expect(result.pinned).to.eql(pinned))
  }

  function clearPins () {
    return pin.ls()
      .then(ls => {
        const pinsToRemove = ls
          .filter(out => out.type === pinTypes.recursive)
          .map(out => pin.rm(out.hash))
        return Promise.all(pinsToRemove)
      })
      .then(() => pin.ls())
      .then(ls => {
        const pinsToRemove = ls
          .filter(out => out.type === pinTypes.direct)
          .map(out => pin.rm(out.hash))
        return Promise.all(pinsToRemove)
      })
  }

  before(function (done) {
    this.timeout(20 * 1000)
    repo = createTempRepo()
    ipfs = new IPFS({
      repo,
      config: {
        Bootstrap: []
      }
    })
    ipfs.on('ready', () => {
      pin = ipfs.pin
      ipfs.add(fixtures, done)
    })
  })

  after(function (done) {
    this.timeout(60 * 1000)
    ipfs.stop(done)
  })

  after((done) => repo.teardown(done))

  describe('isPinnedWithType', function () {
    beforeEach(function () {
      return clearPins()
        .then(() => pin.add(pins.root))
    })

    it('when node is pinned', function () {
      return pin.add(pins.solarWiki)
        .then(() => pin._isPinnedWithType(pins.solarWiki, pinTypes.all))
        .then(pinned => expect(pinned.pinned).to.eql(true))
    })

    it('when node is not in datastore', function () {
      const falseHash = `${pins.root.slice(0, -2)}ss`
      return pin._isPinnedWithType(falseHash, pinTypes.all)
        .then(pinned => {
          expect(pinned.pinned).to.eql(false)
          expect(pinned.reason).to.eql(undefined)
        })
    })

    it('when node is in datastore but not pinned', function () {
      return pin.rm(pins.root)
        .then(() => expectPinned(pins.root, false))
    })

    it('when pinned recursively', function () {
      return pin._isPinnedWithType(pins.root, pinTypes.recursive)
        .then(result => {
          expect(result.pinned).to.eql(true)
          expect(result.reason).to.eql(pinTypes.recursive)
        })
    })

    it('when pinned indirectly', function () {
      return pin._isPinnedWithType(pins.mercuryWiki, pinTypes.indirect)
        .then(result => {
          expect(result.pinned).to.eql(true)
          expect(result.reason.toBaseEncodedString()).to.eql(pins.root)
        })
    })

    it('when pinned directly', function () {
      return pin.add(pins.mercuryDir, { recursive: false })
        .then(() => {
          return pin._isPinnedWithType(pins.mercuryDir, pinTypes.direct)
            .then(result => {
              expect(result.pinned).to.eql(true)
              expect(result.reason).to.eql(pinTypes.direct)
            })
        })
    })

    it('when not pinned', function () {
      return clearPins()
        .then(() => pin._isPinnedWithType(pins.mercuryDir, pinTypes.direct))
        .then(pin => expect(pin.pinned).to.eql(false))
    })
  })

  describe('add', function () {
    beforeEach(function () {
      return clearPins()
    })

    it('recursive', function () {
      return pin.add(pins.root)
        .then(() => {
          const pinChecks = Object.values(pins)
            .map(hash => expectPinned(hash))

          return Promise.all(pinChecks)
        })
    })

    it('direct', function () {
      return pin.add(pins.root, { recursive: false })
        .then(() => Promise.all([
          expectPinned(pins.root),
          expectPinned(pins.solarWiki, false)
        ]))
    })

    it('recursive pin parent of direct pin', function () {
      return pin.add(pins.solarWiki, { recursive: false })
        .then(() => pin.add(pins.root))
        .then(() => Promise.all([
          // solarWiki is pinned both directly and indirectly o.O
          expectPinned(pins.solarWiki, pinTypes.direct),
          expectPinned(pins.solarWiki, pinTypes.indirect)
        ]))
    })

    it('directly pinning a recursive pin fails', function () {
      return pin.add(pins.root)
        .then(() => pin.add(pins.root, { recursive: false }))
        .catch(err => expect(err).to.match(/already pinned recursively/))
    })

    it('can\'t pin item not in datastore', () => {
      const falseHash = `${pins.root.slice(0, -2)}ss`
      return expectTimeout(pin.add(falseHash), 4000)
    })

    // TODO block rm breaks subsequent tests
    it.skip('needs all children in datastore to pin recursively', () => {
      return ipfs.block.rm(pins.mercuryWiki)
        .then(() => expectTimeout(pin.add(pins.root), 4000))
    })
  })

  describe('ls', function () {
    before(function () {
      return clearPins()
        .then(() => Promise.all([
          pin.add(pins.root),
          pin.add(pins.mercuryDir, { recursive: false })
        ]))
    })

    it('lists pins of a particular hash', function () {
      return pin.ls(pins.mercuryDir)
        .then(out => expect(out[0].hash).to.eql(pins.mercuryDir))
    })

    it('indirect pins supersedes direct pins', function () {
      return pin.ls()
        .then(ls => {
          const pinType = ls.find(out => out.hash === pins.mercuryDir).type
          expect(pinType).to.eql(pinTypes.indirect)
        })
    })

    describe('list pins of type', function () {
      it('all', function () {
        return pin.ls()
          .then(out =>
            expect(out).to.deep.include.members([
              { type: 'recursive',
                hash: 'QmTAMavb995EHErSrKo7mB8dYkpaSJxu6ys1a6XJyB2sys' },
              { type: 'indirect',
                hash: 'QmTMbkDfvHwq3Aup6Nxqn3KKw9YnoKzcZvuArAfQ9GF3QG' },
              { type: 'indirect',
                hash: 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q' },
              { type: 'indirect',
                hash: 'QmVgSHAdMxFAuMP2JiMAYkB8pCWP1tcB9djqvq8GKAFiHi' }
            ])
          )
      })

      it('direct', function () {
        return pin.ls({ type: 'direct' })
          .then(out =>
            expect(out).to.deep.include.members([
              { type: 'direct',
                hash: 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q' }
            ])
          )
      })

      it('recursive', function () {
        return pin.ls({ type: 'recursive' })
          .then(out =>
            expect(out).to.deep.include.members([
              { type: 'recursive',
                hash: 'QmTAMavb995EHErSrKo7mB8dYkpaSJxu6ys1a6XJyB2sys' }
            ])
          )
      })

      it('indirect', function () {
        return pin.ls({ type: 'indirect' })
          .then(out =>
            expect(out).to.deep.include.members([
              { type: 'indirect',
                hash: 'QmTMbkDfvHwq3Aup6Nxqn3KKw9YnoKzcZvuArAfQ9GF3QG' },
              { type: 'indirect',
                hash: 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q' },
              { type: 'indirect',
                hash: 'QmVgSHAdMxFAuMP2JiMAYkB8pCWP1tcB9djqvq8GKAFiHi' }
            ])
          )
      })
    })
  })

  describe('rm', function () {
    beforeEach(function () {
      return clearPins()
        .then(() => pin.add(pins.root))
    })

    it('a recursive pin', function () {
      return pin.rm(pins.root)
        .then(() => {
          return Promise.all([
            expectPinned(pins.root, false),
            expectPinned(pins.mercuryWiki, false)
          ])
        })
    })

    it('a direct pin', function () {
      return clearPins()
        .then(() => pin.add(pins.mercuryDir, { recursive: false }))
        .then(() => pin.rm(pins.mercuryDir))
        .then(() => expectPinned(pins.mercuryDir, false))
    })

    it('fails to remove an indirect pin', function () {
      return pin.rm(pins.solarWiki)
        .catch(err => expect(err).to.match(/is pinned indirectly under/))
        .then(() => expectPinned(pins.solarWiki))
    })

    it('fails when an item is not pinned', function () {
      return pin.rm(pins.root)
        .then(() => pin.rm(pins.root))
        .catch(err => expect(err).to.match(/is not pinned/))
    })
  })

  describe('flush', function () {
    beforeEach(function () {
      return pin.add(pins.root)
    })

    it('flushes', function () {
      return pin.ls()
        .then(ls => expect(ls.length).to.eql(4))
        .then(() => {
          // indirectly trigger a datastore flush by adding something
          return clearPins()
            .then(() => pin.add(pins.mercuryWiki))
        })
        .then(() => pin._load())
        .then(() => pin.ls())
        .then(ls => expect(ls.length).to.eql(1))
    })
  })
})

'''
'''--- test/core/pin.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('pin', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('ls', () => {
    it('should callback with error for invalid non-string pin type option', (done) => {
      ipfs.pin.ls({ type: 6 }, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_PIN_TYPE')
        done()
      })
    })

    it('should callback with error for invalid string pin type option', (done) => {
      ipfs.pin.ls({ type: '__proto__' }, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_INVALID_PIN_TYPE')
        done()
      })
    })
  })
})

'''
'''--- test/core/ping.spec.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const pull = require('pull-stream/pull')
const drain = require('pull-stream/sinks/drain')
const parallel = require('async/parallel')
const series = require('async/series')
const DaemonFactory = require('ipfsd-ctl')
const isNode = require('detect-node')

const expect = chai.expect
chai.use(dirtyChai)
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })
const dfProc = DaemonFactory.create({
  exec: require('../../'),
  type: 'proc'
})

const config = {
  Bootstrap: [],
  Discovery: {
    MDNS: {
      Enabled:
        false
    }
  }
}

function spawnNode ({ dht = false, type = 'js' }, cb) {
  const args = dht ? [] : ['--offline']
  const factory = type === 'js' ? df : dfProc
  factory.spawn({
    args,
    config,
    initOptions: { bits: 512 }
  }, cb)
}

// Determine if a ping response object is a pong, or something else, like a status message
function isPong (pingResponse) {
  return Boolean(pingResponse && pingResponse.success && !pingResponse.text)
}

describe('ping', function () {
  this.timeout(60 * 1000)

  if (!isNode) return

  describe('in-process daemon', function () {
    let ipfsdA
    let ipfsdB
    let bMultiaddr
    let ipfsdBId

    // Spawn nodes
    before(function (done) {
      this.timeout(60 * 1000)

      series([
        spawnNode.bind(null, { dht: false, type: 'proc' }),
        spawnNode.bind(null, { dht: false })
      ], (err, ipfsd) => {
        expect(err).to.not.exist()
        ipfsdA = ipfsd[0]
        ipfsdB = ipfsd[1]
        done()
      })
    })

    // Get the peer info object
    before(async function () {
      this.timeout(60 * 1000)

      const peerInfo = await ipfsdB.api.id()

      ipfsdBId = peerInfo.id
      bMultiaddr = peerInfo.addresses[0]
    })

    // Connect the nodes
    before(async function () {
      this.timeout(60 * 1000)
      await ipfsdA.api.swarm.connect(bMultiaddr)
    })

    after(async () => {
      if (!ipfsdA) return
      await ipfsdA.stop()
    })

    after(async () => {
      if (!ipfsdB) return
      await ipfsdB.stop()
    })

    it('can ping via a promise without options', async () => {
      const res = await ipfsdA.api.ping(ipfsdBId)

      expect(res.length).to.be.ok()
      expect(res[0].success).to.be.true()
    })
  })

  describe('DHT disabled', function () {
    // Without DHT nodes need to be previously connected
    let ipfsdA
    let ipfsdB
    let bMultiaddr
    let ipfsdBId

    // Spawn nodes
    before(function (done) {
      this.timeout(60 * 1000)

      series([
        spawnNode.bind(null, { dht: false }),
        spawnNode.bind(null, { dht: false })
      ], (err, ipfsd) => {
        expect(err).to.not.exist()
        ipfsdA = ipfsd[0]
        ipfsdB = ipfsd[1]
        done()
      })
    })

    // Get the peer info object
    before(function (done) {
      this.timeout(60 * 1000)

      ipfsdB.api.id((err, peerInfo) => {
        expect(err).to.not.exist()
        ipfsdBId = peerInfo.id
        bMultiaddr = peerInfo.addresses[0]
        done()
      })
    })

    // Connect the nodes
    before(function (done) {
      this.timeout(60 * 1000)
      ipfsdA.api.swarm.connect(bMultiaddr, done)
    })

    after((done) => {
      if (!ipfsdA) return done()
      ipfsdA.stop(done)
    })

    after((done) => {
      if (!ipfsdB) return done()
      ipfsdB.stop(done)
    })

    it('sends the specified number of packets', (done) => {
      let packetNum = 0
      const count = 3
      pull(
        ipfsdA.api.pingPullStream(ipfsdBId, { count }),
        drain((res) => {
          expect(res.success).to.be.true()
          // It's a pong
          if (isPong(res)) {
            packetNum++
          }
        }, (err) => {
          expect(err).to.not.exist()
          expect(packetNum).to.equal(count)
          done()
        })
      )
    })

    it('pinging a not available peer will fail accordingly', (done) => {
      const unknownPeerId = 'QmUmaEnH1uMmvckMZbh3yShaasvELPW4ZLPWnB4entMTEn'
      let messageNum = 0
      // const count = 1
      pull(
        ipfsdA.api.pingPullStream(unknownPeerId, {}),
        drain(({ success, time, text }) => {
          messageNum++
          // Assert that the ping command falls back to the peerRouting
          if (messageNum === 1) {
            expect(text).to.include('Looking up')
          }
        }, (err) => {
          expect(err).to.exist()
          // FIXME when we can have streaming
          // expect(messageNum).to.equal(count)
          done()
        })
      )
    })
  })

  describe('DHT enabled', function () {
    // Our bootstrap process will run 3 IPFS daemons where
    // A ----> B ----> C
    // Allowing us to test the ping command using the DHT peer routing
    let ipfsdA
    let ipfsdB
    let ipfsdC
    let bMultiaddr
    let cMultiaddr
    let ipfsdCId

    // Spawn nodes
    before(function (done) {
      this.timeout(60 * 1000)

      series([
        spawnNode.bind(null, { dht: true }),
        spawnNode.bind(null, { dht: true }),
        spawnNode.bind(null, { dht: true })
      ], (err, ipfsd) => {
        expect(err).to.not.exist()
        ipfsdA = ipfsd[0]
        ipfsdB = ipfsd[1]
        ipfsdC = ipfsd[2]
        done()
      })
    })

    // Get the peer info objects
    before(function (done) {
      this.timeout(60 * 1000)

      parallel([
        ipfsdB.api.id.bind(ipfsdB.api),
        ipfsdC.api.id.bind(ipfsdC.api)
      ], (err, peerInfo) => {
        expect(err).to.not.exist()
        bMultiaddr = peerInfo[0].addresses[0]
        ipfsdCId = peerInfo[1].id
        cMultiaddr = peerInfo[1].addresses[0]
        done()
      })
    })

    // Connect the nodes
    before(function (done) {
      this.timeout(30 * 1000)
      let interval

      // Check to see if peers are already connected
      const checkConnections = () => {
        ipfsdB.api.swarm.peers((err, peerInfos) => {
          if (err) return done(err)

          if (peerInfos.length > 1) {
            clearInterval(interval)
            return done()
          }
        })
      }

      parallel([
        ipfsdA.api.swarm.connect.bind(ipfsdA.api, bMultiaddr),
        ipfsdB.api.swarm.connect.bind(ipfsdB.api, cMultiaddr)
      ], (err) => {
        if (err) return done(err)
        interval = setInterval(checkConnections, 300)
      })
    })

    after((done) => {
      if (!ipfsdA) return done()
      ipfsdA.stop(done)
    })

    after((done) => {
      if (!ipfsdB) return done()
      ipfsdB.stop(done)
    })

    after((done) => {
      if (!ipfsdC) return done()
      ipfsdC.stop(done)
    })

    it('if enabled uses the DHT peer routing to find peer', (done) => {
      let messageNum = 0
      let packetNum = 0
      const count = 3
      pull(
        ipfsdA.api.pingPullStream(ipfsdCId, { count }),
        drain((res) => {
          messageNum++
          expect(res.success).to.be.true()
          // Assert that the ping command falls back to the peerRouting
          if (messageNum === 1) {
            expect(res.text).to.include('Looking up')
          }
          // It's a pong
          if (isPong(res)) {
            packetNum++
          }
        }, (err) => {
          expect(err).to.not.exist()
          expect(packetNum).to.equal(count)
          done()
        })
      )
    })
  })
})

'''
'''--- test/core/preload.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const hat = require('hat')
const parallel = require('async/parallel')
const waterfall = require('async/waterfall')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const MockPreloadNode = require('../utils/mock-preload-node')
const IPFS = require('../../src')
const createTempRepo = require('../utils/create-repo-nodejs')

describe('preload', () => {
  let ipfs
  let repo

  before(function (done) {
    this.timeout(50 * 1000)

    repo = createTempRepo()
    ipfs = new IPFS({
      repo,
      config: {
        Addresses: {
          Swarm: []
        },
        Bootstrap: []
      },
      preload: {
        enabled: true,
        addresses: [MockPreloadNode.defaultAddr]
      }
    })

    ipfs.on('ready', done)
  })

  afterEach(function (done) {
    this.timeout(10 * 1000)
    MockPreloadNode.clearPreloadCids(done)
  })

  after(function (done) {
    this.timeout(50 * 1000)
    ipfs.stop(done)
  })

  after(function (done) {
    this.timeout(50 * 1000)
    repo.teardown(done)
  })

  it('should preload content added with add', function (done) {
    this.timeout(50 * 1000)
    ipfs.add(Buffer.from(hat()), (err, res) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(res[0].hash, done)
    })
  })

  it('should preload multiple content added with add', function (done) {
    this.timeout(50 * 1000)
    ipfs.add([{
      content: Buffer.from(hat())
    }, {
      content: Buffer.from(hat())
    }, {
      content: Buffer.from(hat())
    }], (err, res) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(res.map(file => file.hash), done)
    })
  })

  it('should preload multiple content and intermediate dirs added with add', function (done) {
    this.timeout(50 * 1000)
    ipfs.add([{
      path: 'dir0/dir1/file0',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/dir1/file1',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/file2',
      content: Buffer.from(hat())
    }], (err, res) => {
      expect(err).to.not.exist()

      const rootDir = res.find(file => file.path === 'dir0')
      expect(rootDir).to.exist()

      MockPreloadNode.waitForCids(rootDir.hash, done)
    })
  })

  it('should preload multiple content and wrapping dir for content added with add and wrapWithDirectory option', function (done) {
    this.timeout(50 * 1000)
    ipfs.add([{
      path: 'dir0/dir1/file0',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/dir1/file1',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/file2',
      content: Buffer.from(hat())
    }], { wrapWithDirectory: true }, (err, res) => {
      expect(err).to.not.exist()

      const wrappingDir = res.find(file => file.path === '')
      expect(wrappingDir).to.exist()

      MockPreloadNode.waitForCids(wrappingDir.hash, done)
    })
  })

  it('should preload content retrieved with cat', function (done) {
    this.timeout(50 * 1000)
    ipfs.add(Buffer.from(hat()), { preload: false }, (err, res) => {
      expect(err).to.not.exist()
      ipfs.cat(res[0].hash, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(res[0].hash, done)
      })
    })
  })

  it('should preload content retrieved with get', function (done) {
    this.timeout(50 * 1000)
    ipfs.add(Buffer.from(hat()), { preload: false }, (err, res) => {
      expect(err).to.not.exist()
      ipfs.get(res[0].hash, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(res[0].hash, done)
      })
    })
  })

  it('should preload content retrieved with ls', function (done) {
    this.timeout(50 * 1000)
    ipfs.add([{
      path: 'dir0/dir1/file0',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/dir1/file1',
      content: Buffer.from(hat())
    }, {
      path: 'dir0/file2',
      content: Buffer.from(hat())
    }], { wrapWithDirectory: true }, (err, res) => {
      expect(err).to.not.exist()

      const wrappingDir = res.find(file => file.path === '')
      expect(wrappingDir).to.exist()

      // Adding these files with have preloaded wrappingDir.hash, clear it out
      MockPreloadNode.clearPreloadCids((err) => {
        expect(err).to.not.exist()

        ipfs.ls(wrappingDir.hash, (err) => {
          expect(err).to.not.exist()
          MockPreloadNode.waitForCids(wrappingDir.hash, done)
        })
      })
    })
  })

  it('should preload content added with object.new', function (done) {
    this.timeout(50 * 1000)
    ipfs.object.new((err, cid) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
    })
  })

  it('should preload content added with object.put', function (done) {
    this.timeout(50 * 1000)
    ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, (err, cid) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
    })
  })

  it('should preload content added with object.patch.addLink', function (done) {
    this.timeout(50 * 1000)
    parallel({
      parent: (cb) => {
        waterfall([
          (done) => ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, done),
          (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
        ], cb)
      },
      link: (cb) => {
        waterfall([
          (done) => ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, done),
          (cid, done) => ipfs.object.get(cid, (err, node) => done(err, { node, cid }))
        ], cb)
      }
    }, (err, result) => {
      expect(err).to.not.exist()

      ipfs.object.patch.addLink(result.parent.cid, {
        name: 'link',
        cid: result.link.cid,
        size: result.link.node.size
      }, (err, cid) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content added with object.patch.rmLink', function (done) {
    this.timeout(50 * 1000)
    waterfall([
      (cb) => ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, cb),
      (cid, cb) => ipfs.object.get(cid, (err, node) => cb(err, { node, cid })),
      ({ node, cid }, cb) => {
        ipfs.object.put({
          Data: Buffer.from(hat()),
          Links: [{
            name: 'link',
            cid: cid,
            size: node.size
          }]
        }, cb)
      }
    ], (err, parentCid) => {
      expect(err).to.not.exist()

      ipfs.object.patch.rmLink(parentCid, { name: 'link' }, (err, cid) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content added with object.patch.setData', function (done) {
    this.timeout(50 * 1000)
    ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, (err, cid) => {
      expect(err).to.not.exist()

      ipfs.object.patch.setData(cid, Buffer.from(hat()), (err, cid) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content added with object.patch.appendData', function (done) {
    this.timeout(50 * 1000)
    ipfs.object.put({ Data: Buffer.from(hat()), Links: [] }, (err, cid) => {
      expect(err).to.not.exist()

      ipfs.object.patch.appendData(cid, Buffer.from(hat()), (err, cid) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content retrieved with object.get', function (done) {
    this.timeout(50 * 1000)
    ipfs.object.new(null, { preload: false }, (err, cid) => {
      expect(err).to.not.exist()

      ipfs.object.get(cid, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content added with block.put', function (done) {
    this.timeout(50 * 1000)
    ipfs.block.put(Buffer.from(hat()), (err, block) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(block.cid.toBaseEncodedString(), done)
    })
  })

  it('should preload content retrieved with block.get', function (done) {
    this.timeout(50 * 1000)
    ipfs.block.put(Buffer.from(hat()), { preload: false }, (err, block) => {
      expect(err).to.not.exist()
      ipfs.block.get(block.cid, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(block.cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content retrieved with block.stat', function (done) {
    this.timeout(50 * 1000)
    ipfs.block.put(Buffer.from(hat()), { preload: false }, (err, block) => {
      expect(err).to.not.exist()
      ipfs.block.stat(block.cid, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(block.cid.toBaseEncodedString(), done)
      })
    })
  })

  it('should preload content added with dag.put', function (done) {
    this.timeout(50 * 1000)
    const obj = { test: hat() }
    ipfs.dag.put(obj, { format: 'dag-cbor', hashAlg: 'sha2-256' }, (err, cid) => {
      expect(err).to.not.exist()
      MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
    })
  })

  it('should preload content retrieved with dag.get', function (done) {
    this.timeout(50 * 1000)
    const obj = { test: hat() }
    const opts = { format: 'dag-cbor', hashAlg: 'sha2-256', preload: false }
    ipfs.dag.put(obj, opts, (err, cid) => {
      expect(err).to.not.exist()
      ipfs.dag.get(cid, (err) => {
        expect(err).to.not.exist()
        MockPreloadNode.waitForCids(cid.toBaseEncodedString(), done)
      })
    })
  })
})

describe('preload disabled', function () {
  this.timeout(50 * 1000)
  let ipfs
  let repo

  before((done) => {
    repo = createTempRepo()
    ipfs = new IPFS({
      repo,
      config: {
        Addresses: {
          Swarm: []
        }
      },
      preload: {
        enabled: false,
        addresses: [MockPreloadNode.defaultAddr]
      }
    })

    ipfs.on('ready', done)
  })

  afterEach((done) => MockPreloadNode.clearPreloadCids(done))

  after((done) => ipfs.stop(done))

  after((done) => repo.teardown(done))

  it('should not preload if disabled', (done) => {
    ipfs.add(Buffer.from(hat()), (err, res) => {
      expect(err).to.not.exist()

      MockPreloadNode.waitForCids(res[0].hash, (err) => {
        expect(err).to.exist()
        expect(err.code).to.equal('ERR_TIMEOUT')
        done()
      })
    })
  })
})

'''
'''--- test/core/pubsub.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const hat = require('hat')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const IPFS = require('../../src')
const createTempRepo = require('../utils/create-repo-nodejs')

describe('pubsub disabled', () => {
  let ipfs
  let repo

  before(function (done) {
    this.timeout(20 * 1000)

    repo = createTempRepo()
    ipfs = new IPFS({
      repo,
      config: {
        Addresses: {
          Swarm: []
        }
      },
      preload: {
        enabled: false
      },
      EXPERIMENTAL: {
        pubsub: false
      }
    })

    ipfs.on('ready', done)
  })

  after((done) => ipfs.stop(done))

  after((done) => repo.teardown(done))

  it('should not allow subscribe if disabled', done => {
    const topic = hat()
    const handler = () => done(new Error('unexpected message'))
    ipfs.pubsub.subscribe(topic, handler, (err) => {
      expect(err).to.exist()
      expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
      done()
    })
  })

  it('should not allow subscribe if disabled (promised)', async () => {
    try {
      const topic = hat()
      const handler = () => { throw new Error('unexpected message') }
      await ipfs.pubsub.subscribe(topic, handler)
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })

  it('should not allow unsubscribe if disabled', done => {
    const topic = hat()
    const handler = () => done(new Error('unexpected message'))
    ipfs.pubsub.unsubscribe(topic, handler, (err) => {
      expect(err).to.exist()
      expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
      done()
    })
  })

  it('should not allow unsubscribe if disabled (promised)', async () => {
    try {
      const topic = hat()
      const handler = () => { throw new Error('unexpected message') }
      await ipfs.pubsub.unsubscribe(topic, handler)
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })

  it('should not allow publish if disabled', done => {
    const topic = hat()
    const msg = Buffer.from(hat())
    ipfs.pubsub.publish(topic, msg, (err) => {
      expect(err).to.exist()
      expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
      done()
    })
  })

  it('should not allow publish if disabled (promised)', async () => {
    try {
      const topic = hat()
      const msg = Buffer.from(hat())
      await ipfs.pubsub.publish(topic, msg)
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })

  it('should not allow ls if disabled', done => {
    ipfs.pubsub.ls((err) => {
      expect(err).to.exist()
      expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
      done()
    })
  })

  it('should not allow ls if disabled (promised)', async () => {
    try {
      await ipfs.pubsub.ls()
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })

  it('should not allow peers if disabled', done => {
    const topic = hat()
    ipfs.pubsub.peers(topic, (err) => {
      expect(err).to.exist()
      expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
      done()
    })
  })

  it('should not allow peers if disabled (promised)', async () => {
    try {
      const topic = hat()
      await ipfs.pubsub.peers(topic)
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })

  it('should not allow setMaxListeners if disabled', async () => {
    try {
      await ipfs.pubsub.setMaxListeners(100)
    } catch (err) {
      return expect(err.code).to.equal('ERR_PUBSUB_DISABLED')
    }
    throw new Error('expected error to be thrown')
  })
})

'''
'''--- test/core/stats.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const pull = require('pull-stream')
const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('stats', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('bwPullStream', () => {
    it('should return erroring stream for invalid interval option', (done) => {
      pull(
        ipfs.stats.bwPullStream({ poll: true, interval: 'INVALID INTERVAL' }),
        pull.collect((err) => {
          expect(err).to.exist()
          expect(err.code).to.equal('ERR_INVALID_POLL_INTERVAL')
          done()
        })
      )
    })
  })

  describe('bw', () => {
    it('should not error when passed null options', (done) => {
      ipfs.stats.bw(null, (err) => {
        expect(err).to.not.exist()
        done()
      })
    })
  })
})

'''
'''--- test/core/swarm.spec.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const IPFSFactory = require('ipfsd-ctl')
const IPFS = require('../../src/core')

describe('swarm', () => {
  let ipfsd, ipfs

  before(function (done) {
    this.timeout(20 * 1000)

    const factory = IPFSFactory.create({ type: 'proc' })

    factory.spawn({
      exec: IPFS,
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = _ipfsd.api
      done()
    })
  })

  after((done) => {
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('peers', () => {
    it('should not error when passed null options', (done) => {
      ipfs.swarm.peers(null, (err) => {
        expect(err).to.not.exist()
        done()
      })
    })
  })
})

'''
'''--- test/core/utils.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const fs = require('fs')
const fromB58String = require('multihashes').fromB58String

// This gets replaced by `create-repo-browser.js` in the browser
const createTempRepo = require('../utils/create-repo-nodejs.js')
const IPFS = require('../../src/core')
const utils = require('../../src/core/utils')

describe('utils', () => {
  const rootHash = 'QmTAMavb995EHErSrKo7mB8dYkpaSJxu6ys1a6XJyB2sys'
  const rootPath = `/ipfs/${rootHash}`
  const rootMultihash = fromB58String(rootHash)
  const aboutHash = 'QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q'
  const aboutPath = `${rootPath}/mercury`
  const aboutMultihash = fromB58String(aboutHash)

  describe('parseIpfsPath', () => {
    it('parses path with no links', function () {
      expect(utils.parseIpfsPath(rootHash))
        .to.deep.equal({
          hash: rootHash,
          links: []
        })
    })

    it('parses path with links', function () {
      expect(utils.parseIpfsPath(`${rootHash}/docs/index`))
        .to.deep.equal({
          hash: rootHash,
          links: ['docs', 'index']
        })
    })

    it('parses path with /ipfs/ prefix', function () {
      expect(utils.parseIpfsPath(`/ipfs/${rootHash}/about`))
        .to.deep.equal({
          hash: rootHash,
          links: ['about']
        })
    })

    it('parses path with leading and trailing slashes', function () {
      expect(utils.parseIpfsPath(`/${rootHash}/`))
        .to.deep.equal({
          hash: rootHash,
          links: []
        })
    })

    it('normalize path with no ipfs path, nor ipns path nor cid should throw an exception', function () {
      try {
        utils.normalizePath(`/${rootHash}/`)
      } catch (err) {
        expect(err).to.exist()
      }
    })

    it('normalize path should return an ipfs path, when an ipfs path is provided', function () {
      const ipfsPath = `/ipfs/${rootHash}`
      expect(utils.normalizePath(ipfsPath))
        .to.equal(ipfsPath)
    })

    it('normalize path should return an ipfs path, when a cid is provided', function () {
      const ipfsPath = `/ipfs/${rootHash}`
      expect(utils.normalizePath(rootHash))
        .to.equal(ipfsPath)
    })

    it('normalize path should return an ipns path, when an ipns path is provided', function () {
      const ipnsPath = `/ipns/${rootHash}`
      expect(utils.normalizePath(ipnsPath))
        .to.equal(ipnsPath)
    })

    it('parses non sha2-256 paths', function () {
      // There are many, many hashing algorithms. Just one should be a sufficient
      // indicator. Used go-ipfs@0.4.13 `add --hash=keccak-512` to generate
      const keccak512 = 'zB7S6ZdcqsTqvNhBpx3SbFTocRpAUHj1w9WQXQGyWBVEsLStNfaaNtsdFUQbRk4tYPZvnpGbtDN5gEH4uVzUwsFyJh9Ei'
      expect(utils.parseIpfsPath(keccak512))
        .to.deep.equal({
          hash: keccak512,
          links: []
        })
    })

    it('returns error for malformed path', function () {
      const fn = () => utils.parseIpfsPath(`${rootHash}//about`)
      expect(fn).to.throw('invalid ipfs ref path')
    })

    it('returns error if root is not a valid sha2-256 multihash', function () {
      const fn = () => utils.parseIpfsPath('invalid/ipfs/path')
      expect(fn).to.throw('invalid ipfs ref path')
    })
  })

  describe('resolvePath', function () {
    this.timeout(100 * 1000)
    const fixtures = [
      'test/fixtures/planets/mercury/wiki.md',
      'test/fixtures/planets/solar-system.md'
    ].map(path => ({
      path,
      content: fs.readFileSync(path)
    }))

    let node
    let repo

    before(done => {
      repo = createTempRepo()
      node = new IPFS({
        repo,
        config: {
          Bootstrap: []
        }
      })
      node.once('ready', () => node.add(fixtures, done))
    })

    after(done => node.stop(done))

    after(done => repo.teardown(done))

    it('handles base58 hash format', (done) => {
      utils.resolvePath(node.object, rootHash, (err, hashes) => {
        expect(err).to.not.exist()
        expect(hashes.length).to.equal(1)
        expect(hashes[0]).to.deep.equal(rootMultihash)
        done()
      })
    })

    it('handles multihash format', (done) => {
      utils.resolvePath(node.object, aboutMultihash, (err, hashes) => {
        expect(err).to.not.exist()
        expect(hashes.length).to.equal(1)
        expect(hashes[0]).to.deep.equal(aboutMultihash)
        done()
      })
    })

    it('handles ipfs paths format', function (done) {
      this.timeout(200 * 1000)
      utils.resolvePath(node.object, aboutPath, (err, hashes) => {
        expect(err).to.not.exist()
        expect(hashes.length).to.equal(1)
        expect(hashes[0]).to.deep.equal(aboutMultihash)
        done()
      })
    })

    it('handles an array', (done) => {
      const paths = [rootHash, rootPath, rootMultihash]
      utils.resolvePath(node.object, paths, (err, hashes) => {
        expect(err).to.not.exist()
        expect(hashes.length).to.equal(3)
        expect(hashes[0]).to.deep.equal(rootMultihash)
        expect(hashes[1]).to.deep.equal(rootMultihash)
        expect(hashes[2]).to.deep.equal(rootMultihash)
        done()
      })
    })

    it('should error on invalid hashes', function (done) {
      utils.resolvePath(node.object, '/ipfs/asdlkjahsdfkjahsdfd', err => {
        expect(err).to.exist()
        done()
      })
    })

    it(`should error when a link doesn't exist`, function (done) {
      utils.resolvePath(node.object, `${aboutPath}/fusion`, err => {
        expect(err.message).to.include(
          `no link named "fusion" under QmbJCNKXJqVK8CzbjpNFz2YekHwh3CSHpBA86uqYg3sJ8q`
        )
        done()
      })
    })
  })
})

'''
'''--- test/fixtures/planets/mercury/wiki.md ---
# Mercury (planet)
> From Wikipedia, the free encyclopedia

Mercury is the smallest and innermost planet in the Solar System. Its orbital period around the Sun of 87.97 days is the shortest of all the planets in the Solar System. It is named after the Roman deity Mercury, the messenger of the gods.

Like Venus, Mercury orbits the Sun within Earth's orbit as an inferior planet, and never exceeds 28° away from the Sun. When viewed from Earth, this proximity to the Sun means the planet can only be seen near the western or eastern horizon during the early evening or early morning. At this time it may appear as a bright star-like object, but is often far more difficult to observe than Venus. The planet telescopically displays the complete range of phases, similar to Venus and the Moon, as it moves in its inner orbit relative to Earth, which reoccurs over the so-called synodic period approximately every 116 days.

Mercury is gravitationally locked with the Sun in a 3:2 spin-orbit resonance, and rotates in a way that is unique in the Solar System. As seen relative to the fixed stars, it rotates on its axis exactly three times for every two revolutions it makes around the Sun. As seen from the Sun, in a frame of reference that rotates with the orbital motion, it appears to rotate only once every two Mercurian years. An observer on Mercury would therefore see only one day every two years.

Mercury's axis has the smallest tilt of any of the Solar System's planets (about ​1⁄30 degree). Its orbital eccentricity is the largest of all known planets in the Solar System; at perihelion, Mercury's distance from the Sun is only about two-thirds (or 66%) of its distance at aphelion. Mercury's surface appears heavily cratered and is similar in appearance to the Moon's, indicating that it has been geologically inactive for billions of years. Having almost no atmosphere to retain heat, it has surface temperatures that vary diurnally more than on any other planet in the Solar System, ranging from 100 K (−173 °C; −280 °F) at night to 700 K (427 °C; 800 °F) during the day across the equatorial regions. The polar regions are constantly below 180 K (−93 °C; −136 °F). The planet has no known natural satellites.

Two spacecraft have visited Mercury: Mariner 10 flew by in 1974 and 1975; and MESSENGER, launched in 2004, orbited Mercury over 4,000 times in four years before exhausting its fuel and crashing into the planet's surface on April 30, 2015.

'''
'''--- test/fixtures/planets/solar-system.md ---
# Solar System
> From Wikipedia, the free encyclopedia

The Solar System is the gravitationally bound system comprising the Sun and the objects that orbit it, either directly or indirectly. Of those objects that orbit the Sun directly, the largest eight are the planets, with the remainder being smaller objects, such as dwarf planets and small Solar System bodies. Of the objects that orbit the Sun indirectly, the moons, two are larger than the smallest planet, Mercury.

The Solar System formed 4.6 billion years ago from the gravitational collapse of a giant interstellar molecular cloud. The vast majority of the system's mass is in the Sun, with the majority of the remaining mass contained in Jupiter. The four smaller inner planets, Mercury, Venus, Earth and Mars, are terrestrial planets, being primarily composed of rock and metal. The four outer planets are giant planets, being substantially more massive than the terrestrials. The two largest, Jupiter and Saturn, are gas giants, being composed mainly of hydrogen and helium; the two outermost planets, Uranus and Neptune, are ice giants, being composed mostly of substances with relatively high melting points compared with hydrogen and helium, called volatiles, such as water, ammonia and methane. All eight planets have almost circular orbits that lie within a nearly flat disc called the ecliptic.

The Solar System also contains smaller objects. The asteroid belt, which lies between the orbits of Mars and Jupiter, mostly contains objects composed, like the terrestrial planets, of rock and metal. Beyond Neptune's orbit lie the Kuiper belt and scattered disc, which are populations of trans-Neptunian objects composed mostly of ices, and beyond them a newly discovered population of sednoids. Within these populations are several dozen to possibly tens of thousands of objects large enough that they have been rounded by their own gravity. Such objects are categorized as dwarf planets. Identified dwarf planets include the asteroid Ceres and the trans-Neptunian objects Pluto and Eris. In addition to these two regions, various other small-body populations, including comets, centaurs and interplanetary dust clouds, freely travel between regions. Six of the planets, at least four of the dwarf planets, and many of the smaller bodies are orbited by natural satellites, usually termed "moons" after the Moon. Each of the outer planets is encircled by planetary rings of dust and other small objects.

The solar wind, a stream of charged particles flowing outwards from the Sun, creates a bubble-like region in the interstellar medium known as the heliosphere. The heliopause is the point at which pressure from the solar wind is equal to the opposing pressure of the interstellar medium; it extends out to the edge of the scattered disc. The Oort cloud, which is thought to be the source for long-period comets, may also exist at a distance roughly a thousand times further than the heliosphere. The Solar System is located in the Orion Arm, 26,000 light-years from the center of the Milky Way.

'''
'''--- test/fixtures/test-data/badnode.json ---
{
  bad config
}

'''
'''--- test/fixtures/test-data/node.json ---
{ "Data": "another", "Links": [ { "Name": "some link", "Hash": "QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V", "Size": 8 } ] }

'''
'''--- test/gateway/index.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)
const API = require('../../src/http')
const loadFixture = require('aegir/fixtures')
const os = require('os')
const path = require('path')
const hat = require('hat')
const fileType = require('file-type')

const bigFile = loadFixture('js/test/fixtures/15mb.random', 'interface-ipfs-core')
const directoryContent = {
  'index.html': loadFixture('test/gateway/test-folder/index.html'),
  'nested-folder/hello.txt': loadFixture('test/gateway/test-folder/nested-folder/hello.txt'),
  'nested-folder/ipfs.txt': loadFixture('test/gateway/test-folder/nested-folder/ipfs.txt'),
  'nested-folder/nested.html': loadFixture('test/gateway/test-folder/nested-folder/nested.html'),
  'cat-folder/cat.jpg': loadFixture('test/gateway/test-folder/cat-folder/cat.jpg'),
  'unsniffable-folder/hexagons-xml.svg': loadFixture('test/gateway/test-folder/unsniffable-folder/hexagons-xml.svg'),
  'unsniffable-folder/hexagons.svg': loadFixture('test/gateway/test-folder/unsniffable-folder/hexagons.svg')
}

describe('HTTP Gateway', function () {
  this.timeout(80 * 1000)

  let http = {}
  let gateway

  before(async () => {
    this.timeout(60 * 1000)
    const repoPath = path.join(os.tmpdir(), '/ipfs-' + hat())

    http.api = new API({
      repo: repoPath,
      init: true,
      config: {
        Addresses: {
          Swarm: ['/ip4/127.0.0.1/tcp/0'],
          API: '/ip4/127.0.0.1/tcp/0',
          Gateway: '/ip4/127.0.0.1/tcp/0'
        },
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          }
        }
      }
    })

    const content = (name) => ({
      path: `test-folder/${name}`,
      content: directoryContent[name]
    })

    const emptyDir = (name) => ({ path: `test-folder/${name}` })

    await http.api.start()

    gateway = http.api._gatewayServer

    // QmbQD7EMEL1zeebwBsWEfA3ndgSS6F7S6iTuwuqasPgVRi
    await http.api._ipfs.add([
      content('index.html'),
      emptyDir('empty-folder'),
      content('nested-folder/hello.txt'),
      content('nested-folder/ipfs.txt'),
      content('nested-folder/nested.html'),
      emptyDir('nested-folder/empty')
    ])
    // Qme79tX2bViL26vNjPsF3DP1R9rMKMvnPYJiKTTKPrXJjq
    await http.api._ipfs.add(bigFile)
    // QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o
    await http.api._ipfs.add(Buffer.from('hello world' + '\n'), { cidVersion: 0 })
    // QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ
    await http.api._ipfs.add([content('cat-folder/cat.jpg')])
    // QmVZoGxDvKM9KExc8gaL4uTbhdNtWhzQR7ndrY7J1gWs3F
    await http.api._ipfs.add([
      content('unsniffable-folder/hexagons-xml.svg'),
      content('unsniffable-folder/hexagons.svg')
    ])
  })

  after(() => http.api.stop())

  it('returns 400 for request without argument', async () => {
    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs'
    })

    expect(res.statusCode).to.equal(400)
    expect(res.headers['cache-control']).to.equal('no-cache')
    expect(res.headers.etag).to.equal(undefined)
    expect(res.headers['x-ipfs-path']).to.equal(undefined)
    expect(res.headers.suborigin).to.equal(undefined)
  })

  it('400 for request with invalid argument', async () => {
    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/invalid'
    })

    expect(res.statusCode).to.equal(400)
    expect(res.headers['cache-control']).to.equal('no-cache')
    expect(res.headers.etag).to.equal(undefined)
    expect(res.headers['x-ipfs-path']).to.equal(undefined)
    expect(res.headers.suborigin).to.equal(undefined)
  })

  it('valid CIDv0', async () => {
    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o'
    })

    expect(res.statusCode).to.equal(200)
    expect(res.rawPayload).to.eql(Buffer.from('hello world' + '\n'))
    expect(res.payload).to.equal('hello world' + '\n')
    expect(res.headers['cache-control']).to.equal('public, max-age=29030400, immutable')
    expect(res.headers.etag).to.equal('"QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o"')
    expect(res.headers['x-ipfs-path']).to.equal('/ipfs/QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o')
    expect(res.headers.suborigin).to.equal('ipfs000bafybeicg2rebjoofv4kbyovkw7af3rpiitvnl6i7ckcywaq6xjcxnc2mby')
  })

  /* TODO when support for CIDv1 lands
  it('valid CIDv1', (done) => {
    gateway.inject({
      method: 'GET',
      url: '/ipfs/TO-DO'
    }, (res) => {
      expect(res.statusCode).to.equal(200)
      expect(res.rawPayload).to.eql(Buffer.from('hello world' + '\n'))
      expect(res.payload).to.equal('hello world' + '\n')
      expect(res.headers.etag).to.equal(TO-DO)
      expect(res.headers['x-ipfs-path']).to.equal(TO-DO)
      expect(res.headers.suborigin).to.equal(TO-DO)
      expect(res.headers['cache-control']).to.equal('public, max-age=29030400, immutable')

      done()
    })
  })
  */

  it('stream a large file', async () => {
    const bigFileHash = 'Qme79tX2bViL26vNjPsF3DP1R9rMKMvnPYJiKTTKPrXJjq'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + bigFileHash
    })

    expect(res.statusCode).to.equal(200)
    expect(res.rawPayload).to.eql(bigFile)
  })

  it('load a jpg file', async () => {
    const kitty = 'QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ/cat.jpg'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + kitty
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('image/jpeg')
    expect(res.headers['x-ipfs-path']).to.equal('/ipfs/' + kitty)
    expect(res.headers['cache-control']).to.equal('public, max-age=29030400, immutable')
    expect(res.headers.etag).to.equal('"Qmd286K6pohQcTKYqnS1YhWrCiS4gz7Xi34sdwMe9USZ7u"')
    expect(res.headers.suborigin).to.equal('ipfs000bafybeidsg6t7ici2osxjkukisd5inixiunqdpq2q5jy4a2ruzdf6ewsqk4')

    let fileSignature = fileType(res.rawPayload)
    expect(fileSignature.mime).to.equal('image/jpeg')
    expect(fileSignature.ext).to.equal('jpg')
  })

  it('load a svg file (unsniffable)', async () => {
    const hexagons = 'QmVZoGxDvKM9KExc8gaL4uTbhdNtWhzQR7ndrY7J1gWs3F/hexagons.svg'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + hexagons
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('image/svg+xml')
  })

  it('load a svg file with xml leading declaration (unsniffable)', async () => {
    const hexagons = 'QmVZoGxDvKM9KExc8gaL4uTbhdNtWhzQR7ndrY7J1gWs3F/hexagons-xml.svg'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + hexagons
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('image/svg+xml')
  })

  it('load a directory', async () => {
    const dir = 'QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ/'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + dir
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('text/html; charset=utf-8')
    expect(res.headers['x-ipfs-path']).to.equal('/ipfs/' + dir)
    expect(res.headers['cache-control']).to.equal('no-cache')
    expect(res.headers.etag).to.equal(undefined)
    expect(res.headers.suborigin).to.equal('ipfs000bafybeidsg6t7ici2osxjkukisd5inixiunqdpq2q5jy4a2ruzdf6ewsqk4')

    // check if the cat picture is in the payload as a way to check
    // if this is an index of this directory
    let listedFile = res.payload.match(/\/ipfs\/QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ\/cat\.jpg/g)
    expect(listedFile).to.have.lengthOf(1)
  })

  it('load a webpage index.html', async () => {
    const dir = 'QmbQD7EMEL1zeebwBsWEfA3ndgSS6F7S6iTuwuqasPgVRi/index.html'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + dir
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('text/html; charset=utf-8')
    expect(res.headers['x-ipfs-path']).to.equal('/ipfs/' + dir)
    expect(res.headers['cache-control']).to.equal('public, max-age=29030400, immutable')
    expect(res.headers.etag).to.equal('"Qma6665X5k3zti8nKy7gmXK2BndNDSkgmANpV6k3FUjUeg"')
    expect(res.headers.suborigin).to.equal('ipfs000bafybeigccfheqv7upr4k64bkg5b5wiwelunyn2l2rbirmm43m34lcpuqqe')
    expect(res.rawPayload).to.deep.equal(directoryContent['index.html'])
  })

  it('load a webpage {hash}/nested-folder/nested.html', async () => {
    const dir = 'QmbQD7EMEL1zeebwBsWEfA3ndgSS6F7S6iTuwuqasPgVRi/nested-folder/nested.html'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + dir
    })

    expect(res.statusCode).to.equal(200)
    expect(res.headers['content-type']).to.equal('text/html; charset=utf-8')
    expect(res.headers['x-ipfs-path']).to.equal('/ipfs/' + dir)
    expect(res.headers['cache-control']).to.equal('public, max-age=29030400, immutable')
    expect(res.headers.etag).to.equal('"QmUBKGqJWiJYMrNed4bKsbo1nGYGmY418WCc2HgcwRvmHc"')
    expect(res.headers.suborigin).to.equal('ipfs000bafybeigccfheqv7upr4k64bkg5b5wiwelunyn2l2rbirmm43m34lcpuqqe')
    expect(res.rawPayload).to.deep.equal(directoryContent['nested-folder/nested.html'])
  })

  it('redirect to generated index', async () => {
    const dir = 'QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + dir
    })

    expect(res.statusCode).to.equal(301)
    expect(res.headers.location).to.equal('/ipfs/QmW2WQi7j6c7UgJTarActp7tDNikE4B2qXtFCfLPdsgaTQ/')
    expect(res.headers['x-ipfs-path']).to.equal(undefined)
  })

  it('redirect to webpage index.html', async () => {
    const dir = 'QmbQD7EMEL1zeebwBsWEfA3ndgSS6F7S6iTuwuqasPgVRi/'

    const res = await gateway.inject({
      method: 'GET',
      url: '/ipfs/' + dir
    })

    expect(res.statusCode).to.equal(302)
    expect(res.headers.location).to.equal('/ipfs/QmbQD7EMEL1zeebwBsWEfA3ndgSS6F7S6iTuwuqasPgVRi/index.html')
    expect(res.headers['x-ipfs-path']).to.equal(undefined)
  })
})

'''
'''--- test/gateway/test-folder/index.html ---
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IPFS test index.html</title>
</head>
<body>
  index.html
</body>
</html>

'''
'''--- test/gateway/test-folder/nested-folder/hello.txt ---
Hello

'''
'''--- test/gateway/test-folder/nested-folder/ipfs.txt ---
IPFS

'''
'''--- test/gateway/test-folder/nested-folder/nested.html ---
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IPFS test nested.html</title>
</head>
<body>
  nested.html
</body>
</html>

'''
'''--- test/gateway/test-folder/unsniffable-folder/hexagons-xml.svg ---
<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 153.7 167.4" style="enable-background:new 0 0 153.7 167.4;" xml:space="preserve">
<style type="text/css">
	.st0{opacity:0.2;enable-background:new    ;}
</style>
<g>
	<path class="st0" d="M2.4,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,125.4z
		 M2.4,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L2.4,125.4z"/>
	<path class="st0" d="M83.3,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1H110l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L83.3,125.4z
		 M83.3,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.6l0,0L83.3,125.4z"/>
	<path class="st0" d="M56.4,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,125.4
		z M56.4,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L56.4,125.4z"/>
	<path class="st0" d="M15.7,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M15.7,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L29,94.5h0.1L15.7,102.3z"/>
	<path class="st0" d="M123.5,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M123.5,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L123.5,102.3z"/>
	<path class="st0" d="M96.6,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M96.6,102.3l0.1,15.5v-0.1l13.4,7.7H110l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L96.6,102.3z"/>
	<path class="st0" d="M69.8,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.5-7.8l0,0l0,0L69.8,102.3
		z M69.8,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L69.8,102.3z"/>
	<path class="st0" d="M42.9,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M42.9,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1l0.1-15.5v0.1l-13.4-7.8h0.1L42.9,102.3z"/>
	<path class="st0" d="M2.4,79.2l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0L2.3,94.7l0,0l0,0L2.4,79.2z
		 M2.4,79.2l0.1,15.5v-0.1l13.3,7.7h-0.1l13.4-7.8L29,94.6V79.1v0.1l-13.4-7.8h0.1L2.4,79.2z"/>
	<path class="st0" d="M29.5,125.6l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L29.5,125.6
		z M29.5,125.6l0.1,15.5V141l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L29.5,125.6z"/>
	<path class="st0" d="M56.4,79.2l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,79.2z
		 M56.4,79.2l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V79.1v0.1l-13.4-7.8h0.1L56.4,79.2z"/>
	<path class="st0" d="M15.7,9.8L29.1,2l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L29,33.1l0,0l0,0l-13.3-7.8l0,0l0,0V9.8z M15.7,9.8
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V9.7v0.1L29,2h0.1L15.7,9.8z"/>
	<path d="M2.4,141l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.3,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,141z M2.4,141
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L2.4,141z"/>
	<path d="M83.3,141l13.4-7.9l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1H110l-13.2,7.8l0,0l0,0l-13.4-7.8l0,0l0,0L83.3,141z M83.3,141v15.5
		v-0.1l13.5,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.7l0,0L83.3,141z"/>
	<path d="M56.4,141l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.2,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,141z M56.4,141
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.7h0.1L56.4,141z"/>
	<path d="M15.7,117.8l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L29,141.1l0,0l0,0l-13.4-7.8l0,0l0,0L15.7,117.8z M15.7,117.8
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L29,110h0.1L15.7,117.8z"/>
	<path d="M96.6,117.8L110,110l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L96.6,117.8z M96.6,117.8
		l0.1,15.5v-0.1l13.4,7.7H110l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L96.6,117.8z"/>
	<path d="M69.8,117.8l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.4v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.5-7.7l0,0l0,0L69.8,117.8z
		 M69.8,117.8v15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L83,110h0.1L69.8,117.8z"/>
	<path d="M42.9,117.8l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L42.9,117.8z
		 M42.9,117.8l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L42.9,117.8z"/>
	<path d="M2.4,94.7l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L15.7,118l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,94.7z M2.4,94.7
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V94.6v0.1l-13.4-7.8h0.1L2.4,94.7z"/>
	<path d="M56.4,94.7l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L69.7,118l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,94.7z M56.4,94.7
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V94.6v0.1l-13.4-7.8h0.1L56.4,94.7z"/>
	<path d="M42.9,71.6l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L42.9,71.6z M42.9,71.6
		L43,87.1V87l13.4,7.7h-0.1L69.7,87l-0.1,0.1V71.6v0.1l-13.4-7.8h0.1L42.9,71.6z"/>
	<path d="M2.4,48.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5V64h-0.1l-13.4,7.7l0,0l0,0L2.3,63.9l0,0l0,0L2.4,48.4z M2.4,48.4
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V48.3v0.1l-13.4-7.8h0.1L2.4,48.4z"/>
</g>
</svg>

'''
'''--- test/gateway/test-folder/unsniffable-folder/hexagons.svg ---
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 153.7 167.4" style="enable-background:new 0 0 153.7 167.4;" xml:space="preserve">
<style type="text/css">
	.st0{opacity:0.2;enable-background:new    ;}
</style>
<g>
	<path class="st0" d="M2.4,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,125.4z
		 M2.4,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L2.4,125.4z"/>
	<path class="st0" d="M83.3,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1H110l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L83.3,125.4z
		 M83.3,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.6l0,0L83.3,125.4z"/>
	<path class="st0" d="M56.4,125.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,125.4
		z M56.4,125.4l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L56.4,125.4z"/>
	<path class="st0" d="M15.7,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M15.7,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L29,94.5h0.1L15.7,102.3z"/>
	<path class="st0" d="M123.5,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M123.5,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L123.5,102.3z"/>
	<path class="st0" d="M96.6,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M96.6,102.3l0.1,15.5v-0.1l13.4,7.7H110l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L96.6,102.3z"/>
	<path class="st0" d="M69.8,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.5-7.8l0,0l0,0L69.8,102.3
		z M69.8,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L69.8,102.3z"/>
	<path class="st0" d="M42.9,102.3l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0V102.3z
		 M42.9,102.3l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1l0.1-15.5v0.1l-13.4-7.8h0.1L42.9,102.3z"/>
	<path class="st0" d="M2.4,79.2l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0L2.3,94.7l0,0l0,0L2.4,79.2z
		 M2.4,79.2l0.1,15.5v-0.1l13.3,7.7h-0.1l13.4-7.8L29,94.6V79.1v0.1l-13.4-7.8h0.1L2.4,79.2z"/>
	<path class="st0" d="M29.5,125.6l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L29.5,125.6
		z M29.5,125.6l0.1,15.5V141l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L29.5,125.6z"/>
	<path class="st0" d="M56.4,79.2l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,79.2z
		 M56.4,79.2l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V79.1v0.1l-13.4-7.8h0.1L56.4,79.2z"/>
	<path class="st0" d="M15.7,9.8L29.1,2l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L29,33.1l0,0l0,0l-13.3-7.8l0,0l0,0V9.8z M15.7,9.8
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V9.7v0.1L29,2h0.1L15.7,9.8z"/>
	<path d="M2.4,141l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.3,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,141z M2.4,141
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L2.4,141z"/>
	<path d="M83.3,141l13.4-7.9l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1H110l-13.2,7.8l0,0l0,0l-13.4-7.8l0,0l0,0L83.3,141z M83.3,141v15.5
		v-0.1l13.5,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.7l0,0L83.3,141z"/>
	<path d="M56.4,141l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.2,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,141z M56.4,141
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.3-7.7h0.1L56.4,141z"/>
	<path d="M15.7,117.8l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L29,141.1l0,0l0,0l-13.4-7.8l0,0l0,0L15.7,117.8z M15.7,117.8
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L29,110h0.1L15.7,117.8z"/>
	<path d="M96.6,117.8L110,110l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L96.6,117.8z M96.6,117.8
		l0.1,15.5v-0.1l13.4,7.7H110l13.4-7.8l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L96.6,117.8z"/>
	<path d="M69.8,117.8l13.4-7.8l0,0l0,0l13.5,7.8l0,0v0.1v15.4v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.5-7.7l0,0l0,0L69.8,117.8z
		 M69.8,117.8v15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1v-15.5v0.1L83,110h0.1L69.8,117.8z"/>
	<path d="M42.9,117.8l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L42.9,117.8z
		 M42.9,117.8l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.7l-0.1,0.1v-15.5v0.1l-13.4-7.8h0.1L42.9,117.8z"/>
	<path d="M2.4,94.7l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L15.7,118l0,0l0,0l-13.4-7.8l0,0l0,0L2.4,94.7z M2.4,94.7
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V94.6v0.1l-13.4-7.8h0.1L2.4,94.7z"/>
	<path d="M56.4,94.7l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1L69.7,118l0,0l0,0l-13.4-7.8l0,0l0,0L56.4,94.7z M56.4,94.7
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V94.6v0.1l-13.4-7.8h0.1L56.4,94.7z"/>
	<path d="M42.9,71.6l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5v0.1h-0.1l-13.4,7.7l0,0l0,0l-13.4-7.8l0,0l0,0L42.9,71.6z M42.9,71.6
		L43,87.1V87l13.4,7.7h-0.1L69.7,87l-0.1,0.1V71.6v0.1l-13.4-7.8h0.1L42.9,71.6z"/>
	<path d="M2.4,48.4l13.4-7.8l0,0l0,0l13.4,7.7l0,0v0.1v15.5V64h-0.1l-13.4,7.7l0,0l0,0L2.3,63.9l0,0l0,0L2.4,48.4z M2.4,48.4
		l0.1,15.5v-0.1l13.4,7.7h-0.1l13.4-7.8l-0.1,0.1V48.3v0.1l-13.4-7.8h0.1L2.4,48.4z"/>
</g>
</svg>

'''
'''--- test/http-api/block.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const multihash = require('multihashes')
const waterfall = require('async/waterfall')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

describe('block endpoint', () => {
  let ipfs = null
  let ipfsd = null

  before(function (done) {
    this.timeout(20 * 1000)

    df.spawn({
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  describe('.block', () => {
    describe('.put', () => {
      it('updates value', (done) => {
        const data = Buffer.from('hello world\n')
        const expectedResult = {
          key: 'QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp',
          size: 12
        }

        waterfall([
          (cb) => ipfs.block.put(data, cb),
          (block, cb) => {
            expect(block.cid.multihash).to.eql(
              multihash.fromB58String(expectedResult.key)
            )
            cb()
          }
        ], done)
      })
    })

    describe('.get', () => {
      it('returns error for request with invalid argument', (done) => {
        ipfs.block.get('invalid', (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        ipfs.block.get('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp', (err, result) => {
          expect(err).to.not.exist()
          expect(result.data.toString())
            .to.equal('hello world\n')
          done()
        })
      })
    })

    describe('.stat', () => {
      it('returns error for request without argument', (done) => {
        ipfs.block.stat(null, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid argument', (done) => {
        ipfs.block.stat('invalid', (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        ipfs.block.stat('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp', (err, result) => {
          expect(err).to.not.exist()
          expect(result.key)
            .to.equal('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp')
          expect(result.size).to.equal(12)
          done()
        })
      })
    })
  })
})

'''
'''--- test/http-api/bootstrap.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

describe('bootstrap endpoint', () => {
  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)

    df.spawn({
      initOptions: { bits: 512 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  describe('.bootstrap', () => {
    const invalidArg = 'this/Is/So/Invalid/'
    const validIp4 = '/ip4/101.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z'
    let peers

    describe('.add', function () {
      this.timeout(40 * 1000)

      it('returns an error when called with an invalid arg', (done) => {
        ipfs.bootstrap.add(invalidArg, (err) => {
          expect(err).to.be.an.instanceof(Error)
          done()
        })
      })

      it('returns a list of containing the bootstrap peer when called with a valid arg (ip4)', (done) => {
        ipfs.bootstrap.add(validIp4, (err, res) => {
          expect(err).to.not.exist()
          expect(res).to.be.eql({ Peers: [validIp4] })
          done()
        })
      })

      it('prevents duplicate inserts of bootstrap peers', () => {
        return ipfs
          .bootstrap
          .rm(null, { all: true })
          .then((res) => {
            expect(res.Peers.length).to.equal(0)
            return ipfs.bootstrap.add(validIp4)
          })
          .then(res => {
            expect(res).to.be.eql({ Peers: [validIp4] })
            return ipfs.bootstrap.add(validIp4)
          })
          .then((res) => {
            expect(res).to.be.eql({ Peers: [validIp4] })
            return ipfs.bootstrap.list()
          })
          .then((res) => {
            expect(res).to.exist()
            const insertPosition = res.Peers.indexOf(validIp4)
            expect(insertPosition).to.not.equal(-1)
            expect(res.Peers.length).to.equal(1)
          })
      })

      it('returns a list of bootstrap peers when called with the default option', (done) => {
        ipfs.bootstrap.add({ default: true }, (err, res) => {
          expect(err).to.not.exist()
          peers = res.Peers
          expect(peers).to.exist()
          expect(peers.length).to.be.above(1)
          done()
        })
      })
    })

    describe('.list', () => {
      it('returns a list of peers', (done) => {
        ipfs.bootstrap.list((err, res) => {
          expect(err).to.not.exist()
          peers = res.Peers
          expect(peers).to.exist()
          done()
        })
      })
    })

    describe('.rm', () => {
      it('returns an error when called with an invalid arg', (done) => {
        ipfs.bootstrap.rm(invalidArg, (err) => {
          expect(err).to.be.an.instanceof(Error)
          done()
        })
      })

      it('returns empty list because no peers removed when called without an arg or options', (done) => {
        ipfs.bootstrap.rm(null, (err, res) => {
          expect(err).to.not.exist()
          peers = res.Peers
          expect(peers).to.exist()
          expect(peers.length).to.eql(0)
          done()
        })
      })

      it('returns list containing the peer removed when called with a valid arg (ip4)', (done) => {
        ipfs.bootstrap.rm(validIp4, (err, res) => {
          expect(err).to.not.exist()

          peers = res.Peers
          expect(peers).to.exist()
          expect(peers.length).to.eql(1)
          done()
        })
      })

      it('returns list of all peers removed when all option is passed', (done) => {
        ipfs.bootstrap.rm(null, { all: true }, (err, res) => {
          expect(err).to.not.exist()
          peers = res.Peers
          expect(peers).to.exist()
          done()
        })
      })
    })
  })
})

'''
'''--- test/http-api/config.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const ncp = require('ncp').ncp
const rimraf = require('rimraf')
const waterfall = require('async/waterfall')

const isWindows = require('../utils/platforms').isWindows
const skipOnWindows = isWindows() ? describe.skip : describe

const fs = require('fs')
const path = require('path')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

skipOnWindows('config endpoint', () => {
  const repoExample = path.join(__dirname, '../fixtures/go-ipfs-repo')
  const repoPath = path.join(__dirname, '../repo-tests-run')

  let updatedConfig = null

  let ipfs = null
  let ipfsd = null

  // wait until the repo is ready to use
  before(function (done) {
    this.timeout(10 * 1000)

    setTimeout(done, 5 * 1000)
  })

  before(function (done) {
    this.timeout(20 * 1000)

    ncp(repoExample, repoPath, (err) => {
      expect(err).to.not.exist()

      waterfall([
        (cb) => df.spawn({
          repoPath: repoPath,
          initOptions: { bits: 512 },
          config: { Bootstrap: [] },
          disposable: false,
          start: true
        }, cb),
        (_ipfsd, cb) => {
          ipfsd = _ipfsd
          ipfsd.start(cb)
        }
      ], (err) => {
        expect(err).to.not.exist()
        ipfs = ipfsd.api

        updatedConfig = () => {
          const config = fs.readFileSync(path.join(__dirname, '../repo-tests-run/config'))
          return JSON.parse(config, 'utf8')
        }

        done()
      })
    })
  })

  after(function (done) {
    this.timeout(50 * 1000)
    rimraf(repoPath, (err) => {
      expect(err).to.not.exist()
      ipfsd.stop(done)
    })
  })

  describe('.config', () => {
    it('.get returns error for request with invalid argument', (done) => {
      ipfs.config.get('kittens', (err, res) => {
        expect(err).to.exist()
        done()
      })
    })

    it('.get returns value for request with argument', (done) => {
      ipfs.config.get('API.HTTPHeaders', (err, value) => {
        expect(err).not.to.exist()
        expect(value).to.equal(null)
        done()
      })
    })

    it('.set updates value for request with both args', (done) => {
      ipfs.config.set('Datastore.Path', 'kitten', (err) => {
        expect(err).not.to.exist()
        done()
      })
    })

    it('.set returns error for request with both args and JSON flag with invalid JSON argument', (done) => {
      ipfs.config.set('Datastore.Path', 'kitten', { json: true }, (err) => {
        expect(err).to.exist()
        done()
      })
    })

    it('.set updates value for request with both args and bool flag and true argument', (done) => {
      ipfs.config.set('Datastore.Path', true, (err) => {
        expect(err).not.to.exist()
        done()
      })
    })

    it('.set updates value for request with both args and bool flag and false argument', (done) => {
      ipfs.config.set('Datastore.Path', false, (err) => {
        expect(err).not.to.exist()
        done()
      })
    })

    it('.get updatedConfig', (done) => {
      ipfs.config.get((err, config) => {
        expect(err).not.to.exist()
        expect(config).to.be.eql(updatedConfig())
        done()
      })
    })

    // This one is one stale mode till go-ipfs decides
    // what to do with the .replace command
    describe.skip('.replace', () => {
      it('returns error if the config is invalid', (done) => {
        const filePath = 'test/fixtures/test-data/badconfig'

        ipfs.config.replace(filePath, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('updates value', (done) => {
        const filePath = 'test/fixtures/test-data/otherconfig'
        const expectedConfig = JSON.parse(fs.readFileSync(filePath, 'utf8'))

        ipfs.config.replace(filePath, (err) => {
          expect(err).not.to.exist()
          expect(expectedConfig).to.deep.equal(updatedConfig())
          done()
        })
      })
    })
  })
})

'''
'''--- test/http-api/dns.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

describe('dns endpoint', () => {
  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)
    df.spawn({
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  describe('.dns', () => {
    it('resolve ipfs.io dns', function (done) {
      this.timeout(40 * 1000)

      ipfs.dns('ipfs.io', (err, result) => {
        expect(err).to.not.exist()
        expect(result).to.exist()
        done()
      })
    })
  })
})

'''
'''--- test/http-api/files.js ---
/* eslint-env mocha */
/* eslint max-nested-callbacks: ["error", 8] */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const DaemonFactory = require('ipfsd-ctl')
const expect = chai.expect
chai.use(dirtyChai)
const {
  FILE_TYPES
} = require('ipfs-mfs')

const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

describe('.files', () => {
  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)
    df.spawn({
      initOptions: { bits: 512 },
      config: { Bootstrap: [] }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after(function (done) {
    this.timeout(20 * 1000)
    if (ipfsd) {
      ipfsd.stop(done)
    } else {
      done()
    }
  })

  describe('.add', function () {
    it('performs a speculative add, --only-hash', () => {
      const content = String(Math.random())

      return ipfs.add(Buffer.from(content), { onlyHash: true })
        .then(files => {
          const getAttempt = ipfs.object.get(files[0].hash)
            .then(() => {
              throw new Error('Should not find an object for content added with --only-hash')
            })

          return Promise.race([
            getAttempt,
            new Promise((resolve, reject) => setTimeout(resolve, 4000))
          ])
        })
    })
  })

  describe('.ls', function () {
    it('lists empty directory', () => {
      return ipfs.files.ls()
        .then(files => {
          expect(files).to.be.empty()
        })
    })

    it('lists files', () => {
      const fileName = `single-file-${Math.random()}.txt`

      return ipfs.files.write(`/${fileName}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.ls())
        .then(files => {
          expect(files.length).to.equal(1)
          expect(files[0].name).to.equal(fileName)
        })
    })

    it('lists files in directories', () => {
      const dirName = `dir-${Math.random()}`
      const fileName = `file-in-dir-${Math.random()}.txt`

      return ipfs.files.write(`/${dirName}/${fileName}`, Buffer.from('Hello world'), {
        create: true,
        parents: true
      })
        .then(() => ipfs.files.ls(`/${dirName}`))
        .then(files => {
          expect(files.length).to.equal(1)
          expect(files[0].name).to.equal(fileName)
        })
    })
  })

  describe('.cp', function () {
    it('copies a file', () => {
      const source = `source-file-${Math.random()}.txt`
      const destination = `destination-file-${Math.random()}.txt`

      return ipfs.files.write(`/${source}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.cp(`/${source}`, `/${destination}`))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceFile = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceFile.type).to.equal(FILE_TYPES.file)

          const destFile = files
            .filter(file => file.name === destination)
            .pop()

          expect(destFile.type).to.equal(FILE_TYPES.file)
        })
    })

    it('copies a directory', () => {
      const source = `source-dir-${Math.random()}`
      const destination = `destination-dir-${Math.random()}`

      return ipfs.files.mkdir(`/${source}`)
        .then(() => ipfs.files.cp(`/${source}`, `/${destination}`))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceDir = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceDir.type).to.equal(FILE_TYPES.directory)

          const destDir = files
            .filter(file => file.name === destination)
            .pop()

          expect(destDir.type).to.equal(FILE_TYPES.directory)
        })
    })

    it('copies a file with array args', () => {
      const source = `source-file-${Math.random()}.txt`
      const destination = `destination-file-${Math.random()}.txt`

      return ipfs.files.write(`/${source}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.cp([`/${source}`, `/${destination}`]))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceFile = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceFile.type).to.equal(FILE_TYPES.file)

          const destFile = files
            .filter(file => file.name === destination)
            .pop()

          expect(destFile.type).to.equal(FILE_TYPES.file)
        })
    })

    it('copies a directory with array args', () => {
      const source = `source-dir-${Math.random()}`
      const destination = `destination-dir-${Math.random()}`

      return ipfs.files.mkdir(`/${source}`)
        .then(() => ipfs.files.cp([`/${source}`, `/${destination}`]))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceDir = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceDir.type).to.equal(FILE_TYPES.directory)

          const destDir = files
            .filter(file => file.name === destination)
            .pop()

          expect(destDir.type).to.equal(FILE_TYPES.directory)
        })
    })
  })

  describe('.mkdir', function () {
    it('makes a directory', () => {
      const directory = `directory-${Math.random()}`

      return ipfs.files.mkdir(`/${directory}`)
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const dir = files
            .filter(file => file.name === directory)
            .pop()

          expect(dir.type).to.equal(FILE_TYPES.directory)
        })
    })
  })

  describe('.mv', function () {
    it('moves a file', () => {
      const source = `source-file-${Math.random()}.txt`
      const destination = `destination-file-${Math.random()}.txt`

      return ipfs.files.write(`/${source}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.mv(`/${source}`, `/${destination}`))
        .then(() => ipfs.files.ls(`/`))
        .then(files => {
          const sourceFile = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceFile).to.not.exist()

          const destFile = files
            .filter(file => file.name === destination)
            .pop()

          expect(destFile.type).to.equal(FILE_TYPES.file)
        })
    })

    it('moves a directory', () => {
      const source = `source-dir-${Math.random()}`
      const destination = `destination-dir-${Math.random()}`

      return ipfs.files.mkdir(`/${source}`)
        .then(() => ipfs.files.mv(`/${source}`, `/${destination}`))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceDir = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceDir).to.not.exist()

          const destDir = files
            .filter(file => file.name === destination)
            .pop()

          expect(destDir.type).to.equal(FILE_TYPES.directory)
        })
    })

    it('moves a file with array args', () => {
      const source = `source-file-${Math.random()}.txt`
      const destination = `destination-file-${Math.random()}.txt`

      return ipfs.files.write(`/${source}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.mv([`/${source}`, `/${destination}`]))
        .then(() => ipfs.files.ls(`/`))
        .then(files => {
          const sourceFile = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceFile).to.not.exist()

          const destFile = files
            .filter(file => file.name === destination)
            .pop()

          expect(destFile.type).to.equal(FILE_TYPES.file)
        })
    })

    it('moves a directory with array args', () => {
      const source = `source-dir-${Math.random()}`
      const destination = `destination-dir-${Math.random()}`

      return ipfs.files.mkdir(`/${source}`)
        .then(() => ipfs.files.mv([`/${source}`, `/${destination}`]))
        .then(() => ipfs.files.ls(`/`, {
          long: true
        }))
        .then(files => {
          const sourceDir = files
            .filter(file => file.name === source)
            .pop()

          expect(sourceDir).to.not.exist()

          const destDir = files
            .filter(file => file.name === destination)
            .pop()

          expect(destDir.type).to.equal(FILE_TYPES.directory)
        })
    })
  })

  describe('.read', function () {
    it('reads a file', () => {
      const fileName = `single-file-${Math.random()}.txt`
      const content = Buffer.from('Hello world')

      return ipfs.files.write(`/${fileName}`, content, {
        create: true
      })
        .then(() => ipfs.files.read(`/${fileName}`))
        .then(buffer => {
          expect(buffer).to.deep.equal(content)
        })
    })
  })

  describe('.rm', function () {
    it('removes a file', () => {
      const fileName = `single-file-${Math.random()}.txt`

      return ipfs.files.write(`/${fileName}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.rm(`/${fileName}`))
        .then(() => ipfs.files.ls(`/`))
        .then(files => {
          const file = files
            .filter(file => file.name === fileName)
            .pop()

          expect(file).to.not.exist()
        })
    })

    it('removes a directory', () => {
      const dirName = `dir-${Math.random()}`
      const fileName = `file-in-dir-${Math.random()}.txt`

      return ipfs.files.write(`/${dirName}/${fileName}`, Buffer.from('Hello world'), {
        create: true,
        parents: true
      })
        .then(() => ipfs.files.rm(`/${dirName}`, {
          recursive: true
        }))
        .then(() => ipfs.files.ls(`/`))
        .then(files => {
          const dir = files
            .filter(file => file.name === dirName)
            .pop()

          expect(dir).to.not.exist()
        })
    })
  })

  describe('.stat', function () {
    it('stats a file', () => {
      const fileName = `single-file-${Math.random()}.txt`

      return ipfs.files.write(`/${fileName}`, Buffer.from('Hello world'), {
        create: true
      })
        .then(() => ipfs.files.stat(`/${fileName}`))
        .then(stats => {
          expect(stats).to.deep.equal({
            blocks: 1,
            cumulativeSize: 69,
            hash: 'Qmetpc7cZmN25Wcc6R27cGCAvCDqCS5GjHG4v7xABEfpmJ',
            local: undefined,
            size: 11,
            sizeLocal: undefined,
            type: 'file',
            withLocality: false
          })
        })
    })

    it('stats a directory', () => {
      const dirName = `dir-${Math.random()}`

      return ipfs.files.mkdir(`/${dirName}`)
        .then(() => ipfs.files.stat(`/${dirName}`))
        .then(stats => {
          expect(stats).to.deep.equal({
            blocks: 0,
            cumulativeSize: 4,
            hash: 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',
            local: undefined,
            size: 0,
            sizeLocal: undefined,
            type: 'directory',
            withLocality: false
          })
        })
    })
  })
})

'''
'''--- test/http-api/id.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const ncp = require('ncp').ncp
const rimraf = require('rimraf')
const waterfall = require('async/waterfall')
const path = require('path')

const isWindows = require('../utils/platforms').isWindows
const skipOnWindows = isWindows() ? describe.skip : describe

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

skipOnWindows('id endpoint', () => {
  const repoExample = path.join(__dirname, '../fixtures/go-ipfs-repo')
  const repoPath = path.join(__dirname, '../repo-tests-run')

  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)

    ncp(repoExample, repoPath, (err) => {
      expect(err).to.not.exist()

      waterfall([
        (cb) => df.spawn({
          repoPath: repoPath,
          initOptions: { bits: 512 },
          config: { Bootstrap: [] },
          disposable: false,
          start: true
        }, cb),
        (_ipfsd, cb) => {
          ipfsd = _ipfsd
          ipfsd.start(cb)
        }
      ], (err) => {
        expect(err).to.not.exist()
        ipfs = ipfsd.api
        done()
      })
    })
  })

  after((done) => {
    rimraf(repoPath, (err) => {
      expect(err).to.not.exist()
      ipfsd.stop(done)
    })
  })

  describe('.id', () => {
    it('get the identity', (done) => {
      ipfs.id((err, result) => {
        expect(err).to.not.exist()
        expect(result.id).to.equal(idResult.ID)
        expect(result.publicKey).to.equal(idResult.PublicKey)
        const agentComponents = result.agentVersion.split('/')
        expect(agentComponents).lengthOf.above(1)
        expect(agentComponents[0]).to.equal(idResult.AgentVersion)
        expect(result.protocolVersion).to.equal(idResult.ProtocolVersion)
        done()
      })
    })
  })
})

const idResult = {
  ID: 'QmTuh8pVDCz5kbShrK8MJsJgTycCcGwZm8hQd8SxdbYmby',
  PublicKey: 'CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCiyLgGRpuGiorm6FzvBbrTU60e6iPMmwXL9mXyGitepQyeN7XF8e6cooFeJI/NIyvbmpa7rHCDzTWP+6ebIMOXjUjQDAgaYdHywKbAXi2cgh96yuTN+cfPJ0IVA1/4Xsn/mnaMmSNDxqnK3fExEDxZizL9iI7KQCGOHociwjNj2cqaz+4ldTQ6QBbqa8nBMbulUNtSzwihQHTHNVwhuYFGPXIIK8UhM1VR20HcCbX+TZ9RpBWLIGZgjJl2ClW7wLW1OAb55I/9CK6AmfOriVYSBxZSFi2jiPCGQmuzfiqEke6/hSZtxe8DRo8ELOQ9K2P3L27H2az2atis2FoqVY2LAgMBAAE=',
  Addresses: ['/ip4/0.0.0.0/tcp/0'],
  AgentVersion: 'js-ipfs',
  ProtocolVersion: '9000'
}

'''
'''--- test/http-api/index.js ---
'use strict'

require('./block')
require('./bootstrap')
require('./config')
require('./dns')
require('./id')
require('./routes')
require('./interface')
require('./object')
require('./version')
require('./files')

'''
'''--- test/http-api/inject/bitswap.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const CID = require('cids')
const waitFor = require('../../utils/wait-for').promises

module.exports = (http) => {
  describe('/bitswap', () => {
    const wantedCid0 = 'QmUBdnXXPyoDFXj3Hj39dNJ5VkN3QFRskXxcGaYFBB8CNR'
    const wantedCid1 = 'zb2rhafnd6kEUujnoMkozHnWXY7XpWttyVDWKXfChqA42VTDU'
    let api

    before(() => {
      api = http.api._apiServer
    })

    before(async function () {
      this.timeout(120 * 1000)

      // Add a CID to the wantlist
      api.inject({ method: 'GET', url: `/api/v0/block/get?arg=${wantedCid0}` })
      api.inject({ method: 'GET', url: `/api/v0/block/get?arg=${wantedCid1}` })

      const test = async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/bitswap/wantlist'
        })

        if (res.statusCode !== 200) {
          throw new Error(`unexpected status ${res.statusCode}`)
        }

        const isWanted0 = res.result.Keys.some(k => k['/'] === wantedCid0)
        const isWanted1 = res.result.Keys.some(k => k['/'] === wantedCid1)

        return isWanted0 && isWanted1
      }

      return waitFor(test, {
        name: `${wantedCid0} and ${wantedCid1} to be wanted`,
        timeout: 60 * 1000
      })
    })

    it('/wantlist', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/wantlist'
      })

      expect(res.statusCode).to.equal(200)
      expect(res.result).to.have.property('Keys')
      expect(res.result.Keys).to.deep.include({ '/': wantedCid0 })
    })

    it('/wantlist?cid-base=base64', async () => {
      const base64Cid = new CID(wantedCid1).toString('base64')
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/wantlist?cid-base=base64'
      })

      expect(res.statusCode).to.equal(200)
      expect(res.result.Keys).to.deep.include({ '/': base64Cid })
    })

    it('/wantlist?cid-base=invalid', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/wantlist?cid-base=invalid'
      })

      expect(res.statusCode).to.equal(400)
      expect(res.result.Message).to.include('Invalid request query input')
    })

    it('/stat', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/stat'
      })

      expect(res.statusCode).to.equal(200)
      expect(res.result).to.have.property('ProvideBufLen')
      expect(res.result).to.have.property('BlocksReceived')
      expect(res.result).to.have.property('Wantlist')
      expect(res.result).to.have.property('Peers')
      expect(res.result).to.have.property('DupBlksReceived')
      expect(res.result).to.have.property('DupDataReceived')
      expect(res.result).to.have.property('DataReceived')
      expect(res.result).to.have.property('BlocksSent')
      expect(res.result).to.have.property('DataSent')
    })

    it('/stat?cid-base=base64', async () => {
      const base64Cid = new CID(wantedCid1).toString('base64')
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/stat?cid-base=base64'
      })

      expect(res.statusCode).to.equal(200)
      expect(res.result.Wantlist).to.deep.include({ '/': base64Cid })
    })

    it('/stat?cid-base=invalid', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bitswap/stat?cid-base=invalid'
      })

      expect(res.statusCode).to.equal(400)
      expect(res.result.Message).to.include('Invalid request query input')
    })
  })
}

'''
'''--- test/http-api/inject/block.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const fs = require('fs')
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const multibase = require('multibase')

module.exports = (http) => {
  describe('/block', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    describe('/block/put', () => {
      it('returns 400 if no node is provided', async () => {
        const form = new FormData()
        const headers = form.getHeaders()
        const payload = await streamToPromise(form)

        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('updates value', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/hello'
        form.append('data', fs.createReadStream(filePath))
        const headers = form.getHeaders()
        const expectedResult = {
          Key: 'QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp',
          Size: 12
        }

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.deep.equal(expectedResult)
      })

      it('should put a value and return a base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put?cid-base=base64',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Key)).to.deep.equal('base64')
      })

      it('should not put a value for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put?cid-base=invalid',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/block/get', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/get'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/get?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/get?arg=QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.equal('hello world\n')
      })
    })

    describe('/block/stat', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/stat'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/stat?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/stat?arg=QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key)
          .to.equal('QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp')
        expect(res.result.Size).to.equal(12)
      })

      it('should stat a block and return a base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put?cid-base=base64',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Key)).to.deep.equal('base64')
      })

      it('should not stat a block for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/block/put?cid-base=invalid',
          headers,
          payload
        })
        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/block/rm', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/rm'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/rm?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 200', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/block/rm?arg=QmZjTnYw2TFhn9Nn7tjmPSoTBoY7YRkwPzwSrSbabY24Kp'
        })

        expect(res.statusCode).to.equal(200)
      })
    })
  })
}

'''
'''--- test/http-api/inject/bootstrap.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const qs = require('qs')
const defaultList = require('../../../src/core/runtime/config-nodejs.js')().Bootstrap

module.exports = (http) => {
  describe('/bootstrap', () => {
    const validIp4 = '/ip4/101.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z'
    let api

    before(() => {
      api = http.api._apiServer
      return api.inject({
        method: 'GET',
        url: '/api/v0/bootstrap/add/default'
      })
    })

    it('/list', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bootstrap/list'
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.deep.equal(defaultList)
    })

    it('/list alias', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/bootstrap'
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.deep.equal(defaultList)
    })

    it('/add', async () => {
      const query = {
        arg: validIp4
      }

      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/bootstrap/add?${qs.stringify(query)}`
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.be.eql([validIp4])
    })

    it('/add/default', async () => {
      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/bootstrap/add/default`
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.be.eql(defaultList)
    })

    it('/rm', async () => {
      const query = {
        arg: validIp4
      }

      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/bootstrap/rm?${qs.stringify(query)}`
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.be.eql([validIp4])
    })

    it('/rm/all', async () => {
      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/bootstrap/rm/all`
      })

      expect(res.statusCode).to.be.eql(200)
      expect(res.result.Peers).to.be.eql([])
    })
  })
}

'''
'''--- test/http-api/inject/config.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const fs = require('fs')
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const path = require('path')

module.exports = (http) => {
  describe('/config', () => {
    const configPath = path.join(__dirname, '../../repo-tests-run/config')
    const originalConfigPath = path.join(__dirname, '../../fixtures/go-ipfs-repo/config')

    let updatedConfig
    let api

    before(() => {
      updatedConfig = () => JSON.parse(fs.readFileSync(configPath, 'utf8'))
      api = http.api._apiServer
    })

    after(() => {
      fs.writeFileSync(configPath, fs.readFileSync(originalConfigPath, 'utf8'), 'utf8')
    })

    describe('/config', () => {
      it('returns 400 for request without arguments', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config'
        })

        expect(res.statusCode).to.equal(400)
      })

      it('404 for request with missing args', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=kitten'
        })

        expect(res.statusCode).to.equal(404)
        expect(res.result.Code).to.equal(3)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value for request with valid arg', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=API.HTTPHeaders'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('API.HTTPHeaders')
        expect(res.result.Value).to.equal(null)
      })

      it('returns value for request as subcommand', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config/API.HTTPHeaders'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('API.HTTPHeaders')
        expect(res.result.Value).to.equal(null)
      })

      it('updates value for request with both args', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=Datastore.Path&arg=kitten'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('Datastore.Path')
        expect(res.result.Value).to.equal('kitten')
        expect(updatedConfig().Datastore.Path).to.equal('kitten')
      })

      it('returns 400 value for request with both args and JSON flag with invalid JSON argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=Datastore.Path&arg=kitten&json'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('updates value for request with both args and JSON flag with valid JSON argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=Datastore.Path&arg={"kitten": true}&json'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('Datastore.Path')
        expect(res.result.Value).to.deep.equal({ kitten: true })
        expect(updatedConfig().Datastore.Path).to.deep.equal({ kitten: true })
      })

      it('updates value for request with both args and bool flag and true argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=Datastore.Path&arg=true&bool'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('Datastore.Path')
        expect(res.result.Value).to.deep.equal(true)
        expect(updatedConfig().Datastore.Path).to.deep.equal(true)
      })

      it('updates value for request with both args and bool flag and false argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config?arg=Datastore.Path&arg=false&bool'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Key).to.equal('Datastore.Path')
        expect(res.result.Value).to.deep.equal(false)
        expect(updatedConfig().Datastore.Path).to.deep.equal(false)
      })
    })

    it('/config/show', async () => {
      const res = await api.inject({
        method: 'POST',
        url: '/api/v0/config/show'
      })

      expect(res.statusCode).to.equal(200)
      expect(res.result).to.deep.equal(updatedConfig())
    })

    describe('/config/replace', () => {
      it('returns 400 if no config is provided', async () => {
        const form = new FormData()
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config/replace',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('returns 500 if the config is invalid', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badconfig'
        form.append('file', fs.createReadStream(filePath))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config/replace',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(500)
      })

      it('updates value', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/otherconfig'
        form.append('file', fs.createReadStream(filePath))
        const headers = form.getHeaders()
        const expectedConfig = JSON.parse(fs.readFileSync(filePath, 'utf8'))

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/config/replace',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(updatedConfig()).to.deep.equal(expectedConfig)
      })
    })
  })
}

'''
'''--- test/http-api/inject/dht.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

module.exports = (http) => {
  describe('/dht', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    describe('/findpeer', () => {
      it('returns 400 if no peerId is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/findpeer`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 404 if peerId is provided as there is no peers in the routing table', async () => {
        const peerId = 'QmQ2zigjQikYnyYUSXZydNXrDRhBut2mubwJBaLXobMt3A'
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/findpeer?arg=${peerId}`
        })

        expect(res.statusCode).to.equal(404)
      })
    })

    describe('/findprovs', () => {
      it('returns 400 if no key is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/findprovs`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 200 if key is provided', async () => {
        const key = 'Qmc77hSNykXJ6Jxp1C6RpD8VENV7RK6JD7eAcWpc7nEZx2'
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/findprovs?arg=${key}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Type).to.be.eql(4)
      })
    })

    describe('/get', () => {
      it('returns 400 if no key is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/get`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 200 if key is provided', async () => {
        const key = 'key'
        const value = 'value'

        let res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/put?arg=${key}&arg=${value}`
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/get?arg=${key}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Type).to.be.eql(5)
        expect(res.result.Extra).to.be.eql(value)
      })
    })

    describe('/provide', () => {
      it('returns 400 if no key is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/provide`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 500 if key is provided as the file was not added', async () => {
        const key = 'Qmc77hSNykXJ6Jxp1C6RpD8VENV7RK6JD7eAcWpc7nEZx2'
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/provide?arg=${key}`
        })

        expect(res.statusCode).to.equal(500) // needs file add
      })
    })

    describe('/put', () => {
      it('returns 400 if no key or value is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/put`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 200 if key and value is provided', async function () {
        this.timeout(60 * 1000)

        const key = 'key'
        const value = 'value'

        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/dht/put?arg=${key}&arg=${value}`
        })

        expect(res.statusCode).to.equal(200)
      })
    })
  })
}

'''
'''--- test/http-api/inject/dns.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect

module.exports = (http) => {
  describe('/dns', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('resolve ipfs.io dns', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/dns?arg=ipfs.io'
      })

      expect(res.result).to.have.property('Path')
    })
  })
}

'''
'''--- test/http-api/inject/files.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const crypto = require('crypto')
const expect = require('chai').expect
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const multibase = require('multibase')

module.exports = (http) => {
  describe('/files', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    describe('/add', () => {
      it('should add buffer bigger than Hapi default max bytes (1024 * 1024)', async () => {
        const payload = Buffer.from([
          '',
          '------------287032381131322',
          'Content-Disposition: form-data; name="test"; filename="test.txt"',
          'Content-Type: text/plain',
          '',
          crypto.randomBytes(1024 * 1024 * 2).toString('hex'),
          '------------287032381131322--'
        ].join('\r\n'))

        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers: {
            'Content-Type': 'multipart/form-data; boundary=----------287032381131322'
          },
          payload
        })

        expect(res.statusCode).to.not.equal(413) // Payload too large
        expect(res.statusCode).to.equal(200)
      })

      // TODO: unskip when we can retrieve data from the repo with a different
      // version CID then it was added with.
      it.skip('should add data and return a base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/add?cid-base=base64',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(JSON.parse(res.result).Hash)).to.deep.equal('base64')
      })

      it('should add data without pinning and return a base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/add?cid-base=base64&pin=false',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(JSON.parse(res.result).Hash)).to.deep.equal('base64')
      })
    })

    describe('/cat', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/cat'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/cat?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('should cat a valid hash', async function () {
        this.timeout(30 * 1000)

        const data = Buffer.from('TEST' + Date.now())
        const form = new FormData()
        form.append('data', data)
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        const cid = JSON.parse(res.result).Hash

        res = await api.inject({
          method: 'GET',
          url: '/api/v0/cat?arg=' + cid
        })

        expect(res.statusCode).to.equal(200)
        expect(res.rawPayload).to.deep.equal(data)
        expect(res.payload).to.equal(data.toString())
      })
    })

    describe('/get', () => {}) // TODO

    describe('/ls', () => {
      it('should list directory contents and return a base64 encoded CIDs', async () => {
        const form = new FormData()
        form.append('file', Buffer.from('TEST' + Date.now()), { filename: 'data.txt' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add?wrap-with-directory=true',
          headers,
          payload
        })
        expect(res.statusCode).to.equal(200)

        const files = res.result.trim().split('\n').map(r => JSON.parse(r))
        const dir = files[files.length - 1]

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/ls?cid-base=base64&arg=' + dir.Hash
        })
        expect(res.statusCode).to.equal(200)
        res.result.Objects[0].Links.forEach(item => {
          expect(multibase.isEncoded(item.Hash)).to.deep.equal('base64')
        })
      })
    })
  })
}

'''
'''--- test/http-api/inject/id.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect

module.exports = (http) => {
  describe('/id', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('get the id', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/id'
      })

      expect(res.result.ID).to.equal(idResult.ID)
      expect(res.result.PublicKey).to.equal(idResult.PublicKey)
      const agentComponents = res.result.AgentVersion.split('/')
      expect(agentComponents).lengthOf.above(1)
      expect(agentComponents[0]).to.equal(idResult.AgentVersion)
      expect(res.result.ProtocolVersion).to.equal(idResult.ProtocolVersion)
    })
  })
}

const idResult = {
  ID: 'QmTuh8pVDCz5kbShrK8MJsJgTycCcGwZm8hQd8SxdbYmby',
  PublicKey: 'CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCiyLgGRpuGiorm6FzvBbrTU60e6iPMmwXL9mXyGitepQyeN7XF8e6cooFeJI/NIyvbmpa7rHCDzTWP+6ebIMOXjUjQDAgaYdHywKbAXi2cgh96yuTN+cfPJ0IVA1/4Xsn/mnaMmSNDxqnK3fExEDxZizL9iI7KQCGOHociwjNj2cqaz+4ldTQ6QBbqa8nBMbulUNtSzwihQHTHNVwhuYFGPXIIK8UhM1VR20HcCbX+TZ9RpBWLIGZgjJl2ClW7wLW1OAb55I/9CK6AmfOriVYSBxZSFi2jiPCGQmuzfiqEke6/hSZtxe8DRo8ELOQ9K2P3L27H2az2atis2FoqVY2LAgMBAAE=',
  Addresses: [ '/ip4/0.0.0.0/tcp/0' ],
  AgentVersion: 'js-ipfs',
  ProtocolVersion: '9000'
}

'''
'''--- test/http-api/inject/name.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')

const expect = chai.expect
chai.use(dirtyChai)

const checkAll = (bits) => string => bits.every(bit => string.includes(bit))

module.exports = (http) => {
  describe('/name', function () {
    const cid = 'QmbndGRXYRyfU41TUvc52gMrwq87JJg18QsDPcCeaMcM61'
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('should publish a record', async function () {
      this.timeout(80 * 1000)

      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/name/publish?arg=${cid}&resolve=false`
      })

      expect(res).to.exist()
      expect(res.result.Value).to.equal(`/ipfs/${cid}`)
    })

    it('should publish and resolve a record', async function () {
      this.timeout(160 * 1000)

      let res = await api.inject({
        method: 'GET',
        url: `/api/v0/name/publish?arg=${cid}&resolve=false`
      })

      expect(res).to.exist()
      expect(res.result.Value).to.equal(`/ipfs/${cid}`)

      res = await api.inject({
        method: 'GET',
        url: `/api/v0/name/resolve`
      })

      expect(res).to.exist()
      expect(res.result.Path).to.satisfy(checkAll([`/ipfs/${cid}`]))
    })
  })
}

'''
'''--- test/http-api/inject/object.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const fs = require('fs')
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const multibase = require('multibase')

module.exports = (http) => {
  describe('/object', () => {
    let api

    before('api', () => {
      api = http.api._apiServer
    })

    describe('/new', () => {
      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Hash)
          .to.equal('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n')
        expect(res.result.Links).to.be.eql([])
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should create a new object and return a base64 encoded CID', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new?cid-base=base64'
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not create a new object for invalid cid-base option', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new?cid-base=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/get', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/get'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/get?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/get?arg=QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Links).to.eql([])
        expect(res.result.Data).to.be.empty()
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should get object and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/get?cid-base=base64&arg=' + res.result.Hash
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not get an object for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })
        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/get?cid-base=invalid&arg=' + res.result.Hash
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/put', () => {
      it('returns 400 if no node is provided', async () => {
        const form = new FormData()
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('returns 400 if the node is invalid', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badnode.json'
        form.append('file', fs.createReadStream(filePath))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('updates value', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/node.json'
        form.append('data', fs.createReadStream(filePath))
        const headers = form.getHeaders()

        const expectedResult = {
          Data: Buffer.from('another'),
          Hash: 'QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm',
          Links: [{
            Name: 'some link',
            Hash: 'QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V',
            Size: 8
          }],
          Size: 68
        }

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.eql(expectedResult)
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should put data and return a base64 encoded CID', async () => {
        const form = new FormData()
        form.append('file', JSON.stringify({ Data: 'TEST' + Date.now(), Links: [] }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put?cid-base=base64',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not put data for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('file', JSON.stringify({ Data: 'TEST' + Date.now(), Links: [] }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put?cid-base=invalid',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/stat', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/stat'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/stat?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/stat?arg=QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Hash).to.equal('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm')
        expect(res.result.NumLinks).to.equal(1)
        expect(res.result.BlockSize).to.equal(60)
        expect(res.result.LinksSize).to.equal(60 - 7)
        expect(res.result.DataSize).to.equal(7)
        expect(res.result.CumulativeSize).to.equal(60 + 8)
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should stat object and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/stat?cid-base=base64&arg=' + res.result.Hash
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not stat object for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/stat?cid-base=invalid&arg=' + res.result.Hash
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/data', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/data'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/data?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/data?arg=QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.equal('another')
      })
    })

    describe('/links', () => {
      it('returns 400 for request without argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/links'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/links?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const expectedResult = {
          Hash: 'QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm',
          Links: [
            { Name: 'some link', Hash: 'QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V', Size: 8 }
          ]
        }

        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/links?arg=QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.deep.equal(expectedResult)
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should list object links and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)
        const linkHash = res.result.Hash

        const form = new FormData()
        form.append('file', JSON.stringify({
          Data: 'TEST' + Date.now(),
          Links: [{ Name: 'emptyNode', Hash: linkHash, Size: 8 }]
        }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = res.result.Hash

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/links?cid-base=base64&arg=' + hash
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
        expect(res.result.Links).to.have.length(1)
        expect(multibase.isEncoded(res.result.Links[0].Hash)).to.deep.equal('base64')
      })

      it('should not list object links for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)
        const linkHash = res.result.Hash

        const form = new FormData()
        form.append('file', JSON.stringify({
          Data: 'TEST' + Date.now(),
          Links: [{ Name: 'emptyNode', Hash: linkHash, Size: 8 }]
        }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = res.result.Hash

        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/links?cid-base=invalid&arg=' + hash
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/patch/append-data', () => {
      it('returns 400 for request without key', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 if no data is provided', async () => {
        const form = new FormData()
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data?arg=QmVLUHkjGg3duGb5w3dnwK5w2P9QWuJmtVNuDPLc9ZDjzk',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('returns 400 for request with invalid key', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badconfig'
        form.append('file', fs.createReadStream(filePath))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data?arg=invalid',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('updates value', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badconfig'
        form.append('data', fs.createReadStream(filePath))
        const headers = form.getHeaders()
        const expectedResult = {
          Data: fs.readFileSync(filePath),
          Hash: 'QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6',
          Links: [],
          Size: 19
        }

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data?arg=QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.deep.equal(expectedResult)
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should append data to object and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data?cid-base=base64&arg=' + res.result.Hash,
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not append data to object for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/append-data?cid-base=invalid&arg=' + res.result.Hash,
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/patch/set-data', () => {
      it('returns 400 for request without key', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 if no data is provided', async () => {
        const form = new FormData()
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data?arg=QmVLUHkjGg3duGb5w3dnwK5w2P9QWuJmtVNuDPLc9ZDjzk',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('returns 400 for request with invalid key', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badconfig'
        form.append('file', fs.createReadStream(filePath))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data?arg=invalid',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
      })

      it('updates value', async () => {
        const form = new FormData()
        const filePath = 'test/fixtures/test-data/badconfig'
        form.append('data', fs.createReadStream(filePath))
        const headers = form.getHeaders()
        const expectedResult = {
          Hash: 'QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6',
          Links: []
        }

        const payload = await streamToPromise(form)
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data?arg=QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result).to.deep.equal(expectedResult)
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should set data for object and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })
        expect(res.statusCode).to.equal(200)

        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data?cid-base=base64&arg=' + res.result.Hash,
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not set data for object for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/set-data?cid-base=invalid&arg=' + res.result.Hash,
          headers,
          payload
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/patch/add-link', () => {
      it('returns 400 for request without arguments', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/add-link'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with only one invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/add-link?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid first argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/add-link?arg=&arg=foo&arg=QmTz3oc4gdpRMKP2sdGUPZTAGRngqjsi99BPoztyP53JMM'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with empty second argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/add-link?arg=QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn&arg=&arg=QmTz3oc4gdpRMKP2sdGUPZTAGRngqjsi99BPoztyP53JMM'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/add-link?arg=QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n&arg=foo&arg=QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Hash).to.equal('QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK')
        expect(res.result.Links[0]).to.deep.equal({
          Name: 'foo',
          Hash: 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',
          Size: 4
        })
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should add a link to an object and return a base64 encoded CID', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/object/patch/add-link?cid-base=base64&arg=${res.result.Hash}&arg=test&arg=${res.result.Hash}`
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not add a link to an object for invalid cid-base option', async () => {
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/object/patch/add-link?cid-base=invalid&arg=${res.result.Hash}&arg=test&arg=${res.result.Hash}`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('/patch/rm-link', () => {
      it('returns 400 for request without arguments', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/rm-link'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with only one invalid argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/rm-link?arg=invalid'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid first argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/rm-link?arg=invalid&arg=foo'
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns 400 for request with invalid second argument', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/rm-link?arg=QmZKetgwm4o3LhNaoLSHv32wBhTwj9FBwAdSchDMKyFQEx&arg='
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.equal(1)
        expect(res.result.Message).to.be.a('string')
      })

      it('returns value', async () => {
        const res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/patch/rm-link?arg=QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK&arg=foo'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Hash).to.equal('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n')
      })

      // TODO: unskip after switch to v1 CIDs by default
      it.skip('should remove a link from an object and return a base64 encoded CID', async () => {
        const linkName = 'TEST' + Date.now()

        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)
        const linkHash = res.result.Hash

        const form = new FormData()
        form.append('file', JSON.stringify({
          Data: 'TEST' + Date.now(),
          Links: [{ Name: linkName, Hash: linkHash, Size: 8 }]
        }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = res.result.Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/object/patch/rm-link?cid-base=base64&arg=${hash}&arg=${linkName}`
        })

        expect(res.statusCode).to.equal(200)
        expect(multibase.isEncoded(res.result.Hash)).to.deep.equal('base64')
      })

      it('should not remove a link from an object for invalid cid-base option', async () => {
        const linkName = 'TEST' + Date.now()

        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/new'
        })

        expect(res.statusCode).to.equal(200)
        const linkHash = res.result.Hash

        const form = new FormData()
        form.append('file', JSON.stringify({
          Data: 'TEST' + Date.now(),
          Links: [{ Name: linkName, Hash: linkHash, Size: 8 }]
        }), { filename: 'node.json' })
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        res = await api.inject({
          method: 'POST',
          url: '/api/v0/object/put',
          headers,
          payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = res.result.Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/object/patch/rm-link?cid-base=invalid&arg=${hash}&arg=${linkName}`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })
  })
}

'''
'''--- test/http-api/inject/pin.js ---
/* eslint-env mocha */
/* eslint max-nested-callbacks: ["error", 8] */
'use strict'

const expect = require('chai').expect
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const multibase = require('multibase')

// We use existing pin structure in the go-ipfs-repo fixture
// so that we don't have to stream a bunch of object/put operations
// This is suitable because these tests target the functionality
// of the /pin endpoints and don't delve into the pin core
//
// fixture's pins:
// - root1
//   - c1
//   - c2
//   - c3
//   - c4
//   - c5
//   - c6

const pins = {
  root1: 'QmfGBRT6BbWJd7yUc2uYdaUZJBbnEFvTqehPFoSMQ6wgdr',
  c1: 'QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V',
  c2: 'QmYCvbfNbCwFR45HiNP45rwJgvatpiW38D961L5qAhUM5Y',
  c3: 'QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7',
  c4: 'QmQN88TEidd3RY2u3dpib49fERTDfKtDpvxnvczATNsfKT',
  c5: 'QmPZ9gcCEpqKTo6aq61g2nXGUhM4iCL3ewB6LDXZCtioEB',
  c6: 'QmciSU8hfpAXKjvK5YLUSwApomGSWN5gFbP4EpDAEzu2Te'
}

module.exports = (http) => {
  describe('pin', function () {
    this.timeout(20 * 1000)
    let api

    before(() => {
      api = http.api._apiServer
    })

    describe('rm', () => {
      it('fails on invalid args', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/rm?arg=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.match(/invalid ipfs ref path/)
      })

      it('unpins recursive pins', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/rm?arg=${pins.root1}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Pins).to.deep.eql([pins.root1])
      })

      it('unpins direct pins', async () => {
        let res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=${pins.root1}&recursive=false`
        })

        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/rm?arg=${pins.root1}&recursive=false`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Pins).to.deep.eql([pins.root1])
      })

      it('should remove pin and return base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers: headers,
          payload: payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = JSON.parse(res.result).Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/rm?arg=${hash}&cid-base=base64`
        })

        expect(res.statusCode).to.equal(200)
        res.result.Pins.forEach(cid => {
          expect(multibase.isEncoded(cid)).to.deep.equal('base64')
        })
      })

      it('should not remove pin for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers: headers,
          payload: payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = JSON.parse(res.result).Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/rm?arg=${hash}&cid-base=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('add', () => {
      it('fails on invalid args', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.match(/invalid ipfs ref path/)
      })

      it('recursively', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=${pins.root1}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Pins).to.deep.eql([pins.root1])
      })

      it('directly', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=${pins.root1}&recursive=false`
        })
        // by directly pinning a node that is already recursively pinned,
        // it should error and verifies that the endpoint is parsing
        // the recursive arg correctly.
        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.match(/already pinned recursively/)
      })

      it('should add pin and return base64 encoded CID', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add?pin=false',
          headers: headers,
          payload: payload
        })

        expect(res.statusCode).to.equal(200)
        const hash = JSON.parse(res.result).Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=${hash}&cid-base=base64`
        })

        expect(res.statusCode).to.equal(200)
        res.result.Pins.forEach(cid => {
          expect(multibase.isEncoded(cid)).to.deep.equal('base64')
        })
      })

      it('should not add pin for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add?pin=false',
          headers: headers,
          payload: payload
        })
        expect(res.statusCode).to.equal(200)
        const hash = JSON.parse(res.result).Hash

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/add?arg=${hash}&cid-base=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })

    describe('ls', () => {
      it('fails on invalid args', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pin/ls?arg=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.match(/invalid ipfs ref path/)
      })

      it('finds all pinned objects', async () => {
        const res = await api.inject({
          method: 'GET',
          url: '/api/v0/pin/ls'
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Keys).to.include.all.keys(Object.values(pins))
      })

      it('finds specific pinned objects', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pin/ls?arg=${pins.c1}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Keys[pins.c1].Type)
          .to.equal(`indirect through ${pins.root1}`)
      })

      it('finds pins of type', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pin/ls?type=recursive`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Keys['QmfGBRT6BbWJd7yUc2uYdaUZJBbnEFvTqehPFoSMQ6wgdr'])
          .to.deep.eql({ Type: 'recursive' })
      })

      it('should list pins and return base64 encoded CIDs', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers: headers,
          payload: payload
        })
        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/ls?cid-base=base64`
        })

        expect(res.statusCode).to.equal(200)
        Object.keys(res.result.Keys).forEach(cid => {
          expect(multibase.isEncoded(cid)).to.deep.equal('base64')
        })
      })

      it('should not list pins for invalid cid-base option', async () => {
        const form = new FormData()
        form.append('data', Buffer.from('TEST' + Date.now()))
        const headers = form.getHeaders()

        const payload = await streamToPromise(form)
        let res = await api.inject({
          method: 'POST',
          url: '/api/v0/add',
          headers: headers,
          payload: payload
        })
        expect(res.statusCode).to.equal(200)

        res = await api.inject({
          method: 'POST',
          url: `/api/v0/pin/ls?cid-base=invalid`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Message).to.include('Invalid request query input')
      })
    })
  })
}

'''
'''--- test/http-api/inject/ping.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')

const expect = chai.expect
chai.use(dirtyChai)

module.exports = (http) => {
  describe('/ping', function () {
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('returns 400 if both n and count are provided', async () => {
      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/ping?arg=peerid&n=1&count=1`
      })

      expect(res.statusCode).to.equal(400)
    })

    it('returns 400 if arg is not provided', async () => {
      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/ping?count=1`
      })

      expect(res.statusCode).to.equal(400)
    })

    it('returns 500 for incorrect Peer Id', async function () {
      this.timeout(90 * 1000)

      const res = await api.inject({
        method: 'GET',
        url: `/api/v0/ping?arg=peerid`
      })

      expect(res.statusCode).to.equal(500)
    })
  })
}

'''
'''--- test/http-api/inject/pubsub.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

module.exports = (http) => {
  describe('/pubsub', () => {
    let api

    const buf = Buffer.from('some message')
    const topic = 'nonScents'
    const topicNotSubscribed = 'somethingRandom'

    before(() => {
      api = http.api._apiServer
    })

    describe('/sub', () => {
      it('returns 400 if no topic is provided', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pubsub/sub`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 200 with topic', async () => {
        // TODO: Agree on a better way to test this (currently this hangs)
        // Regarding: https://github.com/ipfs/js-ipfs/pull/644#issuecomment-267687194
        // Current Patch: Subscribe to a topic so the other tests run as expected
        const ipfs = api.app.ipfs
        const handler = (msg) => {}

        await ipfs.pubsub.subscribe(topic, handler)

        await new Promise((resolve, reject) => {
          setTimeout(() => {
            ipfs.pubsub.unsubscribe(topic, handler)
            resolve()
          }, 100)
        })
        // const res = await api.inject({
        //   method: 'GET',
        //   url: `/api/v0/pubsub/sub/${topic}`
        // })
        //   console.log(res.result)
        //   expect(res.statusCode).to.equal(200)
        //   done()
        // })
      })
    })

    describe('/pub', () => {
      it('returns 400 if no buffer is provided', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pubsub/pub?arg=&arg=`
        })

        expect(res.statusCode).to.equal(400)
        expect(res.result.Code).to.be.eql(1)
      })

      it('returns 200 with topic and buffer', async () => {
        const res = await api.inject({
          method: 'POST',
          url: `/api/v0/pubsub/pub?arg=${topic}&arg=${buf}`
        })

        expect(res.statusCode).to.equal(200)
      })
    })

    describe.skip('/ls', () => {
      it('returns 200', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pubsub/ls`
        })
        expect(res.statusCode).to.equal(200)
        expect(res.result.Strings).to.be.eql([topic])
      })
    })

    describe('/peers', () => {
      it('returns 200 if not subscribed to a topic', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pubsub/peers?arg=${topicNotSubscribed}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Strings).to.be.eql([])
      })

      it('returns 200 with topic', async () => {
        const res = await api.inject({
          method: 'GET',
          url: `/api/v0/pubsub/peers?arg=${topic}`
        })

        expect(res.statusCode).to.equal(200)
        expect(res.result.Strings).to.be.eql([])
      })
    })
  })
}

'''
'''--- test/http-api/inject/resolve.js ---
/* eslint-env mocha */
/* eslint max-nested-callbacks: ["error", 8] */
'use strict'

const expect = require('chai').expect
const FormData = require('form-data')
const streamToPromise = require('stream-to-promise')
const multibase = require('multibase')

module.exports = (http) => {
  describe('resolve', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('should resolve a path and return a base2 encoded CID', async () => {
      const form = new FormData()
      form.append('data', Buffer.from('TEST' + Date.now()))
      const headers = form.getHeaders()

      const payload = await streamToPromise(form)
      let res = await api.inject({
        method: 'POST',
        url: '/api/v0/add',
        headers: headers,
        payload: payload
      })
      expect(res.statusCode).to.equal(200)
      const hash = JSON.parse(res.result).Hash

      res = await api.inject({
        method: 'POST',
        url: `/api/v0/resolve?arg=/ipfs/${hash}&cid-base=base2`
      })

      expect(res.statusCode).to.equal(200)
      expect(multibase.isEncoded(res.result.Path.replace('/ipfs/', ''))).to.deep.equal('base2')
    })

    it('should not resolve a path for invalid cid-base option', async () => {
      const form = new FormData()
      form.append('data', Buffer.from('TEST' + Date.now()))
      const headers = form.getHeaders()

      const payload = await streamToPromise(form)
      let res = await api.inject({
        method: 'POST',
        url: '/api/v0/add',
        headers: headers,
        payload: payload
      })
      expect(res.statusCode).to.equal(200)
      const hash = JSON.parse(res.result).Hash

      res = await api.inject({
        method: 'POST',
        url: `/api/v0/resolve?arg=/ipfs/${hash}&cid-base=invalid`
      })
      expect(res.statusCode).to.equal(400)
      expect(res.result.Message).to.include('Invalid request query input')
    })
  })
}

'''
'''--- test/http-api/inject/version.js ---
/* eslint-env mocha */
'use strict'

const expect = require('chai').expect
const pkgversion = require('./../../../package.json').version

module.exports = (http) => {
  describe('/version', () => {
    let api

    before(() => {
      api = http.api._apiServer
    })

    it('get the version', async () => {
      const res = await api.inject({
        method: 'GET',
        url: '/api/v0/version'
      })

      expect(res.result).to.have.a.property('Version', pkgversion)
      expect(res.result).to.have.a.property('Commit')
      expect(res.result).to.have.a.property('Repo')
    })
  })
}

'''
'''--- test/http-api/interface.js ---
/* eslint-env mocha */
'use strict'

const tests = require('interface-ipfs-core')
const CommonFactory = require('../utils/interface-common-factory')

describe('interface-ipfs-core over ipfs-http-client tests', () => {
  const defaultCommonFactory = CommonFactory.create({
    factoryOptions: { exec: 'src/cli/bin.js' }
  })

  tests.bitswap(defaultCommonFactory)

  tests.block(defaultCommonFactory)

  tests.bootstrap(defaultCommonFactory)

  tests.config(defaultCommonFactory)

  tests.dag(defaultCommonFactory, {
    skip: { reason: 'TODO: DAG HTTP endpoints not implemented in js-ipfs yet!' }
  })

  tests.dht(CommonFactory.create({
    spawnOptions: {
      initOptions: { bits: 512 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }
  }), {
    skip: [
      // dht.get
      {
        name: 'should get a value after it was put on another node',
        reason: 'Needs https://github.com/ipfs/interface-ipfs-core/pull/383'
      }
    ]
  })

  tests.filesRegular(defaultCommonFactory)

  tests.filesMFS(defaultCommonFactory)

  tests.key(CommonFactory.create({
    spawnOptions: {
      args: ['--pass ipfs-is-awesome-software'],
      initOptions: { bits: 512 }
    }
  }))

  tests.miscellaneous(CommonFactory.create({
    // No need to stop, because the test suite does a 'stop' test.
    createTeardown: () => cb => cb()
  }), {
    skip: [
      {
        name: 'should resolve an IPNS DNS link',
        reason: 'TODO IPNS not implemented yet'
      },
      {
        name: 'should resolve IPNS link recursively',
        reason: 'TODO IPNS not implemented yet'
      }
    ]
  })

  tests.object(defaultCommonFactory)

  tests.pin(defaultCommonFactory)

  tests.ping(defaultCommonFactory)

  tests.pubsub(CommonFactory.create({
    spawnOptions: {
      args: ['--enable-pubsub-experiment'],
      initOptions: { bits: 512 }
    }
  }))

  tests.repo(defaultCommonFactory, {
    skip: [
      // repo.gc
      {
        name: 'gc',
        reason: 'TODO: repo.gc is not implemented in js-ipfs yet!'
      }
    ]
  })

  tests.stats(defaultCommonFactory)

  tests.swarm(CommonFactory.create({
    createSetup ({ ipfsFactory, nodes }) {
      return callback => {
        callback(null, {
          spawnNode (repoPath, config, cb) {
            if (typeof repoPath === 'function') {
              cb = repoPath
              repoPath = undefined
            }

            if (typeof config === 'function') {
              cb = config
              config = undefined
            }

            const spawnOptions = { repoPath, config, initOptions: { bits: 512 } }

            ipfsFactory.spawn(spawnOptions, (err, _ipfsd) => {
              if (err) {
                return cb(err)
              }

              nodes.push(_ipfsd)
              cb(null, _ipfsd.api)
            })
          }
        })
      }
    }
  }))

  tests.types(defaultCommonFactory, { skip: { reason: 'FIXME: currently failing' } })

  tests.util(defaultCommonFactory, { skip: { reason: 'FIXME: currently failing' } })
})

'''
'''--- test/http-api/object.js ---
/* eslint max-nested-callbacks: ["error", 8] */
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const fs = require('fs')
const dagPB = require('ipld-dag-pb')
const DAGLink = dagPB.DAGLink

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

function asJson (cb) {
  return (err, result) => {
    expect(err).to.not.exist()
    const nodeJSON = result.toJSON()
    cb(null, nodeJSON)
  }
}

describe('object endpoint', () => {
  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)

    df.spawn({
      initOptions: { bits: 512 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  describe('.object', () => {
    it('.new', (done) => {
      ipfs.object.new((err, cid) => {
        expect(err).to.not.exist()
        expect(cid.toBaseEncodedString())
          .to.equal('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n')

        ipfs.object.get(cid, asJson((err, res) => {
          expect(err).to.not.exist()
          expect(res.links).to.be.eql([])
          done()
        }))
      })
    })

    describe('.get', () => {
      it('returns error for request without argument', (done) => {
        ipfs.object.get(null, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid argument', (done) => {
        ipfs.object.get('invalid', { enc: 'base58' }, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        ipfs.object.get('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n', { enc: 'base58' }, asJson((err, res) => {
          expect(err).to.not.exist()
          expect(res.links).to.be.eql([])
          expect(res.data).to.eql(Buffer.from(''))
          done()
        }))
      })
    })

    describe('.put', () => {
      it('returns error if the node is invalid', (done) => {
        const filePath = 'test/fixtures/test-data/badnode.json'

        ipfs.object.put(filePath, { enc: 'json' }, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('updates value', (done) => {
        const filePath = fs.readFileSync('test/fixtures/test-data/node.json')
        const expectedResult = {
          data: Buffer.from('another'),
          links: [{
            name: 'some link',
            cid: 'QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V',
            size: 8
          }],
          size: 68
        }

        ipfs.object.put(filePath, { enc: 'json' }, (err, cid) => {
          expect(err).to.not.exist()
          expect(cid.toBaseEncodedString())
            .to.equal('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm')

          ipfs.object.get(cid, asJson((err, res) => {
            expect(err).to.not.exist()
            expect(res).to.eql(expectedResult)
            done()
          }))
        })
      })
    })

    describe('.stat', () => {
      it('returns error for request without argument', (done) => {
        ipfs.object.stat(null, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid argument', (done) => {
        ipfs.object.stat('invalid', { enc: 'base58' }, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        ipfs.object.stat('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm', { enc: 'base58' }, (err, result) => {
          expect(err).to.not.exist()
          expect(result.Hash).to.equal('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm')
          expect(result.NumLinks).to.equal(1)
          expect(result.BlockSize).to.equal(60)
          expect(result.LinksSize).to.equal(60 - 7)
          expect(result.DataSize).to.equal(7)
          expect(result.CumulativeSize).to.equal(60 + 8)
          done()
        })
      })
    })

    describe('.data', () => {
      it('returns error for request without argument', (done) => {
        ipfs.object.data(null, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid argument', (done) => {
        ipfs.object.data('invalid', { enc: 'base58' }, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        ipfs.object.data('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm', { enc: 'base58' }, (err, result) => {
          expect(err).to.not.exist()
          expect(result.toString()).to.equal('another')
          done()
        })
      })
    })

    describe('.links', () => {
      it('returns error for request without argument', (done) => {
        ipfs.object.links(null, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid argument', (done) => {
        ipfs.object.links('invalid', { enc: 'base58' }, (err, result) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns value', (done) => {
        const expectedResult = {
          name: 'some link',
          cid: 'QmXg9Pp2ytZ14xgmQjYEiHjVjMFXzCVVEcRTWJBmLgR39V',
          size: 8
        }

        ipfs.object.links('QmZZmY4KCu9r3e7M2Pcn46Fc5qbn6NpzaAGaYb22kbfTqm', { enc: 'base58' }, (err, result) => {
          expect(err).to.not.exist()
          expect(result[0].toJSON()).to.deep.equal(expectedResult)
          done()
        })
      })
    })

    describe('.patch.appendData', () => {
      it('returns error for request without key & data', (done) => {
        ipfs.object.patch.appendData(null, null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request without data', (done) => {
        const filePath = 'test/fixtures/test-data/badnode.json'

        ipfs.object.patch.appendData(null, filePath, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('updates value', (done) => {
        const key = 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'
        const filePath = 'test/fixtures/test-data/badnode.json'
        const expectedResult = {
          data: fs.readFileSync(filePath),
          links: [],
          size: 19
        }

        ipfs.object.patch.appendData(key, filePath, { enc: 'base58' }, (err, cid) => {
          expect(err).to.not.exist()
          expect(cid.toBaseEncodedString())
            .to.equal('QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6')

          ipfs.object.get(cid, asJson((err, res) => {
            expect(err).to.not.exist()
            expect(res).to.eql(expectedResult)
            done()
          }))
        })
      })
    })

    describe('.patch.setData', () => {
      it('returns error for request without key & data', (done) => {
        ipfs.object.patch.setData(null, null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request without data', (done) => {
        const filePath = 'test/fixtures/test-data/badnode.json'

        ipfs.object.patch.setData(null, filePath, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('updates value', (done) => {
        const key = 'QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6'
        const filePath = 'test/fixtures/test-data/badnode.json'
        const expectedResult = {
          data: fs.readFileSync(filePath),
          links: [],
          size: 19
        }

        ipfs.object.patch.setData(key, filePath, { enc: 'base58' }, (err, cid) => {
          expect(err).to.not.exist()
          expect(cid.toBaseEncodedString())
            .to.equal('QmfY37rjbPCZRnhvvJuQ46htW3VCAWziVB991P79h6WSv6')

          ipfs.object.get(cid, asJson((err, res) => {
            expect(err).to.not.exist()
            expect(res).to.eql(expectedResult)
            done()
          }))
        })
      })
    })

    describe('.patch.addLink', () => {
      it('returns error for request without arguments', (done) => {
        ipfs.object.patch.addLink(null, null, null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request only one invalid argument', (done) => {
        ipfs.object.patch.addLink('invalid', null, null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request without name', (done) => {
        const root = 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn'
        const name = ''
        const ref = 'QmTz3oc4gdpRMKP2sdGUPZTAGRngqjsi99BPoztyP53JMM'
        const link = new DAGLink(name, 2, ref)
        ipfs.object.patch.addLink(root, link, { enc: 'base58' }, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('updates value', (done) => {
        const root = 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'
        const name = 'foo'
        const ref = 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn'
        const link = new DAGLink(name, 10, ref)

        ipfs.object.patch.addLink(root, link, { enc: 'base58' }, (err, cid) => {
          expect(err).not.to.exist()
          expect(cid.toBaseEncodedString())
            .to.equal('QmdVHE8fUD6FLNLugtNxqDFyhaCgdob372hs6BYEe75VAK')

          ipfs.object.get(cid, asJson((err, res) => {
            expect(err).to.not.exist()
            expect(res.links[0]).to.eql({
              name: 'foo',
              cid: 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',
              size: 4
            })
            done()
          }))
        })
      })
    })

    describe('.patch.rmLink', () => {
      it('returns error for request without arguments', (done) => {
        ipfs.object.patch.rmLink(null, null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request only one invalid argument', (done) => {
        ipfs.object.patch.rmLink('invalid', null, (err) => {
          expect(err).to.exist()
          done()
        })
      })

      it('returns error for request with invalid first argument', (done) => {
        const root = ''
        const link = 'foo'

        ipfs.object.patch.rmLink(root, link, (err) => {
          expect(err).to.exist()
          done()
        })
      })
    })
  })
})

'''
'''--- test/http-api/routes.js ---
/* eslint-env mocha */
'use strict'

const fs = require('fs')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
chai.use(dirtyChai)
const hat = require('hat')
const API = require('../../src/http/index')
const promisify = require('promisify-es6')
const ncp = promisify(require('ncp').ncp)
const path = require('path')
const clean = require('../utils/clean')

describe('HTTP API', () => {
  const repoExample = path.join(__dirname, '../fixtures/go-ipfs-repo')
  const repoTests = path.join(__dirname, '../repo-tests-run')

  // bootstrap nodes get the set up too slow and gets timed out
  const testsForCustomConfig = ['dht.js', 'files.js', 'name.js', 'pin.js', 'ping.js']

  let http = {}

  const startHttpAPI = async (config) => {
    http.api = new API({
      repo: repoTests,
      pass: hat(),
      config,
      EXPERIMENTAL: {
        pubsub: true
      }
    })
    await ncp(repoExample, repoTests)
    await http.api.start()
  }

  describe('custom config', () => {
    const config = {
      Bootstrap: [],
      Discovery: {
        MDNS: {
          Enabled: false
        },
        webRTCStar: {
          Enabled: false
        }
      }
    }

    before(async function () {
      this.timeout(60 * 1000)

      await startHttpAPI(config)
    })

    after(async function () {
      this.timeout(50 * 1000)

      await http.api.stop()
      clean(repoTests)
    })

    describe('## http-api spec tests for custom config', () => {
      fs.readdirSync(path.join(`${__dirname}/inject/`))
        .forEach((file) => testsForCustomConfig.includes(file) && require(`./inject/${file}`)(http))
    })
  })

  describe('default config', () => {
    const config = {
      Bootstrap: []
    }

    before(async function () {
      this.timeout(60 * 1000)
      await startHttpAPI(config)
    })

    after(async function () {
      this.timeout(50 * 1000)

      await http.api.stop()
      clean(repoTests)
    })

    describe('## http-api spec tests for default config', () => {
      fs.readdirSync(path.join(`${__dirname}/inject/`))
        .forEach((file) => !testsForCustomConfig.includes(file) && require(`./inject/${file}`)(http))
    })
  })
})

'''
'''--- test/http-api/version.js ---
/* eslint-env mocha */
'use strict'

const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create({ exec: 'src/cli/bin.js' })

describe('version endpoint', () => {
  let ipfs = null
  let ipfsd = null
  before(function (done) {
    this.timeout(20 * 1000)
    df.spawn({
      initOptions: { bits: 512 },
      config: {
        Bootstrap: [],
        Discovery: {
          MDNS: {
            Enabled: false
          },
          webRTCStar: {
            Enabled: false
          }
        }
      }
    }, (err, _ipfsd) => {
      expect(err).to.not.exist()
      ipfsd = _ipfsd
      ipfs = ipfsd.api
      done()
    })
  })

  after((done) => ipfsd.stop(done))

  describe('.version', () => {
    it('get the version', (done) => {
      ipfs.version((err, result) => {
        expect(err).to.not.exist()
        expect(result).to.have.a.property('version')
        expect(result).to.have.a.property('commit')
        expect(result).to.have.a.property('repo')
        done()
      })
    })
  })
})

'''
'''--- test/node.js ---
'use strict'

require('./cli')
require('./http-api')
require('./gateway')
require('./core/node.js')

'''
'''--- test/sharness/lib/install-sharness.sh ---
#!/bin/sh
# install-sharness.sh
#
# Copyright (c) 2014 Juan Batiz-Benet
# Copyright (c) 2015 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#
# This script checks that Sharness is installed in:
#
# $(pwd)/$clonedir/$sharnessdir/
#
# where $clonedir and $sharnessdir are configured below.
#
# If Sharness is not installed, this script will clone it
# from $urlprefix (defined below).
#
# If Sharness is not uptodate with $version (defined below),
# this script will fetch and will update the installed
# version to $version.
#

# settings
version=ecba410b0b58400dd6517cfa6594fdac243d9056
urlprefix=https://github.com/chriscool/sharness.git
clonedir=lib
sharnessdir=sharness

if test -f "$clonedir/$sharnessdir/SHARNESS_VERSION_$version"
then
    # There is the right version file. Great, we are done!
    exit 0
fi

die() {
    echo >&2 "$@"
    exit 1
}

checkout_version() {
    git checkout "$version" || die "Could not checkout '$version'"
    rm -f SHARNESS_VERSION_* || die "Could not remove 'SHARNESS_VERSION_*'"
    touch "SHARNESS_VERSION_$version" || die "Could not create 'SHARNESS_VERSION_$version'"
    echo "Sharness version $version is checked out!"
}

if test -d "$clonedir/$sharnessdir/.git"
then
    # We need to update sharness!
    cd "$clonedir/$sharnessdir" || die "Could not cd into '$clonedir/$sharnessdir' directory"
    git fetch || die "Could not fetch to update sharness"
else
    # We need to clone sharness!
    mkdir -p "$clonedir" || die "Could not create '$clonedir' directory"
    cd "$clonedir" || die "Could not cd into '$clonedir' directory"

    git clone "$urlprefix" || die "Could not clone '$urlprefix'"
    cd "$sharnessdir" || die "Could not cd into '$sharnessdir' directory"
fi

checkout_version

'''
'''--- test/sharness/lib/ipfs-test-lib.sh ---
# Generic test functions for ipfs cli tests

# Quote arguments for sh eval
shellquote() {
	_space=''
	for _arg
	do
		# On Mac OS, sed adds a newline character.
		# With a printf wrapper the extra newline is removed.
		printf "$_space'%s'" "$(printf "%s" "$_arg" | sed -e "s/'/'\\\\''/g;")"
		_space=' '
	done
	printf '\n'
}

# Echo the args, run the cmd, and then also fail,
# making sure a test case fails.
test_fsh() {
    echo "> $@"
    eval $(shellquote "$@")
    echo ""
    false
}

# Same as sharness' test_cmp but using test_fsh (to see the output).
# We have to do it twice, so the first diff output doesn't show unless it's
# broken.
test_cmp() {
	diff -q "$@" >/dev/null || test_fsh diff -u "$@"
}

# Same as test_cmp above, but we sort files before comparing them.
test_sort_cmp() {
	sort "$1" >"$1_sorted" &&
	sort "$2" >"$2_sorted" &&
	test_cmp "$1_sorted" "$2_sorted"
}

# Same as test_cmp above, but we standardize directory
# separators before comparing the files.
test_path_cmp() {
	sed -e "s/\\\\/\//g" "$1" >"$1_std" &&
	sed -e "s/\\\\/\//g" "$2" >"$2_std" &&
	test_cmp "$1_std" "$2_std"
}

# Docker

# This takes a Dockerfile, and a build context directory
docker_build() {
    docker build --rm -f "$1" "$2"
}

# This takes an image as argument and writes a docker ID on stdout
docker_run() {
    docker run -d "$1"
}

# This takes a docker ID and a command as arguments
docker_exec() {
    if test "$CIRCLE" = 1
    then
        sudo lxc-attach -n "$(docker inspect --format '{{.Id}}' $1)" -- /bin/bash -c "$2"
    else
	docker exec -t "$1" /bin/bash -c "$2"
    fi
}

# This takes a docker ID as argument
docker_stop() {
    docker stop "$1"
}

# Test whether all the expected lines are included in a file. The file
# can have extra lines.
#
# $1 - Path to file with expected lines.
# $2 - Path to file with actual output.
#
# Examples
#
#   test_expect_success 'foo says hello' '
#       echo hello >expected &&
#       foo >actual &&
#       test_cmp expected actual
#   '
#
# Returns the exit code of the command set by TEST_CMP.
test_includes_lines() {
	sort "$1" >"$1_sorted" &&
	sort "$2" >"$2_sorted" &&
	comm -2 -3 "$1_sorted" "$2_sorted" >"$2_missing" &&
	[ ! -s "$2_missing" ] || test_fsh comm -2 -3 "$1_sorted" "$2_sorted"
}

# Depending on GNU seq availability is not nice.
# Git also has test_seq but it uses Perl.
test_seq() {
	test "$1" -le "$2" || return
	i="$1"
	j="$2"
	while test "$i" -le "$j"
	do
		echo "$i"
		i=$(expr "$i" + 1)
	done
}

'''
'''--- test/sharness/lib/iptb-lib.sh ---
# iptb test framework
#
# Copyright (c) 2014, 2016 Jeromy Johnson, Christian Couder
# MIT Licensed; see the LICENSE file in this repository.

export IPTB_ROOT="$(pwd)/.iptb"

ipfsi() {
	dir="$1"
	shift
	IPFS_PATH="$IPTB_ROOT/$dir" ipfs "$@"
}

check_has_connection() {
	node="$1"
	ipfsi "$node" swarm peers >"swarm_peers_$node" &&
	grep "ipfs" "swarm_peers_$node" >/dev/null
}

startup_cluster() {
	num_nodes="$1"
	bound=$(expr "$num_nodes" - 1)

	test_expect_success "start up nodes" '
		iptb start
	'

	test_expect_success "connect nodes to eachother" '
		iptb connect [1-$bound] 0
	'

	for i in $(test_seq 0 "$bound")
	do
		test_expect_success "node $i is connected" '
			check_has_connection "$i" ||
			test_fsh cat "swarm_peers_$i"
		'
	done
}

'''
'''--- test/sharness/lib/test-lib-hashes.sh ---
# this file defines several useful hashes used across the test codebase.
# thus they can be defined + changed in one place

HASH_WELCOME_DOCS="QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG"
HASH_GATEWAY_ASSETS="QmXB7PLRWH6bCiwrGh2MrBBjNkLv3mY3JdYXCikYZSwLED"
HASH_HELP_PAGE="QmY5heUM5qgRubMDD1og9fhCPA6QdkMp3QCwd4s7gJsyE7"
HASH_EMPTY_DIR="QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn"

'''
'''--- test/sharness/lib/test-lib.sh ---
# Test framework for go-ipfs
#
# Copyright (c) 2014 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#
# We are using sharness (https://github.com/chriscool/sharness)
# which was extracted from the Git test framework.

# add current directory to path, for ipfs tool.
BIN=$(cd .. && echo `pwd`/bin)
PATH=${BIN}:${PATH}

# assert the `ipfs` we're using is the right one.
if test $(which ipfs) != ${BIN}/ipfs; then
	echo >&2 "Cannot find the tests' local ipfs tool."
	echo >&2 "Please check test and ipfs tool installation."
	JS_BIN=$(dirname $(dirname "${BIN}"))"/src/cli/bin.js"
	echo >&2 "For js-ipfs, look for a symlink from '${BIN}/ipfs' to '${JS_BIN}'."
	echo >&2 "Use 'make' or 'make deps' as it should install this symlink."
	exit 1
fi

# set sharness verbosity. we set the env var directly as
# it's too late to pass in --verbose, and --verbose is harder
# to pass through in some cases.
test "$TEST_VERBOSE" = 1 && verbose=t

# source the common hashes first.
. lib/test-lib-hashes.sh

SHARNESS_LIB="lib/sharness/sharness.sh"

. "$SHARNESS_LIB" || {
	echo >&2 "Cannot source: $SHARNESS_LIB"
	echo >&2 "Please check Sharness installation."
	exit 1
}

# Please put go-ipfs specific shell functions below

# grab + output options
test "$TEST_NO_FUSE" != 1 && test_set_prereq FUSE
test "$TEST_EXPENSIVE" = 1 && test_set_prereq EXPENSIVE
test "$TEST_NO_DOCKER" != 1 && type docker >/dev/null 2>&1 && test_set_prereq DOCKER

TEST_OS=$(uname -s | tr [a-z] [A-Z])

# Set a prereq as error messages are often different on Windows/Cygwin
expr "$TEST_OS" : "CYGWIN_NT" >/dev/null || test_set_prereq STD_ERR_MSG

if test "$TEST_VERBOSE" = 1; then
	echo '# TEST_VERBOSE='"$TEST_VERBOSE"
	echo '# TEST_NO_FUSE='"$TEST_NO_FUSE"
	echo '# TEST_EXPENSIVE='"$TEST_EXPENSIVE"
	echo '# TEST_OS='"$TEST_OS"
fi

# source our generic test lib
. ../lib/ipfs-test-lib.sh

# source iptb lib
. ../lib/iptb-lib.sh

test_cmp_repeat_10_sec() {
	for i in $(test_seq 1 100)
	do
		test_cmp "$1" "$2" >/dev/null && return
		go-sleep 100ms
	done
	test_cmp "$1" "$2"
}

test_run_repeat_60_sec() {
	for i in $(test_seq 1 600)
	do
		(test_eval_ "$1") && return
		go-sleep 100ms
	done
	return 1 # failed
}

test_wait_output_n_lines_60_sec() {
	for i in $(test_seq 1 600)
	do
		test $(cat "$1" | wc -l | tr -d " ") -ge $2 && return
		go-sleep 100ms
	done
	actual=$(cat "$1" | wc -l | tr -d " ")
	test_fsh "expected $2 lines of output. got $actual"
}

test_wait_open_tcp_port_10_sec() {
	for i in $(test_seq 1 100)
	do
		# this is not a perfect check, but it's portable.
		# cant count on ss. not installed everywhere.
		# cant count on netstat using : or . as port delim. differ across platforms.
		echo $(netstat -aln | egrep "^tcp.*LISTEN" | egrep "[.:]$1" | wc -l) -gt 0
		if [ $(netstat -aln | egrep "^tcp.*LISTEN" | egrep "[.:]$1" | wc -l) -gt 0 ]; then
			return 0
		fi
		go-sleep 100ms
	done
	return 1
}

# test_config_set helps us make sure _we really did set_ a config value.
# it sets it and then tests it. This became elaborate because ipfs config
# was setting really weird things and am not sure why.
test_config_set() {

	# grab flags (like --bool in "ipfs config --bool")
	test_cfg_flags="" # unset in case.
	test "$#" = 3 && { test_cfg_flags=$1; shift; }

	test_cfg_key=$1
	test_cfg_val=$2

	# when verbose, tell the user what config values are being set
	test_cfg_cmd="ipfs config $test_cfg_flags \"$test_cfg_key\" \"$test_cfg_val\""
	test "$TEST_VERBOSE" = 1 && echo "$test_cfg_cmd"

	# ok try setting the config key/val pair.
	ipfs config $test_cfg_flags "$test_cfg_key" "$test_cfg_val"
	echo "$test_cfg_val" >cfg_set_expected
	ipfs config "$test_cfg_key" >cfg_set_actual
	test_cmp cfg_set_expected cfg_set_actual
}

test_init_ipfs() {

	# we set the Addresses.API config variable.
	# the cli client knows to use it, so only need to set.
	# todo: in the future, use env?

	test_expect_success "ipfs init succeeds" '
		export IPFS_PATH="$(pwd)/.ipfs" &&
		ipfs init -b=1024 > /dev/null
	'

	test_expect_success "prepare config -- mounting and bootstrap rm" '
		mkdir mountdir ipfs ipns &&
		test_config_set Mounts.IPFS "$(pwd)/ipfs" &&
		test_config_set Mounts.IPNS "$(pwd)/ipns" &&
		test_config_set Addresses.API "/ip4/127.0.0.1/tcp/0" &&
		test_config_set Addresses.Gateway "/ip4/127.0.0.1/tcp/0" &&
		test_config_set --json Addresses.Swarm "[
  \"/ip4/0.0.0.0/tcp/0\"
]" &&
		ipfs bootstrap rm --all ||
		test_fsh cat "\"$IPFS_PATH/config\""
	'

}

test_config_ipfs_gateway_writable() {
	test_expect_success "prepare config -- gateway writable" '
		test_config_set --bool Gateway.Writable true ||
		test_fsh cat "\"$IPFS_PATH/config\""
	'
}

test_wait_for_file() {
	loops=$1
	delay=$2
	file=$3
	fwaitc=0
	while ! test -f "$file"
	do
		if test $fwaitc -ge $loops
		then
			echo "Error: timed out waiting for file: $file"
			return 1
		fi

		go-sleep $delay
		fwaitc=`expr $fwaitc + 1`
	done
}

test_set_address_vars() {
	daemon_output="$1"

	test_expect_success "set up address variables" '
		API_MADDR=$(cat "$IPFS_PATH/api") &&
		API_ADDR=$(convert_tcp_maddr $API_MADDR) &&
		API_PORT=$(port_from_maddr $API_MADDR) &&

		GWAY_MADDR=$(sed -n "s/^Gateway (.*) server listening on //p" "$daemon_output") &&
		GWAY_ADDR=$(convert_tcp_maddr $GWAY_MADDR) &&
		GWAY_PORT=$(port_from_maddr $GWAY_MADDR)
	'

	if ipfs swarm addrs local >/dev/null 2>&1; then
		test_expect_success "set swarm address vars" '
		ipfs swarm addrs local > addrs_out &&
			SWARM_MADDR=$(grep "127.0.0.1" addrs_out) &&
			SWARM_PORT=$(port_from_maddr $SWARM_MADDR)
		'
	fi
}

test_launch_ipfs_daemon() {

	args="$@"

	test "$TEST_ULIMIT_PRESET" != 1 && ulimit -n 1024

	test_expect_success "'ipfs daemon' succeeds" '
		ipfs daemon $args >actual_daemon 2>daemon_err &
	'

	# wait for api file to show up
	test_expect_success "api file shows up" '
		test_wait_for_file 20 100ms "$IPFS_PATH/api"
	'

	test_set_address_vars actual_daemon

	# we say the daemon is ready when the API server is ready.
	test_expect_success "'ipfs daemon' is ready" '
		IPFS_PID=$! &&
		pollEndpoint -ep=/version -host=$API_MADDR -v -tout=1s -tries=60 2>poll_apierr > poll_apiout ||
		test_fsh cat actual_daemon || test_fsh cat daemon_err || test_fsh cat poll_apierr || test_fsh cat poll_apiout
	'
}

do_umount() {
    if [ "$(uname -s)" = "Linux" ]; then
	fusermount -u "$1"
    else
	umount "$1"
    fi
}

test_mount_ipfs() {

	# make sure stuff is unmounted first.
	test_expect_success FUSE "'ipfs mount' succeeds" '
		do_umount "$(pwd)/ipfs" || true &&
		do_umount "$(pwd)/ipns" || true &&
		ipfs mount >actual
	'

	test_expect_success FUSE "'ipfs mount' output looks good" '
		echo "IPFS mounted at: $(pwd)/ipfs" >expected &&
		echo "IPNS mounted at: $(pwd)/ipns" >>expected &&
		test_cmp expected actual
	'

}

test_launch_ipfs_daemon_and_mount() {

	test_init_ipfs
	test_launch_ipfs_daemon
	test_mount_ipfs

}

test_kill_repeat_10_sec() {
	# try to shut down once + wait for graceful exit
	kill $1
	for i in $(test_seq 1 100)
	do
		go-sleep 100ms
		! kill -0 $1 2>/dev/null && return
	done

	# if not, try once more, which will skip graceful exit
	kill $1
	go-sleep 1s
	! kill -0 $1 2>/dev/null && return

	# ok, no hope. kill it to prevent it messing with other tests
	kill -9 $1 2>/dev/null
	return 1
}

test_kill_ipfs_daemon() {

	test_expect_success "'ipfs daemon' is still running" '
		kill -0 $IPFS_PID
	'

	test_expect_success "'ipfs daemon' can be killed" '
		test_kill_repeat_10_sec $IPFS_PID
	'
}

test_curl_resp_http_code() {
	curl -I "$1" >curl_output || {
		echo "curl error with url: '$1'"
		echo "curl output was:"
		cat curl_output
		return 1
	}
	shift &&
	RESP=$(head -1 curl_output) &&
	while test "$#" -gt 0
	do
		expr "$RESP" : "$1" >/dev/null && return
		shift
	done
	echo "curl response didn't match!"
	echo "curl response was: '$RESP'"
	echo "curl output was:"
	cat curl_output
	return 1
}

test_must_be_empty() {
	if test -s "$1"
	then
		echo "'$1' is not empty, it contains:"
		cat "$1"
		return 1
	fi
}

test_should_contain() {
	test "$#" = 2 || error "bug in the test script: not 2 parameters to test_should_contain"
	if ! grep -q "$1" "$2"
	then
		echo "'$2' does not contain '$1', it contains:"
		cat "$2"
		return 1
	fi
}

test_str_contains() {
	find=$1
	shift
	echo "$@" | egrep "\b$find\b" >/dev/null
}

disk_usage() {
    # normalize du across systems
    case $(uname -s) in
        Linux)
            DU="du -sb"
            ;;
        FreeBSD)
            DU="du -s -A -B 1"
            ;;
        Darwin | DragonFly | *)
            DU="du -s"
            ;;
    esac
        $DU "$1" | awk "{print \$1}"
}

# output a file's permission in human readable format
generic_stat() {
    # normalize stat across systems
    case $(uname -s) in
        Linux)
            _STAT="stat -c %A"
            ;;
        FreeBSD | Darwin | DragonFly)
            _STAT="stat -f %Sp"
            ;;
    esac
    $_STAT "$1"
}

test_check_peerid() {
	peeridlen=$(echo "$1" | tr -dC "[:alnum:]" | wc -c | tr -d " ") &&
	test "$peeridlen" = "46" || {
		echo "Bad peerid '$1' with len '$peeridlen'"
		return 1
	}
}

convert_tcp_maddr() {
	echo $1 | awk -F'/' '{ printf "%s:%s", $3, $5 }'
}

port_from_maddr() {
	echo $1 | awk -F'/' '{ print $NF }'
}

'''
'''--- test/sharness/t0000-sharness.sh ---
#!/bin/sh

test_description="Show basic features of Sharness"

. ./lib/sharness/sharness.sh

test_expect_success "Success is reported like this" "
    echo hello world | grep hello
"

test_expect_success "Commands are chained this way" "
    test x = 'x' &&
    test 2 -gt 1 &&
    echo success
"

return_42() {
    echo "Will return soon"
    return 42
}

test_expect_success "You can test for a specific exit code" "
    test_expect_code 42 return_42
"

test_expect_failure "We expect this to fail" "
    test 1 = 2
"

test_done

# vi: set ft=sh :

'''
'''--- test/sharness/t0010-basic-commands.sh ---
#!/bin/sh
#
# Copyright (c) 2014 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#

test_description="Test installation and some basic commands"

. lib/test-lib.sh

test_expect_success "current dir is writable" '
	echo "It works!" > test.txt
'

test_expect_success "ipfs version succeeds" '
	ipfs version > version.txt
'

test_expect_success "ipfs version shows js-ipfs" '
	grep "js-ipfs" version.txt > /dev/null ||
	test_fsh cat version.txt
'

test_expect_success "ipfs version output looks good" '
	egrep "^js-ipfs version: [0-9]+\.[0-9]+\.[0-9]" version.txt >/dev/null ||
	test_fsh cat version.txt
'

test_expect_success "ipfs version --all has all required fields" '
	ipfs version --all > version_all.txt &&
	grep "js-ipfs version" version_all.txt &&
  grep "Repo version" version_all.txt &&
	grep "System version" version_all.txt &&
	grep "Node.js version" version_all.txt
'

test_expect_success "ipfs help succeeds" '
	ipfs help > help.txt
'

# test_expect_success "ipfs help output looks good" '
# 	egrep -i "^Usage" help.txt > /dev/null &&
# 	egrep "ipfs .* <command>" help.txt >/dev/null ||
# 	test_fsh cat help.txt
# '

test_expect_success "'ipfs commands' succeeds" '
	ipfs commands > commands.txt
'

test_expect_success "'ipfs commands' output looks good" '
	grep "add" commands.txt &&
	grep "daemon" commands.txt &&
	grep "version" commands.txt
'

# test_expect_success "All commands accept --help" '
# 	while read -r cmd
# 	do
# 		echo "running: $cmd --help"
# 		$cmd --help </dev/null >/dev/null || return
# 	done <commands.txt
# '

# test_expect_success "'ipfs commands --flags' succeeds" '
# 	ipfs commands --flags >commands.txt
# '

# test_expect_success "'ipfs commands --flags' output looks good" '
# 	grep "ipfs pin add --recursive / ipfs pin add -r" commands.txt &&
# 	grep "ipfs id --format / ipfs id -f" commands.txt &&
# 	grep "ipfs repo gc --quiet / ipfs repo gc -q" commands.txt
# '

test_done

'''
'''--- test/sharness/t0015-basic-sh-functions.sh ---
#!/bin/sh
#
# Copyright (c) 2015 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#

test_description="Test some basic shell functions"

. lib/test-lib.sh

test_expect_success "shellquote works with simple stuff" '
	var=$(shellquote one two)
'

test_expect_success "shellquote output looks good" '
	test "$var" = "'\''one'\'' '\''two'\''" ||
	test_fsh echo "var is \"$var\" instead of \"'\''one'\'' '\''two'\''\""
'

# The following two printf statements are equivalent:
# printf "%s\n" \''"foo\
# bar'
# printf "\047\042\146\157\157\134\012\142\141\162\012"
# We use the second one to simplify quoting.

test_expect_success "shellquote works with complex printf" '
	eval "$(shellquote printf "\047\042\146\157\157\134\012\142\141\162\012")" >actual
'

test_expect_success "shellquote output looks good" '
	printf "\047\042\146\157\157\134\012\142\141\162\012" >expected &&
	test_cmp expected actual
'

test_expect_success "shellquote works with many different bytes" '
	bytes_sans_NUL=$(
		printf "\001\002\003\004\005\006\007\010\011\013\014\015\016\017\020\021\022\023\024\025\026\027\030\031\032\033\034\035\036\037\040\041\042\043\044%%\046\047\050\051\052\053\054\055\056\057\060\061\062\063\064\065\066\067\070\071\072\073\074\075\076\077\100\101\102\103\104\105\106\107\110\111\112\113\114\115\116\117\120\121\122\123\124\125\126\127\130\131\132\133\134\135\136\137\140\141\142\143\144\145\146\147\150\151\152\153\154\155\156\157\160\161\162\163\164\165\166\167\170\171\172\173\174\175\176\177\200\201\202\203\204\205\206\207\210\211\212\213\214\215\216\217\220\221\222\223\224\225\226\227\230\231\232\233\234\235\236\237\240\241\242\243\244\245\246\247\250\251\252\253\254\255\256\257\260\261\262\263\264\265\266\267\270\271\272\273\274\275\276\277\300\301\302\303\304\305\306\307\310\311\312\313\314\315\316\317\320\321\322\323\324\325\326\327\330\331\332\333\334\335\336\337\340\341\342\343\344\345\346\347\350\351\352\353\354\355\356\357\360\361\362\363\364\365\366\367\370\371\372\373\374\375\376\377"
	) &&
	eval "$(shellquote printf "%s" "$bytes_sans_NUL")" >actual
'

test_expect_success "shellquote output looks good" '
	printf "%s" "$bytes_sans_NUL" >expected &&
	test_cmp expected actual
'

test_done

'''
'''--- test/sharness/t0020-init.sh ---
#!/bin/sh
#
# Copyright (c) 2014 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#

test_description="Test init command"

. lib/test-lib.sh

# test that ipfs fails to init if IPFS_PATH isnt writeable
test_expect_success "create dir and change perms succeeds" '
	export IPFS_PATH="$(pwd)/.badipfs" &&
	mkdir "$IPFS_PATH" &&
	chmod 000 "$IPFS_PATH"
'

test_expect_success "ipfs init fails" '
	test_must_fail ipfs init 2> init_fail_out
'

# Under Windows/Cygwin the error message is different,
# so we use the STD_ERR_MSG prereq.
if test_have_prereq STD_ERR_MSG; then
	init_err_msg="Error: failed to take lock at $IPFS_PATH: permission denied"
else
	init_err_msg="Error: mkdir $IPFS_PATH: The system cannot find the path specified."
fi

init_js_err_msg="Error: EACCES: permission denied, stat '$IPFS_PATH/version'"

# test_expect_success "ipfs init output looks good" '
# 	echo "$init_js_err_msg" > init_fail_exp &&
# 	test_cmp init_fail_exp init_fail_out
# '

test_expect_success "cleanup dir with bad perms" '
	chmod 775 "$IPFS_PATH" &&
	rmdir "$IPFS_PATH"
'

# test no repo error message
# this applies to `ipfs add sth`, `ipfs refs <hash>`
test_expect_success "ipfs cat fails" '
    export IPFS_PATH="$(pwd)/.ipfs" &&
    test_must_fail ipfs cat Qmaa4Rw81a3a1VEx4LxB7HADUAXvZFhCoRdBzsMZyZmqHD 2> cat_fail_out
'

test_done

'''
'''--- test/sharness/t0022-init-default.sh ---
#!/bin/sh
#
# Copyright (c) 2014 Christian Couder
# MIT Licensed; see the LICENSE file in this repository.
#

test_description="Test init command with default config"

. lib/test-lib.sh

cfg_key="Addresses.API"
cfg_val="/ip4/0.0.0.0/tcp/5001"

# test that init succeeds
test_expect_success "ipfs init succeeds" '
	export IPFS_PATH="$(pwd)/.ipfs" &&
	echo "IPFS_PATH: \"$IPFS_PATH\"" &&
	BITS="2048" &&
	ipfs init --bits="$BITS" >actual_init ||
	test_fsh cat actual_init
'

test_expect_success ".ipfs/config has been created" '
	test -f "$IPFS_PATH"/config ||
	test_fsh ls -al .ipfs
'

test_expect_success "ipfs config succeeds" '
	ipfs config $cfg_flags "$cfg_key" "$cfg_val"
'

test_expect_success "ipfs read config succeeds" '
    IPFS_DEFAULT_CONFIG=$(cat "$IPFS_PATH"/config)
'

test_expect_success "clean up ipfs dir" '
	rm -rf "$IPFS_PATH"
'

test_expect_success "ipfs init default config succeeds" '
	echo $IPFS_DEFAULT_CONFIG | ipfs init - >actual_init ||
	test_fsh cat actual_init
'

test_done

'''
'''--- test/utils/clean.js ---
'use strict'

const rimraf = require('rimraf')
const fs = require('fs')

module.exports = (dir) => {
  try {
    fs.accessSync(dir)
  } catch (err) {
    // Does not exist so all good
    return
  }

  rimraf.sync(dir)
}

'''
'''--- test/utils/create-repo-browser.js ---
/* global self */
'use strict'

const IPFSRepo = require('ipfs-repo')
const hat = require('hat')

const idb = self.indexedDB ||
  self.mozIndexedDB ||
  self.webkitIndexedDB ||
  self.msIndexedDB

function createTempRepo (repoPath) {
  repoPath = repoPath || '/ipfs-' + hat()

  const repo = new IPFSRepo(repoPath)

  repo.teardown = (done) => {
    repo.close(() => {
      idb.deleteDatabase(repoPath)
      idb.deleteDatabase(repoPath + '/blocks')
      done()
    })
  }

  return repo
}

module.exports = createTempRepo

'''
'''--- test/utils/create-repo-nodejs.js ---
'use strict'

const IPFSRepo = require('ipfs-repo')
const clean = require('./clean')
const os = require('os')
const path = require('path')
const hat = require('hat')
const series = require('async/series')

function createTempRepo (repoPath) {
  repoPath = repoPath || path.join(os.tmpdir(), '/ipfs-test-' + hat())

  const repo = new IPFSRepo(repoPath)

  repo.teardown = (done) => {
    series([
      // ignore err, might have been closed already
      (cb) => repo.close(() => cb()),
      (cb) => {
        clean(repoPath)
        cb()
      }
    ], done)
  }

  return repo
}

module.exports = createTempRepo

'''
'''--- test/utils/dns-fetch-stub.js ---
'use strict'

// Create a fetch stub with a fall through to the provided fetch implementation
// if the URL doesn't match https://ipfs.io/api/v0/dns?arg=ipfs.io.
module.exports = (fetch) => {
  return function () {
    if (arguments[0].startsWith('https://ipfs.io/api/v0/dns?arg=ipfs.io')) {
      return Promise.resolve({
        json: () => Promise.resolve({
          Path: '/ipfs/QmYNQJoKGNHTpPxCBPh9KkDpaExgd2duMa3aF6ytMpHdao'
        })
      })
    }
    return fetch.apply(this, arguments)
  }
}

'''
'''--- test/utils/expect-timeout.js ---
'use strict'

/**
 * Resolve if @param promise hangs for at least @param ms, throw otherwise
 * @param  {Promise} promise promise that you expect to hang
 * @param  {Number} ms       millis to wait
 * @return {Promise}
 */
module.exports = (promise, ms) => {
  return Promise.race([
    promise.then((out) => {
      throw new Error('Expected Promise to timeout but it was successful.')
    }),
    new Promise((resolve, reject) => setTimeout(resolve, ms))
  ])
}

'''
'''--- test/utils/interface-common-factory.js ---
/* eslint-env mocha */
'use strict'

const each = require('async/each')
const IPFSFactory = require('ipfsd-ctl')
const ipfsClient = require('ipfs-http-client')
const IPFS = require('../../src')

function createFactory (options) {
  options = options || {}

  options.factoryOptions = options.factoryOptions || { type: 'proc', exec: IPFS }
  options.spawnOptions = options.spawnOptions || {
    initOptions: { bits: 512 },
    config: {
      Bootstrap: [],
      Discovery: {
        MDNS: {
          Enabled: false
        },
        webRTCStar: {
          Enabled: false
        }
      }
    }
  }

  if (options.factoryOptions.type !== 'proc') {
    options.factoryOptions.IpfsClient = options.factoryOptions.IpfsClient || ipfsClient
  }

  const ipfsFactory = IPFSFactory.create(options.factoryOptions)

  return function createCommon () {
    const nodes = []
    let setup, teardown

    if (options.createSetup) {
      setup = options.createSetup({ ipfsFactory, nodes }, options)
    } else {
      setup = (callback) => {
        callback(null, {
          spawnNode (cb) {
            ipfsFactory.spawn(options.spawnOptions, (err, _ipfsd) => {
              if (err) {
                return cb(err)
              }

              nodes.push(_ipfsd)
              cb(null, _ipfsd.api)
            })
          }
        })
      }
    }

    if (options.createTeardown) {
      teardown = options.createTeardown({ ipfsFactory, nodes }, options)
    } else {
      teardown = callback => each(nodes, (node, cb) => node.stop(cb), callback)
    }

    return { setup, teardown }
  }
}

exports.create = createFactory

'''
'''--- test/utils/ipfs-exec.js ---
'use strict'

const execa = require('execa')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const _ = require('lodash')

// This is our new test utility to easily check and execute ipfs cli commands.
//
// The top level export is a function that can be passed a `repoPath`
// and optional `opts` to customize the execution of the commands.
// This function returns the actual executer, which consists of
// `ipfs('get <hash>')` and `ipfs.fail('get <hash>')`
// The first one executes and asserts that the command ran successfully
// and returns a promise which is resolved to `stdout` of the command.
// The `.fail` variation asserts that the command exited with `Code > 0`
// and returns a promise that resolves to `stderr`.
module.exports = (repoPath, opts) => {
  const env = _.clone(process.env)
  env.IPFS_PATH = repoPath

  const config = Object.assign({}, {
    stripEof: false,
    env: env,
    timeout: 60 * 1000
  }, opts)

  const exec = (args) => execa(`${process.cwd()}/src/cli/bin.js`, args, config)
  const execRaw = (args) => execa(`${process.cwd()}/src/cli/bin.js`, args, Object.assign({}, config, {
    encoding: null
  }))

  const execute = (exec, args) => {
    if (args.length === 1) {
      args = args[0].split(' ')
    }

    const cp = exec(args)
    const res = cp.then((res) => {
      // We can't escape the os.tmpdir warning due to:
      // https://github.com/shelljs/shelljs/blob/master/src/tempdir.js#L43
      // expect(res.stderr).to.be.eql('')
      return res.stdout
    })

    res.kill = cp.kill.bind(cp)
    res.stdin = cp.stdin
    res.stdout = cp.stdout
    res.stderr = cp.stderr

    return res
  }

  function ipfs () {
    return execute(exec, Array.from(arguments))
  }

  // Will return buffers instead of strings
  ipfs.raw = function () {
    return execute(execRaw, Array.from(arguments))
  }

  /**
   * Expect the command passed as @param arguments to fail.
   * @return {Promise} Resolves if the command passed as @param arguments fails,
   *                    rejects if it was successful.
   */
  ipfs.fail = function ipfsFail () {
    let args = Array.from(arguments)
    let caught = false
    if (args.length === 1) {
      args = args[0].split(' ')
    }

    return exec(args)
      .catch(err => {
        caught = true
        expect(err).to.exist()
      })
      .then(() => {
        if (!caught) {
          throw new Error(`jsipfs expected to fail during command: jsipfs ${args.join(' ')}`)
        }
      })
  }

  return ipfs
}

'''
'''--- test/utils/mock-preload-node.js ---
/* eslint-env browser */
'use strict'

const http = require('http')
const toUri = require('multiaddr-to-uri')
const URL = require('url').URL || self.URL
const errCode = require('err-code')

const defaultPort = 1138
const defaultAddr = `/dnsaddr/localhost/tcp/${defaultPort}`

module.exports.defaultAddr = defaultAddr

// Create a mock preload IPFS node with a gateway that'll respond 200 to a
// request for /api/v0/refs?arg=*. It remembers the preload CIDs it has been
// called with, and you can ask it for them and also clear them by issuing a
// GET/DELETE request to /cids.
module.exports.createNode = () => {
  let cids = []

  const server = http.createServer((req, res) => {
    res.setHeader('Access-Control-Allow-Origin', '*')
    res.setHeader('Access-Control-Request-Method', '*')
    res.setHeader('Access-Control-Allow-Methods', 'OPTIONS, GET, DELETE')
    res.setHeader('Access-Control-Allow-Headers', '*')
    if (req.method === 'OPTIONS') {
      res.writeHead(200)
      res.end()
      return
    }

    if (req.url.startsWith('/api/v0/refs')) {
      const arg = new URL(`https://ipfs.io${req.url}`).searchParams.get('arg')
      cids = cids.concat(arg)
    } else if (req.method === 'DELETE' && req.url === '/cids') {
      res.statusCode = 204
      cids = []
    } else if (req.method === 'GET' && req.url === '/cids') {
      res.setHeader('Content-Type', 'application/json')
      res.write(JSON.stringify(cids))
    } else {
      res.statusCode = 500
    }

    res.end()
  })

  server.start = (opts, cb) => {
    if (typeof opts === 'function') {
      cb = opts
      opts = {}
    }
    return server.listen(Object.assign({ port: defaultPort }, opts), cb)
  }

  server.stop = (cb) => server.close(cb)

  return server
}

function parseMultiaddr (addr) {
  if (!(addr.endsWith('http') || addr.endsWith('https'))) {
    addr = addr + '/http'
  }
  return new URL(toUri(addr))
}

// Get the stored preload CIDs for the server at `addr`
const getPreloadCids = (addr, cb) => {
  if (typeof addr === 'function') {
    cb = addr
    addr = defaultAddr
  }

  addr = addr || defaultAddr

  const { protocol, hostname, port } = parseMultiaddr(addr)

  const req = http.get({ protocol, hostname, port, path: '/cids' }, (res) => {
    if (res.statusCode !== 200) {
      res.resume()
      return cb(new Error('failed to get preloaded CIDs from mock preload node'))
    }

    let data = ''

    res.on('error', cb)
    res.on('data', chunk => { data += chunk })

    res.on('end', () => {
      let obj
      try {
        obj = JSON.parse(data)
      } catch (err) {
        return cb(err)
      }
      cb(null, obj)
    })
  })

  req.on('error', cb)
}

module.exports.getPreloadCids = getPreloadCids

// Clear the stored preload URLs for the server at `addr`
module.exports.clearPreloadCids = (addr, cb) => {
  if (typeof addr === 'function') {
    cb = addr
    addr = defaultAddr
  }

  addr = addr || defaultAddr

  const { protocol, hostname, port } = parseMultiaddr(addr)

  const req = http.request({
    method: 'DELETE',
    protocol,
    hostname,
    port,
    path: '/cids'
  }, (res) => {
    res.resume()

    if (res.statusCode !== 204) {
      return cb(new Error('failed to clear CIDs from mock preload node'))
    }

    cb()
  })

  req.on('error', cb)
  req.end()
}

// Wait for the passed CIDs to appear in the CID list from the preload node
module.exports.waitForCids = (cids, opts, cb) => {
  if (typeof opts === 'function') {
    cb = opts
    opts = {}
  }

  opts = opts || {}
  opts.timeout = opts.timeout || 1000

  cids = Array.isArray(cids) ? cids : [cids]

  const start = Date.now()

  const checkForCid = () => {
    getPreloadCids(opts.addr, (err, preloadCids) => {
      if (err) return cb(err)

      // See if our cached preloadCids includes all the cids we're looking for.
      const { missing, duplicates } = cids.reduce((results, cid) => {
        const count = preloadCids.filter(preloadedCid => preloadedCid === cid).length
        if (count === 0) {
          results.missing.push(cid)
        } else if (count > 1) {
          results.duplicates.push(cid)
        }
        return results
      }, { missing: [], duplicates: [] })

      if (duplicates.length) {
        return cb(errCode(new Error(`Multiple occurances of ${duplicates} found`), 'ERR_DUPLICATE'))
      }

      if (missing.length === 0) {
        return cb()
      }

      if (Date.now() > start + opts.timeout) {
        return cb(errCode(new Error('Timed out waiting for CIDs to be preloaded'), 'ERR_TIMEOUT'))
      }

      setTimeout(checkForCid, 5)
    })
  }

  checkForCid()
}

'''
'''--- test/utils/on-and-off.js ---
/* eslint-env mocha */
'use strict'

const hat = require('hat')
const chai = require('chai')
const dirtyChai = require('dirty-chai')
const expect = chai.expect
chai.use(dirtyChai)

const ipfsExec = require('../utils/ipfs-exec')
const clean = require('../utils/clean')
const os = require('os')

const DaemonFactory = require('ipfsd-ctl')
const df = DaemonFactory.create()

function off (tests) {
  describe('daemon off (directly to core)', () => {
    let thing = {}
    let repoPath

    before(function () {
      this.timeout(60 * 1000)

      repoPath = os.tmpdir() + '/ipfs-' + hat()
      thing.ipfs = ipfsExec(repoPath)
      thing.ipfs.repoPath = repoPath
      return thing.ipfs('init')
    })

    after(function (done) {
      this.timeout(20 * 1000)
      clean(repoPath)
      setImmediate(done)
    })

    tests(thing)
  })
}

function on (tests) {
  describe('daemon on (through http-api)', () => {
    let thing = {}

    let ipfsd
    before(function (done) {
      // CI takes longer to instantiate the daemon,
      // so we need to increase the timeout for the
      // before step
      this.timeout(60 * 1000)

      df.spawn({
        type: 'js',
        exec: `./src/cli/bin.js`,
        initOptions: { bits: 512 },
        config: { Bootstrap: [] }
      }, (err, node) => {
        expect(err).to.not.exist()
        ipfsd = node
        thing.ipfs = ipfsExec(node.repoPath)
        thing.ipfs.repoPath = node.repoPath
        done()
      })
    })

    after(function (done) {
      this.timeout(15 * 1000)
      ipfsd.stop(done)
    })

    tests(thing)
  })
}

/*
 * CLI Utility to run the tests offline (daemon off) and online (daemon on)
 */
exports = module.exports = (tests) => {
  off(tests)
  on(tests)
}

exports.off = off
exports.on = on

'''
'''--- test/utils/platforms.js ---
'use strict'

const os = require('os')
const current = os.platform()

module.exports = {
  isWindows: () => {
    return current === 'win32'
  },
  isMacOS: () => {
    return current === 'darwin'
  },
  isLinux: () => {
    return current === 'linux'
  }
}

'''
'''--- test/utils/wait-for.js ---
'use strict'

// Wait for async function `test` to callback(null, true) or timeout after
// options.timeout milliseconds.
module.exports = function waitFor (test, options, callback) {
  if (typeof options === 'function') {
    callback = options
    options = {}
  }

  options = options || {}
  options.timeout = options.timeout || 5000
  options.interval = options.interval || 0
  options.name = options.name || 'event'

  const start = Date.now()

  const check = () => {
    test((err, arrived) => {
      if (err) {
        return callback(err)
      }

      if (arrived) {
        return callback()
      }

      if (Date.now() > start + options.timeout) {
        return callback(new Error(`Timed out waiting for ${options.name}`))
      }

      setTimeout(check, options.interval)
    })
  }

  check()
}

module.exports.promises = async (test, options) => {
  options = Object.assign({ timeout: 5000, interval: 0, name: 'event' }, options)
  const start = Date.now()

  while (true) {
    const arrived = await test()

    if (arrived) {
      return
    }

    if (Date.now() > start + options.timeout) {
      throw new Error(`Timed out waiting for ${options.name}`)
    }

    await new Promise(resolve => setTimeout(resolve, options.interval))
  }
}

'''