*GitHub Repository "near/near-state-indexer"*

'''--- .buildkite/pipeline.yml ---
steps:
  - command: "source ~/.cargo/env && cargo fmt --all -- --check"
    label: "Formatter"
    
  - command: "source ~/.cargo/env && cargo clippy"
    label: "Linter"
    
  - command: "source ~/.cargo/env && cargo test"
    label: "Tests"

  - command: "fossa init && fossa analyze --server-scan && fossa test"
    label: "Fossa"
    branches: "master"

'''
'''--- .fossa.yml ---
# Generated by FOSSA CLI (https://github.com/fossas/fossa-cli)
# Visit https://fossa.com to learn more

version: 2
cli:
  server: https://app.fossa.com
  fetcher: custom
  project: git@github.com:near/near-indexer-for-explorer.git
analyze:
  modules:
  - name: Cargo.lock
    type: cargo
    target: .
    path: .

'''
'''--- .github/ISSUE_TEMPLATE/BOUNTY.yml ---
name: "Simple Bounty"
description: "Use this template to create a HEROES Simple Bounty via Github bot"
title: "Bounty: "
labels: ["bounty"]
assignees: heroes-bot-test
body:
  - type: markdown
    attributes:
      value: |
        Hi! Let's set up your bounty! Please don't change the template - @heroes-bot-test won't be able to help you.

  - type: dropdown
    id: type
    attributes:
      label: What talent are you looking for?
      options:
        - Marketing
        - Development
        - Design
        - Other
        - Content
        - Research
        - Audit

  - type: textarea
    id: description
    attributes:
      label: What you need to be done?

  - type: dropdown
    id: tags
    attributes:
      label: Tags
      description: Add tags that match the topic of the work
      multiple: true
      options:
        - API
        - Blockchain
        - Community
        - CSS
        - DAO
        - dApp
        - DeFi
        - Design
        - Documentation
        - HTML
        - Javascript
        - NFT
        - React
        - Rust
        - Smart contract
        - Typescript
        - UI/UX
        - web3
        - Translation
        - Illustration
        - Branding
        - Copywriting
        - Blogging
        - Editing
        - Video Creation
        - Social Media
        - Graphic Design
        - Transcription
        - Product Design
        - Artificial Intelligence
        - Quality Assurance
        - Risk Assessment
        - Security Audit
        - Bug Bounty
        - Code Review
        - Blockchain Security
        - Smart Contract Testing
        - Penetration Testing
        - Vulnerability Assessment
        - BOS
        - News
        - Hackathon
        - NEARCON2023
        - NEARWEEK

  - type: input
    id: deadline
    attributes:
      label: Deadline
      description: "Set a deadline for your bounty. Please enter the date in format: DD.MM.YYYY"
      placeholder: "19.05.2027"

  - type: dropdown
    id: currencyType
    attributes:
      label: Currency
      description: What is the currency you want to pay?
      options:
        - USDC.e
        - USDT.e
        - DAI
        - wNEAR
        - USDt
        - XP
        - marmaj
        - NEKO
        - JUMP
        - USDC
        - NEARVIDIA
      default: 0
    validations:
      required: true

  - type: input
    id: currencyAmount
    attributes:
      label: Amount
      description: How much it will be cost?

  - type: markdown
    attributes:
      value: "## Advanced settings"

  - type: checkboxes
    id: kyc
    attributes:
      label: KYC
      description: "Use HEROES' KYC Verification, only applicants who passed HEROES' KYC can apply and work on this bounty!"
      options:
        - label: Use KYC Verification

  - type: markdown
    attributes:
      value: |
        ### This cannot be changed once the bounty is live!

'''
'''--- CHANGELOG.md ---
# Changelog

## 0.10.3

* Upgrade `nearcore` to 1.22.0
* Add [NFT events](https://nomicon.io/Standards/NonFungibleToken/Event.html) support: `assets__non_fungible_token_events` table stores the information about NFT `mint`, `transfer`, `burn` events

## 0.10.2

- Change the retry logic. Make indexer fail with error if is has retried for 5 min
- Upgrade `nearcore` to 1.22.0

## 0.10.1

* Upgrade `nearcore` to 1.21.1

## 0.10.0

* Drop `--allow-missing-relations-in-first-blocks` flag
* Introduce `--non-strict-mode` which does the same as `--allow-missing-relations-in-first-blocks` flag did but endlessly
* Add `--stop-after-number-of-blocks <count>` flag to plan Indexer for Explorer to stop once it indexed the provided `<count>` of blocks. May be useful for debug or maintenance purposes.

## Breaking changes

* The flag `--allow-missing-relations-in-first-blocks` is not available anymore in favor of `--non-strict-mode` flag

## 0.9.3

* Escape `args_json` on the fly to avoid null-byte issues
* Upgrade to NEAR Indexer Framework `0.10.0`
* Refactor the storing Accounts and AccessKeys from genesis to optimize memory usage
* Improve logging to better understand what Indexer for Explorer is doing on the start

## 0.9.2 (hotfix)

* Change `receiver_id` field type to `String` to be compatible with `nearcore` `AccessKeyPermissionView` struct (it caused problems during AccessKey serialization)

## 0.9.1

* Upgrade `nearcore` to 1.21.0 (rc1)

## 0.9.0 (nearcore dependency contains bug)

* Upgrade `nearcore` to 1.21.0

## Breaking changes

* `init` command has changed according to changes in `nearcore`:
  - `download` argument has been replaced with `download_config` and `download_genesis`
  - `boot_nodes` argument was added
  - `download_config_url` was added
* `AccountId` from `near-primitives` was replaced with separate crate `near-account-id` and it is no longer an alias for `String`
  - All the fields related to an account id have type `near_account_id::AccountId`

## 0.8.0

* Background calculation of circulating supply and storing it to DB
* Improvements on some tables (add indexes, simplify sorting etc.)

## 0.7.1

* Update nearcore version to 1.20.0-rc.2

## 0.7.0

* Handle null-bytes in `AddKey` actions
* Update nearcore version to 1.20.0

## Breaking change

`init_configs` function from nearcore has been extended with additional optional parameter `max_gas_burnt_view`. We've extended NEAR Indexer for Explorer `InitConfigArgs`

## 0.6.9

* Add `--concurrency` parameter to adjust the number of simultaneously running asynchronous adapters

## 0.6.8

* Update NEAR Indexer Framework version to 0.9.2 (with optimized delayed receipts tracking system)

## 0.6.7

* Remove duplicates from `account_changes` table by fixing unique index ([see issue #74](https://github.com/near/near-indexer-for-explorer/issues/74))

## 0.6.6 (hotfix)

* Upgrade `nearcore` to 1.19.1 (hotfix)

## 0.6.5

* Update NEAR Indexer Framework version to 0.9.1 (previous contained a bug with processing delayed local receipts)

## 0.6.4 (contains bug)

* Fix the overwriting of `created_by_receipt_id` for implicit accounts that may confuse users ([see issue #68 for ref](https://github.com/near/near-indexer-for-explorer/issues/68))

## 0.6.3

* Denormalize table `action_receipt_actions` in order to speed up some queries by avoid
  additional joins
* Extend `extract_action_type_and_value_from_action_view` function to try to parse base64 encoded args
  as a JSON object to put them decoded in the function call args `action_receipt_actions.args` additionally

## 0.6.2

* Upgrade `nearcore` dependency to exclude recent updates to runtime which caused a bug ([see for ref](https://github.com/near/nearcore/releases/tag/1.19.0-rc.2))

## 0.6.1

* Upgrade `nearcore` to support newer protocol version (45)

## 0.6.0

* Upgrade `nearcore` to get NEAR Indexer Framework 0.9.0
* Corresponding changes into adapters according to changes in `StreamerMessage` structure
* NEAR Indexer for Explorer now uses stable Rust (`rust-toolchain` has been updated accordingly) 

## 0.5.0

* Tweak `sync-from-interruption` mode to start syncing from N blocks earlier that actual interruption

## 0.4.0

* Update `nearcore` dependency
* Update underlying dependencies to correspond `nearcore`

**The way of starting `actix` runtime has changes**

## 0.3.0

* Migrate from `tokio-diesel` to `actix-diesel` (patched by @frol)

## 0.2.3

* Upgrade `nearcore` dependency
* Upgrade some external dependencies (`actix`, `tokio`)

## 0.2.2

* Fill `deleted_by_receipt_id` if `access_key` on owner account deletion

## 0.2.1

* Add `access_key` on transfer to implicit account action
* Upgrade `nearcore` dependency

'''
'''--- CONTRIBUTING.md ---
Thank you for considering contributing to the NEAR Indexer for Explorer!

We welcome all external contributions. This document outlines the process of contributing to NEAR Indexer for Explorer.
For contributing to other repositories, see `CONTRIBUTING.md` in the corresponding repository.
For non-technical contributions, such as e.g. content or events, see [this document](https://docs.nearprotocol.com/docs/contribution/contribution-overview).

# Pull Requests and Issues

All the contributions to NEAR Indexer for Explorer happen via Pull Requests. To create a Pull Request, fork NEAR Indexer for Explorer repository on GitHub, create a new branch, do the work there, and then send the PR via GitHub interface.

The PRs should always be against the `master` branch.

The exact process depends on the particular contribution you are making.

## Typos or small fixes

If you see an obvious typo, or an obvious bug that can be fixed with a small change, in the code or documentation, feel free to submit the pull request that fixes it without opening an issue.

### Submitting the PR

Once your change is ready, prepare the PR. The PR can contain any number of commits, but when it is merged, they will all get squashed. The commit names and descriptions can be arbitrary, but the name and the description of the PR must follow the following template:

```
<type>: <name>

<description>

Test plan
---------
<test plan>
```

Where `type` is `fix` for fixes, `feat` for features, `refactor` for changes that primarily reorganize code, `doc` for changes that primarily change documentation or comments, and `test` for changes that primarily introduce new tests. The type is case sensitive.

The `test plan` should describe in detail what tests are presented, and what cases they cover.

### After the PR is submitted

1. We have a CI process configured to run all the sanity tests on each PR. If the CI fails on your PR, you need to fix it before it will be reviewed.
2. Once the CI passes, you should expect the first feedback to appear within 48 hours. The reviewers will first review your tests, and make sure that they can convince themselves the test coverage is adequate before they even look into the change, so make sure you tested all the corner cases.
3. Once you address all the comments, and your PR is accepted, we will take care of merging it.

## Proposing new ideas and features

If you want to propose an idea or a feature and work on it, create a new issue in the `near-indexer-for-Explorer` repository.

You should expect someone to comment on the issue within 48 hours after it is created.

## Code Style

We enforce formatting with rustfmt, so your code should be formatted with `cargo fmt` and checked with `cargo clippy` to pass CI. Additionally, we extend those default rules with some extras.

### Imports Ordering and Grouping

We use the following order to group our imports (use statements):

1. standard Rust library imports (e.g. `std::sync::Arc`)
2. external crates (e.g. `tokio::time`)
3. near-* crates (e.g. `near_indexer::near_primitives::types`)
4. local crate modules (e.g. `crate::db`)
5. local modules (e.g. `self::access_keys`)
6. `mod` statements

Separate each group with an empty line and maintain alphabetical order inside of each group (it is done automatically by rustfmt).

Here is an artificial example:

```rust
use std::path::PathBuf;
use std::sync::Arc;

use tokio::time;

use near_indexer::near_primitives;

pub use crate::db::AccessKey;

use self::db;

mod access_keys;
mod utils;
```

### Use Statements

#### Wildcards

Try to avoid wildcard imports on a module level as they are hard to reason about. Note, it is fine to use them in a limited scope, e.g. inside a function, macro, etc.

#### Module Imports vs Leaf Item Imports

To improve readability, try to avoid importing individual structs, functions, etc unless they are nonambiguous.

We prefer this:

```rust
use near_indexer::near_primitives;

fn my_func() {
    let my_account = near_primitives::types::Account::from("test.near");
}
```

over:

```rust
use near_indexer::near_primitives::types::Account;

fn my_func() {
    let my_account = Account::from("test.near");
}
```

The rationale behind this is that there are plenty of different `Account` types in various contexts (e.g. DB schema, NEAR account, local crate struct).

## Checklist before submitting PR

We created a list of things that should be surely fixed before the review. It will save your time and the time of the reviewer. Here it is:

1. Automatic checks
    - `cargo fmt`
    - `cargo clippy`
2. Code structure
    - Is the code self-explanatory? Can you rewrite it to be so? If not, can you add some comments to make the life of the future you easier? Consider using links to other materials if it's suitable
    - Take care of function parameter types and return values. Do something meaningful if you know Rust; otherwise, simply pass parameters by reference (&)
    - Use as narrow scope as you can. At least change `pub` to `pub(crate)`
3. Imports
    - Imports should be frugal. Read about it [above](https://github.com/near/near-indexer-for-explorer/blob/master/CONTRIBUTING.md#module-imports-vs-leaf-item-imports)
    - Use relative import (`super`) if you use the same module
    - Check [imports ordering](https://github.com/near/near-indexer-for-explorer/blob/master/CONTRIBUTING.md#imports-ordering-and-grouping)
4. Types
    - Use `str` instead of `String` if it's possible
    - Use wrapper type instead of a raw one. E.g. `AccountId` instead of `str`, `Duration` instead of `u64`
5. Wording
    - Get rid of short name versions, we do not pay for symbols. `account_id` is better than `acc`
    - Spend time on the naming of variables and functions. It does matter. Look around, the codebase should help you
    - Spend time on the wording in logging. Does it explain what is going on? Does it help to solve the issue?
    - Use Grammarly for docstrings
6. "I just learn Rust and I do weird things"
    - `x.to_string().as_str()` -> `&x.to_string()`
    - `for x in items.iter()` -> `for x in &items`
    - Use `{:?}` if you need to log the value and `{}` does not work
    - Do not use `return` if you can, it's Rust, the last statement is the result for the function
7. Do not forget to re-check everything again before sending the code

(...to be continued)

# Setting up the environment

`nearcore` uses nightly Rust features, so you will need nightly rust installed. See [this document](https://doc.rust-lang.org/1.2.0/book/nightly-rust.html) for details. NEAR Indexer for Explorer follows `rust-toolchain` specified by `nearcore`.

Majority of NEAR developers use CLion with Rust plugin as their primary IDE.

We also had success with VSCode with rust-analyzer, see the steps for installation [here](https://commonwealth.im/near/proposal/discussion/338-remote-development-with-vscode-and-rustanalyzer).

Some of us use VIM with [rust.vim](https://github.com/rust-lang/rust.vim) and [rusty-tags](https://github.com/dan-t/rusty-tags). It has fewer features than CLion or VSCode, but overall provides a usable setting.

Refer to [this document](https://docs.nearprotocol.com/docs/contribution/nearcore) for details on setting up your environment.

'''
'''--- Cargo.toml ---
[package]
name = "state-indexer"
version = "0.1.0"
authors = ["Near Inc <hello@nearprotocol.com>"]
edition = "2021"

[dependencies]
actix = "=0.11.0-beta.2"
actix-rt = "=2.2.0"  # remove it once actix is upgraded to 0.11+
actix-web = "=4.0.0-beta.6"
actix-http = "=3.0.0-beta.6"
actix-tls = "=3.0.0-beta.5"
actix_derive = "=0.6.0-beta.1"
anyhow = "1.0.43"
base64 = "0.11"
bigdecimal = "=0.1.0"
borsh = "0.9.1"
chrono = "0.4.19"
clap = "3.0.0-beta.5"
dotenv = "0.15.0"
futures = "0.3.5"
hex = "0.4"
itertools = "0.10.3"
# syn version conflict, replace with crates.io version once released
near-sdk = { git = "https://github.com/near/near-sdk-rs", rev="03487c184d37b0382dd9bd41c57466acad58fc1f" }
num-traits = "0.2.11"
openssl-probe = { version = "0.1.2" }
r2d2 = "0.8.8"
serde = { version = "1", features = ["derive"] }
serde_json = "1.0.55"
redis = { version = "0.20", features = ["tokio-comp"] }
tokio = { version = "1.1", features = ["sync", "time"] }
tokio-stream = { version = "0.1" }
tracing = "0.1.13"
tracing-subscriber = "0.2.4"
uint = { version = "0.8.3", default-features = false }

near-indexer = { git = "https://github.com/near/nearcore", tag="1.25.0-rc.3" }
near-crypto = { git = "https://github.com/near/nearcore", tag="1.25.0-rc.3" }
near-client = { git = "https://github.com/near/nearcore", tag="1.25.0-rc.3" }

'''
'''--- README.md ---
# NEAR State Indexer

NEAR State Indexer is built on top of [NEAR Indexer microframework](https://github.com/near/nearcore/tree/master/chain/indexer) to watch the network and store all the state changes in the Redis database.
It can be consumed by https://github.com/vgrichina/fast-near to run NEAR RPC service.

## Self-hosting

Before you proceed, make sure you have the following software installed:
* [rustup](https://rustup.rs/) or Rust version that is mentioned in `rust-toolchain` file in the root of [nearcore](https://github.com/nearprotocol/nearcore) project.

Clone this repository and open the project folder

```bash
$ git clone git@github.com:near/near-indexer-for-explorer.git
$ cd near-indexer-for-explorer
```

You need to provide database credentials in `.env` file like below (replace Redis connection string as needed):

```bash
$ echo "REDIS_URL=redis://127.0.0.1/" > .env
```

To connect the specific chain you need to have necessary configs, you can generate it as follows:

```bash
$ cargo run --release -- --home-dir ~/.near/testnet init --chain-id testnet --download-config
```

The above code will download the official genesis config and generate necessary configs. You can replace `testnet` in the command above to different network ID (`betanet`, `mainnet`).

**NB!** According to changes in `nearcore` config generation we don't fill all the necessary fields in the config file.
While this issue is open https://github.com/nearprotocol/nearcore/issues/3156 you need to download config you want and replace the generated one manually.
 - [testnet config.json](https://s3-us-west-1.amazonaws.com/build.nearprotocol.com/nearcore-deploy/testnet/config.json)
 - [betanet config.json](https://s3-us-west-1.amazonaws.com/build.nearprotocol.com/nearcore-deploy/betanet/config.json)
 - [mainnet config.json](https://s3-us-west-1.amazonaws.com/build.nearprotocol.com/nearcore-deploy/mainnet/config.json)

Configs for the specified network are in the `--home-dir` provided folder. We need to ensure that NEAR State Indexer follows
all the necessary shards, so `"tracked_shards"` parameters in `~/.near/testnet/config.json` needs to be configured properly.
For example, with a single shared network, you just add the shard #0 to the list:

```
...
"tracked_shards": [0],
...
```

## Running NEAR State Indexer:

Command to run NEAR State Indexer have to contain sync mode.

You can choose NEAR State Indexer sync mode by setting what to stream:
 - `sync-from-latest` - start indexing blocks from the latest finalized block
 - `sync-from-interruption --delta <number_of_blocks>` - start indexing blocks from the block NEAR Indexer was interrupted last time but earlier for `<number_of_blocks>` if provided
 - `sync-from-block --height <block_height>` - start indexing blocks from the specific block height

Optionally you can tell Indexer to store data from genesis (Accounts and Access Keys) by adding key `--store-genesis` to the `run` command.

NEAR State Indexer works in strict mode by default, but you can disable it for specific amount of blocks. The strict mode means that every piece of data
will be retried to store to database in case of error. Errors may occur when the parent piece of data is still processed but the child piece is already
trying to be stored. So Indexer keeps retrying to store the data until success. However if you're running Indexer not from the genesis it is possible that you
really miss some of parent data and it'll be impossible to store child one, so you can disable strict mode for 1000 blocks to ensure you've passed the strong
relation data area and you're running Indexer where it is impossible to loose any piece of data.

To disable strict mode you need to provide:

```
--non-strict-mode
```

Sometimes you may want to index block while sync process is happening, by default an indexer node is waiting for full sync to complete but you can enable indexing while the node is syncing by passing `--stream-while-syncing`

By default NEAR State Indexer processes only a single block at a time. You can adjust this with the `--concurrency` argument (when the blocks are mostly empty, it is fine to go with as many as 100 blocks of concurrency).

So final command to run NEAR State Indexer can look like:

```bash
$ cargo run --release -- --home-dir ~/.near/testnet run --store-genesis --stream-while-syncing --non-strict-mode --stop-after-number-of-blocks 1000 --concurrency 1 sync-from-latest
```

After the network is synced, you should see logs of every block height currently received by NEAR State Indexer.

## Syncing

Whenever you run NEAR State Indexer for any network except localnet you'll need to sync with the network. This is required because it's a natural behavior of `nearcore` node and NEAR State Indexer is a wrapper for the regular `nearcore` node. In order to work and index the data your node must be synced with the network. This process can take a while, so we suggest to download a fresh backup of the `data` folder and put it in you `--home-dir` of your choice (by default it is `~/.near`)

Running your NEAR State Indexer node on top of a backup data will reduce the time of syncing process because your node will download only missing data and it will take reasonable time.

All the backups can be downloaded from the public S3 bucket which contains latest daily snapshots:

* [Recent 5-epoch Mainnet data folder](https://near-protocol-public.s3.ca-central-1.amazonaws.com/backups/mainnet/rpc/data.tar)
* [Recent 5-epoch Testnet data folder](https://near-protocol-public.s3.ca-central-1.amazonaws.com/backups/testnet/rpc/data.tar)

## Running NEAR State Indexer as archival node

It's not necessary but in order to index everything in the network it is better to do it from the genesis. `nearcore` node is running in non-archival mode by default. That means that the node keeps data only for [5 last epochs](https://docs.near.org/docs/concepts/epoch). In order to index data from the genesis we need to turn the node in archival mode.

To do it we need to update `config.json` located in `--home-dir` or your choice (by default it is `~/.near`).

Find next keys in the config and update them as following:

```json
{
  ...
  "archive": true,
  "tracked_shards": [0],
  ...
}
```

The syncing process in archival mode can take a lot of time, so it's better to download a backup provided by NEAR and put it in your `data` folder. After that your node will need to sync only missing data and it should take reasonable time.

All the backups can be downloaded from the public S3 bucket which contains latest daily snapshots:

* [Archival Mainnet data folder](https://near-protocol-public.s3.ca-central-1.amazonaws.com/backups/mainnet/archive/data.tar)
* [Archival Testnet data folder](https://near-protocol-public.s3.ca-central-1.amazonaws.com/backups/testnet/archive/data.tar)

See https://docs.near.org/docs/roles/integrator/exchange-integration#running-an-archival-node for reference

## Local debugging

If you want to play with the code locally, it's better not to copy existing mainnet/testnet (it requires LOTS of memory), but to have your own small example.
Go through steps [above](https://github.com/near/near-indexer-for-explorer#self-hosting) until (by not including) `init` command.

Then use `init` command with different arguments,

```bash
$ cargo run --release -- --home-dir ~/.near/localnet init --chain-id localnet
```

Edit `~/.near/localnet/config.json` by adding tracking shards and archiving option (see [example above](https://github.com/near/near-indexer-for-explorer#running-near-indexer-for-explorer-as-archival-node)).

```bash
$ cargo run -- --home-dir ~/.near/localnet run --store-genesis sync-from-latest
```

Congrats, the blocks are being produced right now!
There should be some lines in the DB.
Now, we need to generate some activity to add new examples.

```bash
$ npm i -g near-cli
$ NEAR_ENV=local near create-account awesome.test.near --initialBalance 30 --masterAccount test.near --keyPath=~/.near/localnet/validator_key.json
$ NEAR_ENV=local near send test.near awesome.test.near 5
```

All available commands are [here](https://github.com/near/near-cli#near-cli-command-line-interface).

You can stop and re-run the example at any time.
Blocks will continue producing from the last state.

## Troubleshooting

When operating normally, you should see "INFO indexer_for_explorer: Block height ..." messages in the logs.

### The node is fully synced and running, but no indexer messages and no transactions in the database (not indexing)

Make sure the blocks you want to save exist on the node. Check them via [JSON RPC](https://docs.near.org/docs/api/rpc#block-details):

```
curl http://127.0.0.1:3030/ -X POST --header 'Content-type: application/json' --data '{"jsonrpc": "2.0", "id": "dontcare", "method": "block", "params": {"block_id": 9820214}}'
```

NOTE: Block #9820214 is the first block after genesis block (#9820210) on Mainnet.

If it returns an error that the block does not exist or missing, it means that your node does not have the necessary data. Your options here are to start from the blocks that are recorded on the node or start an archival node (see above) and make sure you have the full network history (either use a backup or let the node sync from scratch (it is quite slow, so backup is recommended))

'''
'''--- TROBLESHOOTING.md ---
# Troubleshooting or NEAR Indexer for Explorer handbook

This document tries to describe how to handle known issues that may occur during the work process of NEAR Indexer for Explorer instance.

*It is assumed that the indexer instance is running with the `systemd` and the service is called `indexer`*

We use this `systemd` config:

```bash
[Unit]
Description=Indexer Service
StartLimitIntervalSec=500
StartLimitBurst=5

[Service]
User=ubuntu
Group=ubuntu
ExecStart=/home/ubuntu/indexer run --stream-while-syncing sync-from-interruption --delta 500
MemoryMax=90%
Restart=always
RestartSec=5s
EnvironmentFile=/home/ubuntu/.env
LimitAS=infinity
LimitRSS=infinity
LimitCORE=infinity
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
After=google-startup-scripts.service
```

---

In case of any issues, you need to check the node logs. Indexer is running as a `systemd` service, so you can check the logs with the command:

```bash
$ journalctl --follow --unit indexer
```

Normal logs look similar to the screenshot

![normal logs](./docs/handbook_1.png)

During the normal working process indexer prints `INFO indexer_explorer: Block height N`

If it does not print anything or prints some debug structures instead of normal logs it probably means something went wrong. See Common issues section.

## Common issues

In case of any of the following issues, we stop the indexer `systemd` service to take manual control over indexer with the commands listed in the relevant sections below.

```bash
$ sudo service indexer stop
```

To handle any of the following issues, we’ll be running the indexer manually in a `tmux` on behalf of the `ubuntu` user.

```bash
$ sudo su ubuntu
$ cd ~
$ tmux
```

All of the following section assumes you’re running the command in `tmux`

### If it stuck

You need to record somewhere (a good place is https://github.com/near/near-indexer-for-explorer/issues) the block in which the indexer has stuck for further proper investigation.

Example of not fine indexer logs:

![logs with issues](./docs/handbook_2.png)

For now, we want to try to “skip” that block. In order to achieve this, we would run the indexer syncing process from the block height number following for the one where we have stuck.

If the stuck block height is 47961813

```bash
$ env RUST_LOG=”near=info” ./indexer run --stream-while-syncing sync-from-block --height 47961814 2>&1 | tee -a indexer.log
```

**Note** that this might be stuck as well, usually, nearest blocks have related data that can lead to getting stuck. So you might need to brute-force the block height to start syncing. Edit the above command by increasing the block height by 1 or by 10 until the indexer starts printing normal logs. If you cannot find that block in the nearest 100 blocks, see the next section.

### Non-strict-mode or If it stuck and we want to skip some blocks in order to continue properly

Similar to the case “If it stuck” and we want to skip the weird blocks in order to make the indexer work properly and investigate the root cause later.

You need to record somewhere (a good place is https://github.com/near/near-indexer-for-explorer/issues) the block in which the indexer has stuck for further proper investigation.

Example of not fine indexer logs:

![logs with issues](./docs/handbook_2.png)

For now, we want to try to “skip” that block. In order to achieve this, we would run the indexer syncing process from the block height number following for the one where we have stuck in non-strict-mode.

**A few words about non-strict-mode**

In this mode, the indexer will ignore some relations to keep working and not failing if it is unable to store because of missing relative data. This will skip `account_state_changes`, `access_keys` and will retry storing receipts at most 4 times.

We’re going to start from the stuck block and skip the next 100 (you can adjust it). After 100 blocks we will rerun the indexer in regular mode.

If the stuck block height is 47961813

```bash
$ env RUST_LOG=”near=info” ./indexer run --stream-while-syncing --non-strict-mode --stop-after-number-of-blocks 100 sync-from-block --height 47961813 2>&1 | tee -a indexer.log
```

Once 100 blocks are indexed in `non-strict-mode` the indexer will stop. We need to run it in regular mode and wait for indexer team to investigate the root cause.

```bash
$ env RUST_LOG=”near=info” ./indexer run --stream-while-syncing sync-from-interruption --delta 0 2>&1 | tee -a indexer-regular.log
```

### How to catch the tip of the network if it lagged

If the logs are normal but the latest printed block heights are delayed more than 30 minutes from the latest block height from the finality or the indexer was stuck for too long (see If it stuck section) we might need to catch up with the network.
Having at least two indexer nodes we need to run one of them in non-strict-mode from the latest block

```bash
$ env RUST_LOG=”near=info” ./indexer run --stream-while-syncing --non-strict-mode sync-from-latest 2>&1 | tee -a indexer.log
```

This will force the indexer to sync with the network ignoring some of the data completely. It’ll ignore `account_state_changes`, `access_keys` and might ignore some receipts.

On the other node, you need to perform actions from the “If it stuck” section

## Enabling verbose logs

NEAR Indexer for Explorer is configured to respect `RUST_LOG` environment variable. In order to enable or change the log level of any of the underlying module you can use it.

For example, to enable `info` level logs for the underlying `near` you can run the indexer like:

```bash
$ env RUST_LOG="near=info" ./indexer run ...
```

### `--verbose` equivalent from the nearcore

```bash
env RUST_LOG="cranelift_codegen=warn,cranelift_codegen=warn,h2=warn,trust_dns_resolver=warn,trust_dns_proto=warn,near=debug,indexer=debug,near_indexer_for_explorer=debug" ./indexer run ...
```

'''
'''--- rust-toolchain.toml ---
[toolchain]
# This specifies the version of Rust we use to build.
# Individual crates in the workspace may support a lower version, as indicated by `rust-version` field in each crate's `Cargo.toml`.
# The version specified below, should be at least as high as the maximum `rust-version` within the workspace.
channel = "1.58.1"
components = [ "rustfmt" ]
targets = [ "wasm32-unknown-unknown" ]

'''
'''--- rustfmt.toml ---
fn_args_layout = "Compressed"
max_width = 120
fn_call_width = 120

'''
'''--- src/configs.rs ---
use std::convert::TryFrom;

use clap::Parser;

/// NEAR Indexer for Explorer
/// Watches for stream of blocks from the chain
#[derive(Parser, Debug)]
#[clap(
    version,
    author,
    about,
    setting(clap::AppSettings::DisableHelpSubcommand),
    setting(clap::AppSettings::PropagateVersion),
    setting(clap::AppSettings::NextLineHelp)
)]
pub(crate) struct Opts {
    /// Sets a custom config dir. Defaults to ~/.near/
    #[clap(short, long)]
    pub home_dir: Option<std::path::PathBuf>,
    #[clap(subcommand)]
    pub subcmd: SubCommand,
}

#[derive(Parser, Debug)]
pub(crate) enum SubCommand {
    /// Run NEAR Indexer Example. Start observe the network
    Run(RunArgs),
    /// Initialize necessary configs
    Init(InitConfigArgs),
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct RunArgs {
    /// Store initial data from genesis like Accounts, AccessKeys
    #[clap(long)]
    pub store_genesis: bool,
    /// Force streaming while node is syncing
    #[clap(long)]
    pub stream_while_syncing: bool,
    /// Switches indexer to non-strict mode (skips Receipts without parent Transaction hash, stops storing AccountChanges and AccessKeys)
    #[clap(long)]
    pub non_strict_mode: bool,
    /// Stops indexer completely after indexing the provided number of blocks
    #[clap(long, short)]
    pub stop_after_number_of_blocks: Option<std::num::NonZeroUsize>,
    /// Sets the concurrency for indexing. Note: concurrency (set to 2+) may lead to warnings due to tight constraints between transactions and receipts (those will get resolved eventually, but unless it is the second pass of indexing, concurrency won't help at the moment).
    #[clap(long, default_value = "1")]
    pub concurrency: std::num::NonZeroU16,
    #[clap(subcommand)]
    pub sync_mode: SyncModeSubCommand,
}

#[allow(clippy::enum_variant_names)] // we want commands to be more explicit
#[derive(Parser, Debug, Clone)]
pub(crate) enum SyncModeSubCommand {
    /// continue from the block Indexer was interrupted
    SyncFromInterruption(InterruptionArgs),
    /// start from the newest block after node finishes syncing
    SyncFromLatest,
    /// start from specified block height
    SyncFromBlock(BlockArgs),
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct InterruptionArgs {
    /// start indexing this number of blocks earlier than the actual interruption happened
    #[clap(long, default_value = "0")]
    pub delta: u64,
}

#[derive(Parser, Debug, Clone)]
pub(crate) struct BlockArgs {
    /// block height for block sync mode
    #[clap(long)]
    pub height: u64,
}

impl TryFrom<SyncModeSubCommand> for near_indexer::SyncModeEnum {
    type Error = &'static str;

    fn try_from(sync_mode: SyncModeSubCommand) -> Result<Self, Self::Error> {
        match sync_mode {
            SyncModeSubCommand::SyncFromInterruption(_) => Err("Unable to convert SyncFromInterruption variant because it has additional parameter which is not acceptable by near_indexer::SyncModeEnum::SyncFromInterruption"),
            SyncModeSubCommand::SyncFromLatest => Ok(Self::LatestSynced),
            SyncModeSubCommand::SyncFromBlock(args) => Ok(Self::BlockHeight(args.height)),
        }
    }
}

#[derive(Parser, Debug)]
pub(crate) struct InitConfigArgs {
    /// chain/network id (localnet, testnet, devnet, betanet)
    #[clap(short, long)]
    pub chain_id: Option<String>,
    /// Account ID for the validator key
    #[clap(long)]
    pub account_id: Option<String>,
    /// Specify private key generated from seed (TESTING ONLY)
    #[clap(long)]
    pub test_seed: Option<String>,
    /// Number of shards to initialize the chain with
    #[clap(short, long, default_value = "1")]
    pub num_shards: u64,
    /// Makes block production fast (TESTING ONLY)
    #[clap(short, long)]
    pub fast: bool,
    /// Genesis file to use when initialize testnet (including downloading)
    #[clap(short, long)]
    pub genesis: Option<String>,
    #[clap(short, long)]
    /// Download the verified NEAR config file automatically.
    #[clap(long)]
    pub download_config: bool,
    #[clap(long)]
    pub download_config_url: Option<String>,
    /// Download the verified NEAR genesis file automatically.
    #[clap(long)]
    pub download_genesis: bool,
    /// Specify a custom download URL for the genesis-file.
    #[clap(long)]
    pub download_genesis_url: Option<String>,
    /// Customize max_gas_burnt_view runtime limit.  If not specified, value
    /// from genesis configuration will be taken.
    #[clap(long)]
    pub max_gas_burnt_view: Option<u64>,
    /// Initialize boots nodes in <node_key>@<ip_addr> format seperated by commas
    /// to bootstrap the network and store them in config.json
    #[clap(long)]
    pub boot_nodes: Option<String>,
}

'''
'''--- src/main.rs ---
use clap::Parser;
use std::convert::TryFrom;
use std::env;

use borsh::BorshSerialize;
use futures::StreamExt;
use redis::aio::Connection;
use redis::AsyncCommands;
use tokio::sync::mpsc;
use tracing::{info, warn};
use tracing_subscriber::EnvFilter;

use crate::configs::{Opts, SubCommand};
use near_indexer::near_primitives;
use near_primitives::account::Account;
use near_primitives::views::StateChangeValueView;

mod configs;
#[macro_use]
mod retriable;

// Categories for logging
const INDEXER_FOR_EXPLORER: &str = "indexer_for_explorer";

async fn get_redis_connection() -> anyhow::Result<Connection> {
    let redis_url = env::var("REDIS_URL").unwrap_or_else(|_| "redis://127.0.0.1/".to_string());
    let redis_client = redis::Client::open(redis_url)?;
    Ok(redis_client.get_async_connection().await?)
}

async fn handle_message(streamer_message: near_indexer::StreamerMessage, _strict_mode: bool) -> anyhow::Result<()> {
    let mut redis_connection = get_redis_connection().await?;

    let block_height = streamer_message.block.header.height;
    let block_hash = streamer_message.block.header.hash;

    for state_change in streamer_message.state_changes {
        match state_change.value {
            StateChangeValueView::DataUpdate { account_id, key, value } => {
                println!("DataUpdate {}", account_id);
                let redis_key = [account_id.as_ref().as_bytes(), b":", key.as_ref()].concat();
                redis_connection
                    .zadd([b"data:", redis_key.as_slice()].concat(), block_hash.as_ref(), block_height)
                    .await?;
                let value_vec: &[u8] = value.as_ref();
                redis_connection
                    .set([b"data-value:", redis_key.as_slice(), b":", block_hash.as_ref()].concat(), value_vec)
                    .await?;
            }
            StateChangeValueView::DataDeletion { account_id, key } => {
                println!("DataDeletion {}", account_id);
                let redis_key = [b"data:", account_id.as_ref().as_bytes(), b":", key.as_ref()].concat();
                redis_connection
                    .zadd(redis_key, block_hash.as_ref(), block_height)
                    .await?;
            }
            StateChangeValueView::ContractCodeUpdate { account_id, code } => {
                println!("ContractCodeUpdate {}", account_id);
                let redis_key = [b"code:", account_id.as_ref().as_bytes()].concat();
                redis_connection
                    .zadd(redis_key.as_slice(), block_hash.as_ref(), block_height)
                    .await?;
                let value_vec: &[u8] = code.as_ref();
                redis_connection
                    .set([redis_key.as_slice(), b":", block_hash.as_ref()].concat(), value_vec)
                    .await?;
            }
            StateChangeValueView::ContractCodeDeletion { account_id } => {
                println!("ContractCodeDeletion {}", account_id);
                let redis_key = [b"code:", account_id.as_ref().as_bytes()].concat();
                redis_connection
                    .zadd(redis_key, block_hash.as_ref(), block_height)
                    .await?;
            }
            StateChangeValueView::AccountUpdate { account_id, account } => {
                println!("AccountUpdate {}", account_id);
                let redis_key = account_id.as_ref().as_bytes();
                redis_connection
                    .zadd([b"account:", redis_key].concat(), block_hash.as_ref(), block_height)
                    .await?;
                let value = Account::from(account).try_to_vec().unwrap();
                redis_connection
                    .set([b"account-data:", redis_key, b":", block_hash.as_ref()].concat(), value)
                    .await?;
            }
            StateChangeValueView::AccountDeletion { account_id } => {
                println!("AccountDeletion {}", account_id);
                redis_connection
                    .zadd([b"account:", account_id.as_ref().as_bytes()].concat(), block_hash.as_ref(), block_height)
                    .await?;
            }
            _ => {}
        }
    }

    let disable_block_height_update = env::var("DISABLE_BLOCK_INDEX_UPDATE").unwrap_or_else(|_| "false".to_string());
    if !(disable_block_height_update == "true" || disable_block_height_update == "yes") {
        println!("latest_block_height {}", block_height);
        redis_connection.set(b"latest_block_height", block_height).await?;
    }

    Ok(())
}

async fn listen_blocks(
    stream: mpsc::Receiver<near_indexer::StreamerMessage>, concurrency: std::num::NonZeroU16, strict_mode: bool,
    stop_after_number_of_blocks: Option<std::num::NonZeroUsize>,
) {
    if let Some(stop_after_n_blocks) = stop_after_number_of_blocks {
        warn!(target: crate::INDEXER_FOR_EXPLORER, "Indexer will stop after indexing {} blocks", stop_after_n_blocks,);
    }
    if !strict_mode {
        warn!(target: crate::INDEXER_FOR_EXPLORER, "Indexer is starting in NON-STRICT mode",);
    }
    info!(target: crate::INDEXER_FOR_EXPLORER, "Stream has started");
    let handle_messages = tokio_stream::wrappers::ReceiverStream::new(stream).map(|streamer_message| async {
        info!(target: crate::INDEXER_FOR_EXPLORER, "Block height {}", &streamer_message.block.header.height);
        handle_message(streamer_message, strict_mode)
            .await
            .map_err(|e| println!("error {}", e))
    });
    let mut handle_messages = if let Some(stop_after_n_blocks) = stop_after_number_of_blocks {
        handle_messages.take(stop_after_n_blocks.get()).boxed_local()
    } else {
        handle_messages.boxed_local()
    }
    .buffer_unordered(usize::from(concurrency.get()));

    while let Some(_handled_message) = handle_messages.next().await {}
    // Graceful shutdown
    info!(target: crate::INDEXER_FOR_EXPLORER, "Indexer will be shutdown gracefully in 7 seconds...",);
    drop(handle_messages);
    tokio::time::sleep(std::time::Duration::from_secs(7)).await;
}

/// Takes `home_dir` and `RunArgs` to build proper IndexerConfig and returns it
async fn construct_near_indexer_config(
    home_dir: std::path::PathBuf, args: configs::RunArgs,
) -> near_indexer::IndexerConfig {
    // Extract await mode to avoid duplication
    info!(target: crate::INDEXER_FOR_EXPLORER, "construct_near_indexer_config");
    let sync_mode: near_indexer::SyncModeEnum = match args.sync_mode {
        configs::SyncModeSubCommand::SyncFromInterruption(interruption_args) if interruption_args.delta == 1 => {
            info!(target: crate::INDEXER_FOR_EXPLORER, "got from interruption");
            // If delta is 0 we just return IndexerConfig with sync_mode FromInterruption
            // without any changes
            near_indexer::SyncModeEnum::FromInterruption
        }
        configs::SyncModeSubCommand::SyncFromInterruption(interruption_args) => {
            info!(target: crate::INDEXER_FOR_EXPLORER, "got from interruption");
            info!(target: crate::INDEXER_FOR_EXPLORER, "delta is non zero, calculating...");

            let mut redis_connection = get_redis_connection().await.expect("error connecting to Redis");
            redis_connection
                .get(b"latest_block_height")
                .await
                .ok()
                .map(|latest_block_height: Option<u64>| {
                    if let Some(height) = latest_block_height {
                        near_indexer::SyncModeEnum::BlockHeight(height.saturating_sub(interruption_args.delta))
                    } else {
                        near_indexer::SyncModeEnum::FromInterruption
                    }
                })
                .unwrap_or_else(|| near_indexer::SyncModeEnum::FromInterruption)
        }
        configs::SyncModeSubCommand::SyncFromBlock(block_args) => {
            near_indexer::SyncModeEnum::BlockHeight(block_args.height)
        }
        configs::SyncModeSubCommand::SyncFromLatest => near_indexer::SyncModeEnum::LatestSynced,
    };

    near_indexer::IndexerConfig {
        home_dir,
        sync_mode,
        await_for_node_synced: if args.stream_while_syncing {
            near_indexer::AwaitForNodeSyncedEnum::StreamWhileSyncing
        } else {
            near_indexer::AwaitForNodeSyncedEnum::WaitForFullSync
        },
    }
}

fn main() {
    // We use it to automatically search the for root certificates to perform HTTPS calls
    // (sending telemetry and downloading genesis)
    openssl_probe::init_ssl_cert_env_vars();

    let mut env_filter = EnvFilter::new(
        "tokio_reactor=info,near=info,near=error,stats=info,telemetry=info,indexer=info,indexer_for_explorer=info,aggregated=info",
    );

    if let Ok(rust_log) = std::env::var("RUST_LOG") {
        if !rust_log.is_empty() {
            for directive in rust_log.split(',').filter_map(|s| match s.parse() {
                Ok(directive) => Some(directive),
                Err(err) => {
                    eprintln!("Ignoring directive `{}`: {}", s, err);
                    None
                }
            }) {
                env_filter = env_filter.add_directive(directive);
            }
        }
    }

    tracing_subscriber::fmt::Subscriber::builder()
        .with_env_filter(env_filter)
        .with_writer(std::io::stderr)
        .init();

    let opts: Opts = Opts::parse();

    let home_dir = opts.home_dir.unwrap_or_else(near_indexer::get_default_home);

    match opts.subcmd {
        SubCommand::Run(args) => {
            tracing::info!(
                target: crate::INDEXER_FOR_EXPLORER,
                "NEAR Indexer for Explorer v{} starting...",
                env!("CARGO_PKG_VERSION")
            );

            let system = actix::System::new();
            system.block_on(async move {
                let indexer_config = construct_near_indexer_config(home_dir, args.clone()).await;
                let indexer = near_indexer::Indexer::new(indexer_config).unwrap();

                // Regular indexer process starts here
                let stream = indexer.streamer();

                listen_blocks(stream, args.concurrency, !args.non_strict_mode, args.stop_after_number_of_blocks).await;

                actix::System::current().stop();
            });
            system.run().unwrap();
        }
        SubCommand::Init(config) => near_indexer::init_configs(
            &home_dir,
            config.chain_id.as_ref().map(AsRef::as_ref),
            config.account_id.map(|account_id_string| {
                near_indexer::near_primitives::types::AccountId::try_from(account_id_string)
                    .expect("Received accound_id is not valid")
            }),
            config.test_seed.as_ref().map(AsRef::as_ref),
            config.num_shards,
            config.fast,
            config.genesis.as_ref().map(AsRef::as_ref),
            config.download_genesis,
            config.download_genesis_url.as_ref().map(AsRef::as_ref),
            config.download_config,
            config.download_config_url.as_ref().map(AsRef::as_ref),
            config.boot_nodes.as_ref().map(AsRef::as_ref),
            config.max_gas_burnt_view,
        )
        .expect("Failed to initiate config"),
    }
}

'''
'''--- src/retriable.rs ---
#[macro_export]
macro_rules! await_retry_or_panic {
    ($query: expr, $number_of_retries: expr, $error_message: expr, $debug_structs: expr $(, $is_error_handled:expr)? $(,)?) => {
        {
            let mut interval = crate::INTERVAL;
            let mut retry_attempt = 0usize;
            loop {
                if retry_attempt == $number_of_retries {
                    return Err(
                        anyhow::anyhow!(
                            "Failed to perform query to database after {} attempts. Stop trying.",
                            $number_of_retries
                        )
                    );
                }
                retry_attempt += 1;

                match $query.await {
                    Ok(res) => break Some(res),
                    Err(async_error) => {
                        $(if $is_error_handled(&async_error).await {
                            break None;
                        })?

                        tracing::error!(
                             target: crate::INDEXER_FOR_EXPLORER,
                             "Error occurred during {}: \n{:#?} \n{:#?} \n Retrying in {} milliseconds...",
                             async_error,
                             &$error_message,
                             &$debug_structs,
                             interval.as_millis(),
                         );
                        tokio::time::sleep(interval).await;
                        if interval < crate::MAX_DELAY_TIME {
                            interval *= 2;
                        }
                    }
                }
            }
        }
    };
}

'''