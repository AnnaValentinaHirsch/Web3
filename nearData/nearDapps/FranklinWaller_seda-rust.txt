*GitHub Repository "FranklinWaller/seda-rust"*

'''--- .devcontainer/devcontainer.json ---
{
	"name": "seda-rust",
	"dockerComposeFile": "docker-compose.yml",
	"service": "vscode",
	"workspaceFolder": "/workspace",
	// Comment the next line if you want to keep your containers running after VS Code shuts down.
	"shutdownAction": "stopCompose",
	"features": {
		"ghcr.io/devcontainers/features/common-utils:1": {
			"installZsh": "true",
			"username": "vscode",
			"uid": "1000",
			"gid": "1000",
			"upgradePackages": "true"
		},
		"ghcr.io/devcontainers/features/rust:1": "latest",
		"ghcr.io/devcontainers/features/git:1": {
			"version": "latest",
			"ppa": "false"
		}
	},
	"overrideFeatureInstallOrder": [
		"ghcr.io/devcontainers/features/common-utils"
	],
	// Allow dubious ownership in GIT repository
	"postStartCommand": "git config --global --add safe.directory $PWD",
	// Configure tool-specific properties.
	"customizations": {
		// Configure properties specific to VS Code.
		"vscode": {
			// Set *default* container specific settings.json values on container create.
			"settings": {
				"lldb.executable": "/usr/bin/lldb",
				// VS Code don't watch files under ./target
				"files.watcherExclude": {
					"**/target/**": true
				},
				"rust-analyzer.checkOnSave.command": "clippy",
				"rust-analyzer.rustfmt.extraArgs": [
					"+nightly"
				],
				"[rust]": {
					"editor.defaultFormatter": "rust-lang.rust-analyzer",
					"editor.formatOnSave": true
				}
			},
			// Add the IDs of extensions you want installed when the container is created.
			"extensions": [
				"vadimcn.vscode-lldb",
				"mutantdino.resourcemonitor",
				"rust-lang.rust-analyzer",
				"tamasfe.even-better-toml",
				"serayuzgur.crates",
				"Tyriar.sort-lines",
				"2gua.rainbow-brackets",
				"oderwat.indent-rainbow"
			]
		}
	},
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "rustc --version",
	// Set `remoteUser` to `root` to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "vscode",
	"mounts": [
		"source=${localWorkspaceFolderBasename}-target,target=${containerWorkspaceFolder}/target,type=volume"
	],
	"postCreateCommand": "sudo chown vscode target"
}
'''
'''--- .devcontainer/docker-compose.yml ---
version: '3.8'

services:
  vscode:
    build: 
      context: .
      dockerfile: Dockerfile
      args: 
        VARIANT: ${DEBIAN_VARIANT:-bullseye}

    volumes:
      - ..:/workspace:cached

      # Uncomment the next line to use Docker from inside the container. See https://aka.ms/vscode-remote/samples/docker-from-docker-compose for details.
      # - /var/run/docker.sock:/var/run/docker.sock 

    # Overrides default command so things don't shut down after the process ends.
    command: /bin/sh -c "while sleep 1000; do :; done"

    # Uncomment to run app on the same network as the service container, allows "forwardPorts" in devcontainer.json function.
    # network_mode: service:another-service

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

    # Uncomment the next line to use a non-root user for all processes - See https://aka.ms/vscode-remote/containers/non-root for details.
    # user: vscode

    # Uncomment the next four lines if you will use a ptrace-based debugger like C++, Go, and Rust.
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp:unconfined

  # Uncomment to include other services not opened by VS Code as well
  # another-service:
  #   image: mongo:latest
  #   restart: unless-stopped

'''
'''--- .github/ISSUE_TEMPLATE.md ---
## üëâ [Please follow one of these issue templates](https://github.com/sedaprotocol/seda-rust/issues/new/choose) üëà

Note: to keep the backlog clean and actionable, issues may be immediately closed if they do not follow one of the above issue templates.

'''
'''--- .github/ISSUE_TEMPLATE/bug.md ---
---
name: üêõ Bug Report
about: Submit a bug report if something isn't working
title: "[Bug]"
labels: bug
---

## üêõ Bug Report

<!--
    What's the bug in **seda-rust** that you found?
    How serious is this bug, and what is affected? What module(s), such as `seda-node`, is concerned?
-->

(Write your description here)

## Steps to Reproduce

<!--
    What module(s) are affected by the issue?
    How do I reproduce this issue?
-->

#### Code snippet to reproduce

```
# Add code here
```

#### Stack trace & error message

```
// Paste the output here
```

## Expected Behavior

<!--
    What was supposed to happen?
    What happened instead?
-->

(Write what you expected to happen here)

## Your Environment

- <!-- seda-rust Version -->
- <!-- Rust Version -->
- <!-- Computer OS -->

'''
'''--- .github/ISSUE_TEMPLATE/config.yml ---
blank_issues_enabled: false

'''
'''--- .github/ISSUE_TEMPLATE/documentation.md ---
---
name: üìö Documentation
about: Report an issue related to documentation
title: "[Docs]"
labels: 'documentation'
---

## üìö Documentation

<!--
    Did you find a mistake in the documentation?
    Is there documentation about that's missing?
-->

(Write your answer here.)

'''
'''--- .github/ISSUE_TEMPLATE/feature.md ---
---
name:  üöÄ Feature
about: Submit a new feature request
title: "[Feature]"
labels: feature
---

## üöÄ Feature

<!--
    What is the feature you would like to see in **seda-rust**?
-->

(Write your description here)

## Motivation

<!--
    Why should this feature be implemented?
    How would this feature be used?
		What module(s) does this affect, such as `seda-runtime-core`?

    Is this feature request related to a problem? If so, please describe.
    Please link to any relevant issues or other PRs!
-->

(Outline your motivation here)

## Implementation

<!--
    What needs to be built for the feature to be supported?
	What module(s) does this feature affect? Or is it a new module?
    How should this feature be implemented?
-->

**Are you willing to open a pull request?** (See
[CONTRIBUTING](../../CONTRIBUTING.md))

'''
'''--- .github/PULL_REQUEST_TEMPLATE.md ---
<!--
    Thank you for submitting the PR! We appreciate you spending the time to work on these changes.

    Please help us understand your motivation by explaining why you decided to make this change.

    Happy contributing!
-->

## Motivation

(Write your motivation here)

## Explanation of Changes

<!-- Please explain why you made these changes the way you did.  -->

(Write your explanation here)

## Testing

<!--
    How do you test these changes?
	What command do you run to test these changes specifically?
-->

(Write your test plan here)

## Related PRs and Issues

<!--
    Please link to any relevant Issues and PRs.
-->

(Link your related PRs and Issues here)

'''
'''--- .github/workflows/push.yml ---
name: Push
on:
  pull_request:
    push:
      branches:
        - main
env:
  RUST_BACKTRACE: 1

jobs:
  fmt:
    name: Fmt Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Install Rust Nightly
        uses: dtolnay/rust-toolchain@nightly
        with:
          toolchain: nightly
          components: rustfmt

      - name: Format Check
        uses: actions-rs/cargo@v1
        with:
          command: fmt
          args: --all -- --check

  clippy_and_test:
    name: Clippy and Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Install Rust Stable
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable
          components: clippy

      - name: Install WASM Rust Toolchains
        run: rustup target add wasm32-wasi wasm32-unknown-unknown

      - name: Install dependencies
        run: |
          sudo apt-get update -y -qq
          sudo apt-get -y install --no-install-recommends protobuf-compiler

      - name: Cache cargo registry
        uses: actions/cache@v3
        continue-on-error: false
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Clippy Check
        run: make check

      - name: Test
        if: always()
        run: make test-build

'''
'''--- .rustfmt.toml ---
# Stable Rustfmt Flags
edition = "2021"
max_width = 120
merge_derives = true
newline_style = "Unix"
use_field_init_shorthand = true

# Unstable Rustfmt Flags
condense_wildcard_suffixes = true
enum_discrim_align_threshold = 120
error_on_unformatted = true
format_macro_matchers = true
group_imports = "StdExternalCrate"
imports_granularity = "Crate"
imports_layout = "HorizontalVertical"
reorder_impl_items = true
struct_field_align_threshold = 120
version = "Two"
wrap_comments = true

'''
'''--- CLI.md ---
# Command-Line Help for `seda`

This document contains the help content for the `seda` command-line program.

**Command Overview:**

* [`seda`‚Ü¥](#seda)
* [`seda document`‚Ü¥](#seda-document)
* [`seda generate`‚Ü¥](#seda-generate)
* [`seda run`‚Ü¥](#seda-run)
* [`seda node`‚Ü¥](#seda-node)
* [`seda node bridge`‚Ü¥](#seda-node-bridge)
* [`seda node get`‚Ü¥](#seda-node-get)
* [`seda node get-nodes`‚Ü¥](#seda-node-get-nodes)
* [`seda node register`‚Ü¥](#seda-node-register)
* [`seda node update`‚Ü¥](#seda-node-update)
* [`seda node update accept-ownership`‚Ü¥](#seda-node-update-accept-ownership)
* [`seda node update set-pending-owner`‚Ü¥](#seda-node-update-set-pending-owner)
* [`seda node update set-socket-address`‚Ü¥](#seda-node-update-set-socket-address)
* [`seda node unregister`‚Ü¥](#seda-node-unregister)
* [`seda node peers`‚Ü¥](#seda-node-peers)
* [`seda node peers add`‚Ü¥](#seda-node-peers-add)
* [`seda node peers list`‚Ü¥](#seda-node-peers-list)
* [`seda node peers remove`‚Ü¥](#seda-node-peers-remove)
* [`seda node peers discover`‚Ü¥](#seda-node-peers-discover)
* [`seda sub-chain`‚Ü¥](#seda-sub-chain)
* [`seda sub-chain call`‚Ü¥](#seda-sub-chain-call)
* [`seda sub-chain view`‚Ü¥](#seda-sub-chain-view)

## `seda`

For interacting with the SEDA protocol.

**Usage:** `seda [OPTIONS] <COMMAND>`

###### **Subcommands:**

* `document` ‚Äî Debug command for helping to generate our CLI.md file
* `generate` ‚Äî Generates an auto-completion file content for the specified shell
* `run` ‚Äî Runs the SEDA node
* `node` ‚Äî Commands to interact with the SEDA node
* `sub-chain` ‚Äî Debug commands to help interact with sub-chains

###### **Options:**

* `--log-file-path <LOG_FILE_PATH>` ‚Äî The path where you want the log file to write to

## `seda document`

Debug command for helping to generate our CLI.md file

**Usage:** `seda document`

## `seda generate`

Generates an auto-completion file content for the specified shell

**Usage:** `seda generate <SHELL>`

###### **Arguments:**

* `<SHELL>` ‚Äî The shell to generate the auto-completion for

  Possible values: `bash`, `elvish`, `fish`, `powershell`, `zsh`

## `seda run`

Runs the SEDA node

**Usage:** `seda run [OPTIONS]`

###### **Options:**

* `-d`, `--deposit <DEPOSIT>` ‚Äî An option to override the node deposit config value
* `-g`, `--gas <GAS>` ‚Äî An option to override the node gas config value
* `--seda-chain-secret-key <SEDA_CHAIN_SECRET_KEY>` ‚Äî An option to override the node chain secret key config value
* `--seda-secret-key <SEDA_SECRET_KEY>` ‚Äî An option to override the node secret key config value
* `--seda-sk-file-path <SEDA_SK_FILE_PATH>` ‚Äî The path where you want to write to the generated secret key
* `--signer-account-id <SIGNER_ACCOUNT_ID>` ‚Äî An option to override the node signer account ID config value
* `--contract-account-id <CONTRACT_ACCOUNT_ID>` ‚Äî An option to override the node contract account ID config value
* `--public-key <PUBLIC_KEY>` ‚Äî An option to override the node public key config value
* `--job-manager-interval-ms <JOB_MANAGER_INTERVAL_MS>` ‚Äî An option to override the node job manager interval(ms) config value
* `--runtime-worker-threads <RUNTIME_WORKER_THREADS>` ‚Äî An option to override the node runtime worker threads config value
* `--chain-rpc-url <CHAIN_RPC_URL>` ‚Äî An option to override the Near chain rpc url config value
* `--in-peers <IN_PEERS>` ‚Äî The amount of inbound peers we are trying to maintain
* `--out-peers <OUT_PEERS>` ‚Äî The maximum amount of out peers we allow
* `--p2p-server-address <P2P_SERVER_ADDRESS>` ‚Äî An option to override the node p2p server address config value
* `--p2p-known-peers <P2P_KNOWN_PEERS>` ‚Äî An option to override the node p2p known peers config value
* `--disable-mdns <DISABLE_MDNS>` ‚Äî Option to use mDNS to discover peers locally

  Possible values: `true`, `false`

* `--max-mdns-peers <MAX_MDNS_PEERS>` ‚Äî Maximum amount of peers we want to use from mDNS
* `--max-manual-peers <MAX_MANUAL_PEERS>` ‚Äî Maximum amount of peers we want to use from our manually configured peers
* `--disable-manual-peers <DISABLE_MANUAL_PEERS>` ‚Äî Option to disable usage of manually configured peers

  Possible values: `true`, `false`

* `--max-kademlia-peers <MAX_KADEMLIA_PEERS>` ‚Äî Maximum amount of peers we fetch from using Kademlia
* `--disable-kademlia-peers <DISABLE_KADEMLIA_PEERS>` ‚Äî Option to disable usage of kademlia

  Possible values: `true`, `false`

* `--cooldown-duration <COOLDOWN_DURATION>` ‚Äî How long a peer should not be used due a connection issue in ms

## `seda node`

Commands to interact with the SEDA node

**Usage:** `seda node [OPTIONS] <COMMAND>`

###### **Subcommands:**

* `bridge` ‚Äî Run a view method on the specified chain with the args and post it to the main chain
* `get` ‚Äî Get a node from a given node ID if it exists
* `get-nodes` ‚Äî Get a list of nodes limited by the given size from an offset
* `register` ‚Äî Register a node from the given deposit and socket address
* `update` ‚Äî Update a node by either accepting ownership, setting the pending owner, or changing the socket address
* `unregister` ‚Äî Unregister a node from the given node ID
* `peers` ‚Äî Commands for interacting with the p2p peers

###### **Options:**

* `--chain-rpc-url <CHAIN_RPC_URL>` ‚Äî An option to override the Near chain rpc url config value

## `seda node bridge`

Run a view method on the specified chain with the args and post it to the main chain

**Usage:** `seda node bridge --chain <CHAIN> --sub-chain-contract-id <SUB_CHAIN_CONTRACT_ID> --sub-chain-method-name <SUB_CHAIN_METHOD_NAME> --bridge-deposit <BRIDGE_DEPOSIT> --args <ARGS>`

###### **Options:**

* `-c`, `--chain <CHAIN>`

  Possible values: `another`, `near`

* `--sub-chain-contract-id <SUB_CHAIN_CONTRACT_ID>`
* `--sub-chain-method-name <SUB_CHAIN_METHOD_NAME>`
* `--bridge-deposit <BRIDGE_DEPOSIT>`
* `-a`, `--args <ARGS>`

## `seda node get`

Get a node from a given node ID if it exists

**Usage:** `seda node get [OPTIONS] --node-id <NODE_ID>`

###### **Options:**

* `-n`, `--node-id <NODE_ID>`
* `-c`, `--contract-id <CONTRACT_ID>`

## `seda node get-nodes`

Get a list of nodes limited by the given size from an offset

**Usage:** `seda node get-nodes [OPTIONS]`

###### **Options:**

* `-l`, `--limit <LIMIT>`

  Default value: `10`
* `-o`, `--offset <OFFSET>`

  Default value: `0`
* `-c`, `--contract-id <CONTRACT_ID>`

## `seda node register`

Register a node from the given deposit and socket address

**Usage:** `seda node register [OPTIONS] --register-deposit <REGISTER_DEPOSIT> --socket-address <SOCKET_ADDRESS>`

###### **Options:**

* `-r`, `--register-deposit <REGISTER_DEPOSIT>`
* `-s`, `--socket-address <SOCKET_ADDRESS>`
* `-d`, `--deposit <DEPOSIT>` ‚Äî An option to override the node deposit config value
* `-g`, `--gas <GAS>` ‚Äî An option to override the node gas config value
* `--seda-chain-secret-key <SEDA_CHAIN_SECRET_KEY>` ‚Äî An option to override the node chain secret key config value
* `--seda-secret-key <SEDA_SECRET_KEY>` ‚Äî An option to override the node secret key config value
* `--seda-sk-file-path <SEDA_SK_FILE_PATH>` ‚Äî The path where you want to write to the generated secret key
* `--signer-account-id <SIGNER_ACCOUNT_ID>` ‚Äî An option to override the node signer account ID config value
* `--contract-account-id <CONTRACT_ACCOUNT_ID>` ‚Äî An option to override the node contract account ID config value
* `--public-key <PUBLIC_KEY>` ‚Äî An option to override the node public key config value
* `--job-manager-interval-ms <JOB_MANAGER_INTERVAL_MS>` ‚Äî An option to override the node job manager interval(ms) config value
* `--runtime-worker-threads <RUNTIME_WORKER_THREADS>` ‚Äî An option to override the node runtime worker threads config value

## `seda node update`

Update a node by either accepting ownership, setting the pending owner, or changing the socket address

**Usage:** `seda node update [OPTIONS] --node-id <NODE_ID> <COMMAND>`

###### **Subcommands:**

* `accept-ownership` ‚Äî 
* `set-pending-owner` ‚Äî 
* `set-socket-address` ‚Äî 

###### **Options:**

* `-n`, `--node-id <NODE_ID>`
* `-d`, `--deposit <DEPOSIT>` ‚Äî An option to override the node deposit config value
* `-g`, `--gas <GAS>` ‚Äî An option to override the node gas config value
* `--seda-chain-secret-key <SEDA_CHAIN_SECRET_KEY>` ‚Äî An option to override the node chain secret key config value
* `--seda-secret-key <SEDA_SECRET_KEY>` ‚Äî An option to override the node secret key config value
* `--seda-sk-file-path <SEDA_SK_FILE_PATH>` ‚Äî The path where you want to write to the generated secret key
* `--signer-account-id <SIGNER_ACCOUNT_ID>` ‚Äî An option to override the node signer account ID config value
* `--contract-account-id <CONTRACT_ACCOUNT_ID>` ‚Äî An option to override the node contract account ID config value
* `--public-key <PUBLIC_KEY>` ‚Äî An option to override the node public key config value
* `--job-manager-interval-ms <JOB_MANAGER_INTERVAL_MS>` ‚Äî An option to override the node job manager interval(ms) config value
* `--runtime-worker-threads <RUNTIME_WORKER_THREADS>` ‚Äî An option to override the node runtime worker threads config value

## `seda node update accept-ownership`

**Usage:** `seda node update accept-ownership`

## `seda node update set-pending-owner`

**Usage:** `seda node update set-pending-owner <OWNER>`

###### **Arguments:**

* `<OWNER>`

## `seda node update set-socket-address`

**Usage:** `seda node update set-socket-address <ADDRESS>`

###### **Arguments:**

* `<ADDRESS>`

## `seda node unregister`

Unregister a node from the given node ID

**Usage:** `seda node unregister [OPTIONS] --node-id <NODE_ID>`

###### **Options:**

* `-n`, `--node-id <NODE_ID>`
* `-d`, `--deposit <DEPOSIT>` ‚Äî An option to override the node deposit config value
* `-g`, `--gas <GAS>` ‚Äî An option to override the node gas config value
* `--seda-chain-secret-key <SEDA_CHAIN_SECRET_KEY>` ‚Äî An option to override the node chain secret key config value
* `--seda-secret-key <SEDA_SECRET_KEY>` ‚Äî An option to override the node secret key config value
* `--seda-sk-file-path <SEDA_SK_FILE_PATH>` ‚Äî The path where you want to write to the generated secret key
* `--signer-account-id <SIGNER_ACCOUNT_ID>` ‚Äî An option to override the node signer account ID config value
* `--contract-account-id <CONTRACT_ACCOUNT_ID>` ‚Äî An option to override the node contract account ID config value
* `--public-key <PUBLIC_KEY>` ‚Äî An option to override the node public key config value
* `--job-manager-interval-ms <JOB_MANAGER_INTERVAL_MS>` ‚Äî An option to override the node job manager interval(ms) config value
* `--runtime-worker-threads <RUNTIME_WORKER_THREADS>` ‚Äî An option to override the node runtime worker threads config value

## `seda node peers`

Commands for interacting with the p2p peers

**Usage:** `seda node peers <COMMAND>`

###### **Subcommands:**

* `add` ‚Äî Adds a peer to a running node
* `list` ‚Äî Lists all currently connected peers
* `remove` ‚Äî Removes a connected peer
* `discover` ‚Äî Triggers the node to discover more peers

## `seda node peers add`

Adds a peer to a running node

**Usage:** `seda node peers add <MULTI_ADDR>`

###### **Arguments:**

* `<MULTI_ADDR>` ‚Äî A libp2p compatible address (ex. /ip4/127.0.0.1/tcp/44635)

## `seda node peers list`

Lists all currently connected peers

**Usage:** `seda node peers list`

## `seda node peers remove`

Removes a connected peer

**Usage:** `seda node peers remove <PEER_ID>`

###### **Arguments:**

* `<PEER_ID>` ‚Äî A libp2p peer id (ex. 12D3KooWRg13CAzihqGpVfifoeK4nmZ15D3vpZSPfmaDT53CBr9R)

## `seda node peers discover`

Triggers the node to discover more peers

**Usage:** `seda node peers discover`

## `seda sub-chain`

Debug commands to help interact with sub-chains

**Usage:** `seda sub-chain [OPTIONS] <COMMAND>`

###### **Subcommands:**

* `call` ‚Äî Calls the specified method on the specified chain with the given args and contract ID
* `view` ‚Äî Views the specified method on the specified chain with the given args and contract ID

###### **Options:**

* `--chain-rpc-url <CHAIN_RPC_URL>` ‚Äî An option to override the Near chain rpc url config value

## `seda sub-chain call`

Calls the specified method on the specified chain with the given args and contract ID

**Usage:** `seda sub-chain call [OPTIONS] <CHAIN> <CONTRACT_ID> <METHOD_NAME> <ARGS> <CALL_DEPOSIT>`

###### **Arguments:**

* `<CHAIN>` ‚Äî The sub-chain to call

  Possible values: `another`, `near`

* `<CONTRACT_ID>` ‚Äî The contract ID for the sub-chain
* `<METHOD_NAME>` ‚Äî The method name to call
* `<ARGS>` ‚Äî The args to pass to the call method
* `<CALL_DEPOSIT>` ‚Äî The deposit for the call method

###### **Options:**

* `-d`, `--deposit <DEPOSIT>` ‚Äî An option to override the node deposit config value
* `-g`, `--gas <GAS>` ‚Äî An option to override the node gas config value
* `--seda-chain-secret-key <SEDA_CHAIN_SECRET_KEY>` ‚Äî An option to override the node chain secret key config value
* `--seda-secret-key <SEDA_SECRET_KEY>` ‚Äî An option to override the node secret key config value
* `--seda-sk-file-path <SEDA_SK_FILE_PATH>` ‚Äî The path where you want to write to the generated secret key
* `--signer-account-id <SIGNER_ACCOUNT_ID>` ‚Äî An option to override the node signer account ID config value
* `--contract-account-id <CONTRACT_ACCOUNT_ID>` ‚Äî An option to override the node contract account ID config value
* `--public-key <PUBLIC_KEY>` ‚Äî An option to override the node public key config value
* `--job-manager-interval-ms <JOB_MANAGER_INTERVAL_MS>` ‚Äî An option to override the node job manager interval(ms) config value
* `--runtime-worker-threads <RUNTIME_WORKER_THREADS>` ‚Äî An option to override the node runtime worker threads config value

## `seda sub-chain view`

Views the specified method on the specified chain with the given args and contract ID

**Usage:** `seda sub-chain view <CHAIN> <CONTRACT_ID> <METHOD_NAME> <ARGS>`

###### **Arguments:**

* `<CHAIN>` ‚Äî The sub-chain to call

  Possible values: `another`, `near`

* `<CONTRACT_ID>` ‚Äî The contract ID for the sub-chain
* `<METHOD_NAME>` ‚Äî The method name to view
* `<ARGS>` ‚Äî The args to pass to the view method

<hr/>

<small><i>
    This document was generated automatically by
    <a href="https://crates.io/crates/clap-markdown"><code>clap-markdown</code></a>.
</i></small>

'''
'''--- CONTRIBUTING.md ---
# Contributing

This file describes the process for contributing to `seda-rust`.

## Starting

First and foremost, [fork](https://github.com/sedaprotocol/seda-rust/fork) the repository. Then please read the
[developing instructions](DEVELOPING.md) for setting up your environment.

## Commits

Your commits must follow specific guidelines.

### Signed Commits

Sign all commits with a GPG key. GitHub has extensive documentation on how to:

- [Create](https://docs.github.com/en/authentication/managing-commit-signature-verification/generating-a-new-gpg-key)
  a new GPG key.
- [Add](https://docs.github.com/en/authentication/managing-commit-signature-verification/A-a-gpg-key-to-your-github-account)
  a GPG key to your GitHub.
- [Sign](https://docs.github.com/en/authentication/managing-commit-signature-verification/A-a-gpg-key-to-your-github-account)
  your commits.

### Convention

All commits are to follow the
[Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) standard.
Commit messages should always be meaningful.

## Getting Ready For a PR

This section describes actions to keep in mind while developing.

### Change Size

Please try to keep changes small to make reviews easier. We will reject more
extensive unless there is a valid reason.

### Formatting and Cleanliness

Please ensure your code is formatted and clippy gives no warnings.

## PRs

For creating the PR, please follow the instructions below.

1. Firstly, please open a
   [PR](https://github.com/SedaProtocol/seda-rust/compare) from your forked repo
   to the `main` branch of `seda-rust`.
2. Please fill in the PR template that is there.
3. Then assign it to yourself and anyone else who worked on the issue with you.
4. Make sure all CI tests pass.
5. Finally, please assign at least two reviewers to your PR:
   - [FranklinWaller](https://github.com/FranklinWaller)
   - [gluax](https://github.com/gluax)
   - [jamesondh](https://github.com/jamesondh)
   - [mariocao](https://github.com/mariocao)
   - [mennatabuelnaga](https://github.com/mennatabuelnaga)

'''
'''--- Cargo.toml ---
[workspace]
resolver = "2"
default-members = ["cli", "delegate-cli"]
members = [
	"chains",
	"cli",
	"common",
	"contracts",
	"config",
	"crypto",
	"delegate-cli",
	"logger",
	"node",
	"p2p",
	"runtime/core",
	"runtime/macros",
	"runtime/sdk",
	"tooling/debug",
	"wasm/cli",
	"wasm/consensus",
	"wasm/test/demo-cli",
	"wasm/test/promise-wasm-bin",
]

[workspace.package]
rust-version = "1.66.1"

[profile.dev]
codegen-units = 512
debug = 2
incremental = true
opt-level = 0

[profile.release]
codegen-units = 1
incremental = false
lto = "thin"
opt-level = 3
panic = "abort"
strip = true

[profile.release-docker]
inherits = "release"
opt-level = "z"

[workspace.dependencies]
actix = "0.13"
async-trait = "0.1"
bs58 = "0.4.0"
base64 = "0.13"
bn254 = { git = "https://github.com/sedaprotocol/bn254", branch = "main" }
borsh = { version = "0.9", default-features = false }
clap = { version = "4.1", default-features = false }
clap-markdown = { version = "0.1", default-features = false }
clap_complete = { version = "4.1", default-features = false }
concat-kdf = "0.1"
dotenv = "0.15"
ed25519-dalek = "1.0"
futures = { version = "0.3", default-features = false }
getrandom = { version = "0.2"}
hex = "0.4"
jsonrpsee = { version = "0.16", default-features = false }
jsonrpsee-types = "0.16"
lazy_static = "1.4"
libp2p = { version = "0.50", default-features = false }
near-bigint = "1.0"
near-contract-standards = "4.0"
near-crypto = "0.15"
near-jsonrpc-client = { version = "0.4", default-features = false }
near-jsonrpc-primitives = "0.15"
near-primitives = "0.15"
near-sdk = { version = "4.0", default-features = false }
near-sys = "0.2"
near-units = "0.2"
parking_lot = "0.12"
primitive-types = "0.12"
rand = "0.8"
reqwest = "0.11"
rusqlite = { version = "0.28", features = ["bundled"] }
schemars = "0.8"
seda-chains = { path = "./chains" }
seda-common = { path = "./common" }
seda-config = { path = "./config" }
seda-crypto = { path = "./crypto" }
seda-logger = { path = "./logger" }
seda-node = { path = "./node" }
seda-p2p = { path = "./p2p" }
seda-runtime = { path = "./runtime/core" }
seda-runtime-sdk = { path = "./runtime/sdk" }
serde = { version = "1.0", default-features = false, features = ["derive"] }
serde_json = { version = "1.0", default-features = false }
sha2 = { version = "0.10", default-features = false }
thiserror = "1.0"
tokio = { version = "1.21", default-features = false }
tokio-rusqlite = "0.3"
toml = "0.5"
tracing = { version = "0.1", features = ["log-always"] }
tracing-appender = "0.2"
tracing-subscriber = { version = "0.3", default-features = false }
uint = { version = "0.8", default-features = false }
url = { version = "2.3", default-features = false }
wasmer = { version = "2.3", default-features = false }
wasmer-wasi = { version = "2.3", default-features = false }
workspaces = "0.7"

'''
'''--- DEVELOPING.md ---
# Developing

For setting up your environment to develop `seda-rust`. Shows how to build, run,
format, and clean the code base. To learn how to contribute please read
[here](CONTRIBUTING.md).

## Dev-Container

If you are using [VSCode](https://code.visualstudio.com/) and
[docker](https://www.docker.com/) you can open the project in a
[dev-container](https://github.com/Microsoft/vscode-remote-release) where all deps will be installed already.
Otherwise please see the [dev dependencies](#dev-dependencies).

## Dev Dependencies

### [Rust](https://www.rust-lang.org/tools/install)

- [rustup](https://www.rust-lang.org/tools/install)
- `stable` toolchain
  - `rustup install stable`
  - `rustup default stable`
- `nightly` toolchain
  - `rustup install stable`
- `wasm32-wasi` toolchain
  - `cargo install cargo-wasi`

### [Make](https://www.gnu.org/software/make/)

- Windows
  - install [scoop](https://scoop.sh/)
  - `scoop bucket add main`
  - `scoop install make`
- macOS
  - `xcode-select --install` or with brew `brew install make`
- Linux
  - Likely already comes installed.
  - However, please see your distribution specific installer.

## Building

- `make build` builds only the `seda` binary.
- `make build-wasm` builds the wasm binaries and the `seda` binary.
- `make wasm` builds the wasm binaries.

## Formatting & Cleanliness

- `make clean` runs `cargo clean`
- `make check` runs `clippy` with the deny flag like in our CI.
- `make fmt` runs `cargo +nightly fmt --all`

## Running

Be sure to [configure](#configuration) your node before running.

The run commands takes additional arguments to pass to the node. For an example
of how to pass arguments `make run -- --help`.

For more command documentation please see the documentation [here](CLI.md).

- `make run` runs the already built binary but has no dependencies, so you have
  to run `build-wasm` first or `make run-build-all`.
- `make run-build` builds `seda` and then runs it.
- `make run-build-all` builds the wasm binaries, then `seda`, and finally runs.
- `make run-build-wasm` builds the wasm binaries, then runs `seda`.

## Testing

Unfortunately not all of our contract tests work on Windows. For the best testing experience please use a unix based machine.

### From scratch
- You must first rust `make seda-debugger` so that the debugger tool is built for testing.
- Next you must build the test wasm binaries by running `make wasm-test`.
- `make test` runs
  `cargo test --workspace --exclude demo-cli --exclude seda-cli --exclude promise-wasm-bin`.

### Test and Build

- `make test-build` builds seda-debugger, and the wasm binaries before running the same command as
  `make test`.

'''
'''--- LICENSE.md ---
                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.

'''
'''--- README.md ---
<p align="center">
  <a href="https://seda.xyz/">
    <img width="90%" alt="seda-rust" src="https://www.seda.xyz/images/footer/footer-image.png">
  </a>
</p>

<h1 align="center">
   SEDA Rust
</h1>

[![Build Status][actions-badge]][actions-url]
[![GitHub Stars][github-stars-badge]](https://github.com/sedaprotocol/seda-rust)
[![GitHub Contributors][github-contributors-badge]](https://github.com/sedaprotocol/seda-rust/graphs/contributors)
[![Discord chat][discord-badge]][discord-url]
[![Twitter][twitter-badge]][twitter-url]

<!-- once we publish seda:
[![Crates.io][crates-badge]][crates-url]
[crates-badge]: https://img.shields.io/crates/v/seda
[crates-url]: https://crates.io/crates/seda
 -->

[actions-badge]: https://github.com/sedaprotocol/seda-rust/actions/workflows/push.yml/badge.svg
[actions-url]: https://github.com/sedaprotocol/seda-rust/actions/workflows/push.yml+branch%3Amain
[github-stars-badge]: https://img.shields.io/github/stars/sedaprotocol/seda-rust.svg?style=flat-square&label=github%20stars
[github-contributors-badge]: https://img.shields.io/github/contributors/sedaprotocol/seda-rust.svg?style=flat-square
[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord&style=flat-square
[discord-url]: https://discord.gg/seda
[twitter-badge]: https://img.shields.io/twitter/url/https/twitter.com/SedaProtocol.svg?style=social&label=Follow%20%40SedaProtocol
[twitter-url]: https://twitter.com/SedaProtocol

Open source Rust implementation of the
[SEDA Protocol](https://docs.seda.xyz/).

**NOTE** this repo adheres to the [GPLv3 license](LICENSE.md).

To learn how to build a local version, please read [developing](DEVELOPING.md).
To learn how to contribute, please read [contributing](CONTRIBUTING.md).

## Dependencies

There are currently no dependencies.

## Configuration

The configuration for the `node` and the `CLI` commands.

### TOML File

Config is written in [TOML](https://toml.io/en/) and read by default from your
operating systems app config location.

- Unix Systems(Mac & Linux) `/etc/seda-rust/config.toml`
- Windows `C:\\ProgramData\\seda-rust\\config.toml`

On the first run, a default configuration generates. You need to specify some
fields via the command line interface or from environment variables.

Some fields below are not required, as they have default values, or you can pass
them through the [environment variables](#env) or the [CLI](CLI.md). For the
sake of documentation, here the names of variables will be followed by
parentheses with symbols inside:

- ? - means the field is entirely optional and has a default value.
- ! - means it's overwritable by an environment variable.
- \* - means it's overwritable by the cli.

You can look at the example configuration [here](example.config.toml).

#### Fields

- seda_server_address(?!) - Defines the address for seda to run its RPC server on.
- seda_server_port(?!) - Defines the port for seda to run its RPC server on.
- chains - All config fields related to the supported chains.
  - near - All config fields related to the near chain.
    - chain_rpc_url(!\*) - The near server URL.
- node - All config fields related to the seda node.
  - contract_account_id(\*) - Your near contract account id.
  - deposit(?\*) - The deposit amount.
  - gas(?\*) - The gas amount.
  - job_manager_interval_ms(?\*) - How often the node runs jobs.
  - p2p_server_address(?\*) - The address to run the p2p server on.
  - p2p_known_peers(?\*) - The list of known peers for the node.
  - public_key(\*) - Your near public key.
  - runtime_worker_threads(?\*) - The number of threads the node can use to spin
    up jobs.
  - seda_chain_secret_key(!\*) - Your near secret key.
  - seda_secret_key(!\*) - Your node secret key.
  - seda_sk_file_path(!\*) - Your node secret key file path.
  - signer_account_id(\*) - Your near signer account id.
- logging - All config fields related to the seda logger.
  - log_file_path(?!\*) - The path where the log file will write.

### ENV

SEDA configuration uses the following ENV variables if they exist.

**NOTE**: You can use a `.env` file to overwrite the env variables more easily.~~~

| Name                  | Description                                                                                                                        |
| --------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| `SEDA_CONFIG_PATH`    | Defines an alternative path for the seda configuration file to be.                                                                 |
| `SEDA_LOG_FILE_PATH`  | Overwrites the config `logging.log_file_path` field.                                                                               |
| `SEDA_NEAR_RPC_URL`   | Overwrites the config `near_chain.chain_rpc_url` field.                                                                            |
| `SEDA_CHAIN_SECRET_KEY`     | Overwrites the config `node.seda_chain_secret_key` field.       
| `SEDA_SECRET_KEY`     | Overwrites the config `node.seda_secret_key` field.                                                                               |
| `SEDA_SERVER_ADDRESS` | Overwrites the config `seda_server_address` field.                                                                                 |
| `SEDA_SERVER_PORT`    | Overwrites the config `seda_server_port` field.                                                                                    |
| `RUST_LOG`            | Controlled via the [tracing_subscriber](https://docs.rs/tracing-subscriber/0.3.16/tracing_subscriber/struct.EnvFilter.html) crate. |

'''
'''--- chains/Cargo.toml ---
[package]
name = "seda-chains"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
async-trait = { workspace = true }
borsh = { workspace = true }
hex = { workspace = true }
near-jsonrpc-client = { workspace = true }
near-jsonrpc-primitives = { workspace = true }
near-primitives = { workspace = true }
tokio = { workspace = true }
seda-config = { workspace = true }
seda-runtime-sdk = { workspace = true }
near-crypto = { workspace = true }
thiserror = { workspace = true }

'''
'''--- chains/src/another_chain.rs ---
use std::sync::Arc;

use seda_config::AnotherConfig;

use super::errors::Result;
use crate::ChainAdapterTrait;

#[derive(Debug)]
pub struct AnotherChain;

#[async_trait::async_trait]
impl ChainAdapterTrait for AnotherChain {
    type Client = Arc<()>;
    type Config = AnotherConfig;

    fn new_client(_config: &Self::Config) -> Result<Self::Client> {
        Ok(Arc::new(()))
    }

    async fn construct_signed_tx(
        _signer_account_id: Option<&str>,
        _signer_keypair: &[u8],
        _contract_id: &str,
        _method_name: &str,
        _args: Vec<u8>,
        _gas: u64,
        _deposit: u128,
        _server_url: &str,
    ) -> Result<Vec<u8>> {
        unimplemented!()
    }

    async fn construct_transfer_tx(
        _signer_account_id: Option<&str>,
        _signer_keypair: &[u8],
        _receiver_id: &str,
        _deposit: u128,
        _server_url: &str,
    ) -> Result<Vec<u8>> {
        unimplemented!()
    }

    async fn send_tx(_client: Self::Client, _signed_tx: &[u8]) -> Result<Vec<u8>> {
        unimplemented!()
    }

    async fn view(_client: Self::Client, _contract_id: &str, _method_name: &str, _args: Vec<u8>) -> Result<Vec<u8>> {
        unimplemented!()
    }
}

'''
'''--- chains/src/chain_adapter_trait.rs ---
use std::fmt::Debug;

use crate::Result;

#[async_trait::async_trait]
pub trait ChainAdapterTrait: Debug + Send + Sync + 'static {
    /// The Client type for the adapter specific implementation.
    type Client: Send + Sync + 'static;
    /// The Config fields for the adapter specific implementation.
    type Config: Send + Sync;

    /// Returns an new instance of the client given the server address.
    fn new_client(config: &Self::Config) -> Result<Self::Client>;

    /// Returns a signed transaction given the necessary information.
    #[allow(clippy::too_many_arguments)]
    async fn construct_signed_tx(
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        gas: u64,
        deposit: u128,
        server_url: &str,
    ) -> Result<Vec<u8>>;

    async fn construct_transfer_tx(
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        receiver_id: &str,
        amount: u128,
        server_url: &str,
    ) -> Result<Vec<u8>>;

    /// To send a transaction for the adapter specific implementation.
    async fn send_tx(client: Self::Client, signed_tx: &[u8]) -> Result<Vec<u8>>;
    /// To view for the adapter specific implementation.
    async fn view(client: Self::Client, contract_id: &str, method_name: &str, args: Vec<u8>) -> Result<Vec<u8>>;
}

'''
'''--- chains/src/errors.rs ---
use near_crypto::ParseKeyError;
use near_jsonrpc_client::methods::broadcast_tx_async::RpcBroadcastTxAsyncError;
use near_primitives::account::id::ParseAccountError;
use thiserror::Error;
#[derive(Error, Debug)]
pub enum ChainAdapterError {
    #[error("error calling contract change method")]
    CallChangeMethod(String),

    #[error("error calling contract view method")]
    CallViewMethod,

    #[error("error failed to send tx: `{0}`")]
    FailedTx(String),

    #[error("time limit exceeded for the transaction to be recognized")]
    BadTransactionTimestamp,

    #[error("failed to extract current nonce")]
    FailedToExtractCurrentNonce,

    #[error("Bad Parameters for method `{0}`")]
    BadParams(String),

    #[error("error parsing string to near secretkey")]
    ParseAccountId(#[from] ParseAccountError),

    #[error("near json rpc query error {0}")]
    JsonRpcQueryError(
        #[from] near_jsonrpc_client::errors::JsonRpcError<near_jsonrpc_client::methods::query::RpcQueryError>,
    ),

    #[error("error parsing string to near AccountId")]
    ParseKey(#[from] ParseKeyError),

    #[error("near json rpc tx error")]
    JsonRpcTxError(#[from] near_jsonrpc_client::errors::JsonRpcError<RpcBroadcastTxAsyncError>),

    #[error("Config error: chain_rpc_url from env var or config [main_chain] section.")]
    MissingNearServerUrlConfig,

    #[error("error serializing to vec")]
    StdIoError(#[from] std::io::Error),

    #[error("error converting slice to Ed25519 keypair")]
    InvalidEd25519KeyPair,
}

pub type Result<T, E = ChainAdapterError> = core::result::Result<T, E>;

'''
'''--- chains/src/lib.rs ---
//! Defines a Chain type based on features when compiling.

mod another_chain;
pub use another_chain::AnotherChain;
use seda_config::ChainConfigs;
use seda_runtime_sdk::Chain;

mod errors;

pub use errors::*;

mod chain_adapter_trait;
pub use chain_adapter_trait::*;

mod near_chain;
pub use near_chain::NearChain;

#[derive(Debug, Clone)]
pub enum Client {
    Another(<AnotherChain as ChainAdapterTrait>::Client),
    Near(<NearChain as ChainAdapterTrait>::Client),
}

impl Client {
    pub fn new(chain: &Chain, chains_config: &ChainConfigs) -> Result<Self> {
        Ok(match chain {
            Chain::Another => Self::Another(AnotherChain::new_client(&chains_config.another)?),
            Chain::Near => Self::Near(NearChain::new_client(&chains_config.near)?),
        })
    }

    fn another(&self) -> <AnotherChain as ChainAdapterTrait>::Client {
        if let Self::Another(v) = self {
            v.clone()
        } else {
            unreachable!()
        }
    }

    fn near(&self) -> <NearChain as ChainAdapterTrait>::Client {
        if let Self::Near(v) = self {
            v.clone()
        } else {
            unreachable!()
        }
    }
}

pub mod chain {
    use super::*;
    #[allow(clippy::too_many_arguments)]
    pub async fn construct_signed_tx(
        chain: Chain,
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        gas: u64,
        deposit: u128,
        server_url: &str,
    ) -> Result<Vec<u8>> {
        match chain {
            Chain::Another => {
                AnotherChain::construct_signed_tx(
                    signer_account_id,
                    signer_keypair,
                    contract_id,
                    method_name,
                    args,
                    gas,
                    deposit,
                    server_url,
                )
                .await
            }
            Chain::Near => {
                NearChain::construct_signed_tx(
                    signer_account_id,
                    signer_keypair,
                    contract_id,
                    method_name,
                    args,
                    gas,
                    deposit,
                    server_url,
                )
                .await
            }
        }
    }

    pub async fn construct_transfer_tx(
        chain: Chain,
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        receiver_id: &str,
        amount: u128,
        server_url: &str,
    ) -> Result<Vec<u8>> {
        match chain {
            Chain::Another => {
                AnotherChain::construct_transfer_tx(signer_account_id, signer_keypair, receiver_id, amount, server_url)
                    .await
            }
            Chain::Near => {
                NearChain::construct_transfer_tx(signer_account_id, signer_keypair, receiver_id, amount, server_url)
                    .await
            }
        }
    }

    pub async fn send_tx(chain: Chain, client: Client, signed_tx: &[u8]) -> Result<Vec<u8>> {
        match chain {
            Chain::Another => AnotherChain::send_tx(client.another(), signed_tx).await,
            Chain::Near => NearChain::send_tx(client.near(), signed_tx).await,
        }
    }

    pub async fn view(
        chain: Chain,
        client: Client,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
    ) -> Result<Vec<u8>> {
        match chain {
            Chain::Another => AnotherChain::view(client.another(), contract_id, method_name, args).await,
            Chain::Near => NearChain::view(client.near(), contract_id, method_name, args).await,
        }
    }
}

'''
'''--- chains/src/near_chain.rs ---
use std::sync::Arc;

use borsh::{BorshDeserialize, BorshSerialize};
use near_crypto::{ED25519PublicKey, ED25519SecretKey, SecretKey};
use near_jsonrpc_client::{methods, JsonRpcClient};
use near_jsonrpc_primitives::types::{query::QueryResponseKind, transactions::TransactionInfo};
use near_primitives::{
    transaction::{Action, FunctionCallAction, SignedTransaction, Transaction, TransferAction},
    types::{AccountId, BlockReference, Finality, FunctionArgs},
    views::{FinalExecutionStatus, QueryRequest},
};
use seda_config::NearConfig;
use tokio::time;

use super::errors::{ChainAdapterError, Result};
use crate::ChainAdapterTrait;

#[derive(Debug)]
pub struct NearChain;

impl NearChain {
    async fn construct_tx(
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        receiver_id: &str,
        rpc_url: &str,
        actions: Vec<Action>,
    ) -> Result<Vec<u8>> {
        let client = JsonRpcClient::connect(rpc_url);
        let signer = get_in_memory_signer(signer_account_id, signer_keypair)?;

        let access_key_query_response = client
            .call(methods::query::RpcQueryRequest {
                block_reference: BlockReference::latest(),
                request:         near_primitives::views::QueryRequest::ViewAccessKey {
                    account_id: signer.account_id.clone(),
                    public_key: signer.public_key.clone(),
                },
            })
            .await?;

        let current_nonce = match access_key_query_response.kind {
            QueryResponseKind::AccessKey(access_key) => access_key.nonce,
            _ => Err(ChainAdapterError::FailedToExtractCurrentNonce)?,
        };

        let transaction = Transaction {
            signer_id: signer.account_id.clone(),
            public_key: signer.public_key.clone(),
            nonce: current_nonce + 1,
            receiver_id: receiver_id.parse()?,
            block_hash: access_key_query_response.block_hash,
            actions,
        };

        let signed_transaction = transaction.sign(&signer);

        Ok(signed_transaction.try_to_vec()?)
    }
}

#[async_trait::async_trait]
impl ChainAdapterTrait for NearChain {
    type Client = Arc<JsonRpcClient>;
    type Config = NearConfig;

    fn new_client(config: &Self::Config) -> Result<Self::Client> {
        Ok(Arc::new(JsonRpcClient::connect(&config.chain_rpc_url)))
    }

    async fn construct_signed_tx(
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        gas: u64,
        deposit: u128,
        server_url: &str,
    ) -> Result<Vec<u8>> {
        let client = JsonRpcClient::connect(server_url);

        let signer = get_in_memory_signer(signer_account_id, signer_keypair)?;
        let access_key_query_response = client
            .call(methods::query::RpcQueryRequest {
                block_reference: BlockReference::latest(),
                request:         near_primitives::views::QueryRequest::ViewAccessKey {
                    account_id: signer.account_id.clone(),
                    public_key: signer.public_key.clone(),
                },
            })
            .await?;

        let current_nonce = match access_key_query_response.kind {
            QueryResponseKind::AccessKey(access_key) => access_key.nonce,
            _ => Err(ChainAdapterError::FailedToExtractCurrentNonce)?,
        };

        let transaction = Transaction {
            signer_id:   signer.account_id.clone(),
            public_key:  signer.public_key.clone(),
            nonce:       current_nonce + 1,
            receiver_id: contract_id.parse()?,
            block_hash:  access_key_query_response.block_hash,
            actions:     vec![Action::FunctionCall(FunctionCallAction {
                method_name: method_name.to_string(),
                args,
                gas,
                deposit,
            })],
        };
        let signed_transaction = transaction.sign(&signer);

        Ok(signed_transaction.try_to_vec()?)
    }

    async fn construct_transfer_tx(
        signer_account_id: Option<&str>,
        signer_keypair: &[u8],
        receiver_id: &str,
        deposit: u128,
        server_url: &str,
    ) -> Result<Vec<u8>> {
        Self::construct_tx(
            signer_account_id,
            signer_keypair,
            receiver_id,
            server_url,
            vec![Action::Transfer(TransferAction { deposit })],
        )
        .await
    }

    async fn send_tx(client: Self::Client, signed_tx: &[u8]) -> Result<Vec<u8>> {
        let signed_tx = SignedTransaction::try_from_slice(signed_tx)?;
        let request = methods::broadcast_tx_async::RpcBroadcastTxAsyncRequest {
            signed_transaction: signed_tx.clone(),
        };

        let sent_at = time::Instant::now();
        let tx_hash = client.call(request).await?;

        loop {
            let response = client
                .call(methods::tx::RpcTransactionStatusRequest {
                    transaction_info: TransactionInfo::TransactionId {
                        hash:       tx_hash,
                        account_id: signed_tx.transaction.signer_id.clone(),
                    },
                })
                .await;
            let received_at = time::Instant::now();
            let delta = (received_at - sent_at).as_secs();

            if delta > 60 {
                return Err(ChainAdapterError::BadTransactionTimestamp);
            }

            match response {
                Err(err) => match err.handler_error() {
                    Some(methods::tx::RpcTransactionError::UnknownTransaction { .. }) => {
                        time::sleep(time::Duration::from_secs(2)).await;
                        continue;
                    }
                    _ => return Err(ChainAdapterError::CallChangeMethod(err.to_string())),
                },
                Ok(response) => {
                    if let FinalExecutionStatus::SuccessValue(value) = response.status {
                        return Ok(value);
                    } else {
                        return Err(ChainAdapterError::FailedTx(format!("{:?}", response.status)));
                    }
                }
            }
        }
    }

    async fn view(client: Self::Client, contract_id: &str, method_name: &str, args: Vec<u8>) -> Result<Vec<u8>> {
        let request = methods::query::RpcQueryRequest {
            block_reference: BlockReference::Finality(Finality::Final),
            request:         QueryRequest::CallFunction {
                account_id:  contract_id.parse()?,
                method_name: method_name.to_string(),
                args:        FunctionArgs::from(args),
            },
        };

        let response = client.call(request).await?;

        if let QueryResponseKind::CallResult(result) = response.kind {
            Ok(result.result)
        } else {
            Err(ChainAdapterError::CallViewMethod)
        }
    }
}

// This function takes as input an `Option` of a string specifying a
// non-implicit account ID and the Ed25519 keypair bytes.
fn get_in_memory_signer(signer_account_id: Option<&str>, signer_keypair: &[u8]) -> Result<near_crypto::InMemorySigner> {
    let ed25519_secret_key = ED25519SecretKey(
        signer_keypair
            .try_into()
            .map_err(|_| ChainAdapterError::InvalidEd25519KeyPair)?,
    );

    // If human-readable account ID is not given, implicit public key is derived
    let signer_account_id: AccountId = if let Some(account_id) = signer_account_id {
        account_id.parse()?
    } else {
        let ed25519_public_key: ED25519PublicKey = ed25519_secret_key.0[32..].try_into()?;

        hex::encode(ed25519_public_key).parse()?
    };

    let signer_secret_key: SecretKey = SecretKey::ED25519(ed25519_secret_key);

    Ok(near_crypto::InMemorySigner::from_secret_key(
        signer_account_id,
        signer_secret_key,
    ))
}

'''
'''--- cli/Cargo.toml ---
[package]
name = "seda-cli"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[[bin]]
name = "seda"
path = "src/main.rs"

[dependencies]
async-trait = { workspace = true }
bn254 = { workspace = true }
bs58 = { workspace = true }
clap = { workspace = true, features = ["default"] }
clap-markdown = { workspace = true }
clap_complete = { workspace = true }
dotenv = { workspace = true }
ed25519-dalek = { workspace = true }
hex = { workspace = true }
jsonrpsee = { workspace = true, features = ["client"] }
near-crypto = { workspace = true }
near-jsonrpc-client = { workspace = true }
near-jsonrpc-primitives = { workspace = true }
near-primitives = { workspace = true }
rand = "0.7"
seda-chains = { workspace = true }
seda-crypto = { workspace = true }
seda-common = { workspace = true, features = ["cli"] }
seda-config = { workspace = true, features = ["cli"] }
seda-logger = { workspace = true }
seda-node = { workspace = true }
seda-runtime-sdk = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tracing = { workspace = true }

[dev-dependencies]
jsonrpsee = { workspace = true }

'''
'''--- cli/src/cli/commands/init.rs ---
use std::path::{Path, PathBuf};

use clap::Args;
use seda_config::{create_and_load_or_load_config, NodeConfigInner, FULL_CONFIG_PATH};
use seda_crypto::MasterKey;

use crate::Result;

#[derive(Debug, Args)]
pub struct Init {
    #[clap(default_value = NodeConfigInner::SEDA_SECRET_KEY_PATH, short, long)]
    key_path: String,

    #[clap(default_value = FULL_CONFIG_PATH, short, long)]
    /// The path where the config file should be written to
    config_path: String,
}

impl Init {
    pub fn handle(&self) -> Result<()> {
        let master_key: MasterKey = if let Ok(env_secret_key) = std::env::var("SEDA_SECRET_KEY") {
            MasterKey::try_from(&env_secret_key)?
        } else if Path::new(&self.key_path).exists() {
            MasterKey::read_from_path(&self.key_path)?
        } else {
            let key = MasterKey::random();
            key.write_to_path(&self.key_path)?;
            println!("Written SEDA secret key to {}", &self.key_path);

            key
        };

        let bn254_key = master_key.derive_bn254(0)?;
        let ed25519_key = master_key.derive_ed25519(0)?;

        let ed25519_public_key = ed25519_key.public_key.as_bytes().to_vec();
        let bn254_public_key = bn254_key.public_key.to_compressed()?;

        let account_id = hex::encode(&ed25519_public_key);

        // Generates our template config file
        create_and_load_or_load_config(Some(PathBuf::from(self.config_path.to_string())));

        println!("Key information: \n");
        println!("NEAR Account ID: {account_id}");
        println!(
            "ED25519 Public Key (base58 encoded): ed25519:{}",
            bs58::encode(&ed25519_public_key).into_string()
        );
        println!(
            "BN254 Public Key (base58 encoded): bn254:{}",
            bs58::encode(&bn254_public_key).into_string()
        );

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/mod.rs ---
mod node;
pub(crate) use node::*;

mod run;
pub(crate) use run::*;

mod init;
pub(crate) use init::*;

#[cfg(debug_assertions)]
mod sub_chain;
use seda_chains::{chain, Client};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime_sdk::Chain;
use serde::{de::DeserializeOwned, Serialize};
use serde_json::json;
#[cfg(debug_assertions)]
pub(crate) use sub_chain::*;

pub(crate) async fn call<T: DeserializeOwned + Serialize>(
    chain: Chain,
    contract_id: &str,
    method_name: &str,
    deposit: u128,
    args: String,
    node_config: &NodeConfig,
    chains_config: &ChainConfigs,
) -> crate::Result<()> {
    let client = Client::new(&chain, chains_config)?;
    let server_url = match chain {
        Chain::Another => &chains_config.another.chain_rpc_url,
        Chain::Near => &chains_config.near.chain_rpc_url,
    };
    let keypair_ed25519_bytes = Vec::<u8>::from(&node_config.keypair_ed25519);

    let signed_txn = chain::construct_signed_tx(
        chain,
        None,
        &keypair_ed25519_bytes,
        contract_id,
        method_name,
        args.into_bytes(),
        node_config.gas,
        deposit,
        server_url,
    )
    .await?;
    let result = chain::send_tx(chain, client, &signed_txn).await?;
    let result_value = serde_json::from_slice::<T>(&result)?;
    serde_json::to_writer_pretty(
        std::io::stdout(),
        &json!({
                "status": "success",
                "result": result_value,
        }),
    )?;

    Ok(())
}

pub(crate) async fn view<T: DeserializeOwned + Serialize>(
    chain: Chain,
    contract_id: &str,
    method_name: &str,
    // TODO: Consider changing to AsRef<[u8]> for cleaner/ease of use
    args: Option<String>,
    chains_config: &ChainConfigs,
) -> crate::Result<()> {
    let client = Client::new(&chain, chains_config)?;
    let result = chain::view(
        chain,
        client,
        contract_id,
        method_name,
        args.unwrap_or_default().into_bytes(),
    )
    .await?;
    let value = serde_json::from_slice::<T>(&result)?;
    serde_json::to_writer_pretty(std::io::stdout(), &value)?;

    Ok(())
}

'''
'''--- cli/src/cli/commands/node/bridge.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, rpc_params, ws_client::WsClientBuilder};
use seda_config::{AppConfig, PartialChainConfigs};
use seda_runtime_sdk::Chain;

use crate::Result;

#[derive(Debug, Args)]
pub struct Bridge {
    #[arg(short, long)]
    pub chain:                 Chain,
    #[arg(long)]
    pub sub_chain_contract_id: String,
    #[arg(long)]
    pub sub_chain_method_name: String,
    #[arg(long)]
    pub bridge_deposit:        u128,
    #[arg(short, long)]
    pub args:                  String,
}

impl Bridge {
    pub async fn handle(self, config: AppConfig, _chains_config: PartialChainConfigs) -> Result<()> {
        // we don't need to validate configs here because they are using the one's from
        // when the Node was built. unless we should update it to use the one
        // when run from here? but that doesn't make sense to me.
        let client = WsClientBuilder::default()
            .build(format!("ws://{}", &config.seda_server_url))
            .await?;
        let args: Vec<String> = vec![
            "bridge".to_string(),
            self.chain.to_string(),
            self.sub_chain_contract_id,
            self.sub_chain_method_name,
            self.bridge_deposit.to_string(),
            self.args,
        ];

        let response: Vec<String> = client.request("cli", rpc_params!(args)).await?;
        // This is assuming we are always putting valid json in our wasm output...
        // This formatting is also a bit awkward...
        serde_json::to_writer_pretty(std::io::stdout(), &response)?;
        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/node/get/mod.rs ---
mod node;
pub(crate) use node::Node;
mod nodes;
pub(crate) use nodes::Nodes;

'''
'''--- cli/src/cli/commands/node/get/node.rs ---
use clap::Args;
use seda_common::{GetNodeArgs, NodeInfo};
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::view, Result};

/// Returns node information for a given implicit account id, incl. balance and
/// registered public keys.
#[derive(Debug, Args)]
pub struct Node {
    /// SEDA contract account id
    #[arg(short, long)]
    pub contract_id: Option<String>,
    /// Node implicit account id (Ed25519 public key in hex)
    #[arg(short, long)]
    pub node_id:     Option<String>,
}

impl Node {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;
        let node_config = config
            .node
            .to_config(PartialNodeConfig::default())
            .expect("Could not get default node configuration");

        let contract_id = self.contract_id.unwrap_or(node_config.contract_account_id.clone());
        let node_id = self
            .node_id
            .unwrap_or(hex::encode(node_config.keypair_ed25519.public_key.to_bytes()));

        let args = GetNodeArgs::from(node_id).to_string();

        view::<Option<NodeInfo>>(Chain::Near, &contract_id, "get_node", Some(args), &chains_config).await
    }
}

'''
'''--- cli/src/cli/commands/node/get/nodes.rs ---
use clap::Args;
use seda_common::{GetNodesArgs, NodeInfo};
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::view, Result};

/// Returns a list of node information, incl. balance and registered public
/// keys.
#[derive(Debug, Args)]
pub struct Nodes {
    /// Number of items to be returned
    #[arg(short, long, default_value_t = 10)]
    pub limit:       u64,
    /// Number of items to be ommitted in the returned list
    #[arg(short, long, default_value_t = 0)]
    pub offset:      u64,
    /// SEDA contract account id
    #[arg(short, long)]
    pub contract_id: Option<String>,
}

impl Nodes {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;
        let node_config = config
            .node
            .to_config(PartialNodeConfig::default())
            .expect("Could not get default node configuration");

        let contract_id = self.contract_id.unwrap_or(node_config.contract_account_id.clone());

        let args = GetNodesArgs::from((self.limit, self.offset)).to_string();
        view::<Vec<NodeInfo>>(Chain::Near, &contract_id, "get_nodes", Some(args), &chains_config).await
    }
}

'''
'''--- cli/src/cli/commands/node/mod.rs ---
use clap::Subcommand;
use seda_config::{AppConfig, PartialChainConfigs};

use self::peers::Peers;
use crate::Result;

mod bridge;
mod get;
mod peers;
mod register;
mod unregister;
mod update;

#[derive(Debug, Subcommand)]
pub enum Node {
    #[cfg(debug_assertions)]
    // seda node bridge -c near --sub-chain-contract-id "mc.mennat0.testnet" --sub-chain-method-name "get_node"
    // --bridge-deposit 1350000000000000000000 --args '{\"node_id\": \"1\"}'
    /// Run a view method on the specified chain with the args and post it to
    /// the main chain.
    Bridge(bridge::Bridge),
    // seda node get -n 1
    /// Get a node from a given node ID if it exists.
    Get(get::Node),
    // seda node get-nodes
    // seda node get-nodes -l 2 -o 1
    /// Get a list of nodes limited by the given size from an offset.
    GetNodes(get::Nodes),
    // seda node register -s 127.0.0.1:6666 -r 870000000000000000000
    /// Register a node from the given deposit and socket address.
    Register(register::Register),
    // seda node update -n 18 set-socket-address 127.0.0.1:6666
    /// Update a node by either accepting ownership, setting the pending owner,
    /// or changing the socket address.
    Update(update::Update),
    // seda node unregister -n 19
    /// Unregister a node from the given node ID.
    Unregister(unregister::Unregister),
    /// Commands for interacting with the p2p peers
    Peers {
        #[command(subcommand)]
        sub_peers_command: Peers,
    },
}

impl Node {
    #[tokio::main]
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        match self {
            Self::Bridge(bridge) => bridge.handle(config, chains_config).await,
            Self::Get(get_node) => get_node.handle(config, chains_config).await,
            Self::GetNodes(get_nodes) => get_nodes.handle(config, chains_config).await,
            Self::Register(register_node) => register_node.handle(config, chains_config).await,
            Self::Update(update_node) => update_node.handle(config, chains_config).await,
            Self::Unregister(unregister_node) => unregister_node.handle(config, chains_config).await,
            Self::Peers { sub_peers_command } => sub_peers_command.handle(config).await,
        }
    }
}

'''
'''--- cli/src/cli/commands/node/peers/add.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, rpc_params, ws_client::WsClientBuilder};
use seda_config::AppConfig;

use crate::Result;

#[derive(Debug, Args)]
pub struct AddPeer {
    /// A libp2p compatible address (ex. /ip4/127.0.0.1/tcp/44635)
    pub multi_addr: String,
}

impl AddPeer {
    pub async fn handle(self, config: AppConfig) -> Result<()> {
        let client = WsClientBuilder::default()
            .build(format!("ws://{}", &config.seda_server_url))
            .await?;

        client.request("add_peer", rpc_params!(&self.multi_addr)).await?;
        println!("Peer {} has been added", &self.multi_addr);

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/node/peers/discover.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, rpc_params, ws_client::WsClientBuilder};
use seda_config::AppConfig;

use crate::Result;

#[derive(Debug, Args)]
pub struct DiscoverPeers;

impl DiscoverPeers {
    pub async fn handle(self, config: AppConfig) -> Result<()> {
        let client = WsClientBuilder::default()
            .build(format!("ws://{}", &config.seda_server_url))
            .await?;

        client.request("discover_peers", rpc_params!()).await?;

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/node/peers/list.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, rpc_params, ws_client::WsClientBuilder};
use seda_config::AppConfig;
use serde_json::Value;

use crate::Result;

#[derive(Debug, Args)]
pub struct ListPeers;

impl ListPeers {
    pub async fn handle(self, config: AppConfig) -> Result<()> {
        let client = WsClientBuilder::default()
            .build(format!("ws://{}", &config.seda_server_url))
            .await?;

        let response: Value = client.request("list_peers", rpc_params!()).await?;

        serde_json::to_writer_pretty(std::io::stdout(), &response)?;

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/node/peers/mod.rs ---
use clap::Subcommand;
use seda_config::AppConfig;

use crate::Result;

mod add;
mod discover;
mod list;
mod remove;

#[derive(Debug, Subcommand)]
pub enum Peers {
    /// Adds a peer to a running node
    Add(add::AddPeer),
    /// Lists all currently connected peers
    List(list::ListPeers),
    /// Removes a connected peer
    Remove(remove::RemovePeer),
    /// Triggers the node to discover more peers
    Discover(discover::DiscoverPeers),
}

impl Peers {
    pub async fn handle(self, config: AppConfig) -> Result<()> {
        match self {
            Self::Add(add_peer) => add_peer.handle(config).await,
            Self::List(list_peers) => list_peers.handle(config).await,
            Self::Remove(remove_peer) => remove_peer.handle(config).await,
            Self::Discover(discover_peers) => discover_peers.handle(config).await,
        }
    }
}

'''
'''--- cli/src/cli/commands/node/peers/remove.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, rpc_params, ws_client::WsClientBuilder};
use seda_config::AppConfig;

use crate::Result;

#[derive(Debug, Args)]
pub struct RemovePeer {
    /// A libp2p peer id (ex.
    /// 12D3KooWRg13CAzihqGpVfifoeK4nmZ15D3vpZSPfmaDT53CBr9R)
    pub peer_id: String,
}

impl RemovePeer {
    pub async fn handle(self, config: AppConfig) -> Result<()> {
        let client = WsClientBuilder::default()
            .build(format!("ws://{}", &config.seda_server_url))
            .await?;

        client.request("remove_peer", rpc_params!(&self.peer_id)).await?;
        println!("Peer {} has been removed", &self.peer_id);

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/node/register.rs ---
use clap::Args;
use seda_common::RegisterNodeArgs;
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::call, Result};

#[derive(Debug, Args)]
pub struct Register {
    #[arg(short, long)]
    pub register_deposit: u128,
    #[arg(short, long)]
    pub socket_address:   String,
    #[command(flatten)]
    pub node_config:      PartialNodeConfig,
}

impl Register {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;
        let node_config = &config.node.to_config(self.node_config)?;

        let sig = bn254::ECDSA::sign(
            node_config.keypair_bn254.public_key.to_uncompressed()?,
            &node_config.keypair_bn254.private_key,
        )?;
        let args = RegisterNodeArgs {
            multi_addr:       self.socket_address,
            bn254_public_key: node_config.keypair_bn254.public_key.to_uncompressed()?,
            signature:        sig.to_uncompressed()?,
        }
        .to_string();
        call::<Option<serde_json::Value>>(
            Chain::Near,
            &node_config.contract_account_id,
            "register_node",
            self.register_deposit,
            args,
            node_config,
            &chains_config,
        )
        .await
    }
}

'''
'''--- cli/src/cli/commands/node/unregister.rs ---
use clap::Args;
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;
use serde_json::json;

use crate::{cli::commands::call, Result};

#[derive(Debug, Args)]
pub struct Unregister {
    #[arg(short, long)]
    pub node_id:     u64,
    #[command(flatten)]
    pub node_config: PartialNodeConfig,
}

impl Unregister {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;

        let node_config = &config.node.to_config(self.node_config)?;
        let args = json!({
                "node_id": self.node_id.to_string(),
        })
        .to_string();
        call::<String>(
            Chain::Near,
            &node_config.contract_account_id,
            "unregister_node",
            0,
            args,
            node_config,
            &chains_config,
        )
        .await
    }
}

'''
'''--- cli/src/cli/commands/node/update.rs ---
use clap::Args;
use seda_common::UpdateNode;
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::call, Result};

#[derive(Debug, Args)]
pub struct Update {
    #[command(flatten)]
    pub node_config: PartialNodeConfig,
    #[command(subcommand)]
    pub command:     UpdateNode,
}

impl Update {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;
        let node_config = &config.node.to_config(self.node_config)?;

        let args = self.command.to_string();
        call::<Option<serde_json::Value>>(
            Chain::Near,
            &node_config.contract_account_id,
            "update_node",
            0,
            args,
            node_config,
            &chains_config,
        )
        .await
    }
}

'''
'''--- cli/src/cli/commands/run.rs ---
use clap::Args;
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig, PartialP2PConfig};

use crate::Result;

#[derive(Debug, Args)]
pub struct Run {
    #[command(flatten)]
    pub node_config:   PartialNodeConfig,
    #[command(flatten)]
    pub chains_config: PartialChainConfigs,
    #[command(flatten)]
    pub p2p_config:    PartialP2PConfig,
}

impl Run {
    pub fn handle(self, config: AppConfig) -> Result<()> {
        let node_config = config.node.to_config(self.node_config)?;
        let chains_config = config.chains.to_config(self.chains_config)?;
        let p2p_config = config.p2p.to_config(self.p2p_config)?;
        seda_node::run(&config.seda_server_url, node_config, p2p_config, chains_config);

        Ok(())
    }
}

'''
'''--- cli/src/cli/commands/sub_chain/call.rs ---
use clap::Args;
use seda_config::{AppConfig, PartialChainConfigs, PartialNodeConfig};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::call, Result};

#[derive(Debug, Args)]
pub struct Call {
    /// The sub-chain to call.
    chain:           Chain,
    /// The contract ID for the sub-chain.
    contract_id:     String,
    /// The method name to call.
    method_name:     String,
    /// The args to pass to the call method.
    args:            String,
    /// The deposit for the call method.
    call_deposit:    u128,
    #[command(flatten)]
    pub node_config: PartialNodeConfig,
}

impl Call {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let node_config = config.node.to_config(self.node_config)?;
        let chains_config = config.chains.to_config(chains_config)?;
        call::<serde_json::Value>(
            self.chain,
            &self.contract_id,
            &self.method_name,
            self.call_deposit,
            self.args,
            &node_config,
            &chains_config,
        )
        .await
    }
}

'''
'''--- cli/src/cli/commands/sub_chain/mod.rs ---
use clap::Subcommand;
use seda_config::{AppConfig, PartialChainConfigs};

use crate::Result;

mod call;
mod view;

#[derive(Debug, Subcommand)]
pub enum SubChain {
    // seda sub-chain call near mc.mennat0.testnet register_node "{\"socket_address\":\"127.0.0.1:8080\"}"
    // 870000000000000000000
    /// Calls the specified method on the specified chain with the given args
    /// and contract ID.
    Call(Box<call::Call>),
    // TODO maybe a ListMethods command,
    // seda sub-chain view near mc.mennat0.testnet get_active_nodes "{\"offset\":\"0\",\"limit\":\"2\"}"
    /// Views the specified method on the specified chain with the given args
    /// and contract ID.
    View(view::View),
}

impl SubChain {
    #[tokio::main]
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        match self {
            Self::Call(call) => call.handle(config, chains_config).await,
            Self::View(view) => view.handle(config, chains_config).await,
        }
    }
}

'''
'''--- cli/src/cli/commands/sub_chain/view.rs ---
use clap::Args;
use seda_config::{AppConfig, PartialChainConfigs};
use seda_runtime_sdk::Chain;

use crate::{cli::commands::view, Result};

#[derive(Debug, Args)]
pub struct View {
    /// The sub-chain to call.
    chain:       Chain,
    /// The contract ID for the sub-chain.
    contract_id: String,
    /// The method name to view.
    method_name: String,
    /// The args to pass to the view method.
    args:        Option<String>,
}

impl View {
    pub async fn handle(self, config: AppConfig, chains_config: PartialChainConfigs) -> Result<()> {
        let chains_config = config.chains.to_config(chains_config)?;
        view::<serde_json::Value>(
            self.chain,
            &self.contract_id,
            &self.method_name,
            self.args,
            &chains_config,
        )
        .await
    }
}

'''
'''--- cli/src/cli/mod.rs ---
use std::io::Write;

use clap::{command, CommandFactory, Parser, Subcommand};
use clap_complete::{generate, Shell};
use seda_config::{AppConfig, PartialChainConfigs, PartialLoggerConfig};

use crate::Result;

mod commands;
use commands::*;

#[derive(Parser)]
#[command(name = "seda")]
#[command(author = "https://github.com/SedaProtocol")]
#[command(version)]
#[command(propagate_version = true)]
#[command(about = "For interacting with the SEDA protocol.", long_about = None)]
#[command(next_line_help = true)]
pub struct CliOptions {
    #[command(flatten)]
    pub log_options: PartialLoggerConfig,
    #[command(subcommand)]
    pub command:     Command,
}

#[derive(Debug, Subcommand)]
pub enum Command {
    #[cfg(debug_assertions)]
    // seda document
    /// Debug command for helping to generate our CLI.md file.
    Document,
    // seda generate bash > seda.bash
    /// Generates an auto-completion file content for the specified shell.
    Generate {
        /// The shell to generate the auto-completion for.
        shell: Shell,
    },
    // seda node run
    /// Runs the SEDA node.
    Run(Run),
    /// Commands to interact with the SEDA node.
    Node {
        #[command(flatten)]
        chains_config:    PartialChainConfigs,
        #[command(subcommand)]
        sub_node_command: Node,
    },
    #[cfg(debug_assertions)]
    /// Debug commands to help interact with sub-chains.
    SubChain {
        #[command(flatten)]
        chains_config:     PartialChainConfigs,
        #[command(subcommand)]
        sub_chain_command: SubChain,
    },
    /// Creates a new config and secret key (if it doesn't exist) and outputs
    /// it's derived contents
    Init(Init),
}

impl Command {
    pub fn handle(self, config: AppConfig) -> Result<()> {
        match self {
            #[cfg(debug_assertions)]
            Self::Document => {
                // We have to write to the file for OS support.
                // If we ask the user to pipe not all shell pipe commands are UTF-8 by default.
                let help_content = clap_markdown::help_markdown::<CliOptions>();
                let mut path = std::path::PathBuf::from(env!("CARGO_MANIFEST_DIR"));
                path.pop();
                path.push("CLI.md");
                let mut file = std::fs::OpenOptions::new().write(true).open(path)?;
                file.write_all(help_content.as_bytes())?;
                Ok(())
            }
            Self::Init(init_command) => init_command.handle(),
            Self::Generate { shell } => {
                let mut cmd = CliOptions::command();
                let cmd_name = cmd.get_name().to_string();
                generate(shell, &mut cmd, cmd_name, &mut std::io::stdout());
                Ok(())
            }
            Self::Node {
                chains_config,
                sub_node_command,
            } => sub_node_command.handle(config, chains_config),
            Self::Run(run_command) => run_command.handle(config),
            #[cfg(debug_assertions)]
            Self::SubChain {
                chains_config,
                sub_chain_command,
            } => sub_chain_command.handle(config, chains_config),
        }
    }
}

'''
'''--- cli/src/errors.rs ---
use seda_chains::ChainAdapterError;
use seda_config::ConfigError;
use seda_crypto::CryptoError;
use seda_node::NodeError;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum CliError {
    #[error("jsonrpsee client error")]
    JsonRpcClient(#[from] jsonrpsee::core::error::Error),
    #[error(transparent)]
    ChainAdapter(#[from] ChainAdapterError),
    #[error("Config error: {0}")]
    LoadConfig(#[from] ConfigError),
    #[error("Config error: {0}")]
    Config(String),
    #[error(transparent)]
    Node(#[from] NodeError),
    #[error(transparent)]
    Json(#[from] serde_json::Error),
    #[error(transparent)]
    Bn254(#[from] bn254::Error),
    // #[error(transparent)]
    // Crypt(#[from] )
    #[cfg(debug_assertions)]
    #[error(transparent)]
    CLIDocument(#[from] std::io::Error),

    #[error(transparent)]
    Crypto(#[from] CryptoError),
}

impl From<&str> for CliError {
    fn from(value: &str) -> Self {
        Self::from(value.to_string())
    }
}

impl From<String> for CliError {
    fn from(value: String) -> Self {
        Self::Config(value)
    }
}

pub type Result<T, E = CliError> = core::result::Result<T, E>;

'''
'''--- cli/src/main.rs ---
mod cli;
use clap::Parser;
use cli::CliOptions;
mod errors;
use errors::Result;

fn main() -> Result<()> {
    // Load the dotenv file first since our config overloads values from it.
    dotenv::dotenv().ok();
    // Parse the CLI Options.
    let options = CliOptions::parse();
    // Load the config before starting our logger.
    let (config, partial_log_config) = seda_config::create_and_load_or_load_config(None);
    // We hold the guards so logging works properly.
    let _guard = seda_logger::init(&partial_log_config.to_config(options.log_options.clone())?);
    options.command.handle(config)
}

'''
'''--- common/Cargo.toml ---
[package]
name = "seda-common"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[features]
default = []
cli = ["clap"]
test = ["rand"]

[dependencies]
borsh = { workspace = true }
clap = { workspace = true, optional = true, features = ["derive"] }
rand = { workspace = true, optional = true }
seda-crypto = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }

'''
'''--- common/src/lib.rs ---
mod node;
use borsh::{BorshDeserialize, BorshSerialize};
pub use node::*;
use serde::{Deserialize, Serialize};
use serde_json::json;

#[derive(Debug, Clone, Eq, PartialEq, BorshDeserialize, BorshSerialize, Deserialize, Serialize)]
pub struct DepositInfo {
    pub node_ed25519_public_key: Vec<u8>,
    pub amount:                  u128,
}

/// Withdraw request info for one account to a node
#[derive(Debug, Clone, Eq, PartialEq, BorshDeserialize, BorshSerialize, Deserialize, Serialize)]
pub struct WithdrawRequest {
    pub amount: u128,
    pub epoch:  u64, // epoch when funds will be available for withdrawal
}

'''
'''--- common/src/node/get.rs ---
use super::*;

#[derive(Debug, Serialize)]
pub struct GetNodeArgs {
    pub account_id: String,
}

impl From<String> for GetNodeArgs {
    fn from(account_id: String) -> Self {
        Self { account_id }
    }
}

impl ToString for GetNodeArgs {
    fn to_string(&self) -> String {
        let json = json!(self);
        json.to_string()
    }
}

#[derive(Debug, Clone, Default, Eq, PartialEq, BorshDeserialize, BorshSerialize, Deserialize, Serialize)]
pub struct Node {
    pub multi_addr:         String,
    pub balance:            u128,
    pub bn254_public_key:   Vec<u8>,
    pub ed25519_public_key: Vec<u8>,
}

#[derive(Debug, Serialize)]
pub struct GetNodesArgs {
    pub limit:  String,
    pub offset: String,
}

impl From<(u64, u64)> for GetNodesArgs {
    fn from((limit, offset): (u64, u64)) -> Self {
        Self {
            limit:  limit.to_string(),
            offset: offset.to_string(),
        }
    }
}

impl ToString for GetNodesArgs {
    fn to_string(&self) -> String {
        let json = json!(self);
        json.to_string()
    }
}

#[derive(Deserialize, Serialize, BorshDeserialize, BorshSerialize, Debug, Clone)]
pub struct ComputeMerkleRootResult {
    pub merkle_root:         Vec<u8>,
    pub current_slot:        u64,
    pub current_slot_leader: Option<String>,
}

#[derive(Deserialize, Serialize)]
pub struct RequestWithdrawResult {
    pub current_epoch:  u64,
    pub withdraw_epoch: u64,
}

#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, Clone)]
pub struct MainChainConfig {
    pub minimum_stake:            u128,
    pub epoch_delay_for_election: u64,
    pub committee_size:           u64,
    pub withdraw_delay:           u64,
}

'''
'''--- common/src/node/mod.rs ---
mod get;
pub use get::*;

mod register;
pub use register::*;

mod update;
pub use update::*;

use super::*;

#[derive(Debug, Clone, Eq, PartialEq, BorshDeserialize, BorshSerialize, Deserialize, Serialize)]
pub struct NodeInfo {
    // Changed from near_sdk::AccountId, as near_sdk is not compatible on windows machines.
    pub account_id:         String,
    pub multi_addr:         String,
    pub balance:            u128,
    pub bn254_public_key:   Vec<u8>,
    pub ed25519_public_key: Vec<u8>,
}

impl NodeInfo {
    #[cfg(feature = "rand")]
    pub fn random() -> Self {
        use rand::{distributions::Alphanumeric, thread_rng, Rng};
        let rng = &mut thread_rng();
        let account_id_stem = rng
            .sample_iter(&Alphanumeric)
            .take(7)
            .map(char::from)
            .collect::<String>();
        let master_key = seda_crypto::MasterKey::random();
        Self {
            account_id:         format!("{account_id_stem}.testnet"),
            multi_addr:         format!(
                "{}.{}.{}.{}:{}",
                rng.gen_range(1..255),
                rng.gen_range(1..255),
                rng.gen_range(1..255),
                rng.gen_range(1..255),
                rng.gen_range(1..65535)
            ),
            balance:            rng.gen_range(0..u128::MAX),
            bn254_public_key:   master_key
                .derive_bn254(0)
                .unwrap()
                .public_key
                .to_uncompressed()
                .unwrap(),
            ed25519_public_key: master_key.derive_ed25519(0).unwrap().public_key.as_bytes().to_vec(),
        }
    }
}

'''
'''--- common/src/node/register.rs ---
use super::*;

#[derive(Debug, Serialize)]
pub struct RegisterNodeArgs {
    pub multi_addr:       String,
    pub bn254_public_key: Vec<u8>,
    pub signature:        Vec<u8>,
}

impl ToString for RegisterNodeArgs {
    fn to_string(&self) -> String {
        let json = json!(self);
        json.to_string()
    }
}

'''
'''--- common/src/node/update.rs ---
use super::*;

/// Update node commands
#[derive(Debug, Clone, Deserialize, Serialize)]
#[cfg_attr(feature = "cli", derive(clap::Subcommand))]
pub enum UpdateNode {
    SetSocketAddress { new_multi_addr: String },
}

impl ToString for UpdateNode {
    fn to_string(&self) -> String {
        let json = json!(self);
        json.to_string()
    }
}

'''
'''--- config/Cargo.toml ---
[package]
name = "seda-config"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[features]
default = []
cli = ["clap"]
delegate-cli = []

[dependencies]
clap = { workspace = true, features = ["derive", "std"], optional = true }
lazy_static = { workspace = true }
seda-crypto = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
toml = { workspace = true }
tokio = { workspace = true, features = ["sync"] }

'''
'''--- config/src/config.rs ---
use std::path::PathBuf;

use serde::{Deserialize, Serialize};

use crate::{
    env_overwrite,
    errors::{Result, TomlError},
    Config,
};
#[cfg(feature = "cli")]
use crate::{PartialChainConfigs, PartialLoggerConfig, PartialNodeConfig, PartialP2PConfig};

#[derive(Debug, Serialize, Deserialize)]
pub struct PartialAppConfig {
    pub seda_server_address: String,
    pub seda_server_port:    u64,
    #[cfg(feature = "cli")]
    pub chains:              PartialChainConfigs,
    #[cfg(feature = "cli")]
    pub node:                PartialNodeConfig,
    #[cfg(feature = "cli")]
    pub logging:             PartialLoggerConfig,
    #[cfg(feature = "cli")]
    pub p2p:                 PartialP2PConfig,
}

impl Default for PartialAppConfig {
    fn default() -> Self {
        let mut this = Self {
            seda_server_address:             "127.0.0.1".to_string(),
            seda_server_port:                12345,
            #[cfg(feature = "cli")]
            chains:                          PartialChainConfigs::default(),
            #[cfg(feature = "cli")]
            node:                            PartialNodeConfig::default(),
            #[cfg(feature = "cli")]
            logging:                         PartialLoggerConfig::default(),
            #[cfg(feature = "cli")]
            p2p:                             PartialP2PConfig::default(),
        };
        this.overwrite_from_env();
        this
    }
}

impl Config for PartialAppConfig {
    fn template() -> Self {
        Self {
            seda_server_address:             "127.0.0.1".to_string(),
            seda_server_port:                12345,
            #[cfg(feature = "cli")]
            chains:                          PartialChainConfigs::template(),
            #[cfg(feature = "cli")]
            node:                            PartialNodeConfig::template(),
            #[cfg(feature = "cli")]
            logging:                         PartialLoggerConfig::template(),
            #[cfg(feature = "cli")]
            p2p:                             PartialP2PConfig::template(),
        }
    }

    fn overwrite_from_env(&mut self) {
        env_overwrite!(self.seda_server_address, "SEDA_SERVER_ADDRESS");
        env_overwrite!(self.seda_server_port, "SEDA_SERVER_PORT", |p: String| p
            .parse()
            .expect("Invalid port number specified."));
        #[cfg(feature = "cli")]
        self.chains.overwrite_from_env();
        #[cfg(feature = "cli")]
        self.node.overwrite_from_env();
        #[cfg(feature = "cli")]
        self.logging.overwrite_from_env();
    }
}

impl PartialAppConfig {
    /// For reading from a toml file.
    pub fn from_read<R: std::io::Read>(buf: &mut R) -> Result<Self> {
        let mut content = String::new();
        buf.read_to_string(&mut content)?;
        let mut config: Self = toml::from_str(&content).map_err(TomlError::Deserialize)?;
        config.overwrite_from_env();
        Ok(config)
    }

    /// For reading from a toml file from a path.
    pub fn read_from_path(path: PathBuf) -> Result<Self> {
        let mut file = std::fs::OpenOptions::new().read(true).open(path)?;
        Self::from_read(&mut file)
    }

    /// For writing a default configuration file.
    pub fn write_template<W: std::io::Write>(buf: &mut W) -> Result<()> {
        let template = Self::template();
        let content = toml::to_string_pretty(&template).map_err(TomlError::Serialize)?;
        buf.write_all(content.as_bytes())?;
        Ok(())
    }

    /// For creating a default config to a given path.
    pub fn create_template_from_path(path: &PathBuf) -> Result<()> {
        if let Some(prefix) = path.parent() {
            if !prefix.exists() {
                std::fs::create_dir_all(prefix)?;
            }
        }
        let mut file = std::fs::OpenOptions::new().create(true).write(true).open(path)?;
        Self::write_template(&mut file)
    }
}

#[derive(Debug)]
pub struct AppConfig {
    pub seda_server_url: String,
    #[cfg(feature = "cli")]
    pub chains:          PartialChainConfigs,
    #[cfg(feature = "cli")]
    pub node:            PartialNodeConfig,
    #[cfg(feature = "cli")]
    pub p2p:             PartialP2PConfig,
}

impl AsRef<AppConfig> for AppConfig {
    fn as_ref(&self) -> &Self {
        self
    }
}
#[cfg(feature = "cli")]
impl From<PartialAppConfig> for (AppConfig, PartialLoggerConfig) {
    fn from(value: PartialAppConfig) -> Self {
        (
            AppConfig {
                seda_server_url:                format!("{}:{}", value.seda_server_address, value.seda_server_port),
                #[cfg(feature = "cli")]
                chains:                         value.chains,
                #[cfg(feature = "cli")]
                node:                           value.node,
                #[cfg(feature = "cli")]
                p2p:                            value.p2p,
            },
            #[cfg(feature = "cli")]
            value.logging,
        )
    }
}

'''
'''--- config/src/configs/delegate.rs ---
use std::sync::Arc;

use serde::{Deserialize, Serialize};

#[cfg(feature = "delegate-cli")]
use crate::{env_overwrite, ConfigError};
#[cfg(feature = "delegate-cli")]
use crate::{merge_config_cli, Config, Result};

#[cfg(feature = "delegate-cli")]
#[derive(clap::Args)]
/// The configuration for the seda engine.
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct PartialDelegateConfig {
    /// An option to override the validator secret key config value.
    #[arg(long)]
    pub validator_secret_key: Option<String>,
    /// An option to override the account secret key config value. (Used to sign
    /// top-ups and stakings)
    #[arg(long)]
    pub account_secret_key:   Option<String>,
    /// An option to override the signer account ID config value.
    #[arg(long)]
    pub signer_account_id:    Option<String>,
    /// An option to override the delegate contract id
    #[arg(long)]
    pub delegate_contract_id: Option<String>,
    /// An option to override the RPC URL
    #[arg(long)]
    pub rpc_url:              Option<String>,
    /// An option to override the node gas config value.
    #[arg(short, long)]
    pub gas:                  Option<u64>,
}

#[cfg(feature = "delegate-cli")]
impl PartialDelegateConfig {
    pub fn to_config(self, cli_options: Self) -> Result<DelegateConfig> {
        let validator_master_key = merge_config_cli!(self, cli_options, validator_secret_key, Ok(String::new()))?;
        let account_secret_key = merge_config_cli!(
            self,
            cli_options,
            account_secret_key,
            Err(ConfigError::from("node.secret_key"))
        )?;
        let signer_account_id = merge_config_cli!(
            self,
            cli_options,
            signer_account_id,
            Err(ConfigError::from("node.signer_account_id"))
        )?;

        let delegate_contract_id = merge_config_cli!(self, cli_options, delegate_contract_id, Ok(String::new()))?;
        let rpc_url = merge_config_cli!(self, cli_options, rpc_url, Ok(DelegateConfigInner::RPC_URL.to_string()))?;
        let gas = merge_config_cli!(self, cli_options, gas, Ok(DelegateConfigInner::GAS))?;

        Ok(Arc::new(DelegateConfigInner {
            validator_master_key,
            account_secret_key,
            signer_account_id,
            delegate_contract_id,
            rpc_url,
            gas,
        }))
    }
}

#[cfg(feature = "delegate-cli")]
impl Config for PartialDelegateConfig {
    fn template() -> Self {
        Self {
            validator_secret_key: None,
            delegate_contract_id: None,
            account_secret_key:   None,
            signer_account_id:    None,
            rpc_url:              None,
            gas:                  Some(DelegateConfigInner::GAS),
        }
    }

    fn overwrite_from_env(&mut self) {
        env_overwrite!(self.validator_secret_key, "VALIDATOR_SECRET_KEY");
        env_overwrite!(self.account_secret_key, "ACCOUNT_SECRET_KEY");
        env_overwrite!(self.signer_account_id, "SIGNER_ACCOUNT_ID");
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DelegateConfigInner {
    pub account_secret_key:   String,
    pub validator_master_key: String,
    pub signer_account_id:    String,
    pub delegate_contract_id: String,
    pub rpc_url:              String,
    pub gas:                  u64,
}

impl DelegateConfigInner {
    // TODO cfg this
    pub fn test_config() -> DelegateConfig {
        Arc::new(Self {
            delegate_contract_id: String::new(),
            rpc_url:              String::new(),
            validator_master_key: String::new(),
            account_secret_key:   String::new(),
            signer_account_id:    String::new(),
            gas:                  Self::GAS,
        })
    }

    pub fn from_json_str(s: &str) -> DelegateConfig {
        let this = serde_json::from_str(s).unwrap();
        Arc::new(this)
    }
}

impl DelegateConfigInner {
    // 300 Tgas
    pub const GAS: u64 = 300_000_000_000_000;
    pub const RPC_URL: &str = "https://rpc.testnet.near.org";
}

pub type DelegateConfig = Arc<DelegateConfigInner>;

'''
'''--- config/src/configs/logger.rs ---
use std::path::PathBuf;

#[cfg(feature = "cli")]
use {
    crate::{env_overwrite, merge_config_cli, Config, Result},
    serde::{Deserialize, Serialize},
};

#[cfg(feature = "cli")]
#[derive(clap::Args, Debug, Clone, Default, Serialize, Deserialize)]
pub struct PartialLoggerConfig {
    /// The path where you want the log file to write to.
    #[arg(long)]
    pub log_file_path: Option<PathBuf>,
}

#[cfg(feature = "cli")]
impl PartialLoggerConfig {
    pub fn to_config(self, cli_options: Self) -> Result<LoggerConfig> {
        let log_file_path = merge_config_cli!(
            self,
            cli_options,
            log_file_path,
            std::env::current_dir().map_err(|e| crate::ConfigError::FailedToGetCurrentDir(e.to_string()))
        )?;
        Ok(LoggerConfig { log_file_path })
    }
}
#[cfg(feature = "cli")]
impl Config for PartialLoggerConfig {
    fn template() -> Self {
        Self {
            log_file_path: std::env::current_dir().ok(),
        }
    }

    fn overwrite_from_env(&mut self) {
        env_overwrite!(self.log_file_path, "SEDA_LOG_FILE_PATH", |p| Some(PathBuf::from(p)));
    }
}

/// The configuration for the logger.
#[derive(Debug)]
pub struct LoggerConfig {
    pub log_file_path: PathBuf,
}

'''
'''--- config/src/configs/macros.rs ---
#[macro_export]
macro_rules! env_overwrite {
    ($field:expr, $name:expr) => {
        if let Some(var) = std::env::var($name).ok() {
            $field = var.into();
        }
    };
    ($field:expr, $name:expr, $parse:expr) => {
        if let Some(var) = std::env::var($name).ok() {
            $field = $parse(var);
        }
    };
}

#[macro_export]
macro_rules! merge_config_cli {
	($self:ident, $cli:ident, $field:ident, $default:expr, $parse:expr) => {
			match ($self.$field, $cli.$field) {
					(None, None) => $default,
					(None, Some(field))
					| (Some(field), None)
					// CLI option overrides
					| (Some(_), Some(field)) => Ok::<_, $crate::ConfigError>($parse(field)),
			}
	};
	($self:ident, $cli:ident, $field:ident, $default:expr) => {
		match ($self.$field, $cli.$field) {
				(None, None) => $default,
				(None, Some(field))
				| (Some(field), None)
				// CLI option overrides
				| (Some(_), Some(field)) => Ok::<_, $crate::ConfigError>(field),
		}
	};

	($self:ident, $cli:ident, $field:ident) => {
		match ($self.$field, $cli.$field) {
				(None, None) => None,
				(None, Some(field))
				| (Some(field), None)
				// CLI option overrides
				| (Some(_), Some(field)) => Some(field),
		}
	};
}

'''
'''--- config/src/configs/main_chain/another_config.rs ---
use serde::{Deserialize, Serialize};

use crate::Config;

#[derive(Debug, Default, Serialize, Deserialize)]
pub struct PartialAnotherConfig {
    pub chain_rpc_url: Option<String>,
}

impl PartialAnotherConfig {
    pub fn to_config(self) -> AnotherConfig {
        // Fine cause it's just for testing.
        AnotherConfig {
            chain_rpc_url: self
                .chain_rpc_url
                .unwrap_or_else(|| "https://rpc.testnet.near.org".to_string()),
        }
    }
}

impl Config for PartialAnotherConfig {
    fn template() -> Self {
        Self {
            chain_rpc_url: Some("https://rpc.testnet.near.org".to_string()),
        }
    }
}

#[derive(Debug, Clone)]
pub struct AnotherConfig {
    pub chain_rpc_url: String,
}

impl AnotherConfig {
    // TODO cfg this
    pub fn test_config() -> Self {
        Self {
            chain_rpc_url: "https://rpc.testnet.near.org".to_string(),
        }
    }
}

'''
'''--- config/src/configs/main_chain/mod.rs ---
//! Defines a ChainConfig type based on features when compiling.

mod near;
use std::sync::Arc;

pub use near::*;

mod another_config;
pub use another_config::*;
#[cfg(feature = "cli")]
use {
    crate::{Config, Result},
    serde::{Deserialize, Serialize},
};

#[cfg(feature = "cli")]
#[derive(clap::Args, Debug, Default, Serialize, Deserialize)]
pub struct PartialChainConfigs {
    #[arg(skip)]
    pub another: PartialAnotherConfig,
    #[command(flatten)]
    pub near:    PartialNearConfig,
}

#[cfg(feature = "cli")]
impl PartialChainConfigs {
    pub fn to_config(self, cli_options: PartialChainConfigs) -> Result<ChainConfigs> {
        Ok(Arc::new(ChainConfigsInner {
            another: self.another.to_config(),
            near:    self.near.to_config(cli_options.near)?,
        }))
    }
}

#[cfg(feature = "cli")]
impl Config for PartialChainConfigs {
    fn template() -> Self {
        PartialChainConfigs {
            another: PartialAnotherConfig::template(),
            near:    PartialNearConfig::template(),
        }
    }

    fn overwrite_from_env(&mut self) {
        self.another.overwrite_from_env();
        self.near.overwrite_from_env();
    }
}

#[derive(Debug, Clone)]
pub struct ChainConfigsInner {
    pub another: AnotherConfig,
    pub near:    NearConfig,
}

impl ChainConfigsInner {
    // TODO cfg this
    pub fn test_config() -> Arc<Self> {
        Arc::new(Self {
            another: AnotherConfig::test_config(),
            near:    NearConfig::test_config(),
        })
    }
}

pub type ChainConfigs = Arc<ChainConfigsInner>;

'''
'''--- config/src/configs/main_chain/near.rs ---
#[cfg(feature = "cli")]
use {
    crate::{env_overwrite, merge_config_cli, Config, ConfigError, Result},
    serde::{Deserialize, Serialize},
};

#[cfg(feature = "cli")]
#[derive(clap::Parser, Debug, Clone, Default, Serialize, Deserialize)]
pub struct PartialNearConfig {
    /// An option to override the Near chain rpc url config value.
    #[arg(long)]
    pub chain_rpc_url: Option<String>,
}

#[cfg(feature = "cli")]
impl PartialNearConfig {
    pub fn to_config(self, cli_options: Self) -> Result<NearConfig> {
        let chain_rpc_url = merge_config_cli!(
            self,
            cli_options,
            chain_rpc_url,
            Err(ConfigError::from("near.chain_rpc_url"))
        )?;
        Ok(NearConfig { chain_rpc_url })
    }
}

#[cfg(feature = "cli")]
impl Config for PartialNearConfig {
    fn template() -> Self {
        Self {
            chain_rpc_url: Some("https://rpc.testnet.near.org".to_string()),
        }
    }

    fn overwrite_from_env(&mut self) {
        env_overwrite!(self.chain_rpc_url, "SEDA_NEAR_RPC_URL");
    }
}

#[derive(Debug, Clone)]
pub struct NearConfig {
    pub chain_rpc_url: String,
}

impl NearConfig {
    // TODO cfg this
    pub fn test_config() -> Self {
        Self {
            chain_rpc_url: "https://rpc.testnet.near.org".to_string(),
        }
    }
}

'''
'''--- config/src/configs/mod.rs ---
mod logger;
pub use logger::*;

mod macros;
pub use macros::*;

mod main_chain;
pub use main_chain::*;

mod node;
pub use node::*;

mod p2p;
pub use p2p::*;

mod delegate;
pub use delegate::*;

pub trait Config: std::fmt::Debug + Default + serde::Serialize + serde::de::DeserializeOwned {
    fn template() -> Self;
    fn overwrite_from_env(&mut self) {}
}

'''
'''--- config/src/configs/node.rs ---
use std::{path::PathBuf, sync::Arc};

use seda_crypto::{Bn254KeyPair, Ed25519KeyPair, MasterKey};
#[cfg(feature = "cli")]
use serde::{Deserialize, Serialize};

#[cfg(feature = "cli")]
use crate::{env_overwrite, merge_config_cli, Config, ConfigError, Result};

#[cfg(feature = "cli")]
#[derive(clap::Args)]
/// The configuration for the seda engine.
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct PartialNodeConfig {
    /// An option to override the node deposit config value.
    #[arg(short, long)]
    pub deposit:                 Option<String>,
    /// An option to override the node gas config value.
    #[arg(short, long)]
    pub gas:                     Option<u64>,
    /// An option to override the node secret key config value.
    #[arg(long)]
    pub master_key:              Option<String>,
    /// The path where you want to write to the generated secret key.
    #[arg(long)]
    pub seda_sk_file_path:       Option<PathBuf>,
    /// An option to override the node contract account ID config value.
    #[arg(long)]
    pub contract_account_id:     Option<String>,
    /// An option to override the node job manager interval(ms) config value.
    #[arg(long)]
    pub job_manager_interval_ms: Option<u64>,
    /// An option to override the node runtime worker threads config value.
    #[arg(long)]
    pub runtime_worker_threads:  Option<u8>,
    /// An option to override the path of the consensus WASM binary.
    #[arg(long)]
    pub consensus_wasm_path:     Option<PathBuf>,
}

fn default_consensus_wasm_path() -> PathBuf {
    // TODO: Once we have a remote production WASM binary we should move this to the
    // debug only flag
    let mut path_prefix = PathBuf::from(env!("CARGO_MANIFEST_DIR"));

    #[cfg(debug_assertions)]
    path_prefix.push("../target/wasm32-wasi/debug/consensus.wasm");
    #[cfg(not(debug_assertions))]
    path_prefix.push("../target/wasm32-wasi/release/consensus.wasm");

    path_prefix
}

#[cfg(feature = "cli")]
impl PartialNodeConfig {
    pub fn get_node_public_key(self) -> Result<Vec<u8>> {
        let default_cli_options = PartialNodeConfig::default();
        let seda_sk_file_path = merge_config_cli!(
            self,
            default_cli_options,
            seda_sk_file_path,
            Ok(PathBuf::from(NodeConfigInner::SEDA_SECRET_KEY_PATH))
        )?;

        let master_key_config_option = merge_config_cli!(self, default_cli_options, master_key);

        let master_key = if let Some(key) = master_key_config_option {
            MasterKey::try_from(&key)?
        } else if seda_sk_file_path.exists() {
            MasterKey::read_from_path(&seda_sk_file_path)?
        } else {
            let mk = MasterKey::random();
            mk.write_to_path(NodeConfigInner::SEDA_SECRET_KEY_PATH)?;

            mk
        };

        Ok(master_key.derive_ed25519(0)?.public_key.to_bytes().to_vec())
    }

    pub fn to_config(self, cli_options: Self) -> Result<NodeConfig> {
        let deposit = merge_config_cli!(self, cli_options, deposit, Ok(NodeConfigInner::DEPOSIT), |f: String| f
            .parse()
            .unwrap())?;
        let gas = merge_config_cli!(self, cli_options, gas, Ok(NodeConfigInner::GAS))?;

        let seda_sk_file_path = merge_config_cli!(
            self,
            cli_options,
            seda_sk_file_path,
            Ok(PathBuf::from(NodeConfigInner::SEDA_SECRET_KEY_PATH))
        )?;

        let master_key_config_option = merge_config_cli!(self, cli_options, master_key);

        let master_key = if let Some(key) = master_key_config_option {
            MasterKey::try_from(&key)?
        } else if seda_sk_file_path.exists() {
            MasterKey::read_from_path(&seda_sk_file_path)?
        } else {
            let mk = MasterKey::random();
            mk.write_to_path(NodeConfigInner::SEDA_SECRET_KEY_PATH)?;

            mk
        };

        let keypair_ed25519 = master_key.derive_ed25519(0)?;
        let keypair_bn254 = master_key.derive_bn254(0)?;

        let contract_account_id = merge_config_cli!(
            self,
            cli_options,
            contract_account_id,
            Err(ConfigError::from("node.contract_account_id"))
        )?;
        let job_manager_interval_ms = merge_config_cli!(
            self,
            cli_options,
            job_manager_interval_ms,
            Ok(NodeConfigInner::JOB_MANAGER_INTERVAL_MS)
        )?;
        let runtime_worker_threads = merge_config_cli!(
            self,
            cli_options,
            runtime_worker_threads,
            Ok(NodeConfigInner::RUNTIME_WORKER_THREADS),
            |f| f as usize
        )?;

        let consensus_wasm_path: PathBuf = merge_config_cli!(
            self,
            cli_options,
            consensus_wasm_path,
            Ok(default_consensus_wasm_path())
        )?;

        // Make sure we will not run the node with the account secret key
        if std::env::var("ACCOUNT_SECRET_KEY").is_ok() {
            return Err(ConfigError::UnwantedConfig("ACCOUNT_SECRET_KEY".to_string()));
        }

        Ok(Arc::new(NodeConfigInner {
            deposit,
            gas,
            keypair_bn254,
            keypair_ed25519,
            contract_account_id,
            job_manager_interval_ms,
            runtime_worker_threads,
            consensus_wasm_path,
        }))
    }
}

#[cfg(feature = "cli")]
impl Config for PartialNodeConfig {
    fn template() -> Self {
        Self {
            deposit:                 None,
            gas:                     None,
            master_key:              None,
            seda_sk_file_path:       None,
            contract_account_id:     None,
            job_manager_interval_ms: None,
            runtime_worker_threads:  None,
            consensus_wasm_path:     None,
        }
    }

    fn overwrite_from_env(&mut self) {
        env_overwrite!(self.master_key, "SEDA_SECRET_KEY");
    }
}
#[derive(Debug)]
pub struct NodeConfigInner {
    pub deposit:                 u128,
    pub gas:                     u64,
    pub keypair_bn254:           Bn254KeyPair,
    pub keypair_ed25519:         Ed25519KeyPair,
    pub contract_account_id:     String,
    pub job_manager_interval_ms: u64,
    pub runtime_worker_threads:  usize,
    pub consensus_wasm_path:     PathBuf,
}

impl NodeConfigInner {
    // TODO cfg this
    pub fn test_config(master_key: Option<MasterKey>) -> NodeConfig {
        let master_key = master_key.unwrap_or_else(MasterKey::random);

        Arc::new(Self {
            deposit:                 Self::DEPOSIT,
            gas:                     Self::GAS,
            keypair_bn254:           master_key.derive_bn254(0).unwrap(),
            keypair_ed25519:         master_key.derive_ed25519(0).unwrap(),
            contract_account_id:     String::new(),
            job_manager_interval_ms: Self::JOB_MANAGER_INTERVAL_MS,
            runtime_worker_threads:  Self::RUNTIME_WORKER_THREADS,
            consensus_wasm_path:     default_consensus_wasm_path(),
        })
    }
}

impl NodeConfigInner {
    pub const DEPOSIT: u128 = 87 * 10_u128.pow(19);
    pub const GAS: u64 = 300_000_000_000_000;
    pub const JOB_MANAGER_INTERVAL_MS: u64 = 10;
    pub const RUNTIME_WORKER_THREADS: usize = 2;
    pub const SEDA_SECRET_KEY_PATH: &str = "./seda_secret_key";
}

pub type NodeConfig = Arc<NodeConfigInner>;

'''
'''--- config/src/configs/p2p.rs ---
use std::{sync::Arc, time::Duration};

use serde::{Deserialize, Serialize};

#[cfg(feature = "cli")]
use crate::{merge_config_cli, Config, Result};

#[cfg(feature = "cli")]
#[derive(clap::Args)]
/// The configuration for the seda engine.
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct PartialP2PConfig {
    /// The amount of inbound peers we are trying to maintain
    #[arg(long)]
    pub in_peers:               Option<i32>,
    /// The maximum amount of out peers we allow
    #[arg(long)]
    pub out_peers:              Option<i32>,
    /// An option to override the node p2p server address config value.
    #[arg(long)]
    pub p2p_server_address:     Option<String>,
    /// An option to override the node p2p known peers config value.
    #[arg(long)]
    pub p2p_known_peers:        Option<Vec<String>>,
    /// Option to use mDNS to discover peers locally
    #[arg(long)]
    pub disable_mdns:           Option<bool>,
    /// Maximum amount of peers we want to use from mDNS
    #[arg(long)]
    pub max_mdns_peers:         Option<i32>,
    /// Maximum amount of peers we want to use from our manually configured
    /// peers
    #[arg(long)]
    pub max_manual_peers:       Option<i32>,
    /// Option to disable usage of manually configured peers
    #[arg(long)]
    pub disable_manual_peers:   Option<bool>,
    /// Maximum amount of peers we fetch from using Kademlia
    #[arg(long)]
    pub max_kademlia_peers:     Option<i32>,
    /// Option to disable usage of kademlia
    #[arg(long)]
    pub disable_kademlia_peers: Option<bool>,
    /// How long a peer should not be used due a connection issue in ms
    #[arg(long)]
    pub cooldown_duration:      Option<u64>,
}

#[cfg(feature = "cli")]
impl PartialP2PConfig {
    pub fn to_config(self, cli_options: Self) -> Result<P2PConfig> {
        let p2p_server_address = merge_config_cli!(
            self,
            cli_options,
            p2p_server_address,
            Ok(P2PConfigInner::P2P_SERVER_ADDRESS.to_string())
        )?;
        let p2p_known_peers = merge_config_cli!(self, cli_options, p2p_known_peers, Ok(Vec::new()))?;
        let disable_mdns = merge_config_cli!(self, cli_options, disable_mdns, Ok(false))?;
        let max_mdns_peers = merge_config_cli!(self, cli_options, max_mdns_peers, Ok(P2PConfigInner::MAX_MDNS_PEERS))?;
        let in_peers = merge_config_cli!(self, cli_options, in_peers, Ok(P2PConfigInner::IN_PEERS))?;
        let out_peers = merge_config_cli!(self, cli_options, out_peers, Ok(P2PConfigInner::OUT_PEERS))?;
        let max_manual_peers = merge_config_cli!(
            self,
            cli_options,
            max_manual_peers,
            Ok(P2PConfigInner::MAX_MANUAL_PEERS)
        )?;
        let disable_manual_peers = merge_config_cli!(self, cli_options, disable_manual_peers, Ok(false))?;
        let disable_kademlia_peers = merge_config_cli!(self, cli_options, disable_kademlia_peers, Ok(false))?;
        let max_kademlia_peers = merge_config_cli!(
            self,
            cli_options,
            max_kademlia_peers,
            Ok(P2PConfigInner::MAX_KADEMLIA_PEERS)
        )?;

        let cooldown_duration = merge_config_cli!(
            self,
            cli_options,
            cooldown_duration,
            Ok(Duration::from_millis(P2PConfigInner::COOLDOWN_DURATION)),
            Duration::from_millis
        )?;

        Ok(Arc::new(P2PConfigInner {
            p2p_server_address,
            p2p_known_peers,
            disable_mdns,
            max_manual_peers,
            max_mdns_peers,
            disable_manual_peers,
            in_peers,
            out_peers,
            disable_kademlia_peers,
            max_kademlia_peers,
            cooldown_duration,
        }))
    }
}

#[cfg(feature = "cli")]
impl Config for PartialP2PConfig {
    fn template() -> Self {
        Self {
            p2p_server_address:     Some(P2PConfigInner::P2P_SERVER_ADDRESS.to_string()),
            p2p_known_peers:        None,
            disable_mdns:           None,
            disable_manual_peers:   None,
            max_manual_peers:       Some(P2PConfigInner::MAX_MANUAL_PEERS),
            in_peers:               Some(P2PConfigInner::IN_PEERS),
            out_peers:              Some(P2PConfigInner::OUT_PEERS),
            max_mdns_peers:         Some(P2PConfigInner::MAX_MDNS_PEERS),
            disable_kademlia_peers: None,
            max_kademlia_peers:     Some(P2PConfigInner::MAX_KADEMLIA_PEERS),
            cooldown_duration:      Some(P2PConfigInner::COOLDOWN_DURATION),
        }
    }

    fn overwrite_from_env(&mut self) {}
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct P2PConfigInner {
    pub p2p_server_address:     String,
    pub p2p_known_peers:        Vec<String>,
    pub disable_mdns:           bool,
    pub max_mdns_peers:         i32,
    pub in_peers:               i32,
    pub out_peers:              i32,
    pub disable_manual_peers:   bool,
    pub max_manual_peers:       i32,
    pub max_kademlia_peers:     i32,
    pub disable_kademlia_peers: bool,
    pub cooldown_duration:      Duration,
}

impl P2PConfigInner {
    // TODO cfg this
    pub fn test_config() -> P2PConfig {
        Arc::new(Self {
            p2p_server_address:     Self::P2P_SERVER_ADDRESS.to_string(),
            p2p_known_peers:        Vec::new(),
            disable_mdns:           false,
            disable_manual_peers:   false,
            max_manual_peers:       Self::MAX_MANUAL_PEERS,
            in_peers:               Self::IN_PEERS,
            out_peers:              Self::OUT_PEERS,
            max_mdns_peers:         Self::MAX_MDNS_PEERS,
            disable_kademlia_peers: false,
            max_kademlia_peers:     Self::MAX_KADEMLIA_PEERS,
            cooldown_duration:      Duration::from_secs(Self::COOLDOWN_DURATION),
        })
    }

    pub fn from_json_str(s: &str) -> P2PConfig {
        let this = serde_json::from_str(s).unwrap();
        Arc::new(this)
    }
}

impl P2PConfigInner {
    // 30 seconds
    pub const COOLDOWN_DURATION: u64 = 30_000;
    pub const IN_PEERS: i32 = 25;
    pub const MAX_KADEMLIA_PEERS: i32 = 1000;
    pub const MAX_MANUAL_PEERS: i32 = 1000;
    pub const MAX_MDNS_PEERS: i32 = 1000;
    pub const OUT_PEERS: i32 = 100;
    pub const P2P_SERVER_ADDRESS: &str = "/ip4/0.0.0.0/tcp/0";
}

pub type P2PConfig = Arc<P2PConfigInner>;

'''
'''--- config/src/errors.rs ---
use seda_crypto::CryptoError;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum TomlError {
    #[error("Invalid Toml Deserialization: {0}")]
    Deserialize(#[from] toml::de::Error),
    #[error("Invalid Toml Serialization: {0}")]
    Serialize(#[from] toml::ser::Error),
}

#[derive(Error, Debug)]
pub enum ConfigError {
    #[error("Config io error: {0}")]
    ConfigIoError(#[from] std::io::Error),
    #[error(transparent)]
    InvalidTomlConfig(#[from] TomlError),
    #[error("The field `{0}` must be provided.")]
    MustProvideField(String),
    #[error("Failed to get current directory for logging file path: `{0}.")]
    FailedToGetCurrentDir(String),
    #[error("Unwanted config field `{0}`, due security concerns")]
    UnwantedConfig(String),
    #[error(transparent)]
    CryptoError(#[from] CryptoError),
}

impl From<String> for ConfigError {
    fn from(value: String) -> Self {
        Self::MustProvideField(value)
    }
}

impl From<&str> for ConfigError {
    fn from(value: &str) -> Self {
        value.to_string().into()
    }
}

pub type Result<T, E = ConfigError> = core::result::Result<T, E>;

'''
'''--- config/src/lib.rs ---
mod config;
pub use config::*;

mod configs;
pub use configs::*;

mod errors;
#[cfg(not(target_family = "wasm"))]
use std::path::{Path, PathBuf};

pub use errors::*;

// Standard config location for unix apps.
#[cfg(target_family = "unix")]
pub const FULL_CONFIG_PATH: &str = "./config.toml";
// Standard config location for windows apps.
#[cfg(target_family = "windows")]
pub const FULL_CONFIG_PATH: &str = "C:\\ProgramData\\seda-rust\\config.toml";

#[cfg(not(target_family = "wasm"))]
fn default_config_path() -> PathBuf {
    let config_path = std::env::var("SEDA_CONFIG_PATH").unwrap_or_default();
    if !config_path.trim().is_empty() {
        Path::new(&config_path).to_path_buf()
    } else {
        Path::new(FULL_CONFIG_PATH).to_path_buf()
    }
}

#[cfg(not(target_family = "wasm"))]
#[cfg(feature = "cli")]
pub fn create_and_load_or_load_config(config_toml_path: Option<PathBuf>) -> (AppConfig, PartialLoggerConfig) {
    let path: PathBuf = if let Some(config_path) = config_toml_path {
        config_path
    } else {
        default_config_path()
    };

    if !path.exists() {
        if let Err(err) = PartialAppConfig::create_template_from_path(&path) {
            eprintln!("{err}");
            std::process::exit(1);
        }
    }

    match PartialAppConfig::read_from_path(path) {
        Ok(config) => config.into(),
        Err(err) => {
            // TODO we should eventually have better error codes.
            eprintln!("{err}");
            std::process::exit(1);
        }
    }
}

'''
'''--- contracts/.cargo/config.toml ---
[target.wasm32-unknown-unknown]
rustflags = ["-C", "link-arg=-s"]

[build]
target-dir = "../target"

'''
'''--- contracts/Cargo.toml ---
[package]
name = "seda-mainchain"
version = "0.1.0"
edition = "2021"
resolver = "2"
rust-version.workspace = true

[lib]
crate-type = ["cdylib", "lib"]

[dependencies]
bn254 = { workspace = true }
bs58 = { workspace = true }
getrandom = { workspace = true, features = ["custom"], default-features = false}
rand = {workspace = true, features = ["std"], default-features = false }
hex = { workspace = true }
near-bigint = { workspace = true }
near-contract-standards = { workspace = true }
near-sdk = { workspace = true, features = ["legacy", "unit-testing"] }
near-sys = { workspace = true }
schemars = { workspace = true }
seda-common = { workspace = true }
serde = { workspace = true }
sha2 = { workspace = true, features = ["std"] }
uint = { workspace = true }

'''
'''--- contracts/launch-local-near-cluster.sh ---
#!/usr/bin/env bash
# Modified from https://github.com/kurtosis-tech/near-kurtosis-module/blob/master/launch-local-near-cluster.sh

set -euo pipefail   # Bash "strict mode"
script_dirpath="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# ==================================================================================================
#                                             Constants
# ==================================================================================================

VALIDATOR_KEY_PROPERTY_W_QUOTES='"rootValidatorKey":'
NETWORK_ID_PROPERTY="networkName"
MASTER_ACCOUNT_PROPERTY="account_id"
NODE_RPC_URL_PROPERTY="nearNodeRpcUrl"
HELPER_URL_PROPERTY="contractHelperServiceUrl"
EXPLORER_URL_PROPERTY="explorerUrl"
WALLET_URL_PROPERTY="walletUrl"
ALIAS_NAME="local_near"
NEAR_KURTOSIS_DIRPATH="${HOME}/.neartosis"
NEAR_MODULE_IMAGE="kurtosistech/near-kurtosis-module"
KURTOSIS_CMD="kurtosis"
ENCLAVE_ID="near"

# Magic variables that the NEAR CLI will use if set (see https://github.com/near/near-cli/pull/885/files )
NEAR_CLI_NEAR_ENV_ENVVAR="NEAR_ENV"
NEAR_CLI_NETWORK_ID_ENVVAR="NEAR_CLI_LOCALNET_NETWORK_ID"
NEAR_CLI_NODE_URL_ENVVAR="NEAR_NODE_URL"
NEAR_CLI_KEY_FILEPATH_ENVVAR="NEAR_CLI_LOCALNET_KEY_PATH"
NEAR_CLI_WALLET_URL_ENVVAR="NEAR_WALLET_URL"
NEAR_CLI_CONTRACT_HELPER_URL_ENVVAR="NEAR_HELPER_URL"
NEAR_CLI_CONTRACT_HELPER_ACCOUNT_ENVVAR="NEAR_HELPER_ACCOUNT"
NEAR_CLI_EXPLORER_URL_ENVVAR="NEAR_EXPLORER_URL"

# Tells the CLI that it should use the 'localnet' config from its config.json
LOCALNET_NEAR_ENV="local"

# ==================================================================================================
#                                     Cluster Initialization Logic
# ==================================================================================================

if ! [ -d "${NEAR_KURTOSIS_DIRPATH}" ]; then
    if ! mkdir -p "${NEAR_KURTOSIS_DIRPATH}"; then
        echo "Error: No NEAR-in-Kurtosis directory was found at '${NEAR_KURTOSIS_DIRPATH}' so we tried to create it, but an error occurred" >&2
        exit 1
    fi
    echo "Created directory '${NEAR_KURTOSIS_DIRPATH}' for storing all NEAR-in-Kurtosis output"
fi

if ! now_str="$(date +%FT%H.%M.%S)"; then
    echo "Error: Couldn't retrieve the current timestamp, which is necessary for timestamping log & key files" >&2
    exit 1
fi

module_exec_dirpath="${NEAR_KURTOSIS_DIRPATH}/${now_str}"
if ! mkdir -p "${module_exec_dirpath}"; then
    echo "Error: Couldn't create directory '${module_exec_dirpath}' to store the module exec output" >&2
    exit 1
fi

exec_output_filepath="${module_exec_dirpath}/exec-output.log"
# The funky ${1+"${@}"} incantation is how you you feed arguments exactly as-is to a child script in Bash
# ${*} loses quoting and ${@} trips set -e if no arguments are passed, so this incantation says, "if and only if
#  ${1} exists, evaluate ${@}"
if ! "${KURTOSIS_CMD}" module exec --enclave-id "${ENCLAVE_ID}" "${NEAR_MODULE_IMAGE}" ${1+"${@}"} | tee "${exec_output_filepath}"; then
    echo "Error: An error occurred executing module '${NEAR_MODULE_IMAGE}'" >&2
    exit 1
fi

function get_json_property() {
    module_output_filepath="${1:-}"
    property_name="${2:-}"
    if [ -z "${module_output_filepath}" ]; then
        echo "Error: The filepath to the module output must be provided" >&2
        return 1
    fi
    if [ -z "${property_name}" ]; then
        echo "Error: A JSON property name must be provided" >&2
        return 1
    fi
    cat "${module_output_filepath}" | grep "${property_name}" | awk '{print $NF}' | sed 's/^"//' | sed 's/",*$//'
}

validator_key_filepath="${module_exec_dirpath}/validator-key.json"
if ! cat "${exec_output_filepath}" | awk "/${VALIDATOR_KEY_PROPERTY_W_QUOTES}/,/\}/" | sed "s/${VALIDATOR_KEY_PROPERTY_W_QUOTES}//" | sed 's/},/}/' > "${validator_key_filepath}"; then
    echo "Error: Couldn't extract the validator key JSON from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! contract_helper_url="$(get_json_property "${exec_output_filepath}" "${HELPER_URL_PROPERTY}")"; then
    echo "Error: Couldn't extract the contract helper URL from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! network_id="$(get_json_property "${exec_output_filepath}" "${NETWORK_ID_PROPERTY}")"; then
    echo "Error: Couldn't extract the network ID from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! master_account="$(get_json_property "${exec_output_filepath}" "${MASTER_ACCOUNT_PROPERTY}")"; then
    echo "Error: Couldn't extract the master account from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! node_url="$(get_json_property "${exec_output_filepath}" "${NODE_RPC_URL_PROPERTY}")"; then
    echo "Error: Couldn't extract the NEAR node RPC URL from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! helper_url="$(get_json_property "${exec_output_filepath}" "${HELPER_URL_PROPERTY}")"; then
    echo "Error: Couldn't extract the contract helper service URL from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! explorer_url="$(get_json_property "${exec_output_filepath}" "${EXPLORER_URL_PROPERTY}")"; then
    echo "Error: Couldn't extract the explorer URL from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi
if ! wallet_url="$(get_json_property "${exec_output_filepath}" "${WALLET_URL_PROPERTY}")"; then
    echo "Error: Couldn't extract the wallet URL from module exec logfile '${exec_output_filepath}'" >&2
    exit 1
fi

# ==================================================================================================
#                                        Contract deployment
# ==================================================================================================

echo "Deploying contracts to local NEAR network"

export ${NEAR_CLI_NEAR_ENV_ENVVAR}=${LOCALNET_NEAR_ENV}
export ${NEAR_CLI_NETWORK_ID_ENVVAR}=${network_id}
export ${NEAR_CLI_NODE_URL_ENVVAR}=${node_url}
export ${NEAR_CLI_KEY_FILEPATH_ENVVAR}=${validator_key_filepath}
export ${NEAR_CLI_WALLET_URL_ENVVAR}=${wallet_url}
export ${NEAR_CLI_CONTRACT_HELPER_URL_ENVVAR}=${contract_helper_url}
export ${NEAR_CLI_CONTRACT_HELPER_ACCOUNT_ENVVAR}=${master_account}
export ${NEAR_CLI_EXPLORER_URL_ENVVAR}=${explorer_url}

near create-account mainchain.test.near --masterAccount test.near
near deploy --accountId mainchain.test.near --wasmFile $script_dirpath/../target/wasm32-unknown-unknown/release/seda_contracts.wasm
near call mainchain.test.near new --accountId test.near

# ==================================================================================================
#                                              Success
# ==================================================================================================

echo "============================================================ SUCCESS ================================================================================"
echo "  ACTION Paste the following in your terminal to declare the following variables so you can use them:"
echo ""
echo "         export ${NEAR_CLI_NEAR_ENV_ENVVAR}=\"${LOCALNET_NEAR_ENV}\""
echo "         export ${NEAR_CLI_NETWORK_ID_ENVVAR}=\"${network_id}\""
echo "         export ${NEAR_CLI_NODE_URL_ENVVAR}=\"${node_url}\""
echo "         export ${NEAR_CLI_KEY_FILEPATH_ENVVAR}=\"${validator_key_filepath}\""
echo "         export ${NEAR_CLI_WALLET_URL_ENVVAR}=\"${wallet_url}\""
echo "         export ${NEAR_CLI_CONTRACT_HELPER_URL_ENVVAR}=\"${contract_helper_url}\""
echo "         export ${NEAR_CLI_CONTRACT_HELPER_ACCOUNT_ENVVAR}=\"${master_account}\""
echo "         export ${NEAR_CLI_EXPLORER_URL_ENVVAR}=\"${explorer_url}\""
echo "  "
echo "  ACTION Paste the following into your terminal now to use the '${ALIAS_NAME}' command as a replacement for the NEAR CLI for connecting to your"
echo "         local cluster (e.g. '${ALIAS_NAME} login'):"
echo "  "
echo "         alias ${ALIAS_NAME}='${NEAR_CLI_NEAR_ENV_ENVVAR}=\"${LOCALNET_NEAR_ENV}\" ${NEAR_CLI_NETWORK_ID_ENVVAR}=\"${network_id}\" ${NEAR_CLI_NODE_URL_ENVVAR}=\"${node_url}\" ${NEAR_CLI_KEY_FILEPATH_ENVVAR}=\"${validator_key_filepath}\" ${NEAR_CLI_WALLET_URL_ENVVAR}=\"${wallet_url}\" ${NEAR_CLI_CONTRACT_HELPER_URL_ENVVAR}=\"${contract_helper_url}\" ${NEAR_CLI_CONTRACT_HELPER_ACCOUNT_ENVVAR}=\"${master_account}\" ${NEAR_CLI_EXPLORER_URL_ENVVAR}=\"${explorer_url}\" near'"
echo "  "
echo "  ACTION If you want the '${ALIAS_NAME}' command available in all your new terminal windows, add the above alias into your .bash_profile/.bashrc/.zshrc"
echo "         file and open a new terminal window."
echo "  "
echo "  ACTION To stop your cluster, run the following:"
echo ""
echo "         ${KURTOSIS_CMD} enclave stop ${ENCLAVE_ID}"
echo ""
echo "  ACTION To remove your cluster, run:"
echo ""
echo "         ${KURTOSIS_CMD} clean -a"
echo ""
echo "============================================================ SUCCESS ================================================================================"

'''
'''--- contracts/src/batch.rs ---
use bn254::PublicKey;
use near_sdk::{
    borsh::{self, BorshDeserialize, BorshSerialize},
    env,
    log,
    near_bindgen,
    AccountId,
};
use sha2::{Digest, Sha256};

use crate::{manage_storage_deposit, merkle::CryptoHash, MainchainContract, MainchainContractExt};

pub type BatchHeight = u64;
pub type BatchId = CryptoHash;

#[derive(BorshDeserialize, BorshSerialize, Clone)]
pub struct BatchHeader {
    pub height:     BatchHeight,
    pub state_root: CryptoHash,
}

/// Batch data without merkle roots (stored on contract)
#[derive(BorshDeserialize, BorshSerialize, Clone)]
pub struct Batch {
    pub header:       BatchHeader,
    pub transactions: Vec<String>,
}

/// Batch data using merkle roots (used to calculate batch id)
#[derive(BorshDeserialize, BorshSerialize)]
pub struct MerklizedBatch {
    pub prev_root:    BatchId,
    pub header:       BatchHeader,
    pub transactions: Vec<u8>,
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    pub fn get_latest_batch_id(&self) -> BatchId {
        self.batch_ids_by_height.get(&self.num_batches).unwrap_or_default()
    }

    #[payable]
    pub fn post_signed_batch(
        &mut self,
        // Bn254 aggregate signature
        aggregate_signature: Vec<u8>,
        // Bn254 aggregate public key
        aggregate_public_key: Vec<u8>,
        // Ed25519 public keys of bn254 signers
        signers: Vec<AccountId>,
        // Ed25519 signature
        leader_signature: Vec<u8>,
    ) {
        manage_storage_deposit!(self, {
            // update the epoch if necessary
            self.process_epoch();

            log!("slot leader: {}", self.get_current_slot_leader().unwrap());
            log!("block: {}", env::block_height());
            assert_eq!(self.get_current_slot_leader().unwrap(), env::signer_account_id());
            let leader_pk = self
                .active_nodes
                .get(&env::signer_account_id())
                .unwrap()
                .bn254_public_key;
            assert!(
                self.bn254_verify(
                    self.last_generated_random_number.to_le_bytes().to_vec(),
                    leader_signature.clone(),
                    leader_pk
                ),
                "Invalid slot leader signature"
            );
            let current_slot = self.get_current_slot();
            let hash = Sha256::digest([leader_signature, current_slot.to_le_bytes().to_vec()].concat());
            let new_random: near_bigint::U256 = near_bigint::U256::from_little_endian(&hash);
            self.last_generated_random_number = new_random;

            // reconstruct the aggregate public key from signers[] to verify all signers are
            // eligible for this batch while also verifying individual eligibility
            let current_committee = self.committees.get(&self.get_current_epoch()).unwrap();
            assert!(
                current_committee.contains(&signers[0]),
                "Node is not part of the committee"
            );
            let aggregate_public_key_reconstructed = signers.iter().skip(1).fold(
                PublicKey::from_uncompressed(self.active_nodes.get(&signers[0]).unwrap().bn254_public_key).unwrap(),
                |acc, signer| {
                    assert!(current_committee.contains(signer), "Node is not part of the committee");
                    let signer_public_key =
                        PublicKey::from_uncompressed(self.active_nodes.get(signer).unwrap().bn254_public_key).unwrap();
                    acc + signer_public_key
                },
            );
            assert!(
                aggregate_public_key_reconstructed.to_uncompressed().unwrap() == aggregate_public_key,
                "Invalid aggregate public key"
            );

            // verify aggregate signature
            let merkle_root = self.internal_compute_merkle_root();
            assert!(
                self.bn254_verify(merkle_root.clone(), aggregate_signature, aggregate_public_key),
                "Invalid aggregate signature"
            );

            let header = BatchHeader {
                height:     self.num_batches + 1,
                state_root: CryptoHash::default(), // TODO
            };

            // create batch
            let batch = Batch {
                header:       header.clone(),
                transactions: self.data_request_accumulator.to_vec(),
            };

            // calculate batch id
            let batch_id = CryptoHash::hash_borsh(&MerklizedBatch {
                prev_root: self.get_latest_batch_id(),
                header,
                transactions: merkle_root,
            });

            // store batch
            self.num_batches += 1;
            self.batch_by_id.insert(&batch_id, &batch);
            self.batch_ids_by_height.insert(&self.num_batches, &batch_id);

            // clear data request accumulator
            self.data_request_accumulator.clear();
        }); // end manage_storage_deposit
    }
}

'''
'''--- contracts/src/batch_test.rs ---
use std::collections::HashMap;

use near_contract_standards::{fungible_token::core::FungibleTokenCore, storage_management::StorageManagement};
use near_sdk::{json_types::U128, testing_env, AccountId};
use rand::Rng;

use super::test_utils::{
    bn254_sign,
    get_context_for_ft_transfer,
    get_context_for_post_signed_batch,
    get_context_with_deposit,
    get_context_with_deposit_at_block,
    new_contract,
};
use crate::{
    consts::INIT_MINIMUM_STAKE,
    tests::test_utils::{bn254_sign_aggregate, make_test_account, TestAccount},
};

#[test]
fn post_signed_batch() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());

    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let test_acc = make_test_account("test_near".to_string());

    // post some data requests to the accumulator
    testing_env!(get_context_with_deposit(test_acc.clone()));
    contract.post_data_request("data_request_1".to_string());
    contract.post_data_request("data_request_2".to_string());
    contract.post_data_request("data_request_3".to_string());

    let mut test_accounts: HashMap<AccountId, TestAccount> = HashMap::new();
    let num_of_nodes = 20;
    for x in 0..num_of_nodes {
        let acc_str = format!("{x:}_near");
        let acc = make_test_account(acc_str.clone());

        // transfer some tokens
        testing_env!(get_context_with_deposit(dao.clone(),));
        contract.storage_deposit(Some(acc_str.clone().try_into().unwrap()), None);
        testing_env!(get_context_for_ft_transfer(dao.clone()));
        contract.ft_transfer(acc_str.clone().try_into().unwrap(), deposit_amount, None);

        test_accounts.insert(acc_str.parse().unwrap(), acc.clone());
        let sig = bn254_sign(&acc.bn254_private_key.clone(), acc_str.as_bytes());

        testing_env!(get_context_with_deposit(acc.clone()));
        // register nodes
        contract.register_node(
            "0.0.0.0:8080".to_string(),
            acc.bn254_public_key.to_uncompressed().unwrap(),
            sig.to_uncompressed().unwrap(),
        );
        // deposit into contract
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.deposit(deposit_amount, acc.ed25519_public_key.clone().into());
    }

    // time travel and activate nodes
    testing_env!(get_context_with_deposit_at_block(test_acc.clone(), 1000000));
    contract.process_epoch();

    // assert we have committees for this epoch and the next 2
    assert_ne!(contract.get_committee(contract.get_current_epoch()).unwrap().len(), 0);
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 1).unwrap().len(),
        0
    );
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 2).unwrap().len(),
        0
    );
    assert_eq!(contract.get_committee(contract.get_current_epoch() + 3), None);

    // assert each committee has config.committee_size members
    assert_eq!(
        contract.get_committee(contract.get_current_epoch()).unwrap().len(),
        contract.config.committee_size as usize
    );

    // get the merkle root (for all nodes to sign)
    let merkle_root = contract.compute_merkle_root().merkle_root;

    // gather the chosen committee test accounts for signing
    let chosen_committee_account_ids = contract.get_committee(contract.get_current_epoch()).unwrap();
    let chosen_committee: Vec<TestAccount> = chosen_committee_account_ids
        .iter()
        .map(|acc_id| test_accounts.get(acc_id).unwrap().clone())
        .collect();
    let (agg_signature, agg_public_key) = bn254_sign_aggregate(chosen_committee, &merkle_root);

    assert_eq!(contract.num_batches, 0);

    // find the slot leader
    testing_env!(get_context_for_post_signed_batch(test_acc.clone()));
    let slot_leader_account_id = contract.get_current_slot_leader().unwrap();
    let slot_leader_test_account = test_accounts.get(&slot_leader_account_id).unwrap();

    // sign and post the batch
    testing_env!(get_context_for_post_signed_batch(slot_leader_test_account.clone()));
    let num_batches = contract.num_batches;
    let leader_sig = bn254_sign(
        &slot_leader_test_account.bn254_private_key,
        &contract.last_generated_random_number.to_le_bytes(),
    );
    contract.post_signed_batch(
        agg_signature.to_uncompressed().unwrap(),
        agg_public_key.to_uncompressed().unwrap(),
        chosen_committee_account_ids,
        leader_sig.to_uncompressed().unwrap(),
    );
    assert_eq!(contract.num_batches, num_batches + 1);
}

#[test]
#[should_panic(expected = "Invalid slot leader signature")]
fn post_signed_batch_with_wrong_leader_sig() {
    let mut contract = new_contract();
    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let dao = make_test_account("dao_near".to_string());

    let test_acc = make_test_account("test_near".to_string());

    // post some data requests to the accumulator
    testing_env!(get_context_with_deposit(test_acc.clone()));
    contract.post_data_request("data_request_1".to_string());
    contract.post_data_request("data_request_2".to_string());
    contract.post_data_request("data_request_3".to_string());

    let mut test_accounts: HashMap<AccountId, TestAccount> = HashMap::new();
    let num_of_nodes = 20;
    for x in 0..num_of_nodes {
        let acc_str = format!("{x:}_near");
        let acc = make_test_account(acc_str.clone());
        // transfer some tokens
        testing_env!(get_context_with_deposit(dao.clone(),));
        contract.storage_deposit(Some(acc_str.clone().try_into().unwrap()), None);
        testing_env!(get_context_for_ft_transfer(dao.clone()));
        contract.ft_transfer(acc_str.clone().try_into().unwrap(), deposit_amount, None);

        test_accounts.insert(acc_str.parse().unwrap(), acc.clone());
        let sig = bn254_sign(&acc.bn254_private_key.clone(), acc_str.as_bytes());

        testing_env!(get_context_with_deposit(acc.clone()));
        // register nodes
        contract.register_node(
            "0.0.0.0:8080".to_string(),
            acc.bn254_public_key.to_uncompressed().unwrap(),
            sig.to_uncompressed().unwrap(),
        );
        // deposit into contract
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.deposit(deposit_amount, acc.ed25519_public_key.clone().into());
    }

    // time travel and activate nodes
    testing_env!(get_context_with_deposit_at_block(test_acc.clone(), 1000000));
    contract.process_epoch();

    // get the merkle root (for all nodes to sign)
    let merkle_root = contract.compute_merkle_root().merkle_root;

    // gather the chosen committee test accounts for signing
    let chosen_committee_account_ids = contract.get_committee(contract.get_current_epoch()).unwrap();
    let chosen_committee: Vec<TestAccount> = chosen_committee_account_ids
        .iter()
        .map(|acc_id| test_accounts.get(acc_id).unwrap().clone())
        .collect();
    let (agg_signature, agg_public_key) = bn254_sign_aggregate(chosen_committee, &merkle_root);

    // find the slot leader
    testing_env!(get_context_for_post_signed_batch(test_acc.clone()));
    let slot_leader_account_id = contract.get_current_slot_leader().unwrap();
    let slot_leader_test_account = test_accounts.get(&slot_leader_account_id).unwrap();

    // sign and post the batch with an invalid signature
    testing_env!(get_context_for_post_signed_batch(slot_leader_test_account.clone()));
    let num_batches = contract.num_batches;
    let mut rng = rand::thread_rng();
    let random_seed = rng.gen::<u64>();
    let invalid_leader_sig = bn254_sign(&slot_leader_test_account.bn254_private_key, &random_seed.to_le_bytes());
    contract.post_signed_batch(
        agg_signature.to_uncompressed().unwrap(),
        agg_public_key.to_uncompressed().unwrap(),
        chosen_committee_account_ids,
        invalid_leader_sig.to_uncompressed().unwrap(),
    );
    assert_eq!(contract.num_batches, num_batches + 1);
}

#[test]
fn post_empty_signed_batch() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());

    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let test_acc = make_test_account("test_near".to_string());

    // no data requests posted

    let mut test_accounts: HashMap<AccountId, TestAccount> = HashMap::new();
    let num_of_nodes = 2;
    for x in 0..num_of_nodes {
        let acc_str = format!("{x:}_near");
        let acc = make_test_account(acc_str.clone());

        // transfer some tokens
        testing_env!(get_context_with_deposit(dao.clone(),));
        contract.storage_deposit(Some(acc_str.clone().try_into().unwrap()), None);
        testing_env!(get_context_for_ft_transfer(dao.clone()));
        contract.ft_transfer(acc_str.clone().try_into().unwrap(), deposit_amount, None);

        test_accounts.insert(acc_str.parse().unwrap(), acc.clone());
        let sig = bn254_sign(&acc.bn254_private_key.clone(), acc_str.as_bytes());

        testing_env!(get_context_with_deposit(acc.clone()));
        // register nodes
        contract.register_node(
            "0.0.0.0:8080".to_string(),
            acc.bn254_public_key.to_uncompressed().unwrap(),
            sig.to_uncompressed().unwrap(),
        );
        // deposit into contract
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.deposit(deposit_amount, acc.ed25519_public_key.clone().into());
    }

    // time travel and activate nodes
    testing_env!(get_context_with_deposit_at_block(test_acc.clone(), 1000000));
    contract.process_epoch();

    // assert we have committees for this epoch and the next 2
    assert_ne!(contract.get_committee(contract.get_current_epoch()).unwrap().len(), 0);
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 1).unwrap().len(),
        0
    );
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 2).unwrap().len(),
        0
    );
    assert_eq!(contract.get_committee(contract.get_current_epoch() + 3), None);

    // assert each committee has config.committee_size members
    assert_eq!(
        contract.get_committee(contract.get_current_epoch()).unwrap().len(),
        contract.config.committee_size as usize
    );

    // get the merkle root (for all nodes to sign)
    let merkle_root = contract.compute_merkle_root().merkle_root;

    // gather the chosen committee test accounts for signing
    let chosen_committee_account_ids = contract.get_committee(contract.get_current_epoch()).unwrap();
    let chosen_committee: Vec<TestAccount> = chosen_committee_account_ids
        .iter()
        .map(|acc_id| test_accounts.get(acc_id).unwrap().clone())
        .collect();
    let (agg_signature, agg_public_key) = bn254_sign_aggregate(chosen_committee, &merkle_root);

    assert_eq!(contract.num_batches, 0);

    // find the slot leader
    testing_env!(get_context_for_post_signed_batch(test_acc.clone()));
    let slot_leader_account_id = contract.get_current_slot_leader().unwrap();
    let slot_leader_test_account = test_accounts.get(&slot_leader_account_id).unwrap();

    // sign and post the batch
    testing_env!(get_context_for_post_signed_batch(slot_leader_test_account.clone()));
    let num_batches = contract.num_batches;
    let leader_sig = bn254_sign(
        &slot_leader_test_account.bn254_private_key,
        &contract.last_generated_random_number.to_le_bytes(),
    );
    contract.post_signed_batch(
        agg_signature.to_uncompressed().unwrap(),
        agg_public_key.to_uncompressed().unwrap(),
        chosen_committee_account_ids,
        leader_sig.to_uncompressed().unwrap(),
    );
    assert_eq!(contract.num_batches, num_batches + 1);
}

'''
'''--- contracts/src/committee.rs ---
use getrandom::{register_custom_getrandom, Error};
use near_sdk::{env, near_bindgen, AccountId};
use sha2::{Digest, Sha256};

use crate::{MainchainContract, MainchainContractExt};
register_custom_getrandom!(get_random_in_near);

/// Contract private methods
impl MainchainContract {
    pub fn select_committee(&mut self, random_number: near_bigint::U256) -> Vec<AccountId> {
        let validators = self.active_nodes.keys_as_vector().to_vec();
        let mut chosen_committee: Vec<AccountId> = Vec::new();
        let mut chosen_indices: Vec<usize> = Vec::new();
        let mut rerolls = 0;
        // choose `config.committee_size` validators from current active nodes
        for i in 0..self.config.committee_size {
            let hash = Sha256::digest([random_number.to_le_bytes().as_ref(), i.to_le_bytes().as_ref()].concat());
            let prn: near_bigint::U256 = near_bigint::U256::from_little_endian(&hash);
            let mut chosen_index: usize = (prn % validators.len()).as_usize();

            // if the chosen validator index was previously selected, we fetch another one
            while chosen_indices.contains(&chosen_index) {
                rerolls += 1;

                let hash = Sha256::digest(
                    [
                        random_number.to_le_bytes().as_ref(),
                        (i + self.config.committee_size + rerolls).to_le_bytes().as_ref(),
                    ]
                    .concat(),
                );
                let prn: near_bigint::U256 = near_bigint::U256::from_little_endian(&hash);
                chosen_index = (prn % validators.len()).as_usize();
            }
            chosen_indices.push(chosen_index);
            let validator = validators.get(chosen_index).expect("couldn't fetch validator");
            chosen_committee.push(validator.clone());
        }

        chosen_committee
    }
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    pub fn get_committee(&self, epoch: u64) -> Option<Vec<AccountId>> {
        self.committees.get(&epoch)
    }

    pub fn get_last_generated_random_number(&self) -> near_bigint::U256 {
        self.last_generated_random_number
    }

    pub fn get_current_slot_leader(&self) -> Option<AccountId> {
        let current_committee = self.committees.get(&self.get_current_epoch())?;
        let hash = Sha256::digest(
            [
                self.last_generated_random_number.to_le_bytes().as_ref(),
                self.get_current_slot().to_le_bytes().as_ref(),
            ]
            .concat(),
        );
        let prn: near_bigint::U256 = near_bigint::U256::from_little_endian(&hash);
        let chosen_index = (prn % self.config.committee_size).as_usize();
        current_committee.get(chosen_index).cloned()
    }
}

pub fn get_random_in_near(buf: &mut [u8]) -> Result<(), Error> {
    let random = env::random_seed();
    buf.copy_from_slice(&random);
    Ok(())
}

'''
'''--- contracts/src/committee_selection_test.rs ---
use near_contract_standards::{fungible_token::core::FungibleTokenCore, storage_management::StorageManagement};
use near_sdk::{json_types::U128, testing_env};

use super::test_utils::{get_context_view, get_context_with_deposit, new_contract};
use crate::{
    consts::INIT_MINIMUM_STAKE,
    tests::test_utils::{
        bn254_sign,
        get_context_for_ft_transfer,
        get_context_with_deposit_at_block,
        make_test_account,
    },
};

#[test]
fn test_committee_selection() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let bob = make_test_account("bob_near".to_string());

    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let num_of_nodes = 20;
    for x in 1..num_of_nodes {
        let acc_str = format!("{x:}_near");
        let acc = make_test_account(acc_str.clone());

        let sig = bn254_sign(&acc.bn254_private_key, acc_str.as_bytes());
        testing_env!(get_context_with_deposit(dao.clone(),));
        contract.storage_deposit(Some(acc_str.clone().try_into().unwrap()), None);
        testing_env!(get_context_for_ft_transfer(dao.clone()));
        contract.ft_transfer(acc_str.clone().try_into().unwrap(), deposit_amount, None);

        // register node
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.register_node(
            "0.0.0.0:8080".to_string(),
            acc.bn254_public_key.to_uncompressed().unwrap(),
            sig.to_uncompressed().unwrap(),
        );
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.deposit(deposit_amount, acc.ed25519_public_key.into_bytes());

        // check owner and multi_addr
        testing_env!(get_context_view());
        assert_eq!(
            "0.0.0.0:8080".to_string(),
            contract.get_node(acc.account_id).unwrap().multi_addr
        );
    }

    // time travel and activate nodes
    testing_env!(get_context_with_deposit_at_block(bob, 1000000));
    contract.process_epoch();

    // assert we have committees for this epoch and the next 2
    assert_ne!(contract.get_committee(contract.get_current_epoch()).unwrap().len(), 0);
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 1).unwrap().len(),
        0
    );
    assert_ne!(
        contract.get_committee(contract.get_current_epoch() + 2).unwrap().len(),
        0
    );
    assert_eq!(contract.get_committee(contract.get_current_epoch() + 3), None);

    // assert each committee has DEFAULT_COMMITTEE_SIZE members
    for i in 0..3 {
        assert_eq!(
            contract.get_committee(contract.get_current_epoch() + i).unwrap().len() as u64,
            contract.config.committee_size
        );
    }
}

'''
'''--- contracts/src/consts.rs ---
use near_sdk::Gas;

pub const BASE_GAS: u64 = 5_000_000_000_000;
pub const PROMISE_CALL: u64 = 5_000_000_000_000;
pub const GAS_FOR_FT_ON_TRANSFER: Gas = Gas(BASE_GAS + PROMISE_CALL);
pub const DATA_IMAGE_SVG_ICON: &str = "data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 288 288'%3E%3Cg id='l' data-name='l'%3E%3Cpath d='M187.58,79.81l-30.1,44.69a3.2,3.2,0,0,0,4.75,4.2L191.86,103a1.2,1.2,0,0,1,2,.91v80.46a1.2,1.2,0,0,1-2.12.77L102.18,77.93A15.35,15.35,0,0,0,90.47,72.5H87.34A15.34,15.34,0,0,0,72,87.84V201.16A15.34,15.34,0,0,0,87.34,216.5h0a15.35,15.35,0,0,0,13.08-7.31l30.1-44.69a3.2,3.2,0,0,0-4.75-4.2L96.14,186a1.2,1.2,0,0,1-2-.91V104.61a1.2,1.2,0,0,1,2.12-.77l89.55,107.23a15.35,15.35,0,0,0,11.71,5.43h3.13A15.34,15.34,0,0,0,216,201.16V87.84A15.34,15.34,0,0,0,200.66,72.5h0A15.35,15.35,0,0,0,187.58,79.81Z'/%3E%3C/g%3E%3C/svg%3E";
pub const INITIAL_SUPPLY: u128 = 100_000_000_000_000_000_000_000_000_000; // 100,000 SEDA
pub const INIT_MINIMUM_STAKE: u128 = 100_000_000_000_000_000_000_000_000; // 1 SEDA
pub const INIT_EPOCH_DELAY_FOR_ELECTION: u64 = 2;
pub const DEFAULT_COMMITTEE_SIZE: u64 = 2;
pub const SLOTS_PER_EPOCH: u64 = 32;
pub const NEAR_BLOCKS_PER_SEDA_SLOT: u64 = 10; // at 1.2s/block, 12s/slot
pub const EPOCH_COMMITTEES_LOOKAHEAD: u64 = 2;

'''
'''--- contracts/src/dao.rs ---
use near_sdk::{
    borsh::{self, BorshDeserialize, BorshSerialize},
    env,
    near_bindgen,
    serde::{Deserialize, Serialize},
    AccountId,
};

use crate::{
    consts::{DEFAULT_COMMITTEE_SIZE, INIT_EPOCH_DELAY_FOR_ELECTION, INIT_MINIMUM_STAKE},
    MainchainContract,
    MainchainContractExt,
};

#[derive(BorshDeserialize, BorshSerialize, Deserialize, Serialize, Clone)]
pub struct Config {
    pub minimum_stake:            u128,
    pub epoch_delay_for_election: u64,
    pub committee_size:           u64,
    pub withdraw_delay:           u64,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            minimum_stake:            INIT_MINIMUM_STAKE,
            epoch_delay_for_election: INIT_EPOCH_DELAY_FOR_ELECTION,
            committee_size:           DEFAULT_COMMITTEE_SIZE,
            withdraw_delay:           INIT_EPOCH_DELAY_FOR_ELECTION,
        }
    }
}

#[derive(Deserialize, Serialize)]
pub enum UpdateConfig {
    MinimumStake,
    EpochDelayForElection,
}

/// Contract private methods
impl MainchainContract {
    pub(crate) fn assert_dao(&self, account_id: &AccountId) {
        assert_eq!(account_id, &self.dao, "Only DAO can call this method");
    }
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    pub fn get_config(&self) -> Config {
        self.config.clone()
    }

    pub fn update_config(&mut self, key: UpdateConfig, value: u128) {
        self.assert_dao(&env::signer_account_id());
        match key {
            UpdateConfig::MinimumStake => self.config.minimum_stake = value,
            UpdateConfig::EpochDelayForElection => self.config.epoch_delay_for_election = value as u64,
        }
    }
}

'''
'''--- contracts/src/dao_test.rs ---
use near_sdk::testing_env;

use super::test_utils::{get_context, make_test_account, new_contract};
use crate::dao::UpdateConfig;

#[test]
fn update_config() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    testing_env!(get_context(dao));
    contract.update_config(UpdateConfig::MinimumStake, 100);
}

#[test]
#[should_panic(expected = "Only DAO can call this method")]
fn update_config_wrong_account() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    testing_env!(get_context(bob));
    contract.update_config(UpdateConfig::MinimumStake, 100);
}

'''
'''--- contracts/src/data_request.rs ---
use near_sdk::{env, near_bindgen};
use seda_common::ComputeMerkleRootResult;

use crate::{manage_storage_deposit, merkle::merklize, MainchainContract, MainchainContractExt};

/// Contract private methods
impl MainchainContract {
    pub fn internal_compute_merkle_root(&self) -> Vec<u8> {
        merklize(&self.data_request_accumulator.to_vec()).0.try_into().unwrap()
    }
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    #[payable]
    pub fn post_data_request(&mut self, data_request: String) {
        manage_storage_deposit!(self, "require", self.data_request_accumulator.push(&data_request));
    }

    /// Returns the merkle root of the data request accumulator, the current
    /// slot and the current slot leader`
    pub fn compute_merkle_root(&self) -> ComputeMerkleRootResult {
        ComputeMerkleRootResult {
            merkle_root:         self.internal_compute_merkle_root(),
            current_slot:        self.get_current_slot(),
            current_slot_leader: self.get_current_slot_leader().map(|x| x.to_string()),
        }
    }
}

'''
'''--- contracts/src/data_request_test.rs ---
use near_sdk::testing_env;

use super::test_utils::{get_context, get_context_with_deposit, make_test_account, new_contract};

#[test]
fn post_data_request() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());

    // post data request
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.post_data_request("data_request_1".to_string());
    contract.post_data_request("data_request_2".to_string());
    contract.post_data_request("data_request_3".to_string());

    // compute merkle root
    testing_env!(get_context(bob));
    contract.compute_merkle_root();
}

#[should_panic(expected = "Insufficient storage, need 670000000000000000000")]
#[test]
fn post_data_request_no_deposit() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());

    // post data request
    testing_env!(get_context(bob));
    contract.post_data_request("data_request_1".to_string());
}

'''
'''--- contracts/src/epoch.rs ---
use near_sdk::{env, log, near_bindgen};

use crate::{
    consts::{EPOCH_COMMITTEES_LOOKAHEAD, NEAR_BLOCKS_PER_SEDA_SLOT, SLOTS_PER_EPOCH},
    manage_storage_deposit,
    MainchainContract,
    MainchainContractExt,
};

pub type EpochHeight = u64;

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    pub fn get_current_epoch(&self) -> u64 {
        env::block_height() / (NEAR_BLOCKS_PER_SEDA_SLOT * SLOTS_PER_EPOCH)
    }

    #[payable]
    pub fn process_epoch(&mut self) {
        manage_storage_deposit!(self, {
            // check if epoch has already been processed
            let epoch = self.get_current_epoch();
            if epoch <= self.last_processed_epoch {
                log!("Epoch {} has already been processed", epoch);
                return;
            }
            log!("Processing epoch {}", epoch);

            // move pending nodes to active nodes if they are eligible for this epoch
            let eligible_nodes: Vec<_> = self
                .pending_nodes
                .iter()
                .filter(|(_, activation_epoch)| activation_epoch <= &epoch)
                .map(|(account_id, _)| account_id)
                .collect();
            for account_id in eligible_nodes {
                log!("Moving pending node {} to active nodes", account_id);
                self.active_nodes
                    .insert(&account_id, &self.inactive_nodes.get(&account_id).unwrap());
                self.inactive_nodes.remove(&account_id);
                self.pending_nodes.remove(&account_id);
            }
            // log!("pending_nodes: {:?}", self.pending_nodes.to_vec());

            // if bootstrapping phase, wait until there are committee_size active nodes
            if self.bootstrapping_phase {
                if self.active_nodes.len() < self.config.committee_size {
                    log!("Not enough active nodes to exit bootstrapping phase");
                    return;
                }
                self.bootstrapping_phase = false;
                log!("Exiting bootstrapping phase");
                // select committees EPOCH_COMMITTEES_LOOKAHEAD epochs in advance
                for i in 0..EPOCH_COMMITTEES_LOOKAHEAD {
                    let committee = self.select_committee(self.last_generated_random_number);
                    self.committees.insert(&(epoch + i), &committee);
                }
            }

            // select committee from active nodes
            let committee = self.select_committee(self.last_generated_random_number);
            log!("Selected committee for epoch {}: {:?}", epoch, committee);
            self.committees
                .insert(&(epoch + EPOCH_COMMITTEES_LOOKAHEAD), &committee);

            // set last processed epoch to current epoch
            self.last_processed_epoch = epoch;
        });
    }
}

'''
'''--- contracts/src/fungible_token.rs ---
use near_contract_standards::fungible_token::metadata::{FungibleTokenMetadata, FungibleTokenMetadataProvider};
use near_sdk::{json_types::U128, log, near_bindgen, AccountId, Balance, PromiseOrValue};

use crate::{MainchainContract, MainchainContractExt};

/// Private contract
impl MainchainContract {
    pub fn mint(&mut self, account_id: &AccountId, amount: Balance) {
        let new_user_balance = self.token.accounts.get(account_id).unwrap() + amount;
        self.token.accounts.insert(account_id, &new_user_balance);
    }

    pub fn burn(&mut self, account_id: &AccountId, amount: Balance) {
        let new_user_balance = self.token.accounts.get(account_id).unwrap() - amount;
        self.token.accounts.insert(account_id, &new_user_balance);
    }
}

/// Public contract methods
#[near_bindgen]
impl MainchainContract {
    fn on_account_closed(&mut self, account_id: AccountId, balance: Balance) {
        log!("Closed @{} with {}", account_id, balance);
    }

    fn on_tokens_burned(&mut self, account_id: AccountId, amount: Balance) {
        log!("Account @{} burned {}", account_id, amount);
    }
}

near_contract_standards::impl_fungible_token_core!(MainchainContract, token, on_tokens_burned);
near_contract_standards::impl_fungible_token_storage!(MainchainContract, token, on_account_closed);

#[near_bindgen]
impl FungibleTokenMetadataProvider for MainchainContract {
    fn ft_metadata(&self) -> FungibleTokenMetadata {
        self.metadata.get().unwrap()
    }
}

'''
'''--- contracts/src/fungible_token_test.rs ---
use near_contract_standards::{fungible_token::core::FungibleTokenCore, storage_management::StorageManagement};
use near_sdk::{json_types::U128, testing_env};

use super::test_utils::{
    bn254_sign,
    get_context_for_ft_transfer,
    get_context_with_deposit,
    make_test_account,
    new_contract,
};
use crate::consts::{INITIAL_SUPPLY, INIT_MINIMUM_STAKE};

#[test]
fn total_supply() {
    let contract = new_contract();
    assert_eq!(contract.ft_total_supply(), U128(INITIAL_SUPPLY));
}

#[test]
fn simple_transfer() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let transfer_amount = U128(100);

    let initial_dao_balance = contract.ft_balance_of("dao_near".to_string().try_into().unwrap());

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), transfer_amount, None);

    let dao_balance = contract.ft_balance_of("dao_near".to_string().try_into().unwrap());
    let alice_balance = contract.ft_balance_of("alice_near".to_string().try_into().unwrap());

    assert_eq!(dao_balance, U128(initial_dao_balance.0 - transfer_amount.0));
    assert_eq!(alice_balance, transfer_amount);
}

#[test]
fn total_supply_includes_staked() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let bob = make_test_account("bob_near".to_string());
    let bob_signature = bn254_sign(&bob.bn254_private_key, "bob_near".to_string().as_bytes());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to bob
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("bob_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("bob_near".to_string().try_into().unwrap(), deposit_amount, None);

    // bob registers node
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );

    // bob deposits
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.deposit(deposit_amount, bob.ed25519_public_key.into_bytes());

    assert_eq!(contract.ft_total_supply(), U128(INITIAL_SUPPLY));
}

'''
'''--- contracts/src/integration_test.rs ---
use near_sdk::{json_types::U128, testing_env};

use super::test_utils::{
    bn254_sign,
    call_random_data_request,
    get_context_with_deposit_at_block,
    make_register_test_accounts,
    new_contract_with_committee_size,
    ONE_EPOCH,
};
use crate::{
    consts::{INIT_MINIMUM_STAKE, SLOTS_PER_EPOCH},
    tests::test_utils::{bn254_sign_aggregate, get_context_at_block, make_test_account, TestAccount, ONE_SLOT},
};

// Realistic test parameters
// const MAX_DATA_REQUESTS: u32 = 128;
// const COMMITTEE_SIZE: u64 = 128;
// const MAX_NODES: u64 = COMMITTEE_SIZE * 2;
// const TEST_EPOCHS: u64 = 5;

// Fast test parameters
const MAX_DATA_REQUESTS: u32 = 5;
const COMMITTEE_SIZE: u64 = 3;
const MAX_NODES: u64 = COMMITTEE_SIZE;
const TEST_EPOCHS: u64 = 1;

/// Simulates committee selection and posting batches to a set amount of epochs
// TODO: test registering/depositing/withdrawing nodes during an epoch
#[test]
fn integration_test_1() {
    let mut contract = new_contract_with_committee_size(COMMITTEE_SIZE);
    let mut block_number = 0;
    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let dao = make_test_account("dao_near".to_string());
    let test_acc = make_test_account("test_near".to_string());

    // register a random amount of nodes, with a minimum of the bootstrapping
    let test_accounts = make_register_test_accounts(
        &mut contract,
        &dao,
        COMMITTEE_SIZE as usize,
        MAX_NODES as usize,
        deposit_amount,
    );

    // time travel to the beginning of an epoch and activate nodes
    block_number += ONE_EPOCH * 2;
    println!("Block number: {}", block_number);
    testing_env!(get_context_with_deposit_at_block(test_acc.clone(), block_number));
    contract.process_epoch();

    // loop through a predefined number of epochs
    for _ in 0..TEST_EPOCHS {
        testing_env!(get_context_at_block(block_number));
        let epoch = contract.get_current_epoch();
        println!("\nEpoch: {}", epoch);

        // loop through every slot in this epoch and post a batch
        for _ in 0..SLOTS_PER_EPOCH {
            testing_env!(get_context_at_block(block_number));
            assert_eq!(contract.get_current_epoch(), epoch, "Epoch changed unexpectedly");

            // post some data requests to the accumulator
            testing_env!(get_context_with_deposit_at_block(test_acc.clone(), block_number));
            let num_data_requests = call_random_data_request(&mut contract, 0, MAX_DATA_REQUESTS as usize);
            if num_data_requests == 0 {
                println!("No data requests/batch posted for this slot");
                block_number += ONE_SLOT;
                continue;
            }

            // get the merkle root (for all nodes to sign)
            let merkle_root = contract.compute_merkle_root().merkle_root;

            // gather the chosen committee test accounts for signing
            let chosen_committee_account_ids = contract.get_committee(contract.get_current_epoch()).unwrap();
            let chosen_committee: Vec<TestAccount> = chosen_committee_account_ids
                .iter()
                .map(|acc_id| test_accounts.get(acc_id).unwrap().clone())
                .collect();
            let (agg_signature, agg_public_key) = bn254_sign_aggregate(chosen_committee, &merkle_root);

            // find the slot leader
            testing_env!(get_context_at_block(block_number));
            let slot_leader_account_id = contract.get_current_slot_leader().unwrap();
            let slot_leader_test_account = test_accounts.get(&slot_leader_account_id).unwrap();
            println!("Slot leader {} at block {}", slot_leader_account_id, block_number);

            // sign and post the batch
            let num_batches = contract.num_batches;
            testing_env!(get_context_with_deposit_at_block(
                slot_leader_test_account.clone(),
                block_number
            ));
            let leader_sig = bn254_sign(
                &slot_leader_test_account.bn254_private_key,
                &contract.last_generated_random_number.to_le_bytes(),
            );
            contract.post_signed_batch(
                agg_signature.to_uncompressed().unwrap(),
                agg_public_key.to_uncompressed().unwrap(),
                chosen_committee_account_ids,
                leader_sig.to_uncompressed().unwrap(),
            );
            assert_eq!(contract.num_batches, num_batches + 1);

            let slot = contract.get_current_slot();
            println!("Posted batch for slot {}", slot);

            // time travel to the next slot
            block_number += ONE_SLOT;
        }
    }
}

'''
'''--- contracts/src/lib.rs ---
pub mod batch;
pub mod committee;
pub mod consts;
pub mod dao;
pub mod data_request;
pub mod epoch;
pub mod fungible_token;
pub mod merkle;
pub mod node_registry;
pub mod slot;
pub mod storage;
pub mod verify;
use merkle::CryptoHash;
use near_contract_standards::fungible_token::{metadata::FungibleTokenMetadata, FungibleToken};
use near_sdk::{
    borsh::{self, BorshDeserialize, BorshSerialize},
    collections::{LazyOption, LookupMap, UnorderedMap, Vector},
    env,
    json_types::U128,
    near_bindgen,
    AccountId,
    Balance,
    BorshStorageKey,
    PanicOnDefault,
};
use seda_common::{Node, WithdrawRequest};

use crate::{
    batch::{Batch, BatchHeight, BatchId},
    epoch::EpochHeight,
};

/// Collection keys
#[derive(BorshStorageKey, BorshSerialize)]
enum MainchainStorageKeys {
    FungibleToken,
    FungibleTokenMetadata,
    ActiveNodes,
    Committees,
    PendingNodes,
    InactiveNodes,
    DataRequestAccumulator,
    BatchIdsByHeight,
    BatchById,
    NodesByBn254PublicKey,
    NodesByEd25519PublicKey,
    Depositors,
    Depositor { account_hash: [u8; 32] },
    WithdrawRequests,
    WithdrawRequest { account_hash: [u8; 32] },
}

/// Contract global state
#[near_bindgen]
#[derive(PanicOnDefault, BorshDeserialize, BorshSerialize)]
pub struct MainchainContract {
    // Fungible token used for staking
    token:    FungibleToken,
    // Fungible token metadata
    metadata: LazyOption<FungibleTokenMetadata>,
    // DAO account with admin privileges
    dao:      AccountId,
    // Mainchain configuration, changeable by the DAO
    config:   dao::Config,

    // TODO: do all of these need to be UnorderedMaps?
    // Nodes that are eligible to participate in the current epoch
    active_nodes:                 UnorderedMap<AccountId, Node>,
    // Nodes that are not eligible to participate in the current epoch
    inactive_nodes:               UnorderedMap<AccountId, Node>,
    // Sub-set of inactive nodes that are waiting to be activated
    pending_nodes:                UnorderedMap<AccountId, EpochHeight>,
    // Sub-set of active nodes that are part of the committee of the current epoch
    // committees[EPOCH_COMMITTEES_LOOKAHEAD + 1][SLOTS_PER_EPOCH]
    nodes_by_ed25519_public_key:  LookupMap<Vec<u8>, AccountId>,
    depositors:                   LookupMap<AccountId, UnorderedMap<Vec<u8>, Balance>>,
    // committees[EPOCH_COMMITTEES_LOOKAHEAD + 1][config.committee_size]
    committees:                   LookupMap<EpochHeight, Vec<AccountId>>,
    data_request_accumulator:     Vector<String>,
    num_batches:                  BatchHeight,
    batch_ids_by_height:          LookupMap<BatchHeight, BatchId>,
    batch_by_id:                  LookupMap<BatchId, Batch>,
    last_total_balance:           Balance,
    nodes_by_bn254_public_key:    LookupMap<Vec<u8>, AccountId>,
    random_seed:                  CryptoHash,
    bootstrapping_phase:          bool,
    last_processed_epoch:         EpochHeight,
    last_generated_random_number: near_bigint::U256,
    withdraw_requests:            LookupMap<Vec<u8>, LookupMap<AccountId, WithdrawRequest>>,
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    #[init]
    pub fn new(
        dao: AccountId,
        initial_supply: U128,
        metadata: FungibleTokenMetadata,
        committee_size: u64,
        random_seed: near_bigint::U256,
    ) -> Self {
        assert!(!env::state_exists(), "Already initialized");
        assert!(
            env::is_valid_account_id(dao.as_bytes()),
            "The DAO account ID is invalid"
        );
        let config = dao::Config {
            committee_size,
            ..Default::default()
        };

        metadata.assert_valid();
        let mut this = Self {
            token: FungibleToken::new(MainchainStorageKeys::FungibleToken),
            metadata: LazyOption::new(MainchainStorageKeys::FungibleTokenMetadata, Some(&metadata)),
            dao: dao.clone(),
            config,
            active_nodes: UnorderedMap::new(MainchainStorageKeys::ActiveNodes),
            inactive_nodes: UnorderedMap::new(MainchainStorageKeys::InactiveNodes),
            pending_nodes: UnorderedMap::new(MainchainStorageKeys::PendingNodes),
            committees: LookupMap::new(MainchainStorageKeys::Committees),
            data_request_accumulator: Vector::<String>::new(MainchainStorageKeys::DataRequestAccumulator),
            num_batches: 0,
            batch_ids_by_height: LookupMap::new(MainchainStorageKeys::BatchIdsByHeight),
            batch_by_id: LookupMap::new(MainchainStorageKeys::BatchById),
            last_total_balance: 0,
            nodes_by_bn254_public_key: LookupMap::new(MainchainStorageKeys::NodesByBn254PublicKey),
            nodes_by_ed25519_public_key: LookupMap::new(MainchainStorageKeys::NodesByEd25519PublicKey),
            depositors: LookupMap::new(MainchainStorageKeys::Depositors),
            withdraw_requests: LookupMap::new(MainchainStorageKeys::WithdrawRequests),
            random_seed: CryptoHash::default(),
            bootstrapping_phase: true,
            last_processed_epoch: 0,
            last_generated_random_number: random_seed,
        };
        this.token.internal_register_account(&dao);
        this.token.internal_deposit(&dao, initial_supply.into());
        this
    }
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
#[path = ""]
mod tests {
    mod batch_test;
    mod committee_selection_test;
    mod dao_test;
    mod data_request_test;
    mod fungible_token_test;
    mod integration_test;
    mod node_registry_test;
    mod slot_test;
    mod test_utils;
    mod verify_test;
}

'''
'''--- contracts/src/merkle.rs ---
use near_sdk::{
    borsh::{self, BorshDeserialize, BorshSerialize},
    serde::{Deserialize, Serialize},
};
use sha2::Digest;

#[cfg_attr(feature = "deepsize_feature", derive(deepsize::DeepSizeOf))]
#[derive(
    Copy, Clone, PartialEq, Eq, PartialOrd, Debug, Ord, BorshSerialize, BorshDeserialize, Serialize, Deserialize,
)]
pub struct CryptoHash(pub [u8; 32]);

impl Default for CryptoHash {
    fn default() -> Self {
        Self::new()
    }
}

impl CryptoHash {
    pub const fn new() -> Self {
        Self([0; 32])
    }

    /// Calculates hash of borsh-serialised representation of an object.
    pub fn hash_borsh<T: BorshSerialize>(value: &T) -> CryptoHash {
        let mut hasher = sha2::Sha256::default();
        BorshSerialize::serialize(value, &mut hasher).unwrap();
        CryptoHash(hasher.finalize().into())
    }
}

pub type MerkleHash = CryptoHash;

pub fn combine_hash(hash1: &MerkleHash, hash2: &MerkleHash) -> MerkleHash {
    CryptoHash::hash_borsh(&(hash1, hash2))
}

/// Modified from nearcore/core/primitives/src/merkle.rs
pub fn merklize<T: BorshSerialize>(arr: &[T]) -> MerkleHash {
    if arr.is_empty() {
        return MerkleHash::default();
    }
    let mut len = arr.len().next_power_of_two();
    let mut hashes = arr.iter().map(CryptoHash::hash_borsh).collect::<Vec<_>>();

    hashes.sort();

    // degenerate case
    if len == 1 {
        return hashes[0];
    }
    let mut arr_len = arr.len();

    while len > 1 {
        len /= 2;
        for i in 0..len {
            let hash = if 2 * i >= arr_len {
                continue;
            } else if 2 * i + 1 >= arr_len {
                hashes[2 * i]
            } else {
                combine_hash(&hashes[2 * i], &hashes[2 * i + 1])
            };
            hashes[i] = hash;
        }
        arr_len = (arr_len + 1) / 2;
    }
    hashes[0]
}

'''
'''--- contracts/src/node_registry.rs ---
use near_sdk::{
    collections::{LookupMap, UnorderedMap},
    env,
    json_types::{U128, U64},
    log,
    near_bindgen,
    AccountId,
    Balance,
};
use seda_common::{DepositInfo, Node, NodeInfo, RequestWithdrawResult, UpdateNode, WithdrawRequest};

use crate::{manage_storage_deposit, MainchainContract, MainchainContractExt, MainchainStorageKeys};

/// Contract private methods
impl MainchainContract {
    pub fn internal_get_node(&self, account_id: &AccountId) -> Option<Node> {
        let active_node = self.active_nodes.get(account_id);
        if let Some(node) = active_node {
            return Some(node);
        }
        let inactive_node = self.inactive_nodes.get(account_id);
        if let Some(node) = inactive_node {
            return Some(node);
        }
        None
    }

    pub fn get_expect_node(&self, account_id: AccountId) -> Node {
        self.internal_get_node(&account_id)
            .unwrap_or_else(|| panic!("{}", format!("Node {account_id} does not exist")))
    }

    pub fn get_expect_node_by_ed25519_public_key(&self, ed25519_public_key: Vec<u8>) -> Node {
        let account_id = self
            .nodes_by_ed25519_public_key
            .get(&ed25519_public_key)
            .unwrap_or_else(|| panic!("Node {:?} does not exist", ed25519_public_key));
        self.internal_get_node(&account_id)
            .unwrap_or_else(|| panic!("{}", format!("Node {account_id} does not exist")))
    }

    pub fn handle_node_balance_update(&mut self, account_id: &AccountId, node: &Node) {
        // if minimum stake is reached, make sure node is active or set epoch when
        // eligible for committee selection
        if node.balance >= self.config.minimum_stake {
            // minimum stake is reached, if not already an active node, set the epoch when
            // eligible for committee selection
            if self.active_nodes.get(account_id).is_some() {
                // node is already active
                self.active_nodes.insert(account_id, node);
                log!(
                    "Node {} is already active, updated balance to {}",
                    account_id,
                    node.balance
                );
            } else {
                // node is not active, set epoch when eligible for committee selection
                let epoch_when_eligible = self.get_current_epoch() + self.config.epoch_delay_for_election;
                self.inactive_nodes.insert(account_id, node);
                self.pending_nodes.insert(account_id, &epoch_when_eligible);
                log!(
                    "Moving node {} to pending nodes, balance is {}, eligible for committee selection in epoch {}",
                    account_id,
                    node.balance,
                    epoch_when_eligible
                );
            }
        } else {
            // minimum stake is not reached, check if node is active
            if self.active_nodes.get(account_id).is_some() {
                // node is active, remove from active nodes and add to inactive nodes
                self.active_nodes.remove(account_id);
                self.inactive_nodes.insert(account_id, node);
                log!(
                    "Moving node {} to inactive nodes, balance is {}",
                    account_id,
                    node.balance
                );
            } else {
                // node is not active, update inactive nodes
                self.inactive_nodes.insert(account_id, node);
                log!(
                    "Node {} is already inactive, updated balance to {}",
                    account_id,
                    node.balance
                );
            }
        }
    }

    pub fn internal_deposit(&mut self, amount: Balance, ed25519_public_key: Vec<u8>) {
        manage_storage_deposit!(self, "require", {
            let depositor_account_id = env::signer_account_id();

            // subtract from user balance and add to contract balance
            self.burn(&depositor_account_id, amount);
            let mut node = self.get_expect_node_by_ed25519_public_key(ed25519_public_key.clone());
            node.balance += amount;
            let node_account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
            self.handle_node_balance_update(&node_account_id, &node);

            // update info for depositor
            let mut depositor = self.depositors.get(&depositor_account_id).unwrap_or_else(|| {
                UnorderedMap::new(MainchainStorageKeys::Depositor {
                    account_hash: env::sha256_array(depositor_account_id.as_bytes()),
                })
            });
            depositor.insert(&ed25519_public_key, &amount);
            self.depositors.insert(&depositor_account_id, &depositor);

            // update the total balance of the contract
            self.last_total_balance += amount;

            env::log_str(
                format!(
                    "@{} deposited {} into {}'s node. New balance is {}",
                    depositor_account_id, amount, node_account_id, node.balance
                )
                .as_str(),
            );
        });
    }

    pub fn internal_withdraw(&mut self, amount: Balance, ed25519_public_key: Vec<u8>) {
        manage_storage_deposit!(self, {
            assert!(amount > 0, "Withdrawal amount should be positive");
            let mut node = self.get_expect_node_by_ed25519_public_key(ed25519_public_key.clone());
            assert!(node.balance >= amount, "Not enough balance to withdraw");

            // find depositor info for this node
            let depositor_account_id = env::signer_account_id();
            let mut depositor = self
                .depositors
                .get(&depositor_account_id)
                .expect("No deposit info found for this account");
            let deposited = depositor
                .get(&ed25519_public_key)
                .expect("No deposit info found for this node");
            assert!(deposited >= amount, "Not enough balance to withdraw");

            // find withdraw request
            let mut node_withdraw_requests = self.withdraw_requests.get(&ed25519_public_key).unwrap_or_else(|| {
                LookupMap::new(MainchainStorageKeys::WithdrawRequest {
                    account_hash: env::sha256_array(ed25519_public_key.as_slice()),
                })
            });
            // assert there is a pending withdrawal for this depositor
            let withdraw_request = node_withdraw_requests
                .get(&depositor_account_id)
                .expect("No pending withdrawal request found for this account");
            // check that the epoch is valid
            let current_epoch = self.get_current_epoch();
            assert!(
                withdraw_request.epoch <= current_epoch,
                "{} epochs remain until withdrawal is allowed",
                withdraw_request.epoch - current_epoch
            );

            // subtract from contract balance and add to user balance
            self.mint(&depositor_account_id, amount);
            node.balance -= amount;
            let node_account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
            self.handle_node_balance_update(&node_account_id, &node);
            depositor.insert(&ed25519_public_key, &(deposited - amount));
            self.depositors.insert(&depositor_account_id, &depositor);

            // update global balance
            self.last_total_balance -= amount;

            // remove the withdraw request
            node_withdraw_requests.remove(&depositor_account_id);
            self.withdraw_requests
                .insert(&ed25519_public_key, &node_withdraw_requests);

            env::log_str(
                format!(
                    "@{} withdrawing {} from {}'s node. New balance is {}",
                    depositor_account_id, node_account_id, amount, node.balance
                )
                .as_str(),
            );
        });
    }

    pub fn internal_get_nodes(
        &self,
        nodes_map: &UnorderedMap<AccountId, Node>,
        limit: U64,
        offset: U64,
    ) -> Vec<NodeInfo> {
        let mut nodes = Vec::new();
        let mut index = nodes_map.len() - u64::from(offset);
        let limit = u64::from(limit);
        while index > 0 && nodes.len() < limit.try_into().unwrap() {
            if let Some(node_id) = nodes_map.keys().nth(index as usize - 1) {
                let node = nodes_map.get(&node_id).unwrap();
                let human_readable_node = NodeInfo {
                    account_id:         node_id.to_string(),
                    multi_addr:         node.multi_addr,
                    balance:            node.balance,
                    ed25519_public_key: node.ed25519_public_key,
                    bn254_public_key:   node.bn254_public_key,
                };
                nodes.push(human_readable_node);
            }
            index -= 1;
        }
        nodes
    }
}

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    /// Registers a new node while charging for storage usage
    #[payable]
    pub fn register_node(&mut self, multi_addr: String, bn254_public_key: Vec<u8>, signature: Vec<u8>) {
        let account_id = env::signer_account_id();
        let ed25519_public_key = env::signer_account_pk().into_bytes().to_vec();

        // assert unique bn254_public_key and ed25519_public_key
        assert!(
            !self.nodes_by_bn254_public_key.contains_key(&bn254_public_key.clone()),
            "bn254_public_key already exists"
        );
        assert!(
            !self.nodes_by_ed25519_public_key.contains_key(&ed25519_public_key),
            "ed25519_public_key already exists"
        );

        // verify the signature
        assert!(
            self.bn254_verify(account_id.as_bytes().to_vec(), signature, bn254_public_key.clone()),
            "Invalid signature"
        );

        // create a new node
        log!("{} registered node", account_id);
        let node = Node {
            multi_addr,
            balance: 0,
            ed25519_public_key,
            bn254_public_key: bn254_public_key.clone(),
        };

        manage_storage_deposit!(self, "require", {
            // insert in inactive nodes
            self.inactive_nodes.insert(&account_id, &node);

            // insert in nodes_by_bn254_public_key and nodes_by_ed25519_public_key
            self.nodes_by_bn254_public_key.insert(&bn254_public_key, &account_id);
            self.nodes_by_ed25519_public_key
                .insert(&node.ed25519_public_key, &account_id);
        });
    }

    pub fn unregister_node(&mut self, ed25519_public_key: Vec<u8>) {
        manage_storage_deposit!(self, "refund", {
            // assert the signer_account_pk matches the ed25519_public_key
            assert!(
                env::signer_account_pk().into_bytes().to_vec() == ed25519_public_key,
                "Invalid ed25519_public_key"
            );

            // assert the node balance is zero
            let node = self.get_expect_node_by_ed25519_public_key(ed25519_public_key.clone());
            assert!(node.balance == 0, "Node balance is not zero");

            // remove the node
            let account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
            self.inactive_nodes.remove(&account_id);
        });
    }

    /// Updates one of the node's fields
    #[payable]
    pub fn update_node(&mut self, command: UpdateNode) {
        let account_id = env::signer_account_id();
        let mut node = self.get_expect_node(account_id.clone());

        match command {
            UpdateNode::SetSocketAddress { new_multi_addr } => {
                log!("{} updated node multi_addr to {}", account_id, new_multi_addr);
                node.multi_addr = new_multi_addr;
            }
        }

        manage_storage_deposit!(self, {
            if self.active_nodes.get(&account_id).is_some() {
                self.active_nodes.insert(&account_id, &node);
            } else {
                self.inactive_nodes.insert(&account_id, &node);
            }
        });
    }

    /// Deposits the given amount to the given account.
    #[payable]
    pub fn deposit(&mut self, amount: U128, ed25519_public_key: Vec<u8>) {
        let amount: Balance = amount.into();
        self.internal_deposit(amount, ed25519_public_key);
    }

    #[payable]
    pub fn request_withdraw(&mut self, amount: U128, ed25519_public_key: Vec<u8>) -> RequestWithdrawResult {
        manage_storage_deposit!(self, "require", {
            let amount: Balance = amount.into();
            assert!(amount > 0, "Withdrawal amount should be positive");
            let node = self.get_expect_node_by_ed25519_public_key(ed25519_public_key.clone());
            assert!(node.balance >= amount, "Not enough balance to withdraw");

            // find depositor info for this node
            let depositor_account_id = env::signer_account_id();
            let depositor = self
                .depositors
                .get(&depositor_account_id)
                .expect("No deposit info found for this account");
            let deposited = depositor
                .get(&ed25519_public_key)
                .expect("No deposit info found for this node");
            assert!(deposited >= amount, "Not enough balance to withdraw");

            // create a new pending withdrawal
            let mut node_withdraw_requests = self.withdraw_requests.get(&ed25519_public_key).unwrap_or_else(|| {
                LookupMap::new(MainchainStorageKeys::WithdrawRequest {
                    account_hash: env::sha256_array(ed25519_public_key.as_slice()),
                })
            });
            // assert there is no pending withdrawal for this depositor
            assert!(
                node_withdraw_requests.get(&depositor_account_id).is_none(),
                "There is already a pending withdrawal for this account"
            );
            let pending_withdraw = WithdrawRequest {
                amount,
                epoch: self.get_current_epoch() + self.config.withdraw_delay,
            };
            let node_account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
            log!(
                "{} requested withdrawal of {} from {}'s node. Will be available at epoch {}",
                depositor_account_id,
                amount,
                node_account_id,
                self.config.withdraw_delay + self.get_current_epoch()
            );
            node_withdraw_requests.insert(&depositor_account_id, &pending_withdraw);
            self.withdraw_requests
                .insert(&ed25519_public_key, &node_withdraw_requests);
        });
        RequestWithdrawResult {
            current_epoch:  self.get_current_epoch(),
            withdraw_epoch: self.config.withdraw_delay + self.get_current_epoch(),
        }
    }

    #[payable]
    pub fn cancel_withdraw_request(&mut self, ed25519_public_key: Vec<u8>) {
        manage_storage_deposit!(self, {
            let depositor_account_id = env::signer_account_id();
            let mut node_withdraw_requests = self.withdraw_requests.get(&ed25519_public_key).unwrap_or_else(|| {
                LookupMap::new(MainchainStorageKeys::WithdrawRequest {
                    account_hash: env::sha256_array(ed25519_public_key.as_slice()),
                })
            });
            node_withdraw_requests.remove(&depositor_account_id);
            self.withdraw_requests
                .insert(&ed25519_public_key, &node_withdraw_requests);
            let node_account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
            log!(
                "{} cancelled withdrawal request for {}",
                depositor_account_id,
                node_account_id
            );
        });
    }

    /// Withdraws the balance for given account.
    #[payable]
    pub fn withdraw(&mut self, amount: U128, ed25519_public_key: Vec<u8>) {
        let amount: Balance = amount.into();
        self.internal_withdraw(amount, ed25519_public_key);
    }

    /*************** */
    /* View methods */
    /*************** */

    pub fn is_node_active(&self, account_id: AccountId) -> bool {
        self.active_nodes.get(&account_id).is_some()
    }

    /// Returns the balance of the given account.
    pub fn get_node_balance(&self, account_id: AccountId) -> U128 {
        U128(self.internal_get_node(&account_id).unwrap().balance)
    }

    pub fn get_node(&self, account_id: AccountId) -> Option<NodeInfo> {
        let node = self.internal_get_node(&account_id);
        if let Some(node) = node {
            Some(NodeInfo {
                account_id:         account_id.to_string(),
                multi_addr:         node.multi_addr,
                balance:            node.balance,
                ed25519_public_key: node.ed25519_public_key,
                bn254_public_key:   node.bn254_public_key,
            })
        } else {
            None
        }
    }

    pub fn get_inactive_nodes(&self, limit: U64, offset: U64) -> Vec<NodeInfo> {
        self.internal_get_nodes(&self.inactive_nodes, limit, offset)
    }

    pub fn get_active_nodes(&self, limit: U64, offset: U64) -> Vec<NodeInfo> {
        self.internal_get_nodes(&self.active_nodes, limit, offset)
    }

    pub fn get_deposits(&self, account_id: AccountId) -> Vec<DepositInfo> {
        let depositor = self.depositors.get(&account_id).unwrap();
        let mut deposits = Vec::new();
        for deposit in depositor.iter() {
            deposits.push(DepositInfo {
                amount:                  deposit.1,
                node_ed25519_public_key: deposit.0,
            });
        }
        deposits
    }

    pub fn get_node_by_ed25519_public_key(&self, ed25519_public_key: Vec<u8>) -> NodeInfo {
        let account_id = self.nodes_by_ed25519_public_key.get(&ed25519_public_key).unwrap();
        let node = self.internal_get_node(&account_id).unwrap();
        NodeInfo {
            account_id:         account_id.to_string(),
            multi_addr:         node.multi_addr,
            balance:            node.balance,
            ed25519_public_key: node.ed25519_public_key,
            bn254_public_key:   node.bn254_public_key,
        }
    }

    pub fn get_node_by_bn254_public_key(&self, bn254_public_key: Vec<u8>) -> NodeInfo {
        let account_id = self.nodes_by_bn254_public_key.get(&bn254_public_key).unwrap();
        let node = self.internal_get_node(&account_id).unwrap();
        NodeInfo {
            account_id:         account_id.to_string(),
            multi_addr:         node.multi_addr,
            balance:            node.balance,
            ed25519_public_key: node.ed25519_public_key,
            bn254_public_key:   node.bn254_public_key,
        }
    }
}

'''
'''--- contracts/src/node_registry_test.rs ---
use near_contract_standards::{fungible_token::core::FungibleTokenCore, storage_management::StorageManagement};
use near_sdk::{
    json_types::{U128, U64},
    test_utils::get_logs,
    testing_env,
};
use seda_common::{NodeInfo, UpdateNode};

use super::test_utils::{
    bn254_sign,
    get_context,
    get_context_for_ft_transfer,
    get_context_view,
    get_context_with_deposit,
    get_context_with_deposit_at_block,
    new_contract,
};
use crate::{consts::INIT_MINIMUM_STAKE, tests::test_utils::make_test_account};

#[test]
fn register_and_get_node() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    let bob_signature = bn254_sign(&bob.bn254_private_key, bob.account_id.as_bytes());

    // register node
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );
    assert_eq!(get_logs(), vec!["bob_near registered node"]);
    // check owner and multi_addr
    testing_env!(get_context_view());
    assert_eq!(
        "0.0.0.0:8080".to_string(),
        contract.get_node(bob.account_id).unwrap().multi_addr
    );
}

#[test]
#[should_panic(expected = "Insufficient storage, need 6500000000000000000000")]
fn register_not_enough_storage() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    let bob_signature = bn254_sign(&bob.bn254_private_key, bob.account_id.as_bytes());

    // register node
    testing_env!(get_context(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );
}

#[test]
fn set_node_multi_addr() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    let bob_signature = bn254_sign(&bob.bn254_private_key, bob.account_id.as_bytes());

    // register node
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );
    assert_eq!(get_logs(), vec!["bob_near registered node"]);

    // update the multi_addr
    contract.update_node(UpdateNode::SetSocketAddress {
        new_multi_addr: "1.1.1.1:8081".to_string(),
    });

    // check the multi_addr after updating
    testing_env!(get_context_view());
    assert_eq!(
        "1.1.1.1:8081".to_string(),
        contract.get_node(bob.account_id).unwrap().multi_addr
    );
}

#[test]
fn get_nodes() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let bob = make_test_account("bob_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let carol = make_test_account("carol_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);
    let bob_signature = bn254_sign(&bob.bn254_private_key, "bob_near".to_string().as_bytes());
    let alice_signature = bn254_sign(&alice.bn254_private_key, "alice_near".to_string().as_bytes());
    let carol_signature = bn254_sign(&carol.bn254_private_key, "carol_near".to_string().as_bytes());

    // DAO transfers tokens to bob, alice, and carol
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    contract.storage_deposit(Some("bob_near".to_string().try_into().unwrap()), None);
    contract.storage_deposit(Some("carol_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);
    contract.ft_transfer("bob_near".to_string().try_into().unwrap(), deposit_amount, None);
    contract.ft_transfer("carol_near".to_string().try_into().unwrap(), deposit_amount, None);

    // register three nodes
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "1.1.1.1:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );
    testing_env!(get_context_with_deposit(carol.clone()));
    contract.register_node(
        "2.2.2.2:8080".to_string(),
        carol.bn254_public_key.to_uncompressed().unwrap(),
        carol_signature.to_uncompressed().unwrap(),
    );

    // all nodes deposit the minimum stake
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.deposit(deposit_amount, bob.clone().ed25519_public_key.into_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.clone().ed25519_public_key.into_bytes());
    testing_env!(get_context_with_deposit(carol.clone()));
    contract.deposit(deposit_amount, carol.clone().ed25519_public_key.into_bytes());

    // time travel and activate nodes
    testing_env!(get_context_with_deposit_at_block(bob.clone(), 1000000));
    contract.process_epoch();

    // define expected nodes
    let node1 = NodeInfo {
        account_id:         "bob_near".to_string(),
        balance:            deposit_amount.0,
        multi_addr:         "0.0.0.0:8080".to_string(),
        bn254_public_key:   bob.clone().bn254_public_key.to_uncompressed().unwrap(),
        ed25519_public_key: bob.ed25519_public_key.into_bytes(),
    };
    let node2 = NodeInfo {
        account_id:         "alice_near".to_string(),
        balance:            deposit_amount.0,
        multi_addr:         "1.1.1.1:8080".to_string(),
        bn254_public_key:   alice.clone().bn254_public_key.to_uncompressed().unwrap(),
        ed25519_public_key: alice.ed25519_public_key.into_bytes(),
    };
    let node3 = NodeInfo {
        account_id:         "carol_near".to_string(),
        balance:            deposit_amount.0,
        multi_addr:         "2.2.2.2:8080".to_string(),
        bn254_public_key:   carol.clone().bn254_public_key.to_uncompressed().unwrap(),
        ed25519_public_key: carol.ed25519_public_key.into_bytes(),
    };

    // get the first node
    testing_env!(get_context_view());
    let get_node = contract.get_node("bob_near".to_string().try_into().unwrap());
    assert_eq!(get_node.unwrap(), node1);

    // check the latest 2 nodes
    let latest_2_nodes = contract.get_active_nodes(U64(2), U64(0));
    assert_eq!(latest_2_nodes, vec![node3.clone(), node2.clone()]);

    // check the latest 3 nodes
    let latest_3_nodes = contract.get_active_nodes(U64(100), U64(0));
    assert_eq!(latest_3_nodes, vec![node3, node2.clone(), node1.clone()]);

    // check offset of 1
    let latest_nodes_offset = contract.get_active_nodes(U64(100), U64(1));
    assert_eq!(latest_nodes_offset, vec![node2, node1]);

    // assert all nodes are activated
    let inactive_nodes = contract.get_inactive_nodes(U64(100), U64(0));
    assert_eq!(inactive_nodes, vec![]);
}

#[test]
#[should_panic(expected = "bn254_public_key already exists")]
fn duplicated_key() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let bob_signature = bn254_sign(&bob.bn254_private_key, "bob_near".to_string().as_bytes());
    let alice_signature = bn254_sign(&bob.bn254_private_key, "alice_near".to_string().as_bytes());

    // bob registers node
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );

    // alice registers node with duplicated key
    testing_env!(get_context_with_deposit(alice));
    contract.register_node(
        "1.1.1.1:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );
}

#[test]
fn deposit_withdraw() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check alice's balance is now zero
    assert_eq!(
        contract.ft_balance_of("alice_near".to_string().try_into().unwrap()),
        U128(0)
    );

    // check alice is not active
    assert!(!contract.is_node_active("alice_near".to_string().try_into().unwrap()),);

    // check alice's deposited amount
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, deposit_amount);

    // alice requests withdraw
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.request_withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // alice withdraws
    testing_env!(get_context_with_deposit_at_block(alice.clone(), 1000000));
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check alice's balance has increased again and the node balance has decreased
    assert_eq!(
        contract.ft_balance_of("alice_near".to_string().try_into().unwrap()),
        deposit_amount
    );
    assert_eq!(
        contract.get_node_balance("alice_near".to_string().try_into().unwrap()),
        U128(0)
    );

    // unregister node now that balance is zero
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.unregister_node(alice.ed25519_public_key.as_bytes().to_vec());
}

#[test]
#[should_panic(expected = "No deposit info found for this account")]
fn withdraw_wrong_account() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let bob = make_test_account("bob_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check alice's balance is now zero
    assert_eq!(
        contract.ft_balance_of("alice_near".to_string().try_into().unwrap()),
        U128(0)
    );

    // check alice is not active
    assert!(!contract.is_node_active("alice_near".to_string().try_into().unwrap()));

    // check alice's deposited amount
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, deposit_amount);

    // bob tries withdrawing from alice's account
    testing_env!(get_context(bob));
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
}

#[test]
fn deposit_withdraw_one_node_two_depositors() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let bob = make_test_account("bob_near".to_string());
    let deposit_amount = U128(100_000_000_000_000_000_000_000);

    // DAO transfers tokens to alice and bob
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    contract.storage_deposit(Some("bob_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);
    contract.ft_transfer("bob_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice and bob deposit into alice's pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check total deposited amount is now 2x deposit amount
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(deposit_amount.0 * 2));

    // alice and bob request withdraws
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.request_withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.request_withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // alice and bob withdraw
    testing_env!(get_context_with_deposit_at_block(alice.clone(), 1000000));
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
    testing_env!(get_context_with_deposit_at_block(bob, 1000000));
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check total deposited amount is now 0
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(0));
}

#[test]
fn deposit_withdraw_two_nodes_one_depositor() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let bob = make_test_account("bob_near".to_string());
    let deposit_amount = U128(100_000_000_000_000_000_000_000);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice and bob register nodes
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    let bob_signature = bn254_sign(&bob.bn254_private_key, bob.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );
    testing_env!(get_context_with_deposit(bob.clone()));
    contract.register_node(
        "1.1.1.1:8080".to_string(),
        bob.bn254_public_key.to_uncompressed().unwrap(),
        bob_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into alice and bob's pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(U128(deposit_amount.0 / 2), alice.ed25519_public_key.as_bytes().to_vec());
    contract.deposit(U128(deposit_amount.0 / 2), bob.ed25519_public_key.as_bytes().to_vec());

    // assert alice has deposits in 2 pools
    let alice_deposits = contract.get_deposits(alice.clone().account_id);
    assert_eq!(alice_deposits.len(), 2);

    // check alice's balance is now zero
    assert_eq!(
        contract.ft_balance_of("alice_near".to_string().try_into().unwrap()),
        U128(0)
    );

    // check deposited amounts for both pools is deposit amount / 2
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(deposit_amount.0 / 2));
    let node_balance = contract.get_node_balance("bob_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(deposit_amount.0 / 2));

    // alice requests withdraws from both pools
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.request_withdraw(U128(deposit_amount.0 / 2), alice.ed25519_public_key.as_bytes().to_vec());
    contract.request_withdraw(U128(deposit_amount.0 / 2), bob.ed25519_public_key.as_bytes().to_vec());

    // alice withdraws from both pools
    testing_env!(get_context_with_deposit_at_block(alice.clone(), 1000000));
    contract.withdraw(U128(deposit_amount.0 / 2), alice.ed25519_public_key.as_bytes().to_vec());
    contract.withdraw(U128(deposit_amount.0 / 2), bob.ed25519_public_key.as_bytes().to_vec());

    // check alice's balance is now original deposit amount
    assert_eq!(
        contract.ft_balance_of("alice_near".to_string().try_into().unwrap()),
        deposit_amount
    );

    // check deposited amounts for both pools is 0
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(0));
    let node_balance = contract.get_node_balance("bob_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, U128(0));
}

#[test]
#[should_panic]
fn deposit_nonexistent_node() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
}

#[test]
#[should_panic(expected = "No pending withdrawal request found for this account")]
fn cancel_withdraw_request() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check alice's deposited amount
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, deposit_amount);

    // alice requests withdraw
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.request_withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // alice cancels withdraw
    testing_env!(get_context_with_deposit_at_block(alice.clone(), 1000000));
    contract.cancel_withdraw_request(alice.ed25519_public_key.as_bytes().to_vec());

    // try to withdraw after cancelling
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
}

#[test]
#[should_panic(expected = "2 epochs remain until withdrawal is allowed")]
fn withdraw_before_epoch() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // check alice's deposited amount
    let node_balance = contract.get_node_balance("alice_near".to_string().try_into().unwrap());
    assert_eq!(node_balance, deposit_amount);

    // alice requests withdraw
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.request_withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // alice withdraws without waiting
    contract.withdraw(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());
}

#[test]
#[should_panic(expected = "Node balance is not zero")]
fn unregister_nonzero_node() {
    let mut contract = new_contract();
    let dao = make_test_account("dao_near".to_string());
    let alice = make_test_account("alice_near".to_string());
    let deposit_amount = U128(INIT_MINIMUM_STAKE);

    // DAO transfers tokens to alice
    testing_env!(get_context_with_deposit(dao.clone()));
    contract.storage_deposit(Some("alice_near".to_string().try_into().unwrap()), None);
    testing_env!(get_context_for_ft_transfer(dao));
    contract.ft_transfer("alice_near".to_string().try_into().unwrap(), deposit_amount, None);

    // alice registers node
    let alice_signature = bn254_sign(&alice.bn254_private_key, alice.account_id.as_bytes());
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.register_node(
        "0.0.0.0:8080".to_string(),
        alice.bn254_public_key.to_uncompressed().unwrap(),
        alice_signature.to_uncompressed().unwrap(),
    );

    // alice deposits into pool
    testing_env!(get_context_with_deposit(alice.clone()));
    contract.deposit(deposit_amount, alice.ed25519_public_key.as_bytes().to_vec());

    // alice tries to unregister node
    contract.unregister_node(alice.ed25519_public_key.as_bytes().to_vec());
}

'''
'''--- contracts/src/slot.rs ---
use near_sdk::{env, near_bindgen};

use crate::{consts::NEAR_BLOCKS_PER_SEDA_SLOT, MainchainContract, MainchainContractExt};

/// Contract public methods
#[near_bindgen]
impl MainchainContract {
    pub fn get_current_slot(&self) -> u64 {
        env::block_height() / NEAR_BLOCKS_PER_SEDA_SLOT
    }
}

'''
'''--- contracts/src/slot_test.rs ---
use near_sdk::testing_env;

use super::test_utils::{get_context_at_block, new_contract};
use crate::consts::{NEAR_BLOCKS_PER_SEDA_SLOT, SLOTS_PER_EPOCH};

#[test]
fn get_current_slot() {
    let contract = new_contract();

    testing_env!(get_context_at_block(0)); // block 0
    assert_eq!(contract.get_current_slot(), 0); // slot 0

    testing_env!(get_context_at_block(NEAR_BLOCKS_PER_SEDA_SLOT - 1)); // block 9
    assert_eq!(contract.get_current_slot(), 0); // slot 0

    testing_env!(get_context_at_block(NEAR_BLOCKS_PER_SEDA_SLOT)); // block 10
    assert_eq!(contract.get_current_slot(), 1); // slot 1
}

#[test]
fn get_current_epoch() {
    let contract = new_contract();

    testing_env!(get_context_at_block(0)); // block 0
    assert_eq!(contract.get_current_epoch(), 0); // epoch 0

    testing_env!(get_context_at_block(NEAR_BLOCKS_PER_SEDA_SLOT * SLOTS_PER_EPOCH - 1)); // block 319
    assert_eq!(contract.get_current_slot(), 31); // slot 31
    assert_eq!(contract.get_current_epoch(), 0); // epoch 0

    testing_env!(get_context_at_block(NEAR_BLOCKS_PER_SEDA_SLOT * SLOTS_PER_EPOCH)); // block 320
    assert_eq!(contract.get_current_slot(), 32); // slot 32
    assert_eq!(contract.get_current_epoch(), 1); // epoch 1
}

'''
'''--- contracts/src/storage.rs ---
use near_sdk::{env, log, Promise};

use crate::MainchainContract;

#[macro_export]
macro_rules! manage_storage_deposit {
    // storage is assumed to increase
    ($self:ident,"require", $expression:expr) => {
        let initial_storage_usage = env::storage_usage();
        $expression;
        $self.require_storage_deposit(initial_storage_usage);
    };

    // storage is assumed to decrease
    ($self:ident,"refund", $expression:expr) => {
        let initial_storage_usage = env::storage_usage();
        $expression;
        $self.refund_storage_deposit(initial_storage_usage);
    };

    // storage could increase or decrease
    ($self:ident, $expression:expr) => {
        let initial_storage_usage = env::storage_usage();
        $expression;
        if (env::storage_usage() > initial_storage_usage) {
            $self.require_storage_deposit(initial_storage_usage);
        } else {
            $self.refund_storage_deposit(initial_storage_usage);
        }
    };
}

/// Contract private methods
impl MainchainContract {
    pub fn require_storage_deposit(&self, initial_storage_usage: u64) {
        let storage_cost = env::storage_byte_cost() * u128::from(env::storage_usage() - initial_storage_usage);
        assert!(
            storage_cost <= env::attached_deposit(),
            "Insufficient storage, need {storage_cost}",
        );
    }

    pub fn refund_storage_deposit(&self, initial_storage_usage: u64) {
        let storage_cost = env::storage_byte_cost() * u128::from(initial_storage_usage - env::storage_usage());
        Promise::new(env::signer_account_id()).transfer(storage_cost);
        log!(
            "Refunding {} for storage deposit to {}",
            storage_cost,
            env::signer_account_id()
        );
    }
}

'''
'''--- contracts/src/test_utils.rs ---
use std::collections::HashMap;

use bn254::{PrivateKey, PublicKey, Signature, ECDSA};
use near_contract_standards::{
    fungible_token::{
        core::FungibleTokenCore,
        metadata::{FungibleTokenMetadata, FT_METADATA_SPEC},
    },
    storage_management::StorageManagement,
};
use near_sdk::{json_types::U128, test_utils::VMContextBuilder, testing_env, AccountId, Balance, VMContext};
use rand::Rng;

use crate::{
    consts::{DATA_IMAGE_SVG_ICON, INITIAL_SUPPLY},
    MainchainContract,
};

pub const ONE_EPOCH: u64 = 320; // one SEDA epoch in terms of NEAR blocks
pub const ONE_SLOT: u64 = 10; // one SEDA slot in terms of NEAR blocks
const TEST_DEPOSIT_AMOUNT: Balance = 618_720_000_000_000_000_000_000; // enough deposit to cover storage for all functions that require it
pub const TEST_COMMITTEE_SIZE: u64 = 2;

pub fn new_contract() -> MainchainContract {
    new_contract_with_committee_size(TEST_COMMITTEE_SIZE)
}

pub fn new_contract_with_committee_size(committee_size: u64) -> MainchainContract {
    let mut rng = rand::thread_rng();
    let random_seed = rng.gen::<u64>();
    MainchainContract::new(
        "dao_near".to_string().try_into().unwrap(),
        U128(INITIAL_SUPPLY),
        FungibleTokenMetadata {
            spec:           FT_METADATA_SPEC.to_string(),
            name:           "Example NEAR fungible token".to_string(),
            symbol:         "EXAMPLE".to_string(),
            icon:           Some(DATA_IMAGE_SVG_ICON.to_string()),
            reference:      None,
            reference_hash: None,
            decimals:       24,
        },
        committee_size,
        random_seed.into(),
    )
}

#[derive(Clone)]
pub struct TestAccount {
    pub account_id:         AccountId,
    pub ed25519_public_key: near_sdk::PublicKey,
    pub bn254_private_key:  PrivateKey,
    pub bn254_public_key:   PublicKey,
}

pub fn make_test_account(account_id: String) -> TestAccount {
    // reroll until we get a valid ed25519_public_key
    // TODO: this is ugly but works for now
    let truncated;
    loop {
        let rng = &mut rand::thread_rng();
        let bytes = rng.gen::<[u8; 32]>();
        let encoded = bs58::encode(bytes).into_string();
        if encoded.len() < 44 {
            continue;
        }
        truncated = encoded[..44].to_string();
        break;
    }

    let ed25519_public_key: near_sdk::PublicKey = truncated.parse().unwrap();

    let rng = &mut rand::thread_rng();
    let bn254_private_key = PrivateKey::random(rng);
    let bn254_public_key = PublicKey::from_private_key(&bn254_private_key);

    TestAccount {
        account_id: account_id.try_into().unwrap(),
        ed25519_public_key,
        bn254_private_key,
        bn254_public_key,
    }
}

pub fn get_context_view() -> VMContext {
    VMContextBuilder::new().is_view(true).build()
}
pub fn get_context(test_account: TestAccount) -> VMContext {
    VMContextBuilder::new()
        .signer_account_id(test_account.account_id.clone())
        .signer_account_pk(test_account.ed25519_public_key)
        .predecessor_account_id(test_account.account_id)
        .is_view(false)
        .build()
}
pub fn get_context_for_post_signed_batch(test_account: TestAccount) -> VMContext {
    VMContextBuilder::new()
        .signer_account_id(test_account.account_id)
        .signer_account_pk(test_account.ed25519_public_key)
        .is_view(false)
        .attached_deposit(TEST_DEPOSIT_AMOUNT)
        .block_index(1000000)
        .build()
}
pub fn get_context_with_deposit(test_account: TestAccount) -> VMContext {
    VMContextBuilder::new()
        .signer_account_id(test_account.account_id)
        .signer_account_pk(test_account.ed25519_public_key)
        .is_view(false)
        .attached_deposit(TEST_DEPOSIT_AMOUNT)
        .build()
}
pub fn get_context_for_ft_transfer(test_account: TestAccount) -> VMContext {
    VMContextBuilder::new()
        .signer_account_id(test_account.account_id.clone())
        .signer_account_pk(test_account.ed25519_public_key)
        .predecessor_account_id(test_account.account_id)
        .is_view(false)
        .attached_deposit(1)
        .build()
}
pub fn get_context_at_block(block_index: u64) -> VMContext {
    VMContextBuilder::new().block_index(block_index).is_view(true).build()
}
pub fn get_context_with_deposit_at_block(test_account: TestAccount, block_index: u64) -> VMContext {
    VMContextBuilder::new()
        .signer_account_id(test_account.account_id.clone())
        .signer_account_pk(test_account.ed25519_public_key)
        .is_view(false)
        .attached_deposit(TEST_DEPOSIT_AMOUNT)
        .block_index(block_index)
        .build()
}

pub fn bn254_sign(private_key: &PrivateKey, message: &[u8]) -> Signature {
    ECDSA::sign(message, private_key).unwrap()
}

pub fn bn254_sign_aggregate(accounts: Vec<TestAccount>, message: &[u8]) -> (Signature, PublicKey) {
    // initialize with first account
    let mut agg_signature = bn254_sign(&accounts[0].bn254_private_key, &message);
    let mut agg_public_key = accounts[0].bn254_public_key.clone();

    // aggregate the rest
    for account in accounts.iter().skip(1) {
        let signature = bn254_sign(&account.bn254_private_key, &message);
        agg_public_key = agg_public_key + account.bn254_public_key.clone();
        agg_signature = agg_signature + signature;
    }

    (agg_signature, agg_public_key)
}

pub fn call_random_data_request(
    contract: &mut MainchainContract,
    min_data_requests: usize,
    max_data_requests: usize,
) -> usize {
    let mut rng = rand::thread_rng();
    let num_data_requests = rng.gen_range(min_data_requests..=max_data_requests);

    for i in 0..num_data_requests {
        let data_request_name = format!("data_request_{}", i);
        contract.post_data_request(data_request_name);
    }
    println!("Posted {} data requests", num_data_requests);
    num_data_requests
}

pub fn make_register_test_accounts(
    contract: &mut MainchainContract,
    dao: &TestAccount,
    min_nodes: usize,
    max_nodes: usize,
    deposit_amount: U128,
) -> HashMap<AccountId, TestAccount> {
    let mut test_accounts: HashMap<AccountId, TestAccount> = HashMap::new();

    let mut rng = rand::thread_rng();
    let num_of_nodes = rng.gen_range(min_nodes..=max_nodes);

    for x in 0..num_of_nodes {
        let acc_str = format!("{x}_near", x = x);
        let acc = make_test_account(acc_str.clone());

        // transfer some tokens
        testing_env!(get_context_with_deposit(dao.clone(),));
        contract.storage_deposit(Some(acc_str.clone().try_into().unwrap()), None);
        testing_env!(get_context_for_ft_transfer(dao.clone()));
        contract.ft_transfer(acc_str.clone().try_into().unwrap(), deposit_amount, None);

        test_accounts.insert(acc_str.parse().unwrap(), acc.clone());
        let sig = bn254_sign(&acc.bn254_private_key.clone(), acc_str.as_bytes());

        // register nodes
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.register_node(
            "0.0.0.0:8080".to_string(),
            acc.bn254_public_key.to_uncompressed().unwrap(),
            sig.to_uncompressed().unwrap(),
        );
        // deposit into contract
        testing_env!(get_context_with_deposit(acc.clone()));
        contract.deposit(deposit_amount, acc.ed25519_public_key.clone().into());
    }
    println!("Created {} test accounts", num_of_nodes);
    test_accounts
}

'''
'''--- contracts/src/verify.rs ---
use bn254::format_pairing_check_uncompressed_values;
use near_sdk::near_bindgen;
use near_sys::alt_bn128_pairing_check;

use crate::{MainchainContract, MainchainContractExt};

#[near_bindgen]
impl MainchainContract {
    pub fn bn254_verify(&mut self, message: Vec<u8>, signature: Vec<u8>, public_key: Vec<u8>) -> bool {
        let vals = format_pairing_check_uncompressed_values(message, signature, public_key).unwrap();

        let res;
        unsafe {
            res = alt_bn128_pairing_check(core::mem::size_of_val(&vals) as u64, vals.as_ptr() as *const u64 as u64);
        }

        res == 1
    }
}

'''
'''--- contracts/src/verify_test.rs ---
use bn254::{PrivateKey, PublicKey, Signature, ECDSA};
use near_sdk::testing_env;

use super::test_utils::{get_context, new_contract};
use crate::tests::test_utils::make_test_account;

/// Test `ECDSA::verify` function with own signed message
#[test]
fn test_verify_signed_msg() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    testing_env!(get_context(bob));

    // Public key
    let private_key = hex::decode("2009da7287c158b126123c113d1c85241b6e3294dd75c643588630a8bc0f934c").unwrap();
    let private_key = PrivateKey::try_from(private_key.as_slice()).unwrap();
    let public_key = PublicKey::from_private_key(&private_key).to_uncompressed().unwrap();

    // Signature
    let signature_vec = hex::decode("020f047a153e94b5f109e4013d1bd078112817cf0d58cdf6ba8891f9849852ba5b").unwrap();
    let sig = Signature::from_compressed(signature_vec)
        .unwrap()
        .to_uncompressed()
        .unwrap();

    // Message signed
    let msg = hex::decode("73616d706c65").unwrap();

    // Verify signature
    assert!(contract.bn254_verify(msg, sig, public_key), "Verification failed");
}

/// Test aggregate signature verification
#[test]
fn test_verify_aggregate_signatures() {
    let mut contract = new_contract();
    let bob = make_test_account("bob_near".to_string());
    testing_env!(get_context(bob));

    // Message
    let msg = hex::decode("73616d706c65").unwrap();

    // Signature 1
    let private_key_1_bytes = hex::decode("1ab1126ff2e37c6e6eddea943ccb3a48f83b380b856424ee552e113595525565").unwrap();
    let private_key_1 = PrivateKey::try_from(private_key_1_bytes.as_slice()).unwrap();
    let sign_1 = ECDSA::sign(&msg, &private_key_1).unwrap();
    let sign_1_bytes = sign_1.to_uncompressed().unwrap();

    let public_key_1 = PublicKey::from_private_key(&private_key_1);
    let public_key_1_bytes = public_key_1.to_uncompressed().unwrap();

    // Signature 2
    let secret_key_2_bytes = hex::decode("2009da7287c158b126123c113d1c85241b6e3294dd75c643588630a8bc0f934c").unwrap();
    let private_key_2 = PrivateKey::try_from(secret_key_2_bytes.as_slice()).unwrap();
    let sign_2 = ECDSA::sign(&msg, &private_key_2).unwrap();
    let sign_2_bytes = sign_2.to_uncompressed().unwrap();

    let public_key_2 = PublicKey::from_private_key(&private_key_2);
    let public_key_2_bytes = public_key_2.to_uncompressed().unwrap();

    // Public Key and Signature aggregation
    let agg_public_key = (public_key_1 + public_key_2).to_uncompressed().unwrap();
    let agg_signature = (sign_1 + sign_2).to_uncompressed().unwrap();

    // Verification single signatures
    assert!(
        contract.bn254_verify(msg.clone(), sign_1_bytes, public_key_1_bytes),
        "Signature 1 verification failed"
    );
    assert!(
        contract.bn254_verify(msg.clone(), sign_2_bytes, public_key_2_bytes),
        "Signature 2 signature verification failed"
    );

    // Aggregate signature verification
    assert!(
        contract.bn254_verify(msg, agg_signature, agg_public_key),
        "Aggregated signature verification failed"
    );
}

'''
'''--- crypto/Cargo.toml ---
[package]
name = "seda-crypto"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
bn254 = { workspace = true, features = ["serde"] }
concat-kdf = { workspace = true, features = ["std"] }
ed25519-dalek = { workspace = true }
hex = { workspace = true }
rand = { workspace = true }
serde = { workspace = true }
sha2 = { workspace = true }
thiserror = { workspace = true }

[dev-dependencies]
bs58 = { workspace = true }
near-crypto = { workspace = true }
rand = { workspace = true }
serde_json = { workspace=true, features = ["std"] }
'''
'''--- crypto/src/errors.rs ---
use thiserror::Error;

#[derive(Error, Debug)]
pub enum CryptoError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    #[error("Key derivation error: {0}")]
    KeyDerivation(#[from] concat_kdf::Error),
    #[error(transparent)]
    Bn254Error(#[from] bn254::Error),
    #[error("Invalid master key length: {0}")]
    InvalidMasterKeyLength(#[from] std::array::TryFromSliceError),
    #[error("Invalid hex: {0}")]
    FromHex(#[from] hex::FromHexError),
}

pub type Result<T, E = CryptoError> = core::result::Result<T, E>;

'''
'''--- crypto/src/keypair.rs ---
use bn254::{PrivateKey as Bn254PrivateKey, PublicKey as Bn254PublicKey};
use concat_kdf::derive_key;
use ed25519_dalek::{PublicKey as Ed25519PublicKey, SecretKey as Ed25519PrivateKey, SECRET_KEY_LENGTH};

use super::Result;
use crate::MasterKey;

#[derive(PartialEq, Eq)]
pub enum KeyType {
    Bn254,
    Ed25519,
}

/// KeyPair type has a two generics, one to represent the private and public key
/// types. It defaults to a Bn254 KeyPair.
#[derive(Debug, Clone)]
pub struct KeyPair<Private, Public> {
    pub private_key: Private,
    pub public_key:  Public,
}

pub type Ed25519KeyPair = KeyPair<Ed25519PrivateKey, Ed25519PublicKey>;
pub type Bn254KeyPair = KeyPair<Bn254PrivateKey, Bn254PublicKey>;

impl From<&Ed25519KeyPair> for Vec<u8> {
    fn from(val: &Ed25519KeyPair) -> Self {
        let mut result = vec![];

        result.extend_from_slice(val.private_key.as_bytes());
        result.extend_from_slice(val.public_key.as_bytes());

        result
    }
}

impl AsRef<Ed25519KeyPair> for Ed25519KeyPair {
    fn as_ref(&self) -> &Ed25519KeyPair {
        self
    }
}

impl MasterKey {
    pub fn derive_bn254(&self, index: usize) -> Result<KeyPair<Bn254PrivateKey, Bn254PublicKey>> {
        let master_sk = derive_key::<sha2::Sha256>(&self.seed, b"bn254", SECRET_KEY_LENGTH)?;
        let sk = derive_key::<sha2::Sha256>(master_sk.as_slice(), &index.to_ne_bytes(), SECRET_KEY_LENGTH)?;
        let private_key = Bn254PrivateKey::try_from(sk.as_slice()).unwrap();
        let public_key = Bn254PublicKey::from_private_key(&private_key);

        Ok(KeyPair {
            public_key,
            private_key,
        })
    }

    pub fn derive_ed25519(&self, index: usize) -> Result<KeyPair<Ed25519PrivateKey, Ed25519PublicKey>> {
        let master_sk = derive_key::<sha2::Sha256>(&self.seed, b"ed25519", SECRET_KEY_LENGTH)?;
        let sk = derive_key::<sha2::Sha256>(master_sk.as_slice(), &index.to_ne_bytes(), SECRET_KEY_LENGTH)?;
        let private_key = Ed25519PrivateKey::from_bytes(sk.as_slice()).unwrap();
        let public_key: Ed25519PublicKey = (&private_key).into();

        Ok(KeyPair {
            public_key,
            private_key,
        })
    }
}

'''
'''--- crypto/src/lib.rs ---
mod errors;
pub use errors::*;
mod master_key;
pub use master_key::*;
mod keypair;
pub use keypair::*;

#[cfg(test)]
#[path = ""]
pub mod test {
    mod test;
}

'''
'''--- crypto/src/master_key.rs ---
use std::{fs::read_to_string, path::Path};

use rand::RngCore;
use serde::{Deserialize, Serialize};

use super::{CryptoError, Result};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MasterKey {
    pub seed: [u8; 32],
}

impl MasterKey {
    pub fn random() -> Self {
        let mut seed = [0u8; 32];
        rand::rngs::OsRng.fill_bytes(&mut seed);

        Self { seed }
    }

    pub fn read_from_path<T: AsRef<Path>>(path: T) -> Result<Self> {
        let hex = read_to_string(path)?;
        let seed = hex::decode(hex)?.as_slice().try_into()?;

        Ok(Self { seed })
    }

    pub fn write_to_path<T: AsRef<Path>>(&self, path: T) -> Result<()> {
        let hex = hex::encode(self.seed);
        std::fs::write(path, hex)?;

        Ok(())
    }
}

impl From<MasterKey> for String {
    fn from(master_key: MasterKey) -> Self {
        hex::encode(master_key.seed)
    }
}

impl From<[u8; 32]> for MasterKey {
    fn from(seed: [u8; 32]) -> Self {
        Self { seed }
    }
}

impl From<MasterKey> for [u8; 32] {
    fn from(master_key: MasterKey) -> Self {
        master_key.seed
    }
}

impl TryFrom<&String> for MasterKey {
    type Error = CryptoError;

    fn try_from(hex_string: &String) -> std::result::Result<Self, Self::Error> {
        let seed: [u8; 32] = hex::decode(hex_string)?.as_slice().try_into()?;

        Ok(Self { seed })
    }
}

'''
'''--- crypto/src/test.rs ---
use bn254::ECDSA;
use ed25519_dalek::{Keypair, Signature, Signer};

use crate::{CryptoError, MasterKey};

#[test]
fn generate_bn254_pair() {
    let master_key = MasterKey::random();
    let bn_pair = master_key.derive_bn254(1).expect("Couldn't derive bn254 key pair");
    let msg = "awesome-seda";
    let signature = ECDSA::sign(msg, &bn_pair.private_key).expect("couldnt sign msg");
    assert!(ECDSA::verify(msg, &signature, &bn_pair.public_key).is_ok())
}

#[test]
fn generate_ed25519_pair() {
    let master_key = MasterKey::random();
    let ed_pair = master_key.derive_ed25519(1).expect("Couldn't derive ed25519 key pair");
    let ed25519_pair = Keypair::from_bytes(&[ed_pair.private_key.to_bytes(), ed_pair.public_key.to_bytes()].concat())
        .expect("Couldn't convert ed25519 keypair");
    let msg: &[u8] = b"awesome-seda";
    let signature: Signature = ed25519_pair.sign(msg);
    assert!(ed25519_pair.verify(msg, &signature).is_ok());
}

#[test]
fn master_key_from_hex_1() {
    let mk_random = MasterKey::random();
    let mk_string: String = mk_random.into();
    let mk_from_string = MasterKey::try_from(&mk_string);
    assert!(mk_from_string.is_ok());
}

#[test]
fn master_key_from_hex_2() {
    let mk_string: String = "0000000000000000000000000000000000000000000000000000000000000000".to_string();
    let master_key = MasterKey::try_from(&mk_string);
    assert!(master_key.is_ok());
}

#[test]
fn master_key_from_hex_error_length() {
    let mk_string: String = "1234".to_string();
    let master_key = MasterKey::try_from(&mk_string);
    assert!(matches!(master_key, Err(CryptoError::InvalidMasterKeyLength(_))));
}

#[test]
fn master_key_from_hex_error_invalid() {
    let mk_string: String = "potato".to_string();
    let master_key = MasterKey::try_from(&mk_string);
    assert!(matches!(master_key, Err(CryptoError::FromHex(_))));
}

#[test]
fn near_crypto_compat_1() {
    let mk_string: String = "0000000000000000000000000000000000000000000000000000000000000001".to_string();
    let master_key = MasterKey::try_from(&mk_string).unwrap();

    let ed25519_keypair = master_key.derive_ed25519(0).unwrap();
    let expected_public_key = bs58::encode(ed25519_keypair.public_key.as_bytes()).into_string();

    let secret_key_string = bs58::encode::<Vec<u8>>(ed25519_keypair.as_ref().into()).into_string();
    let secret_key_res: Result<near_crypto::SecretKey, _> = secret_key_string.parse();
    let derived_public_key = secret_key_res.unwrap().public_key().to_string();

    assert_eq!(derived_public_key, format!("ed25519:{}", expected_public_key));
}

#[test]
fn near_crypto_compat_2() {
    let mk_string: String = "0000000000000000000000000000000000000000000000000000000000000001".to_string();
    let master_key = MasterKey::try_from(&mk_string).unwrap();

    let ed25519_keypair = master_key.derive_ed25519(0).unwrap();
    let expected_public_key = bs58::encode(ed25519_keypair.public_key.as_bytes()).into_string();

    let ed25519_keypair_bytes: Vec<u8> = ed25519_keypair.as_ref().into();
    let signer_secret_key: near_crypto::SecretKey =
        near_crypto::SecretKey::ED25519(near_crypto::ED25519SecretKey(ed25519_keypair_bytes.try_into().unwrap()));
    let derived_public_key = signer_secret_key.public_key().to_string();

    assert_eq!(derived_public_key, format!("ed25519:{}", expected_public_key));
}

#[test]
fn derive_bn254_different_keys() {
    let master_key: MasterKey = MasterKey::random();

    let bn254_key_1 = master_key.derive_bn254(0).unwrap();
    let bn254_key_2 = master_key.derive_bn254(1).unwrap();

    let private_key_1 = bn254_key_1.private_key.to_bytes().unwrap();
    let private_key_2 = bn254_key_2.private_key.to_bytes().unwrap();

    assert_ne!(private_key_1, private_key_2)
}

#[test]
fn derive_ed25519_different_keys() {
    let master_key: MasterKey = MasterKey::random();

    let bn254_key_1 = master_key.derive_ed25519(0).unwrap();
    let bn254_key_2 = master_key.derive_ed25519(1).unwrap();

    let private_key_1 = bn254_key_1.private_key.to_bytes();
    let private_key_2 = bn254_key_2.private_key.to_bytes();

    assert_ne!(private_key_1, private_key_2)
}

'''
'''--- delegate-cli/Cargo.toml ---
[package]
name = "seda-delegate-cli"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[[bin]]
name = "seda-delegate"
path = "src/main.rs"

[dependencies]
bn254 = { workspace = true }
bs58 = { workspace = true }
clap = { workspace = true, features = ["default"] }
clap-markdown = { workspace = true }
clap_complete = { workspace = true }
dotenv = { workspace = true }
hex = { workspace = true }
seda-chains = { workspace = true }
seda-config = { workspace = true, features = ["cli", "delegate-cli"] }
seda-crypto = { workspace = true }
seda-runtime-sdk = { workspace = true }
serde_json = { workspace = true, features = ["std"] }
tokio = { workspace = true }
thiserror = { workspace = true }

'''
'''--- delegate-cli/src/cli/commands/mod.rs ---
pub mod register;
pub mod setup;
pub mod stake;
pub mod top_up;

'''
'''--- delegate-cli/src/cli/commands/register.rs ---
use bn254::ECDSA;
use clap::Args;
use seda_chains::{chain, Client};
use seda_config::{ChainConfigsInner, DelegateConfig};
use seda_crypto::MasterKey;
use seda_runtime_sdk::Chain;
use serde_json::json;

use crate::cli::{errors::Result, utils::to_yocto};

#[derive(Debug, Args)]
pub struct Register {
    /// The contract address to register on
    pub delegation_contract_id: String,

    #[clap(default_value = "")]
    /// The multi address that is associated with the node, follows the libp2p
    /// multi address spec (<ip-multiaddr>/tcp/<tcp-port>)
    pub multi_addr: String,
}

impl Register {
    pub async fn handle(self, config: DelegateConfig) -> Result<()> {
        let validator_master_key = MasterKey::try_from(&config.validator_master_key)?;
        let bn254_key = validator_master_key.derive_bn254(0)?;
        let ed25519_key = validator_master_key.derive_ed25519(0)?;
        let ed25519_public_key = ed25519_key.public_key.as_bytes().to_vec();
        let account_id = hex::encode(&ed25519_public_key);
        let signature = ECDSA::sign(&account_id, &bn254_key.private_key)?;
        let ed25519_keypair_bytes = Vec::<u8>::from(&ed25519_key);

        let signed_tx = chain::construct_signed_tx(
            Chain::Near,
            None,
            &ed25519_keypair_bytes,
            &self.delegation_contract_id,
            "register_node",
            json!({
                "multi_addr": self.multi_addr,
                "bn254_public_key": &bn254_key.public_key.to_uncompressed()?,
                "signature": &signature.to_uncompressed()?,
            })
            .to_string()
            .into_bytes(),
            80000000000000,
            to_yocto("0.01"),
            &config.rpc_url,
        )
        .await?;

        println!(
            "Registring {} on contract {}..",
            &hex::encode(ed25519_public_key),
            self.delegation_contract_id
        );

        let config = ChainConfigsInner::test_config();
        let client = Client::new(&Chain::Near, &config)?;
        chain::send_tx(Chain::Near, client, &signed_tx).await?;

        println!("Transaction has been completed");

        Ok(())
    }
}

'''
'''--- delegate-cli/src/cli/commands/setup.rs ---
use clap::Args;
use seda_config::DelegateConfig;
use seda_crypto::MasterKey;

use super::{register::Register, stake::Stake, top_up::TopUp};
use crate::cli::errors::Result;

#[derive(Debug, Args)]
pub struct Setup {
    /// The contract address to stake on
    pub delegation_contract_id: String,

    #[clap(default_value_t = 1, short, long)]
    /// Amount of tokens to transfer in wholes (1 = 1 NEAR)
    pub topup_amount: u64,

    #[clap(default_value_t = 100, short, long)]
    /// The amount of SEDA tokens to stake (1 = 1 SEDA)
    pub stake_amount: u64,

    #[clap(default_value = "", short, long)]
    /// The multi address that is associated with the node (defaults to none)
    pub multi_addr: String,
}

impl Setup {
    pub async fn handle(self, config: DelegateConfig) -> Result<()> {
        let validator_master_key = MasterKey::try_from(&config.validator_master_key).unwrap();
        let ed25519_key = validator_master_key.derive_ed25519(0).unwrap();
        let ed25519_public_key = ed25519_key.public_key.as_ref();

        let top_up = TopUp {
            amount:   self.topup_amount,
            receiver: hex::encode(ed25519_public_key),
        };

        top_up.handle(config.clone()).await?;

        let register = Register {
            delegation_contract_id: self.delegation_contract_id.clone(),
            multi_addr:             self.multi_addr,
        };

        register.handle(config.clone()).await?;

        let stake = Stake {
            amount:                 self.stake_amount,
            delegation_contract_id: self.delegation_contract_id,
        };

        stake.handle(config).await?;

        Ok(())
    }
}

'''
'''--- delegate-cli/src/cli/commands/stake.rs ---
use clap::Args;
use seda_chains::{chain, Client};
use seda_config::{ChainConfigsInner, DelegateConfig};
use seda_crypto::MasterKey;
use seda_runtime_sdk::Chain;
use serde_json::json;

use crate::cli::{
    errors::Result,
    utils::{get_signer_keypair_from_config, to_yocto},
};

#[derive(Debug, Args)]
pub struct Stake {
    /// The contract address to stake on
    pub delegation_contract_id: String,
    /// The amount of SEDA tokens to stake (1 = 1 SEDA)
    pub amount:                 u64,
}

impl Stake {
    pub async fn handle(self, config: DelegateConfig) -> Result<()> {
        // SEDA tokens are in the same denominator as NEAR (24 decimals)
        let amount_yocto = to_yocto(&self.amount.to_string());
        let validator_master_key = MasterKey::try_from(&config.validator_master_key)?;
        let ed25519_key = validator_master_key.derive_ed25519(0)?;

        // This is needed to be compliant to be with NEAR
        let mut ed25519_public_key: Vec<u8> = vec![0];
        ed25519_public_key.extend_from_slice(ed25519_key.public_key.as_bytes());
        let account_id = hex::encode(&ed25519_public_key);

        let signer_keypair = get_signer_keypair_from_config(&config.account_secret_key)?;

        println!(
            "Staking {} SEDA on {} for node {account_id}..",
            &self.amount, self.delegation_contract_id
        );

        let signed_tx = chain::construct_signed_tx(
            Chain::Near,
            Some(&config.signer_account_id),
            &signer_keypair,
            &self.delegation_contract_id,
            "deposit",
            json!({
                "amount": &amount_yocto.to_string(),
                "ed25519_public_key": &ed25519_public_key,
            })
            .to_string()
            .into_bytes(),
            config.gas,
            to_yocto("0.01"),
            &config.rpc_url,
        )
        .await?;

        let config = ChainConfigsInner::test_config();
        let client = Client::new(&Chain::Near, &config)?;
        chain::send_tx(Chain::Near, client, &signed_tx).await?;

        println!("Transaction has been completed");

        Ok(())
    }
}

'''
'''--- delegate-cli/src/cli/commands/top_up.rs ---
use clap::Args;
use seda_chains::{chain, Client};
use seda_config::{ChainConfigsInner, DelegateConfig};
use seda_runtime_sdk::Chain;

use crate::cli::{
    errors::Result,
    utils::{get_signer_keypair_from_config, to_yocto},
};

#[derive(Debug, Args)]
pub struct TopUp {
    /// The receiver account id you want to transfer to (ex. example.near)
    pub receiver: String,
    /// Amount of tokens to transfer in wholes (1 = 1 NEAR)
    pub amount:   u64,
}

impl TopUp {
    pub async fn handle(self, config: DelegateConfig) -> Result<()> {
        // Convert to yocto NEAR, which uses 24 decimals
        let amount_yocto = to_yocto(&self.amount.to_string());
        let signer_keypair = get_signer_keypair_from_config(&config.account_secret_key)?;

        let signed_tx = chain::construct_transfer_tx(
            Chain::Near,
            Some(&config.signer_account_id),
            &signer_keypair,
            &self.receiver,
            amount_yocto,
            &config.rpc_url,
        )
        .await?;

        let config = ChainConfigsInner::test_config();
        let client = Client::new(&Chain::Near, &config)?;

        println!("Sending {}N to {}..", self.amount, self.receiver);
        chain::send_tx(Chain::Near, client, &signed_tx).await?;
        println!("Transaction has been completed");

        Ok(())
    }
}

'''
'''--- delegate-cli/src/cli/errors.rs ---
use bn254::Error as Bn254Error;
use seda_chains::ChainAdapterError;
use seda_crypto::CryptoError;
use thiserror::Error;

#[derive(Error, Debug)]
pub enum DelegateCliError {
    #[error("Config error: {0}")]
    Config(String),

    #[error("Could not convert key: {0}")]
    Crypto(#[from] CryptoError),

    #[error("BN254 operation failed: {0}")]
    Bn254(#[from] Bn254Error),

    #[error("Using the chain interface threw an error: {0}")]
    Chain(#[from] ChainAdapterError),
}

pub type Result<T, E = DelegateCliError> = core::result::Result<T, E>;

'''
'''--- delegate-cli/src/cli/mod.rs ---
use clap::{command, Parser, Subcommand};
use seda_config::{DelegateConfig, PartialDelegateConfig};

use self::errors::Result;
mod commands;

pub mod errors;
mod utils;

#[derive(Parser)]
#[command(name = "seda-delegate")]
#[command(author = "https://github.com/SedaProtocol")]
#[command(version)]
#[command(propagate_version = true)]
#[command(about = "For staking & delegation on the SEDA protocol.", long_about = None)]
#[command(next_line_help = true)]
pub struct CliOptions {
    #[command(flatten)]
    pub delegate_config: PartialDelegateConfig,
    #[command(subcommand)]
    pub command:         Command,
}

#[derive(Debug, Subcommand)]
pub enum Command {
    /// Top-up a target account by a given amount in NEAR
    TopUp(commands::top_up::TopUp),
    /// Register a node to a delegation contract
    Register(commands::register::Register),
    /// Allows you to stake to a given delegator
    Stake(commands::stake::Stake),
    /// A all in one command to get started as a node operator
    Setup(commands::setup::Setup),
}

impl Command {
    #[tokio::main]
    pub async fn handle(self, config: DelegateConfig) -> Result<()> {
        match self {
            Self::TopUp(top_up) => {
                top_up.handle(config).await?;
            }
            Self::Register(register) => {
                register.handle(config).await?;
            }
            Self::Stake(stake) => {
                stake.handle(config).await?;
            }
            Self::Setup(setup) => {
                setup.handle(config).await?;
            }
        }

        Ok(())
    }
}

'''
'''--- delegate-cli/src/cli/utils.rs ---
use super::errors::{DelegateCliError, Result};

/// Taken from https://docs.rs/near-sdk-sim/latest/near_sdk_sim/
/// Converts a string (nominated in full NEAR tokens) and converts it to
/// yoctoNEAR (smallest denominator in NEAR)
pub fn to_yocto(value: &str) -> u128 {
    let vals: Vec<_> = value.split('.').collect();
    let part1 = vals[0].parse::<u128>().unwrap() * 10u128.pow(24);
    if vals.len() > 1 {
        let power = vals[1].len() as u32;
        let part2 = vals[1].parse::<u128>().unwrap() * 10u128.pow(24 - power);
        part1 + part2
    } else {
        part1
    }
}

/// Retrieve Ed25519 keypair bytes from a string in the format of
/// `ed25519:base58-encoded-string`
pub(crate) fn get_signer_keypair_from_config(account_secret_key: &str) -> Result<Vec<u8>> {
    let signer_keypair_str = account_secret_key
        .strip_prefix("ed25519:")
        .ok_or(DelegateCliError::Config(
            "`account_secret_key` should contain prefix `ed25519:`".to_string(),
        ))?;

    Ok(bs58::decode(signer_keypair_str)
        .into_vec()
        .expect("Base58-encoded ed25519 keypair should be valid"))
}

'''
'''--- delegate-cli/src/main.rs ---
use clap::Parser;
use cli::errors::Result;
use seda_config::{Config, PartialDelegateConfig};

use crate::cli::CliOptions;

mod cli;

fn main() -> Result<()> {
    // Load the dotenv file first since our config overloads values from it.
    dotenv::dotenv().ok();

    let options = CliOptions::parse();
    let mut env_config = PartialDelegateConfig::default();
    env_config.overwrite_from_env();

    let config = options.delegate_config.to_config(env_config).unwrap();

    options.command.handle(config)
}

'''
'''--- example.config.toml ---
seda_server_address = '127.0.0.1'
seda_server_port = 12345
[chains.another]
chain_rpc_url = 'https://rpc.testnet.near.org'

[chains.near]
chain_rpc_url = 'https://rpc.testnet.near.org'

[node]
contract_account_id = 'fill this in'
public_key = 'fill this in'
seda_chain_secret_key = 'fill this in'
seda_secret_key = 'fill this in'
seda_sk_file_path = 'fill this in'

signer_account_id = 'fill this in'

[logging]
log_file_path = 'C:\Users\galu\Documents\work\Flux\seda-rust'

'''
'''--- logger/Cargo.toml ---
[package]
name = "seda-logger"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
seda-config = { workspace = true }
serde = { workspace = true }
tracing = { workspace = true, features = ["std"] }
tracing-appender = { workspace = true }
# tracing-log = { workspace = true }
tracing-subscriber = { workspace = true, features = [
	"ansi",
	"env-filter",
	"smallvec",
] }

'''
'''--- logger/src/lib.rs ---
use std::io;

use seda_config::LoggerConfig;
use tracing_appender::non_blocking::WorkerGuard;
use tracing_subscriber::{fmt, prelude::__tracing_subscriber_SubscriberExt, EnvFilter};

pub fn init(config: &LoggerConfig) -> Vec<WorkerGuard> {
    // Grabs from RUST_LOG env var and if not defaults to
    // TRACE for debug, and info for non debug.
    let level_filter = EnvFilter::try_from_default_env().unwrap_or_default();
    #[cfg(debug_assertions)]
    let level_filter = level_filter
        .add_directive("seda_chains=trace".parse().unwrap())
        .add_directive("seda_p2p=trace".parse().unwrap())
        .add_directive("seda_cli=trace".parse().unwrap())
        .add_directive("seda_node=trace".parse().unwrap())
        .add_directive("seda_runtime=trace".parse().unwrap());
    #[cfg(not(debug_assertions))]
    let level_filter = level_filter
        .add_directive("seda_chains=info".parse().unwrap())
        .add_directive("seda_p2p=info".parse().unwrap())
        .add_directive("seda_cli=info".parse().unwrap())
        .add_directive("seda_node=info".parse().unwrap())
        .add_directive("seda_runtime=info".parse().unwrap());

    let mut guards = Vec::new();

    let (stdout, stdout_guard) = tracing_appender::non_blocking(io::stdout());
    guards.push(stdout_guard);
    let stdout = fmt::Layer::new().with_writer(stdout).pretty().with_thread_ids(true);
    // Logging shows files and line number but only for debug builds.
    #[cfg(not(debug_assertions))]
    let stdout = stdout.with_line_number(false).with_file(false);

    let file_appender = tracing_appender::rolling::daily(&config.log_file_path, "seda_log");
    let (non_blocking, file_guard) = tracing_appender::non_blocking(file_appender);
    guards.push(file_guard);
    let mut file_logger = fmt::Layer::new().with_writer(non_blocking);
    file_logger.set_ansi(false);

    let subscriber = tracing_subscriber::registry()
        .with(level_filter)
        .with(stdout)
        .with(file_logger);
    tracing::subscriber::set_global_default(subscriber).expect("Failed to set logger.");

    guards
}

'''
'''--- node/Cargo.toml ---
[package]
name = "seda-node"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
actix = { workspace = true }
async-trait = { workspace = true }
bn254 = {workspace = true }
borsh = { workspace = true }
ed25519-dalek = {workspace = true}
futures = { workspace = true }
hex = {workspace = true}
jsonrpsee = { workspace = true, features = ["macros", "server"] }
parking_lot = { workspace = true }
reqwest = { workspace = true }
rusqlite = { workspace = true }
seda-chains = { workspace = true }
seda-config = { workspace = true }
seda-p2p = { workspace = true }
seda-runtime = { workspace = true }
seda-runtime-sdk = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tokio-rusqlite = { workspace = true }
tracing = { workspace = true }

'''
'''--- node/src/app/job_manager.rs ---
use std::time::Duration;

use actix::{AsyncContext, Handler, Message};
use seda_runtime::HostAdapter;

use crate::{app::App, runtime_job::RuntimeJob};

/// The Job Manager‚Äôs job is to take events coming from P2P, tickers, RPC, etc
/// and give the task to the runtime when there is an available thread. Each
/// event comes with a ID that corresponds with that task. It‚Äôs important that
/// tasks that cannot be processed at the same time must have the same ID to
/// prevent this. For example with aggregating. (If you open two threads that
/// both do `counter += 1` the result would be `counter = 1` instead of `counter
/// = 2` and information will get lost)
///
/// The Job Manager is essentially pretty dumb, it takes the event and checks if
/// there is no thread currently running with that ID. If not and there is a
/// thread available, it spins up a new thread and gives the event information
/// along with some arguments.
#[derive(Message)]
#[rtype(result = "()")]
pub struct StartJobManager;

impl StartJobManager {
    const JOB_MANAGER_INTERVAL: u64 = 200;
}

impl<HA: HostAdapter> Handler<StartJobManager> for App<HA> {
    type Result = ();

    fn handle(&mut self, msg: StartJobManager, ctx: &mut Self::Context) -> Self::Result {
        let mut event_queue = self.event_queue.write();
        let running_event_ids = self.running_event_ids.read();
        if let Some(event) = event_queue.get_next(running_event_ids.as_slice()) {
            self.runtime_worker.do_send(RuntimeJob { event });
        }

        ctx.notify_later(msg, Duration::from_millis(StartJobManager::JOB_MANAGER_INTERVAL));
    }
}

'''
'''--- node/src/app/job_manager_test.rs ---
// use std::sync::Arc;

// use actix::{Actor, SyncArbiter, System};
// use parking_lot::RwLock;

// use crate::{
//     app::{App, Shutdown},
//     event_queue::{Event, EventData, EventQueue},
//     event_queue_handler::AddEventToQueue,
//     job_manager::StartJobManager,
//     runtime_job::RuntimeWorker,
// };

// #[test]
// fn test_job_manager() {
//     let system = System::new();

//     system.block_on(async {
//         let app = App {
//             event_queue:       Arc::new(RwLock::new(EventQueue::default())),
//             running_event_ids: Arc::new(RwLock::new(Vec::new())),
//         }
//         .start();

//         app.send(AddEventToQueue {
//             event: Event {
//                 id:   "test".to_string(),
//                 data: EventData::ChainTick,
//             },
//         })
//         .await
//         .unwrap();

//         let runtime_worker = SyncArbiter::start(2, move || RuntimeWorker);
//         app.send(StartJobManager { runtime_worker })
//             .await
//             .expect("Should be Ok()");

//         app.send(Shutdown).await.unwrap();
//     });

//     system.run().expect("Should run!");
// }

'''
'''--- node/src/app/mod.rs ---
use std::sync::Arc;

use actix::prelude::*;
use parking_lot::RwLock;
use seda_config::{ChainConfigs, NodeConfig};
use seda_p2p::DiscoveryStatus;
use seda_runtime::{HostAdapter, InMemory};
use seda_runtime_sdk::{events::EventId, p2p::P2PCommand};
use tokio::sync::mpsc::Sender;
use tracing::info;

use crate::{
    event_queue::EventQueue,
    host::{BatchTickManager, Host, SetAppAddress},
    rpc::JsonRpcServer,
    runtime_job::RuntimeWorker,
};

mod job_manager;
pub mod p2p_message_handler;
mod shutdown;
pub use shutdown::Shutdown;
// Node Actor definition
pub struct App<HA: HostAdapter> {
    pub event_queue:       Arc<RwLock<EventQueue>>,
    pub running_event_ids: Arc<RwLock<Vec<EventId>>>,
    pub runtime_worker:    Addr<RuntimeWorker<HA>>,
    pub rpc_server:        JsonRpcServer,
    pub shared_memory:     Arc<RwLock<InMemory>>,
}

impl<HA: HostAdapter> App<HA> {
    pub async fn new(
        node_config: NodeConfig,
        rpc_server_address: &str,
        chain_configs: ChainConfigs,
        p2p_command_sender_channel: Sender<P2PCommand>,
        disocvery_status: DiscoveryStatus,
    ) -> Self {
        // Have to clone beforehand in order for the variable to be moved. (We also need
        // the same sender for the RPC)
        let p2p_command_sender_channel_clone = p2p_command_sender_channel.clone();

        let shared_memory = Arc::new(RwLock::new(InMemory::default()));
        // Hack to get around Copy requirement for move closure.
        let sm_clone = shared_memory.clone();
        let runtime_worker = SyncArbiter::start(node_config.runtime_worker_threads, move || RuntimeWorker {
            runtime:                    None,
            node_config:                node_config.clone(),
            chain_configs:              chain_configs.clone(),
            p2p_command_sender_channel: p2p_command_sender_channel_clone.clone(),
            shared_memory:              sm_clone.clone(),
        });

        let rpc_server = JsonRpcServer::start(
            runtime_worker.clone(),
            rpc_server_address,
            p2p_command_sender_channel.clone(),
            disocvery_status.clone(),
        )
        .await
        .expect("Error starting jsonrpsee server");

        App {
            event_queue: Default::default(),
            running_event_ids: Default::default(),
            runtime_worker,
            rpc_server,
            shared_memory,
        }
    }
}

impl<HA: HostAdapter> Actor for App<HA> {
    type Context = Context<Self>;

    fn started(&mut self, ctx: &mut Self::Context) {
        let banner = r#"
         _____ __________  ___         ____  __  _____________
        / ___// ____/ __ \/   |       / __ \/ / / / ___/_  __/
        \__ \/ __/ / / / / /| |______/ /_/ / / / /\__ \ / /
       ___/ / /___/ /_/ / ___ /_____/ _, _/ /_/ /___/ // /
      /____/_____/_____/_/  |_|    /_/ |_|\____//____//_/
        "#;
        info!("Node starting... \n{}", banner);

        info!("Starting Job Manager...");
        let app_address = ctx.address();

        let host = Host::from_registry();
        host.do_send(SetAppAddress { address: app_address });
        host.do_send(BatchTickManager);

        ctx.notify(job_manager::StartJobManager);
    }

    fn stopped(&mut self, _ctx: &mut Self::Context) {
        info!("Node stopped");
    }
}

'''
'''--- node/src/app/p2p_message_handler.rs ---
use actix::Addr;
use seda_runtime_sdk::{
    events::{Event, EventData},
    p2p::P2PMessage,
};
use tokio::sync::mpsc::Receiver;

use super::App;
use crate::{event_queue_handler::AddEventToQueue, host::RuntimeAdapter};

pub struct P2PMessageHandler {
    p2p_message_receiver: Receiver<P2PMessage>,
    app_addr:             Addr<App<RuntimeAdapter>>,
}

impl P2PMessageHandler {
    pub fn new(p2p_message_receiver: Receiver<P2PMessage>, app_addr: Addr<App<RuntimeAdapter>>) -> Self {
        Self {
            p2p_message_receiver,
            app_addr,
        }
    }

    pub async fn listen(&mut self) {
        loop {
            if let Some(message) = self.p2p_message_receiver.recv().await {
                self.app_addr.do_send(AddEventToQueue {
                    event: Event {
                        id:   "p2p-message".to_string(),
                        data: EventData::P2PMessage(message),
                    },
                });
            }
        }
    }
}

'''
'''--- node/src/app/shutdown.rs ---
use actix::{Handler, Message, System};
use seda_runtime::HostAdapter;
use tracing::error;

use super::App;

#[derive(Message)]
#[rtype(result = "()")]
pub struct Shutdown;

impl<HA: HostAdapter> Handler<Shutdown> for App<HA> {
    type Result = ();

    fn handle(&mut self, _msg: Shutdown, _ctx: &mut Self::Context) {
        // Close RPC server
        if let Err(error) = self.rpc_server.stop() {
            error!("Some error happened while closing RPC: {}", error);
        }

        // Close actix system
        System::current().stop();
    }
}

'''
'''--- node/src/errors.rs ---
use thiserror::Error;

#[derive(Error, Debug)]
pub enum NodeError {
    #[error(transparent)]
    RPCError(#[from] jsonrpsee::core::Error),
    #[error(transparent)]
    MailboxError(#[from] actix::MailboxError),
    #[error(transparent)]
    P2PError(#[from] seda_p2p::P2PAdapterError),
    #[error("Reqwest Error: {0}")]
    ReqwestError(#[from] reqwest::Error),
    #[error("Rusqlite Error: {0}")]
    RuqliteError(#[from] rusqlite::Error),
    #[error("Chain Adapter Error: {0}")]
    ChainAdapterError(#[from] seda_chains::ChainAdapterError),
    #[error("Missing app actor address in host adapter, was the node booted?")]
    MissingAppActorAddress,
}

pub type Result<T, E = NodeError> = core::result::Result<T, E>;

'''
'''--- node/src/event_queue.rs ---
use seda_runtime_sdk::events::Event;
use serde::{Deserialize, Serialize};

#[derive(Default, Debug, Serialize, Deserialize)]
pub struct EventQueue {
    items: Vec<Event>,
}

impl EventQueue {
    pub fn add(&mut self, event: Event) {
        self.items.push(event);
    }

    pub fn get_next(&mut self, skip_ids: &[String]) -> Option<Event> {
        for index in 0..self.items.len() {
            if skip_ids.contains(&self.items[index].id) {
                continue;
            }

            let item = self.items.remove(index);
            return Some(item);
        }

        None
    }
}

'''
'''--- node/src/event_queue_handler.rs ---
use actix::{Handler, Message};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::events::Event;
use serde::{Deserialize, Serialize};

use crate::app::App;

#[derive(Message, Serialize, Deserialize)]
#[rtype(result = "()")]
pub struct AddEventToQueue {
    pub event: Event,
}

impl From<Event> for AddEventToQueue {
    fn from(event: Event) -> Self {
        AddEventToQueue { event }
    }
}

impl<HA: HostAdapter> Handler<AddEventToQueue> for App<HA> {
    type Result = ();

    fn handle(&mut self, msg: AddEventToQueue, _ctx: &mut Self::Context) -> Self::Result {
        let mut event_queue = self.event_queue.write();

        event_queue.add(msg.event);
    }
}

'''
'''--- node/src/event_queue_test.rs ---
use seda_runtime_sdk::events::{Event, EventData};

use crate::event_queue::EventQueue;

#[test]
fn add_item_to_event_queue() {
    let mut queue = EventQueue::default();

    queue.add(Event {
        id:   "test-id".to_string(),
        data: EventData::ChainTick,
    });

    let item = queue.get_next(&[]).unwrap();

    assert_eq!(item.id, "test-id".to_string());
}

#[test]
fn get_item_with_skip() {
    let mut queue = EventQueue::default();

    queue.add(Event {
        id:   "test-id".to_string(),
        data: EventData::ChainTick,
    });

    queue.add(Event {
        id:   "test-id-2".to_string(),
        data: EventData::ChainTick,
    });

    let item = queue.get_next(&["test-id".to_string()]).unwrap();

    assert_eq!(item.id, "test-id-2".to_string());
}

#[test]
fn get_item_should_empty_queue() {
    let mut queue = EventQueue::default();

    queue.add(Event {
        id:   "test-id".to_string(),
        data: EventData::ChainTick,
    });

    queue.add(Event {
        id:   "test-id-2".to_string(),
        data: EventData::ChainTick,
    });

    let item = queue.get_next(&[]).unwrap();
    let item2 = queue.get_next(&[]).unwrap();
    let item3 = queue.get_next(&[]);

    assert_eq!(item.id, "test-id".to_string());
    assert_eq!(item2.id, "test-id-2".to_string());
    assert!(item3.is_none());
}

#[test]
fn get_item_should_empty_queue_with_skip() {
    let mut queue = EventQueue::default();

    queue.add(Event {
        id:   "test-id".to_string(),
        data: EventData::ChainTick,
    });

    queue.add(Event {
        id:   "test-id-2".to_string(),
        data: EventData::ChainTick,
    });

    let item = queue.get_next(&["test-id".to_string()]).unwrap();
    let item2 = queue.get_next(&["test-id".to_string()]);

    assert_eq!(item.id, "test-id-2".to_string());
    assert!(item2.is_none());
}

'''
'''--- node/src/host/batch_tick.rs ---
use std::time::Duration;

use actix::{AsyncContext, Handler, Message};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::events::{Event, EventData};

use super::Host;
use crate::event_queue_handler::AddEventToQueue;

#[derive(Message)]
#[rtype(result = "()")]
pub struct BatchTickManager;

impl BatchTickManager {
    // In ms
    const BATCH_TICK_INTERVAL: u64 = 1000 * 10;
}

impl<HA: HostAdapter> Handler<BatchTickManager> for Host<HA> {
    type Result = ();

    fn handle(&mut self, msg: BatchTickManager, ctx: &mut Self::Context) -> Self::Result {
        let event = Event::new("BatchChainTick", EventData::BatchChainTick);
        if let Some(app) = self.app_actor_addr.as_ref() {
            app.do_send::<AddEventToQueue>(event.into());
        }

        ctx.notify_later(msg, Duration::from_millis(BatchTickManager::BATCH_TICK_INTERVAL));
    }
}

'''
'''--- node/src/host/chain_call.rs ---
use actix::prelude::*;
use seda_chains::{chain, Client};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::Chain;

use crate::{Host, Result};
#[derive(Message)]
#[rtype(result = "Result<Vec<u8>>")]
pub struct ChainCall {
    pub chain:         Chain,
    pub contract_id:   String,
    pub method_name:   String,
    pub args:          Vec<u8>,
    pub client:        Client,
    pub deposit:       u128,
    pub node_config:   NodeConfig,
    pub chains_config: ChainConfigs,
}

impl ChainCall {
    pub async fn call_bytes(self) -> Result<Vec<u8>> {
        let server_url = match self.chain {
            Chain::Another => &self.chains_config.another.chain_rpc_url,
            Chain::Near => &self.chains_config.near.chain_rpc_url,
        };
        let keypair_ed25519: Vec<u8> = self.node_config.keypair_ed25519.as_ref().into();

        let signed_txn = chain::construct_signed_tx(
            self.chain,
            None,
            &keypair_ed25519,
            &self.contract_id,
            &self.method_name,
            self.args,
            self.node_config.gas,
            self.deposit,
            server_url,
        )
        .await?;
        let value = chain::send_tx(self.chain, self.client, &signed_txn).await?;

        Ok(value)
    }
}

impl<HA: HostAdapter> Handler<ChainCall> for Host<HA> {
    type Result = ResponseActFuture<Self, Result<Vec<u8>>>;

    fn handle(&mut self, msg: ChainCall, _ctx: &mut Self::Context) -> Self::Result {
        Box::pin(msg.call_bytes().into_actor(self))
    }
}

'''
'''--- node/src/host/chain_view.rs ---
use actix::prelude::*;
use seda_chains::{chain, Client};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::Chain;

use crate::{Host, Result};

#[derive(Message)]
#[rtype(result = "Result<Vec<u8>>")]
pub struct ChainView {
    pub chain:       Chain,
    pub contract_id: String,
    pub method_name: String,
    pub args:        Vec<u8>,
    pub client:      Client,
}

impl ChainView {
    pub async fn view(self) -> Result<Vec<u8>> {
        let value = chain::view(self.chain, self.client, &self.contract_id, &self.method_name, self.args).await?;

        Ok(value)
    }
}

impl<HA: HostAdapter> Handler<ChainView> for Host<HA> {
    type Result = ResponseActFuture<Self, Result<Vec<u8>>>;

    fn handle(&mut self, msg: ChainView, _ctx: &mut Self::Context) -> Self::Result {
        Box::pin(msg.view().into_actor(self))
    }
}

'''
'''--- node/src/host/db_get.rs ---
use actix::prelude::*;
use seda_runtime::HostAdapter;
use serde::{Deserialize, Serialize};

use crate::{Host, NodeError, Result};

#[derive(Message, Serialize, Deserialize)]
#[rtype(result = "Result<Option<String>>")]
pub struct DatabaseGet {
    pub key: String,
}

impl<HA: HostAdapter> Handler<DatabaseGet> for Host<HA> {
    type Result = ResponseActFuture<Self, Result<Option<String>>>;

    fn handle(&mut self, msg: DatabaseGet, _ctx: &mut Self::Context) -> Self::Result {
        let db_conn = self.db_conn.clone();

        let fut = async move {
            let value = db_conn
                .call(move |conn| {
                    let mut stmt = conn.prepare("SELECT value FROM data WHERE key = ?1")?;
                    let mut retrieved: Option<String> = None;

                    stmt.query_row([msg.key], |row| {
                        retrieved = row.get(0)?;
                        Ok(())
                    })?;
                    Ok::<_, NodeError>(retrieved)
                })
                .await?;

            Ok(value)
        };

        Box::pin(fut.into_actor(self))
    }
}

'''
'''--- node/src/host/db_set.rs ---
use actix::prelude::*;
use rusqlite::params;
use seda_runtime::HostAdapter;
use serde::{Deserialize, Serialize};

use crate::{Host, NodeError, Result};

#[derive(Message, Serialize, Deserialize)]
#[rtype(result = "Result<()>")]
pub struct DatabaseSet {
    pub key:   String,
    pub value: String,
}

impl<HA: HostAdapter> Handler<DatabaseSet> for Host<HA> {
    type Result = ResponseActFuture<Self, Result<()>>;

    fn handle(&mut self, msg: DatabaseSet, _ctx: &mut Self::Context) -> Self::Result {
        let db_conn = self.db_conn.clone();

        let fut = async move {
            db_conn
                .call(move |conn| {
                    conn.execute(
                        "INSERT INTO data (key, value) VALUES (?1, ?2)",
                        params![msg.key, msg.value],
                    )?;

                    Ok::<_, NodeError>(())
                })
                .await?;

            Ok(())
        };

        Box::pin(fut.into_actor(self))
    }
}

'''
'''--- node/src/host/http_fetch.rs ---
use actix::prelude::*;
use seda_runtime::HostAdapter;
use serde::{Deserialize, Serialize};

use super::Host;

#[derive(Message, Serialize, Deserialize)]
#[rtype(result = "String")]
pub struct HttpFetch {
    pub url: String,
}

impl<HA: HostAdapter> Handler<HttpFetch> for Host<HA> {
    type Result = ResponseActFuture<Self, String>;

    fn handle(&mut self, msg: HttpFetch, _ctx: &mut Self::Context) -> Self::Result {
        let fut = async { reqwest::get(msg.url).await.unwrap().text().await.unwrap() };

        Box::pin(fut.into_actor(self))
    }
}

'''
'''--- node/src/host/mod.rs ---
mod batch_tick;
pub use batch_tick::*;

mod db_get;
pub use db_get::*;

mod db_set;
pub use db_set::*;

mod http_fetch;
pub use http_fetch::HttpFetch;
use rusqlite::params;
use seda_runtime::HostAdapter;
use tokio_rusqlite::Connection;

mod chain_call;
pub use chain_call::ChainCall;

mod chain_view;
pub use chain_view::ChainView;

mod trigger_event;
pub use trigger_event::TriggerEvent;

mod runtime_host;
use actix::prelude::*;
use futures::executor;
pub use runtime_host::*;

mod set_app_addr;
pub use set_app_addr::*;

use crate::{app::App, NodeError};

pub struct Host<HA: HostAdapter> {
    db_conn:        Connection,
    app_actor_addr: Option<Addr<App<HA>>>,
}

impl<HA: HostAdapter> Default for Host<HA> {
    fn default() -> Self {
        executor::block_on(async move {
            let db_conn = Connection::open("./seda_db.db3").await.expect("Couldn't open db conn");

            db_conn
                .call(|db_conn| {
                    db_conn
                        .execute(
                            "CREATE TABLE IF NOT EXISTS data (
                                key TEXT,
                                value TEXT NOT NULL
                            )",
                            params![],
                        )
                        .expect("couldn't create db table");

                    Ok::<_, NodeError>(())
                })
                .await
                .expect("Couldn't execute db call");

            Host {
                db_conn,
                app_actor_addr: None,
            }
        })
    }
}

impl<HA: HostAdapter> Actor for Host<HA> {
    type Context = Context<Self>;
}

impl<HA: HostAdapter> actix::Supervised for Host<HA> {}

impl<HA: HostAdapter> SystemService for Host<HA> {}

'''
'''--- node/src/host/runtime_host.rs ---
use actix::prelude::*;
use seda_chains::{AnotherChain, ChainAdapterTrait, Client, NearChain};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::{events::Event, Chain};

use crate::{ChainCall, ChainView, DatabaseGet, DatabaseSet, Host, HttpFetch, NodeError, Result, TriggerEvent};

/// A communication layer between Actix and the runtime
pub struct RuntimeAdapter {
    pub chains_config:  ChainConfigs,
    pub another_client: Client,
    pub near_client:    Client,
}

#[async_trait::async_trait]
impl HostAdapter for RuntimeAdapter {
    type Error = NodeError;

    async fn new(config: ChainConfigs) -> Result<Self> {
        Ok(Self {
            another_client: Client::Another(AnotherChain::new_client(&config.another)?),
            near_client:    Client::Near(NearChain::new_client(&config.near)?),
            chains_config:  config,
        })
    }

    fn select_client_from_chain(&self, chain: Chain) -> Client {
        match chain {
            Chain::Another => self.another_client.clone(),
            Chain::Near => self.near_client.clone(),
        }
    }

    async fn db_get(&self, key: &str) -> Result<Option<String>> {
        let host_actor = Host::<Self>::from_registry();

        let result = host_actor.send(DatabaseGet { key: key.to_string() }).await??;

        Ok(result)
    }

    async fn db_set(&self, key: &str, value: &str) -> Result<()> {
        let host_actor = Host::<Self>::from_registry();

        host_actor
            .send(DatabaseSet {
                key:   key.to_string(),
                value: value.to_string(),
            })
            .await??;

        Ok(())
    }

    async fn http_fetch(&self, url: &str) -> Result<String> {
        let host_actor = Host::<Self>::from_registry();

        let result = host_actor.send(HttpFetch { url: url.to_string() }).await?;

        Ok(result)
    }

    async fn chain_call(
        &self,
        chain: Chain,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        deposit: u128,
        node_config: NodeConfig,
    ) -> Result<Vec<u8>> {
        let host_actor = Host::<Self>::from_registry();
        let client = self.select_client_from_chain(chain);
        let result = host_actor
            .send(ChainCall {
                chain,
                contract_id: contract_id.to_string(),
                method_name: method_name.to_string(),
                args,
                client,
                deposit,
                node_config,
                chains_config: self.chains_config.clone(),
            })
            .await??;

        Ok(result)
    }

    async fn chain_view(&self, chain: Chain, contract_id: &str, method_name: &str, args: Vec<u8>) -> Result<Vec<u8>> {
        let host_actor = Host::<Self>::from_registry();
        let client = self.select_client_from_chain(chain);
        let result = host_actor
            .send(ChainView {
                chain,
                contract_id: contract_id.to_string(),
                method_name: method_name.to_string(),
                args,
                client,
            })
            .await??;

        Ok(result)
    }

    async fn trigger_event(&self, event: Event) -> Result<()> {
        let host_actor = Host::<Self>::from_registry();
        host_actor.send(TriggerEvent { event }).await??;

        Ok(())
    }
}

'''
'''--- node/src/host/set_app_addr.rs ---
use actix::{Addr, Handler, Message};
use seda_runtime::HostAdapter;

use super::Host;
use crate::app::App;

/// We need to set the app address in order to access the event queue
/// The VM has the ability to add events to this queue (resolve dr, resolve
/// block, etc)
#[derive(Message)]
#[rtype(result = "()")]
pub struct SetAppAddress<HA: HostAdapter> {
    pub address: Addr<App<HA>>,
}

impl<HA: HostAdapter> Handler<SetAppAddress<HA>> for Host<HA> {
    type Result = ();

    fn handle(&mut self, msg: SetAppAddress<HA>, _ctx: &mut Self::Context) -> Self::Result {
        self.app_actor_addr = Some(msg.address);
    }
}

'''
'''--- node/src/host/trigger_event.rs ---
//! Communication layer between App & Host adapter
//! We send a message to trigger an event to the host actor
//! which redirects the message to the app actor
use actix::prelude::*;
use seda_runtime::HostAdapter;
use seda_runtime_sdk::events::Event;
use serde::{Deserialize, Serialize};

use crate::{event_queue_handler::AddEventToQueue, Host, NodeError::MissingAppActorAddress, Result};

#[derive(Message, Serialize, Deserialize)]
#[rtype(result = "Result<()>")]
pub struct TriggerEvent {
    pub event: Event,
}

impl<HA: HostAdapter> Handler<TriggerEvent> for Host<HA> {
    type Result = Result<()>;

    fn handle(&mut self, msg: TriggerEvent, _ctx: &mut Self::Context) -> Self::Result {
        if let Some(app_actor) = self.app_actor_addr.clone() {
            app_actor.do_send(AddEventToQueue { event: msg.event });

            return Ok(());
        }

        Err(MissingAppActorAddress)
    }
}

'''
'''--- node/src/lib.rs ---
mod app;

use std::sync::Arc;

use app::{p2p_message_handler::P2PMessageHandler, App};
mod errors;
pub use errors::*;
mod event_queue;
mod event_queue_handler;
mod rpc;
mod runtime_job;

mod host;

use actix::prelude::*;
pub(crate) use host::*;
pub use host::{ChainCall, ChainView};
use parking_lot::RwLock;
use seda_config::{ChainConfigs, NodeConfig, P2PConfig};
use seda_p2p::{libp2p::P2PServer, DiscoveryStatusInner, PeerList};
use seda_runtime_sdk::p2p::{P2PCommand, P2PMessage};
use tokio::sync::mpsc::channel;
use tracing::info;

use crate::app::Shutdown;

#[cfg(test)]
#[path = ""]
pub mod test {
    mod event_queue_test;
}
pub fn run(seda_server_address: &str, config: NodeConfig, p2p_config: P2PConfig, chain_configs: ChainConfigs) {
    let system = System::new();
    // Initialize actors inside system context
    system.block_on(async {
        let (p2p_message_sender, p2p_message_receiver) = channel::<P2PMessage>(100);
        let (p2p_command_sender, p2p_command_receiver) = channel::<P2PCommand>(100);

        let known_peers = PeerList::from_vec(&p2p_config.p2p_known_peers);
        let discovery_status = Arc::new(RwLock::new(DiscoveryStatusInner::new(p2p_config.clone(), known_peers)));

        // TODO: add number of workers as config with default value
        let app = App::<RuntimeAdapter>::new(
            config.clone(),
            seda_server_address,
            chain_configs,
            p2p_command_sender,
            discovery_status.clone(),
        )
        .await
        .start();

        let mut p2p_server = P2PServer::new(
            discovery_status.clone(),
            p2p_config.clone(),
            p2p_message_sender,
            p2p_command_receiver,
        )
        .await
        .expect("P2P swarm cannot be started");

        // P2P initialization
        // TODO: most probably this process should be moved somewhere else
        actix::spawn(async move {
            p2p_server.start().await;
            p2p_server.loop_stream().await.expect("P2P Loop failed");
        });

        // Listens for p2p messages and sents the to the event queue
        let mut p2p_message_handler = P2PMessageHandler::new(p2p_message_receiver, app.clone());
        actix::spawn(async move {
            p2p_message_handler.listen().await;
        });

        // Intercept ctrl+c to stop gracefully the system
        actix::spawn(async move {
            tokio::signal::ctrl_c().await.expect("failed to listen for event");
            info!("\nStopping the node gracefully...");

            app.do_send(Shutdown);
        });
    });

    let code = system.run_with_code();
    std::process::exit(code.expect("Actix should return an exit code"));
}

'''
'''--- node/src/rpc.rs ---
use std::str::FromStr;

use actix::prelude::*;
use jsonrpsee::{
    core::{async_trait, Error},
    proc_macros::rpc,
    server::{ServerBuilder, ServerHandle},
};
use seda_p2p::{
    libp2p::{Multiaddr, PeerId},
    DiscoveryStatus,
};
use seda_runtime::HostAdapter;
use seda_runtime_sdk::{
    events::{Event, EventData},
    p2p::{AddPeerCommand, P2PCommand, RemovePeerCommand},
};
use serde_json::Value;
use tokio::sync::mpsc::Sender;
use tracing::debug;

use crate::runtime_job::{RuntimeJob, RuntimeWorker};

#[rpc(server)]
pub trait Rpc {
    #[method(name = "cli")]
    async fn cli(&self, args: Vec<String>) -> Result<Vec<String>, Error>;

    #[method(name = "add_peer")]
    async fn add_peer(&self, multi_addr: String) -> Result<(), Error>;

    #[method(name = "list_peers")]
    async fn list_peers(&self) -> Result<Value, Error>;

    #[method(name = "remove_peer")]
    async fn remove_peer(&self, peer_id: String) -> Result<(), Error>;

    #[method(name = "discover_peers")]
    async fn discover_peers(&self) -> Result<(), Error>;
}

pub struct CliServer<HA: HostAdapter> {
    runtime_worker:             Addr<RuntimeWorker<HA>>,
    p2p_command_sender_channel: Sender<P2PCommand>,
    discovery_status:           DiscoveryStatus,
}

#[async_trait]
impl<HA: HostAdapter> RpcServer for CliServer<HA> {
    async fn cli(&self, args: Vec<String>) -> Result<Vec<String>, Error> {
        debug!("{:?}", &args);

        let result = self
            .runtime_worker
            .send(RuntimeJob {
                event: Event {
                    id:   "test".to_string(),
                    data: EventData::CliCall(args),
                },
            })
            .await
            .map_err(|err| Error::Custom(err.to_string()))?;

        Ok(result.map_err(|err| Error::Custom(err.to_string()))?.vm_result.stderr)
    }

    async fn add_peer(&self, multi_addr: String) -> Result<(), Error> {
        // To check before hand if the input is valid
        if let Err(err) = Multiaddr::from_str(&multi_addr) {
            return Err(Error::Custom(err.to_string()));
        }

        self.p2p_command_sender_channel
            .send(P2PCommand::AddPeer(AddPeerCommand { multi_addr }))
            .await
            .map_err(|err| Error::Custom(err.to_string()))?;

        Ok(())
    }

    async fn list_peers(&self) -> Result<Value, Error> {
        let peer_list = self.discovery_status.read();
        let result = peer_list.connected_peers.get_json();

        Ok(result)
    }

    async fn remove_peer(&self, peer_id: String) -> Result<(), Error> {
        if let Err(err) = PeerId::from_str(&peer_id) {
            return Err(Error::Custom(err.to_string()));
        }

        self.p2p_command_sender_channel
            .send(P2PCommand::RemovePeer(RemovePeerCommand { peer_id }))
            .await
            .map_err(|err| Error::Custom(err.to_string()))?;

        Ok(())
    }

    async fn discover_peers(&self) -> Result<(), Error> {
        self.p2p_command_sender_channel
            .send(P2PCommand::DiscoverPeers)
            .await
            .map_err(|err| Error::Custom(err.to_string()))?;

        Ok(())
    }
}
pub struct JsonRpcServer {
    handle: ServerHandle,
}

impl JsonRpcServer {
    pub async fn start<HA: HostAdapter>(
        runtime_worker: Addr<RuntimeWorker<HA>>,
        addrs: &str,
        p2p_command_sender_channel: Sender<P2PCommand>,
        discovery_status: DiscoveryStatus,
    ) -> Result<Self, Error> {
        let server = ServerBuilder::default().build(addrs).await?;
        let rpc = CliServer {
            runtime_worker,
            p2p_command_sender_channel,
            discovery_status,
        };
        let handle = server.start(rpc.into_rpc())?;

        Ok(Self { handle })
    }

    pub fn stop(&mut self) -> Result<(), Error> {
        self.handle.clone().stop()?;

        Ok(())
    }
}

'''
'''--- node/src/runtime_job.rs ---
use std::{fs, sync::Arc};

use actix::{prelude::*, Handler, Message};
use parking_lot::{Mutex, RwLock};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime::{HostAdapter, InMemory, Result, RunnableRuntime, Runtime, VmConfig, VmResult};
use seda_runtime_sdk::{
    events::{Event, EventData},
    p2p::P2PCommand,
    FromBytes,
};
use tokio::sync::mpsc::Sender;
use tracing::info;

#[derive(MessageResponse)]
pub struct RuntimeJobResult {
    pub vm_result: VmResult,
}

#[derive(Message)]
#[rtype(result = "Result<RuntimeJobResult>")]
pub struct RuntimeJob {
    pub event: Event,
}

pub struct RuntimeWorker<HA: HostAdapter> {
    pub runtime:                    Option<Runtime<HA>>,
    pub node_config:                NodeConfig,
    pub chain_configs:              ChainConfigs,
    pub p2p_command_sender_channel: Sender<P2PCommand>,
    pub shared_memory:              Arc<RwLock<InMemory>>,
}

impl<HA: HostAdapter> Actor for RuntimeWorker<HA> {
    type Context = SyncContext<Self>;

    fn started(&mut self, _ctx: &mut Self::Context) {
        let node_config = self.node_config.clone();
        let chain_configs = self.chain_configs.clone();
        let shared_memory = self.shared_memory.clone();
        // TODO: when conditionally loading the consensus binary see if it allows full
        // or limited features
        let mut runtime = futures::executor::block_on(async move {
            Runtime::new(node_config, chain_configs, shared_memory, false)
                .await
                .expect("TODO")
        });

        runtime
            .init(fs::read(&self.node_config.consensus_wasm_path).unwrap())
            .unwrap();

        self.runtime = Some(runtime);
    }
}

impl<HA: HostAdapter> Handler<RuntimeJob> for RuntimeWorker<HA> {
    type Result = Result<RuntimeJobResult>;

    fn handle(&mut self, msg: RuntimeJob, _ctx: &mut Self::Context) -> Self::Result {
        let memory_adapter = Arc::new(Mutex::new(InMemory::default()));

        let args: Vec<String> = match msg.event.data {
            EventData::BatchChainTick => vec!["batch".to_string()],
            EventData::ChainTick => vec![],
            EventData::CliCall(args) => args,
            // TODO: Make args accept bytes only
            EventData::P2PMessage(message) => {
                vec!["p2p".to_string(), String::from_bytes_vec(message.data).unwrap()]
            }
        };

        let vm_config = VmConfig {
            args,
            program_name: "test".to_string(),
            debug: false,
            start_func: None,
        };

        let runtime = self.runtime.as_ref().unwrap();

        let res = futures::executor::block_on(runtime.start_runtime(
            vm_config,
            memory_adapter,
            self.p2p_command_sender_channel.clone(),
        ));
        // TODO maybe set up a prettier log format rather than debug of this type?
        info!(vm_result = ?res);

        Ok(RuntimeJobResult { vm_result: res })
    }
}

'''
'''--- p2p/Cargo.toml ---
[package]
name = "seda-p2p"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
# TODO: remove dep this after removing stdin
async-std = { version = "1.12.0" }
tokio = { workspace = true }
libp2p = { workspace = true, features = [
	"gossipsub",
	"noise",
	"yamux",
	"mdns",
	"tcp",
	"macros",
	"async-std",
	"kad"
] }
parking_lot = { workspace = true }
seda-config = { workspace = true }
seda-runtime-sdk = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }

[dev-dependencies]
seda-config = { workspace = true }
tokio = { workspace = true, features = ["macros", "rt-multi-thread"] }

'''
'''--- p2p/src/errors.rs ---
use thiserror::Error;

#[derive(Error, Debug)]
pub enum P2PAdapterError {
    #[error("libp2p transport error: {0}")]
    Trasnport(#[from] libp2p::TransportError<std::io::Error>),
    #[error("libp2p gossip error {0}")]
    Gossip(String),
    #[error("libp2p gossip subscription error {0}")]
    GossipSubscription(#[from] libp2p::gossipsub::error::SubscriptionError),
    #[error("libp2p io error {0}")]
    Io(#[from] std::io::Error),
    #[error("libp2p multi addr error: {0}")]
    MultiAddr(#[from] libp2p::multiaddr::Error),
    #[error("libp2p dial error: {0}")]
    DialError(#[from] libp2p::swarm::DialError),
}

pub type Result<T, E = P2PAdapterError> = core::result::Result<T, E>;

'''
'''--- p2p/src/lib.rs ---
mod errors;
pub use errors::*;

pub mod libp2p;

pub use crate::libp2p::{
    discovery_status::{DiscoveryStatus, DiscoveryStatusInner},
    peer_list::PeerList,
};

'''
'''--- p2p/src/libp2p/behaviour.rs ---
use std::{
    collections::hash_map::DefaultHasher,
    hash::{Hash, Hasher},
    time::Duration,
};

use libp2p::{
    gossipsub::{
        Gossipsub,
        GossipsubConfigBuilder,
        GossipsubEvent,
        GossipsubMessage,
        IdentTopic,
        MessageAuthenticity,
        MessageId,
        ValidationMode,
    },
    identity::Keypair,
    kad::{store::MemoryStore, Kademlia, KademliaConfig, KademliaEvent},
    mdns::{self},
    swarm::NetworkBehaviour,
    PeerId,
};

use super::{super::errors::Result, GOSSIP_TOPIC};
use crate::P2PAdapterError;

/// Handles all P2P protocols needed for SEDA.
#[derive(NetworkBehaviour)]
#[behaviour(out_event = "SedaBehaviourEvent")]
pub struct SedaBehaviour {
    /// Message propagation
    pub gossipsub: Gossipsub,
    // TODO: change discovery mechanism
    pub mdns:      mdns::async_io::Behaviour,

    pub kademlia: Kademlia<MemoryStore>,
}

impl SedaBehaviour {
    pub async fn new(key_pair: &Keypair) -> Result<Self> {
        let create_message_id = |message: &GossipsubMessage| {
            let mut hasher = DefaultHasher::new();
            message.data.hash(&mut hasher);
            MessageId::from(hasher.finish().to_string())
        };

        let gossipsub_config = GossipsubConfigBuilder::default()
            .heartbeat_interval(Duration::from_secs(5))
            .validation_mode(ValidationMode::Strict)
            .message_id_fn(create_message_id)
            .build()
            .expect("Valid config");

        let mut gossipsub = Gossipsub::new(MessageAuthenticity::Signed(key_pair.clone()), gossipsub_config)
            .map_err(|e| P2PAdapterError::Gossip(e.to_string()))?;

        let topic = IdentTopic::new(GOSSIP_TOPIC);
        gossipsub.subscribe(&topic)?;

        let local_peer_id = PeerId::from(key_pair.public());
        let mut kademlia_config = KademliaConfig::default();
        kademlia_config.disjoint_query_paths(true);
        kademlia_config.set_kbucket_inserts(libp2p::kad::KademliaBucketInserts::Manual);

        let kademlia_memory_store = MemoryStore::new(local_peer_id);
        let kademlia = Kademlia::with_config(local_peer_id, kademlia_memory_store, kademlia_config);

        Ok(Self {
            mdns: mdns::async_io::Behaviour::new(mdns::Config::default())?,
            gossipsub,
            kademlia,
        })
    }
}

pub enum SedaBehaviourEvent {
    Gossipsub(GossipsubEvent),
    Mdns(mdns::Event),
    Kademlia(KademliaEvent),
}

impl From<mdns::Event> for SedaBehaviourEvent {
    fn from(event: mdns::Event) -> Self {
        Self::Mdns(event)
    }
}

impl From<GossipsubEvent> for SedaBehaviourEvent {
    fn from(event: GossipsubEvent) -> Self {
        Self::Gossipsub(event)
    }
}

impl From<KademliaEvent> for SedaBehaviourEvent {
    fn from(event: KademliaEvent) -> Self {
        Self::Kademlia(event)
    }
}

'''
'''--- p2p/src/libp2p/discovery_status.rs ---
use std::{collections::HashMap, sync::Arc, time::SystemTime};

use libp2p::{Multiaddr, PeerId};
use parking_lot::RwLock;
use seda_config::P2PConfig;

use super::peer_list::{ConnectionType, PeerInfo};
use crate::PeerList;

/// The manager should use this
/// The manager should not check the config but just have a switch statement
/// This struct will check all connections and config which discovery method
/// should be used

pub struct DiscoveryStatusInner {
    p2p_config: P2PConfig,

    pub connected_peers: PeerList,

    /// Peers who should not be connected to until the cooldown period has ended
    /// This prevents the manager to try to connect to the same failing peer
    cooldown_addrs: HashMap<Multiaddr, SystemTime>,

    // Peers that have been found by a discovery mechanism
    // but don't have to be connected, we can use this if we want to add them
    found_manual_peers:   PeerList,
    found_chain_peers:    PeerList,
    found_mdns_peers:     PeerList,
    found_kademlia_peers: PeerList,
}

impl DiscoveryStatusInner {
    pub fn new(p2p_config: P2PConfig, inital_manual_peers: PeerList) -> Self {
        Self {
            p2p_config,
            found_manual_peers: inital_manual_peers,
            found_chain_peers: PeerList::default(),
            found_mdns_peers: PeerList::default(),
            found_kademlia_peers: PeerList::default(),
            connected_peers: PeerList::default(),
            cooldown_addrs: HashMap::default(),
        }
    }

    fn get_connected_len_by_type(&self, connection_type: ConnectionType) -> usize {
        self.connected_peers
            .get_all_info()
            .iter()
            .filter(|(_addr, info)| info.conn_type == connection_type)
            .count()
    }

    pub fn get_connected_list(&self) -> PeerList {
        self.connected_peers.clone()
    }

    /// Checks if the peer is already connected to and hasn't been tried
    /// recently
    fn is_unused_addr(&mut self, addr: &Multiaddr) -> bool {
        if self.connected_peers.has_addr(addr) {
            return false;
        }

        if let Some(peer_cooldowned_time) = self.cooldown_addrs.get(addr) {
            let now = SystemTime::now();

            // When the cooldown period has exceeded
            if now > (*peer_cooldowned_time + self.p2p_config.cooldown_duration) {
                self.cooldown_addrs.remove(addr);
                return true;
            }

            return false;
        }

        true
    }

    /// Gets the discovery method the manager should use
    /// Based on priority and maximum allowed peers from that specific discovery
    /// method
    /// * `skip` - Allows to skip any higher or equal priority then the one
    ///   given (if for example we already exhausted that source)
    pub fn get_current_discovery_method(&self, skip: Option<ConnectionType>) -> ConnectionType {
        // We already reached the maximum required peers, we don't need more
        if self.connected_peers.len() as i32 >= self.p2p_config.out_peers {
            return ConnectionType::None;
        }

        let skip = skip.unwrap_or(ConnectionType::None);

        if !self.p2p_config.disable_manual_peers
            && self.get_connected_len_by_type(ConnectionType::Manual) < (self.p2p_config.max_manual_peers as usize)
            && skip < ConnectionType::Manual
        {
            return ConnectionType::Manual;
        }

        if !self.p2p_config.disable_mdns
            && self.get_connected_len_by_type(ConnectionType::MDns) < (self.p2p_config.max_mdns_peers as usize)
            && skip < ConnectionType::MDns
        {
            return ConnectionType::MDns;
        }

        if !self.p2p_config.disable_kademlia_peers
            && self.get_connected_len_by_type(ConnectionType::Kademlia) < (self.p2p_config.max_kademlia_peers as usize)
            && skip < ConnectionType::Kademlia
        {
            return ConnectionType::Kademlia;
        }

        ConnectionType::None
    }

    pub fn cooldown_addr(&mut self, addr: Multiaddr) {
        println!("Added {addr} to cooldown");
        self.cooldown_addrs.insert(addr, SystemTime::now());
    }

    pub fn add_connected_peer(&mut self, addr: Multiaddr, peer_id: PeerId) {
        self.connected_peers.set_peer_id(addr, peer_id);
    }

    pub fn remove_connected_peer(&mut self, peer_id: Option<&PeerId>, address: Option<&Multiaddr>) {
        if let Some(peer_id) = peer_id {
            if let Some((_addr, peer_info)) = self.connected_peers.get_peer_by_id(peer_id) {
                match peer_info.conn_type {
                    ConnectionType::Chain => self.found_chain_peers.remove_peer_by_id(peer_id),
                    ConnectionType::Kademlia => self.found_kademlia_peers.remove_peer_by_id(peer_id),
                    ConnectionType::MDns => self.found_mdns_peers.remove_peer_by_id(peer_id),
                    // Manual peers (and none) should not remove anything
                    // We are expecting them to maybe be available again
                    _ => {}
                }
            }

            self.connected_peers.remove_peer_by_id(peer_id);
        }

        if let Some(addr) = address {
            if let Some(peer_info) = self.connected_peers.get_peer_by_addr(addr) {
                match peer_info.conn_type {
                    ConnectionType::Chain => self.found_chain_peers.remove_peer_by_addr(addr),
                    ConnectionType::Kademlia => self.found_kademlia_peers.remove_peer_by_addr(addr),
                    ConnectionType::MDns => self.found_mdns_peers.remove_peer_by_addr(addr),
                    // Manual peers (and none) should not remove anything
                    // We are expecting them to maybe be available again
                    _ => {}
                }
            }

            self.connected_peers.remove_peer_by_addr(addr);
        }
    }

    pub fn get_next_manual_peer(&mut self) -> Option<(Multiaddr, PeerInfo)> {
        for (addr, peer_info) in self.found_manual_peers.get_all_info().iter() {
            if self.is_unused_addr(addr) {
                self.connected_peers
                    .add_peer(addr.clone(), peer_info.peer_id, ConnectionType::Manual);

                return Some((addr.clone(), peer_info.clone()));
            }
        }

        None
    }

    pub fn add_mdns_peer(&mut self, addr: Multiaddr, peer_id: PeerId) {
        self.found_mdns_peers
            .add_peer(addr, Some(peer_id), ConnectionType::MDns);
    }

    pub fn get_next_mdns_peer(&mut self) -> Option<(Multiaddr, PeerInfo)> {
        for (addr, peer_info) in self.found_mdns_peers.get_all_info().iter() {
            if self.is_unused_addr(addr) {
                self.connected_peers
                    .add_peer(addr.clone(), peer_info.peer_id, ConnectionType::MDns);

                return Some((addr.clone(), peer_info.clone()));
            }
        }

        None
    }

    pub fn add_kademlia_peer(&mut self, addr: Multiaddr, peer_id: PeerId) {
        self.found_kademlia_peers
            .add_peer(addr, Some(peer_id), ConnectionType::Kademlia);
    }

    pub fn get_next_kademlia_peer(&mut self) -> Option<(Multiaddr, PeerInfo)> {
        for (addr, peer_info) in self.found_kademlia_peers.get_all_info().iter() {
            if self.is_unused_addr(addr) {
                self.connected_peers
                    .add_peer(addr.clone(), peer_info.peer_id, ConnectionType::Kademlia);

                return Some((addr.clone(), peer_info.clone()));
            }
        }

        None
    }

    pub fn add_manual_peer(&mut self, addr: Multiaddr, peer_id: Option<PeerId>) {
        self.found_kademlia_peers
            .add_peer(addr, peer_id, ConnectionType::Kademlia);
    }
}

pub type DiscoveryStatus = Arc<RwLock<DiscoveryStatusInner>>;

'''
'''--- p2p/src/libp2p/libp2p_test.rs ---
use std::sync::Arc;

use libp2p::{futures::StreamExt, swarm::SwarmEvent};
use parking_lot::RwLock;
use seda_config::P2PConfigInner;
use seda_runtime_sdk::p2p::{P2PCommand, P2PMessage};
use tokio::sync::mpsc::channel;

use super::P2PServer;
use crate::{libp2p::peer_list::PeerList, DiscoveryStatusInner};

#[tokio::test]
async fn p2p_service_works() {
    let (p2p_message_sender, _p2p_message_receiver) = channel::<P2PMessage>(100);
    let (_p2p_command_sender, p2p_command_receiver) = channel::<P2PCommand>(100);

    let p2p_config = P2PConfigInner::test_config();
    let discovery_status = Arc::new(RwLock::new(DiscoveryStatusInner::new(
        p2p_config.clone(),
        PeerList::from_vec(&p2p_config.p2p_known_peers),
    )));
    let mut p2p_service = P2PServer::new(
        discovery_status,
        p2p_config.clone(),
        p2p_message_sender,
        p2p_command_receiver,
    )
    .await
    .expect("P2P swarm cannot be started");

    loop {
        match p2p_service.swarm.select_next_some().await {
            SwarmEvent::NewListenAddr { .. } => {
                // listener address registered, we are good to go
                break;
            }
            _ => {
                tracing::error!("Unexpected event");
                panic!("Unexpected event")
            }
        }
    }
}

'''
'''--- p2p/src/libp2p/mod.rs ---
mod behaviour;
pub mod peer_list;
mod transport;

pub mod discovery_status;
#[cfg(test)]
mod libp2p_test;

use std::{str::FromStr, time::Duration};

use behaviour::SedaBehaviour;
use discovery_status::DiscoveryStatus;
use libp2p::{
    core::ConnectedPoint,
    futures::StreamExt,
    gossipsub::{GossipsubEvent, IdentTopic},
    identity::{self},
    kad::{KademliaEvent, QueryResult},
    mdns::Event as MdnsEvent,
    swarm::{DialError, NetworkBehaviour, SwarmEvent},
    Swarm,
};
pub use libp2p::{Multiaddr, PeerId};
use peer_list::{ConnectionType, PeerInfo};
use seda_config::P2PConfig;
use seda_runtime_sdk::p2p::{P2PCommand, P2PMessage};
use tokio::{
    sync::mpsc::{Receiver, Sender},
    time,
};
use transport::build_tcp_transport;

use crate::{libp2p::behaviour::SedaBehaviourEvent, Result};

pub const GOSSIP_TOPIC: &str = "testnet";
pub const SEARCH_PEER_INTERVAL: u64 = 10_000;

pub struct P2PServer {
    swarm:            Swarm<SedaBehaviour>,
    discovery_status: DiscoveryStatus,
    local_peer_id:    PeerId,

    message_sender_channel:   Sender<P2PMessage>,
    command_receiver_channel: Receiver<P2PCommand>,
}

impl P2PServer {
    pub async fn new(
        discovery_status: DiscoveryStatus,
        p2p_config: P2PConfig,
        message_sender_channel: Sender<P2PMessage>,
        command_receiver_channel: Receiver<P2PCommand>,
    ) -> Result<Self> {
        // Generate Peer ID
        // TODO: Support peer id from config and storage
        let local_key = identity::Keypair::generate_ed25519();
        let local_peer_id = PeerId::from(local_key.public());
        tracing::info!("Local peer id: {:?}", local_peer_id);

        let transport = build_tcp_transport(local_key.clone())?;
        let seda_behaviour = SedaBehaviour::new(&local_key).await?;
        let mut swarm = Swarm::with_threadpool_executor(transport, seda_behaviour, local_peer_id);

        swarm.listen_on(p2p_config.p2p_server_address.parse()?)?;

        Ok(Self {
            local_peer_id,
            swarm,
            discovery_status,
            command_receiver_channel,
            message_sender_channel,
        })
    }

    pub async fn start(&mut self) {
        self.search_new_peer(None);
    }

    /// Searches for new peers,
    /// goes through all the behaviours and tries to find a new peer
    /// This only tries to find one peer at a time
    pub fn search_new_peer(&mut self, skip: Option<ConnectionType>) {
        let current_discovery_method: ConnectionType = {
            let discovery_status = self.discovery_status.read();
            discovery_status.get_current_discovery_method(skip)
        };

        match current_discovery_method {
            ConnectionType::Manual => self.search_manual_peers(),
            ConnectionType::MDns => self.search_mdns_peers(),
            ConnectionType::Chain => {
                // TODO: Add chain peers
                self.search_new_peer(Some(ConnectionType::Chain));
            }
            ConnectionType::Kademlia => self.search_kademlia_peers(),
            ConnectionType::None => {
                tracing::debug!("No new peers found/needed");
            }
        }
    }

    fn dial_peer(&mut self, addr: Multiaddr) {
        if let Err(error) = self.swarm.dial(addr.clone()) {
            tracing::warn!("Couldn't dial peer ({}): {:?}", &addr, error);
        }
    }

    fn search_manual_peers(&mut self) {
        let next_manual_peer: Option<(Multiaddr, PeerInfo)> = {
            let mut discovery_status = self.discovery_status.write();
            discovery_status.get_next_manual_peer()
        };

        if let Some((addr, _peer_info)) = next_manual_peer {
            self.dial_peer(addr);
        } else {
            self.search_new_peer(Some(ConnectionType::Manual));
        }
    }

    fn search_mdns_peers(&mut self) {
        let next_mdns_peer: Option<(Multiaddr, PeerInfo)> = {
            let mut discovery_status = self.discovery_status.write();
            discovery_status.get_next_mdns_peer()
        };

        if let Some((addr, _peer_info)) = next_mdns_peer {
            self.dial_peer(addr);
        } else {
            self.search_new_peer(Some(ConnectionType::MDns));
        }
    }

    fn search_kademlia_peers(&mut self) {
        let next_kademlia_peer: Option<(Multiaddr, PeerInfo)> = {
            let mut discovery_status = self.discovery_status.write();
            discovery_status.get_next_kademlia_peer()
        };

        if let Some((addr, _peer_info)) = next_kademlia_peer {
            self.dial_peer(addr);
        } else {
            self.swarm
                .behaviour_mut()
                .kademlia
                .get_closest_peers(self.local_peer_id);
        }
    }

    pub async fn loop_stream(&mut self) -> Result<()> {
        let topic = IdentTopic::new(GOSSIP_TOPIC);
        let mut search_peers_interval = time::interval(Duration::from_millis(SEARCH_PEER_INTERVAL));

        loop {
            tokio::select! {
                _ = search_peers_interval.tick() => {
                    self.search_new_peer(None);
                },

                event = self.swarm.select_next_some() => match event {
                    // Swarm
                    SwarmEvent::NewListenAddr { address, .. } => tracing::info!("Listening on {:?}", address),
                    SwarmEvent::ConnectionEstablished { peer_id, endpoint: ConnectedPoint::Dialer { address, .. }, .. } => {
                        tracing::debug!("Connection established with {peer_id}");

                        {
                            let mut discovery_status = self.discovery_status.write();
                            discovery_status.add_connected_peer(address.clone(), peer_id);
                        }

                        self.swarm.behaviour_mut().kademlia.add_address(&peer_id, address);
                        self.swarm.behaviour_mut().gossipsub.add_explicit_peer(&peer_id);
                        self.search_new_peer(None);
                    },

                    SwarmEvent::ConnectionClosed { peer_id, .. } => {
                        tracing::debug!("Connection closed with {peer_id}");

                        {
                            let mut discovery_status = self.discovery_status.write();
                            discovery_status.remove_connected_peer(Some(&peer_id), None);
                        }

                        self.search_new_peer(None);
                        self.swarm.behaviour_mut().kademlia.remove_peer(&peer_id);
                    },

                    SwarmEvent::OutgoingConnectionError { peer_id: _, error } => {
                        {
                            let mut discovery_status = self.discovery_status.write();

                            if let DialError::Transport(failed_peers) = error {
                                for (addr, _transport_error) in failed_peers {
                                    discovery_status.remove_connected_peer(None, Some(&addr));
                                    discovery_status.cooldown_addr(addr);
                                }
                            }
                        }

                        self.search_new_peer(None);
                    },

                    // Gossip
                    SwarmEvent::Behaviour(SedaBehaviourEvent::Gossipsub(GossipsubEvent::Message {
                        propagation_source: peer_id,
                        message_id: id,
                        message,
                    })) => {
                        tracing::info!(
                            "Got message: '{}' with id: {id} from peer: {peer_id}",
                            String::from_utf8_lossy(&message.data),
                        );

                        let source: Option<String> = message.source.map(|peer| peer.to_string());

                        if let Err(err) = self.message_sender_channel.send(P2PMessage { source, data: message.data }).await {
                            tracing::error!("Couldn't send message through channel: {err}");
                        }
                    },

                    // mDNS behaviour
                    SwarmEvent::Behaviour(SedaBehaviourEvent::Mdns(MdnsEvent::Discovered(list))) => {
                        {
                            let mut discovery_status = self.discovery_status.write();

                            for (peer_id, addr) in list {
                                discovery_status.add_mdns_peer(addr, peer_id);
                            }
                        }

                        self.search_new_peer(None);
                    },

                    // Kademlia behaviour
                    SwarmEvent::Behaviour(SedaBehaviourEvent::Kademlia(KademliaEvent::OutboundQueryProgressed {
                        result: QueryResult::GetClosestPeers(result),
                        ..
                    })) => {
                        match result {
                            Ok(closest_peers_query_result) => {
                                if !closest_peers_query_result.peers.is_empty() {
                                    let mut discovery_status = self.discovery_status.write();

                                    for peer_id in closest_peers_query_result.peers {
                                        let addresses = self.swarm.behaviour_mut().kademlia.addresses_of_peer(&peer_id);

                                        if let Some(first_address) = addresses.first() {
                                            discovery_status.add_kademlia_peer(first_address.clone(), peer_id);
                                        }
                                    }
                                } else {
                                    tracing::debug!("Kademlia couldn't find new peers");
                                }
                            }
                            Err(err) => tracing::error!("Error while using Kademlia: {err}")
                        }
                    },
                    _ => {}
                },

                task = self.command_receiver_channel.recv() => match task {
                    None => {},
                    Some(P2PCommand::Broadcast(data)) => {
                        if let Err(e) = self.swarm.behaviour_mut().gossipsub.publish(topic.clone(), data) {
                            tracing::error!("Publish error: {e:?}");
                        }
                    },
                    Some(P2PCommand::Unicast(_unicast)) => {
                        unimplemented!("Todo unicast");
                    },
                    Some(P2PCommand::AddPeer(add_peer_command)) => {
                        if let Ok(multi_addr) = add_peer_command.multi_addr.parse::<Multiaddr>() {
                            {
                                let mut discovery_status = self.discovery_status.write();
                                discovery_status.add_manual_peer(multi_addr, None);
                            }

                            self.search_new_peer(None);
                        } else {
                            tracing::warn!("Couldn't add peer, invalid address: {}", add_peer_command.multi_addr);
                        }
                    },
                    Some(P2PCommand::RemovePeer(remove_peer_command)) => {
                        match PeerId::from_str(&remove_peer_command.peer_id) {
                            Ok(peer_id) => {
                                self.swarm.disconnect_peer_id(peer_id).ok();

                                {
                                    let mut discovery_status = self.discovery_status.write();
                                    discovery_status.remove_connected_peer(Some(&peer_id), None);
                                }

                                self.search_new_peer(None);
                            },
                            Err(error) => tracing::warn!("PeerId {} is invalid: {error}", &remove_peer_command.peer_id)
                        }
                    },
                    Some(P2PCommand::DiscoverPeers) => {
                        self.search_new_peer(None);
                    }
                }
            }
        }
    }
}

'''
'''--- p2p/src/libp2p/peer_list.rs ---
use std::{collections::HashMap, str::FromStr};

use libp2p::{Multiaddr, PeerId};
use serde_json::Value;

#[derive(Clone, Debug, PartialEq, PartialOrd, Eq)]
pub enum ConnectionType {
    None     = -1,
    Manual   = 0,
    MDns     = 1,
    Chain    = 2,
    Kademlia = 3,
}

#[derive(Clone, Debug)]
pub struct PeerInfo {
    pub peer_id:   Option<PeerId>,
    pub conn_type: ConnectionType,
}

#[derive(Default, Debug, Clone)]
pub struct PeerList {
    addr_to_peer: HashMap<Multiaddr, PeerInfo>,
    peer_to_addr: HashMap<PeerId, Multiaddr>,
}

impl PeerList {
    pub fn from_vec(unparsed_multi_addresses: &[String]) -> PeerList {
        let mut addr_to_peer = HashMap::new();

        unparsed_multi_addresses.iter().for_each(|unparsed_addr| {
            addr_to_peer.insert(
                Multiaddr::from_str(unparsed_addr).unwrap(),
                PeerInfo {
                    peer_id:   None,
                    conn_type: ConnectionType::Manual,
                },
            );
        });

        PeerList {
            addr_to_peer,
            peer_to_addr: HashMap::new(),
        }
    }

    pub fn len(&self) -> usize {
        self.peer_to_addr.len()
    }

    pub fn is_empty(&self) -> bool {
        self.peer_to_addr.is_empty()
    }

    pub fn add_peer(&mut self, multi_addr: Multiaddr, peer_id: Option<PeerId>, conn_type: ConnectionType) {
        self.addr_to_peer
            .insert(multi_addr.clone(), PeerInfo { peer_id, conn_type });

        if let Some(peer) = peer_id {
            self.peer_to_addr.insert(peer, multi_addr);
        }
    }

    pub fn get_peer_by_id(&mut self, peer_id: &PeerId) -> Option<(Multiaddr, PeerInfo)> {
        if let Some(addr) = self.peer_to_addr.get(peer_id) {
            if let Some(peer_info) = self.addr_to_peer.get(addr) {
                return Some((addr.clone(), peer_info.clone()));
            }
        }

        None
    }

    pub fn get_peer_by_addr(&mut self, addr: &Multiaddr) -> Option<PeerInfo> {
        if let Some(peer_info) = self.addr_to_peer.get(addr) {
            return Some(peer_info.clone());
        }

        None
    }

    pub fn set_peer_id(&mut self, multi_addr: Multiaddr, peer_id: PeerId) {
        let mut peer_info = self.addr_to_peer.get(&multi_addr).unwrap().clone();
        peer_info.peer_id = Some(peer_id);

        self.addr_to_peer.insert(multi_addr.clone(), peer_info);
        self.peer_to_addr.insert(peer_id, multi_addr);
    }

    pub fn remove_peer_by_addr(&mut self, multi_addr: &Multiaddr) {
        let item = self.addr_to_peer.get(multi_addr);

        if let Some(peer_info) = item {
            if let Some(peer_id) = peer_info.peer_id {
                self.peer_to_addr.remove(&peer_id);
            }
        }

        self.addr_to_peer.remove(multi_addr);
    }

    pub fn remove_peer_by_id(&mut self, peer_id: &PeerId) {
        let addr = self.peer_to_addr.get(peer_id);

        if let Some(multi_addr) = addr {
            self.addr_to_peer.remove(multi_addr);
        }

        self.peer_to_addr.remove(peer_id);
    }

    pub fn has_peer_id(&self, peer_id: &PeerId) -> bool {
        self.peer_to_addr.contains_key(peer_id)
    }

    pub fn has_addr(&self, addr: &Multiaddr) -> bool {
        self.addr_to_peer.contains_key(addr)
    }

    pub fn get_json(&self) -> Value {
        let mut result: HashMap<String, String> = HashMap::new();

        self.peer_to_addr.iter().for_each(|(peer, addr)| {
            result.insert(addr.to_string(), peer.to_base58());
        });

        serde_json::json!(result)
    }

    pub fn get_all(&self) -> HashMap<PeerId, Multiaddr> {
        self.peer_to_addr.clone()
    }

    pub fn get_all_info(&self) -> HashMap<Multiaddr, PeerInfo> {
        self.addr_to_peer.clone()
    }
}

'''
'''--- p2p/src/libp2p/transport.rs ---
use std::time::Duration;

use libp2p::{
    core::{muxing::StreamMuxerBox, transport, transport::upgrade::Version},
    identity,
    noise,
    tcp::{async_io::Transport as TcpTransport, Config},
    yamux::YamuxConfig,
    PeerId,
    Transport,
};

use crate::Result;

/// Builds the transport that serves as a common ground for all connections.
pub fn build_tcp_transport(key_pair: identity::Keypair) -> Result<transport::Boxed<(PeerId, StreamMuxerBox)>> {
    let noise_keys = noise::Keypair::<noise::X25519Spec>::new()
        .into_authentic(&key_pair)
        .unwrap();
    let noise_config = noise::NoiseConfig::xx(noise_keys).into_authenticated();
    let yamux_config = YamuxConfig::default();
    let transport_config = Config::default().nodelay(true);

    Ok(TcpTransport::new(transport_config)
        .upgrade(Version::V1)
        .authenticate(noise_config)
        .multiplex(yamux_config)
        // TODO: use duration from p2p config
        .timeout(Duration::from_secs(20))
        .boxed())
}

'''
'''--- runtime/core/Cargo.toml ---
[package]
name = "seda-runtime"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
async-trait = { workspace = true }
bn254 = { workspace = true }
futures = { workspace = true, features = ["executor"] }
hex = { workspace = true }
parking_lot = { workspace = true }
seda-chains = { workspace = true }
seda-config = { workspace = true }
seda-runtime-sdk = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tracing = { workspace = true }
wasmer = { workspace = true, features = [
	"default-cranelift",
	"default-universal",
] }
wasmer-wasi = { workspace = true, features = ["host-fs", "sys"] }

[dev-dependencies]
lazy_static = { workspace = true }
reqwest = { workspace = true }
tokio = { workspace = true, features = ["macros", "rt-multi-thread"] }
seda-crypto = { workspace = true }

'''
'''--- runtime/core/src/config.rs ---
use wasmer_wasi::{WasiEnv, WasiState};

#[derive(Debug, Clone)]
pub struct VmConfig {
    /// Name of the binary, ex. "consensus", "fisherman", etc
    pub program_name: String,

    // The function we need to execute, defaults to the WASI default ("_start")
    pub start_func: Option<String>,

    /// Arguments to pass to the WASM binary
    pub args: Vec<String>,

    pub debug: bool,
}

impl VmConfig {
    pub fn finalize(self) -> WasiEnv {
        let mut wasi_state = WasiState::new(&self.program_name);
        wasi_state.args(&self.args);
        wasi_state.finalize().unwrap()
    }
}

'''
'''--- runtime/core/src/context.rs ---
use std::sync::Arc;

use parking_lot::{Mutex, RwLock};
use seda_config::NodeConfig;
use wasmer::{HostEnvInitError, Instance, LazyInit, Memory, WasmerEnv};

use super::PromiseQueue;
use crate::InMemory;

#[derive(Clone)]
pub struct VmContext {
    pub result:                Arc<Mutex<Vec<u8>>>,
    pub memory:                LazyInit<Memory>,
    pub memory_adapter:        Arc<Mutex<InMemory>>,
    pub shared_memory:         Arc<RwLock<InMemory>>,
    pub promise_queue:         Arc<Mutex<PromiseQueue>>,
    pub current_promise_queue: Arc<Mutex<PromiseQueue>>,
    pub node_config:           NodeConfig,
}

impl WasmerEnv for VmContext {
    fn init_with_instance(&mut self, instance: &Instance) -> Result<(), HostEnvInitError> {
        let memory: Memory = instance.exports.get_with_generics_weak("memory")?;
        self.memory.initialize(memory);

        Ok(())
    }
}

impl VmContext {
    pub fn create_vm_context(
        memory_adapter: Arc<Mutex<InMemory>>,
        shared_memory: Arc<RwLock<InMemory>>,
        current_promise_queue: Arc<Mutex<PromiseQueue>>,
        promise_queue: Arc<Mutex<PromiseQueue>>,
        node_config: NodeConfig,
    ) -> VmContext {
        VmContext {
            result: Arc::new(Mutex::new(Vec::new())),
            memory_adapter,
            shared_memory,
            memory: LazyInit::new(),
            current_promise_queue,
            promise_queue,
            node_config,
        }
    }
}

'''
'''--- runtime/core/src/errors.rs ---
use std::num::ParseIntError;

use seda_runtime_sdk::{p2p::P2PCommand, SDKError};
use thiserror::Error;
use tokio::sync::mpsc::error::SendError;
use wasmer::{CompileError, ExportError, InstantiationError};
use wasmer_wasi::{FsError, WasiError, WasiStateCreationError};

#[derive(Debug, Error)]
pub enum RuntimeError {
    #[error(transparent)]
    WasmCompileError(#[from] CompileError),

    #[error(transparent)]
    WasmInstantiationError(Box<InstantiationError>),

    #[error(transparent)]
    WasiError(#[from] WasiError),
    #[error(transparent)]
    WasiStateCreationError(#[from] WasiStateCreationError),

    #[error(transparent)]
    FunctionNotFound(#[from] ExportError),

    #[error("Error while running: {0}")]
    ExecutionError(#[from] wasmer::RuntimeError),

    #[error("VM Host Error: {0}")]
    VmHostError(String),

    #[error("{0}")]
    WasiFsError(#[from] FsError),

    #[error("{0}")]
    IoError(#[from] std::io::Error),

    #[error(transparent)]
    ParseIntError(#[from] ParseIntError),

    // TODO this is scuffed and not true for test_host.
    #[error("Node Error: {0}")]
    NodeError(String),

    #[cfg(test)]
    #[error("Reqwest Error: {0}")]
    ReqwestError(#[from] reqwest::Error),
    #[cfg(test)]
    #[error("Chain Adapter Error: {0}")]
    ChainAdapterError(#[from] seda_chains::ChainAdapterError),

    #[error("P2P Command Channel Error: {0}")]
    P2PCommandChannelError(#[from] SendError<P2PCommand>),

    #[error("BN254 Error: {0}")]
    Bn254Error(#[from] bn254::Error),

    #[error("SDK Error: {0}")]
    SDKError(#[from] SDKError),
}

impl From<InstantiationError> for RuntimeError {
    fn from(r: InstantiationError) -> Self {
        Self::WasmInstantiationError(Box::new(r))
    }
}

impl From<serde_json::Error> for RuntimeError {
    fn from(s: serde_json::Error) -> Self {
        Self::VmHostError(s.to_string())
    }
}

impl From<String> for RuntimeError {
    fn from(s: String) -> Self {
        Self::VmHostError(s)
    }
}

impl From<&str> for RuntimeError {
    fn from(s: &str) -> Self {
        Self::VmHostError(s.into())
    }
}

pub type Result<T, E = RuntimeError> = core::result::Result<T, E>;

'''
'''--- runtime/core/src/host_adapter.rs ---
use std::fmt::Display;

use seda_chains::Client;
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime_sdk::{events::Event, Chain};

#[async_trait::async_trait]
pub trait HostAdapter: Send + Sync + Unpin + 'static {
    type Error: Display + std::error::Error;

    async fn new(config: ChainConfigs) -> Result<Self, Self::Error>
    where
        Self: Sized;

    fn select_client_from_chain(&self, chain: Chain) -> Client;

    async fn db_get(&self, key: &str) -> Result<Option<String>, Self::Error>;
    async fn db_set(&self, key: &str, value: &str) -> Result<(), Self::Error>;
    async fn http_fetch(&self, url: &str) -> Result<String, Self::Error>;

    async fn chain_call(
        &self,
        chain: Chain,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        deposit: u128,
        node_config: NodeConfig,
    ) -> Result<Vec<u8>, Self::Error>;

    async fn chain_view(
        &self,
        chain: Chain,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
    ) -> Result<Vec<u8>, Self::Error>;

    async fn trigger_event(&self, event: Event) -> Result<(), Self::Error>;
}

'''
'''--- runtime/core/src/imports.rs ---
use seda_runtime_sdk::Level;
use wasmer::{imports, Array, Function, ImportObject, Memory, Module, Store, WasmPtr};
use wasmer_wasi::WasiEnv;

use super::{Result, RuntimeError, VmContext};
use crate::MemoryAdapter;

/// Wrapper around memory.get_ref to implement the RuntimeError
fn get_memory(env: &VmContext) -> Result<&Memory> {
    Ok(env.memory.get_ref().ok_or("Memory reference could not be retrieved")?)
}

/// Adds a new promise to the promises stack
pub fn promise_then_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn promise_result_write(env: &VmContext, ptr: WasmPtr<u8, Array>, length: i32) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let mut promises_queue_ref = env.promise_queue.lock();

        let promise_data_raw = ptr
            .get_utf8_string(memory_ref, length as u32)
            .ok_or("Error getting promise data")?;

        let promise = serde_json::from_str(&promise_data_raw)?;

        promises_queue_ref.add_promise(promise);

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, promise_result_write)
}

/// Gets the length (stringified) of the promise status
pub fn promise_status_length_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn promise_status_length(env: &VmContext, promise_index: i32) -> Result<i64> {
        let promises_queue_ref = env.current_promise_queue.lock();

        let promise_info = promises_queue_ref
            .queue
            .get(promise_index as usize)
            .ok_or_else(|| format!("Could not find promise at index: {promise_index}"))?;

        // The length depends on the full status enum + result in JSON
        let status = serde_json::to_string(&promise_info.status)?;

        Ok(status.len() as i64)
    }

    Function::new_native_with_env(store, vm_context, promise_status_length)
}

/// Writes the status of the promise to the WASM memory
pub fn promise_status_write_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn promise_status_write(
        env: &VmContext,
        promise_index: i32,
        result_data_ptr: WasmPtr<u8, Array>,
        result_data_length: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let promises_ref = env.current_promise_queue.lock();
        let promise_info = promises_ref
            .queue
            .get(promise_index as usize)
            .ok_or_else(|| RuntimeError::VmHostError(format!("Could not find promise at index: {promise_index}")))?;

        let promise_status = serde_json::to_string(&promise_info.status)?;

        let promise_status_bytes = promise_status.as_bytes();
        let derefed_ptr = result_data_ptr
            .deref(memory_ref, 0, result_data_length as u32)
            .ok_or("Invalid pointer")?;

        for index in 0..result_data_length {
            derefed_ptr
                .get(index as usize)
                .ok_or("Writing out of bounds to memory")?
                .set(promise_status_bytes[index as usize]);
        }

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, promise_status_write)
}

/// Reads the value from memory as byte array to the wasm result pointer.
pub fn memory_read_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn memory_read(
        env: &VmContext,
        key: WasmPtr<u8, Array>,
        key_length: i64,
        result_data_ptr: WasmPtr<u8, Array>,
        result_data_length: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;

        let memory_adapter = env.memory_adapter.lock();
        let read_value: Vec<u8> = memory_adapter.get(&key)?.unwrap_or_default();
        if result_data_length as usize != read_value.len() {
            Err(format!(
                "The result data length `{result_data_length}` is not the same length for the value `{}`",
                read_value.len()
            ))?;
        }

        let derefed_ptr = result_data_ptr
            .deref(memory_ref, 0, result_data_length as u32)
            .ok_or("Invalid pointer")?;
        for (index, byte) in read_value.iter().enumerate().take(result_data_length as usize) {
            derefed_ptr
                .get(index)
                .ok_or("Writing out of bounds to memory")?
                .set(*byte);
        }

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, memory_read)
}

/// Reads the value from memory as byte array and sends the number of bytes to
/// WASM.
pub fn memory_read_length_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn memory_read_length(env: &VmContext, key: WasmPtr<u8, Array>, key_length: i64) -> Result<i64> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;

        let memory_adapter = env.memory_adapter.lock();
        let read_value: Vec<u8> = memory_adapter.get(&key)?.unwrap_or_default();

        Ok(read_value.len() as i64)
    }

    Function::new_native_with_env(store, vm_context, memory_read_length)
}

/// Writes the value from WASM to the memory storage object.
pub fn memory_write_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn memory_write(
        env: &VmContext,
        key: WasmPtr<u8, Array>,
        key_length: i64,
        value: WasmPtr<u8, Array>,
        value_len: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;
        let value = value.deref(memory_ref, 0, value_len as u32).ok_or("Invalid pointer")?;
        let value_bytes: Vec<u8> = value.into_iter().map(|wc| wc.get()).collect();

        let mut memory_adapter = env.memory_adapter.lock();
        memory_adapter.put(&key, value_bytes);

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, memory_write)
}

/// Reads the value from memory as byte array to the wasm result pointer.
pub fn shared_memory_read_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn shared_memory_read(
        env: &VmContext,
        key: WasmPtr<u8, Array>,
        key_length: i64,
        result_data_ptr: WasmPtr<u8, Array>,
        result_data_length: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;

        let memory_adapter = env.shared_memory.read();
        let read_value: Vec<u8> = memory_adapter.get(&key)?.unwrap_or_default();
        if result_data_length as usize != read_value.len() {
            Err(format!(
                "The result data length `{result_data_length}` is not the same length for the value `{}`",
                read_value.len()
            ))?;
        }

        let derefed_ptr = result_data_ptr
            .deref(memory_ref, 0, result_data_length as u32)
            .ok_or("Invalid pointer")?;
        for (index, byte) in read_value.iter().enumerate().take(result_data_length as usize) {
            derefed_ptr
                .get(index)
                .ok_or("Writing out of bounds to memory")?
                .set(*byte);
        }

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, shared_memory_read)
}

/// Reads the value from memory as byte array and sends the number of bytes to
/// WASM.
pub fn shared_memory_read_length_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn shared_memory_read_length(env: &VmContext, key: WasmPtr<u8, Array>, key_length: i64) -> Result<i64> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;

        let memory_adapter = env.shared_memory.read();
        let read_value: Vec<u8> = memory_adapter.get(&key)?.unwrap_or_default();

        Ok(read_value.len() as i64)
    }

    Function::new_native_with_env(store, vm_context, shared_memory_read_length)
}

/// Reads the value from memory as byte array and returns a bool if it exists
pub fn shared_memory_contains_key_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn shared_memory_contains_key(env: &VmContext, key: WasmPtr<u8, Array>, key_length: i64) -> Result<u8> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;

        let memory_adapter = env.shared_memory.read();
        let contains = memory_adapter.contains_key(&key);

        Ok(contains.into())
    }

    Function::new_native_with_env(store, vm_context, shared_memory_contains_key)
}

/// Writes the value from WASM to the memory storage object.
pub fn shared_memory_write_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn shared_memory_write(
        env: &VmContext,
        key: WasmPtr<u8, Array>,
        key_length: i64,
        value: WasmPtr<u8, Array>,
        value_len: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;
        let key = key
            .get_utf8_string(memory_ref, key_length as u32)
            .ok_or("Error getting promise data")?;
        let value = value.deref(memory_ref, 0, value_len as u32).ok_or("Invalid pointer")?;
        let value_bytes: Vec<u8> = value.into_iter().map(|wc| wc.get()).collect();

        let mut memory_adapter = env.shared_memory.write();
        memory_adapter.put(&key, value_bytes);

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, shared_memory_write)
}

fn execution_result_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn execution_result(env: &VmContext, result_ptr: WasmPtr<u8, Array>, result_length: i32) -> Result<()> {
        let memory_ref = get_memory(env)?;

        let result = result_ptr
            .deref(memory_ref, 0, result_length as u32)
            .ok_or("Invalid pointer")?;

        let result_bytes: Vec<u8> = result.into_iter().map(|wc| wc.get()).collect();

        let mut vm_result = env.result.lock();
        *vm_result = result_bytes;

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, execution_result)
}

pub fn log_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn log(
        env: &VmContext,
        level: WasmPtr<u8, Array>,
        level_len: i32,
        msg: WasmPtr<u8, Array>,
        msg_len: i64,
        line_info: WasmPtr<u8, Array>,
        line_info_len: i64,
    ) -> Result<()> {
        let memory_ref = get_memory(env)?;

        let promise_data_raw = level
            .get_utf8_string(memory_ref, level_len as u32)
            .ok_or("Error getting promise data")?;

        let level: Level = serde_json::from_str(&promise_data_raw)?;

        let msg_data_raw = msg
            .get_utf8_string(memory_ref, msg_len as u32)
            .ok_or("Error getting promise data")?;

        let line_info_raw = line_info
            .get_utf8_string(memory_ref, line_info_len as u32)
            .ok_or("Error getting promise data")?;
        level.log(&msg_data_raw, &line_info_raw);

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, log)
}

/// Verifies a `bn254` ECDSA signature.
///
/// Inputs:
///     - message (any payload in bytes)
///     - signature (bytes as compressed G1 point)
///     - public_key (bytes as compressed G2 point)
///
/// Output:
///     - u8 (boolean, 1 for true)
pub fn bn254_verify_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn bn254_verify(
        env: &VmContext,
        message: WasmPtr<u8, Array>,
        message_length: i64,
        signature: WasmPtr<u8, Array>,
        signature_length: i64,
        public_key: WasmPtr<u8, Array>,
        public_key_length: i64,
    ) -> Result<u8> {
        // Fetch function arguments as Vec<u8>
        let memory_ref = get_memory(env)?;
        let message = message
            .deref(memory_ref, 0, message_length as u32)
            .ok_or("Invalid pointer")?;
        let message: Vec<u8> = message.into_iter().map(|wc| wc.get()).collect();

        let signature = signature
            .deref(memory_ref, 0, signature_length as u32)
            .ok_or("Invalid pointer")?;
        let signature: Vec<u8> = signature.into_iter().map(|wc| wc.get()).collect();

        let public_key = public_key
            .deref(memory_ref, 0, public_key_length as u32)
            .ok_or("Invalid pointer")?;
        let public_key: Vec<u8> = public_key.into_iter().map(|wc| wc.get()).collect();

        // `bn254` verification
        let signature_obj = bn254::Signature::from_uncompressed(signature)?;
        let public_key_obj = bn254::PublicKey::from_uncompressed(public_key)?;

        Ok(bn254::ECDSA::verify(message, &signature_obj, &public_key_obj)
            .is_ok()
            .into())
    }

    Function::new_native_with_env(store, vm_context, bn254_verify)
}

/// Signs with ECDSA using `bn254`.
///
/// Inputs:
///
/// * `message`     - The message bytes
/// * `private_key` - The private key
///
/// Output:
///     - Signature (a G1 point) as byte array to the wasm result pointer
pub fn bn254_sign_import_obj(store: &Store, vm_context: VmContext) -> Function {
    fn bn254_sign(
        env: &VmContext,
        message: WasmPtr<u8, Array>,
        message_length: i64,
        result_data_ptr: WasmPtr<u8, Array>,
        result_data_length: i64,
    ) -> Result<()> {
        // Fetch function arguments as Vec<u8>
        let memory_ref = get_memory(env)?;
        let message = message
            .deref(memory_ref, 0, message_length as u32)
            .ok_or("Invalid pointer")?;
        let message: Vec<u8> = message.into_iter().map(|wc| wc.get()).collect();

        // `bn254` sign
        let signature = bn254::ECDSA::sign(&message, &env.node_config.keypair_bn254.private_key)?;
        let result = signature.to_uncompressed()?;

        if result_data_length as usize != result.len() {
            Err(format!(
                "The result data length `{result_data_length}` is not the same length for the value `{}`",
                result.len()
            ))?;
        }

        let derefed_ptr = result_data_ptr
            .deref(memory_ref, 0, result_data_length as u32)
            .ok_or("Invalid pointer")?;
        for (index, byte) in result.iter().enumerate().take(result_data_length as usize) {
            derefed_ptr
                .get(index)
                .ok_or("Writing out of bounds to memory")?
                .set(*byte);
        }

        Ok(())
    }

    Function::new_native_with_env(store, vm_context, bn254_sign)
}

// Creates the WASM function imports with the stringed names.
pub fn create_wasm_imports(
    store: &Store,
    vm_context: VmContext,
    wasi_env: &mut WasiEnv,
    wasm_module: &Module,
) -> Result<ImportObject> {
    let host_import_obj = imports! {
        "env" => {
            "promise_then" => promise_then_import_obj(store, vm_context.clone()),
            "promise_status_length" => promise_status_length_import_obj(store, vm_context.clone()),
            "promise_status_write" => promise_status_write_import_obj(store, vm_context.clone()),
            "memory_read" => memory_read_import_obj(store, vm_context.clone()),
            "memory_read_length" => memory_read_length_import_obj(store, vm_context.clone()),
            "memory_write" => memory_write_import_obj(store, vm_context.clone()),
            "shared_memory_contains_key" => shared_memory_contains_key_import_obj(store, vm_context.clone()),
            "shared_memory_read" => shared_memory_read_import_obj(store, vm_context.clone()),
            "shared_memory_read_length" => shared_memory_read_length_import_obj(store, vm_context.clone()),
            "shared_memory_write" => shared_memory_write_import_obj(store, vm_context.clone()),
            "execution_result" => execution_result_import_obj(store, vm_context.clone()),
            "_log" => log_import_obj(store, vm_context.clone()),
            "bn254_verify" => bn254_verify_import_obj(store, vm_context.clone()),
            "bn254_sign" => bn254_sign_import_obj(store, vm_context)
        }
    };

    // Combining the WASI exports with our custom (host) imports
    let mut wasi_import_obj = wasi_env.import_object(wasm_module)?;
    let host_exports = host_import_obj
        .get_namespace_exports("env")
        .ok_or("VM could not get env namespace")?;
    wasi_import_obj.register("env", host_exports);

    Ok(wasi_import_obj)
}

'''
'''--- runtime/core/src/lib.rs ---
//! WASI compatible WASM VM

mod config;
pub use config::*;

mod context;
pub use context::*;

mod errors;
pub use errors::*;

mod host_adapter;
pub use host_adapter::*;

pub(crate) mod imports;

mod promise;
pub(crate) use promise::*;

mod runtime;
pub use runtime::*;

mod storage;
pub use storage::*;

mod vm_result;
pub use vm_result::*;

#[cfg(test)]
#[path = ""]
mod test {
    mod test_host;
    pub(crate) use test_host::*;

    mod runtime_test;
}

'''
'''--- runtime/core/src/promise/mod.rs ---
pub mod promise_queue;

pub use promise_queue::*;

'''
'''--- runtime/core/src/promise/promise_queue.rs ---
/// Acts as a wrapper around a vector of promises
/// This allows us to change to batches easily in the future
use seda_runtime_sdk::Promise;

#[derive(Clone, Default, Debug)]
pub struct PromiseQueue {
    /// A list which contains batches of promises
    pub queue: Vec<Promise>,
}

impl PromiseQueue {
    pub fn new() -> Self {
        Self { queue: Vec::new() }
    }

    pub fn add_promise(&mut self, promise: Promise) {
        self.queue.push(promise);
    }
}

'''
'''--- runtime/core/src/runtime.rs ---
use std::{io::Read, sync::Arc};

use parking_lot::{Mutex, RwLock};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime_sdk::{p2p::P2PCommand, CallSelfAction, FromBytes, Promise, PromiseAction, PromiseStatus};
use tokio::sync::mpsc::Sender;
use tracing::info;
use wasmer::{Instance, Module, Store};
use wasmer_wasi::{Pipe, WasiState};

use super::{imports::create_wasm_imports, PromiseQueue, Result, VmConfig, VmContext};
use crate::{
    vm_result::{ExecutionResult, ExitInfo, VmResult, VmResultStatus},
    HostAdapter,
    InMemory,
    RuntimeError,
};

#[derive(Clone)]
pub struct Runtime<HA: HostAdapter> {
    wasm_module:       Option<Module>,
    limited:           bool,
    pub host_adapter:  HA,
    pub node_config:   NodeConfig,
    pub shared_memory: Arc<RwLock<InMemory>>,
}

#[async_trait::async_trait]
pub trait RunnableRuntime {
    async fn new(
        node_config: NodeConfig,
        chains_config: ChainConfigs,
        shared_memory: Arc<RwLock<InMemory>>,
        limited: bool,
    ) -> Result<Self>
    where
        Self: Sized;
    fn init(&mut self, wasm_binary: Vec<u8>) -> Result<()>;

    #[allow(clippy::too_many_arguments)]
    async fn execute_promise_queue(
        &self,
        wasm_module: &Module,
        memory_adapter: Arc<Mutex<InMemory>>,
        promise_queue: PromiseQueue,
        stdout: &mut Vec<String>,
        stderr: &mut Vec<String>,
        // Getting the results of all the promise queues
        // Used to get the result of the last execution (for JSON RPC)
        // Can also be used to debug the queue
        promise_queue_trace: &mut Vec<PromiseQueue>,
        p2p_command_sender_channel: Sender<P2PCommand>,
    ) -> ExecutionResult;

    async fn start_runtime(
        &self,
        config: VmConfig,
        memory_adapter: Arc<Mutex<InMemory>>,
        p2p_command_sender_channel: Sender<P2PCommand>,
    ) -> VmResult;
}

#[async_trait::async_trait]
impl<HA: HostAdapter> RunnableRuntime for Runtime<HA> {
    async fn new(
        node_config: NodeConfig,
        chains_config: ChainConfigs,
        shared_memory: Arc<RwLock<InMemory>>,
        limited: bool,
    ) -> Result<Self> {
        Ok(Self {
            wasm_module: None,
            limited,
            host_adapter: HA::new(chains_config)
                .await
                .map_err(|e| RuntimeError::NodeError(e.to_string()))?,
            node_config,
            shared_memory,
        })
    }

    /// Initializes the runtime, this speeds up VM execution by caching WASM
    /// binary parsing
    fn init(&mut self, wasm_binary: Vec<u8>) -> Result<()> {
        let wasm_store = Store::default();
        let wasm_module = Module::new(&wasm_store, wasm_binary)?;

        self.wasm_module = Some(wasm_module);

        Ok(())
    }

    async fn execute_promise_queue(
        &self,
        wasm_module: &Module,
        memory_adapter: Arc<Mutex<InMemory>>,
        promise_queue: PromiseQueue,
        stdout: &mut Vec<String>,
        stderr: &mut Vec<String>,
        promise_queue_trace: &mut Vec<PromiseQueue>,
        p2p_command_sender_channel: Sender<P2PCommand>,
    ) -> ExecutionResult {
        let mut next_promise_queue = PromiseQueue::new();
        let mut promise_queue_mut = promise_queue.clone();

        {
            // This queue will be used in the current execution
            // We should not use the same promise_queue otherwise getting results back would
            // be hard to do due the indexes of results (will be hard to refactor)
            if promise_queue.queue.is_empty() {
                return VmResultStatus::EmptyQueue.into();
            }

            for index in 0..promise_queue.queue.len() {
                promise_queue_mut.queue[index].status = PromiseStatus::Pending;

                match &promise_queue.queue[index].action {
                    action if self.limited && action.is_limited_action() => {
                        promise_queue_mut.queue[index].status = PromiseStatus::Rejected(
                            format!("Method `{action}` not allowed in limited runtime").into_bytes(),
                        )
                    }
                    // TODO need an ok_or type situation here. if its ok continue otherwise reject
                    // promise? or maybe it should return a VMResult. Might hold off on this till the VMResult changes.
                    PromiseAction::CallSelf(call_action) => {
                        let wasm_store = Store::default();

                        let stdout_pipe = Pipe::new();
                        let stderr_pipe = Pipe::new();

                        // TODO: For some reason a second run does not include any env variables
                        let mut wasi_env = WasiState::new(&call_action.function_name)
                            .env("ORACLE_CONTRACT_ID", &self.node_config.contract_account_id)
                            .env(
                                "ED25519_PUBLIC_KEY",
                                hex::encode(self.node_config.keypair_ed25519.public_key.to_bytes()),
                            )
                            .env(
                                "BN254_PUBLIC_KEY",
                                hex::encode(&self.node_config.keypair_bn254.public_key.to_uncompressed().unwrap()),
                            )
                            .args(call_action.args.clone())
                            .stdout(Box::new(stdout_pipe))
                            .stderr(Box::new(stderr_pipe))
                            .finalize()
                            .map_err(|_| VmResultStatus::WasiEnvInitializeFailure)?;

                        let current_promise_queue = Arc::new(Mutex::new(promise_queue_mut.clone()));
                        let next_queue = Arc::new(Mutex::new(PromiseQueue::new()));

                        let vm_context = VmContext::create_vm_context(
                            memory_adapter.clone(),
                            self.shared_memory.clone(),
                            current_promise_queue,
                            next_queue.clone(),
                            self.node_config.clone(),
                        );

                        let imports = create_wasm_imports(&wasm_store, vm_context.clone(), &mut wasi_env, wasm_module)
                            .map_err(|_| VmResultStatus::FailedToCreateVMImports)?;
                        let wasmer_instance = Instance::new(wasm_module, &imports)
                            .map_err(|_| VmResultStatus::FailedToCreateWasmerInstance)?;
                        let main_func = wasmer_instance
                            .exports
                            .get_function(&call_action.function_name)
                            .map_err(|_| VmResultStatus::FailedToGetWASMFn)?;
                        let runtime_result = main_func.call(&[]);

                        let mut wasi_state = wasi_env.state();
                        let wasi_stdout = wasi_state
                            .fs
                            .stdout_mut()
                            .map_err(|_| VmResultStatus::FailedToGetWASMStdout)?
                            .as_mut()
                            .unwrap();
                        let mut stdout_buffer = String::new();
                        wasi_stdout
                            .read_to_string(&mut stdout_buffer)
                            .map_err(|_| VmResultStatus::FailedToConvertVMPipeToString)?;
                        if !stdout_buffer.is_empty() {
                            stdout.push(stdout_buffer);
                        }

                        let wasi_stderr = wasi_state
                            .fs
                            .stderr_mut()
                            .map_err(|_| VmResultStatus::FailedToGetWASMStderr)?
                            .as_mut()
                            .unwrap();
                        let mut stderr_buffer = String::new();
                        wasi_stderr
                            .read_to_string(&mut stderr_buffer)
                            .map_err(|_| VmResultStatus::FailedToGetWASMStderr)?;
                        if !stderr_buffer.is_empty() {
                            stderr.push(stderr_buffer);
                        }

                        if let Err(err) = runtime_result {
                            info!("WASM Error output: {:?}", &stderr);
                            return VmResultStatus::ExecutionError(err.to_string()).into();
                        }

                        let execution_result = vm_context.result.lock();
                        next_promise_queue = next_queue.lock().clone();
                        promise_queue_mut.queue[index].status =
                            PromiseStatus::Fulfilled(Some(execution_result.clone()));
                    }

                    // Just an example, delete this later
                    PromiseAction::DatabaseSet(db_action) => {
                        let res = String::from_bytes(&db_action.value);
                        promise_queue_mut.queue[index].status = if res.is_err() {
                            res.into()
                        } else {
                            self.host_adapter.db_set(&db_action.key, &res.unwrap()).await.into()
                        };
                    }

                    PromiseAction::DatabaseGet(db_action) => {
                        promise_queue_mut.queue[index].status = self.host_adapter.db_get(&db_action.key).await.into();
                    }

                    PromiseAction::Http(http_action) => {
                        promise_queue_mut.queue[index].status =
                            self.host_adapter.http_fetch(&http_action.url).await.into();
                    }
                    PromiseAction::ChainView(chain_view_action) => {
                        promise_queue_mut.queue[index].status = self
                            .host_adapter
                            .chain_view(
                                chain_view_action.chain,
                                &chain_view_action.contract_id,
                                &chain_view_action.method_name,
                                chain_view_action.args.clone(),
                            )
                            .await
                            .into();
                    }
                    PromiseAction::ChainCall(chain_call_action) => {
                        promise_queue_mut.queue[index].status = self
                            .host_adapter
                            .chain_call(
                                chain_call_action.chain,
                                &chain_call_action.contract_id,
                                &chain_call_action.method_name,
                                chain_call_action.args.clone(),
                                chain_call_action.deposit,
                                self.node_config.clone(),
                            )
                            .await
                            .into();
                    }
                    PromiseAction::TriggerEvent(trigger_event_action) => {
                        promise_queue_mut.queue[index].status = self
                            .host_adapter
                            .trigger_event(trigger_event_action.event.clone())
                            .await
                            .into();
                    }
                    PromiseAction::P2PBroadcast(p2p_broadcast_action) => {
                        // TODO we need to figure out how to handle success and errors using channels.
                        p2p_command_sender_channel
                            .send(P2PCommand::Broadcast(p2p_broadcast_action.data.clone()))
                            .await
                            .expect("fixed with above TODO");
                    }
                }
            }
        }

        promise_queue_trace.push(promise_queue_mut.clone());

        let res = self.execute_promise_queue(
            wasm_module,
            memory_adapter,
            next_promise_queue,
            stdout,
            stderr,
            promise_queue_trace,
            p2p_command_sender_channel,
        );

        res.await
    }

    async fn start_runtime(
        &self,
        config: VmConfig,
        memory_adapter: Arc<Mutex<InMemory>>,
        p2p_command_sender_channel: Sender<P2PCommand>,
    ) -> VmResult {
        let function_name = config.clone().start_func.unwrap_or_else(|| "_start".to_string());
        let wasm_module = self.wasm_module.as_ref().unwrap();

        let mut promise_queue_trace: Vec<PromiseQueue> = Vec::new();
        let mut promise_queue = PromiseQueue::new();

        promise_queue.add_promise(Promise {
            action: PromiseAction::CallSelf(CallSelfAction {
                function_name,
                args: config.args,
            }),
            status: PromiseStatus::Unfulfilled,
        });

        let mut stdout: Vec<String> = vec![];
        let mut stderr: Vec<String> = vec![];

        let exit_info: ExitInfo = self
            .execute_promise_queue(
                wasm_module,
                memory_adapter,
                promise_queue,
                &mut stdout,
                &mut stderr,
                &mut promise_queue_trace,
                p2p_command_sender_channel,
            )
            .await
            .into();

        // There is always 1 queue with 1 promise in the trace (due to this func adding
        // the entrypoint). Only if we haven't hit exit codes, since we no longer return
        // early.
        let result = if !promise_queue_trace.is_empty() {
            let mut last_queue = promise_queue_trace
                .pop()
                .ok_or("Failed to get last promise queue")
                .unwrap();
            let last_promise_status = last_queue
                .queue
                .pop()
                .ok_or("Failed to get last promise in promise queue")
                .unwrap()
                .status;

            match last_promise_status {
                PromiseStatus::Fulfilled(Some(data)) => Some(data),
                PromiseStatus::Rejected(data) => Some(data),
                _ => None,
            }
        } else {
            None
        };

        VmResult {
            stdout,
            stderr,
            result,
            exit_info,
        }
    }
}

'''
'''--- runtime/core/src/runtime_test.rs ---
use std::{env, fs, path::PathBuf, sync::Arc};

use bn254::{PrivateKey, PublicKey, Signature, ECDSA};
use parking_lot::{Mutex, RwLock};
use seda_config::{ChainConfigsInner, NodeConfigInner};
use seda_crypto::MasterKey;
use seda_runtime_sdk::p2p::P2PCommand;
use serde_json::json;
use tokio::sync::mpsc;

use crate::{test::RuntimeTestAdapter, HostAdapter, InMemory, MemoryAdapter, RunnableRuntime, Runtime, VmConfig};

const TEST_MASTER_KEY: &str = "07bc2bbe42d68a80146c873963db1ac5801c7bd79221033b4ccc23cb70a09b28";

fn read_wasm_target(file: &str) -> Vec<u8> {
    let mut path_prefix = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
    path_prefix.push("../../target/wasm32-wasi/debug");
    path_prefix.push(&format!("{file}.wasm"));

    fs::read(path_prefix).unwrap()
}

fn set_env_vars() {
    env::set_var("SEDA_CONFIG_PATH", "../../template_config.toml");
}

fn memory_adapter() -> Arc<Mutex<InMemory>> {
    Arc::new(Mutex::new(InMemory::default()))
}

fn shared_memory() -> Arc<RwLock<InMemory>> {
    Arc::new(RwLock::new(InMemory::default()))
}

fn master_key() -> MasterKey {
    MasterKey::try_from(&TEST_MASTER_KEY.to_owned()).unwrap()
}

#[tokio::test(flavor = "multi_thread")]
async fn test_promise_queue_multiple_calls_with_external_traits() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();

    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime.start_runtime(
        VmConfig {
            args:         vec!["hello world".to_string()],
            program_name: "consensus".to_string(),
            start_func:   None,
            debug:        true,
        },
        memory_adapter,
        p2p_command_sender,
    );

    let vm_result = runtime_execution_result.await;
    assert_eq!(vm_result.exit_info.exit_code, 0);
    let value = runtime.host_adapter.db_get("test_value").await.unwrap();

    assert!(value.is_some());
    assert_eq!(value.unwrap(), "completed");
}

#[tokio::test(flavor = "multi_thread")]
#[should_panic(expected = "Unexpected EOF")]
async fn test_bad_wasm_file() {
    set_env_vars();

    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory(), false)
            .await
            .unwrap();

    runtime.init(vec![203]).unwrap();
}

#[tokio::test(flavor = "multi_thread")]
async fn test_non_existing_function() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec!["hello world".to_string()],
                program_name: "consensus".to_string(),
                start_func:   Some("non_existing_function".to_string()),
                debug:        true,
            },
            memory_adapter,
            p2p_command_sender,
        )
        .await;

    assert_eq!(runtime_execution_result.exit_info.exit_code, 5);
}

#[tokio::test(flavor = "multi_thread")]
async fn test_promise_queue_http_fetch() {
    set_env_vars();
    let fetch_url = "https://swapi.dev/api/planets/1/".to_string();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);

    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec![fetch_url.clone()],
                program_name: "consensus".to_string(),
                start_func:   Some("http_fetch_test".to_string()),
                debug:        true,
            },
            memory_adapter,
            p2p_command_sender,
        )
        .await;

    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    let db_result = runtime.host_adapter.db_get("http_fetch_result").await.unwrap();

    assert!(db_result.is_some());

    let result = db_result.unwrap();
    // Compare result with real API fetch
    let expected_result = reqwest::get(fetch_url).await.unwrap().text().await.unwrap();

    println!("Decoded result {}", result);
    assert_eq!(result, expected_result);
}

#[allow(clippy::await_holding_lock)]
#[tokio::test(flavor = "multi_thread")]
async fn test_memory_adapter() {
    set_env_vars();
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec!["memory adapter".to_string()],
                program_name: "consensus".to_string(),
                start_func:   Some("memory_adapter_test_success".to_string()),
                debug:        true,
            },
            memory_adapter.clone(),
            p2p_command_sender,
        )
        .await;

    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    let memory_adapter_ref = memory_adapter.lock();
    let read_value: Result<Option<Vec<u8>>, _> = memory_adapter_ref.get("u8");
    let expected = 234u8.to_le_bytes().to_vec();
    let expected_str = format!("{expected:?}");
    assert!(read_value.is_ok());
    assert_eq!(read_value.unwrap(), Some(expected));
    let u8_value = runtime.host_adapter.db_get("u8_result").await.unwrap();
    assert!(u8_value.is_some());
    assert_eq!(u8_value.unwrap(), expected_str);

    let u32_value = runtime.host_adapter.db_get("u32_result").await.unwrap();
    let expected = 3467u32.to_le_bytes().to_vec();
    let expected_str = format!("{expected:?}");
    assert!(u32_value.is_some());
    assert_eq!(u32_value.unwrap(), expected_str);
}

#[tokio::test(flavor = "multi_thread")]
#[should_panic(expected = "not implemented")]
async fn test_cli_demo_view_another_chain() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("demo-cli");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();

    runtime.init(wasm_binary).unwrap();
    let contract_id = "mc.mennat0.testnet".to_string();
    let method_name = "get_node_socket_address".to_string();
    let args = json!({"node_id": "12".to_string()}).to_string();

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec![
                    "view".to_string(),
                    "another".to_string(),
                    contract_id,
                    method_name,
                    args,
                ],
                program_name: "consensus".to_string(),
                start_func:   None,
                debug:        true,
            },
            memory_adapter.clone(),
            p2p_command_sender,
        )
        .await;
    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    let db_result = runtime.host_adapter.db_get("chain_view_result").await.unwrap();
    assert!(db_result.is_some());

    assert_eq!(db_result.unwrap(), "view".to_string());
}

#[tokio::test(flavor = "multi_thread")]
async fn test_limited_runtime() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, true)
            .await
            .unwrap();

    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime.start_runtime(
        VmConfig {
            args:         vec![],
            program_name: "consensus".to_string(),
            start_func:   Some("test_limited_runtime".to_string()),
            debug:        true,
        },
        memory_adapter,
        p2p_command_sender,
    );

    let vm_result = runtime_execution_result.await;
    assert_eq!(vm_result.exit_info.exit_code, 0);

    assert_eq!(vm_result.stdout.len(), 1);
    assert!(
        vm_result
            .stdout
            .into_iter()
            .any(|output| output.contains("not allowed in limited runtime"))
    );

    let value = runtime.host_adapter.db_get("foo").await.unwrap();
    assert!(value.is_none());
}

// TODO: test with local deployment or mocked RPC
// #[tokio::test(flavor = "multi_thread")]
// async fn test_cli_demo_view_near_chain() {
//     set_env_vars();
//     let wasm_binary = read_wasm_target("demo-cli");

//     let mut runtime =
//         Runtime::<RuntimeTestAdapter>::new(NodeConfigInner::test_config(),
// ChainConfigsInner:shared_memory, :test_config(), false)             .await
//             .unwrap();
//     let memory_adapter = memory_adapter();
//     let shared_memory = shared_memory();
//     runtime.init(wasm_binary).unwrap();
//     let contract_id = "mc.mennat0.testnet".to_string();
//     let method_name = "get_node_socket_address".to_string();
//     let args = json!({"node_id": "12".to_string()}).to_string();

//     let runtime_execution_result = runtime
//         .start_runtime(
//             VmConfig {
//                 args:         vec!["view".to_string(), "near".to_string(),
// contract_id, method_name, args],                 program_name:
// "consensus".to_string(),                 start_func:   None,
//                 debug:        true,
//             },
//             memory_adapter.clone(),
//         )
//         .await;
//     assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

//     let db_result =
// runtime.host_adapter.db_get("chain_view_result").await.unwrap();     assert!
// (db_result.is_some());

//     assert_eq!(db_result.unwrap(), "127.0.0.1:9000".to_string());
// }

#[tokio::test(flavor = "multi_thread")]
async fn test_bn254_verify_valid() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);

    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    runtime.init(wasm_binary).unwrap();
    let sig = hex::encode(
        Signature::from_compressed(
            hex::decode("020f047a153e94b5f109e4013d1bd078112817cf0d58cdf6ba8891f9849852ba5b").unwrap(),
        )
        .unwrap()
        .to_uncompressed()
        .unwrap(),
    );
    let pk = hex::encode(PublicKey::from_compressed(hex::decode("0b0087beab84f1aeacf30597cda920c6772ecd26ba95d84f66750a16dc9b68cea6d89173eff7f72817e4698f93fcb5a5b04b272a7085d8a12fceb5481e651df7a7").unwrap()).unwrap().to_uncompressed().unwrap());

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec![
                    // Message ("sample" in ASCII)
                    "73616d706c65".to_string(),
                    // Signature (uncompressed G1 point)
                    sig,
                    // Public Key (uncompressed G2 point)
                    pk,
                ],
                program_name: "consensus".to_string(),
                start_func:   Some("bn254_verify_test".to_string()),
                debug:        true,
            },
            memory_adapter,
            p2p_command_sender,
        )
        .await;

    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    // Fetch bn254 verify result from DB
    let db_result = runtime.host_adapter.db_get("bn254_verify_result").await.unwrap();
    assert!(db_result.is_some());
    let result = db_result.unwrap();

    // Valid verification returns true
    assert_eq!(result, format!("{}", true));
}

#[tokio::test(flavor = "multi_thread")]
async fn test_bn254_verify_invalid() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);

    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    runtime.init(wasm_binary).unwrap();
    let sig = hex::encode(
        Signature::from_compressed(
            hex::decode("020f047a153e94b5f109e4013d1bd078112817cf0d58cdf6ba8891f9849852ba5c").unwrap(),
        )
        .unwrap()
        .to_uncompressed()
        .unwrap(),
    );
    let pk = hex::encode(PublicKey::from_compressed(hex::decode("0b0087beab84f1aeacf30597cda920c6772ecd26ba95d84f66750a16dc9b68cea6d89173eff7f72817e4698f93fcb5a5b04b272a7085d8a12fceb5481e651df7a7").unwrap()).unwrap().to_uncompressed().unwrap());
    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec![
                    // Message ("sample" in ASCII)
                    "73616d706c65".to_string(),
                    // WRONG Signature (compressed G1 point) -> 1 flipped bit!
                    sig,
                    // Public Key (compressed G2 point)
                    pk,
                ],
                program_name: "consensus".to_string(),
                start_func:   Some("bn254_verify_test".to_string()),
                debug:        true,
            },
            memory_adapter,
            p2p_command_sender,
        )
        .await;

    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    // Fetch bn254 verify result from DB
    let db_result = runtime.host_adapter.db_get("bn254_verify_result").await.unwrap();
    assert!(db_result.is_some());
    let result = db_result.unwrap();

    // Valid verification returns true
    assert_eq!(result, format!("{}", false));
}

#[tokio::test(flavor = "multi_thread")]
async fn test_bn254_signature() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);

    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();
    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime
        .start_runtime(
            VmConfig {
                args:         vec![
                    // Message ("sample" in ASCII)
                    "73616d706c65".to_string(),
                    // Private Key
                    "2009da7287c158b126123c113d1c85241b6e3294dd75c643588630a8bc0f934c".to_string(),
                ],
                program_name: "consensus".to_string(),
                start_func:   Some("bn254_sign_test".to_string()),
                debug:        true,
            },
            memory_adapter,
            p2p_command_sender,
        )
        .await;
    println!("********runtime_execution_result {:?}", runtime_execution_result);
    assert_eq!(runtime_execution_result.exit_info.exit_code, 0);

    // Fetch bn254 sign result from DB
    let db_result = runtime.host_adapter.db_get("bn254_sign_result").await.unwrap();
    assert!(db_result.is_some());
    let result = db_result.unwrap();

    // Check if expected signature
    let expected_signature = hex::encode(
        Signature::from_compressed(
            hex::decode("03252a430535dfdf7c20713be125fbe3db4b9d5a38062cda01eb91a6611621049d").unwrap(),
        )
        .unwrap()
        .to_uncompressed()
        .unwrap(),
    );
    assert_eq!(result, expected_signature);
}

#[tokio::test(flavor = "multi_thread")]
async fn test_error_turns_into_rejection() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let memory_adapter = memory_adapter();
    let shared_memory = shared_memory();
    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();

    runtime.init(wasm_binary).unwrap();

    let runtime_execution_result = runtime.start_runtime(
        VmConfig {
            args:         vec![],
            program_name: "consensus".to_string(),
            start_func:   Some("test_error_turns_into_rejection".to_string()),
            debug:        true,
        },
        memory_adapter,
        p2p_command_sender,
    );

    let vm_result = runtime_execution_result.await;
    assert_eq!(vm_result.exit_info.exit_code, 0);

    assert_eq!(vm_result.stdout.len(), 1);
    assert!(
        vm_result
            .stdout
            .into_iter()
            .any(|output| output.contains("relative URL without a base"))
    );

    let value = runtime.host_adapter.db_get("foo").await.unwrap();
    assert!(value.is_none());
}

#[tokio::test(flavor = "multi_thread")]
async fn test_shared_memory() {
    set_env_vars();
    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let wasm_binary = read_wasm_target("promise-wasm-bin");
    let node_config = NodeConfigInner::test_config(Some(master_key()));
    let shared_memory = shared_memory();
    let mut runtime = Runtime::<RuntimeTestAdapter>::new(
        node_config.clone(),
        ChainConfigsInner::test_config(),
        shared_memory.clone(),
        false,
    )
    .await
    .unwrap();

    runtime.init(wasm_binary.clone()).unwrap();

    let runtime_execution_result = runtime.start_runtime(
        VmConfig {
            args:         vec![],
            program_name: "consensus".to_string(),
            start_func:   Some("shared_memory_test".to_string()),
            debug:        true,
        },
        memory_adapter(),
        p2p_command_sender,
    );

    let vm_result = runtime_execution_result.await;
    assert_eq!(vm_result.exit_info.exit_code, 0);

    let mut runtime =
        Runtime::<RuntimeTestAdapter>::new(node_config, ChainConfigsInner::test_config(), shared_memory, false)
            .await
            .unwrap();

    runtime.init(wasm_binary).unwrap();

    let (p2p_command_sender, _p2p_command_receiver) = mpsc::channel::<P2PCommand>(100);
    let runtime_execution_result = runtime.start_runtime(
        VmConfig {
            args:         vec![],
            program_name: "consensus".to_string(),
            start_func:   Some("shared_memory_success".to_string()),
            debug:        true,
        },
        memory_adapter(),
        p2p_command_sender,
    );

    let vm_result = runtime_execution_result.await;
    assert_eq!(vm_result.exit_info.exit_code, 0);
}

'''
'''--- runtime/core/src/storage/in_memory_adapter.rs ---
use std::{collections::HashMap, ops::Deref};

use super::{Bytes, FromBytes, MemoryAdapter, ToBytes};
use crate::Result;

#[derive(Debug, Default)]
pub struct InMemory {
    memory: HashMap<String, Bytes>,
}

impl MemoryAdapter for InMemory {
    fn get<O>(&self, key: &str) -> Result<Option<O>>
    where
        O: FromBytes,
    {
        Ok(self.memory.get(key).map(|b| O::from_bytes(b.deref())).transpose()?)
    }

    fn put<V>(&mut self, key: &str, value: V) -> Option<Bytes>
    where
        V: ToBytes,
    {
        self.memory.insert(key.into(), value.to_bytes())
    }

    fn contains_key(&self, key: &str) -> bool {
        self.memory.contains_key(key)
    }
}

'''
'''--- runtime/core/src/storage/in_memory_adapter_test.rs ---
use super::{InMemory, MemoryAdapter, ToBytes};

#[test]
fn test_in_memory_storage() {
    let mut memory_adapter = InMemory::default();

    let input_1 = 245u32;
    assert!(memory_adapter.put("u32", input_1).is_none());

    let input_2 = "hello".to_string();
    assert!(memory_adapter.put("string", input_2.clone()).is_none());

    assert_eq!(memory_adapter.get("u32").unwrap(), Some(input_1));
    assert_eq!(memory_adapter.get("string").unwrap(), Some(input_2));
}

#[test]
fn test_in_memory_storage_overwite_key() {
    let mut memory_adapter = InMemory::default();

    let og = 245u32;
    memory_adapter.put("tbr", og);
    assert_eq!(memory_adapter.get("tbr").unwrap(), Some(og));

    let replacement = "replaced".to_string();
    assert_eq!(memory_adapter.put("tbr", replacement.clone()), Some(og.to_bytes()));
    assert_eq!(memory_adapter.get("tbr").unwrap(), Some(replacement));
}

#[test]
#[should_panic]
fn test_in_memory_storage_incorrect_read_type() {
    let mut memory_adapter = InMemory::default();

    memory_adapter.put("u32", 245u32);
    let _: Option<u8> = memory_adapter.get("u32").unwrap();
}

'''
'''--- runtime/core/src/storage/memory_adapter.rs ---
use super::{Bytes, FromBytes, ToBytes};
use crate::Result;

pub trait MemoryAdapter: Default {
    fn get<V>(&self, key: &str) -> Result<Option<V>>
    where
        V: FromBytes;

    fn put<V>(&mut self, key: &str, value: V) -> Option<Bytes>
    where
        V: ToBytes;

    fn contains_key(&self, key: &str) -> bool;
}

'''
'''--- runtime/core/src/storage/mod.rs ---
mod in_memory_adapter;
pub use in_memory_adapter::*;

mod memory_adapter;
pub use memory_adapter::*;
pub(crate) use seda_runtime_sdk::{Bytes, FromBytes, ToBytes};

#[cfg(test)]
#[path = ""]
pub mod test {
    use super::*;

    mod in_memory_adapter_test;
}

'''
'''--- runtime/core/src/test_host.rs ---
use std::collections::HashMap;

use futures::lock::Mutex;
use lazy_static::lazy_static;
use seda_chains::{chain, AnotherChain, ChainAdapterTrait, Client, NearChain};
use seda_config::{ChainConfigs, NodeConfig};
use seda_runtime_sdk::{events::Event, Chain};

use crate::{HostAdapter, Result, RuntimeError};

lazy_static! {
    #[derive(Clone, Default)]
    static ref HASHMAP: Mutex<HashMap<String, String>> = Mutex::new(HashMap::new());

}

pub struct RuntimeTestAdapter {
    pub another_client: Client,
    pub near_client:    Client,
    pub chain_configs:  ChainConfigs,
}

#[async_trait::async_trait]
impl HostAdapter for RuntimeTestAdapter {
    type Error = RuntimeError;

    async fn new(config: ChainConfigs) -> Result<Self> {
        Ok(Self {
            another_client: Client::Another(AnotherChain::new_client(&config.another)?),
            near_client:    Client::Near(NearChain::new_client(&config.near)?),
            chain_configs:  config,
        })
    }

    fn select_client_from_chain(&self, chain: Chain) -> Client {
        match chain {
            Chain::Another => self.another_client.clone(),
            Chain::Near => self.near_client.clone(),
        }
    }

    async fn db_get(&self, key: &str) -> Result<Option<String>> {
        let db = HASHMAP.lock().await;
        let value = db.get(key);

        Ok(value.cloned())
    }

    async fn db_set(&self, key: &str, value: &str) -> Result<()> {
        let mut db = HASHMAP.lock().await;
        db.insert(key.to_string(), value.to_string());

        Ok(())
    }

    async fn http_fetch(&self, url: &str) -> Result<String> {
        Ok(reqwest::get(url).await?.text().await?)
    }

    async fn chain_view(&self, chain: Chain, contract_id: &str, method_name: &str, args: Vec<u8>) -> Result<Vec<u8>> {
        let client = self.select_client_from_chain(chain);

        Ok(chain::view(chain, client, contract_id, method_name, args).await?)
    }

    async fn chain_call(
        &self,
        chain: Chain,
        contract_id: &str,
        method_name: &str,
        args: Vec<u8>,
        deposit: u128,
        node_config: NodeConfig,
    ) -> Result<Vec<u8>> {
        let server_url = match chain {
            Chain::Another => &self.chain_configs.another.chain_rpc_url,
            Chain::Near => &self.chain_configs.near.chain_rpc_url,
        };
        let keypair_ed25519_bytes = Vec::<u8>::from(&node_config.keypair_ed25519);

        let signed_txn = chain::construct_signed_tx(
            chain,
            None,
            &keypair_ed25519_bytes,
            contract_id,
            method_name,
            args,
            node_config.gas,
            deposit,
            server_url,
        )
        .await?;
        let client = self.select_client_from_chain(chain);

        Ok(chain::send_tx(chain, client, &signed_txn).await?)
    }

    async fn trigger_event(&self, _event: Event) -> Result<()> {
        Ok(())
    }
}

'''
'''--- runtime/core/src/vm_result.rs ---
use serde::{Deserialize, Serialize};
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ExitInfo {
    pub exit_message: String,
    pub exit_code:    u8,
}

impl From<(String, u8)> for ExitInfo {
    fn from((exit_message, exit_code): (String, u8)) -> Self {
        Self {
            exit_message,
            exit_code,
        }
    }
}

/// Represents the result of a Vm instance
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct VmResult {
    pub stdout:    Vec<String>,
    pub stderr:    Vec<String>,
    pub result:    Option<Vec<u8>>,
    pub exit_info: ExitInfo,
}

// TODO create a readme of all these once its better established
/// The possible statuses of a [VmResult]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum VmResultStatus {
    /// When the Vm has nothing in the promise queue to run
    EmptyQueue,
    /// When the Vm runs and exits successfully
    Ok(String),
    /// When the config could not be set into the VM env variables
    FailedToSetConfig,
    /// When the WASI environment variables could not be initialized
    WasiEnvInitializeFailure,
    /// When the host functions could not be exported to the VM
    FailedToCreateVMImports,
    /// When the WASMER instance could not be created
    FailedToCreateWasmerInstance,
    /// When a function from the WASM VM does not exist
    FailedToGetWASMFn,
    /// When we fail to fetch the WASM VM stdout
    FailedToGetWASMStdout,
    /// When we fail to fetch the WASM VM stderr
    FailedToGetWASMStderr,
    /// When we fail to fetch the WASM VM stderr
    FailedToConvertVMPipeToString,
    /// An execution error from the WASM Runtime
    ExecutionError(String),
}

impl From<VmResultStatus> for ExitInfo {
    fn from(value: VmResultStatus) -> Self {
        match value {
            VmResultStatus::EmptyQueue => ("Success: Empty Promise Queue".into(), 0).into(),
            VmResultStatus::Ok(msg) => (format!("Success: {msg}"), 0).into(),
            VmResultStatus::FailedToSetConfig => ("Error: Failed to set VM Config".into(), 1).into(),
            VmResultStatus::WasiEnvInitializeFailure => ("Error: Failed to initialize Wasi Env".into(), 2).into(),
            VmResultStatus::FailedToCreateVMImports => ("Error: Failed to create host imports for VM".into(), 3).into(),
            VmResultStatus::FailedToCreateWasmerInstance => {
                ("Error: Failed to create WASMER instance".into(), 4).into()
            }
            VmResultStatus::FailedToGetWASMFn => {
                ("Error: Failed to find specified function in WASM binary".into(), 5).into()
            }
            VmResultStatus::FailedToGetWASMStdout => ("Error: Failed to get STDOUT of VM".into(), 6).into(),
            VmResultStatus::FailedToGetWASMStderr => ("Error: Failed to get STDERR of VM".into(), 7).into(),
            VmResultStatus::FailedToConvertVMPipeToString => {
                ("Error: Failed to convert VM pipe output to String".into(), 8).into()
            }
            VmResultStatus::ExecutionError(err) => (format!("Execution Error: {err}"), 8).into(),
        }
    }
}

impl From<VmResultStatus> for ExecutionResult {
    fn from(value: VmResultStatus) -> Self {
        Ok(value)
    }
}

pub type ExecutionResult<T = VmResultStatus, E = VmResultStatus> = core::result::Result<T, E>;

impl From<ExecutionResult> for ExitInfo {
    fn from(value: ExecutionResult) -> Self {
        match value {
            Ok(ok) => ok.into(),
            Err(err) => err.into(),
        }
    }
}

'''
'''--- runtime/macros/Cargo.toml ---
[package]
name = "seda-runtime-macros"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[lib]
proc-macro = true

[dependencies]
proc-macro2 = "1.0.47"
quote = "1.0.21"
syn = "1.0.103"

'''
'''--- runtime/macros/src/lib.rs ---
use proc_macro::TokenStream;
use quote::quote;
use syn::{parse::Parse, parse_macro_input, punctuated::Punctuated, Attribute, DeriveInput, Ident, Token};

#[derive(Clone, Default)]
struct AdapterActions {
    pub db:               Option<Ident>,
    pub http:             Option<Ident>,
    pub chain_interactor: Option<Ident>,
}

impl IntoIterator for AdapterActions {
    type IntoIter = std::array::IntoIter<Self::Item, 3>;
    type Item = (&'static str, Option<Ident>);

    fn into_iter(self) -> Self::IntoIter {
        [
            ("database", self.db),
            ("http", self.http),
            ("chain_interactor", self.chain_interactor),
        ]
        .into_iter()
    }
}

impl AdapterActions {
    fn merge(self, other: Self) -> syn::Result<Self> {
        let either = |a: Option<Ident>, b: Option<Ident>| match (a, b) {
            (None, None) => Ok(None),
            (Some(val), None) | (None, Some(val)) => Ok(Some(val)),
            (Some(lhs), Some(rhs)) => {
                let mut error = syn::Error::new_spanned(rhs, "redundant attribute argument");
                error.combine(syn::Error::new_spanned(lhs, "note: first one here"));
                Err(error)
            }
        };

        Ok(Self {
            db:               either(self.db, other.db)?,
            http:             either(self.http, other.http)?,
            chain_interactor: either(self.chain_interactor, other.chain_interactor)?,
        })
    }

    fn from_attrs(attrs: Vec<Attribute>) -> syn::Result<AdapterActions> {
        let actions = attrs
            .into_iter()
            .filter(|attr| attr.path.is_ident("adapter"))
            .try_fold(AdapterActions::default(), |act, attr| {
                let list: Punctuated<AdapterActions, Token![,]> = attr.parse_args_with(Punctuated::parse_terminated)?;

                list.into_iter().try_fold(act, AdapterActions::merge)
            })?;

        actions
            .clone()
            .into_iter()
            .try_for_each(|(field, action)| match action {
                Some(_) => Ok(()),
                None => Err(syn::Error::new_spanned(
                    quote!(
                        #field
                    ),
                    format!("Missing Adapter Type: {field}."),
                )),
            })?;
        Ok(actions)
    }
}

mod keywords {
    syn::custom_keyword!(database);
    syn::custom_keyword!(http);
    syn::custom_keyword!(chain_interactor);
}

impl Parse for AdapterActions {
    fn parse(input: syn::parse::ParseStream) -> syn::Result<Self> {
        if input.peek(keywords::database) {
            input.parse::<keywords::database>()?;
            input.parse::<syn::Token![=]>()?;
            let db = input.parse::<syn::Ident>()?;

            Ok(Self {
                db:               Some(db),
                http:             None,
                chain_interactor: None,
            })
        } else if input.peek(keywords::http) {
            input.parse::<keywords::http>()?;
            input.parse::<syn::Token![=]>()?;
            let http = input.parse::<syn::Ident>()?;
            Ok(Self {
                http:             Some(http),
                db:               None,
                chain_interactor: None,
            })
        } else if input.peek(keywords::chain_interactor) {
            input.parse::<keywords::chain_interactor>()?;
            input.parse::<syn::Token![=]>()?;
            let chain_interactor = input.parse::<syn::Ident>()?;
            Ok(Self {
                chain_interactor: Some(chain_interactor),
                http:             None,
                db:               None,
            })
        } else {
            Err(syn::Error::new(
                input.span(),
                "Unknown adapter type or empty parse stream",
            ))
        }
    }
}

#[proc_macro_derive(Adapter, attributes(adapter))]
pub fn adapter(input: TokenStream) -> TokenStream {
    let derive = parse_macro_input!(input as DeriveInput);
    let name = &derive.ident;
    let actions = match AdapterActions::from_attrs(derive.attrs) {
        Ok(actions) => actions,
        Err(err) => return err.to_compile_error().into(),
    };
    let db = actions.db.unwrap();
    let http = actions.http.unwrap();
    let chain_interactor = actions.chain_interactor.unwrap();

    let adapter_trait_impl = quote!(
        impl HostAdapterTypes for #name {
          type Database = #db;
          type Http = #http;
          type ChainInteractor = #chain_interactor;
        }
    );

    adapter_trait_impl.into()
}

'''
'''--- runtime/sdk/Cargo.toml ---
[package]
name = "seda-runtime-sdk"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[features]
default = []
wasm = ["serde_json"]
full = []

[dependencies]
bn254 = { workspace = true }
clap = { workspace = true, features = ["derive", "std"] }
lazy_static = { workspace = true }
seda-config = { workspace = true }
serde = { workspace = true, features = ["std"] }
serde_json = { workspace = true, optional = true, features = ["std"] }
thiserror = { workspace = true }
tracing = { workspace = true }
url = { workspace = true, features = ["serde"] }

'''
'''--- runtime/sdk/src/bytes.rs ---
use std::ops::Deref;

use serde::{Deserialize, Serialize};

use crate::Result;

#[derive(Clone, Debug, Default, PartialEq, Eq, Serialize, Deserialize)]
pub struct Bytes(Vec<u8>);

impl Bytes {
    pub fn eject(self) -> Vec<u8> {
        self.0
    }
}

/// We implement Deref over the Bytes type allowing us to avoid a clone for
/// `FromBytes`.
impl Deref for Bytes {
    type Target = [u8];

    fn deref(&self) -> &Self::Target {
        self.0.as_slice()
    }
}

pub trait ToBytes {
    fn to_bytes(self) -> Bytes;
}

impl ToBytes for Bytes {
    fn to_bytes(self) -> Bytes {
        self
    }
}

impl ToBytes for Vec<u8> {
    fn to_bytes(self) -> Bytes {
        Bytes(self)
    }
}

impl ToBytes for String {
    fn to_bytes(self) -> Bytes {
        Bytes(self.as_bytes().to_vec())
    }
}

impl ToBytes for &str {
    fn to_bytes(self) -> Bytes {
        Bytes(self.as_bytes().to_vec())
    }
}

impl ToBytes for bool {
    fn to_bytes(self) -> Bytes {
        Bytes(vec![self as u8])
    }
}

/// For functions that return an `()` to be converted to a
/// [crate::PromiseStatus]
impl ToBytes for () {
    fn to_bytes(self) -> Bytes {
        Bytes::default()
    }
}

pub trait FromBytes
where
    Self: Sized,
{
    fn from_bytes(bytes: &[u8]) -> Result<Self>;

    fn from_bytes_vec(bytes: Vec<u8>) -> Result<Self>;
}

impl FromBytes for Vec<u8> {
    fn from_bytes(bytes: &[u8]) -> Result<Self> {
        Ok(bytes.to_vec())
    }

    fn from_bytes_vec(bytes: Vec<u8>) -> Result<Self> {
        Ok(bytes)
    }
}

impl FromBytes for String {
    fn from_bytes(bytes: &[u8]) -> Result<Self> {
        Ok(std::str::from_utf8(bytes)?.into())
    }

    fn from_bytes_vec(bytes: Vec<u8>) -> Result<Self> {
        Self::from_bytes(bytes.as_slice())
    }
}

impl FromBytes for bool {
    fn from_bytes(bytes: &[u8]) -> Result<Self> {
        Ok(bytes[0] > 0)
    }

    fn from_bytes_vec(bytes: Vec<u8>) -> Result<Self> {
        Self::from_bytes(bytes.as_slice())
    }
}

macro_rules! bytes_impls_le_bytes {
    ($type_:ty, $num_bytes:expr) => {
        impl ToBytes for $type_ {
            fn to_bytes(self) -> Bytes {
                Bytes(self.to_le_bytes().to_vec())
            }
        }

        impl FromBytes for $type_ {
            fn from_bytes(bytes: &[u8]) -> Result<Self> {
                let bytes: [u8; $num_bytes] = bytes.try_into()?;
                Ok(<$type_>::from_le_bytes(bytes))
            }

            fn from_bytes_vec(bytes: Vec<u8>) -> Result<Self> {
                Self::from_bytes(bytes.as_slice())
            }
        }
    };
}

bytes_impls_le_bytes!(u8, 1);
bytes_impls_le_bytes!(u32, 4);
bytes_impls_le_bytes!(u64, 8);
bytes_impls_le_bytes!(u128, 16);
bytes_impls_le_bytes!(i8, 1);
bytes_impls_le_bytes!(i32, 4);
bytes_impls_le_bytes!(i64, 8);
bytes_impls_le_bytes!(i128, 16);
bytes_impls_le_bytes!(f32, 4);
bytes_impls_le_bytes!(f64, 8);

'''
'''--- runtime/sdk/src/chain.rs ---
use core::fmt;

use clap::ValueEnum;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Copy, Serialize, Deserialize, ValueEnum)]
pub enum Chain {
    Another,
    Near,
}

impl fmt::Display for Chain {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Chain::Another => write!(f, "another"),
            Chain::Near => write!(f, "near"),
        }
    }
}

'''
'''--- runtime/sdk/src/errors.rs ---
use thiserror::Error;

#[derive(Debug, Error)]
pub enum SDKError {
    #[error(transparent)]
    FromUtf8Error(#[from] std::string::FromUtf8Error),

    #[error("{0:?}")]
    StringBytesConversion(#[from] std::str::Utf8Error),

    #[error(transparent)]
    NumBytesConversion(#[from] std::array::TryFromSliceError),

    #[error(transparent)]
    UrlParse(#[from] url::ParseError),

    #[error("Expected a valid url scheme but got `{0}`")]
    InvalidUrlScheme(String),
}

pub type Result<T, E = SDKError> = core::result::Result<T, E>;

'''
'''--- runtime/sdk/src/events.rs ---
use serde::{Deserialize, Serialize};

use crate::p2p::P2PMessage;

pub type EventId = String;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum EventData {
    // Tick types
    BatchChainTick,
    ChainTick,
    P2PMessage(P2PMessage),
    CliCall(Vec<String>),
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Event {
    pub id:   EventId,
    pub data: EventData,
}

impl Event {
    pub fn new<T: ToString>(id: T, data: EventData) -> Self {
        Self {
            id: id.to_string(),
            data,
        }
    }
}

'''
'''--- runtime/sdk/src/level.rs ---
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub enum Level {
    Debug,
    Error,
    Info,
    Trace,
    Warn,
}

// TODO only log line_info with a config option.
impl Level {
    pub fn log(self, message: &str, line_info: &str) {
        let message = format!("{message}\n    at {line_info}");
        match self {
            Level::Debug => tracing::debug!(message),
            Level::Error => tracing::error!(message),
            Level::Info => tracing::info!(message),
            Level::Trace => tracing::trace!(message),
            Level::Warn => tracing::warn!(message),
        }
    }
}

'''
'''--- runtime/sdk/src/lib.rs ---
mod chain;
pub use chain::Chain;
mod errors;
pub use errors::*;
mod level;
pub use level::Level;
mod bytes;
pub use bytes::*;
pub mod p2p;
mod promises;
mod url;
pub use self::url::*;
mod near;
pub use near::*;

#[cfg(feature = "wasm")]
pub mod wasm;

pub mod events;

pub use promises::{
    CallSelfAction,
    ChainCallAction,
    ChainViewAction,
    DatabaseGetAction,
    DatabaseSetAction,
    HttpAction,
    P2PBroadcastAction,
    Promise,
    PromiseAction,
    PromiseStatus,
    TriggerEventAction,
};

'''
'''--- runtime/sdk/src/near.rs ---
/// Taken from https://docs.rs/near-sdk-sim/latest/near_sdk_sim/
/// Converts a string (nominated in full NEAR tokens) and converts it to
/// yoctoNEAR (smallest denominator in NEAR)
pub fn to_yocto(value: &str) -> u128 {
    let vals: Vec<_> = value.split('.').collect();
    let part1 = vals[0].parse::<u128>().unwrap() * 10u128.pow(24);
    if vals.len() > 1 {
        let power = vals[1].len() as u32;
        let part2 = vals[1].parse::<u128>().unwrap() * 10u128.pow(24 - power);
        part1 + part2
    } else {
        part1
    }
}

'''
'''--- runtime/sdk/src/p2p.rs ---
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct P2PMessage {
    pub source: Option<String>,
    pub data:   Vec<u8>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct UnicastCommand {
    pub peer_id: String,
    pub data:    Vec<u8>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct AddPeerCommand {
    pub multi_addr: String,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct RemovePeerCommand {
    pub peer_id: String,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub enum P2PCommand {
    Broadcast(Vec<u8>),
    Unicast(UnicastCommand),
    AddPeer(AddPeerCommand),
    RemovePeer(RemovePeerCommand),
    DiscoverPeers,
}

'''
'''--- runtime/sdk/src/promises/actions.rs ---
use core::fmt;

use serde::{Deserialize, Serialize};

use crate::{events::Event, Chain};

// TODO: all action types with Vec<u8> can just be the Bytes type.
#[derive(Serialize, Deserialize, Clone, Debug)]
pub enum PromiseAction {
    CallSelf(CallSelfAction),
    DatabaseSet(DatabaseSetAction),
    DatabaseGet(DatabaseGetAction),
    Http(HttpAction),
    ChainView(ChainViewAction),
    ChainCall(ChainCallAction),
    TriggerEvent(TriggerEventAction),
    P2PBroadcast(P2PBroadcastAction),
}

impl PromiseAction {
    #[cfg(not(target_family = "wasm"))]
    pub fn is_limited_action(&self) -> bool {
        !matches!(self, Self::CallSelf(_) | Self::Http(_))
    }
}

impl fmt::Display for PromiseAction {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::CallSelf(_) => write!(f, "call_self"),
            Self::DatabaseSet(_) => write!(f, "db_set"),
            Self::DatabaseGet(_) => write!(f, "db_get"),
            Self::Http(_) => write!(f, "http"),
            Self::ChainView(_) => write!(f, "chain_view"),
            Self::ChainCall(_) => write!(f, "chain_call"),
            Self::TriggerEvent(_) => write!(f, "trigger_event"),
            Self::P2PBroadcast(_) => write!(f, "p2p_broadcast"),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct CallSelfAction {
    pub function_name: String,
    pub args:          Vec<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct DatabaseSetAction {
    pub key:   String,
    pub value: Vec<u8>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct DatabaseGetAction {
    pub key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct HttpAction {
    // TODO: change to url::Url
    pub url: String,
    // TODO: add headers, method, etc :)
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct ChainViewAction {
    pub chain:       Chain,
    pub contract_id: String,
    pub method_name: String,
    pub args:        Vec<u8>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct ChainCallAction {
    pub chain:       Chain,
    pub contract_id: String,
    pub method_name: String,
    pub args:        Vec<u8>,
    pub deposit:     u128,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct TriggerEventAction {
    pub event: Event,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct P2PBroadcastAction {
    pub data: Vec<u8>,
}

'''
'''--- runtime/sdk/src/promises/mod.rs ---
mod actions;
mod promise;

pub use actions::*;
pub use promise::{Promise, PromiseStatus};

'''
'''--- runtime/sdk/src/promises/promise.rs ---
use serde::{Deserialize, Serialize};

use super::PromiseAction;
use crate::ToBytes;

// TODO: Fulfilled and Rejected could now just be our Bytes type.
#[derive(Serialize, Deserialize, Clone, Debug)]
pub enum PromiseStatus {
    /// Initial state
    Unfulfilled,

    /// We are processing the promise
    Pending,

    /// The promise completed
    Fulfilled(Option<Vec<u8>>),

    /// There was an error executing this promise
    // TODO: Is there ever a case where Rejected isn't a string?
    // HTTP rejections could be an object(but encoded in a string).
    // Could private the type and then have methods or something.
    Rejected(Vec<u8>),
}

impl<T: crate::ToBytes, E: std::error::Error> From<Result<T, E>> for PromiseStatus {
    fn from(value: Result<T, E>) -> Self {
        match value {
            Ok(fulfilled) => PromiseStatus::Fulfilled(Some(fulfilled.to_bytes().eject())),
            Err(rejection) => PromiseStatus::Rejected(rejection.to_string().to_bytes().eject()),
        }
    }
}

impl<T: crate::ToBytes, E: std::error::Error> From<Result<Option<T>, E>> for PromiseStatus {
    fn from(value: Result<Option<T>, E>) -> Self {
        match value {
            Ok(fulfilled) => PromiseStatus::Fulfilled(fulfilled.map(|inner| inner.to_bytes().eject())),
            Err(rejection) => PromiseStatus::Rejected(rejection.to_string().to_bytes().eject()),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Promise {
    /// The name of the action we should execute
    pub action: PromiseAction,

    /// The status of the promise, will include the result if it's fulfilled
    pub status: PromiseStatus,
}

'''
'''--- runtime/sdk/src/url.rs ---
use url::Url;

use crate::Result;

pub trait ToUrl {
    fn to_url(self) -> Result<Url>;
}

impl ToUrl for String {
    fn to_url(self) -> Result<Url> {
        Ok(Url::parse(&self)?)
    }
}

impl ToUrl for &str {
    fn to_url(self) -> Result<Url> {
        Ok(Url::parse(self)?)
    }
}

'''
'''--- runtime/sdk/src/wasm/bn254.rs ---
pub use bn254::{PrivateKey as Bn254PrivateKey, PublicKey as Bn254PublicKey, Signature as Bn254Signature};

use super::raw;

pub fn bn254_verify(message: &[u8], signature: &Bn254Signature, public_key: &Bn254PublicKey) -> bool {
    let message_len = message.len() as i64;
    let signature_bytes = signature.to_uncompressed().expect("Signature should be valid");
    let signature_length = signature_bytes.len() as i64;
    let public_key_bytes = public_key.to_uncompressed().expect("Public Key should be valid");
    let public_key_length = public_key_bytes.len() as i64;

    let result = unsafe {
        raw::bn254_verify(
            message.as_ptr(),
            message_len,
            signature_bytes.as_ptr(),
            signature_length,
            public_key_bytes.as_ptr(),
            public_key_length,
        )
    };

    match result {
        0 => false,
        1 => true,
        _ => panic!("Bn254 verify returned invalid bool in u8: {}", result),
    }
}

pub fn bn254_sign(message: &[u8]) -> Bn254Signature {
    let message_len = message.len() as i64;

    // Uncompressed Signatures in G1 have a length of 33 bytes
    let value_len = 64;
    let mut result_data_ptr = vec![0; value_len as usize];

    unsafe { raw::bn254_sign(message.as_ptr(), message_len, result_data_ptr.as_mut_ptr(), value_len) };

    Bn254Signature::from_uncompressed(result_data_ptr).expect("Signature should be valid")
}

'''
'''--- runtime/sdk/src/wasm/call.rs ---
use super::Promise;
use crate::{CallSelfAction, PromiseAction};

pub fn call_self(function_name: &str, args: Vec<String>) -> Promise {
    Promise::new(PromiseAction::CallSelf(CallSelfAction {
        function_name: function_name.to_string(),
        args,
    }))
}

'''
'''--- runtime/sdk/src/wasm/chain_interactor.rs ---
use super::Promise;
use crate::{Chain, ChainCallAction, ChainViewAction, PromiseAction};

pub fn chain_view<C: ToString, M: ToString>(chain: Chain, contract_id: C, method_name: M, args: Vec<u8>) -> Promise {
    Promise::new(PromiseAction::ChainView(ChainViewAction {
        chain,
        contract_id: contract_id.to_string(),
        method_name: method_name.to_string(),
        args,
    }))
}

pub fn chain_call<C: ToString, M: ToString>(
    chain: Chain,
    contract_id: C,
    method_name: M,
    args: Vec<u8>,
    deposit: u128,
) -> Promise {
    Promise::new(PromiseAction::ChainCall(ChainCallAction {
        chain,
        contract_id: contract_id.to_string(),
        method_name: method_name.to_string(),
        args,
        deposit,
    }))
}

'''
'''--- runtime/sdk/src/wasm/database.rs ---
use super::Promise;
use crate::{DatabaseGetAction, DatabaseSetAction, PromiseAction};

pub fn db_set(key: &str, value: &str) -> Promise {
    Promise::new(PromiseAction::DatabaseSet(DatabaseSetAction {
        key:   key.to_string(),
        value: value.to_string().into_bytes(),
    }))
}

pub fn db_get(key: &str) -> Promise {
    Promise::new(PromiseAction::DatabaseGet(DatabaseGetAction { key: key.to_string() }))
}

'''
'''--- runtime/sdk/src/wasm/env.rs ---
pub fn get_oracle_contract_id() -> String {
    std::env::var("ORACLE_CONTRACT_ID").expect("Env 'ORACLE_CONTRACT_ID' does not exist")
}

pub fn get_local_bn254_public_key() -> String {
    std::env::var("BN254_PUBLIC_KEY").expect("Env 'BN254_PUBLIC_KEY' does not exist")
}

pub fn get_local_ed25519_public_key() -> String {
    std::env::var("ED25519_PUBLIC_KEY").expect("Env 'ED25519_PUBLIC_KEY' does not exist")
}

'''
'''--- runtime/sdk/src/wasm/execution.rs ---
use super::{raw, Promise};
use crate::{events::Event, PromiseAction, TriggerEventAction};

pub fn execution_result(result: Vec<u8>) {
    let result_length = result.len() as i32;

    unsafe {
        raw::execution_result(result.as_ptr(), result_length);
    }
}

/// Triggers an event on the host node
/// Allows you to resolve data requests, sign blocks but at a later stage
pub fn trigger_event(event: Event) -> Promise {
    Promise::new(PromiseAction::TriggerEvent(TriggerEventAction { event }))
}

'''
'''--- runtime/sdk/src/wasm/http.rs ---
use super::Promise;
use crate::{HttpAction, PromiseAction};

pub fn http_fetch(url: &str) -> Promise {
    Promise::new(PromiseAction::Http(HttpAction { url: url.into() }))
}

'''
'''--- runtime/sdk/src/wasm/log.rs ---
use super::raw;
use crate::Level;

pub fn _log(level: Level, msg: &str, line_info: &str) {
    let level_str = serde_json::to_string(&level).unwrap();

    unsafe {
        raw::_log(
            level_str.as_ptr(),
            level_str.len() as i32,
            msg.as_ptr(),
            msg.len() as i64,
            line_info.as_ptr(),
            line_info.len() as i64,
        );
    }
}

#[macro_export]
macro_rules! log {
    ($level:expr, $($arg:tt)*) => {{
				let _msg = format!($($arg)*);
				let _line_info = format!("{}:{}", file!(), line!());
				$crate::wasm::_log($level, &_msg, &_line_info)
    }};
}

pub use log;

'''
'''--- runtime/sdk/src/wasm/memory.rs ---
use super::raw;

pub fn memory_read(key: &str) -> Vec<u8> {
    let key_len = key.len() as i64;
    let mut key = key.to_string().into_bytes();
    let value_len = unsafe { raw::memory_read_length(key.as_mut_ptr(), key_len) };
    let mut result_data_ptr = vec![0; value_len as usize];
    unsafe {
        raw::memory_read(key.as_mut_ptr(), key_len, result_data_ptr.as_mut_ptr(), value_len);
    }
    result_data_ptr
}

// TODO: Value could be cleaned up to a generic that implements our ToBytes
// trait :)
pub fn memory_write(key: &str, mut value: Vec<u8>) {
    let key_len = key.len() as i64;
    let mut key = key.to_string().into_bytes();
    let value_len = value.len() as i64;
    unsafe {
        raw::memory_write(key.as_mut_ptr(), key_len, value.as_mut_ptr(), value_len);
    }
}

pub fn shared_memory_get(key: &str) -> Vec<u8> {
    let key_len = key.len() as i64;
    let mut key = key.to_string().into_bytes();
    let value_len = unsafe { raw::shared_memory_read_length(key.as_mut_ptr(), key_len) };
    let mut result_data_ptr = vec![0; value_len as usize];
    unsafe {
        raw::shared_memory_read(key.as_mut_ptr(), key_len, result_data_ptr.as_mut_ptr(), value_len);
    }
    result_data_ptr
}

// TODO: Value could be cleaned up to a generic that implements our ToBytes
// trait :)
pub fn shared_memory_set(key: &str, mut value: Vec<u8>) {
    let key_len = key.len() as i64;
    let mut key = key.to_string().into_bytes();
    let value_len = value.len() as i64;
    unsafe {
        raw::shared_memory_write(key.as_mut_ptr(), key_len, value.as_mut_ptr(), value_len);
    }
}

pub fn shared_memory_contains_key(key: &str) -> bool {
    let key_len = key.len() as i64;
    let mut key = key.to_string().into_bytes();

    let result = unsafe { raw::shared_memory_contains_key(key.as_mut_ptr(), key_len) };

    match result {
        0 => false,
        1 => true,
        _ => unreachable!("Bn254 verify returned invalid bool in u8: {}", result),
    }
}

'''
'''--- runtime/sdk/src/wasm/mod.rs ---
mod bn254;
mod call;
#[cfg(feature = "full")]
mod chain_interactor;
#[cfg(feature = "full")]
mod database;
mod env;
mod execution;
mod http;
mod log;
mod memory;
mod p2p;
mod promise;
mod raw;

pub use call::*;
#[cfg(feature = "full")]
pub use chain_interactor::*;
#[cfg(feature = "full")]
pub use database::*;
pub use env::*;
pub use execution::*;
pub use http::*;
pub use log::*;
pub use memory::*;
#[cfg(feature = "full")]
pub use p2p::*;
pub use promise::*;

pub use self::bn254::*;

'''
'''--- runtime/sdk/src/wasm/p2p.rs ---
use super::Promise;
use crate::{P2PBroadcastAction, PromiseAction};

// TODO: data could be cleaned up to a generic that implements our ToBytes trait
pub fn p2p_broadcast_message(data: Vec<u8>) -> Promise {
    Promise::new(PromiseAction::P2PBroadcast(P2PBroadcastAction { data }))
}

'''
'''--- runtime/sdk/src/wasm/promise.rs ---
use std::str;

use serde::{Deserialize, Serialize};

use super::raw::promise_then;
use crate::{wasm::raw, PromiseAction, PromiseStatus};

#[derive(Debug, Serialize, Deserialize)]
pub struct Promise {
    /// The name of the action we should execute
    pub action: PromiseAction,

    /// The status of the promise, will include the result if it's fulfilled
    pub status: PromiseStatus,

    #[serde(skip)]
    /// The promise we should execute after this one
    pub after: Option<Box<Self>>,
}

impl Promise {
    pub fn new(action: PromiseAction) -> Self {
        Self {
            action,
            after: None,
            status: PromiseStatus::Unfulfilled,
        }
    }

    fn add_to_queue(promise: &Self) {
        // the json! macro was failing
        let promise_data = serde_json::to_string(&promise).expect("Shouldn't ever fail.");

        unsafe {
            promise_then(promise_data.as_ptr(), promise_data.len() as i32);
        }
    }

    /// Starts the promise chain, must be only called on the first promise
    /// before chaining (calling .then())
    pub fn start(self) -> Self {
        Promise::add_to_queue(&self);

        self
    }

    /// Chains this promise after the previous promise
    pub fn then(mut self, after: Self) -> Self {
        Promise::add_to_queue(&after);
        self.after = Some(Box::new(after));

        self
    }

    /// Returns the result of a promise action
    pub fn result(index: i32) -> PromiseStatus {
        let promise_result_length = unsafe { raw::promise_status_length(index) };

        let mut result_data: Vec<u8> = Vec::new();
        result_data.resize(promise_result_length as usize, 0);

        unsafe {
            raw::promise_status_write(index, result_data.as_mut_ptr(), promise_result_length);
        }

        let result_str = String::from_utf8(result_data).unwrap();
        let promise_status: PromiseStatus = serde_json::from_str(&result_str).unwrap();

        promise_status
    }
}

'''
'''--- runtime/sdk/src/wasm/raw.rs ---
extern "C" {
    pub fn promise_then(action_data_offset: *const u8, action_data_length: i32);
    pub fn promise_status_length(promise_index: i32) -> i64;
    pub fn promise_status_write(promise_index: i32, result_data_offset: *const u8, result_data_length: i64);
    pub fn memory_read(key: *const u8, key_length: i64, result_data_ptr: *const u8, result_data_length: i64);
    pub fn memory_read_length(key: *const u8, key_length: i64) -> i64;
    pub fn memory_write(key: *const u8, key_length: i64, value: *const u8, value_length: i64);
    pub fn shared_memory_read(key: *const u8, key_length: i64, result_data_ptr: *const u8, result_data_length: i64);
    pub fn shared_memory_contains_key(key: *const u8, key_length: i64) -> u8;
    pub fn shared_memory_read_length(key: *const u8, key_length: i64) -> i64;
    pub fn shared_memory_write(key: *const u8, key_length: i64, value: *const u8, value_length: i64);
    pub fn execution_result(result: *const u8, result_length: i32);
    pub fn _log(
        level: *const u8,
        level_len: i32,
        msg: *const u8,
        msg_len: i64,
        line_info: *const u8,
        line_info_len: i64,
    );
    pub fn bn254_verify(
        message: *const u8,
        message_length: i64,
        signature: *const u8,
        signature_length: i64,
        public_key: *const u8,
        public_key_length: i64,
    ) -> u8;
    pub fn bn254_sign(message: *const u8, message_length: i64, result_data_ptr: *const u8, result_data_length: i64);
}

'''
'''--- tooling/debug/Cargo.toml ---
[package]
name = "seda-debugger"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[[bin]]
name = "seda_debug"
path = "src/main.rs"

[dependencies]
# Not putting this in the workspace since we don't
# want it used in the rest of the application.
anyhow = "1.0"
async-trait = { workspace = true }
clap = { workspace = true, features = ["default", "derive"] }
jsonrpsee = { workspace = true, features = ["http-client", "macros", "server"] }
near-crypto = { workspace = true }
near-jsonrpc-client = { workspace = true }
near-jsonrpc-primitives = { workspace = true }
near-primitives = { workspace = true }
rand = { workspace = true }
seda-common = { workspace = true, features = ["test"] }
serde_json = { workspace = true }
tokio = { workspace = true, features = ["rt-multi-thread", "signal"] }
tracing = { workspace = true }

[dev-dependencies]
jsonrpsee = { workspace = true }

'''
'''--- tooling/debug/src/main.rs ---
use anyhow::Result;

mod rpc;
use clap::Parser;
pub use rpc::*;

#[derive(Debug, Parser)]
#[command(name = "seda_debug")]
#[command(author = "https://github.com/SedaProtocol")]
#[command(version)]
#[command(propagate_version = true)]
#[command(about = "For help debugging the SEDA protocol.", long_about = None)]
#[command(next_line_help = true)]
/// For debugging and testing the seda node and tools
pub enum DebugMode {
    /// The test RPC for testing.
    TestRpc {
        #[arg(short, long)]
        addr: String,
        #[command(subcommand)]
        rpc:  Rpc,
    },
}

impl DebugMode {
    pub fn handle(self) -> Result<()> {
        match self {
            DebugMode::TestRpc { addr, rpc } => rpc.handle(&addr),
        }
    }
}

fn main() -> Result<()> {
    let options = DebugMode::parse();
    options.handle()
}

'''
'''--- tooling/debug/src/rpc/mod.rs ---
mod start;
mod stop;
mod test_rpc;
use clap::Subcommand;

use super::Result;

#[derive(Debug, Subcommand)]
pub enum Rpc {
    /// Starts the test RPC server
    Start(start::Start),
    /// Stops the test RPC server
    Stop(stop::Stop),
}

impl Rpc {
    pub fn handle(self, addr: &str) -> Result<()> {
        match self {
            Rpc::Start(start) => start.handle(addr),
            Rpc::Stop(stop) => stop.handle(addr),
        }
    }
}

'''
'''--- tooling/debug/src/rpc/start.rs ---
use clap::Args;
use jsonrpsee::server::ServerBuilder;
use tokio::sync::mpsc;

use super::test_rpc::{MockNearRpc, MockNearRpcServer};
use crate::Result;

#[derive(Debug, Args)]
pub struct Start;

impl Start {
    #[tokio::main]
    pub async fn handle(self, addr: &str) -> Result<()> {
        let server = ServerBuilder::default().build(addr).await?;

        println!("Starting Seda Test RPC server on {addr}");
        let (tx, mut rx) = mpsc::channel(1);
        let rpc = MockNearRpc::new(tx);
        let handle = server.start(rpc.into_rpc())?;
        let spawn_handle = handle.clone();
        tokio::spawn(async move {
            tokio::signal::ctrl_c().await.expect("Failed to listen ctrl-c signal.");
            println!("Shutting down Seda Test RPC");
            spawn_handle.stop().expect("Failed to stop Seda Test RPC server");
        });

        while let Some(shutdown) = rx.recv().await {
            if shutdown {
                handle.stop()?;
            }
        }
        Ok(())
    }
}

'''
'''--- tooling/debug/src/rpc/stop.rs ---
use clap::Args;
use jsonrpsee::{core::client::ClientT, http_client::HttpClientBuilder, rpc_params};

use crate::Result;

#[derive(Debug, Args)]
pub struct Stop;

impl Stop {
    #[tokio::main]
    pub async fn handle(self, addr: &str) -> Result<()> {
        let client = HttpClientBuilder::default().build(format!("http://{addr}"))?;
        client.request::<(), _>("stop_server", rpc_params!()).await?;
        Ok(())
    }
}

'''
'''--- tooling/debug/src/rpc/test_rpc.rs ---
use std::str::FromStr;

use async_trait::async_trait;
use jsonrpsee::{core::Error, proc_macros::rpc};
use near_crypto::{PublicKey, Signature};
use near_jsonrpc_client::methods::query::RpcQueryResponse;
use near_jsonrpc_primitives::types::query::QueryResponseKind;
use near_primitives::{
    account::{AccessKey, AccessKeyPermission},
    borsh::BorshDeserialize,
    hash::CryptoHash,
    merkle::{Direction, MerklePathItem},
    transaction::SignedTransaction,
    views::{
        CallResult,
        ExecutionMetadataView,
        ExecutionOutcomeView,
        ExecutionOutcomeWithIdView,
        FinalExecutionOutcomeView,
        SignedTransactionView,
    },
};
use rand::{rngs::OsRng, Rng};
use seda_common::NodeInfo;
use serde_json::json;
use tokio::sync::mpsc::Sender;

use crate::Result;

#[rpc(server)]
pub trait MockNearRpc {
    #[method(name = "broadcast_tx_async")]
    async fn broadcast_tx_async(&self, args: String) -> Result<CryptoHash, Error>;

    #[method(name = "query")]
    async fn query(
        &self,
        account_id: String,
        args_base64: Option<String>,
        finality: String,
        method_name: Option<String>,
        request_type: String,
    ) -> Result<RpcQueryResponse, Error>;

    #[method(name = "stop_server")]
    async fn stop_server(&self) -> Result<(), Error>;

    #[method(name = "tx")]
    async fn tx(&self, hash: String, account_id: String) -> Result<FinalExecutionOutcomeView, Error>;
}

pub struct MockNearRpc {
    shutdown_channel: Sender<bool>,
}

impl MockNearRpc {
    pub fn new(shutdown_channel: Sender<bool>) -> Self {
        Self { shutdown_channel }
    }

    fn random_crypto_hash(&self) -> CryptoHash {
        CryptoHash::hash_bytes(&OsRng.gen::<[u8; 32]>())
    }
}

#[async_trait]
impl MockNearRpcServer for MockNearRpc {
    async fn broadcast_tx_async(&self, params: String) -> Result<CryptoHash, Error> {
        println!("Calling broadcast_tx_async");
        let non_base_64 = near_primitives::serialize::from_base64(&params).unwrap();

        let tx: SignedTransaction =
            SignedTransaction::try_from_slice(&non_base_64).map_err(|e| Error::Custom(e.to_string()))?;
        Ok(tx.get_hash())
    }

    // TODO: would be nice to set up logging so we can confirm things from node side
    // as well
    async fn query(
        &self,
        _account_id: String,
        _args_base64: Option<String>,
        _finality: String,
        method_name: Option<String>,
        request_type: String,
    ) -> Result<RpcQueryResponse, Error> {
        match request_type.as_str() {
            "call_function" if method_name.is_some() => match method_name.unwrap().as_str() {
                "get_node" => Ok(RpcQueryResponse {
                    kind:         QueryResponseKind::CallResult(CallResult {
                        // TODO we have this structure defined already in the CLI
                        // So we can move it to somewhere common
                        result: serde_json::to_vec_pretty(&NodeInfo::random()).unwrap(),
                        logs:   Default::default(),
                    }),
                    block_height: 119467302,
                    block_hash:   self.random_crypto_hash(),
                }),
                "get_active_nodes" => Ok(RpcQueryResponse {
                    kind:         QueryResponseKind::CallResult(CallResult {
                        // TODO we have this structure defined already in the CLI
                        // So we can move it to somewhere common
                        result: serde_json::to_vec_pretty(&json!([
                            NodeInfo::random(),
                            NodeInfo::random(),
                            NodeInfo::random()
                        ]))
                        .unwrap(),
                        logs:   Default::default(),
                    }),
                    block_height: 119467302,
                    block_hash:   self.random_crypto_hash(),
                }),
                "compute_merkle_root" => Ok(RpcQueryResponse {
                    kind:         QueryResponseKind::CallResult(CallResult {
                        // TODO: this needs to be a valid random hash :)
                        // This can be done in the batch sign pr.
                        result: serde_json::to_vec_pretty(&json!(self.random_crypto_hash().as_bytes())).unwrap(),
                        logs:   Default::default(),
                    }),
                    block_height: 119467302,
                    block_hash:   self.random_crypto_hash(),
                }),
                "get_latest_batch_id" => Ok(RpcQueryResponse {
                    kind:         QueryResponseKind::CallResult(CallResult {
                        // TODO: this needs to be a valid random hash :)
                        // This can be done in the batch sign pr.
                        result: serde_json::to_vec_pretty(&json!(self.random_crypto_hash().as_bytes())).unwrap(),
                        logs:   Default::default(),
                    }),
                    block_height: 119467302,
                    block_hash:   self.random_crypto_hash(),
                }),
                _ => unimplemented!(),
            },
            "view_access_key" => Ok(RpcQueryResponse {
                kind:         QueryResponseKind::AccessKey(
                    AccessKey {
                        nonce:      100288680000299,
                        permission: AccessKeyPermission::FullAccess,
                    }
                    .into(),
                ),
                block_height: 119467302,
                block_hash:   self.random_crypto_hash(),
            }),
            _ => unimplemented!(),
        }
    }

    async fn stop_server(&self) -> Result<(), Error> {
        println!("Shutting down Seda Test RPC");
        self.shutdown_channel
            .send(true)
            .await
            .map_err(|e| Error::Custom(e.to_string()))?;
        Ok(())
    }

    async fn tx(&self, _hash: String, _account_id: String) -> Result<FinalExecutionOutcomeView, Error> {
        println!("calling tx");
        // TODO this would normally look up the tx but for now we have dummy data
        // let tx_info = TransactionInfo::TransactionId {
        //     hash:       CryptoHash::from_str(&hash).unwrap(),
        //     account_id: account_id.parse().unwrap(),
        // };

        Ok(FinalExecutionOutcomeView {
            status:              near_primitives::views::FinalExecutionStatus::SuccessValue(vec![8]),
            transaction:         SignedTransactionView {
                signer_id:   "seda-debug.near".parse().unwrap(),
                public_key:  PublicKey::from_str("ed25519:Eyyt8zB1NfpQcYGSXLRg83Xx7xk6Z2ohPfVhouuyYY1Y").unwrap(),
                nonce:       100288680000344,
                receiver_id: "mc.seda-debug.near".parse().unwrap(),
                actions:     vec![],
                signature:   Signature::default(),
                hash:        self.random_crypto_hash(),
            },
            transaction_outcome: ExecutionOutcomeWithIdView {
                proof:      vec![MerklePathItem {
                    hash:      self.random_crypto_hash(),
                    direction: Direction::Right,
                }],
                block_hash: self.random_crypto_hash(),
                id:         self.random_crypto_hash(),
                outcome:    ExecutionOutcomeView {
                    logs:         Vec::new(),
                    receipt_ids:  vec![self.random_crypto_hash()],
                    gas_burnt:    2428030560766,
                    tokens_burnt: 242803056076600000000,
                    executor_id:  "seda-debug.near".parse().unwrap(),
                    status:       near_primitives::views::ExecutionStatusView::SuccessReceiptId(
                        self.random_crypto_hash(),
                    ),
                    metadata:     ExecutionMetadataView {
                        version:     1,
                        gas_profile: None,
                    },
                },
            },
            receipts_outcome:    Vec::new(),
        })
    }
}

'''
'''--- wasm/cli/Cargo.toml ---
[package]
name = "cli"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
clap = { workspace = true, features = ["derive", "help", "std", "string"] }
seda-runtime-sdk = { workspace = true, features = ["full", "wasm"] }

'''
'''--- wasm/cli/src/main.rs ---
use clap::{Parser, Subcommand};
use seda_runtime_sdk::{
    wasm::{call_self, chain_call, chain_view, db_set, http_fetch, log, p2p_broadcast_message, Promise},
    Chain,
    FromBytes,
    PromiseStatus,
};

#[derive(Debug, Parser)]
#[command(name = "seda")]
#[command(author = "https://github.com/SedaProtocol")]
#[command(version = "0.1.0")]
#[command(about = "For interacting with the SEDA protocol.", long_about = None)]
struct Options {
    #[command(subcommand)]
    command: Option<Commands>,
}

#[derive(Debug, Subcommand)]
enum Commands {
    P2p {
        message: String,
    },
    Hello,
    HttpFetch {
        url: String,
    },
    View {
        chain:       Chain,
        contract_id: String,
        method_name: String,
        args:        String,
    },
    Call {
        chain:       Chain,
        contract_id: String,
        method_name: String,
        args:        String,
        deposit:     u128,
    },
}

fn main() {
    let options = Options::parse();
    log!(seda_runtime_sdk::Level::Debug, "options: {options:?}");

    if let Some(command) = options.command {
        match command {
            Commands::HttpFetch { url } => {
                http_fetch(&url).start().then(call_self("http_fetch_result", vec![]));
            }
            Commands::P2p { message } => {
                println!("Received a message from inside wasm {message}");
                p2p_broadcast_message(vec![23]).start();
            }
            Commands::Hello => {
                println!("Hello World from inside wasm");
            }
            Commands::View {
                chain,
                contract_id,
                method_name,
                args,
            } => {
                chain_view(chain, contract_id, method_name, args.into_bytes())
                    .start()
                    .then(call_self("chain_view_test_success", vec![]));
            }
            Commands::Call {
                chain,
                contract_id,
                method_name,
                args,
                deposit,
            } => {
                chain_call(chain, contract_id, method_name, args.into_bytes(), deposit)
                    .start()
                    .then(call_self("chain_call_test_success", vec![]));
            }
        }
    }
}

#[no_mangle]
fn http_fetch_result() {
    let result = Promise::result(0);

    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };

    println!("Value: {value_to_store}");
}

#[no_mangle]
fn chain_view_test_success() {
    let result = Promise::result(0);
    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };
    println!("Value: {value_to_store}");

    db_set("chain_view_result", &value_to_store).start();
}

#[no_mangle]
fn chain_call_test_success() {
    let result = Promise::result(0);
    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };
    println!("Value: {value_to_store}");
    db_set("chain_call_result", &value_to_store).start();
}

'''
'''--- wasm/consensus/Cargo.toml ---
[package]
name = "consensus"
version = "0.1.0"
edition = "2021"

[dependencies]
clap = { workspace = true, features = [
	"derive",
	"error-context",
	"help",
	"std",
	"string",
] }
hex = { workspace = true }
primitive-types = { workspace = true }
seda-common = { workspace = true }
seda-runtime-sdk = { workspace = true, features = ["full", "wasm"] }
serde = { workspace = true, features = ["derive"] }
serde_json = { workspace = true }

'''
'''--- wasm/consensus/src/main.rs ---
use clap::Parser;

mod message;
mod tasks;
mod types;

#[derive(Debug, Parser)]
struct Options {
    #[command(subcommand)]
    task: tasks::Task,
}

fn main() {
    let options = Options::parse();
    options.task.handle();
}

'''
'''--- wasm/consensus/src/message.rs ---
use std::str::FromStr;

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BatchMessage {
    pub batch_header:       Vec<u8>,
    pub bn254_public_key:   Vec<u8>,
    pub signature:          Vec<u8>,
    pub ed25519_public_key: Vec<u8>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Message {
    Batch(BatchMessage),
}

// TODO: impl Bytes Trait
// impl Message {
//     pub fn to_bytes(&self) -> Vec<u8> {
//         serde_json::to_vec(self).expect("Failed to convert to json bytes")
//     }

//     pub fn from_bytes(bytes: &[u8]) -> Self {
//         serde_json::from_slice(bytes).expect("Failed to get message from json
// bytes")     }
// }

impl FromStr for Message {
    // TODO: Error handling for consensus
    type Err = ();

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Ok(serde_json::from_str(s).expect("Failed to read from json string"))
    }
}

'''
'''--- wasm/consensus/src/tasks/batch.rs ---
use clap::Args;
use primitive_types::U256;
use seda_common::{ComputeMerkleRootResult, MainChainConfig};
use seda_runtime_sdk::{
    log,
    to_yocto,
    wasm::{
        bn254_sign,
        call_self,
        chain_call,
        chain_view,
        get_local_bn254_public_key,
        get_local_ed25519_public_key,
        get_oracle_contract_id,
        p2p_broadcast_message,
        shared_memory_get,
        shared_memory_set,
        Bn254PublicKey,
        Promise,
    },
    FromBytes,
    Level,
    PromiseStatus,
};
use serde_json::json;

use crate::{
    message::{BatchMessage, Message},
    types::batch_signature::{
        add_public_key,
        add_signature,
        get_or_create_batch_signature_store,
        BatchSignatureStore,
        BATCH_SIGNATURE_STORE_KEY,
    },
};

#[derive(Debug, Args)]
pub struct Batch;

impl Batch {
    pub fn handle(self) {
        let contract_id = get_oracle_contract_id();
        log!(Level::Debug, "[BatchTask] Starting task for contract id: {contract_id}");

        // TODO: Temp fix, need to fix env variables
        shared_memory_set("contract_id", contract_id.clone().into());
        shared_memory_set(
            "ed25519_public_key",
            hex::decode(get_local_ed25519_public_key()).expect("Missing WASI env var for ED25519 public key"),
        );
        shared_memory_set(
            "bn254_public_key",
            hex::decode(get_local_bn254_public_key()).expect("Missing WASI env var for BN254 public key"),
        );

        chain_view(
            seda_runtime_sdk::Chain::Near,
            &contract_id,
            "compute_merkle_root",
            Vec::new(),
        )
        .start()
        // TODO: config logic should be moved to its own task
        .then(chain_view(
            seda_runtime_sdk::Chain::Near,
            &contract_id,
            "get_config",
            Vec::new(),
        ))
        .then(chain_view(
            seda_runtime_sdk::Chain::Near,
            contract_id,
            "get_last_generated_random_number",
            Vec::new(),
        ))
        .then(call_self("batch_step_1", vec![]));
    }
}

#[no_mangle]
fn batch_step_1() {
    // Retrieve data from shared memory
    let contract_id =
        String::from_utf8(shared_memory_get("contract_id")).expect("Could not read contract id from shared memory");
    let bn254_public_key = shared_memory_get("bn254_public_key");
    let ed25519_public_key = shared_memory_get("ed25519_public_key");
    let mut signature_store = get_or_create_batch_signature_store(BATCH_SIGNATURE_STORE_KEY);

    // Retrieve batch from promise result
    let batch: ComputeMerkleRootResult = match Promise::result(0) {
        PromiseStatus::Fulfilled(Some(batch_bytes)) => serde_json::from_slice(&batch_bytes)
            .expect("Cannot convert `merkle_root` json to `ComputeMerkleRootResult`"),
        PromiseStatus::Rejected(error) => {
            let err = String::from_bytes_vec(error).unwrap();
            panic!("`compute_merkle_root` promise rejected: {err:?}");
        }
        other => {
            panic!("`compute_merkle_root` promise other: {other:?}");
        }
    };

    let node_implicit_account = hex::encode(&ed25519_public_key);
    log!(
        Level::Debug,
        "[BatchTask][Slot #{}] Processing batch #{} (leader: {})",
        &batch.current_slot,
        hex::encode(&batch.merkle_root),
        Some(&node_implicit_account) == batch.current_slot_leader.as_ref()
    );

    // Process batch (includes verification and broadcasting)
    process_batch(&batch, &mut signature_store, &ed25519_public_key, &bn254_public_key);
    // Process slot leader logic (only if node is slot leader)
    if batch.current_slot_leader.is_none() {
        log!(Level::Info, "Main-chain contract still bootstrapping (no slot leader)");
    } else if batch.current_slot_leader == Some(node_implicit_account) {
        process_slot_leader(&batch, &mut signature_store, &contract_id);
    }
}

fn process_batch(
    batch: &ComputeMerkleRootResult,
    signature_store: &mut BatchSignatureStore,
    ed25519_public_key: &[u8],
    bn254_public_key: &[u8],
) {
    // Case 1. Check if it was already processed
    if batch.merkle_root == signature_store.batch_header && batch.current_slot == signature_store.slot {
        log!(
            Level::Debug,
            "[BatchTask][Slot #{}] Ignoring batch #{} (already processed and recently broadcasted)",
            batch.current_slot,
            hex::encode(&batch.merkle_root)
        );
    }
    // Case 2. Check if was processed but not broadcasted during this slot
    else if batch.merkle_root == signature_store.batch_header && batch.current_slot != signature_store.slot {
        log!(
            Level::Debug,
            "[BatchTask][Slot #{}] Broadcasting previous batch #{} (already processed)",
            batch.current_slot,
            hex::encode(&batch.merkle_root)
        );

        signature_store.slot = batch.current_slot;
        shared_memory_set(
            BATCH_SIGNATURE_STORE_KEY,
            serde_json::to_string(&signature_store).unwrap().into(),
        );

        p2p_broadcast_message(signature_store.p2p_message.clone()).start();
    }
    // Case 3. Process new batch with different merkle root
    else {
        log!(
            Level::Debug,
            "[BatchTask][Slot #{}] Processing new batch #{}",
            batch.current_slot,
            hex::encode(&batch.merkle_root)
        );

        // FIXME: Verify that this batch points to the previous batch
        let bn254_signature = bn254_sign(&batch.merkle_root);

        // Update signature store with new batch data
        let mut signature_store = BatchSignatureStore::new(batch.current_slot, batch.clone().merkle_root);

        signature_store.aggregated_signature = add_signature(signature_store.aggregated_signature, bn254_signature)
            .to_uncompressed()
            .expect("Could not compress Bn254 signature");

        signature_store.aggregated_public_keys = add_public_key(
            signature_store.aggregated_public_keys,
            Bn254PublicKey::from_uncompressed(bn254_public_key).expect("Could not derive key"),
        )
        .to_uncompressed()
        .expect("Could not compress Bn254 Public Key");

        signature_store.signers.push(hex::encode(ed25519_public_key));

        signature_store.signatures.insert(
            hex::encode(bn254_public_key),
            bn254_signature.to_uncompressed().unwrap(),
        );

        signature_store.slot = batch.current_slot;

        let message = Message::Batch(BatchMessage {
            batch_header:       batch.clone().merkle_root,
            bn254_public_key:   bn254_public_key.to_vec(),
            signature:          bn254_signature.to_uncompressed().expect("TODO"),
            ed25519_public_key: ed25519_public_key.to_vec(),
        });
        signature_store.p2p_message =
            serde_json::to_vec(&message).expect("`BatchMessage` could not be serialized to bytes");

        // TODO: process accumulated batch messages from previous P2P tasks

        shared_memory_set(
            BATCH_SIGNATURE_STORE_KEY,
            serde_json::to_string(&signature_store)
                .expect("Could not convert SignatureStore to json")
                .into(),
        );

        p2p_broadcast_message(signature_store.p2p_message.clone()).start();
    }
}

fn process_slot_leader(batch: &ComputeMerkleRootResult, signature_store: &mut BatchSignatureStore, contract_id: &str) {
    // Retrieve chain config and last random number from promise results
    let chain_config = if let PromiseStatus::Fulfilled(Some(config)) = Promise::result(1) {
        serde_json::from_slice::<MainChainConfig>(&config).expect("Config is not of type `MainChainConfig`")
    } else {
        panic!("Could not fetch config from contract");
    };
    let last_random_number = if let PromiseStatus::Fulfilled(Some(num)) = Promise::result(2) {
        // Example of encoded number:
        // 85808566236214186893554888775712866405891396064732569795826684455150103772489
        let encoded = serde_json::from_slice::<String>(&num).expect("random number is not a string");
        U256::from_dec_str(&encoded).expect("Generated number is not a U256")
    } else {
        panic!("Could not fetch random number");
    };

    log!(
        Level::Info,
        "[BatchTask][Slot #{}] Selected as slot leader (got {}/{} signatures for batch #{})",
        batch.current_slot,
        signature_store.signatures.len(),
        chain_config.committee_size,
        hex::encode(&batch.merkle_root)
    );

    // Check if node has stored all signatures
    // TODO: Change to 2/3 in the future
    if chain_config.committee_size == signature_store.signatures.len() as u64 {
        let mut last_random_value_bytes: [u8; 32] = [0; 32];
        last_random_number.to_little_endian(&mut last_random_value_bytes);

        let leader_signature_bytes = bn254_sign(&last_random_value_bytes)
            .to_uncompressed()
            .expect("Could not compress Bn254 signaturre");

        log!(
            Level::Info,
            "[BatchTask][Slot #{}] Submitting signed batch #{} to contract `{}` with {}/{} aggregated signagutes",
            batch.current_slot,
            hex::encode(&batch.merkle_root),
            contract_id,
            signature_store.signatures.len(),
            chain_config.committee_size,
        );

        chain_call(
            seda_runtime_sdk::Chain::Near,
            contract_id,
            "post_signed_batch",
            json!({
                "aggregate_signature": signature_store.aggregated_signature,
                "aggregate_public_key": signature_store.aggregated_public_keys,
                "signers": signature_store.signers,
                "leader_signature": leader_signature_bytes
            })
            .to_string()
            .into_bytes(),
            // TODO: double-check deposit value
            to_yocto("1"),
        )
        .start();
    }
}

'''
'''--- wasm/consensus/src/tasks/bridge.rs ---
use clap::Args;
use seda_runtime_sdk::{
    log,
    wasm::{
        call_self,
        chain_call,
        chain_view,
        get_oracle_contract_id,
        memory_read,
        memory_write,
        shared_memory_get,
        shared_memory_set,
        Promise,
    },
    Chain,
    FromBytes,
    Level,
    PromiseStatus,
    ToBytes,
};

#[derive(Debug, Args)]
pub struct Bridge {
    chain:       Chain,
    contract_id: String,
    method_name: String,
    deposit:     u128,
    args:        String,
}

impl Bridge {
    pub fn handle(self) {
        log!(Level::Debug, "Bridge Handle");

        // TODO: Temp fix, need to fix env variables
        let contract_id = get_oracle_contract_id();
        shared_memory_set("contract_id", contract_id.into());

        // we have a method to auto convert to bytes in a trait in runtime.
        // it should be moved to the sdk
        // TODO: SEDA-188 will make it so we can pass these instead of a vec of strings
        // to .then()
        memory_write("bridge_deposit", self.deposit.to_bytes().eject());
        chain_view(self.chain, self.contract_id, self.method_name, self.args.into_bytes())
            .start()
            .then(call_self("bridge_step_1", vec![]));
    }
}

#[no_mangle]
fn bridge_step_1() {
    log!(Level::Debug, "Bridge Step 1");
    let contract_id =
        String::from_utf8(shared_memory_get("contract_id")).expect("Could not read contract id from shared memory");
    let result = Promise::result(0);
    let deposit_bytes = memory_read("bridge_deposit");
    let deposit = u128::from_bytes_vec(deposit_bytes).unwrap();
    match result {
        // TODO: I wonder if SEDA-188 could also make it so we don't have to do these conversions manually?
        PromiseStatus::Fulfilled(Some(data)) => {
            let data = String::from_bytes_vec(data).expect("chain_view resulted in a invalid string");
            let args_string = serde_json::json!({ "data_request": data }).to_string();
            log!(Level::Debug, "Posting args: {args_string}");
            chain_call(
                Chain::Near,
                contract_id, // TODO: Currently panics
                "post_data_request",
                args_string.into_bytes(),
                deposit,
            )
            .start()
            .then(call_self("bridge_step_2", vec![]));
        }
        _ => log!(Level::Error, "Cannot bridge sub chain view failed"),
    }
}

#[no_mangle]
fn bridge_step_2() {
    log!(Level::Debug, "Bridge Step 2");
    let result = Promise::result(0);
    println!("{{\"status\": \"success\"}}");
    match result {
        PromiseStatus::Fulfilled(Some(vec)) => log!(
            Level::Debug,
            "Success message: {}",
            String::from_bytes_vec(vec).unwrap()
        ),
        _ => log!(Level::Error, "Posting bridge result to main chain failed."),
    }
}

'''
'''--- wasm/consensus/src/tasks/mod.rs ---
use clap::Subcommand;

mod batch;
mod bridge;
mod p2p;

#[derive(Debug, Subcommand)]
pub enum Task {
    Batch(batch::Batch),
    Bridge(bridge::Bridge),
    P2P(p2p::P2P),
}

impl Task {
    pub fn handle(self) {
        match self {
            Self::Batch(batch) => batch.handle(),
            Self::Bridge(bridge) => bridge.handle(),
            Self::P2P(p2p) => p2p.handle(),
        }
    }
}

'''
'''--- wasm/consensus/src/tasks/p2p.rs ---
use std::str::FromStr;

use clap::Args;
use seda_runtime_sdk::{
    log,
    wasm::{bn254_verify, shared_memory_set, Bn254PublicKey, Bn254Signature},
    Level,
};

use crate::{
    message::Message,
    types::batch_signature::{
        add_public_key,
        add_signature,
        get_or_create_batch_signature_store,
        BATCH_SIGNATURE_STORE_KEY,
    },
};

#[derive(Debug, Args)]
pub struct P2P {
    // TODO should change to bytes for more efficiency
    message: String,
}

impl P2P {
    /// This function should behave as follows:
    ///  1. Generic verifications:
    ///     * Check if batch is valid
    ///         - signed by a member of current epoch committee
    ///         - valid bn254 signature
    ///     * Otherwise, it is ignored and P2P counter-measure is triggered
    ///  2. Check batch header (i.e., merkle root)
    ///     * If current known batch, append to list of accumulated signatures
    ///     * If unknown batch, add to future batch list (current batch was
    ///       submitted)
    pub fn handle(self) {
        let message = Message::from_str(&self.message).expect("Failed to decode message");

        match message {
            Message::Batch(batch_message) => {
                // Step 1: batch verifications
                // TODO: check that batch was signed by a member of the epoch committee

                // Check valid bn254 signature
                let bn254_signature = Bn254Signature::from_uncompressed(&batch_message.signature)
                    .expect("Could not get signature from compressed bytes");
                let bn254_public_key = Bn254PublicKey::from_uncompressed(&batch_message.bn254_public_key)
                    .expect("Could not get signature from compressed bytes");

                if !bn254_verify(
                    &batch_message.batch_header,
                    &bn254_signature,
                    &Bn254PublicKey::from_uncompressed(&batch_message.bn254_public_key).unwrap(),
                ) {
                    // TODO: Check if we should disconnect p2p node/slashed/measures
                    log!(
                        Level::Warn,
                        "[P2PTask] Received P2P batch message with an invalid Bn254 signature"
                    );

                    return;
                }

                // Step 2: check batch message data
                let mut signature_store = get_or_create_batch_signature_store(BATCH_SIGNATURE_STORE_KEY);

                // Case 1: batch message for same batch header / merkle root
                if batch_message.batch_header == signature_store.batch_header {
                    // Check if batch signature was already been included
                    let bn254_public_key_str = hex::encode(&batch_message.bn254_public_key);
                    if signature_store.signatures.contains_key(&bn254_public_key_str) {
                        // TODO: Check if we should disconnect p2p node/slashed/measures
                        log!(
                            Level::Warn,
                            "[P2PTask] Received P2P batch message with duplicated signature"
                        );

                        return;
                    }

                    // Aggregate signature and public key
                    let new_aggregate_signature = add_signature(signature_store.aggregated_signature, bn254_signature)
                        .to_uncompressed()
                        .expect("Could not compress Bn254 signature");
                    let new_aggregate_public_key =
                        add_public_key(signature_store.aggregated_public_keys, bn254_public_key)
                            .to_uncompressed()
                            .expect("Could not compress Bn254 Public Key");
                    let ed25519_public_key_str = hex::encode(&batch_message.ed25519_public_key);

                    signature_store.aggregated_signature = new_aggregate_signature;
                    signature_store.aggregated_public_keys = new_aggregate_public_key;
                    signature_store.signers.push(ed25519_public_key_str);
                    signature_store
                        .signatures
                        .insert(bn254_public_key_str, batch_message.signature);

                    log!(
                        Level::Debug,
                        "[P2PTask] Added new signature to batch #{} (total: {})",
                        hex::encode(&signature_store.batch_header),
                        signature_store.signatures.len()
                    );
                }
                // Case 2: batch message for unknown batch header / merkle root
                else {
                    log!(
                        Level::Warn,
                        "[P2PTask] Received a P2P batch message for a (yet) unknown batch header"
                    );
                    // TODO: accumulate future batch messages to be processed by Batch Task
                    todo!("Not yet implemented because batch header is always the same");
                }

                // Save changes in shared memory
                shared_memory_set(
                    BATCH_SIGNATURE_STORE_KEY,
                    serde_json::to_string(&signature_store).unwrap().into(),
                );
            }
        }
    }
}

'''
'''--- wasm/consensus/src/types/batch_signature.rs ---
use std::collections::HashMap;

use seda_runtime_sdk::wasm::{shared_memory_contains_key, shared_memory_get, Bn254PublicKey, Bn254Signature};
use serde::{Deserialize, Serialize};

pub const BATCH_SIGNATURE_STORE_KEY: &str = "batch_signatures";

const EMPTY_SHA256: [u8; 32] = [
    227, 176, 196, 66, 152, 252, 28, 20, 154, 251, 244, 200, 153, 111, 185, 36, 39, 174, 65, 228, 100, 155, 147, 76,
    164, 149, 153, 27, 120, 82, 184, 85,
];

#[derive(Serialize, Deserialize)]
pub struct BatchSignatureStore {
    pub aggregated_signature:   Vec<u8>,
    pub aggregated_public_keys: Vec<u8>,
    /// Vec of accountIds (implicit ed25519 public keys)
    pub signers:                Vec<String>,
    // Hashmap<Bn254PublicKey, Bn254Signature>
    pub signatures:             HashMap<String, Vec<u8>>,
    pub slot:                   u64,
    pub batch_header:           Vec<u8>,
    pub p2p_message:            Vec<u8>,
}

impl Default for BatchSignatureStore {
    fn default() -> Self {
        Self {
            aggregated_public_keys: Default::default(),
            aggregated_signature:   Default::default(),
            batch_header:           EMPTY_SHA256.to_vec(),
            p2p_message:            Default::default(),
            signatures:             Default::default(),
            signers:                Default::default(),
            slot:                   0,
        }
    }
}

impl BatchSignatureStore {
    pub fn new(slot: u64, root: Vec<u8>) -> Self {
        BatchSignatureStore {
            aggregated_public_keys: Vec::new(),
            aggregated_signature: Vec::new(),
            batch_header: root,
            p2p_message: Default::default(),
            signatures: HashMap::new(),
            signers: Vec::new(),
            slot,
        }
    }
}

pub fn get_or_create_batch_signature_store(storage_key: &str) -> BatchSignatureStore {
    if shared_memory_contains_key(storage_key) {
        serde_json::from_slice(&shared_memory_get(storage_key)).expect("Invalid stored `BatchSignatureStore` object")
    } else {
        BatchSignatureStore::default()
    }
}

pub fn add_signature(aggregated_signature: Vec<u8>, signature: Bn254Signature) -> Bn254Signature {
    if aggregated_signature.is_empty() {
        return signature;
    }

    Bn254Signature::from_uncompressed(aggregated_signature).expect("Given Bn254Signature signature is not decodable")
        + signature
}

pub fn add_public_key(aggregated_public_key: Vec<u8>, public_key: Bn254PublicKey) -> Bn254PublicKey {
    if aggregated_public_key.is_empty() {
        return public_key;
    }

    Bn254PublicKey::from_uncompressed(aggregated_public_key).expect("Given Bn254PublicKey is not decodable")
        + public_key
}

'''
'''--- wasm/consensus/src/types/mod.rs ---
pub mod batch_signature;

'''
'''--- wasm/test/demo-cli/Cargo.toml ---
[package]
name = "demo-cli"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
clap = { workspace = true, features = ["derive", "std", "string"] }
seda-runtime-sdk = { workspace = true, features = ["full", "wasm"] }

'''
'''--- wasm/test/demo-cli/src/main.rs ---
use clap::{Parser, Subcommand};
use seda_runtime_sdk::{
    wasm::{call_self, chain_call, chain_view, db_set, http_fetch, Promise},
    Chain,
    FromBytes,
    PromiseStatus,
};

#[derive(Parser)]
#[command(name = "seda")]
#[command(author = "https://github.com/SedaProtocol")]
#[command(version = "0.1.0")]
#[command(about = "For interacting with the SEDA protocol.", long_about = None)]
struct Options {
    #[command(subcommand)]
    command: Option<Commands>,
}

#[derive(Subcommand)]
enum Commands {
    Hello,
    HttpFetch {
        url: String,
    },
    View {
        chain:       Chain,
        contract_id: String,
        method_name: String,
        args:        String,
    },
    Call {
        chain:       Chain,
        contract_id: String,
        method_name: String,
        args:        String,
        deposit:     u128,
    },
}

fn main() {
    let options = Options::parse();

    if let Some(command) = options.command {
        match command {
            // cargo run cli http-fetch "https://www.breakingbadapi.com/api/characters/1"
            Commands::HttpFetch { url } => {
                http_fetch(&url).start().then(call_self("http_fetch_result", vec![]));
            }
            Commands::Hello => {
                println!("Hello World from inside wasm");
            }
            //cargo run cli view mc.mennat0.testnet get_node_owner "{\"node_id\":\"12\"}"
            Commands::View {
                chain,
                contract_id,
                method_name,
                args,
            } => {
                chain_view(chain, contract_id, method_name, args.into_bytes())
                    .start()
                    .then(call_self("chain_view_test_success", vec![]));
            }
            // cargo run cli call mc.mennat0.testnet register_node "{\"socket_address\":\"127.0.0.1:8080\"}"
            // "870000000000000000000"
            Commands::Call {
                chain,
                contract_id,
                method_name,
                args,
                deposit,
            } => {
                chain_call(chain, contract_id, method_name, args.into_bytes(), deposit)
                    .start()
                    .then(call_self("chain_call_test_success", vec![]));
            }
        }
    }
}

#[no_mangle]
fn http_fetch_result() {
    let result = Promise::result(0);

    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };

    println!("Value: {value_to_store}");
}

#[no_mangle]
fn chain_view_test_success() {
    let result = Promise::result(0);
    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };
    println!("Value: {value_to_store}");

    db_set("chain_view_result", &value_to_store).start();
}

#[no_mangle]
fn chain_call_test_success() {
    let result = Promise::result(0);
    let value_to_store: String = match result {
        PromiseStatus::Fulfilled(Some(vec)) => String::from_bytes_vec(vec).unwrap(),
        _ => "Promise failed..".to_string(),
    };
    println!("Value: {value_to_store}");
    db_set("chain_call_result", &value_to_store).start();
}

'''
'''--- wasm/test/promise-wasm-bin/Cargo.toml ---
[package]
name = "promise-wasm-bin"
version = "0.1.0"
edition = "2021"
rust-version.workspace = true

[dependencies]
seda-runtime-sdk = { workspace = true, features = ["full", "wasm"] }

'''
'''--- wasm/test/promise-wasm-bin/src/main.rs ---
use std::{env, fmt::Write, num::ParseIntError};

use seda_runtime_sdk::{
    wasm::{
        bn254_sign,
        bn254_verify,
        call_self,
        db_get,
        db_set,
        execution_result,
        http_fetch,
        memory_read,
        memory_write,
        shared_memory_get,
        shared_memory_set,
        Bn254PrivateKey,
        Bn254PublicKey,
        Bn254Signature,
        Promise,
    },
    FromBytes,
    PromiseStatus,
    ToBytes,
};

fn main() {
    let args: Vec<String> = env::args().collect();

    println!("Hello World {:?}", args);

    db_set("from_wasm", "somevalue")
        .start()
        .then(db_get("from_wasm"))
        .then(call_self("db_fetch_success", vec!["ArgFromInsideWasm".to_string()]));
}

#[no_mangle]
fn db_fetch_success() {
    let args: Vec<String> = env::args().collect();
    println!("Inside the callback {:?}", args);
    Promise::result(1);

    db_set("another_one", "a")
        .start()
        .then(db_set("x", "y"))
        .then(db_get("another_one"))
        .then(call_self("completed_all", vec![]));
}

#[no_mangle]
fn completed_all() {
    db_set("test_value", "completed").start();

    Promise::result(2);
}

#[no_mangle]
fn http_fetch_test() {
    let args: Vec<String> = env::args().collect();
    println!("Hello world {:?}", args);

    http_fetch(args.get(1).unwrap())
        .start()
        .then(call_self("http_fetch_test_success", vec![]));
}

#[no_mangle]
fn http_fetch_test_success() {
    let result = Promise::result(0);

    if let PromiseStatus::Fulfilled(Some(bytes)) = result {
        let value_to_store = String::from_bytes_vec(bytes).unwrap();

        db_set("http_fetch_result", &value_to_store).start();
    }
}

#[no_mangle]
fn memory_adapter_test_success() {
    let key = "u8";
    let value = 234u8.to_bytes().eject();
    memory_write(key, value.clone());

    let read_value = memory_read(key);
    println!("read_value: {read_value:?}");
    assert_eq!(read_value, value);

    let key = "u32";
    let value = 3467u32.to_bytes().eject();
    memory_write(key, value);
    call_self("memory_adapter_callback_test_success", Vec::new()).start();
}

#[no_mangle]
fn memory_adapter_callback_test_success() {
    let read_value = memory_read("u8");
    db_set("u8_result", &format!("{read_value:?}")).start();
    let read_value = memory_read("u32");
    db_set("u32_result", &format!("{read_value:?}")).start();
}

#[no_mangle]
fn test_setting_execution_result() {
    db_set("random_key", "random_value")
        .start()
        .then(call_self("test_setting_execution_result_step1", vec![]));
}

#[no_mangle]
fn test_setting_execution_result_step1() {
    let result = "test-success".to_bytes().eject();
    execution_result(result);
}

#[no_mangle]
fn test_limited_runtime() {
    db_set("foo", "bar").start().then(call_self("test_rejected", vec![]));
}

#[no_mangle]
fn bn254_verify_test() {
    let args: Vec<String> = env::args().collect();
    println!("bn254 verify test: {:?}", args);

    // Message
    let message_hex = args.get(1).unwrap();
    let message = decode_hex(message_hex).unwrap();

    // Signature
    let signature_hex = args.get(2).unwrap();
    let signature_bytes = decode_hex(signature_hex).unwrap();
    let signature = Bn254Signature::from_uncompressed(signature_bytes).unwrap();

    // Public key
    let public_key_hex = args.get(3).unwrap();
    let public_key_bytes = decode_hex(public_key_hex).unwrap();
    let public_key = Bn254PublicKey::from_uncompressed(public_key_bytes).unwrap();

    let result = bn254_verify(&message, &signature, &public_key);
    db_set("bn254_verify_result", &format!("{result}")).start();
}

#[no_mangle]
fn bn254_sign_test() {
    let args: Vec<String> = env::args().collect();
    println!("bn254 sign test: {:?}", args);

    // Message
    let message_hex = args.get(1).unwrap();
    let message = decode_hex(message_hex).unwrap();

    // Private Key
    let private_key_hex = args.get(2).unwrap();
    let private_key_bytes = decode_hex(private_key_hex).unwrap();
    let _private_key = Bn254PrivateKey::try_from(private_key_bytes.as_slice()).unwrap();

    let result = bn254_sign(&message);
    let result_hex = encode_hex(&result.to_uncompressed().unwrap());
    db_set("bn254_sign_result", &result_hex).start();
}

// TODO: Something to include in our SDK? Or bn254 lib. Or use hex crate.
fn decode_hex(s: &str) -> Result<Vec<u8>, ParseIntError> {
    (0..s.len())
        .step_by(2)
        .map(|i| u8::from_str_radix(&s[i..i + 2], 16))
        .collect()
}

// TODO: Something to include in our SDK? Or bn254 lib. Or use hex crate.
fn encode_hex(bytes: &[u8]) -> String {
    let mut result = String::with_capacity(bytes.len() * 2);
    for &b in bytes {
        write!(&mut result, "{:02x}", b).unwrap();
    }

    result
}

#[no_mangle]
fn test_error_turns_into_rejection() {
    http_fetch("fail!").start().then(call_self("test_rejected", vec![]));
}

#[no_mangle]
fn test_rejected() {
    let result = Promise::result(0);
    if let PromiseStatus::Rejected(rejected) = result {
        let str = String::from_bytes(&rejected).unwrap();
        println!("Promise rejected: {str}");
    } else {
        panic!("didn't reject");
    }
}

#[no_mangle]
fn shared_memory_test() {
    shared_memory_set("foo", "bar".to_bytes().eject());
}

#[no_mangle]
fn shared_memory_success() {
    let foo_get = shared_memory_get("foo");
    let bar = String::from_bytes_vec(foo_get).unwrap();
    assert_eq!("bar", bar);
}

'''